Content,Tag,Label,Link,Inter
Call for InternsNASA Science Data VisualizationCome visualize space craft and remote sensing data on the planetary scale with the NASA JPL / Caltech / Art Center visualization internship  a multi-disciplinary program for computer scientists and designers.We use visualization to understand the universe.Students will develop creative interactive visualization tools for scientific research/engineering groups selected from a broad set of areas at JPL and Caltech. Working in multidisciplinary teams  students will use methods from User-Centered Design  computing  3D graphics and interaction design to visualize real data sets that support active scientific research. They will receive mentorship in visualization  computing and design from program co-organizers Hillary Mushkin (Caltech)  Scott Davidoff (JPL) and Maggie Hendrie (Art Center) as well as Santiago Lombeyda (Caltech). Students will work closely with scientific or engineering researchers to understand their research and data  identify their visualization needs and determine the relevance of design iterations to their research and data. This should be a good opportunity for students interested in data visualization techniques and real world problems who want to gain experience crossing disciplinary boundariesDATES | June 17 – August 23  2019 (to be confirmed)LOCATION | Pasadena  CaliforniaSALARY | $6.3K for undergraduates  $8.3K for graduate studentsELIGIBILITY | Applicants must be continuing students. Students graduating before fall 2019 are not eligible to apply. THESE PROJECTS REQUIRE COLLABORATION WITH JPL. THEREFORE STUDENTS MUST BE US CITIZENS OR PERMANENT RESIDENTS. GPA must be >= 3.0APPLICATIONS | via email to datavis@caltech.edu; including CV (+Portfolio if relevant) and answers to the following: 1. Why do you want to work in visualization? 2. What visualization experience do you have? 3. What example of visualization do you particularly find inspiring and why? or what example of visualization do you find misleading or ineffective and how would you propose fixing it?DEADLINE | Accepting applications now  until the positions are filled.Questions? Email datavis@caltech.eduSummer Internship – Social Dynamics TeamNokia Bell Labs Cambridge (UK)If you would like to apply  please send your application in pdf format with the subject line “Internship 2019” to daniele.quercia@nokia-bell-labs.com by *January 27th*  2019. Your application will be used solely for the purpose of selecting internship candidates and will be deleted as soon as the selection is complete.The Social Dynamics team at Nokia Bell Labs Cambridge (UK) is looking for summer interns to work on the following internship projects (http://researchswinger.org/hiring.html):1. Visual AI. Creating new beautiful and elegant techniques to display and visualize the results of state-of-the-art artificial intelligence models. Experience with Web Design and Frontend Development (HTML5  Javascript  D3)2. The Language of Love. Learn the typical markers of different types of social exchange from large corpora of text. Enrolled in PhD in NLP or related fields. Experience with Python  Machine Learning  Natural Language Processing  and Big Data Analysis.3. Tracking Well Being with Mobile Sensing. Develop mobile sensing solutions to obtain physiological readings and build models to measure psychological well being. Enrolled in PhD in Computer Science  HCI or related fields. Experience with Python  Machine Learning  Mobile and Wearable Development.4. The Social Life of Cities. Investigate how the urban space shapes our social relationships. Enrolled in PhD in Computational Social Science or related fields. Experience with Python  GIS tools  Network Analysis.5. Healthy City and Human Behavior. Investigate how air and sound pollutions affect human behavior. Enrolled in PhD in any computational field. Experience with Python  GIS tools  and Geographic Studies.6. Look from Above. Investigate the usefulness of satellite data for discovering intangible urban properties such as dwellers’ happiness. Enrolled in PhD in Computer Science  Geography  or related. Experience with Python  Computer Vision (experience with Deep Learning Models is a plus)  GIS tools  and Web Development.7. Exploring Causality in Well-being Data. Study observational social media data reflecting emotional support online and explain causal relationships. Enrolled in PhD in Computer Science or related fields. Experience with Python  Machine Learning  Causality  and Web Development.To learn more about our research  please check our sites: researchswinger.org  lajello.com  goodcitylife.org  sanja7s.space  comarios.com  and sites.google.com/site/keadamzhou.Research Intern PositionB12To apply  please send an email to pao@b12.io with your CV.Who we areB12 is building a better future of creative and analytical work. Our current product provides customers with AI-generated websites  and connects them with designers who help them improve their website through our open source framework Orchestra.We’re an NYC-based startup that is excited about research  has 4 Ph.D.s in fields like Human-Computer Interaction and Database Systems. We’d love to collaborate on projects that both you  your advisor  and our team are all excited about. We want to publish our findings in top-tier conferences.What you’ll doPotential summer 2019 projectsYou’d be a good fit ifSummer Design InternMicrosoft Research – Human-Computer InteractionTo apply  email CV to John Tang at johntang@microsoft.comMicrosoft Research is looking for a design-oriented intern for a project that explores designing user experiences around video calling for people with the Autism Spectrum Disorder. Given the challenges that people with ASD can have in detecting and expressing emotion in social conversations  we’re exploring ways to use AI to detect emotion in video calling  and then design a UX that helps people with ASD to perceive that emotion and conversely express that emotion  probably through some visual display overlaid or associated with the video call UX. We’re not sure exactly what that will look like (or sound or feel like)  so we’re looking for an intern to help us explore the design space. Even better if the intern has some experience with user studies that could help us evaluate a working prototype with people with ASD. It’s a fun project at the intersection of design  accessibility  AI  and video user experiences!Summer Intern – Medical Content Outreach (MCO)St. Jude Children’s Research HospitalClick here for more details and to apply.The Medical Content Outreach (MCO) department at St. Jude Children’s Research Hospital is seeking an intern to support user experience and digital marketing for a new online pediatric cancer resource. For over half a century  St. Jude has been leading the way to find cures and advance care for children with cancer and other life-threatening diseases. The Together website (https://together.stjude.org) was launched in fall 2018  offering trustworthy information and support for all patients and families affected by childhood cancer.Intern – Digital Visual Design & Technical MarketingSolar TurbinesPaid summer internship position available and we are looking for motivated design students.Students can apply online or email Thompson Pham  Digital Design & Marketing Manager  at pham_thompson_h@solarturbines.com.Graduate Student Internships (Open Call)FXPALClick here for more details and to applyFX Palo Alto Laboratory  Inc. (FXPAL) invites highly qualified graduate students to work alongside our researchers. Although the majority of our interns come between May and September  we also accept interns on a year-round basis. Interns are selected based upon their educational standing  academic studies  potential and suitable match with our specific projects. Internships are usually 12 weeks in length. Intern candidates typically hold Bachelor’s degrees in Computer Science  Electrical Engineering  or related fields and are enrolled in an advanced degree program at the time the internship begins.Please send your resume along with contact information for two (2) references.Apply early  as personal interviews may be conducted as soon as the end of January for summer placement. Students from outside the U.S. are welcome to apply.All applicants must provide documentation to prove legal right to work in the U.S. Some relocation provisions will be offered to final candidates. FX Palo Alto Laboratory is an equal opportunity employer. We value diversity in the work place.Social Media Design InternsSkinalytics  Inc.Contact: Michele Temple-Wong  CEO  at michele.templewong@gmail.comA local start-up company is looking for student interns for the summer. The company currently has their first mobile app prototype and is looking for a team of students to begin developing the social media campaign.The student interns will work with the co-founders to develop a marketing strategy consistent with the brand. They are looking for students interested in or who have experience in multiple areas. Consistent with the brand image of the company and app the students will:Requirements:About Skinalytics  Inc.Skinalytics is a developer of software and analytics tools to make selecting skin care products more personalized  smarter  safer  and easier. They are currently developing an app to help people who have experienced reactions to skin care products avoid those chemicals/products they are sensitive to in the future.User Experience Designer InternshipVirtualiticsVirtualitics is a Pasadena-based startup  that has built an AI-driven  collaborative  data analytics and immersive visualization platform across multiple devices (Desktop  VR  AR  mobile).We are seeking a User Experience Designer intern. Ideal candidates will have solid portfolio demonstrating design principles for interface of software/mobile/VR/web. The candidate will generate UX workflow/wireframe for our immersive platform for desktop  VR  and/or mobile. Work with our internal team of engineers  scientists  game developers and designers to obtain in depth understanding of product development requirements.Minimum Requirements:Preferred:To apply please provide link to your portfolio website to jobs@virtualitics.comContact: Qi Chen (Head of UX)Website: https://www.virtualitics.comWhat we offer: A fantastic working environment; incredibly collaborative team; opportunity to learn from the best; and hourly wages. Candidates must be legally authorized to work in US.ResearchEducationCommunityEventsJobsAboutNewsContact Us,design language, 'Personal computer',https://designlab.ucsd.edu/job-categories/jobs-intern/,'hendrie computer'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.Do you want to read the rest of this article?You can request the full-text of this article directly from the authors on ResearchGate.,development life cycle ( sdlc ), 'Personal computer',https://www.researchgate.net/publication/225081395_A_Simulation_Model_for_the_Waterfall_Software_Development_Life_Cycle,'hendrie computer'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.Do you want to read the rest of this article?You can request the full-text of this article directly from the authors on ResearchGate.,earliest start time, 'Personal computer',https://tel.archives-ouvertes.fr/tel-01859929/document,'hendrie computer'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.Do you want to read the rest of this article?You can request the full-text of this article directly from the authors on ResearchGate.,evolutionary prototyping, 'Personal computer',https://www.researchgate.net/publication/234814539_Out_of_Scandinavia_Alternative_Approaches_to_Software_Design_and_System_Development,'hendrie computer'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,execution time, 'Personal computer',https://www.researchgate.net/publication/281783484_A_Simple_BSP-based_Model_to_Predict_Execution_Time_in_GPU_Applications,'hendrie computer'
"Log sort yard economics  planning  and feasibilityTreesearchJohn Rusty Dramm; Robert Govett; Ted Bilek; Gerry L. Jackson2004-01-01This publication discusses basic marketing and economic concepts  planning approach  and feasibility methodology for assessing log sort yard operations. Special attention is given to sorting small diameter and underutilized logs from forest restoration  fuels reduction  and thinning operations. A planned programming approach of objectively determining the feasibility...7 CFR 3575.47 - Economic feasibility requirements.Code of Federal Regulations  2012 CFR2012-01-01... determine economic feasibility as well as financial viability. (a) Financial feasibility. The borrower... 7 Agriculture 15 2012-01-01 2012-01-01 false Economic feasibility requirements. 3575.47 Section...  DEPARTMENT OF AGRICULTURE GENERAL Community Programs Guaranteed Loans Â§ 3575.47 Economic feasibility...7 CFR 3575.47 - Economic feasibility requirements.Code of Federal Regulations  2014 CFR2014-01-01... determine economic feasibility as well as financial viability. (a) Financial feasibility. The borrower... 7 Agriculture 15 2014-01-01 2014-01-01 false Economic feasibility requirements. 3575.47 Section...  DEPARTMENT OF AGRICULTURE GENERAL Community Programs Guaranteed Loans Â§ 3575.47 Economic feasibility...7 CFR 3575.47 - Economic feasibility requirements.Code of Federal Regulations  2013 CFR2013-01-01... determine economic feasibility as well as financial viability. (a) Financial feasibility. The borrower... 7 Agriculture 15 2013-01-01 2013-01-01 false Economic feasibility requirements. 3575.47 Section...  DEPARTMENT OF AGRICULTURE GENERAL Community Programs Guaranteed Loans Â§ 3575.47 Economic feasibility...7 CFR 3575.47 - Economic feasibility requirements.Code of Federal Regulations  2011 CFR2011-01-01... determine economic feasibility as well as financial viability. (a) Financial feasibility. The borrower... 7 Agriculture 15 2011-01-01 2011-01-01 false Economic feasibility requirements. 3575.47 Section...  DEPARTMENT OF AGRICULTURE GENERAL Community Programs Guaranteed Loans Â§ 3575.47 Economic feasibility...The feasibility  time savings and economic impact of a designated time appointment system at a busy HIV care clinic in Kenya: a randomized controlled trial.PubMedKwena  Zachary A; Njoroge  Betty W; Cohen  Craig R; Oyaro  Patrick; Shikari  Rosemary; Kibaara  Charles K; Bukusi  Elizabeth A2015-01-01As efforts are made to reach universal access to ART in Kenya  the problem of congestion at HIV care clinics is likely to worsen. We evaluated the feasibility and the economic benefits of a designated time appointment system as a solution to decongest HIV care clinics. This was an explanatory two-arm open-label randomized controlled trial that enrolled 354 consenting participants during their normal clinic days and followed-up at subsequent clinic appointments for up to nine months. Intervention arm participants were given specific dates and times to arrive at the clinic for their next appointment while those in the control arm were only given the date and had the discretion to decide on the time to arrive as is the standard practice. At follow-up visits  we recorded arrival and departure times and asked the monetary value of work participants engaged in before and after clinic. We conducted multiple imputation to replace missing data in our primary outcome variables to allow for intention-to-treat analysis; and analyzed the data using Mann-Whitney U test. Overall  72.1% of the intervention participants arrived on time  13.3% arrived ahead of time and 14.6% arrived past scheduled time. Intervention arm participants spent a median of 65 [interquartile range (IQR)  52-87] minutes at the clinic compared to 197 (IQR  173-225) minutes for control participants (p<0.01). Furthermore  intervention arm participants were more productively engaged on their clinic days valuing their cumulative work at a median of USD 10.5 (IQR  60.0-16.8) compared to participants enrolled in the control arm who valued their work at USD 8.3 (IQR  5.5-12.9; p=0.02). A designated time appointment system is feasible and provides substantial time savings associated with greater economic productivity for HIV patients attending a busy HIV care clinic.Conducting Site and Economic Renewable Energy Project Feasibility AssessmentsEPA Pesticide FactsheetsThe Toolbox for Renewable Energy Project Development's Conducting Site and Economic Renewable Energy Project Feasibility Assessments page provides tools and resources to evaluate solar project feasibility and economics that influence project development.40 CFR 52.579 - Economic feasibility considerations.Code of Federal Regulations  2010 CFR2010-07-01... 40 Protection of Environment 3 2010-07-01 2010-07-01 false Economic feasibility considerations. 52... (CONTINUED) APPROVAL AND PROMULGATION OF IMPLEMENTATION PLANS Georgia> Â§ 52.579 Economic feasibility... of economic feasibility could  in some cases  conflict  with the requirements of the Act that primary...7 CFR 3575.47 - Economic feasibility requirements.Code of Federal Regulations  2010 CFR2010-01-01... 7 Agriculture 15 2010-01-01 2010-01-01 false Economic feasibility requirements. 3575.47 Section...  DEPARTMENT OF AGRICULTURE GENERAL Community Programs Guaranteed Loans Â§ 3575.47 Economic feasibility... the credit quality and economic feasibility of the proposed loan and must address all elements of the...40 CFR 52.579 - Economic feasibility considerations.Code of Federal Regulations  2011 CFR2011-07-01... 40 Protection of Environment 3 2011-07-01 2011-07-01 false Economic feasibility considerations. 52... (CONTINUED) APPROVAL AND PROMULGATION OF IMPLEMENTATION PLANS Georgia> Â§ 52.579 Economic feasibility... of economic feasibility could  in some cases  conflict  with the requirements of the Act that primary...40 CFR 52.579 - Economic feasibility considerations.Code of Federal Regulations  2014 CFR2014-07-01... 40 Protection of Environment 3 2014-07-01 2014-07-01 false Economic feasibility considerations. 52... (CONTINUED) APPROVAL AND PROMULGATION OF IMPLEMENTATION PLANS Georgia Â§ 52.579 Economic feasibility... of economic feasibility could  in some cases  conflict  with the requirements of the Act that primary...40 CFR 52.579 - Economic feasibility considerations.Code of Federal Regulations  2012 CFR2012-07-01... 40 Protection of Environment 3 2012-07-01 2012-07-01 false Economic feasibility considerations. 52... (CONTINUED) APPROVAL AND PROMULGATION OF IMPLEMENTATION PLANS Georgia Â§ 52.579 Economic feasibility... of economic feasibility could  in some cases  conflict  with the requirements of the Act that primary...40 CFR 52.579 - Economic feasibility considerations.Code of Federal Regulations  2013 CFR2013-07-01... 40 Protection of Environment 3 2013-07-01 2013-07-01 false Economic feasibility considerations. 52... (CONTINUED) APPROVAL AND PROMULGATION OF IMPLEMENTATION PLANS Georgia Â§ 52.579 Economic feasibility... of economic feasibility could  in some cases  conflict  with the requirements of the Act that primary...Mineral Carbonation Feasibility  an Economic Approach.NASA Astrophysics Data System (ADS)Pasquier  L. C.; Kemache  N.; Cecchi  E.; Mercier  G.; Blais  J. F.; Kentish  S.2016-12-01Mineral Carbonation (MC) is one of the ways proposed to mitigate Carbon dioxide (CO2) emissions. Although it intends to transform CO2 into a stable and inert carbonate by reacting it with any divalent containing material  MC is still globally seen as an unrealistic methodology to reduce CO2  mostly because carbonation was seen as a sequestration technique only (after CO2 capture). Nevertheless  recent studies considered and showed the feasibility of an integrated capture/storage approach. Thus  MC can be adapted to flue gas or other industrial gas streams more or less concentrated in CO2. Furthermore  carbonation can be applied to various problematics and offers the advantage to be feasible with a broad range of feedstock such as alkaline industrial or mining residues. Using an economic approach where by-product valorization is favored  interesting approaches were identified. More specifically  the particular case of the QuÃ©bec province shows that different synergies between wastes and industries can be elaborated. The results indicate that MC can be seen as a practical approach to both reduce CO2 emissions and enhance waste remediation. For instance  the feasibility to export significant amounts of serpentinite mining residue to distant industrial sites using the St Lawrence maritime route was demonstrated. Here the applicability stands on the high value of the generated by-products. On the other hand  steel slags or waste concrete need more local applications due to their limited reaction efficiencies and the lower price of calcium carbonates. While transportation is a major factor for the OPEX cost  the profitability relies on the by-products potential sale. Indeed  the production of low carbon footprint materials from the reaction product will also expand the offer of CO2 utilization avenues. The presentation highlights the results of research made in the lab and using economic modeling to draw a portrait of the opportunities and challenges identified withSTOL ride control feasibility studyNASA Technical Reports Server (NTRS)Gordon  C. K.; Dodson  R. O.1973-01-01The feasibility of developing a ride-smoothing control system for a 20-passenger turboprop STOL transport was assessed. Five different ride-control system configurations with varying degrees of complexity  performance  and cost were investigated. Results indicate that a satisfactory ride-control system can be practically implemented on the aircraft with minimum flight performance degradation.7 CFR 1779.47 - Economic feasibility requirements.Code of Federal Regulations  2010 CFR2010-01-01... 7 Agriculture 12 2010-01-01 2010-01-01 false Economic feasibility requirements. 1779.47 Section...  DEPARTMENT OF AGRICULTURE (CONTINUED) WATER AND WASTE DISPOSAL PROGRAMS GUARANTEED LOANS Â§ 1779.47 Economic... the credit quality and economic feasibility of the proposed loan and must address all elements of the...7 CFR 1779.47 - Economic feasibility requirements.Code of Federal Regulations  2014 CFR2014-01-01... determine economic feasibility as well as financial viability. The borrower's consulting engineer may... success or failure of the facility is dependent on individual businesses  then the economic viability of... 7 Agriculture 12 2014-01-01 2013-01-01 true Economic feasibility requirements. 1779.47 Section...7 CFR 1779.47 - Economic feasibility requirements.Code of Federal Regulations  2012 CFR2012-01-01... determine economic feasibility as well as financial viability. The borrower's consulting engineer may... success or failure of the facility is dependent on individual businesses  then the economic viability of... 7 Agriculture 12 2012-01-01 2012-01-01 false Economic feasibility requirements. 1779.47 Section...7 CFR 1779.47 - Economic feasibility requirements.Code of Federal Regulations  2011 CFR2011-01-01... determine economic feasibility as well as financial viability. The borrower's consulting engineer may... success or failure of the facility is dependent on individual businesses  then the economic viability of... 7 Agriculture 12 2011-01-01 2011-01-01 false Economic feasibility requirements. 1779.47 Section...7 CFR 1779.47 - Economic feasibility requirements.Code of Federal Regulations  2013 CFR2013-01-01... determine economic feasibility as well as financial viability. The borrower's consulting engineer may... success or failure of the facility is dependent on individual businesses  then the economic viability of... 7 Agriculture 12 2013-01-01 2013-01-01 false Economic feasibility requirements. 1779.47 Section...41 CFR 101-5.306 - Economic feasibility.Code of Federal Regulations  2010 CFR2010-07-01... 41 Public Contracts and Property Management 2 2010-07-01 2010-07-01 true Economic feasibility. 101-5.306 Section 101-5.306 Public Contracts and Property Management Federal Property Management... AND COMPLEXES 5.3-Federal Employee Health Services Â§ 101-5.306 Economic feasibility. (a) The studies...7 CFR 1942.116 - Economic feasibility requirements.Code of Federal Regulations  2010 CFR2010-01-01... 7 Agriculture 13 2010-01-01 2009-01-01 true Economic feasibility requirements. 1942.116 Section 1942.116 Agriculture Regulations of the Department of Agriculture (Continued) RURAL HOUSING SERVICE... Facilities Projects Â§ 1942.116 Economic feasibility requirements. All projects financed under this section...7 CFR 1942.116 - Economic feasibility requirements.Code of Federal Regulations  2011 CFR2011-01-01... 7 Agriculture 13 2011-01-01 2009-01-01 true Economic feasibility requirements. 1942.116 Section 1942.116 Agriculture Regulations of the Department of Agriculture (Continued) RURAL HOUSING SERVICE... Facilities Projects Â§ 1942.116 Economic feasibility requirements. All projects financed under this section...41 CFR 101-5.306 - Economic feasibility.Code of Federal Regulations  2014 CFR2014-07-01... 41 Public Contracts and Property Management 2 2014-07-01 2012-07-01 true Economic feasibility. 101-5.306 Section 101-5.306 Public Contracts and Property Management Federal Property Management... AND COMPLEXES 5.3-Federal Employee Health Services Â§ 101-5.306 Economic feasibility. (a) The studies...7 CFR 1942.116 - Economic feasibility requirements.Code of Federal Regulations  2013 CFR2013-01-01... 7 Agriculture 13 2013-01-01 2013-01-01 false Economic feasibility requirements. 1942.116 Section 1942.116 Agriculture Regulations of the Department of Agriculture (Continued) RURAL HOUSING SERVICE... Facilities Projects Â§ 1942.116 Economic feasibility requirements. All projects financed under this section...7 CFR 1942.116 - Economic feasibility requirements.Code of Federal Regulations  2012 CFR2012-01-01... 7 Agriculture 13 2012-01-01 2012-01-01 false Economic feasibility requirements. 1942.116 Section 1942.116 Agriculture Regulations of the Department of Agriculture (Continued) RURAL HOUSING SERVICE... Facilities Projects Â§ 1942.116 Economic feasibility requirements. All projects financed under this section...41 CFR 101-5.306 - Economic feasibility.Code of Federal Regulations  2013 CFR2013-07-01... 41 Public Contracts and Property Management 2 2013-07-01 2012-07-01 true Economic feasibility. 101-5.306 Section 101-5.306 Public Contracts and Property Management Federal Property Management... AND COMPLEXES 5.3-Federal Employee Health Services Â§ 101-5.306 Economic feasibility. (a) The studies...41 CFR 101-5.306 - Economic feasibility.Code of Federal Regulations  2011 CFR2011-07-01... 41 Public Contracts and Property Management 2 2011-07-01 2007-07-01 true Economic feasibility. 101-5.306 Section 101-5.306 Public Contracts and Property Management Federal Property Management... AND COMPLEXES 5.3-Federal Employee Health Services Â§ 101-5.306 Economic feasibility. (a) The studies...7 CFR 1942.116 - Economic feasibility requirements.Code of Federal Regulations  2014 CFR2014-01-01... 7 Agriculture 13 2014-01-01 2013-01-01 true Economic feasibility requirements. 1942.116 Section 1942.116 Agriculture Regulations of the Department of Agriculture (Continued) RURAL HOUSING SERVICE... Facilities Projects Â§ 1942.116 Economic feasibility requirements. All projects financed under this section...41 CFR 101-5.306 - Economic feasibility.Code of Federal Regulations  2012 CFR2012-07-01... 41 Public Contracts and Property Management 2 2012-07-01 2012-07-01 false Economic feasibility. 101-5.306 Section 101-5.306 Public Contracts and Property Management Federal Property Management... AND COMPLEXES 5.3-Federal Employee Health Services Â§ 101-5.306 Economic feasibility. (a) The studies...The feasibility of early pulmonary rehabilitation and activity after COPD exacerbations: external pilot randomised controlled trial  qualitative case study and exploratory economic evaluation.PubMedCox  Matthew; O'Connor  Catherine; Biggs  Katie; Hind  Daniel; Bortolami  Oscar; Franklin  Matthew; Collins  Barbara; Walters  Stephen; Wailoo  Allan; Channell  Julie; Albert  Paul; Freeman  Ursula; Bourke  Stephen; Steiner  Michael; Miles  Jon; O'Brien  Tom; McWilliams  David; Schofield  Terry; O'Reilly  John; Hughes  Rodney2018-03-01Chronic obstructive pulmonary disease (COPD) affects >â€‰3 million people in the UK. Acute exacerbations of COPD (AECOPD) are the second most common reason for emergency hospital admission in the UK. Pulmonary rehabilitation is usual care for stable COPD but there is little evidence for early pulmonary rehabilitation (EPR) following AECOPD  either in hospital or immediately post discharge. To assess the feasibility of recruiting patients  collecting data and delivering EPR to patients with AECOPD to evaluate EPR compared with usual care. Parallel-group  pilot 2â€‰Ã—â€‰2 factorial randomised trial with nested qualitative research and an economic analysis. Two acute hospital NHS trusts. Recruitment was carried out from September 2015 to April 2016 and follow-up was completed in July 2016. Eligible patients were those aged â‰¥â€‰35 years who were admitted with AECOPD  who were non-acidotic and who maintained their blood oxygen saturation level ( S pO 2 ) within a prescribed range. Exclusions included the presence of comorbidities that affected the ability to undertake the interventions. (1) Hospital EPR: muscle training delivered at the patient's hospital bed using a cycle ergometer and (2) home EPR: a pulmonary rehabilitation programme delivered in the patient's home. Both interventions were delivered by trained physiotherapists. Participants were allocated on a 1â€‰:â€‰1â€‰:â€‰1â€‰:â€‰1 ratio to (1) hospital EPR ( n â€‰=â€‰14)  (2) home EPR ( n â€‰=â€‰15)  (3) hospital EPR and home EPR ( n â€‰=â€‰14) and (4) control ( n â€‰=â€‰15). Outcome assessors were blind to treatment allocation; it was not possible to blind patients. Feasibility of recruiting 76 participants in 7 months at two centres; intervention delivery; views on intervention/research acceptability; clinical outcomes including the 6-minute walk distance (6WMD); and costs. Semistructured interviews with participants ( n â€‰=â€‰27) and research health professionals ( n â€‰=â€‰11)  optimisation assessmentsSingle life time cytological screening in high risk women as an economical and feasible approach to control cervical cancer in developing countries like India.PubMedMisra  Jata Shankar; Srivastava  Anand Narain; Das  Vinita2015-01-01In view of funding crunches and inadequate manpower in cytology in developing countries like India  single lifetime screening for cervical cancer has been suggested. In this study  an attempt was made to identify high risk groups of women for this screening to make it more effective for early detection. Cytological data were derived from the ongoing routine cervical cytology screening program for women attending Gynaecology Out Patient Department of Queen Mary's Hospital of K.G.Medical University  Lucknow  India during a span of 35 years (April 1971 - December 2005). Cervical smears in a total of 38 256 women were cytologically evaluated. The frequencies of squamous intraepithelial lesions of cervix (SIL) and carcinoma cervix were found to be 7.0% and 0.6%  respectively  in the series. Predisposing factors related to cervical carcinogenesis were analyzed in detail to establish the most vulnerable groups of women for single life time screening. The incidence of SIL and carcinoma cervix was found to be maximal in women above the age of 40 years irrespective of parity and in multiparous women (with three or more children) irrespective of age. The incidence of cervical cytopathologies was significantly higher in symptomatic women  the frequency of SIL being alarmingly higher in women complaining of contact bleeding and that of carcinoma cervix in older women with postmenopausal bleeding. It is consequently felt that single life time screening must include the three groups of women delineated above. Such selective screening appears to be the most economical  cost effective and feasible approach to affordably control the menace of cervical cancer in developing countries like India.Economic and operational feasibility of short rotation hardwood inventoryTreesearchTom Gallagher; Robert Shaffer2002-01-01Procuring wood during the winter months for a pulpmill in the Southeast has some difficulties  especially in hardwood. Soft ground reduces the operational feasibility of many sites  forcing companies to store hardwood in woodyards for retrieval during wet weather. Intensively managed  short rotation hardwood grown on dry sites could economically supply a pulpmill...SRWC bioenergy productivity and economic feasibility on marginal lands.PubMedGhezehei  Solomon B; Shifflett  Shawn D; Hazel  Dennis W; Nichols  Elizabeth Guthrie2015-09-01Evolving bioenergy markets necessitate consideration of marginal lands for woody biomass production worldwide particularly the southeastern U.S.  a prominent wood pellet exporter to Europe. Growing short rotation woody crops (SRWCs) on marginal lands minimizes concerns about using croplands for bioenergy production and reinforces sustainability of wood supply to existing and growing global biomass markets. We estimated mean annual aboveground green biomass increments (MAIs) and assessed economic feasibility of various operationally established (0.5 ha-109 ha) SRWC stands on lands used to mitigate environmental liabilities of municipal wastewater  livestock wastewater and sludge  and subsurface contamination by petroleum and pesticides. MAIs (Mg ha(-1) yr(-1)) had no consistent relationship with stand density or age. Non-irrigated Populus  Plantanus occidentalis L. and Pinus taeda L. stands produced 2.4-12.4 Mg ha(-1) yr(-1). Older  irrigated Taxodium distchum L.  Fraxinus pennsylvanica L.  and coppiced P. occidentalis stands had higher MAIs (10.6-21.3 Mg ha(-1) yr(-1)) than irrigated Liquidambar styraciflua L. and non-coppiced  irrigated P. occidentalis (8-18 Mg ha(-1) yr(-1)). Natural hardwood MAIs at 20-60 years were less than hardwood and P. taeda productivities at 5-20 years. Unlike weed control  irrigation and coppicing improved managed hardwood productivity. Rotation length affected economic outcomes although the returns were poor due to high establishment and maintenance costs  low productivities and low current stumpage values  which are expected to quickly change with development of robust global markets. Copyright Â© 2015 Elsevier Ltd. All rights reserved.An economic and feasible Quantum Sealed-bid Auction protocolNASA Astrophysics Data System (ADS)Zhang  Rui; Shi  Run-hua; Qin  Jia-qi; Peng  Zhen-wan2018-02-01We present an economic and feasible Quantum Sealed-bid Auction protocol using quantum secure direct communication based on single photons in both the polarization and the spatial-mode degrees of freedom  where each single photon can carry two bits of classical information. Compared with previous protocols  our protocol has higher efficiency. In addition  we propose a secure post-confirmation mechanism without quantum entanglement to guarantee the security and the fairness of the auction.41 CFR 101-5.104-2 - Basis for determining economic feasibility.Code of Federal Regulations  2010 CFR2010-07-01... economic feasibility. 101-5.104-2 Section 101-5.104-2 Public Contracts and Property Management Federal... SERVICES IN FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104-2 Basis for determining economic feasibility. (a) Whenever possible  determination of the economic feasibility of a proposed centralized...41 CFR 101-5.104-2 - Basis for determining economic feasibility.Code of Federal Regulations  2013 CFR2013-07-01... economic feasibility. 101-5.104-2 Section 101-5.104-2 Public Contracts and Property Management Federal... SERVICES IN FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104-2 Basis for determining economic feasibility. (a) Whenever possible  determination of the economic feasibility of a proposed centralized...41 CFR 101-5.104-2 - Basis for determining economic feasibility.Code of Federal Regulations  2012 CFR2012-07-01... economic feasibility. 101-5.104-2 Section 101-5.104-2 Public Contracts and Property Management Federal... SERVICES IN FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104-2 Basis for determining economic feasibility. (a) Whenever possible  determination of the economic feasibility of a proposed centralized...41 CFR 101-5.104-2 - Basis for determining economic feasibility.Code of Federal Regulations  2014 CFR2014-07-01... economic feasibility. 101-5.104-2 Section 101-5.104-2 Public Contracts and Property Management Federal... SERVICES IN FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104-2 Basis for determining economic feasibility. (a) Whenever possible  determination of the economic feasibility of a proposed centralized...41 CFR 101-5.104-2 - Basis for determining economic feasibility.Code of Federal Regulations  2011 CFR2011-07-01... economic feasibility. 101-5.104-2 Section 101-5.104-2 Public Contracts and Property Management Federal... SERVICES IN FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104-2 Basis for determining economic feasibility. (a) Whenever possible  determination of the economic feasibility of a proposed centralized...Technical-economic feasibility of orbiting sunlight reflectorsNASA Astrophysics Data System (ADS)Alferov  Z.; Minin  V.1986-02-01The use of deflectors in orbit as a means of providing artificial illumination is examined. Considerations of technical and economic feasibility are addressed. Three main areas of application are distinguished: reflecting sunlight onto the surface of the Earth; concentration of the flow of solar energy on an orbiting receiver; and retransmission of optical radiation. The advantages of the artificial Earth illumination application of the orbiting reflector scheme in terms of energy savings in lighting cities  and additional daylight time for critical periods of farming operations are discussed.Economic feasibility of solar water and space heating.PubMedBezdek  R H; Hirshberg  A S; Babcock  W H1979-03-23The economic feasibility in 1977 and 1978 of solar water and combined water and space heating is analyzed for single-family detached residences and multi-family apartment buildings in four representative U.S. cities: Boston  Massachusetts; Washington  D.C.; Grand Junction  Colorado; and Los Angeles  California. Three economic decision criteria are utilized: payback period  years to recovery of down payment  and years to net positive cash flow. The cost competitiveness of the solar systems compared to heating systems based on electricity  fuel oil  and natural gas is then discussed for each city  and the impact of the federal tax credit for solar energy systems is assessed. It is found that even without federal incentives some solar water and space heating systems are competitive. Enactment of the solar tax credit  however  greatly enhances their competitiveness. The implications of these findings for government tax and energy pricing policies are discussed.Economic and environmental feasibility of a perennial cow dairy farm.PubMedRotz  C A; Zartman  D L; Crandall  K L2005-08-01More efficient and economical production systems are needed to improve the sustainability of dairy farms. One concept to consider is using perennial cows. Perennial cows are those that maintain a relatively high milk production for >or=2 yr without going through the typical dry period followed by calving. Farm records show that some cows have produced over 20 kg/d after 4 yr of continuous lactation. A farm simulation model was used to evaluate the long-term performance  environmental impact  and economics of a conceptual perennial cow production system on a typical dairy farm in Pennsylvania. Compared with a traditional 100-cow farm with replacement heifers produced on the farm  a perennial herd of 100 cows and purchased replacements provided environmental benefit but sustained a substantial economic loss. However  increasing the perennial herd to 128 cows better utilized the feed produced on the farm. Compared with the traditional 100-cow farm  use of the perennial 128-cow herd reduced supplemental protein and mineral feed purchases by 38%  increased annual milk sales by 21%  reduced nitrogen losses by 17%  maintained a phosphorus balance  and increased annual net return to farm management by 3200 dollars. A traditional 120-cow dairy farm with purchased replacements also used a similar amount of farm-produced feed. Compared with this option  the farm with 128 perennial cows reduced protein and mineral feed purchases by 36%  maintained similar annual milk sales  increased manure production by 7%  reduced N losses by 10%  and increased annual net return by 12 700 dollars. The economic feasibility of the perennial-cow dairy farm was very sensitive to the milk production maintained by the perennial herd and market prices for milk and perennial replacement animals. The analysis was relatively insensitive to the assumed useful life of perennial cows as long as they could be maintained in the herd for at least 3 yr. Thus  a perennial cow production system can improve theFeasibility study of robotic neural controllersNASA Technical Reports Server (NTRS)Magana  Mario E.1990-01-01The results are given of a feasibility study performed to establish if an artificial neural controller could be used to achieve joint space trajectory tracking of a two-link robot manipulator. The study is based on the results obtained by Hecht-Nielsen  who claims that a functional map can be implemented to a desired degree of accuracy with a three layer feedforward artificial neural network. Central to this study is the assumption that the robot model as well as its parameters values are known.Economic feasibility analysis of conventional and dedicated energy crop productionSciTech ConnectNelson  R.G.; Langemeier  M.R.; Krehbiel  L.R.Economic feasibilities (net return per acre) associated with conventional agricultural crop production versus that of dedicated bioenergy crop (herbaceous energy crops) were investigated for northeastern Kansas. Conventional agricultural crops examined were corn  soybeans  wheat  sorghum and alfalfa and dedicated herbaceous energy crops included big bluestem/indiangrass  switchgrass  eastern gamagrass  brome  fescue and cane hay. Costs  prices and government program information from public and private sources were used to project the net return per acre over a six-year period beginning in 1997. Three soil productivity levels (low  average and high)  which had a direct effect on the net return per acre  weremoreÂ Â» used to model differences in expected yield. In all three soil productivity cases  big bluestem/indiangrass  switchgrass and brome hay provided a higher net return per acre versus conventional crops grown on both program and non-program acres. Eastern gamagrass  fescue hay and cane hay had returns that were similar or less than returns provided by conventional crops.Â«Â lessThe Oregon State University wind studies. [economic feasibility of windpowered generatorsNASA Technical Reports Server (NTRS)Wilson  R. E.1973-01-01The economic feasibility of commercial use of wind generated power in selected areas of Oregon is assessed. A number of machines for generating power have been examined. These include the Savonius rotor  translators  conventional wind turbines  the circulation controlled rotor and the vertical axis winged turbine. Of these machines  the conventional wind turbine and the vertical axis winged turbine show the greatest promise on the basis of the power developed per unit of rotor blade area. Attention has been focused on the structural and fatigue analysis of rotors since the economics of rotary winged  wind generated power depends upon low cost  long lifetime rotors. Analysis of energy storage systems and tower design has also been undertaken. An economic means of energy storage has not been found to date. Tower design studies have produced cost estimates that are in general agreement with the cost of the updated Putnam 110-foot tower.Basin view geothermal heating district  Klamath Falls  Oregon. Conceptual design and economic-feasibility study reportNASA Astrophysics Data System (ADS)1981-07-01The findings of a feasibility study performed for Basin View Heating District in Klamath Falls  Oregon are reported. The physical  economic  and political feasibility of establishing a geothermal heating district to provide space heat to housing units in the Basin View Development of Klamath Falls are determined. Of the several systems considered  all are physically feasible. The project is politically feasible if the owner complies with governmental requirements. Economic feasibility is based on considerations of money value rates  tax rates and expected rates of return  which are dependent on government and money markets. For analysis a money value rate of 21% and an owner's marginal tax rate of 35% were adopted.Producing Hardwood Dimension Parts Directly From Logs: An Economic Feasibility StudyTreesearchWenjie Lin; D. Earl Kline; Philip A. Araman; Janice K. Wiedenbeck1995-01-01The economic feasibility and profitability of a direct processing system for converting Factory Grades 2 and 3 red oak logs directly into rough dimension parts were evaluated. New present value (NPV) and internal rate of return (IRR) were used as the measurement of economic feasibility  and return on sales (ROS) was used as the measurement of profitability. NPV and IRR...41 CFR 101-5.104 - Economic feasibility of centralized services.Code of Federal Regulations  2010 CFR2010-07-01... 41 Public Contracts and Property Management 2 2010-07-01 2010-07-01 true Economic feasibility of centralized services. 101-5.104 Section 101-5.104 Public Contracts and Property Management Federal Property... FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104 Economic feasibility of centralized services. ...41 CFR 101-5.104 - Economic feasibility of centralized services.Code of Federal Regulations  2012 CFR2012-07-01... 41 Public Contracts and Property Management 2 2012-07-01 2012-07-01 false Economic feasibility of centralized services. 101-5.104 Section 101-5.104 Public Contracts and Property Management Federal Property... FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104 Economic feasibility of centralized services. ...41 CFR 101-5.104 - Economic feasibility of centralized services.Code of Federal Regulations  2011 CFR2011-07-01... 41 Public Contracts and Property Management 2 2011-07-01 2007-07-01 true Economic feasibility of centralized services. 101-5.104 Section 101-5.104 Public Contracts and Property Management Federal Property... FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104 Economic feasibility of centralized services. ...41 CFR 101-5.104 - Economic feasibility of centralized services.Code of Federal Regulations  2013 CFR2013-07-01... 41 Public Contracts and Property Management 2 2013-07-01 2012-07-01 true Economic feasibility of centralized services. 101-5.104 Section 101-5.104 Public Contracts and Property Management Federal Property... FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104 Economic feasibility of centralized services. ...41 CFR 101-5.104 - Economic feasibility of centralized services.Code of Federal Regulations  2014 CFR2014-07-01... 41 Public Contracts and Property Management 2 2014-07-01 2012-07-01 true Economic feasibility of centralized services. 101-5.104 Section 101-5.104 Public Contracts and Property Management Federal Property... FEDERAL BUILDINGS AND COMPLEXES 5.1-General Â§ 101-5.104 Economic feasibility of centralized services. ...Laminar flow control SPF/08 feasibility demonstrationNASA Astrophysics Data System (ADS)Ecklund  R. C.; Williams  N. R.1981-10-01The feasibility of applying superplastic forming/diffusion bonding (SPF/DB) technology to laminar flow control (LFC) system concepts was demonstrated. Procedures were developed to produce smooth  flat titanium panels  using thin -0.016 inch sheets  meeting LFC surface smoothness requirements. Two large panels 28 x 28 inches were fabricated as final demonstration articles. The first was flat on the top and bottom sides demonstrating the capability of the tooling and the forming and diffusion bonding procedures to produce flat  defect free surfaces. The second panel was configurated for LFC porous panel treatment by forming channels with dimpled projections on the top side. The projections were machined away leaving holes extending into the panel. A perforated titanium sheet was adhesively bonded over this surface to complete the LFC demonstration panel. The final surface was considered flat enough to meet LFC requirements for a jet transport aircraft in cruising flight.Economic feasibility of cooling dry cows across the United States.PubMedFerreira  F C; Gennari  R S; Dahl  G E; De Vries  A2016-12-01Heat stress during the dry period reduces milk yield in the subsequent lactation of dairy cows. Our objectives were to quantify the economic losses due to heat stress if dry cows are not cooled and to evaluate the economic feasibility of dry cow cooling. We used weather data from the National Oceanic and Atmospheric Administration to calculate the number of heat stress days for each of the 50 US states. A heat stress day was declared when the daily average temperature-humidity index was â‰¥68. The number of dairy cows in each state in 2015 was obtained from the USDA-National Agricultural Statistics Service. We assumed that 15% of the cows were dry at any time  a 60-d dry period  and a calving interval of 400d. Only cows in their second or greater parity (65%) benefitted from cooling during the dry period of the previous parity. Milk yield decreased by 5kg in the subsequent lactation (340d) if the cow experienced heat stress during the dry period based on a review of the literature. The default marginal value of milk minus feed cost was $0.33/kg of milk. The investment analysis included purchases of fans and soakers and use of water and electricity. Investment in a dry cow barn was considered separately. The average US dairy cow would experience 96 (26%) heat stress days during the year if not cooled and loses 447kg of milk in the subsequent lactation if not cooled when dry. Annual losses would be $810 million if dry cows were not cooled ($87/cow per yr). For the top 3 milk-producing states (California  Wisconsin  New York)  and Florida and Texas  the average milk losses in the subsequent lactation were 522  349  387  1 197  and 904kg  and reduced profit per cow per year would be $101  $68  $75  $233  and $176  respectively. The average benefit-cost ratio and payback periods of cooling dry cows in the United States were 3.15 and 0.27 yr (dry cow barn already present) and 1.45 and 5.68 yr (if investing in a dry cow barn) in the default scenario. To reach positive netFeasibility of controlled micturition through electric stimulation.PubMedSchmidt  R A; Tanagho  E A1979-01-01Historically  man has been aware of bioelectric phenomena for some 4 000 years. Yet it has only been during the last 20 years that technology has advanced to the stage where controlled bladder emptying has become feasible. A great deal of interest followed the introduction of transistor and bladder stimulation via the principle of radio frequency induction. Spinal cord  sacral  and pelvic nerve and direct bladder stimulation have all been attempted. Only direct bladder stimulation in lower motor neuron situations has shown any promise. The many difficulties associated with bladder stimulation include simultaneous sphincter contraction  pain  electrode and insulation difficulties  and fibroplasia due to movement of electrodes placed in pliable tissues. In addition  the role of the prostate  increased urethral length  and erection responses in the male have received little investigation. These problems are outlined and experimental observations of attempts to achieve controlled micturition in canines areresented. These studies were carried out over a 3-year period  and emphasize responses to stimulation of the spinal cord and sacral roots. It was concluded that the most efficient manner by which to effect simulated micturition is via stimulation of the ventral sacral root dominant for bladder responsiveness  and combine this with selective division of somatic fibers of only the root being stimulated.Economic feasibility of solar thermal industrial applications and selected case studiesNASA Astrophysics Data System (ADS)Montelione  A.; Boyd  D.; Branz  M.1981-12-01The economic feasibility is assessed of utilizing solar energy to augment an existing fossil fuel system to generate industrial process heat. Several case studies in the textile and food processing industries in the southern United States were analyzed. Sensitivity analyses were performed  and comparisons illustrating the effects of the Economic Recovery Tax Act of 1981 were made. The economic desirability of the proposed solar systems varied with the type of system selected  location of the facility  state tax credits  and type of fuel displaced. For those systems presently not economical  the projected time to economic feasibility was ascertained.FBI fingerprint identification automation study. AIDS 3 evaluation report. Volume 4: Economic feasibilityNASA Technical Reports Server (NTRS)Mulhall  B. D. L.1980-01-01The results of the economic analysis of the AIDS 3 system design are presented. AIDS 3 evaluated a set of economic feasibility measures including life cycle cost  implementation cost  annual operating expenditures and annual capital expenditures. The economic feasibility of AIDS 3 was determined by comparing the evaluated measures with the same measures  where applicable  evaluated for the current system. A set of future work load scenarios was constructed using JPL's environmental evaluation study of the fingerprint identification system. AIDS 3 and the current system were evaluated for each of the economic feasibility measures for each of the work load scenarios. They were compared for a set of performance measures  including response time and accuracy  and for a set of cost/benefit ratios  including cost per transaction and cost per technical search. Benefit measures related to the economic feasibility of the system are also presented  including the required number of employees and the required employee skill mix.Technical and economic feasibility of integrated video service by satelliteNASA Technical Reports Server (NTRS)Price  K. M.; Kwan  R. K.; White  L. W.; Garlow  R. K.; Henderson  T. R.1992-01-01A feasibility study is presented of utilizing modern satellite technology  or more advanced technology  to create a cost-effective  user-friendly  integrated video service  which can provide videophone  video conference  or other equivalent wideband service on demand. A system is described that permits a user to select a desired audience and establish the required links similar to arranging a teleconference by phone. Attention is given to video standards  video traffic scenarios  satellite system architecture  and user costs.Technical and Economical Feasibility of SSTO and TSTO Launch VehiclesNASA Astrophysics Data System (ADS)Lerch  JensThis paper discusses whether it is more cost effective to launch to low earth orbit in one or two stages  assuming current or near future technologies. First the paper provides an overview of the current state of the launch market and the hurdles to introducing new launch vehicles capable of significantly lowering the cost of access to space and discusses possible routes to solve those problems. It is assumed that reducing the complexity of launchers by reducing the number of stages and engines  and introducing reusability will result in lower launch costs. A number of operational and historic launch vehicle stages capable of near single stage to orbit (SSTO) performance are presented and the necessary steps to modify them into an expendable SSTO launcher and an optimized two stage to orbit (TSTO) launcher are shown  through parametric analysis. Then a ballistic reentry and recovery system is added to show that reusable SSTO and TSTO vehicles are also within the current state of the art. The development and recurring costs of the SSTO and the TSTO systems are estimated and compared. This analysis shows whether it is more economical to develop and operate expendable or reusable SSTO or TSTO systems under different assumption for launch rate and initial investment.Technical  economic and environmental feasibility of recycling nutrients in waste in Southern Thailand.PubMedSchouw  Nanette Levanius; BregnhÃ¸j  Henrik; Mosbaek  Hans; Tjell  Jens Christian2003-06-01Technical  economic and environmental criteria were used to evaluate the feasibility of recycling plant nutrients in kitchen waste  human excreta and sullage from households in Phattalung (urban)  Kuan Lang (peri urban) and Prik (rural) in Southern Thailand. The difference in situation and context of the three areas called for individual solutions  and for each area three sanitation systems were evaluated. However  in all three areas recycling human excreta and kitchen waste via composting latrines was found to be more environmental feasible than human excreta managed in septic tanks or sub surface trickle irrigation and kitchen waste disposed of at landfill sites or treated at composting plants. Sullage should in Kuan Lang and Prik be used directly on garden crops  but in Phattalung be treated in waste stabilisation ponds before discharge  to be environmentally feasible. The economic feasibility results varied among the three areas and among the involved stakeholders: farmers and Kuan Lang administration benefited from recycling waste  at the expense of other private users  Phattalung municipality and Prik municipality. The main cause of these conflicting interests was lack of cost recovery and public participation  which should therefore serve as the fundament of any future environmental and economic feasible sanitation system.Impact of product mix and markets on the economic feasibility of hardwood thinningTreesearchJohn E. Baumgras; Chris B. LeDoux1989-01-01Results demonstrate how the economic feasibility of commercial hardwood thinning is impacted by tree diameter  product mix  and primary product markets. These results indicate that multiproduct harvesting can increase revenues by $0.01/ftÂ³ to $0.32/ftÂ³; and that small shifts in price levels or haul distance can postpone commercial thinning...Economic feasibility of products from inland West small-diameter timberTreesearchSpelter Henry; Rong Wang; Peter Ince1996-01-01A large part of the forests located in the Rocky Mountain region of the U.S. West (inland West) is characterized by densely packed  small-diameter stands. The purpose of this study was to examine the economic feasibility of using small-diameter material from this resource to manufacture various wood products: oriented strandboard (OSB)  stud lumber  random-length...Economic feasibility of converting center pivot irrigation to subsurface drip irrigationUSDA-ARS?s Scientific Manuscript databaseAdvancements in irrigation technology have increased water use efficiency. However  producers can be reluctant to convert to a more efficient irrigation system when the initial investment costs are high. This study examines the economic feasibility of replacing low energy precision application (LEPA...The financial and economic feasibility of rural household biodigesters for poor communities in South Africa.PubMedSmith  Michael T; Goebel  Jessica Schroenn; Blignaut  James N2014-02-01Given the persistence of systemic poverty in  most notably  the rural parts of South Africa  the question is whether the use of biodigesters as a source of energy offers potential solutions to some of the difficulties and development needs faced by people in these areas. At the core  this translates into whether this technology would be financially and economically feasible for installation and use by rural households. Here we conduct both a financial and an economic cost-benefit analysis in one such community based on survey data from 120 households. Analysis of these data and supporting literature reveals that a biodigester is not a financially feasible investment for a rural household. Substantial economic benefits are  however  found to make a biodigester a worthwhile investment from a broader societal perspective. This is a compelling argument for further study and the consideration of government support in the light of broader economy-wide benefits. Copyright Â© 2013 Elsevier Ltd. All rights reserved.An economic analysis of black-tailed prairie dog (Cynomys ludovicianus) controlTreesearchAlan R. Collins; John P. Workman; Daniel W. Uresk1984-01-01Black-tailed prairie dog (Cynomys ludovicianus) control by poisoning with zinc phosphide was not economically feasible in the Conata Basin of South Dakota. Economic analyses were conducted from U.S. Forest Service and rancher viewpoints. Control programs were analyzed with annual maintenance or complete retreatment of initially treated areas to...A feasibility study of orbiter flight control experimentsNASA Technical Reports Server (NTRS)Geissler  W. H.1978-01-01The results of a feasibility study of orbiter flight control experiments performed are summarized. Feasibility studies were performed on a group of 14 experiments selected from a candidate list of 35 submitted to the study contractor by the flight control community. Concepts and requirements were developed for the 14 selected experiments and they were ranked on a basis of technical value  feasibility  and cost. It was concluded that all the selected experiments can be considered as potential candidates for the Orbiter Experiment program  which is being formulated for the Orbiter Flight Tests and subsequent operational flights  regardless of the relative ranking established during the study. None of the selected experiments has significant safety implications and the cost of most was estimated to be less than $200K.Bristol girls dance project feasibility study: using a pilot economic evaluation to inform design of a full trialPubMed CentralPowell  Jane E; Carroll  Fran E; Sebire  Simon J; Haase  Anne M; Jago  Russell2013-01-01Background There is currently little guidance for pilot trial economic evaluation where health outcomes and costs are influenced by a range of wider determinants and factors. Objectives This article presents the findings of a pilot economic evaluation study running alongside the Bristol Girls Dance Project (BGDP) feasibility study. Design 3-arm  cluster randomised  controlled pilot trial and economic evaluation. 7 schools (n=210) from the Bristol and greater Bristol area  UK were randomly allocated to the intervention arm 3 schools (n=90) and the control arm 4 schools (n=120). Intervention Girls aged 11â€“12â€…years with parental consent were provided with two  90â€…min dance sessionsÂ per week for 9â€…weeks at school facilities. Economic outcome measures Programme costs and girlsâ€™ preferences for attributes of dance and preferences for competing leisure time activities were measured. Results The mainstream average cost of the BGDP programme (not including research  control and dance teacher training costs) per school was $2126.40  Â£1329Â and â‚¬1555 and per participant was $70.90  Â£44.31Â and â‚¬51.84 in 2010â€“2011 prices. Discrete choice experiment (DCE) methods are acceptable to girls of this age indicating time available for other leisure activities on dance class days is the attribute girls valued most and 2â€…h leisure time remaining preferred to 3â€…h. Conclusions This pilot study indicates that providing full cost data for a future trial of the BGDP programme is feasible and practical. There is no evidence from preference data to support adjustment to intervention design. A future economic evaluation is likely to be successful utilising the resource use checklist developed. The importance of categorising separately resources used to develop  prepare  deliver and maintain the programme to estimate mainstream costs accurately is demonstrated. PMID:24362013Economic growth and carbon emission controlNASA Astrophysics Data System (ADS)Zhang  ZhenyuThe question about whether environmental improvement is compatible with continued economic growth remains unclear and requires further study in a specific context. This study intends to provide insight on the potential for carbon emissions control in the absence of international agreement  and connect the empirical analysis with theoretical framework. The Chinese electricity generation sector is used as a case study to demonstrate the problem. Both social planner and private problems are examined to derive the conditions that define the optimal level of production and pollution. The private problem will be demonstrated under the emission regulation using an emission tax  an input tax and an abatement subsidy respectively. The social optimal emission flow is imposed into the private problem. To provide tractable analytical results  a Cobb-Douglas type production function is used to describe the joint production process of the desired output and undesired output (i.e.  electricity and emissions). A modified Hamiltonian approach is employed to solve the system and the steady state solutions are examined for policy implications. The theoretical analysis suggests that the ratio of emissions to desired output (refer to 'emission factor')  is a function of productive capital and other parameters. The finding of non-constant emission factor shows that reducing emissions without further cutting back the production of desired outputs is feasible under some circumstances. Rather than an ad hoc specification  the optimal conditions derived from our theoretical framework are used to examine the relationship between desired output and emission level. Data comes from the China Statistical Yearbook and China Electric Power Yearbook and provincial information of electricity generation for the year of 1993-2003 are used to estimate the Cobb-Douglas type joint production by the full information maximum likelihood (FIML) method. The empirical analysis shed light on the optimalSystems Analysis and Design for Decision Support Systems on Economic Feasibility of ProjectsNASA Astrophysics Data System (ADS)Balaji  S. Arun2010-11-01This paper discuss about need for development of the Decision Support System (DSS) software for economic feasibility of projects in Rwanda  Africa. The various economic theories needed and the corresponding formulae to compute payback period  internal rate of return and benefit cost ratio of projects are clearly given in this paper. This paper is also deals with the systems flow chart to fabricate the system in any higher level computing language. The various input requirements from the projects and the output needed for the decision makers are also included in this paper. The data dictionary used for input and output data structure is also explained.ToHajiilee Economic Development  Inc.(TEDI) Feasibility Study for Utility-Scale SolarSciTech ConnectBurpo  Rob2012-02-29To Hajiilee Economic Development  Inc. (TEDI) is the economic development entity representing the ToHajiilee Chapter of the Navajo Nation  also known as the Caoncito Band of Navajo (CBN). Using DOE funding  TEDI assembled a team of qualified advisors to conduct a feasibility study for a utility-scale 30 MW Photovoltaic (PV) solar power generation facility on TEDI trust lands. The goal for this project has been to gather information and practical business commitments to successfully complete the feasibility analysis. The TEDI approach was to successively make informed decisions to select an appropriate technology best suited to the site  determine environmental viabilitymoreÂ Â» of the site  secure options for the sale of generated power  determine practicality of transmission and interconnection of power to the local grid  and secure preliminary commitments on project financing. The feasibility study has been completed and provides TEDI with a practical understanding of its business options in moving forward with developing a solar project on CBN tribal lands. Funding from DOE has allowed TEDI and its team of professional advisors to carefully select technology and business partners and build a business model to develop this utility-scale solar project. As a result of the positive feasibility findings  TEDI is moving forward with finalizing all pre-construction activities for its major renewable energy project.Â«Â lessEconomic feasibility study for new technological alternatives in wastewater treatment processes: a review.PubMedMolinos-Senante  MarÃ­a; HernÃ¡ndez-Sancho  Francesc; Sala-Garrido  RamÃ³n2012-01-01The concept of sustainability involves the integration of economic  environmental  and social aspects and this also applies in the field of wastewater treatment. Economic feasibility studies are a key tool for selecting the most appropriate option from a set of technological proposals. Moreover  these studies are needed to assess the viability of transferring new technologies from pilot-scale to full-scale. In traditional economic feasibility studies  the benefits that have no market price  such as environmental benefits  are not considered and are therefore underestimated. To overcome this limitation  we propose a new methodology to assess the economic viability of wastewater treatment technologies that considers internal and external impacts. The estimation of the costs is based on the use of cost functions. To quantify the environmental benefits from wastewater treatment  the distance function methodology is proposed to estimate the shadow price of each pollutant removed in the wastewater treatment. The application of this methodological approach by decision makers enables the calculation of the true costs and benefits associated with each alternative technology. The proposed methodology is presented as a useful tool to support decision making.Demonstration of the economic feasibility of plant tissue culture for jojoba (Simmondsia chinensis) and Euphorbia sppSciTech ConnectSluis  C.1980-09-01The economic feasibility of plant tissue culture was demonstrated as applied to two plants: jojoba (Simmondsia chinensis) and Euphorbia spp. The gopher weed (Euphorbia lathyris) was selected as the species of Euphorbia to research due to the interest in this plant as a potential source of hydrocarbon-like compounds. High yield female selections of jojoba were chosen from native stands and were researched to determine the economic feasibility of mass producing these plants via a tissue culture micropropagation program. The female jojoba selection was successfully mass produced through tissue culture. Modifications in initiation techniques  as well as in multiplication media andmoreÂ Â» rooting parameters  were necessary to apply the tissue culture system  which had been developed for juvenile seedling tissue  to mature jojobas. Since prior attempts at transfer of tissue cultured plantlets were unsuccessful  transfer research was a major part of the project and has resulted in a system for transfer of rooted jojoba plantlets to soil. Euphorbia lathyris was successfully cultured using shoot tip cultures. Media and procedures were established for culture initiation  multiplication of shoots  callus induction and growth  and root initiation. Well-developed root systems were not attained and root initiation percentages should be increased if the system is to become commercially feasible.Â«Â lessEconomic Feasibility of Staffing the Intensive Care Unit with a Communication Facilitator.PubMedKhandelwal  Nita; Benkeser  David; Coe  Norma B; Engelberg  Ruth A; Curtis  J Randall2016-12-01In the intensive care unit (ICU)  complex decision making by clinicians and families requires good communication to ensure that care is consistent with the patients' values and goals. To assess the economic feasibility of staffing ICUs with a communication facilitator. Data were from a randomized trial of an ""ICU communication facilitator"" linked to hospital financial records; eligible patients (nâ€‰=â€‰135) were admitted to the ICU at a single hospital with predicted mortality â‰¥30% and a surrogate decision maker. Adjusted regression analyses assessed differences in ICU total and direct variable costs between intervention and control patients. A bootstrap-based simulation assessed the cost efficiency of a facilitator while varying the full-time equivalent of the facilitator and the ICU mortality risk. Total ICU costs (mean 22.8k; 95% CI  -42.0k to -3.6k; Pâ€‰=â€‰0.02) and average daily ICU costs (mean  -0.38k; 95% CI  -0.65k to -0.11k; Pâ€‰=â€‰0.006)] were reduced significantly with the intervention. Despite more contacts  families of survivors spent less time per encounter with facilitators than did families of decedents (mean  25 [SD  11] min vs. 36 [SD  14] min). Simulation demonstrated maximal weekly savings with a 1.0 full-time equivalent facilitator and a predicted ICU mortality of 15% (total weekly ICU cost savings  $58.4k [95% CI  $57.7k-59.2k]; weekly direct variable savings  $5.7k [95% CI  $5.5k-5.8k]) after incorporating facilitator costs. Adding a full-time trained communication facilitator in the ICU may improve the quality of care while simultaneously reducing short-term (direct variable) and long-term (total) health care costs. This intervention is likely to be more cost effective in a lower-mortality population.Technical and economic feasibility study of solar/fossil hybrid power systemsNASA Technical Reports Server (NTRS)Bloomfield  H. S.; Calogeras  J. E.1977-01-01Results show that new hybrid systems utilizing fossil fuel augmentation of solar energy can provide significant capital and energy cost benefits when compared with solar thermal systems requiring thermal storage. These benefits accrue from a reduction of solar collection area that results from both the use of highly efficient gas and combined cycle energy conversion subsystems and elimination of the requirement for long-term energy storage subsystems. Technical feasibility and fuel savings benefits of solar hybrid retrofit to existing fossil-fired  gas and vapor cycle powerplants was confirmed; however  economic viability of steam cycle retrofit was found to be dependent on the thermodynamic and operational characteristics of the existing powerplant.Feasibility Study of Economics and Performance of Solar Photovoltaics in the Commonwealth of Puerto RicoSciTech ConnectSalasovich  J.; Mosey  G.2011-03-01This report presents the results of an assessment of the technical and economic feasibility of deploying a photovoltaics (PV) system on brownfield sites in the Commonwealth of Puerto Rico. All of the assessed sites are landfills. The sites were assessed for possible PV installations. The cost  performance  and site impacts of different PV options were estimated. The economics of the potential systems were analyzed using an electric rate of $0.119/kWh and incentives offered by Puerto Rico and by the serving utility  PREPA. According to the site production calculations  the most cost-effective system in terms of return on investment is themoreÂ Â» thin-film fixed-tilt technology. The report recommends financing options that could assist in the implementation of such a system.Â«Â lessEconomic evaluation of infection control activities.PubMedSeko  T; Tachi  T; Kawashima  N; Maeda  T; Yasuda  M; Noguchi  Y; Teramachi  H2017-08-01Healthcare-associated infections by drug-resistant bacteria affect a patient's prognosis. Infection control activities at medical institutions in Japan are increasingly focused on the threat from these bacteria. To undertake a full cost analysis that included the costs of consumables and labour required for infection control activities. The cost of infection control activities undertaken by the infection control team (ICT) at Nishimino Kosei Hospital in Japan was surveyed from January 2013 to December 2015. The evaluation index of infection control activities used the meticillin-resistant Staphylococcus aureus detection rate. The cost:effectiveness ratio (CER) of each intervention was calculated. Consumables and labour costs increased over time  as did the ratio of labour cost to total cost over time. However  the CER of interventions was found to have decreased  from Â¥164 177 in 2014 to Â¥57 989 in 2015. There were increases not only in the amount of consumables  but also in ICT time  suggesting the possibility of improvements in the economic efficiency of infection control. Increasing the amount of consumables and the time input of the ICT could help improve the economic efficiency of infection control. Our research suggests the possibility for improvements in the economic efficiency of infection control. Copyright Â© 2017 The Healthcare Infection Society. Published by Elsevier Ltd. All rights reserved.Extraction of astaxanthin from microalgae: process design and economic feasibility studyNASA Astrophysics Data System (ADS)Zgheib  Nancy; Saade  Roxana; Khallouf  Rindala; Takache  Hosni2018-03-01In this work  the process design and the economic feasibility of natural astaxanthin extraction fromHaematococcus pluvialisspecies have been reported. Complete process drawing of the process was first performed  and then the process was designed including five main steps being the harvesting process  the cell disruption  the spray drying  the supercritical CO2extraction and the anaerobic digestion. The major components of the facility would include sedimentation tanks  a disk stack centrifuge  a bed miller  a spray dryer  a multistage compressor  an extractor  a pasteurizer and a digester. All units have been sized assuming a 10 kg/h of dried biomass as a feedstock to produce nearly 2592 kg of astaxanthin per year. The investment payback time and the return on investment were all estimated for different market prices of astaxanthin. Based on the results the production process was found to become economically feasible for a market price higher than 1500/Kg. Also  a payback period of 1 year and an ROI equal to 113% was estimated for an astaxanthin market price equal to 6000/Kg.Site dependent factors affecting the economic feasibility of solar powered absorption coolingNASA Technical Reports Server (NTRS)Bartlett  J. C.1978-01-01A procedure was developed to evaluate the cost effectiveness of combining an absorption cycle chiller with a solar energy system. A basic assumption of the procedure is that a solar energy system exists for meeting the heating load of the building  and that the building must be cooled. The decision to be made is to either cool the building with a conventional vapor compression cycle chiller or to use the existing solar energy system to provide a heat input to the absorption chiller. Two methods of meeting the cooling load not supplied by solar energy were considered. In the first method  heat is supplied to the absorption chiller by a boiler using fossil fuel. In the second method  the load not met by solar energy is net by a conventional vapor compression chiller. In addition  the procedure can consider waste heat as another form of auxiliary energy. Commercial applications of solar cooling with an absorption chiller were found to be more cost effective than the residential applications. In general  it was found that the larger the chiller  the more economically feasible it would be. Also  it was found that a conventional vapor compression chiller is a viable alternative for the auxiliary cooling source  especially for the larger chillers. The results of the analysis gives a relative rating of the sites considered as to their economic feasibility of solar cooling.Feasibility of touch-less control of operating room lights.PubMedHartmann  Florian; Schlaefer  Alexander2013-03-01Today's highly technical operating rooms lead to fairly complex surgical workflows where the surgeon has to interact with a number of devices  including the operating room light. Hence  ideally  the surgeon could direct the light without major disruption of his work. We studied whether a gesture tracking-based control of an automated operating room light is feasible. So far  there has been little research on control approaches for operating lights. We have implemented an exemplary setup to mimic an automated light controlled by a gesture tracking system. The setup includes a articulated arm to position the light source and an off-the-shelf RGBD camera to detect the user interaction. We assessed the tracking performance using a robot-mounted hand phantom and ran a number of tests with 18 volunteers to evaluate the potential of touch-less light control. All test persons were comfortable with using the gesture-based system and quickly learned how to move a light spot on flat surface. The hand tracking error is direction-dependent and in the range of several centimeters  with a standard deviation of less than 1Â mm and up to 3.5Â mm orthogonal and parallel to the finger orientation  respectively. However  the subjects had no problems following even more complex paths with a width of less than 10Â cm. The average speed was 0.15 m/s  and even initially slow subjects improved over time. Gestures to initiate control can be performed in approximately 2 s. Two-thirds of the subjects considered gesture control to be simple  and a majority considered it to be rather efficient. Implementation of an automated operating room light and touch-less control using an RGBD camera for gesture tracking is feasible. The remaining tracking error does not affect smooth control  and the use of the system is intuitive even for inexperienced users.Air Traffic Control: Economics of FlightNASA Technical Reports Server (NTRS)Murphy  James R.2004-01-01Contents include the following: 1. Commercial flight is a partnership. Airlines. Pilots. Air traffic control. 2. Airline schedules and weather problems can cause delays at the airport. Delays are inevitable in de-regulated industry due to simple economics. 3.Delays can be mitigated. Build more runways/technology. Increase airspace supply. 4. Cost/benefit analysis determine justification.Economic Incentives for Stormwater Control (ISBN9781439845608)EPA Science InventoryAddressing a huge knowledge gap from a policy perspective  this book focuses on the economic tools available for stormwater runoff control. It provides case studies demonstrating the application of various incentives  such as tradable credits  fees with rebates  and auction mecha...Integrated continuous bioprocessing: Economic  operational  and environmental feasibility for clinical and commercial antibody manufacture.PubMedPollock  James; Coffman  Jon; Ho  Sa V; Farid  Suzanne S2017-07-01This paper presents a systems approach to evaluating the potential of integrated continuous bioprocessing for monoclonal antibody (mAb) manufacture across a product's lifecycle from preclinical to commercial manufacture. The economic  operational  and environmental feasibility of alternative continuous manufacturing strategies were evaluated holistically using a prototype UCL decisional tool that integrated process economics  discrete-event simulation  environmental impact analysis  operational risk analysis  and multiattribute decision-making. The case study focused on comparing whole bioprocesses that used either batch  continuous or a hybrid combination of batch and continuous technologies for cell culture  capture chromatography  and polishing chromatography steps. The cost of goods per gram (COG/g)  E-factor  and operational risk scores of each strategy were established across a matrix of scenarios with differing combinations of clinical development phase and company portfolio size. The tool outputs predict that the optimal strategy for early phase production and small/medium-sized companies is the integrated continuous strategy (alternating tangential flow filtration (ATF) perfusion  continuous capture  continuous polishing). However  the top ranking strategy changes for commercial production and companies with large portfolios to the hybrid strategy with fed-batch culture  continuous capture and batch polishing from a COG/g perspective. The multiattribute decision-making analysis highlighted that if the operational feasibility was considered more important than the economic benefits  the hybrid strategy would be preferred for all company scales. Further considerations outside the scope of this work include the process development costs required to adopt continuous processing. Â© 2017 The Authors Biotechnology Progress published by Wiley Periodicals  Inc. on behalf of American Institute of Chemical Engineers Biotechnol. Prog.  33:854-866  2017. Â© 2017 TheIntegrated continuous bioprocessing: Economic  operational  and environmental feasibility for clinical and commercial antibody manufacturePubMed CentralPollock  James; Coffman  Jon; Ho  Sa V.2017-01-01This paper presents a systems approach to evaluating the potential of integrated continuous bioprocessing for monoclonal antibody (mAb) manufacture across a product's lifecycle from preclinical to commercial manufacture. The economic  operational  and environmental feasibility of alternative continuous manufacturing strategies were evaluated holistically using a prototype UCL decisional tool that integrated process economics  discreteâ€event simulation  environmental impact analysis  operational risk analysis  and multiattribute decisionâ€making. The case study focused on comparing whole bioprocesses that used either batch  continuous or a hybrid combination of batch and continuous technologies for cell culture  capture chromatography  and polishing chromatography steps. The cost of goods per gram (COG/g)  Eâ€factor  and operational risk scores of each strategy were established across a matrix of scenarios with differing combinations of clinical development phase and company portfolio size. The tool outputs predict that the optimal strategy for early phase production and small/mediumâ€sized companies is the integrated continuous strategy (alternating tangential flow filtration (ATF) perfusion  continuous capture  continuous polishing). However  the top ranking strategy changes for commercial production and companies with large portfolios to the hybrid strategy with fedâ€batch culture  continuous capture and batch polishing from a COG/g perspective. The multiattribute decisionâ€making analysis highlighted that if the operational feasibility was considered more important than the economic benefits  the hybrid strategy would be preferred for all company scales. Further considerations outside the scope of this work include the process development costs required to adopt continuous processing. Â© 2017 The Authors Biotechnology Progress published by Wiley Periodicals  Inc. on behalf of American Institute of Chemical Engineers Biotechnol. Prog.  33:854â€“866  2017[Tobacco control from an economic perspective].PubMedLÃ³pez NicolÃ¡s  Angel; Viudes de Velasco  ArÃ¡ntzazu2009-01-01This paper reviews the main arguments put forward from Economics in the area of tobacco control  and provides a detailed description of market failures from both the traditional perspective and recent literature advances. It concludes that smoking is a personal choice that can generate net welfare losses for the society  the smokers family and  above  all the smoker him(her)self. On these grounds there exists economic justification for correcting mechanisms. The article includes a discussion of two important preventive policies in the Spanish context: restrictions in bars and restaurants and tobacco tax hikes.Feasibility of BCI Control in a Realistic Smart Home Environment.PubMedKosmyna  Nataliya; Tarpin-Bernard  Franck; Bonnefond  Nicolas; Rivet  Bertrand2016-01-01Smart homes have been an active area of research  however despite considerable investment  they are not yet a reality for end-users. Moreover  there are still accessibility challenges for the elderly or the disabled  two of the main potential targets for home automation. In this exploratory study we design a control mechanism for smart homes based on Brain Computer Interfaces (BCI) and apply it in the ""Domus"" smart home platform in order to evaluate the potential interest of users about BCIs at home. We enable users to control lighting  a TV set  a coffee machine and the shutters of the smart home. We evaluate the performance (accuracy  interaction time)  usability and feasibility (USE questionnaire) on 12 healthy subjects and 2 disabled subjects. We find that healthy subjects achieve 77% task accuracy. However  disabled subjects achieved a better accuracy (81% compared to 77%).Targeting core groups for gonorrhoea control: feasibility and impact.PubMedGiguÃ¨re  Katia; Alary  Michel2015-06-01We aimed to outline why core groups should be targeted in Neisseria gonorrhoeae control and suggest several important and timely interventions to target core groups while highly resistant strains are spreading. Core group definition  feasibility and impact of gonorrhoea core group interventions as well as gonorrhoea resistance development have been reviewed in the paper. Core group interventions have proven effective in gonorrhoea control in the past but are compromised by the spread of highly resistant strains. Worldwide functional Gonorrhoea Antimicrobial Surveillance Program  better screening and better treatment programmes are needed. Prevention through condom promotion aimed at core groups remains essential. More specific treatment guidance for low-income and middle-income countries without resistance data is required in the meantime to achieve a better use of antibiotics. Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.Feasibility of BCI Control in a Realistic Smart Home EnvironmentPubMed CentralKosmyna  Nataliya; Tarpin-Bernard  Franck; Bonnefond  Nicolas; Rivet  Bertrand2016-01-01Smart homes have been an active area of research  however despite considerable investment  they are not yet a reality for end-users. Moreover  there are still accessibility challenges for the elderly or the disabled  two of the main potential targets for home automation. In this exploratory study we design a control mechanism for smart homes based on Brain Computer Interfaces (BCI) and apply it in the â€œDomusâ€1 smart home platform in order to evaluate the potential interest of users about BCIs at home. We enable users to control lighting  a TV set  a coffee machine and the shutters of the smart home. We evaluate the performance (accuracy  interaction time)  usability and feasibility (USE questionnaire) on 12 healthy subjects and 2 disabled subjects. We find that healthy subjects achieve 77% task accuracy. However  disabled subjects achieved a better accuracy (81% compared to 77%). PMID:27616986A Feasibility Study on the Control of a Generic Air Vehicle Using Control Moment GyrosNASA Technical Reports Server (NTRS)Lim  Kyong B.; Moerder  Daniel D.2006-01-01This paper examines feasibility and performance issues in using Control Moment Gyroscopes (CMGs) to control the attitude of a fixed-wing aircraft. The paper describes a control system structure that permits allocating control authority and bandwidth between a CMG system and conventional aerodynamic control surfaces to stabilize a vehicle with neutral aerodynamic stability. A simulation study explores the interplay between aerodynamic and CMG effects  and indicates desirable physical characteristics for a CMG system to be used for aircraft attitude control.Effect of Different Solar Radiation Data Sources on the Variation of Techno-Economic Feasibility of PV Power SystemNASA Astrophysics Data System (ADS)Alghoul  M. A.; Ali  Amer; Kannanaikal  F. V.; Amin  N.; Aljaafar  A. A.; Kadhim  Mohammed; Sopian  K.2017-11-01The aim of this study is to evaluate the variation in techno-economic feasibility of PV power system under different data sources of solar radiation. HOMER simulation tool is used to predict the techno-economic feasibility parameters of PV power system in Baghdad city  Iraq located at (33.3128Â° N  44.3615Â° E) as a case study. Four data sources of solar radiation  different annual capacity shortages percentage (0  2.5  5  and 7.5)  and wide range of daily load profile (10-100 kWh/day) are implemented. The analyzed parameters of the techno-economic feasibility are COE (/kWh)  PV array power capacity (kW)  PV electrical production (kWh/year)  No. of batteries and battery lifetime (year). The main results of the study revealed the followings: (1) solar radiation from different data sources caused observed to significant variation in the values of the techno-economic feasibility parameters; therefore  careful attention must be paid to ensure the use of an accurate solar input data; (2) Average solar radiation from different data sources can be recommended as a reasonable input data; (3) it is observed that as the size and of PV power system increases  the effect of different data sources of solar radiation increases and causes significant variation in the values of the techno-economic feasibility parameters.Economic feasibility of the sugar beet-to-ethylene value chain.PubMedAlthoff  Jeroen; Biesheuvel  Kees; De Kok  Ad; Pelt  Henk; Ruitenbeek  Matthijs; Spork  Ger; Tange  Jan; Wevers  Ronald2013-09-01As part of a long-term strategy toward renewable feedstock  a feasibility study into options for the production of bioethylene by integrating the sugar beet-to-ethanol-to-ethylene value chain. Seven business cases were studied and tested for actual economic feasibility of alternative sugar-to-ethanol-to-ethylene routes in comparison to fossil-fuel alternatives. An elaborate model was developed to assess the relevant operational and financial aspects of each business case. The calculations indicate that bioethylene from sugar beet is not commercially viable under current market conditions. In light of expected global energy and feedstock prices it is also reasonable to expect that this will not change in the near future. To consider biorenewable sources as starting material  they need to be low in cost (compared to sugar beets) and also require less capital and energy-intensive methods for the conversion to chemicals. In general  European sugar prices will be too high for many chemical applications. Future efforts for in sugar-to-chemicals routes should  therefore  focus on integrated process routes and process intensification and/or on products that contain a significant part of the original carbohydrate backbone. Copyright Â© 2013 WILEY-VCH Verlag GmbH & Co. KGaA  Weinheim.Economic feasibility of diesel fuel substitutes from oilseeds in New York StateSciTech ConnectLazarus  W.F.; Pitt  R.E.1984-11-01The feasibility of producing oilseeds for feed and for a diesel fuel substitute has primarily been discussed in terms of the major oilseed producing areas. The Northeast region of the United States is a major agricultural producing area which imports large quantities of soybean meal for cattle feed. This paper considers the technical and economic feasibility of producing oilseeds for feed and fuel in New York State  which is selected as a case study for the region. The possible crops considered for expanded production are sunflowers  soybeans  and flax. It is found that if enough oilseeds are grown to replacemoreÂ Â» 25% of the diesel fuel used on farms  then at most 5% of the cropland would have to be converted to oilseeds  and meal would not be produced in excess of the amount currently used. The cost of producing oil is calculated as the cost of producing the seed plus the cost of processing minus the value of the meal. Enterprise budgets are developed for estimating oilseed production costs in New York State. The cost of processing is estimated for both an industrial-size plant  which does not now exist in New York  and a small on-farm plant. It is found that the diesel fuel and vegetable oil prices would have to rise substantially before oilseeds were produced in the Northeast region for feed and fuel. Moreover  the construction of an oilseed processing facility would not necessarily stimulate production of oilseeds in the region. 22 references.Â«Â lessEconomic feasibility and environmental impact of synthetic spider silk production from escherichia coli.PubMedEdlund  Alan M; Jones  Justin; Lewis  Randolph; Quinn  Jason C2018-05-25Major ampullate spider silk represents a promising protein-based biomaterial with diverse commercial potential ranging from textiles to medical devices due to its excellent physical and thermal properties. Recent advancements in synthetic biology have facilitated the development of recombinant spider silk proteins from Escherichia coli (E. coli). This study specifically investigates the economic feasibility and environmental impact of synthetic spider silk manufacturing. Pilot scale data was used to validate an engineering process model that includes all of the required sub-processing steps for synthetic fiber manufacture: production  harvesting  purification  drying  and spinning. Modeling was constructed modularly to support assessment of alternative downstream processing technologies. The techno-economic analysis indicates a minimum sale price from pioneer and optimized E. coli plants of $761â€¯kg -1 and $23â€¯kg -1 with greenhouse gas emissions of 572â€¯kg CO 2-eq. kg -1 and 55â€¯kg CO 2-eq. kg -1   respectively. Elevated costs and emissions from the pioneer plant can be directly tied to the high material consumption and low protein yield. Decreased production costs associated with the optimized plant includes improved protein yield  process optimization  and an N th plant assumption. Discussion focuses on the commercial potential of spider silk  the production performance requirements for commercialization  and the impact of alternative technologies on the system. Copyright Â© 2018 Elsevier B.V. All rights reserved.Feasibility of satellite interferometry for surveillance  navigation  and traffic controlNASA Technical Reports Server (NTRS)Gopalapillai  S.; Ruck  G. T.; Mourad  A. G.1976-01-01The feasibility of using a satellite borne interferometry system for surveillance  navigation  and traffic control applications was investigated. The evaluation was comprised of: (1) a two part systems analysis (software and hardware); (2) a survey of competitive navigation systems (both experimental and planned); (3) a comparison of their characteristics and capabilities with those of an interferometry system; and (4) a limited survey of potential users to determine the variety of possible applications for the interferometry system and the requirements which it would have to meet. Five candidate or ""strawman"" interferometry systems for various applications with various capabilities were configured (on a preliminary basis) and were evaluated. It is concluded that interferometry in conjunction with a geostationary satellite has an inherent ability to provide both a means for navigation/position location and communication. It offers a very high potential for meeting a large number of user applications and requirements for navigation and related functions.Feasibility and validity of the structured attention module among economically disadvantaged preschool-age children.PubMedBush  Hillary H; Eisenhower  Abbey; Briggs-Gowan  Margaret; Carter  Alice S2015-01-01Rooted in the theory of attention put forth by Mirsky  Anthony  Duncan  Ahearn  and Kellam (1991)  the Structured Attention Module (SAM) is a developmentally sensitive  computer-based performance task designed specifically to assess sustained selective attention among 3- to 6-year-old children. The current study addressed the feasibility and validity of the SAM among 64 economically disadvantaged preschool-age children (mean age = 58 months; 55% female); a population known to be at risk for attention problems and adverse math performance outcomes. Feasibility was demonstrated by high completion rates and strong associations between SAM performance and age. Principal Factor Analysis with rotation produced robust support for a three-factor model (Accuracy  Speed  and Endurance) of SAM performance  which largely corresponded with existing theorized models of selective and sustained attention. Construct validity was evidenced by positive correlations between SAM Composite scores and all three SAM factors and IQ  and between SAM Accuracy and sequential memory. Value-added predictive validity was not confirmed through main effects of SAM on math performance above and beyond age and IQ; however  significant interactions by child sex were observed: Accuracy and Endurance both interacted with child sex to predict math performance. In both cases  the SAM factors predicted math performance more strongly for girls than for boys. There were no overall sex differences in SAM performance. In sum  the current findings suggest that interindividual variation in sustained selective attention  and potentially other aspects of attention and executive function  among young  high-risk children can be captured validly with developmentally sensitive measures.Optimal Renewable Energy Integration into Refinery with CO2 Emissions Consideration: An Economic Feasibility StudyNASA Astrophysics Data System (ADS)Alnifro  M.; Taqvi  S. T.; Ahmad  M. S.; Bensaida  K.; Elkamel  A.2017-08-01With increasing global energy demand and declining energy return on energy invested (EROEI) of crude oil  global energy consumption by the O&G industry has increased drastically over the past few years. In addition  this energy increase has led to an increase GHG emissions  resulting in adverse environmental effects. On the other hand  electricity generation through renewable resources have become relatively cost competitive to fossil based energy sources in a much â€˜cleanerâ€™ way. In this study  renewable energy is integrated optimally into a refinery considering costs and CO2 emissions. Using Aspen HYSYS  a refinery in the Middle East was simulated to estimate the energy demand by different processing units. An LP problem was formulated based on existing solar energy systems and wind potential in the region. The multi-objective function  minimizing cost as well as CO2 emissions  was solved using GAMS to determine optimal energy distribution from each energy source to units within the refinery. Additionally  an economic feasibility study was carried out to determine the viability of renewable energy technology project implementation to overcome energy requirement of the refinery. Electricity generation through all renewable energy sources considered (i.e. solar PV  solar CSP and wind) were found feasible based on their low levelized cost of electricity (LCOE). The payback period for a Solar CSP project  with an annual capacity of about 411 GWh and a lifetime of 30 years  was found to be 10 years. In contrast  the payback period for Solar PV and Wind were calculated to be 7 and 6 years  respectively. This opens up possibilities for integrating renewables into the refining sector as well as optimizing multiple energy carrier systems within the crude oil industryIs the Production of Embryos in Small-Scale Farming an Economically Feasible Enterprise?PubMedSÃ¡nchez  Z; Lammoglia  M A; AlarcÃ³n  M A; Romero  J J; Galina  C S2015-08-01The present assay attempts to evaluate the feasibility of using embryo transfer in small community farmers by inÂ vivo study and by modelling the results obtained. From the total of 59 donor cows  62.7% responded to treatment  with a significant difference (pÂ =Â 0.002) in the percentage of the response between breeds  being 90.5% (19/21) in Holstein and 47.4% (18/38) in Brahman. A total of 283 embryos were graded as transferable  while 141 as non-transferable  without difference in the percentage of transferable embryo by breed (pÂ =Â 0.18). The mean of transferable embryos graded as class I and II was not different between Holstein and Brahman (pÂ =Â 0.96 and pÂ =Â 0.92  respectively); besides  no differences were observed in the other grades (non-transferable). The highest difference in costs  regardless of its quality by breed  was seen in the lower levels of probable fertility of the embryo transferred  even reaching several hundred dollars. When modelling the expected costs for embryo produced and transferred  values can reach nearly $2000.00 when the probable fertility is only 10%. However  when the probable fertility was 60%  embryo cost was close to $300.00. This technology seems to be viable on average or high-scale systems  having a superovulatory response between 60 and 80% with 4-6 transferrable embryos. Yet  in small-scale farming  due to the reduced number of donors and/or recipients  the costs surpass the economical feasibility of the technique. Â© 2015 Blackwell Verlag GmbH.A Cost Framework for the Economic Feasibility of Wide-Scale Biochar ProductionNASA Astrophysics Data System (ADS)Pourhashem  G.; Masiello  C. A.; Medlock  K. B.  III2017-12-01Biochar is a product of biomass pyrolysis  one of the main thermal pathways of producing biofuels. In addition to sequestering carbon  biochar's soil application helps sustainable agriculture by enhancing soil's structure and ecological functions  as well as lowering NO release from fertilized soils. However  wide-scale biochar land amendment has been limited in part due to its high cost. To examine biochar's cost dynamics  we develop a comprehensive framework for a representative biochar production facility and identify system inputs that are the key drivers of cost and profitability. We assess the production cost of fast and slow pyrolysis-biochar considering a range of parameters e.g. biomass type  process design and scale. We analyzed techno-economic cost data for producing biochar using simulated data from academic literature  and active producer data collected under confidentiality agreement. The combined approach was used to enhance the depth of the dataset and allowed for a reasonable check on published simulated data. Fast and slow pyrolysis have different biofuel and biochar yields and profit. A slow pyrolysis facility recovers its expenses mainly through biochar sale while a fast pyrolysis facility generates its primary revenue through biofuel sale  largely considering biochar a byproduct. Unlike fast pyrolysis that has received most attention in techno-economic studies  publicly available techno-economic data of slow pyrolysis is sparse. This limits the ability to run a thorough cost-benefit analysis to inform the feasibility of wider adoption of biochar for capturing its carbon sequestration and broader environmental benefits. Our model allows for consideration of various market-based policy instruments and can be used as an analytical decision making tool for investors and policy makers to estimate the cost and optimum facility size. This dynamic framework can also be adapted to account for the availability of new data as technology improves andFeasible economic strategies to improve screening compliance for colorectal cancer in KoreaPubMed CentralPark  Sang Min; Yun  Young Ho; Kwon  Soonman2005-01-01AIM: While colorectal cancer (CRC) is an ideal target for population screening  physician and patient attitudes contribute to low levels of screening uptake. This study was carried out to find feasible economic strategies to improve the CRC screening compliance in Korea. METHODS: The natural history of a simulated cohort of 50-year-old Korean in the general population was modeled with CRC screening until the age of 80 years. Cases of positive results were worked up with colonoscopy. After polypectomy  colonoscopy was repeated every 3 years. Baseline screening compliance without insurance coverage by the national health insurance (NHI) was assumed to be 30%. If NHI covered the CRC screening or the reimbursement of screening to physicians increased  the compliance was assumed to increase. We evaluated 16 different CRC screening strategies based on Markov model. RESULTS: When the NHI did not cover the screening and compliance was 30%  non-dominated strategies were colonoscopy every 5 years (COL5) and colonoscopy every 3 years (COL3). In all scenarios of various compliance rates with raised coverage of the NHI and increased reimbursement of colonoscopy  COL10  COL5 and COL3 were non-dominated strategies  and COL10 had lower or minimal incremental medical cost and financial burden on the NHI than the strategy of no screening. These results were stable with sensitivity analyses. CONCLUSION: Economic strategies for promoting screening compliance can be accompanied by expanding insurance coverage by the NHI and by increasing reimbursement for CRC screening to providers. COL10 was a cost-effective and cost saving screening strategy for CRC in Korea. PMID:15786532Economic Time Series Modeling to Determine the Feasibility of Incorporating Drinking Water Treatment in Water Quality TradingEPA Science InventoryThe critical steps required to evaluating the feasiblity of establishing a water quality trading market in a testbed watershed is described. Focus is given toward describing the problem of thin markets as a specifi barrier to successful trading. Economic theory for considering an...Technical and Economic Feasibility Study of At-Grade Concrete Slab Track for Urban Rail Transit SystemsDOT National Transportation Integrated Search1981-08-01The report presents work conducted to evaluate the technical and economic feasibility of using concrete slab track systems for at-grade transit track. The functions of a rail transit track system are to guide railway vehicles and provide a safe and a...Technical and economic feasibility of development innovative technological solutions for expansion the adjustment range of high-power CCPNASA Astrophysics Data System (ADS)Arakelyan  E. K.; Andryushin  A. V.; Burtsev  S. Y.; Andryushin  K. A.2017-11-01The analysis of technical and parametric constraints on the adjustment range of highpower CCP and recommended technological solutions in the technical literature for their elimination. Established that in the conditions of toughening the requirements for economy  reliability and maneuverability on the part of the system operator with the participation of CCP in control the frequency and power in the power system  existing methods do not ensure the fulfillment of these requirements. The current situation in the energy sector â€” the lack of highly manoeuvrable power equipment leads to the need participate in control of power consumption diagrams for all types of power plants  including CCP  although initially they were intended primarily for basic loads. Large-scale research conducted at the department of Automated control systems of technological processes  showed the possibility of a significant expansion of the adjustment range of CCP when it operating in the condensing mode and in the heating mode. The report presents the main results of these research for example the CCP-450 and CCP-450T. Various technological solutions are considered: when CCP in the condensation mode â€” the use of bypass steam distribution schemes  the transfer of a part of the steam turbine into a low-steam mode; when CCP operation in the heating mode â€” bypass steam distribution and the transfer CCP to gas turbine unit â€” power heating plants mode with the transfer the steam turbine to the motor mode. Data on the evaluation of the technical and economic feasibility of the proposed innovative technological solutions are presented in comparison with the methods used to solve this problem  which are used in practice  such as passing through the failures of the electric load graphs by transferring the CCP to the mode of operation with incomplete equipment. When comparing  both the economics  and the maneuverability and reliability of the equipment are considered.Modeling the Economic Feasibility of Large-Scale Net-Zero Water Management: A Case Study.PubMedGuo  Tianjiao; Englehardt  James D; Fallon  Howard Jâ€ƒ While municipal direct potable water reuse (DPR) has been recommended for consideration by the U.S. National Research Council  it is unclear how to size new closed-loop DPR plants  termed ""net-zero water (NZW) plants""  to minimize cost and energy demand assuming upgradient water distribution. Based on a recent model optimizing the economics of plant scale for generalized conditions  the authors evaluated the feasibility and optimal scale of NZW plants for treatment capacity expansion in Miami-Dade County  Florida. Local data on population distribution and topography were input to compare projected costs for NZW vs the current plan. Total cost was minimized at a scale of 49 NZW plants for the service population of 671 823. Total unit cost for NZW systems  which mineralize chemical oxygen demand to below normal detection limits  is projected at ~$10.83 / 1000 gal  approximately 13% above the current plan and less than rates reported for several significant U.S. cities.Technical and economic feasibility of alternative fuel use in process heaters and small boilersSciTech ConnectNot Available1980-02-01The technical and economic feasibility of using alternate fuels - fuels other than oil and natural gas - in combustors not regulated by the Powerplant and Industrial Fuel Use Act of 1978 (FUA) was evaluated. FUA requires coal or alternate fuel use in most large new boilers and in some existing boilers. Section 747 of FUA authorizes a study of the potential for reduced oil and gas use in combustors not subject to the act: small industrial boilers with capacities less than 100 MMBtu/hr  and process heat applications. Alternative fuel use in combustors not regulated by FUA was examined andmoreÂ Â» the impact of several measures to encourage the substitution of alternative fuels in these combustors was analyzed. The primary processes in which significant fuel savings can be achieved are identified. Since feedstock uses of oil and natural gas are considered raw materials  not fuels  feedstock applications are not examined in this analysis. The combustors evaluated in this study comprise approximately 45% of the fuel demand projected in 1990. These uses would account for more than 3.5 million barrels per day equivalent fuel demand in 1990.Â«Â lessFeasibility Study of Economics and Performance of Solar Photovoltaics at the Stringfellow Superfund Site in Riverside  CaliforniaSciTech ConnectMosey  G.; Van Geet  O.2010-12-01This report presents the results of an assessment of the technical and economic feasibility of deploying a photovoltaics (PV) system on the Stringfellow Superfund Site in Riverside  California. The site was assessed for possible PV installations. The cost  performance  and site impacts of different PV options were estimated. The economics of the potential systems were analyzed using an electric rate of $0.13/kWh and incentives offered by Southern California Edison under the California Solar Initiative. According to the assessment  a government-owned  ground-mounted PV system represents a technically and economically feasible option. The report recommends financing options that could assist in themoreÂ Â» implementation of such a system.Â«Â lessOn control of systems delays in economicsNASA Astrophysics Data System (ADS)Kim  A. V.; Kormyshev  V. M.; Novikov  M. Yu.; Nikonov  M. A.2017-11-01The paper continues presentation of the differential game theory for systems with delays and is devoted to the solution of an approach problem in application to economic problems (Dockner E.J.  et all  2000; R. Isaacs  1999). The results are obtained in the framework of the positional differential game theory (N.N. Krasovskii  A.I. Subbotin  1988; A.V. Kryazhimskii  Yu.S. Osipov  1973; Yu.S. Osipov  J. Appl. Math. Mech. Vol. 35  â„– 1  â„– 6  1971) with application of the i-smooth analysis methodology (A.V. Kim  2015). Effective construction of extremal positional control is based on the utilization of the so called u-stable sets The necessary and sufficient conditions of high u-stability are presented in the paper.Feasibility of Economic Analysis of Radiation Therapy Oncology Group (RTOG) 91-11 Using Medicare DataSciTech ConnectKonski  Andre  E-mail: akonski@med.wayne.ed; Bhargavan  Mythreyi; Owen  JeanPurpose: The specific aim of this analysis was to evaluate the feasibility of performing a cost-effectiveness analysis using Medicare data from patients treated on a randomized Phase III clinical trial. Methods and Materials: Cost data included Medicare Part A and Part B costs from all providers-inpatient  outpatient  skilled nursing facility  home health  hospice  and physicians-and were obtained from the Centers for Medicare and Medicaid Services for patients eligible for Medicare  treated on Radiation Therapy Oncology Group (RTOG) 9111 between 1992 and 1996. The 47-month expected discounted (annual discount rate of 3%) cost for each arm of the trial was calculatedmoreÂ Â» in 1996 dollars  with Kaplan-Meier sampling average estimates of survival probabilities for each month and mean monthly costs. Overall and disease-free survival was also discounted 3%/year. The analysis was performed from a payer's perspective. Incremental cost-effectiveness ratios were calculated comparing the chemotherapy arms to the radiation alone arm. Results: Of the 547 patients entered  Medicare cost data and clinical outcomes were available for 66 patients. Reasons for exclusion included no RTOG follow-up  Medicare HMO enrollment  no Medicare claims since trial entry  and trial entry after 1996. Differences existed between groups in tumor characteristics  toxicity  and survival  all which could affect resource utilization. Conclusions: Although we were able to test the methodology of economic analysis alongside a clinical trial using Medicare data  the results may be difficult to translate to the entire trial population because of non-random missing data. Methods to improve Medicare data capture and matching to clinical trial samples are required.Â«Â lessCONTRACT Study - CONservative TReatment of Appendicitis in Children (feasibility): study protocol for a randomised controlled Trial.PubMedHutchings  Natalie; Wood  Wendy; Reading  Isabel; Walker  Erin; Blazeby  Jane M; Van't Hoff  William; Young  Bridget; Crawley  Esther M; Eaton  Simon; Chorozoglou  Maria; Sherratt  Frances C; Beasant  Lucy; Corbett  Harriet; Stanton  Michael P; Grist  Simon; Dixon  Elizabeth; Hall  Nigel J2018-03-02Currently  the routine treatment for acute appendicitis in the United Kingdom is an appendicectomy. However  there is increasing scientific interest and research into non-operative treatment of appendicitis in adults and children. While a number of studies have investigated non-operative treatment of appendicitis in adults  this research cannot be applied to the paediatric population. Ultimately  we aim to perform a UK-based multicentre randomised controlled trial (RCT) to test the clinical and cost effectiveness of non-operative treatment of acute uncomplicated appendicitis in children  as compared with appendicectomy. First  we will undertake a feasibility study to assess the feasibility of performing such a trial. The study involves a feasibility RCT with a nested qualitative research to optimise recruitment as well as a health economic substudy. Children (aged 4-15 years inclusive) diagnosed with acute uncomplicated appendicitis that would normally be treated with an appendicectomy are eligible for the RCT. Exclusion criteria include clinical/radiological suspicion of perforated appendicitis  appendix mass or previous non-operative treatment of appendicitis. Participants will be randomised into one of two arms. Participants in the intervention arm are treated with antibiotics and regular clinical assessment to ensure clinical improvement. Participants in the control arm will receive appendicectomy. Randomisation will be minimised by age  sex  duration of symptoms and centre. Children and families who are approached for the RCT will be invited to participate in the embedded qualitative substudy  which includes recording of recruitment consultants and subsequent interviews with participants and non-participants and their families and recruiters. Analyses of these will inform interventions to optimise recruitment. The main study outcomes include recruitment rate (primary outcome)  identification of strategies to optimise recruitment  performance of trial treatmentMethodological issues in the design and evaluation of supported communication for aphasia training: a cluster-controlled feasibility studyPubMed CentralHorton  Simon; Clark  Allan; Barton  Garry; Lane  Kathleen; Pomeroy  Valerie M2016-01-01Objective To assess the feasibility and acceptability of training stroke service staff to provide supported communication for people with moderateâ€“severe aphasia in the acute phase; assess the suitability of outcome measures; collect data to inform sample size and Health Economic evaluation in a definitive trial. Design Phase II cluster-controlled  observer-blinded feasibility study. Settings In-patient stroke rehabilitation units in the UK matched for bed numbers and staffing were assigned to control and intervention conditions. Participants 70 stroke rehabilitation staff from all professional groups  excluding doctors  were recruited. 20 patients with moderate-severe aphasia were recruited. Intervention Supported communication for aphasia training  adapted to the stroke unit context versus usual care. Training was supplemented by a staff learning log  refresher sessions and provision of communication resources. Main outcome measures Feasibility of recruitment and acceptability of the intervention and of measures required to assess outcomes and Health Economic evaluation in a definitive trial. Staff outcomes: Measure of Support in Conversation; patient outcomes: Stroke and Aphasia Quality of Life Scale; Communicative Access Measure for Stroke; Therapy Outcome Measures for aphasia; EQ-5D-3L was used to assess health outcomes. Results Feasibility of staff recruitment was demonstrated. Training in the intervention was carried out with 28 staff and was found to be acceptable in qualitative reports. 20 patients consented to take part  6 withdrew. 18 underwent all measures at baseline; 16 at discharge; and 14 at 6-month follow-up. Of 175 patients screened 71% were deemed to be ineligible  either lacking capacity or too unwell to participate. Poor completion rates impacted on assessment of patient outcomes. We were able to collect sufficient data at baseline  discharge and follow-up for economic evaluation. Conclusions The feasibility study informed components of the75 FR 64216 - Interpretation of OSHA's Provisions for Feasible Administrative or Engineering Controls of...Federal Register 2010  2011  2012  2013  20142010-10-19... CFR Parts 1910 and 1926 Interpretation of OSHA's Provisions for Feasible Administrative or Engineering... feasible administrative or engineering controls as used in the applicable sections of OSHA's General... administrative or engineering controls rather than personal protective equipment (PPE) to reduce noise exposures...75 FR 77798 - Interpretation of OSHA's Provisions for Feasible Administrative or Engineering Controls of...Federal Register 2010  2011  2012  2013  20142010-12-14... CFR Parts 1910 and 1926 Interpretation of OSHA's Provisions for Feasible Administrative or Engineering... Administrative or Engineering Controls of Occupational Noise  giving interested parties 60 days to comment. The... Provisions for Feasible Administrative or Engineering Controls of Occupational Noise. The notice proposed to...[Feasibility and Economic Analysis of Denitrification of Photovoltaic Wastewater Containing High Fluorine].PubMedLi  Xiang; Zhu  Liang; Huang  Yong; Yang  Peng-bing; Cui  Jian-hong; Ma  Hang2016-04-15In order to reduce acid and alkali dosing in wastewater treatment process of polycrystalline silicon by using denitrification after fluoride removal. This experiment studied the feasibility of first removing nitrogen using the denitrification process by start-up denitrifying reactor before fluoride removal. The results showed that the Fâ» concentration in the waste water to had a certain influence on the denitrification. When the concentration of Fâ» was controlled to about 750 mg Â· Lâ»Â¹  the activity of denitrifying bacteria was not significantly influenced; when the concentration of Fâ» continued to increase  the denitrification efficiency of denitrifying sludge gradually reduced. In wastewater treatment of polycrystalline silicon  if the concentration of Fâ» was kept below 800 mg Â· Lâ»Â¹  the denitrification performance of denitrifying sludge was not obviously affected. After 93 d operation  the total nitrogen in effluent was stabilized below 50 mg Â· Lâ»Â¹  the total nitrogen removal efficiency reached 90%  and the removal rate reached 5 kg Â· (mÂ³ Â· d)â»Â¹. The calculation result showed  compared with the conventional denitrification process after fluoride removal  the proposed process could save about 70% of acid and 100% of alkali dosing  greatly reducing the cost of wastewater treatment.Feasibility study to determine the economic and operational benefits of utilizing unmanned aerial vehicles (UAVs).DOT National Transportation Integrated Search2014-04-01This project explored the feasibility of using Unmanned Aerial Systems (UASs) in Georgia : Department of Transportation (GDOT) operations. The research team conducted 24 interviews with : personnel in four GDOT divisions. Interviews focused on (1) th...Economic feasibility study for improving drinking water quality: a case study of arsenic contamination in rural Argentina.PubMedMolinos-Senante  MarÃ­a; Perez Carrera  Alejo; HernÃ¡ndez-Sancho  Francesc; FernÃ¡ndez-Cirelli  Alicia; Sala-Garrido  RamÃ³n2014-12-01Economic studies are essential in evaluating the potential external investment support and/or internal tariffs available to improve drinking water quality. Cost-benefit analysis (CBA) is a useful tool to assess the economic feasibility of such interventions  i.e. to take some form of action to improve the drinking water quality. CBA should involve the market and non-market effects associated with the intervention. An economic framework was proposed in this study  which estimated the health avoided costs and the environmental benefits for the net present value of reducing the pollutant concentrations in drinking water. We conducted an empirical application to assess the economic feasibility of removing arsenic from water in a rural area of Argentina. Four small-scale methods were evaluated in our study. The results indicated that the inclusion of non-market benefits was integral to supporting investment projects. In addition  the application of the proposed framework will provide water authorities with more complete information for the decision-making process.Economically Feasible Potentials for Wind Power in China and the USNASA Astrophysics Data System (ADS)Lu  X.; McElroy  M. B.; Chris  N. P.; Tchou  J.2011-12-01The present study is intended to explore the economic feasible potentials for wind energy in China and the U.S. subject to their policy systems for renewable energy. These two countries were chosen as subject locales for three reasons: first  they are the two largest countries responsible for energy consumption and CO2 emissions; second  these two countries have the largest installed capacities and the fastest annual growth of wind power in the world; third  China and the U.S. have adopted two distinct but representative incentive policies to accelerate exploitation of the renewable energy source from wind. Investments in large-scale wind farms in China gain privileges from the concession policy established under China's Renewable Energy Law. The electricity generated from wind can be sold at a guaranteed price for a concession period (typically the first ten operational years of a wind farm) to ensure the profitability of the wind farm development. The effectiveness of this policy has been evidenced by the swift growth of total installed capacities for wind power over the past five years in China. A spatial financial model was developed to evaluate the bus-bar prices of wind-generated electricity in China following this wind concession policy. The results indicated that wind could accommodate all of the demand for electricity projected for 2030 assuming a guaranteed bus-bar price of 7.6 U.S. Cents per kWh over the concession period. It is noteworthy that the prices of wind-generated electricity could be as cheap as conventional power generation in the years following the concession period. The power market in the U.S. is more deregulated and electricity is normally traded in a bidding process an hour to a day ahead of real time. Accordingly  the market-oriented policy instrument of PTC subsidies was instituted in the U.S. to ensure the competitiveness of wind power compared to the conventional power generation in the regional power markets. The spatial financialExamining the feasibility of implementing behavioural economics strategies that encourage home dinner vegetable intake among low-income children.PubMedLeak  Tashara M; Swenson  Alison; Rendahl  Aaron; Vickers  Zata; Mykerezi  Elton; Redden  Joseph P; Mann  Traci; Reicks  Marla2017-06-01To examine the feasibility of implementing nine behavioural economics-informed strategies  or 'nudges'  that aimed to encourage home dinner vegetable intake among low-income children. Caregivers were assigned six of nine strategies and implemented one new strategy per week (i.e. 6 weeks) during three dinner meals. Caregivers recorded child dinner vegetable intake on the nights of strategy implementation and rated the level of difficulty for assigned strategies. Baseline data on home vegetable availability and child vegetable liking were collected to assess overall strategy feasibility. Participants' homes in a large Midwestern metropolitan area  USA. Low-income caregiver/child (aged 9-12 years) dyads (n 39). Pairwise comparisons showed that child dinner vegetable intake for the strategy 'Serve at least two vegetables with dinner meals' was greater than intake for each of two other strategies: 'Pair vegetables with other foods the child likes' and 'Eat dinner together with an adult(s) modelling vegetable consumption'. Overall  caregivers' mean rating of difficulty for implementing strategies was 2Â·6 (1='not difficult'  10='very difficult'). Households had a mean of ten different types of vegetables available. Children reported a rating â‰¥5 for seventeen types of vegetable on a labelled hedonic scale (1='hate it'  5-6='it's okay'  10='like it a lot'). Behavioural economics-informed strategies are feasible to implement during dinner meals  with some strategies differing by how much they influence vegetable intake among low-income children in the home.Techno-economic feasibility and life cycle assessment of dairy effluent to renewable diesel via hydrothermal liquefaction.PubMedSummers  Hailey M; Ledbetter  Rhesa N; McCurdy  Alex T; Morgan  Michael R; Seefeldt  Lance C; Jena  Umakanta; Hoekman  S Kent; Quinn  Jason C2015-11-01The economic feasibility and environmental impact is investigated for the conversion of agricultural waste  delactosed whey permeate  through yeast fermentation to a renewable diesel via hydrothermal liquefaction. Process feasibility was demonstrated at laboratory-scale with data leveraged to validate systems models used to perform industrial-scale economic and environmental impact analyses. Results show a minimum fuel selling price of $4.78 per gallon of renewable diesel  a net energy ratio of 0.81  and greenhouse gas emissions of 30.0g-CO2-eqMJ(-1). High production costs and greenhouse gas emissions can be attributed to operational temperatures and durations of both fermentation and hydrothermal liquefaction. However  high lipid yields of the yeast counter these operational demands  resulting in a favorable net energy ratio. Results are presented on the optimization of the process based on economy of scale and a sensitivity analysis highlights improvements in conversion efficiency  yeast biomass productivity and hydrotreating efficiency can dramatically improve commercial feasibility. Copyright Â© 2015 Elsevier Ltd. All rights reserved.Landslides in Equatorial Africa: Identifying culturally  technically and economically feasible resilience strategiesNASA Astrophysics Data System (ADS)Kervyn  Matthieu; de Hontheim  Astrid; Dewitte  Olivier; Jacobs  Liesbet; Maes  Jan; Mertens  Kewan; Trefois  Philippe; Vranken  Liesbet; Poesen  Jean2014-05-01Landslides (LS) cause significant impacts in many equatorial regions. Their impact depends on their size and speed  the elements at risk and the vulnerability of these elements. This problem is particularly acute in Equatorial Africa characterized by mountainous topography  intense rains  deep weathering profiles  high population density and high vulnerability to geohazards. Every year LS cause fatalities and result in structural and functional damage to infrastructure and properties. Losses from LS are expected to increase in the future in response to the demographic pressure causing more development in landslide-prone areas (LSPA)  deforestation and associated changes in land use and land cover  and the changing climate causing higher or more intense rainfalls. Many studies investigated how natural factors and human activities control the occurrence or re-activation of LS. These studies typically delivered susceptibility maps but these are insufficient to lead to efficient risk management. Building resilience requires to have a true hazard estimate  accounting not only for the spatial distribution of future LS but also for their temporal occurrence and the hazard intensity  to quantitatively analyse the socio-economic consequences of LS and to identify effective resilience strategies that are cost-effective  technically efficient and that are culturally acceptable and adapted to the livelihoods of the vulnerable population. Such an analysis is crucial as it enables to provide practical recommendations for households and policy makers to mitigate LS-related damages. This project focuses on 4 representative study areas known for having suffered severely from rainfall-triggered LS in Uganda (Mount Elgon  Mount Rwenzori) and SW and NW Cameroon (Mount Cameroon  Bamenda). In two of these regions  some preliminary studies on LS characteristics and susceptibility mapping have been carried out  while hazard maps  a socio-economic impact analysis and resilience strategiesAdvanced Vehicle Monitoring And Communication Systems For Bus Transit Benefits And Economic FeasibilityDOT National Transportation Integrated Search1993-03-01THIS REPORT ANALYZES THE FEASIBILITY OF ADVANCED VEHICLE MONITORING AND COMMUNICATION (AVM/C) SYSTEMS FOR BUS TRANSIT IN THE UNITED STATES. SUCH SYSTEMS ARE WIDELY USED IN EUROPE AND CANADA TO PROVIDE MORE RELIABLE AND EFFICIENT BUS SERVICES  BUT HAV...Advanced Vehicle Monitoring And Communication Systems For Bus Transit  Benefits And Economic FeasibilityDOT National Transportation Integrated Search1991-09-01THIS REPORT ANALYZES THE FEASIBILITY OF ADVANCED VEHICLE MONITORING AND COMMUNICATION (AVM/C) SYSTEMS FOR BUS TRANSIT IN THE UNITED STATES. SUCH SYSTEMS ARE WIDELY USED IN EUROPE AND CANADA TO PROVIDE MORE RELIABLE AND EFFICIENT BUS SERVICES  BUT HAV...Economic feasibility of producing inside-out beams from small-diameter logsTreesearchDavid W. Patterson; Richard A. Kluender; James E. Granskog2002-01-01Previous work has shown that it is technically feasible to produce inside-out (ISO) beams by taking small-diameter (5 to 7 in.) logs  slabbing four sides  quartering the cant  and turning the quarters inside out and gluing them together. After drying  the beams were found to be straight  with no cracks  and of equal or better mechanical properties than solid sawn...Wisconsin Elementary Teacher Education Project. Volume VI  Feasibility Study: Pricing and Economic Analysis Study. Final Report.ERIC Educational Resources Information CenterWisconsin Univ.  Madison.This document is the second volume of the feasibility study report for the Wisconsin Elementary Teacher Education Project. It provides in part 1 data on program  planning and budgeting  including cost figures for preparing students in the present and new programs  marginal expenses  and costs for implementing the program on other campuses. Part 2â€¦Feasibility Report for Flood Control  Minnesota River at Chaska  Minnesota DTIC Science & Technology1973-08-01objectives of enviromental quality  social well-being  and economic efficiency. Table 7 presents a sumary of the ranking as determined by the Chaska Citizens...cohesion would be severely disrupted and long-standing socio - logical and historical ties would be lost. Further  it is questionable whether the...acres of land including 100 acres of cropland and 400 acres of marshland would be used. The use of dry dams as proposed would conflict with JonathanAssessing the economic and environmental feasibility of utility scaled PV electricity production in the state of Georgia.PubMedTaylor  Ruthie; Critttenden  John2012-01-01Photovoltaic (PV) technology  an increasingly popular source for renewable energy  is being deployed in places with solar insolation that is comparable to that in state of Georgia. This study assesses the feasibility and environmental impact of utility scale photovoltaic (PV) electricity production in Georgia by assessing the economic costs  avoided costs  health benefits  and environmental benefits. The cost of PV used in this study is 3.52 $/kW. The RETScreen model was employed to analyze the impact of incentives on the economic viability of the plants that produce 93 GWh  371 GWh  and 1 484 GWh  respectively. 57% of the capital cost is required in the form of incentives or subsidies to make the projects economically feasible. The high estimated cost of cleaning the equivalent amount of emissions from a coal-fired power plant is $14.5 million  $58 million  and $232 million for a 50 MW  200 MW  and 800 MW plant  respectively Avoided costs in health damages are estimated to be $28 million  $112 million  and $449 million and the numbers of jobs to be created are 2 500  10 000  and 40 000 for 50 MW  200 MW  and 800 MW plants  respectively. And  the cumulative value of renewable energy credits from a 50 MW  200 MW  and a 800 MW plant are $59 million  $237 million  and $789 million  respectively.Economic feasibility of converting cow manure to electricity: a case study of the CVPS Cow Power program in Vermont.PubMedWang  Q; Thompson  E; Parsons  R; Rogers  G; Dunn  D2011-10-01A case study of the Central Vermont Public Service Corporation (CVPS) Cow Power program examines the economic feasibility for dairy farms to convert cow manure into electricity via anaerobic methane digestion. The study reviews the mechanism for CVPS  dairy farms  electricity customers  and government agencies to develop and operate the program since 2004  examines the costs and returns for the participating dairy farms  and assesses their cash flow over a period of 7 yr under different scenarios. With 6 dairy farms generating about 12 million kilowatt-hours of electricity per year and more than 4 600 CVPS electricity customers voluntarily paying premiums of $0.04 per kilowatt-hour  or a total of about $470 000 per year  the CVPS Cow Power program represents a successful and locally sourced renewable energy project with many environmental and economic benefits. Factors for the successful development and operation of the program include significant grants from government agencies and other organizations  strong consumer support  timely adjustments to the basic electricity price paid to the farms  and close collaboration among the participating parties. This study confirms that it is technically feasible to convert cow manure to electricity on farms  but the economic returns depend highly on the base electricity price  premium rate  financial supports from government agencies and other organizations  and sales of the byproducts of methane generation. Copyright Â© 2011 American Dairy Science Association. Published by Elsevier Inc. All rights reserved.Biologic Effects of Atmospheric Pollutants: Asbestos - The Need For and Feasibility of Air Pollution ControlsEPA Pesticide FactsheetsThis 1971 report sets forth in a well-organized fashion the currently available information on asbestos as an air pollutant  with special attention to sources health effects  measurements  and feasibility of control.ECONOMIC FEASIBILITY OF RADIATION-PASTEURIZING FRESH STRAWBERRIES  PEACHES  TOMATOES  GRAPES  ORANGES  AND GRAPEFRUITSciTech ConnectDroge  J.H.1963-08-01Results are reported from a survey of the produce industry on the feasibility of using radiation processing to extend the storage life of fresh strawberries  peaches  tomatoes  grapes  oranges  and grapefruit. A majority of the respondents thought that radiation processing would increase the production and market volume of the selected fruits and vegetables surveyed but would not change output and sales volume of camned  frozen  and other processed forms. Cost estimates of radiation processing are discussed. (C.H.)Feasibility Study of Economics and Performance of Solar Photovoltaics at the Former St. Marks Refinery in St. Marks  FloridaSciTech ConnectLisell  L.; Mosey  G.2010-09-01This report presents the results of an assessment of the technical and economic feasibility of deploying a photovoltaics (PV) system on a brownfield site in St. Marks  Florida. The site was assessed for possible PV installations. The cost  performance  and site impacts of different PV options were estimated. The economics of the potential systems were analyzed using an electric rate of $0.08/kWh and incentives offered in the State of Florida and from the two accessible utilities  Progress Energy and the City of Tallahassee. According to the site production calculations  the most cost-effective system in terms of return on investment ismoreÂ Â» the fixed-tilt thin film technology. The report recommends financing options that could assist in the implementation of such a system.Â«Â lessFeasibility Study of Economics and Performance of Solar Photovoltaics at the Refuse Hideaway Landfill in Middleton  WisconsinSciTech ConnectSalasovich  J.; Mosey  G.2011-08-01This report presents the results of an assessment of the technical and economic feasibility of deploying a photovoltaics (PV) system on a brownfield site at the Refuse Hideaway Landfill in Middleton  Wisconsin. The site currently has a PV system in place and was assessed for further PV installations. The cost  performance  and site impacts of different PV options were estimated. The economics of the potential systems were analyzed using an electric rate of $0.1333/kWh and incentives offered by the State of Wisconsin and by the serving utility  Madison Gas and Electric. According to the site production calculations  the most cost-effectivemoreÂ Â» system in terms of return on investment is the thin-film fixed-tilt technology. The report recommends financing options that could assist in the implementation of such a system.Â«Â lessTowards feasible and effective predictive wavefront control for adaptive opticsSciTech ConnectPoyneer  L A; Veran  JWe have recently proposed Predictive Fourier Control  a computationally efficient and adaptive algorithm for predictive wavefront control that assumes frozen flow turbulence. We summarize refinements to the state-space model that allow operation with arbitrary computational delays and reduce the computational cost of solving for new control. We present initial atmospheric characterization using observations with Gemini North's Altair AO system. These observations  taken over 1 year  indicate that frozen flow is exists  contains substantial power  and is strongly detected 94% of the time.Estimating economic thresholds for pest control: an alternative procedure.PubMedRamirez  O A; Saunders  J L1999-04-01An alternative methodology to determine profit maximizing economic thresholds is developed and illustrated. An optimization problem based on the main biological and economic relations involved in determining a profit maximizing economic threshold is first advanced. From it  a more manageable model of 2 nonsimultaneous reduced-from equations is derived  which represents a simpler but conceptually and statistically sound alternative. The model recognizes that yields and pest control costs are a function of the economic threshold used. Higher (less strict) economic thresholds can result in lower yields and  therefore  a lower gross income from the sale of the product  but could also be less costly to maintain. The highest possible profits will be obtained by using the economic threshold that results in a maximum difference between gross income and pest control cost functions.Feasibility of advanced vehicle control systems for transit busesDOT National Transportation Integrated Search1997-01-01In the course of developing automated vehicle-roadway systems  opportunities to deploy vehicle control systems at intermediate stages of development may emerge. Some of these systems may provide a significant efficiency or safety enhancement to exist...Feasibility of Synergy-Based Exoskeleton Robot Control in Hemiplegia.PubMedHassan  Modar; Kadone  Hideki; Ueno  Tomoyuki; Hada  Yasushi; Sankai  Yoshiyuki; Suzuki  Kenji2018-06-01Here  we present a study on exoskeleton robot control based on inter-limb locomotor synergies using a robot control method developed to target hemiparesis. The robot control is based on inter-limb locomotor synergies and kinesiological information from the non-paretic leg and a walking aid cane to generate motion patterns for the assisted leg. The developed synergy-based system was tested against an autonomous robot control system in five patients with hemiparesis and varying locomotor abilities. Three of the participants were able to walk using the robot. Results from these participants showed an improved spatial symmetry ratio and more consistent step length with the synergy-based method compared with that for the autonomous method  while the increase in the range of motion for the assisted joints was larger with the autonomous system. The kinematic synergy distribution of the participants walking without the robot suggests a relationship between each participant's synergy distribution and his/her ability to control the robot: participants with two independent synergies accounting for approximately 80% of the data variability were able to walk with the robot. This observation was not consistently apparent with conventional clinical measures such as the Brunnstrom stages. This paper contributes to the field of robot-assisted locomotion therapy by introducing the concept of inter-limb synergies  demonstrating performance differences between synergy-based and autonomous robot control  and investigating the range of disability in which the system is usable.Economics.ERIC Educational Resources Information CenterJames  L. D.1978-01-01Presents a literature review of the economic aspects of water pollution control covering publications of 1976-77. This review also includes the policy issues of water management. A list of 77 references is presented. (HM)Defining Feasibility and Pilot Studies in Preparation for Randomised Controlled Trials: Development of a Conceptual Framework.PubMedEldridge  Sandra M; Lancaster  Gillian A; Campbell  Michael J; Thabane  Lehana; Hopewell  Sally; Coleman  Claire L; Bond  Christine M2016-01-01We describe a framework for defining pilot and feasibility studies focusing on studies conducted in preparation for a randomised controlled trial. To develop the framework  we undertook a Delphi survey; ran an open meeting at a trial methodology conference; conducted a review of definitions outside the health research context; consulted experts at an international consensus meeting; and reviewed 27 empirical pilot or feasibility studies. We initially adopted mutually exclusive definitions of pilot and feasibility studies. However  some Delphi survey respondents and the majority of open meeting attendees disagreed with the idea of mutually exclusive definitions. Their viewpoint was supported by definitions outside the health research context  the use of the terms 'pilot' and 'feasibility' in the literature  and participants at the international consensus meeting. In our framework  pilot studies are a subset of feasibility studies  rather than the two being mutually exclusive. A feasibility study asks whether something can be done  should we proceed with it  and if so  how. A pilot study asks the same questions but also has a specific design feature: in a pilot study a future study  or part of a future study  is conducted on a smaller scale. We suggest that to facilitate their identification  these studies should be clearly identified using the terms 'feasibility' or 'pilot' as appropriate. This should include feasibility studies that are largely qualitative; we found these difficult to identify in electronic searches because researchers rarely used the term 'feasibility' in the title or abstract of such studies. Investigators should also report appropriate objectives and methods related to feasibility; and give clear confirmation that their study is in preparation for a future randomised controlled trial designed to assess the effect of an intervention.Economic Feasibility of Wireless Sensor Network-Based Service Provision in a Duopoly Setting with a Monopolist OperatorPubMed CentralRomero  JuliÃ¡n; Sacoto-Cabrera  Erwin J.2017-01-01We analyze the feasibility of providing Wireless Sensor Network-data-based services in an Internet of Things scenario from an economical point of view. The scenario has two competing service providers with their own private sensor networks  a network operator and final users. The scenario is analyzed as two games using game theory. In the first game  sensors decide to subscribe or not to the network operator to upload the collected sensing-data  based on a utility function related to the mean service time and the price charged by the operator. In the second game  users decide to subscribe or not to the sensor-data-based service of the service providers based on a Logit discrete choice model related to the quality of the data collected and the subscription price. The sinks and users subscription stages are analyzed using population games and discrete choice models  while network operator and service providers pricing stages are analyzed using optimization and Nash equilibrium concepts respectively. The model is shown feasible from an economic point of view for all the actors if there are enough interested final users and opens the possibility of developing more efficient models with different types of services. PMID:29186847Economic Feasibility of Wireless Sensor Network-Based Service Provision in a Duopoly Setting with a Monopolist Operator.PubMedSanchis-Cano  Angel; Romero  JuliÃ¡n; Sacoto-Cabrera  Erwin J; Guijarro  Luis2017-11-25We analyze the feasibility of providing Wireless Sensor Network-data-based services in an Internet of Things scenario from an economical point of view. The scenario has two competing service providers with their own private sensor networks  a network operator and final users. The scenario is analyzed as two games using game theory. In the first game  sensors decide to subscribe or not to the network operator to upload the collected sensing-data  based on a utility function related to the mean service time and the price charged by the operator. In the second game  users decide to subscribe or not to the sensor-data-based service of the service providers based on a Logit discrete choice model related to the quality of the data collected and the subscription price. The sinks and users subscription stages are analyzed using population games and discrete choice models  while network operator and service providers pricing stages are analyzed using optimization and Nash equilibrium concepts respectively. The model is shown feasible from an economic point of view for all the actors if there are enough interested final users and opens the possibility of developing more efficient models with different types of services.Optimal control of a harmonic oscillator: Economic interpretationsNASA Astrophysics Data System (ADS)JanovÃ¡  Jitka; Hampel  David2013-10-01Optimal control is a popular technique for modelling and solving the dynamic decision problems in economics. A standard interpretation of the criteria function and Lagrange multipliers in the profit maximization problem is well known. On a particular example  we aim to a deeper understanding of the possible economic interpretations of further mathematical and solution features of the optimal control problem: we focus on the solution of the optimal control problem for harmonic oscillator serving as a model for Phillips business cycle. We discuss the economic interpretations of arising mathematical objects with respect to well known reasoning for these in other problems.Determining the economic feasibility of salvaging gypsy moth-killed hardwoodsTreesearchChris B. LeDoux1990-01-01Oak sawlog and pulpwood losses in stands defoliated by gypsy moths have become a critical problem for some forest landowners. The salvage of gypsy moth-killed hardwoods can become an important source of pulpwood and sawlogs. This study documents a methodology and provides guidelines to determine defoliated oak stands that are economically salvageable. Stand data from...Economic feasibility of biochar application to soils in temperate climate regionsNASA Astrophysics Data System (ADS)Soja  Gerhard; BÃ¼cker  Jannis; Gunczy  Stefan; Kitzler  Barbara; KlinglmÃ¼ller  Michaela; Kloss  Stefanie; Watzinger  Andrea; Wimmer  Bernhard; Zechmeister-Boltenstern  Sophie; Zehetner  Franz2014-05-01The findings that fertility improvements in tropical soils have been successfully mediated by biochar applications have caused wide-spread interest to use biochar as a soil amendment also for soils in temperate climate regions. But these soils in intensively cultivated regions are not always as acidic or sandy as the tropical Ferralsols where biochar is most effective. Therefore it is not self-evident that different soil characteristics allow biochar to display the same benefits if site-specific demands for the optimal organic soil amendment are not considered. This study pursued the objective to study the extent of benefits that biochar could provide for crops on two typical Austrian agricultural soils in a two-year field experiment. An economic evaluation assessed the local biochar production costs and compared them with the value of the observed biochar benefits. From a business economic viewpoint  currently high costs of biochar are not balanced by only moderate increases in crop yields and thus agricultural revenues. Improved water retention due to biochar  however  might justify biochar as an adaptation measure to global warming  especially when considering beside business economic aspects also overall economic aspects. When not assuming total crop failures but only increased soil fertility  even an inclusion of avoided social (=societal) costs by sequestering carbon and thereby helping to mitigate climate change do not economically justify the application of biochar. Price of biochar would need to decrease by at least 40 % to achieve a break-even from the overall economic viewpoint (if optimistic assumptions about the social value of sequestered carbon are applied; at pessimistic assumptions price for biochar must decrease even more in order to break even). When applying an alternative type of soil treatment of using modified biochar but avoiding additional N-fertilization  a similar picture arises: Social benefits due to avoided N-fertilization andFeasibility Study of Economics and Performance of Solar Photovoltaics at Johnson County LandfillSciTech ConnectSalasovich  J.; Mosey  G.2012-01-01The U.S. Environmental Protection Agency (EPA)  in accordance with the RE-Powering America's Land initiative  selected the Johnson County Landfill in Shawnee  Kansas  for a feasibility study of renewable energy production. Citizens of Shawnee  city planners  and site managers are interested in redevelopment uses for landfills in Kansas that are particularly well suited for grid-tied solar photovoltaic (PV) installation. This report assesses the Johnson County Landfill for possible grid-tied PV installations and estimates the cost  performance  and site impacts of three different PV options: crystalline silicon (fixed tilt)  crystalline silicon (single-axis tracking)  and thin film (fixed tilt). Each option represents amoreÂ Â» standalone system that can be sized to use an entire available site area. In addition  the report outlines financing options that could assist in the implementation of a system. The feasibility of PV systems installed on landfills is highly impacted by the available area for an array  solar resource  operating status  landfill cap status  distance to transmission lines  and distance to major roads. The report findings are applicable to other landfills in the surrounding area.Â«Â lessMethodological issues in the design and evaluation of supported communication for aphasia training: a cluster-controlled feasibility study.PubMedHorton  Simon; Clark  Allan; Barton  Garry; Lane  Kathleen; Pomeroy  Valerie M2016-04-18To assess the feasibility and acceptability of training stroke service staff to provide supported communication for people with moderate-severe aphasia in the acute phase; assess the suitability of outcome measures; collect data to inform sample size and Health Economic evaluation in a definitive trial. Phase II cluster-controlled  observer-blinded feasibility study. In-patient stroke rehabilitation units in the UK matched for bed numbers and staffing were assigned to control and intervention conditions. 70 stroke rehabilitation staff from all professional groups  excluding doctors  were recruited. 20 patients with moderate-severe aphasia were recruited. Supported communication for aphasia training  adapted to the stroke unit context versus usual care. Training was supplemented by a staff learning log  refresher sessions and provision of communication resources. Feasibility of recruitment and acceptability of the intervention and of measures required to assess outcomes and Health Economic evaluation in a definitive trial. Staff outcomes: Measure of Support in Conversation; patient outcomes: Stroke and Aphasia Quality of Life Scale; Communicative Access Measure for Stroke; Therapy Outcome Measures for aphasia; EQ-5D-3L was used to assess health outcomes. Feasibility of staff recruitment was demonstrated. Training in the intervention was carried out with 28 staff and was found to be acceptable in qualitative reports. 20 patients consented to take part  6 withdrew. 18 underwent all measures at baseline; 16 at discharge; and 14 at 6-month follow-up. Of 175 patients screened 71% were deemed to be ineligible  either lacking capacity or too unwell to participate. Poor completion rates impacted on assessment of patient outcomes. We were able to collect sufficient data at baseline  discharge and follow-up for economic evaluation. The feasibility study informed components of the intervention and implementation in day-to-day practice. Modifications to the design are neededEconomic Incentive Approaches to Air Pollution Control (1981)EPA Pesticide FactsheetsThis draft report was prepared to respond to the requirements of Section 405(g) of the Clean Air Act for a general report on economic incentive approaches to air pollution control  but was never issued.The economic feasibility of producing sweet sorghum as an ethanol feedstock in MississippiNASA Astrophysics Data System (ADS)Linton  Joseph AndrewThis study examines the feasibility of producing sweet sorghum as an ethanol feedstock in Mississippi. An enterprise budgeting system is used along with estimates of transportation costs to estimate farmers' breakeven costs for producing and delivering sweet sorghum biomass. This breakeven cost for the farmer  along with breakeven costs for the producer based on wholesale ethanol price  production costs  and transportation and marketing costs for the refined ethanol  is used to estimate the amounts that farmers and ethanol producers would be willing to accept (WTA) and willing to pay (WTP)  respectively  for sweet sorghum biomass. These WTA and WTP estimates are analyzed by varying key factors in the biomass and ethanol production processes. Deterministic and stochastic models are used to estimate profits for sweet sorghum and competing crops in two representative counties in Mississippi  with sweet sorghum consistently yielding negative per-acre profits in both counties.Behavioral Economics of Self-Control FailurePubMed CentralHeshmat  Shahram2015-01-01The main idea in this article is that addiction is a consequence of falling victim to decision failures that lead to preference for the addictive behaviors. Addiction is viewed as valuation disease  where the nervous system overvalues cues associated with drugs or drug-taking. Thus  addiction can be viewed as a diminished capacity to choose. Addicted individuals assign lower values to delayed rewards than to immediate ones. The preference for immediate gratification leads to self-control problems. This article highlights a number of motivational forces that can generate self-control failure. PMID:26339218Airport Economics: Management Control Financial Reporting SystemsNASA Technical Reports Server (NTRS)Buchbinder  A.1972-01-01The development of management control financial reporting systems for airport operation is discussed. The operation of the system to provide the reports required for determining the specific revenue producing facilities of airports is described. The organization of the cost reporting centers to show the types of information provided by the system is analyzed.Climate Impact and Economic Feasibility of Solar Thermochemical Jet Fuel Production.PubMedFalter  Christoph; Batteiger  Valentin; Sizmann  Andreas2016-01-05Solar thermochemistry presents a promising option for the efficient conversion of H2O and CO2 into liquid hydrocarbon fuels using concentrated solar energy. To explore the potential of this fuel production pathway  the climate impact and economic performance are analyzed. Key drivers for the economic and ecological performance are thermochemical energy conversion efficiency  the level of solar irradiation  operation and maintenance  and the initial investment in the fuel production plant. For the baseline case of a solar tower concentrator with CO2 capture from air  jet fuel production costs of 2.23 â‚¬/L and life cycle greenhouse gas (LC GHG) emissions of 0.49 kgCO2-equiv/L are estimated. Capturing CO2 from a natural gas combined cycle power plant instead of the air reduces the production costs by 15% but leads to LC GHG emissions higher than that of conventional jet fuel. Favorable assumptions for all involved process steps (30% thermochemical energy conversion efficiency  3000 kWh/(m(2) a) solar irradiation  low CO2 and heliostat costs) result in jet fuel production costs of 1.28 â‚¬/L at LC GHG emissions close to zero. Even lower production costs may be achieved if the commercial value of oxygen as a byproduct is considered.Plant-made vaccines against West Nile virus are potent  safe  and economically feasiblePubMed CentralChen  Qiang2015-01-01The threat of West Nile virus (WNV) epidemics with increasingly severe neuroinvasive infections demands the development and licensing of effective vaccines. To date  vaccine candidates based on inactivated  live-attenuated  or chimeric virus  and viral DNA and WNV protein subunits have been developed. Some have been approved for veterinary use or are under clinical investigation  yet no vaccine has been licensed for human use. Reaching the milestone of a commercialized human vaccine  however  may largely depend on the economics of vaccine production. Analysis suggests that currently only novel low-cost production technologies would allow vaccination to outcompete the cost of surveillance and clinical treatment. Here  we review progress using plants to address the economic challenges of WNV vaccine production. The advantages of plants as hosts for vaccine production in cost  speed and scalability  especially those of viral vector-based transient expression systems  are discussed. The progress in developing WNV subunit vaccines in plants is reviewed within the context of their expression  characterization  downstream processing  and immunogenicity in animal models. The development of vaccines based on enveloped and non-enveloped virus-like particles is also discussed. These advancements suggest that plants may provide a production platform that offers potent  safe and affordable human vaccines against WNV. PMID:25676782Plant-made vaccines against West Nile virus are potent  safe  and economically feasible.PubMedChen  Qiang2015-05-01The threat of West Nile virus (WNV) epidemics with increasingly severe neuroinvasive infections demands the development and licensing of effective vaccines. To date  vaccine candidates based on inactivated  live-attenuated  or chimeric virus  and viral DNA and WNV protein subunits have been developed. Some have been approved for veterinary use or are under clinical investigation  yet no vaccine has been licensed for human use. Reaching the milestone of a commercialized human vaccine  however  may largely depend on the economics of vaccine production. Analysis suggests that currently only novel low-cost production technologies would allow vaccination to outcompete the cost of surveillance and clinical treatment. Here  we review progress using plants to address the economic challenges of WNV vaccine production. The advantages of plants as hosts for vaccine production in cost  speed and scalability  especially those of viral vector-based transient expression systems  are discussed. The progress in developing WNV subunit vaccines in plants is reviewed within the context of their expression  characterization  downstream processing  and immunogenicity in animal models. The development of vaccines based on enveloped and non-enveloped virus-like particles is also discussed. These advancements suggest that plants may provide a production platform that offers potent  safe and affordable human vaccines against WNV. Copyright Â© 2015 WILEY-VCH Verlag GmbH & Co. KGaA  Weinheim.Feasibility Assessment of a Fine-Grained Access Control Model on Resource Constrained Sensors.PubMedUriarte Itzazelaia  Mikel; Astorga  Jasone; Jacob  Eduardo; Huarte  Maider; RomaÃ±a  Pedro2018-02-13Upcoming smart scenarios enabled by the Internet of Things (IoT) envision smart objects that provide services that can adapt to user behavior or be managed to achieve greater productivity. In such environments  smart things are inexpensive and  therefore  constrained devices. However  they are also critical components because of the importance of the information that they provide. Given this  strong security is a requirement  but not all security mechanisms in general and access control models in particular are feasible. In this paper  we present the feasibility assessment of an access control model that utilizes a hybrid architecture and a policy language that provides dynamic fine-grained policy enforcement in the sensors  which requires an efficient message exchange protocol called Hidra. This experimental performance assessment includes a prototype implementation  a performance evaluation model  the measurements and related discussions  which demonstrate the feasibility and adequacy of the analyzed access control model.Feasibility Assessment of a Fine-Grained Access Control Model on Resource Constrained SensorsPubMed CentralHuarte  Maider; RomaÃ±a  Pedro2018-01-01Upcoming smart scenarios enabled by the Internet of Things (IoT) envision smart objects that provide services that can adapt to user behavior or be managed to achieve greater productivity. In such environments  smart things are inexpensive and  therefore  constrained devices. However  they are also critical components because of the importance of the information that they provide. Given this  strong security is a requirement  but not all security mechanisms in general and access control models in particular are feasible. In this paper  we present the feasibility assessment of an access control model that utilizes a hybrid architecture and a policy language that provides dynamic fine-grained policy enforcement in the sensors  which requires an efficient message exchange protocol called Hidra. This experimental performance assessment includes a prototype implementation  a performance evaluation model  the measurements and related discussions  which demonstrate the feasibility and adequacy of the analyzed access control model. PMID:29438338Fuel feasibility study for Red River Army Depot boiler plant. Final report. [Economic breakeven points for conversion to fossil fuelsSciTech ConnectAbles  L.D.This paper establishes economic breakeven points for the conversion to various fossil fuels as a function of time and pollution constraints for the main boiler plant at Red River Army Depot in Texarkana  Texas. In carrying out the objectives of this paper  the author develops what he considers to be the basic conversion costs and operating costs for each fossil fuel under investigation. These costs are analyzed by the use of the present worth comparison method  and the minimum cost difference between the present fuel and the proposed fuel which would justify the conversion to the proposed fuel is calculated.moreÂ Â» These calculated breakeven points allow a fast and easy method of determining the feasibility of a fuel by merely knowing the relative price difference between the fuels under consideration. (GRA)Â«Â lessEconomics of high-rise construction: the feasibility of skyscrapers building in the Russian citiesNASA Astrophysics Data System (ADS)Petrov  Artur; Petrova  Daria2018-03-01The article considers the economic aspects of constructing high-rise buildings in the world and in Russia. Data on the number of high-rise buildings in Russian cities with a million population are presented. It is proved that interest in high-rise construction in Russia has been formed only in Moscow and partly in St. Petersburg and Yekaterinburg. The analysis showed that the reason for this is the expensiveness of high-rise construction. According to the enlarged macro-calculation  the cost of building 1 m2 of the area of the Federation Towers complex (Moscow City) is about 2710 /m2. Practically a possibility of return on investments in the foreseeable time interval exists only in Moscow. For the regions of Russia this task is rather complicated. Population density in regional Russian cities is quite low  business entities do not have the necessary financial resources for investing in high-rise construction  and investments from abroad absent.Impacts of management practices on bioenergy feedstock yield and economic feasibility on Conservation Reserve Program grasslandsSciTech ConnectAnderson  Eric K.; Aberle  Ezra; Chen  ChengciPerennial grass mixtures planted on Conservation Reserve Program (CRP) land are a potential source of dedicated bioenergy feedstock. Long-term nitrogen (N) and harvest management are critical factors for maximizing biomass yield while maintaining the longevity of grass stands. A six-year farm-scale study was conducted to understand the impact of weather variability on biomass yield  determine optimal N fertilization and harvest timing management practices for sustainable biomass production  and estimate economic viability at six CRP sites in the United States. Precipitation during the growing season was a critical factor for annual biomass production across all regions  and annual biomass production wasmoreÂ Â» severely reduced when growing season precipitation was below 50% of average. The N rate of 112 kg ha -1 produced the highest biomass yield at each location. Harvest timing resulting in the highest biomass yield was site-specific and was a factor of predominant grass type  seasonal precipitation  and the number of harvests taken per year. The use of N fertilizer for yield enhancement unambiguously increased the cost of biomass regardless of the harvest timing for all six sites. The breakeven price of biomass at the farmgate ranged from 37 dollars to 311 dollars Mg -1 depending on the rate of N application  timing of harvesting  and location when foregone opportunity costs were not considered. Breakeven prices ranged from 69 dollars to 526 dollars Mg -1 when the loss of CRP land rental payments was included as an opportunity cost. Annual cost of the CRP to the federal government could be reduced by over 8% in the states included in this study; however  this would require the biomass price to be much higher than in the case where the landowner receives the CRP land rent. Lastly  this field research demonstrated the importance of long-term  farm-scale research for accurate estimation of biomass feedstock production and economic viability from perennialImpacts of management practices on bioenergy feedstock yield and economic feasibility on Conservation Reserve Program grasslandsDOE PAGESAnderson  Eric K.; Aberle  Ezra; Chen  Chengci; ...2015-12-21Perennial grass mixtures planted on Conservation Reserve Program (CRP) land are a potential source of dedicated bioenergy feedstock. Long-term nitrogen (N) and harvest management are critical factors for maximizing biomass yield while maintaining the longevity of grass stands. A six-year farm-scale study was conducted to understand the impact of weather variability on biomass yield  determine optimal N fertilization and harvest timing management practices for sustainable biomass production  and estimate economic viability at six CRP sites in the United States. Precipitation during the growing season was a critical factor for annual biomass production across all regions  and annual biomass production wasmoreÂ Â» severely reduced when growing season precipitation was below 50% of average. The N rate of 112 kg ha -1 produced the highest biomass yield at each location. Harvest timing resulting in the highest biomass yield was site-specific and was a factor of predominant grass type  seasonal precipitation  and the number of harvests taken per year. The use of N fertilizer for yield enhancement unambiguously increased the cost of biomass regardless of the harvest timing for all six sites. The breakeven price of biomass at the farmgate ranged from 37 dollars to 311 dollars Mg -1 depending on the rate of N application  timing of harvesting  and location when foregone opportunity costs were not considered. Breakeven prices ranged from 69 dollars to 526 dollars Mg -1 when the loss of CRP land rental payments was included as an opportunity cost. Annual cost of the CRP to the federal government could be reduced by over 8% in the states included in this study; however  this would require the biomass price to be much higher than in the case where the landowner receives the CRP land rent. Lastly  this field research demonstrated the importance of long-term  farm-scale research for accurate estimation of biomass feedstock production and economic viability from perennialQualitative evaluation and economic estimates of an infection control champions program.PubMedLloyd-Smith  Elisa; Curtin  Jim; Gilbart  Wayne; Romney  Marc G2014-12-01In many North American hospitals  conventional infection control operational models often struggle to provide sufficient support to frontline health care workers. The objective of this study was to describe a sustainable infection control champion (ICC) program based on findings from focus groups. A distributed model of infection control was established by placing infection prevention and control-trained ICCs in 3 Canadian hospitals for a period of 12 months. Subsequently  semistructured focus groups were conducted to describe overall feasibility and impeding and critical factors affecting sustainability. An economic estimate of the ICC program compared with the cost of hiring a new infection control practitioner was also calculated. Focus group participants considered the program feasible. Barriers included lack of time and staff turnover. Themes critical for the successful implementation of an ICC program included defined ICC roles and goals  adequate support and resources for the ICC  engagement with all levels of staff  flexible structure  and program evaluation. The cost per bed of the ICC program was less than the cost per bed of hiring a new infection control practitioner. A distributed model of providing infection prevention and control services may have benefit when hospital infection control teams are underresourced  as is often the case. Several key factors are needed for the successful implementation of an ICC program. Copyright Â© 2014 Association for Professionals in Infection Control and Epidemiology  Inc. Published by Elsevier Inc. All rights reserved.Energy balance and economic feasibility of shallow geothermal systems for winery industryNASA Astrophysics Data System (ADS)Ruiz-MazarrÃ³n  F.; Almoguera-MillÃ¡n  J.; GarcÃ­a-Llaneza  J.; Perdigones  A.2012-04-01 paper analyzes the use of shallow geothermal systems in wineries  studying its feasibility versus conventional HVAC systems. A comparative analysis of six European locations will be performed. [1] OIV  Assessment on the world vitiviniculture situation in 2010  in  Organisation Internationale de la Vigne et du Vin  2010. [2] FAO  Agribusiness Handbook: Grapes Wine  in  Investment Centre Division. FAO  2009. [3] F.R. MazarrÃ³n  J. Cid-Falceto  I. CaÃ±as  An assessment of using ground thermal inertia as passive thermal technique in the wine industry around the world  Applied Thermal Engineering  33-34 (0) (2012) 54-61.Laparoscopic Cholecystectomy under Segmental Thoracic Spinal Anesthesia: A Feasible Economical Alternative.PubMedKejriwal  Aditya Kumar; Begum  Shaheen; Krishan  Gopal; Agrawal  Richa2017-01-01Laparoscopic surgery is normally performed under general anesthesia  but regional techniques like thoracic epidural and lumbar spinal have been emerging and found beneficial. We performed a clinical case study of segmental thoracic spinal anaesthesia in a healthy patient. We selected an ASA grade I patient undergoing elective laparoscopic cholecystectomy and gave spinal anesthetic in T10-11 interspace using 1 ml of bupivacaine 5 mg ml -1 mixed with 0.5 ml of fentanyl 50 Î¼g ml -1 . Other drugs were only given (systemically) to manage patient anxiety  pain  nausea  hypotension  or pruritus during or after surgery. The patient was reviewed 2 days postoperatively in ward. The thoracic spinal anesthetia was performed easily in the patient. Some discomfort which was readily treated with 1mg midazolam and 20 mg ketamine intravenously. There was no neurological deficit and hemodynamic parameters were in normal range intra and post-operatively and recovery was uneventful. We used a narrow gauze (26G) spinal needle which minimized the trauma to the patient and the chances of PDPH  which was more if 16 or 18G epidural needle had been used and could have increased further if there have been accidental dura puncture. Also using spinal anesthesia was economical although it should be done cautiously as we are giving spinal anesthesia above the level of termination of spinal cord.Laparoscopic Cholecystectomy under Segmental Thoracic Spinal Anesthesia: A Feasible Economical AlternativePubMed CentralKejriwal  Aditya Kumar; Begum  Shaheen; Krishan  Gopal; Agrawal  Richa2017-01-01Laparoscopic surgery is normally performed under general anesthesia  but regional techniques like thoracic epidural and lumbar spinal have been emerging and found beneficial. We performed a clinical case study of segmental thoracic spinal anaesthesia in a healthy patient. We selected an ASA grade I patient undergoing elective laparoscopic cholecystectomy and gave spinal anesthetic in T10-11 interspace using 1 ml of bupivacaine 5 mg mlâˆ’1 mixed with 0.5 ml of fentanyl 50 Î¼g mlâˆ’1. Other drugs were only given (systemically) to manage patient anxiety  pain  nausea  hypotension  or pruritus during or after surgery. The patient was reviewed 2 days postoperatively in ward. The thoracic spinal anesthetia was performed easily in the patient. Some discomfort which was readily treated with 1mg midazolam and 20 mg ketamine intravenously. There was no neurological deficit and hemodynamic parameters were in normal range intra and post-operatively and recovery was uneventful. We used a narrow gauze (26G) spinal needle which minimized the trauma to the patient and the chances of PDPH  which was more if 16 or 18G epidural needle had been used and could have increased further if there have been accidental dura puncture. Also using spinal anesthesia was economical although it should be done cautiously as we are giving spinal anesthesia above the level of termination of spinal cord. PMID:28928589Evaluating critical factors to the economic feasibility of semi-intensive pig rearing in western Kenya.PubMedLevy  Mike; Dewey  Cate; Weersink  Alfons; Mutua  Florence; Carter  Natalie; Poljak  Zvonimir2014-06-01The purpose of this research is to assess how season  ADG  opportunity costs of farm-grown feeds  pig weight  and butcher price variation impact the economic potential of semi-intensive pig rearing. We developed a unique algorithm that emulates least-cost pig feeding and used it to assess the impact of the aforementioned factors on farmers' maximum revenue and profit potential when pigs are sold to local butchers in western Kenya. When considered as independent factors influencing feed costs to grow a pig to a market weight of 30 kg  variation in ADG  opportunity cost of feed  and weaning season resulted in feed cost differences of up to 982  947  and 379 Kenyan shillings (KES)  respectively. The variation in revenues attributable to butcher or butcher negotiation and seasonal variance of butcher prices for a 30 kg pig was 744 and 225 KES  respectively. Feed items most commonly chosen for least-cost feed rations were small dried fish  cooked ground maize  whole maize  millet  cassava foliage  sweet potato vines  bone meal  avocado  and mango. Smallholder farmers who can feed pigs to reach higher ADG  have lower opportunity costs of feeds and/or who effectively bargain with butchers can benefit from semi-intensive pig rearing. Farmers without access to at least some zero-cost feeds and farmers with opportunity costs of feeds exceeding 50 % of the market price will not earn positive returns from semi-intensive pig rearing.A step forward in laccase exploitation: Recombinant production and evaluation of techno-economic feasibility of the process.PubMedPezzella  Cinzia; Giacobelli  Valerio Guido; Lettera  Vincenzo; Olivieri  Giuseppe; Cicatiello  Paola; Sannia  Giovanni; Piscitelli  Alessandra2017-10-10Protein heterologous production offers viable opportunities to tailor laccase properties to specific industrial needs. The high redox potential laccase POXA1b from Pleurotus ostreatus was chosen as case study of marketable enzyme  due to its desirable properties in terms of activity/stability profile  and already assessed applicability. POXA1b was heterologously produced in Pichia pastoris by investigating the effect of inducible and constitutive expression systems on both the yield and the cost of its production. System performances were first assessed in shaken-flasks and then scaled-up in bioreactor. The production level obtained in the inducible system is 42U/mL  while the activity value achieved with the constitutive one is 60U/mL  the highest obtained in constitutive systems so far. The economic feasibility of recombinant laccase production was simulated  describing the case of an Italian small-medium enterprise. Two scenarios were evaluated: Scenario (I) production based on methanol inducible system; Scenario (II) production based on the constitutive system  fed with glycerol. At all the scales the glycerol-based fermentation is more economic than the methanol-based one. The price forecast for rPOXA1b production is 0.34â‚¬kU -1 for glycerol-based process  and is very competitive with the current price of commercial laccase. Copyright Â© 2017 Elsevier B.V. All rights reserved.Determining the Economic Feasibility of Using Produced Water for Agriculture in Colorado Through Life Cycle Cost AnalysesNASA Astrophysics Data System (ADS)Dolan  F.; Blaine  A. C.; Hogue  T. S.2016-12-01To combat the need for new sources of water in Colorado  the current research looks to produced water as a potential source. Produced water  the water produced alongside oil and gas in a well  is currently viewed as a high-volume waste product; however  this water can potentially be used to irrigate food or non-food crops after treatment. Kern County in California has been using produced water for this purpose for over 20 years and a town in Colorado has followed suit. Our research seeks to determine how Wellington  CO overcame economic  legal  social  and technological barriers in order to put produced water to beneficial use. Life cycle cost analyses of produced water in three counties in Colorado are conducted to determine the economic feasibility of using produced water for irrigation on a broad scale. The current study is chosen based on the quality and quantity of the region's produced water as well as the need for new sources of water within the county. The results of this research will help in the transition between viewing produced water as a waste product and using it as a tool to help secure Colorado's water future.Updated (BP3) Technical and Economic Feasibility Study - Electrochemical Membrane for Carbon Dioxide Capture and Power GenerationSciTech ConnectGhezel-Ayagh  HosseinThis topical report summarizes the results of an updated Technical & Economic Feasibility Study (T&EFS) which was conducted in Budget Period 3 of the project to evaluate the performance and cost of the Electrochemical Membrane (ECM)-based CO 2 capture system. The ECM technology is derived from commercially available inorganic membranes; the same used in FuelCell Energyâ€™s commercial fuel cell power plants and sold under the trade name Direct FuelCellÂ® (DFCÂ®). The ECM stacks are utilized in the Combined Electric Power (generation) And Carbon dioxide Separation (CEPACS) systems which can be deployed as add-ons to conventional power plants (Pulverized Coal  CombinedmoreÂ Â» Cycle  etc.) or industrial facilities to simultaneously produce power while capturing >90% of the CO 2 from the flue gas. In this study  an ECM-based CEPACS plant was designed to capture and compress >90% of the CO 2 (for sequestration or beneficial use) from the flue gas of a reference 550 MW (nominal  net AC) Pulverized Coal (PC) Rankine Cycle (Subcritical steam) power plant. ECM performance was updated based on bench scale ECM stack test results. The system process simulations were performed to generate the CEPACS plant performance estimates. The performance assessment included estimation of the parasitic power consumption for CO 2 capture and compression  and the efficiency impact on the PC plant. While the ECM-based CEPACS system for the 550 MW PC plant captures 90% of CO 2 from the flue gas  it generates additional (net AC) power after compensating for the auxiliary power requirements of CO 2 capture and compression. An equipment list  ECM stacks packaging design  and CEPACS plant layout were developed to facilitate the economic analysis. Vendor quotes were also solicited. The economic feasibility study included estimation of CEPACS plant capital cost  cost of electricity (COE) analyses and estimation of cost per ton of CO 2 captured. The incremental COE for the ECM-based CO 2 capture isUpdated (BP3) Technical and Economic Feasibility Study - Electrochemical Membrane for Carbon Dioxide Capture and Power GenerationSciTech ConnectGhezel-Ayagh  HosseinThis topical report summarizes the results of an updated Technical & Economic Feasibility Study (T&EFS) which was conducted in Budget Period 3 of the project to evaluate the performance and cost of the Electrochemical Membrane (ECM)-based CO2 capture system. The ECM technology is derived from commercially available inorganic membranes; the same used in FuelCell Energyâ€™s commercial fuel cell power plants and sold under the trade name Direct FuelCellÂ® (DFCÂ®). The ECM stacks are utilized in the Combined Electric Power (generation) And Carbon dioxide Separation (CEPACS) systems which can be deployed as add-ons to conventional power plants (Pulverized Coal  Combined Cycle moreÂ Â» etc.) or industrial facilities to simultaneously produce power while capturing >90% of the CO2 from the flue gas. In this study  an ECM-based CEPACS plant was designed to capture and compress >90% of the CO2 (for sequestration or beneficial use) from the flue gas of a reference 550 MW (nominal  net AC) Pulverized Coal (PC) Rankine Cycle (Subcritical steam) power plant. ECM performance was updated based on bench scale ECM stack test results. The system process simulations were performed to generate the CEPACS plant performance estimates. The performance assessment included estimation of the parasitic power consumption for CO2 capture and compression  and the efficiency impact on the PC plant. While the ECM-based CEPACS system for the 550 MW PC plant captures 90% of CO2 from the flue gas  it generates additional (net AC) power after compensating for the auxiliary power requirements of CO2 capture and compression. An equipment list  ECM stacks packaging design  and CEPACS plant layout were developed to facilitate the economic analysis. Vendor quotes were also solicited. The economic feasibility study included estimation of CEPACS plant capital cost  cost of electricity (COE) analyses and estimation of cost per ton of CO2 captured. The incremental COE for the ECM-based CO2 capture is expectedPilot test of Pickliq{reg_sign} process to determine energy and environmental benefits & economic feasibilitySciTech ConnectOlsen  D.R.Green Technology Group (GTG) was awarded Grant No. DE-FG01-96EE 15657 in the amount of $99 904 for a project to advance GTG`s Pickliq{reg_sign} Process in the Copper and Steel Industries. The use of the Pickliq{reg_sign} Process can significantly reduce the production of waste acids containing metal salts. The Pickliq{reg_sign} Process can save energy and eliminate hazardous waste in a typical copper rod or wire mill or a typical steel wire mill. The objective of this pilot project was to determine the magnitude of the economic  energy and environmental benefits of the Pickliq{reg_sign} Process in two applications within the metal processing industry.moreÂ Â» The effectiveness of the process has already been demonstrated at facilities cleaning iron and steel with sulfuric acid. 9207 companies are reported to use sulfuric and hydrochloric acid in the USA. The USEPA TRI statistics of acid not recycled in the US is 2.4 x 10{sup 9} lbs (net) for Hydrochloric Acid and 2.0 x 10{sup 9} lbs (net) for Sulfuric Acid. The energy cost of not reclaiming acid is 10.7 x 10{sup 6} BTU/ton for Hydrochloric Acid and 21.6 x 10{sup 6} BTU/Ton for Sulfuric Acid. This means that there is a very large market for the application of the Pickliq{reg_sign} Process and the widespread use of the process will bring significant world wide savings of energy to the environment.Â«Â lessDefining Feasibility and Pilot Studies in Preparation for Randomised Controlled Trials: Development of a Conceptual FrameworkPubMed CentralEldridge  Sandra M.; Lancaster  Gillian A.; Campbell  Michael J.; Thabane  Lehana; Hopewell  Sally; Coleman  Claire L.; Bond  Christine M.2016-01-01We describe a framework for defining pilot and feasibility studies focusing on studies conducted in preparation for a randomised controlled trial. To develop the framework  we undertook a Delphi survey; ran an open meeting at a trial methodology conference; conducted a review of definitions outside the health research context; consulted experts at an international consensus meeting; and reviewed 27 empirical pilot or feasibility studies. We initially adopted mutually exclusive definitions of pilot and feasibility studies. However  some Delphi survey respondents and the majority of open meeting attendees disagreed with the idea of mutually exclusive definitions. Their viewpoint was supported by definitions outside the health research context  the use of the terms â€˜pilotâ€™ and â€˜feasibilityâ€™ in the literature  and participants at the international consensus meeting. In our framework  pilot studies are a subset of feasibility studies  rather than the two being mutually exclusive. A feasibility study asks whether something can be done  should we proceed with it  and if so  how. A pilot study asks the same questions but also has a specific design feature: in a pilot study a future study  or part of a future study  is conducted on a smaller scale. We suggest that to facilitate their identification  these studies should be clearly identified using the terms â€˜feasibilityâ€™ or â€˜pilotâ€™ as appropriate. This should include feasibility studies that are largely qualitative; we found these difficult to identify in electronic searches because researchers rarely used the term â€˜feasibilityâ€™ in the title or abstract of such studies. Investigators should also report appropriate objectives and methods related to feasibility; and give clear confirmation that their study is in preparation for a future randomised controlled trial designed to assess the effect of an intervention. PMID:26978655Economic Effects of Increased Control Zone Sizes in Conflict ResolutionNASA Technical Reports Server (NTRS)Datta  Koushik1998-01-01A methodology for estimating the economic effects of different control zone sizes used in conflict resolutions between aircraft is presented in this paper. The methodology is based on estimating the difference in flight times of aircraft with and without the control zone  and converting the difference into a direct operating cost. Using this methodology the effects of increased lateral and vertical control zone sizes are evaluated.EEG Neurofeedback for ADHD: Double-Blind Sham-Controlled Randomized Pilot Feasibility TrialERIC Educational Resources Information CenterArnold  L. Eugene; Lofthouse  Nicholas; Hersch  Sarah; Pan  Xueliang; Hurt  Elizabeth; Bates  Bethany; Kassouf  Kathleen; Moone  Stacey; Grantier  Cara2013-01-01Objective: Preparing for a definitive randomized clinical trial (RCT) of neurofeedback (NF) for ADHD  this pilot trial explored feasibility of a double-blind  sham-controlled design and adherence/palatability/relative effect of two versus three treatments/week. Method: Unmedicated 6- to 12-year-olds with ""Diagnostic and Statistical Manual ofâ€¦Integrating CHWs as part of the team leading diabetes group visits: A randomized controlled feasibility studyUSDA-ARS?s Scientific Manuscript databaseThe purpose of the study was to evaluate the feasibility of integrating Community Health Workers (CHWs) as part of the team leading diabetes group visits. This was a randomized controlled study that integrated CHWs as part of the team leading diabetes group visits for low-income Hispanic adults (n=5...The economic feasibility of seawater desalination over the global scale: assessment of the production cost development and national water price until 2050NASA Astrophysics Data System (ADS)Gao  L.; Yoshikawa  S.; Iseri  Y.; Kanae  S.2016-12-01As many countries are suffering water scarcity due to the climate change and human activities  seawater desalination using reverse osmosis (SWRO) has shown to be a progressively promising countermeasure to satisfy the growing water demand. Therefore  the economic feasibility assessment of SWRO will be beneficial for the potential investors and policy-makers of government. In present study  it have proposed a systematic method to evaluate the economic feasibility of implementing SWRO in 140 counties and further estimated the potential future diffusion of SWRO over global scale by 2050. To the purpose  two models has been separately developed to simulate the production cost of SWRO and conventional water price  which are identified as the critical economic factors for feasibility evaluation of SWRO. These two models were firstly applied to historical validation in which proven to be able to well simulate both these two economic factors  and then were applied globally for future simulation over the period of 2015-2050 under three socioeconomic scenarios  i.e. SSP (Shared Socioeconomic Pathways) 1-3. Basin on the estimated production cost and water price  the economic feasibility of adopting SWRO coupling with its future potentialities were carefully evaluated. As a result  it indicated that SWRO was expected to be cost-effectively adopted in more countries by 2050  especially in these developing countries. The significant potential diffusion of SWRO in countries was mainly attributed to both the diminishing production cost and the increasing conventional water price as a result of income growth globally in three SSPs scenarios.Wordless intervention for people with epilepsy and learning disabilities (WIELD): a randomised controlled feasibility trialPubMed CentralMengoni  Silvana E; Gates  Bob; Parkes  Georgina; Wellsted  David; Barton  Garry; Ring  Howard; Khoo  Mary Ellen; Monji-Patel  Deela; Friedli  Karin; Zia  Asif; Irvine  Lisa; Durand  Marie-Anne2016-01-01Objective To investigate the feasibility of a full-scale randomised controlled trial of a picture booklet to improve quality of life for people with epilepsy and learning disabilities. Trial design A randomised controlled feasibility trial. Randomisation was not blinded and was conducted using a centralised secure database and a blocked 1:1 allocation ratio. Setting Epilepsy clinics in 1 English National Health Service (NHS) Trust. Participants Patients with learning disabilities and epilepsy who had: a seizure within the past 12â€…months  meaningful communication and a carer with sufficient proficiency in English. Intervention Participants in the intervention group used a picture booklet with a trained researcher  and a carer present. These participants kept the booklet  and were asked to use it at least twice more over 20â€…weeks. The control group received treatment as usual  and were provided with a booklet at the end of the study. Outcome measures 7 feasibility criteria were used relating to recruitment  data collection  attrition  potential effect on epilepsy-related quality of life (Epilepsy and Learning Disabilities Quality of Life Scale  ELDQOL) at 4-week  12-week and 20-week follow-ups  feasibility of methodology  acceptability of the intervention and potential to calculate cost-effectiveness. Outcome The recruitment rate of eligible patients was 34% and the target of 40 participants was reached. There was minimal missing data and attrition. An intention-to-treat analysis was performed; data from the outcome measures suggest a benefit from the intervention on the ELDQOL behaviour and mood subscales at 4 and 20â€…weeks follow-up. The booklet and study methods were positively received  and no adverse events were reported. There was a positive indication of the potential for a cost-effectiveness analysis. Conclusions All feasibility criteria were fully or partially met  therefore confirming feasibility of a definitive trial. Trial registration number ISRCTNOn the feasibility of closed-loop control of intra-aortic balloon pumpingNASA Technical Reports Server (NTRS)Clark  J. W.  Jr.; Bourland  H. M.; Kane  G. R.1973-01-01A closed-loop control scheme for the control of intra-aortic balloon pumping has been developed and tested in dog experiments. A performance index reflecting the general objectives of balloon-assist pumping is developed and a modified steepest ascent control algorithm is utilized for the selection of a proper operating point for the balloon during its pumping cycle. This paper attempts to indicate the feasibility of closed-loop control of balloon pumping  and particularly its flexibility in achieving both diastolic augmentation of mean aortic pressure and control of the level of end-diastolic pressure (EDP) an important factor in reducing heart work.An Economic Analysis of USDA Erosion Control Programs: A New Perspective. Agricultural Economic Report No. 560.ERIC Educational Resources Information CenterStrohbehn  Roger  Ed.A study analyzed the total (public and private) economic costs and benefits of three U.S. Department of Agriculture erosion control programs. These were the Conservation Technical Assistance Program  Great Plains Conservation Program  and Agricultural Conservation Program. Significant efforts at funding for current programs were directed toâ€¦Facilitating return to work through early specialist health-based interventions (FRESH): protocol for a feasibility randomised controlled trial.PubMedRadford  Kathryn A; Phillips  Julie; Jones  Trevor; Gibson  Ali; Sutton  Chris; Watkins  Caroline; Sach  Tracey; Duley  Lelia; Walker  Marion; Drummond  Avril; Hoffman  Karen; O'Connor  Rory; Forshaw  Denise; Shakespeare  David2015-01-01Over one million people sustain traumatic brain injury each year in the UK and more than 10Â % of these are moderate or severe injuries  resulting in cognitive and psychological problems that affect the ability to work. Returning to work is a primary rehabilitation goal but fewer than half of traumatic brain injury survivors achieve this. Work is a recognised health service outcome  yet UK service provision varies widely and there is little robust evidence to inform rehabilitation practice. A single-centre cohort comparison suggested better work outcomes may be achieved through early occupational therapy targeted at job retention. This study aims to determine whether this intervention can be delivered in three new trauma centres and to conduct a feasibility  randomised controlled trial to determine whether its effects and cost effectiveness can be measured to inform a definitive trial. Mixed methods study  including feasibility randomised controlled trial  embedded qualitative studies and feasibility economic evaluation will recruit 102 people with traumatic brain injury and their nominated carers from three English UK National Health Service (NHS) trauma centres. Participants will be randomised to receive either usual NHS rehabilitation or usual rehabilitation plus early specialist traumatic brain injury vocational rehabilitation delivered by an occupational therapist. The primary objective is to assess the feasibility of conducting a definitive trial; secondary objectives include measurement of protocol integrity (inclusion/exclusion criteria  intervention adherence  reasons for non-adherence) recruitment rate  the proportion of eligible patients recruited  reasons for non-recruitment  spectrum of TBI severity  proportion of and reasons for loss to follow-up  completeness of data collection  gains in face-to-face V s postal data collection and the most appropriate methods of measuring primary outcomes (return to work  retention) to determine the sample size for aApplication of Statistical Quality Control Techniques to Detonator Fabrication: Feasibility StudySciTech ConnectJones  J. Frank1971-05-20A feasibility study was performed on the use of process control techniques which might reduce the need for a duplicate inspection by production inspection and quality control inspection. Two active detonator fabrication programs were selected for the study. Inspection areas accounting for the greatest percentage of total inspection costs were selected by applying ""Pareto's Principle of Maldistribution."" Data from these areas were then gathered and analyzed by a process capabiltiy study.Social Stories in mainstream schools for children with autism spectrum disorder: a feasibility randomised controlled trial.PubMedMarshall  David; Wright  Barry; Allgar  Victoria; Adamson  Joy; Williams  Christine; Ainsworth  Hannah; Cook  Liz; Varley  Danielle; Hackney  Lisa; Dempster  Paul; Ali  Shehzad; Trepel  Dominic; Collingridge Moore  Danielle; Littlewood  Elizabeth; McMillan  Dean2016-08-11To assess the feasibility of recruitment  retention  outcome measures and intervention training/delivery among teachers  parents and children. To calculate a sample size estimation for full trial. A single-centre  unblinded  cluster feasibility randomised controlled trial examining Social Stories delivered within a school environment compared with an attentional control. 37 primary schools in York  UK. 50 participants were recruited and a cluster randomisation approach by school was examined. Participants were randomised into the treatment group (n=23) or a waiting list control group (n=27). Acceptability and feasibility of the trial  intervention and of measurements required to assess outcomes in a definitive trial. An assessment of the questionnaire completion rates indicated teachers would be most appropriate to complete the primary outcome measure. 2 outcome measures: the Social Responsiveness Scale (SRS)-2 and a goal-based measure showed both the highest levels of completion rates (above 80%) at the primary follow-up point (6â€…weeks postintervention) and captured relevant social and behaviour outcomes. Power calculations were based on these 2 outcome measures leading to a total proposed sample size of 180 participant groups. Results suggest that a future trial would be feasible to conduct and could inform the policy and practice of using Social Stories in mainstream schools. ISRCTN96286707; Results. Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://www.bmj.com/company/products-services/rights-and-licensing/DETERMINE THE FEASIBILITY OF DEVELOPING A MODEL DESCRIBING THE FLOW OF OCCUPATIONAL AND ECONOMIC INFORMATION INTO THE SECONDARY VOCATIONAL-TECHNICAL SCHOOL. FINAL REPORT.ERIC Educational Resources Information CenterSILVERN  LEONARD C.THE MAJOR OBJECTIVES OF THIS FEASIBILITY STUDY WERE (1) TO IDENTIFY INFORMATION SOURCES WHICH FURNISH OCCUPATIONAL AND ECONOMIC DATA TO SECONDARY SCHOOLS  (2) TO SELECT THOSE SOURCES WHICH ARE BELIEVED TO HAVE A MEASURABLE INFLUENCE ON THE VOCATIONAL CURRICULUM  AND (3) TO CATEGORIZE  RELATE  AND COMBINE OR RESTRUCTURE THOSE SOURCES INTO Aâ€¦Wordless intervention for epilepsy in learning disabilities (WIELD): study protocol for a randomized controlled feasibility trial.PubMedDurand  Marie-Anne; Gates  Bob; Parkes  Georgina; Zia  Asif; Friedli  Karin; Barton  Garry; Ring  Howard; Oostendorp  Linda; Wellsted  David2014-11-20Epilepsy is the most common neurological problem that affects people with learning disabilities. The high seizure frequency  resistance to treatments  associated skills deficit and co-morbidities make the management of epilepsy particularly challenging for people with learning disabilities. The Books Beyond Words booklet for epilepsy uses images to help people with learning disabilities manage their condition and improve quality of life. Our aim is to conduct a randomized controlled feasibility trial exploring key methodological  design and acceptability issues  in order to subsequently undertake a large-scale randomized controlled trial of the Books Beyond Words booklet for epilepsy. We will use a two-arm  single-centre randomized controlled feasibility design  over a 20-month period  across five epilepsy clinics in Hertfordshire  United Kingdom. We will recruit 40 eligible adults with learning disabilities and a confirmed diagnosis of epilepsy and will randomize them to use either the Books Beyond Words booklet plus usual care (intervention group) or to receive routine information and services (control group). We will collect quantitative data about the number of eligible participants  number of recruited participants  demographic data  discontinuation rates  variability of the primary outcome measure (quality of life: Epilepsy and Learning Disabilities Quality of Life scale)  seizure severity  seizure control  intervention's patterns of use  use of other epilepsy-related information  resource use and the EQ-5D-5L health questionnaire. We will also gather qualitative data about the feasibility and acceptability of the study procedures and the Books Beyond Words booklet. Ethical approval for this study was granted on 28 April 2014  by the Wales Research Ethics Committee 5. Recruitment began on 1 July 2014. The outcomes of this feasibility study will be used to inform the design and methodology of a definitive study  adequately powered to determine the impact ofDynamic adjustments of cognitive control during economic decision making.PubMedSoutschek  Alexander; Schubert  Torsten2014-10-01Decision making in the Ultimatum game requires the resolution of conflicts between economic self-interest and fairness intuitions. Since cognitive control processes play an important role in conflict resolution  the present study examined how control processes that are triggered by conflicts between fairness and self-interest in unfair offers affect subsequent decisions in the Ultimatum game. Our results revealed that more unfair offers were accepted following previously unfair  compared to previously fair offers. Interestingly  the magnitude of this conflict adaptation effect correlated with the individual subjects' focus on economic self-interest. We concluded that conflicts between fairness and self-interest trigger cognitive control processes  which reinforce the focus on the current task goal. Copyright Â© 2014 Elsevier B.V. All rights reserved.Economic design of control charts considering process shift distributionsNASA Astrophysics Data System (ADS)Vommi  Vijayababu; Kasarapu  Rukmini V.2014-09-01Process shift is an important input parameter in the economic design of control charts. Earlier control chart designs considered constant shifts to occur in the mean of the process for a given assignable cause. This assumption has been criticized by many researchers since it may not be realistic to produce a constant shift whenever an assignable cause occurs. To overcome this difficulty  in the present work  a distribution for the shift parameter has been considered instead of a single value for a given assignable cause. Duncan's economic design model for chart has been extended to incorporate the distribution for the process shift parameter. It is proposed to minimize total expected loss-cost to obtain the control chart parameters. Further  three types of process shifts namely  positively skewed  uniform and negatively skewed distributions are considered and the situations where it is appropriate to use the suggested methodology are recommended.Art participation for psychosocial wellbeing during stroke rehabilitation: a feasibility randomised controlled trial.PubMedMorris  Jacqui H; Kelly  Chris; Joice  Sara; Kroll  Thilo; Mead  Gillian; Donnan  Peter; Toma  Madalina; Williams  Brian2017-08-30To examine the feasibility of undertaking a pragmatic single-blind randomised controlled trial (RCT) of a visual arts participation programme to evaluate effects on survivor wellbeing within stroke rehabilitation. Stroke survivors receiving in-patient rehabilitation were randomised to receive eight art participation sessions (nâ€‰=â€‰41) or usual care (nâ€‰=â€‰40). Recruitment  retention  preference for art participation and change in selected outcomes were evaluated at end of intervention outcome assessment and three-month follow-up. Of 315 potentially eligible participants 81 (29%) were recruited. 88% (nâ€‰=â€‰71) completed outcome and 77% (nâ€‰=â€‰62) follow-up assessments. Of eight intervention group non-completers  six had no preference for art participation. Outcome completion varied between 97% and 77%. Running groups was difficult because of randomisation timing. Effectiveness cannot be determined from this feasibility study but effects sizes suggested art participation may benefit emotional wellbeing  measured on the positive and negative affect schedule  and self-efficacy for Art (dâ€‰=â€‰0.24-0.42). Undertaking a RCT of art participation within stroke rehabilitation was feasible. Art participation may enhance self-efficacy and positively influence emotional wellbeing. These should be outcomes in a future definitive trial. A cluster RCT would ensure art groups could be reliably convened. Fewer measures  and better retention strategies are required. Implications for Rehabilitation This feasibility randomised controlled trial (RCT) showed that recruiting and retaining stroke survivors in an RCT of a visual arts participation intervention within stroke rehabilitation was feasible. Preference to participate in art activities may influence recruitment and drop-out rates  and should be addressed and evaluated fully. Art participation as part of rehabilitation may improve some aspects of post-stroke wellbeing  including positive affect and self-efficacy for artThe effect of targeted treatment on people with patellofemoral pain: a pragmatic  randomised controlled feasibility study.PubMedDrew  Benjamin T; Conaghan  Philip G; Smith  Toby O; Selfe  James; Redmond  Anthony C2017-08-04Targeted treatment  matched according to specific clinical criteria e.g. hip muscle weakness  may result in better outcomes for people with patellofemoral pain (PFP). However  to ensure the success of future trials  a number of questions on the feasibility of a targeted treatment need clarification. The aim of the study was to explore the feasibility of matched treatment (MT) compared to usual care (UC) management for a subgroup of people with PFP determined to have hip weakness and to explore the mechanism of effect for hip strengthening. In a pragmatic  randomised controlled feasibility study  24 participants with PFP (58% female; mean age 29Â years) were randomly allocated to receive either MT aimed specifically at hip strengthening  or UC over an eight-week period. The primary outcomes were feasibility outcomes  which included rates of adherence  attrition  eligibility  missing data and treatment efficacy. Secondary outcomes focused on the mechanistic outcomes of the intervention  which included hip kinematics. Conversion to consent (100%)  missing data (0%)  attrition rate (8%) and adherence to both treatment and appointments (>90%) were deemed successful endpoints. The analysis of treatment efficacy showed that the MT group reported a greater improvement for the Global Rating of Change Scale (62% vs. 9%) and the Anterior Knee Pain Scale (-5.23 vs. 1.18) but no between-group differences for either average or worst pain. Mechanistic outcomes showed a greatest reduction in peak hip internal rotation angle for the MT group (13.1% vs. -2.7%). This feasibility study indicates that a definitive randomised controlled trial investigating a targeted treatment approach is achievable. Findings suggest the mechanism of effect of hip strengthening may be to influence kinematic changes in hip function in the transverse plane. This study was registered retrospectively. ISRCTN74560952 . Registration date: 2017-02-06.A survey of methods of feasible directions for the solution of optimal control problemsNASA Technical Reports Server (NTRS)Polak  E.1972-01-01Three methods of feasible directions for optimal control are reviewed. These methods are an extension of the Frank-Wolfe method  a dual method devised by Pironneau and Polack  and a Zontendijk method. The categories of continuous optimal control problems are shown as: (1) fixed time problems with fixed initial state  free terminal state  and simple constraints on the control; (2) fixed time problems with inequality constraints on both the initial and the terminal state and no control constraints; (3) free time problems with inequality constraints on the initial and terminal states and simple constraints on the control; and (4) fixed time problems with inequality state space contraints and constraints on the control. The nonlinear programming algorithms are derived for each of the methods in its associated category.Wordless intervention for people with epilepsy and learning disabilities (WIELD): a randomised controlled feasibility trial.PubMedMengoni  Silvana E; Gates  Bob; Parkes  Georgina; Wellsted  David; Barton  Garry; Ring  Howard; Khoo  Mary Ellen; Monji-Patel  Deela; Friedli  Karin; Zia  Asif; Irvine  Lisa; Durand  Marie-Anne2016-11-10To investigate the feasibility of a full-scale randomised controlled trial of a picture booklet to improve quality of life for people with epilepsy and learning disabilities. A randomised controlled feasibility trial. Randomisation was not blinded and was conducted using a centralised secure database and a blocked 1:1 allocation ratio. Epilepsy clinics in 1 English National Health Service (NHS) Trust. Patients with learning disabilities and epilepsy who had: a seizure within the past 12â€…months  meaningful communication and a carer with sufficient proficiency in English. Participants in the intervention group used a picture booklet with a trained researcher  and a carer present. These participants kept the booklet  and were asked to use it at least twice more over 20â€…weeks. The control group received treatment as usual  and were provided with a booklet at the end of the study. 7 feasibility criteria were used relating to recruitment  data collection  attrition  potential effect on epilepsy-related quality of life (Epilepsy and Learning Disabilities Quality of Life Scale  ELDQOL) at 4-week  12-week and 20-week follow-ups  feasibility of methodology  acceptability of the intervention and potential to calculate cost-effectiveness. The recruitment rate of eligible patients was 34% and the target of 40 participants was reached. There was minimal missing data and attrition. An intention-to-treat analysis was performed; data from the outcome measures suggest a benefit from the intervention on the ELDQOL behaviour and mood subscales at 4 and 20â€…weeks follow-up. The booklet and study methods were positively received  and no adverse events were reported. There was a positive indication of the potential for a cost-effectiveness analysis. All feasibility criteria were fully or partially met  therefore confirming feasibility of a definitive trial. ISRCTN80067039. Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licenceRemote Manipulator System (RMS)-based Controls-Structures Interaction (CSI) flight experiment feasibility studyNASA Technical Reports Server (NTRS)Demeo  Martha E.1990-01-01The feasibility of an experiment which will provide an on-orbit validation of Controls-Structures Interaction (CSI) technology  was investigated. The experiment will demonstrate the on-orbit characterization and flexible-body control of large flexible structure dynamics using the shuttle Remote Manipulator System (RMS) with an attached payload as a test article. By utilizing existing hardware as well as establishing integration  operation and safety algorithms  techniques and procedures  the experiment will minimize the costs and risks of implementing a flight experiment. The experiment will also offer spin-off enhancement to both the Shuttle RMS (SRMS) and the Space Station RMS (SSRMS).Internal voltage control of hydrogen-oxygen fuel cells: Feasibility studyNASA Technical Reports Server (NTRS)Prokopius  P. R.1975-01-01An experimental study was conducted to assess the feasibility of internal voltage regulation of fuel cell systems. Two methods were tested. In one  reactant partial pressure was used as the voltage control parameter and in the other reactant total pressure was used for control. Both techniques were breadboarded and tested on a single alkaline-electrolyte fuel cell. Both methods were found to be possible forms of regulation  however  of the two the total pressure technique would be more efficient  simpler to apply and would provide better transient characteristics.Foot-controlled robotic-enabled endoscope holder for endoscopic sinus surgery: A cadaveric feasibility study.PubMedChan  Jason Y K; Leung  Iris; Navarro-Alarcon  David; Lin  Weiyang; Li  Peng; Lee  Dennis L Y; Liu  Yun-hui; Tong  Michael C F2016-03-01To evaluate the feasibility of a unique prototype foot-controlled robotic-enabled endoscope holder (FREE) in functional endoscopic sinus surgery. Cadaveric study. Using human cadavers  we investigated the feasibility  advantages  and disadvantages of the robotic endoscope holder in performing endoscopic sinus surgery with two hands in five cadaver heads  mimicking a single nostril three-handed technique. The FREE robot is relatively easy to use. Setup was quick  taking less than 3 minutes from docking the robot at the head of the bed to visualizing the middle meatus. The unit is also relatively small  takes up little space  and currently has four degrees of freedom. The learning curve for using the foot control was short. The use of both hands was not hindered by the presence of the endoscope in the nasal cavity. The tremor filtration also aided in the smooth movement of the endoscope  with minimal collisions. The FREE endoscope holder in an ex-vivo cadaver test corroborated the feasibility of the robotic prototype  which allows for a two-handed approach to surgery equal to a single nostril three-handed technique without the holder that may reduce operating time. Further studies will be needed to evaluate its safety profile and use in other areas of endoscopic surgery. NA. Laryngoscope  126:566-569  2016. Â© 2015 The American Laryngological  Rhinological and Otological Society  Inc.A Techno-Economic Analysis of Emission Controls on Hydrocarbon Biofuel ProductionSciTech ConnectBhatt  Arpit; Zhang  Yimin; Davis  RyanBiofuels have the potential to reduce our dependency on petroleum-derived transportation fuels and decrease greenhouse gas (GHG) emissions. Although the overall GHG emissions from biofuels are expected to be lower when compared to those of petroleum fuels  the process of converting biomass feedstocks into biofuels emits various air pollutants  which may be subject to federal air quality regulation or emission limits. While prior research has evaluated the technical and economic feasibility of biofuel technologies  gaps still exist in understanding the regulatory issues associated with the biorefineries and their economic implications on biofuel production costs (referred to as minimum fuel sellingmoreÂ Â» price (MFSP) in this study). The aim of our research is to evaluate the economic impact of implementing emission reduction technologies at biorefineries and estimate the cost effectiveness of two primary control technologies that may be required for air permitting purposes. We analyze a lignocellulosic sugars-to-hydrocarbon biofuel production pathway developed by the National Renewable Energy Laboratory (NREL) and implement air emission controls in Aspen Plus to evaluate how they affect the MFSP. Results from this analysis can help inform decisions about biorefinery siting and sizing  as well as mitigate the risks associated with air permitting.Â«Â lessThe feasibility and acceptability of conducting a trial of specialist medical care and the Lightning Process in children with chronic fatigue syndrome: feasibility randomized controlled trial (SMILE study)PubMed Central2013-01-01Background Chronic fatigue syndrome (CFS) or myalgic encephalomyelitis (ME) is relatively common in children with limited evidence for treatment. The Phil Parker Lightning Process (LP) is a trademarked intervention  which >250 children use annually. There are no reported studies investigating the effectiveness or possible side effects of LP. Methods The trial population was drawn from the Bath and Bristol NHS specialist paediatric CFS or ME service. The study was designed as a pilot randomized trial with children (aged 12 to 18Â years) comparing specialist medical care with specialist medical care plus the Lightning Process. Integrated qualitative methodology was used to explore the feasibility and acceptability of the recruitment  randomization and interventions. Results A total of 56 children were recruited from 156 eligible children (1 October 2010 to 16 June 2012). Recruitment  randomization and both interventions were feasible and acceptable. Participants suggested changes to improve feasibility and acceptability and we incorporated the following in the trial protocol: stopped collecting 6-week outcomes; introduced a second reminder letter; used phone calls to collect primary outcomes from nonresponders; informed participants about different approaches of each intervention and changed our recommendation for the primary outcome for the full study from school attendance to disability (SF-36 physical function subscale) and fatigue (Chalder Fatigue Scale). Conclusions Conducting randomized controlled trials (RCTs) to investigate an alternative treatment such as LP is feasible and acceptable for children with CFS or ME. Feasibility studies that incorporate qualitative methodology enable changes to be made to trial protocols to improve acceptability to participants. This is likely to improve recruitment rate and trial retention. Trial registration Feasibility study first randomization: 29 September 2010. Trial registration: Current Controlled Trials ISRCTN81456207Conceptual process design and techno-economic assessment of ex situ catalytic fast pyrolysis of biomass: A fixed bed reactor implementation scenario for future feasibilitySciTech ConnectDutta  Abhijit; Schaidle  Joshua A.; Humbird  DavidEx situ catalytic fast pyrolysis of biomass is a promising route for the production of fungible liquid biofuels. There is significant ongoing research on the design and development of catalysts for this process. However  there are a limited number of studies investigating process configurations and their effects on biorefinery economics. Herein we present a conceptual process design with techno-economic assessment; it includes the production of upgraded bio-oil via fixed bed ex situ catalytic fast pyrolysis followed by final hydroprocessing to hydrocarbon fuel blendstocks. This study builds upon previous work using fluidized bed systems  as detailed in a recent design reportmoreÂ Â» led by the National Renewable Energy Laboratory (NREL/TP-5100-62455); overall yields are assumed to be similar  and are based on enabling future feasibility. Assuming similar yields provides a basis for easy comparison and for studying the impacts of areas of focus in this study  namely  fixed bed reactor configurations and their catalyst development requirements  and the impacts of an inline hot gas filter. A comparison with the fluidized bed system shows that there is potential for higher capital costs and lower catalyst costs in the fixed bed system  leading to comparable overall costs. The key catalyst requirement is to enable the effective transformation of highly oxygenated biomass into hydrocarbons products with properties suitable for blending into current fuels. Potential catalyst materials are discussed  along with their suitability for deoxygenation  hydrogenation and Câ€“C coupling chemistry. This chemistry is necessary during pyrolysis vapor upgrading for improved bio-oil quality  which enables efficient downstream hydroprocessing; Câ€“C coupling helps increase the proportion of diesel/jet fuel range product. One potential benefit of fixed bed upgrading over fluidized bed upgrading is catalyst flexibility  providing greater control over chemistry and product compositionConceptual process design and techno-economic assessment of ex situ catalytic fast pyrolysis of biomass: A fixed bed reactor implementation scenario for future feasibilityDOE PAGESDutta  Abhijit; Schaidle  Joshua A.; Humbird  David; ...2015-10-06Ex situ catalytic fast pyrolysis of biomass is a promising route for the production of fungible liquid biofuels. There is significant ongoing research on the design and development of catalysts for this process. However  there are a limited number of studies investigating process configurations and their effects on biorefinery economics. Herein we present a conceptual process design with techno-economic assessment; it includes the production of upgraded bio-oil via fixed bed ex situ catalytic fast pyrolysis followed by final hydroprocessing to hydrocarbon fuel blendstocks. This study builds upon previous work using fluidized bed systems  as detailed in a recent design reportmoreÂ Â» led by the National Renewable Energy Laboratory (NREL/TP-5100-62455); overall yields are assumed to be similar  and are based on enabling future feasibility. Assuming similar yields provides a basis for easy comparison and for studying the impacts of areas of focus in this study  namely  fixed bed reactor configurations and their catalyst development requirements  and the impacts of an inline hot gas filter. A comparison with the fluidized bed system shows that there is potential for higher capital costs and lower catalyst costs in the fixed bed system  leading to comparable overall costs. The key catalyst requirement is to enable the effective transformation of highly oxygenated biomass into hydrocarbons products with properties suitable for blending into current fuels. Potential catalyst materials are discussed  along with their suitability for deoxygenation  hydrogenation and Câ€“C coupling chemistry. This chemistry is necessary during pyrolysis vapor upgrading for improved bio-oil quality  which enables efficient downstream hydroprocessing; Câ€“C coupling helps increase the proportion of diesel/jet fuel range product. One potential benefit of fixed bed upgrading over fluidized bed upgrading is catalyst flexibility  providing greater control over chemistry and product compositionModeling of Control Costs  Emissions  and Control Retrofits for Cost Effectiveness and Feasibility AnalysesEPA Pesticide FactsheetsLearn about EPAâ€™s use of the Integrated Planning Model (IPM) to develop estimates of SO2 and NOx emission control costs  projections of futureemissions  and projections of capacity of future control retrofits  assuming controls on EGUs.Integrating CHWs as Part of the Team Leading Diabetes Group Visits: A Randomized Controlled Feasibility Study.PubMedVaughan  Elizabeth M; Johnston  Craig A; Cardenas  Victor J; Moreno  Jennette P; Foreyt  John P2017-12-01Purpose The purpose of the study was to evaluate the feasibility of integrating Community Health Workers (CHWs) as part of the team leading diabetes group visits. Methods This was a randomized controlled study that integrated CHWs as part of the team leading diabetes group visits for low-income Hispanic adults (n = 50). Group visits met for 3 hours each month for a 6-month duration. Main measures included baseline and 6-month clinical outcomes (ie  A1C  lipids)  concordance with 8 standard of care guidelines (ie  screens for cervical  breast  and colon cancer) from the US Preventive Task Force and American Diabetes Association  and participant acceptability. Results Compared to control participants  the intervention group resulted in significantly better clinical outcomes or guideline concordance for the following areas: target A1C levels  retinal eye exams  diabetes foot exams  mammograms  and urine microalbumin. Significantly more individuals in the control group gained weight  whereas a greater number of participants in the intervention group lost weight. Intervention participants found the group visits highly acceptable. Conclusions Integrating CHWs as part a comprehensive diabetes group visit program is a feasible and effective system-level intervention to improve glycemic control and achieve guideline concordance.[Comparison Analysis of Economic and Engineering Control of Industrial VOCs].PubMedWang  Yu-fei; Liu  Chang-xin; Cheng  Jie; Hao  Zheng-ping; Wang  Zheng2015-04-01Volatile organic compounds (VOCs) pollutant has become China's major air pollutant in key urban areas like sulfur dioxide  nitrogen oxides and particulate matter. It is mainly produced from industry sectors  and engineering control is one of the most important reduction measures. During the 12th Five-Year Plan  China decides to invest 40 billion RMB to build pollution control projects in key industry sectors with annual emission reduction of 605 000 t x a(-1). It shows that China attaches a great importance to emission reduction by engineering projects and highlights the awareness of engineering reduction technologies. In this paper  a macroeconomic model  namely computable general equilibrium model  (CGE model) was employed to simulate engineering control and economic control (imposing environmental tax). We aim to compare the pros and cons of the two reduction policies. Considering the economic loss of the whole country  the environmental tax has more impacts on the economy system than engineering reduction measures. We suggest that the central government provides 7 500 RMB x t(-1) as subsidy for enterprises in industry sectors to encourage engineering reduction.The economics of alcohol abuse and alcohol-control policies.PubMedCook  Philip J; Moore  Michael J2002-01-01Economic research has contributed to the evaluation of alcohol policy through empirical analysis of the effects of alcohol-control measures on alcohol consumption and its consequences. It has also provided an accounting framework for defining and comparing costs and benefits of alcohol consumption and related policy interventions  including excise taxes. The most important finding from the economics literature is that consumers tend to drink less ethanol  and have fewer alcohol-related problems  when alcoholic beverage prices are increased or alcohol availability is restricted. That set of findings is relevant for policy purposes because alcohol abuse imposes large ""external"" costs on others. Important challenges remain  including developing a better understanding of the effects of drinking on labor-market productivity.A family intervention to reduce delirium in hospitalised ICU patients: A feasibility randomised controlled trial.PubMedMitchell  Marion L; Kean  Susanne; Rattray  Janice E; Hull  Alastair M; Davis  Chelsea; Murfield  Jenny E; Aitken  Leanne M2017-06-01Family members could play an important role in preventing and reducing the development of delirium in Intensive Care Units (ICU) patients. This study sought to assess the feasibility of design and recruitment  and acceptability for family members and nurses of a family delivered intervention to reduce delirium in ICU patients. A single centre randomised controlled trial in an Australian medical/surgical ICU was conducted. Sixty-one family members were randomised (29 in intervention and 32 in non-intervention group). Following instructions  the intervention comprised the family members providing orientation or memory clues (family photographs  orientation to surroundings) to their relative each day. In addition  family members conducted sensory checks (vision and hearing with glasses and hearing aids); and therapeutic or cognitive stimulation (discussing family life  reminiscing) daily. Eleven ICU nurses were interviewed to gain insight into the feasibility and acceptability of implementing the intervention from their perspective. Recruitment rate was 28% of eligible patients (recruited n=90  attrition n=1). Following instruction by the research nurse the family member delivered the intervention which was assessed to be feasible and acceptable by family members and nurses. Protocol adherence could be improved with alternative data collection methods. Nurses considered the activities acceptable. The study was able to recruit  randomise and retain family member participants. Further strategies are required to assess intervention fidelity and improve data collection. Copyright Â© 2017 Elsevier Ltd. All rights reserved.Feasibility study of a single-blind randomised controlled trial of an occupational therapy intervention.PubMedGantschnig  Brigitte E; Nilsson  Ingeborg; Fisher  Anne G; KÃ¼nzle  Christoph; Page  Julie2016-07-01Several factors facilitate or hinder efficacy research in occupational therapy. Strategies are needed  therefore  to support the successful implementation of trials. To assess the feasibility of conducting a randomised controlled trial (RCT). The main feasibility objectives of this study were to assess the process  resources  management  and scientific basis of a trial RCT. A total of 10 occupational therapists  between the ages of 30 and 55 (M 43.4; SD 8.3) with seven to 26 years' (M 14.3; SD 6.1) experience  participated in this study. Qualitative data collected included minutes of meetings  reports  and field notes. The data were analysed based on the principles of content analysis  using feasibility objectives as the main categories. Data analysis revealed strengths in relation to retention and inclusion criteria of participants  the study protocol  study organisation  and the competence of researchers. Weaknesses were found related to recruitment  randomisation  data collection  time for training and communication  commitment  and design. The findings indicated that there are several factors which had a considerable impact on the implementation of an RCT in practice. However  it was useful to assess methods and procedures of the trial RCT as a basis to refine research plans.Economic and Technical Feasibility Study of Utility-Scale Wind Generation for the New York Buffalo River and South Buffalo Brownfield Opportunity AreasSciTech ConnectRoberts  J. O.; Mosey  G.2014-04-01Through the RE-Powering America's Land initiative  the economic and technical feasibility of utilizing contaminated lands in the Buffalo  New York  area for utility-scale wind development is explored. The study found that there is available land  electrical infrastructure  wind resource  and local interest to support a commercial wind project; however  economies of scale and local electrical markets may need further investigation before significant investment is made into developing a wind project at the Buffalo Reuse Authority site.Supervised exercise training as an adjunct therapy for venous leg ulcers: a randomized controlled feasibility trial.PubMedKlonizakis  M; Tew  G A; Gumber  A; Crank  H; King  B; Middleton  G; Michaels  J A2018-05-01Venous leg ulcers (VLUs) are typically painful and heal slowly. Compression therapy offers high healing rates; however  improvements are not usually sustained. Exercise is a low-cost  low-risk and effective strategy for improving physical and mental health. Little is known about the feasibility and efficacy of supervised exercise training used in combination with compression therapy patients with VLUs. To assess the feasibility of a 12-week supervised exercise programme as an adjunct therapy to compression in patients with VLUs. This was a two-centre  two-arm  parallel-group  randomized feasibility trial. Thirty-nine patients with venous ulcers were recruited and randomized 1Â : 1 either to exercise (three sessions weekly) plus compression therapy or compression only. Progress/success criteria included exercise attendance rate  loss to follow-up and patient preference. Baseline assessments were repeated at 12Â weeks  6Â months and 1Â year  with healing rate and time  ulcer recurrence and infection incidents documented. Intervention and healthcare utilization costs were calculated. Qualitative data were collected to assess participants' experiences. Seventy-two per cent of the exercise group participants attended all scheduled exercise sessions. No serious adverse events and only two exercise-related adverse events (both increased ulcer discharge) were reported. Loss to follow-up was 5%. At 12Â months  median ulcer healing time was lower in the exercise group (13 vs. 34Â·7Â weeks). Mean National Health Service costs were Â£813Â·27 for the exercise and Â£2298Â·57 for the control group. The feasibility and acceptability of both the supervised exercise programme in conjunction with compression therapy and the study procedures is supported. Â© 2017 The Authors. British Journal of Dermatology published by John Wiley & Sons Ltd on behalf of British Association of Dermatologists.A novel experience-based internet intervention for smoking cessation: feasibility randomised controlled trial.PubMedPowell  John; Newhouse  Nikki; Martin  Angela; Jawad  Sena; Yu  Ly-Mee; Davoudianfar  Mina; Locock  Louise; Ziebland  Sue2016-11-11The internet is frequently used to share experiences of health and illness  but this phenomenon has not been harnessed as an intervention to achieve health behaviour change. The aim of this study was to determine the feasibility of a randomised trial assessing the effects of a novel  experience-based website as a smoking cessation intervention. The secondary aim was to measure the potential impact on smoking behaviour of both the intervention and a comparator website. A feasibility randomised controlled single-blind trial assessed a novel  experience-based website containing personal accounts of quitting smoking as a cessation intervention  and a comparator website providing factual information. Feasibility measures including recruitment  and usage of the interventions were recorded  and the following participant-reported outcomes were also measured: Smoking Abstinence Self-Efficacy Questionnaire  the single-item Motivation to Stop Scale  self-reported abstinence  quit attempts and health status outcomes. Eligible smokers from two English regions were entered into the trial and given access to their allocated website for two weeks. Eighty-seven smokers were randomised  65 completed follow-up (75Â %). Median usage was 15Â min for the intervention  and 5Â min for the comparator (range 0.5-213 min). Median logins for both sites was 2 (range 1-20). All participant-reported outcomes were similar between groups. It was technically feasible to deliver a novel intervention harnessing the online sharing of personal experiences as a tool for smoking cessation  but recruitment was slow and actual use was relatively low  with attrition from the trial. Future work needs to maximize engagement and to understand how best to assess the value of such interventions in everyday use  rather than as an isolated 'dose of information'. ISRCTN29549695 DOI 10.1186/ISRCTN29549695 . Registered 17/05/2013.Synthesizing epidemiological and economic optima for control of immunizing infections.PubMedKlepac  Petra; Laxminarayan  Ramanan; Grenfell  Bryan T2011-08-23Epidemic theory predicts that the vaccination threshold required to interrupt local transmission of an immunizing infection like measles depends only on the basic reproductive number and hence transmission rates. When the search for optimal strategies is expanded to incorporate economic constraints  the optimum for disease control in a single population is determined by relative costs of infection and control  rather than transmission rates. Adding a spatial dimension  which precludes local elimination unless it can be achieved globally  can reduce or increase optimal vaccination levels depending on the balance of costs and benefits. For weakly coupled populations  local optimal strategies agree with the global cost-effective strategy; however  asymmetries in costs can lead to divergent control optima in more strongly coupled systems--in particular  strong regional differences in costs of vaccination can preclude local elimination even when elimination is locally optimal. Under certain conditions  it is locally optimal to share vaccination resources with other populations.A Review of Economic Evaluations of Tobacco Control ProgramsPubMed CentralKahende  Jennifer W.; Loomis  Brett R.; Adhikari  Bishwa; Marshall  LaTisha2009-01-01Each year  an estimated 443 000 people die of smoking-related diseases in the United States. Cigarette smoking results in more than $193 billion in medical costs and productivity losses annually. In an effort to reduce this burden  many states  the federal government  and several national organizations fund tobacco control programs and policies. For this report we reviewed existing literature on economic evaluations of tobacco control interventions. We found that smoking cessation therapies  including nicotine replacement therapy (NRT) and self-help are most commonly studied. There are far fewer studies on other important interventions  such as price and tax increases  media campaigns  smoke free air laws and workplace smoking interventions  quitlines  youth access enforcement  school-based programs  and community-based programs. Although there are obvious gaps in the literature  the existing studies show in almost every case that tobacco control programs and policies are either cost-saving or highly cost-effective. PMID:19440269The feasibility of remote-controlled assistance as a search tool for patient education.PubMedLin  I K; Bray  B E; Smith  J A; Lange  L L2001-01-01Patients often desire more information about their conditions than they receive during a physician office visit. To address the patient's information needs  a touchscreen information kiosk was implemented. Results from the first prototype identified interface  security  and technical issues. Misspelling of search terms was identified as the most observable cause of search failure. An experimental remote control assistance feature was added in the second prototype. The feature allowed a medical librarian to provide real-time remote help during searches by taking control of the patient's computer. Remote assistance improved patient satisfaction  increased ease of use  and raised document retrieval rate (86.7% vs. 56.7%). Both patients and librarians found the application useful. Reasons included its convenience and flexibility  opportunity for direct patient contact  ability to teach through direct demonstration  and complementing the librarian's role as an information gateway. The project demonstrated the feasibility of applying remote control technology to patient education.Economic Analysis of Immunization Strategies for PRRS Control [corrected].PubMedLinhares  Daniel C L; Johnson  Clayton; Morrison  Robert B2015-01-01Porcine reproductive and respiratory syndrome virus (PRRSv) is a swine-specific pathogen that causes significant increases in production costs. When a breeding herd becomes infected  in an attempt to hasten control and elimination of PRRSv  some veterinarians have adopted a strategy called load-close-expose which consists of interrupting replacement pig introductions into the herd for several weeks (herd closure) and exposing the whole herd to a replicating PRRSv to boost herd immunity. Either modified-live virus (MLV) vaccine or live field-virus inoculation (FVI) is used. This study consisted of partial budget analyses to compare MLV to FVI as the exposure method of load-close-expose program to control and eliminate PRRSv from infected breeding herds  and secondly to estimate benefit / cost of vaccinating sow herds preventatively. Under the assumptions used in this study  MLV held economic advantage over FVI. However  sensitivity analysis revealed that decreasing margin over variable costs below $ 47.32  or increasing PRRSv-attributed cost above $18.89 or achieving time-to-stability before 25 weeks resulted in advantage of FVI over MLV. Preventive vaccination of sow herds was beneficial when the frequency of PRRSv infection was at least every 1 year and 9 months [corrected]. The economics of preventative vaccination was minimally affected by cost attributed to field-type PRRSv infection on growing pigs or by the breeding herd productivity level. The models developed and described in this paper provide valuable tools to assist veterinarians in their efforts to control PRRSv.The economics of malaria control and elimination: a systematic review.PubMedShretta  Rima; AvanceÃ±a  Anton L V; Hatefi  Arian2016-12-12Declining donor funding and competing health priorities threaten the sustainability of malaria programmes. Elucidating the cost and benefits of continued investments in malaria could encourage sustained political and financial commitments. The evidence  although available  remains disparate. This paper reviews the existing literature on the economic and financial cost and return of malaria control  elimination and eradication. A review of articles that were published on or before September 2014 on the cost and benefits of malaria control and elimination was performed. Studies were classified based on their scope and were analysed according to two major categories: cost of malaria control and elimination to a health system  and cost-benefit studies. Only studies involving more than two control or elimination interventions were included. Outcomes of interest were total programmatic cost  cost per capita  and benefit-cost ratios (BCRs). All costs were converted to 2013 US$ for standardization. Of the 6425 articles identified  54 studies were included in this review. Twenty-two were focused on elimination or eradication while 32 focused on intensive control. Forty-eight per cent of studies included in this review were published on or after 2000. Overall  the annual per capita cost of malaria control to a health system ranged from $0.11 to $39.06 (median: $2.21) while that for malaria elimination ranged from $0.18 to $27 (median: $3.00). BCRs of investing in malaria control and elimination ranged from 2.4 to over 145. Overall  investments needed for malaria control and elimination varied greatly amongst the various countries and contexts. In most cases  the cost of elimination was greater than the cost of control. At the same time  the benefits of investing in malaria greatly outweighed the costs. While the cost of elimination in most cases was greater than the cost of control  the benefits greatly outweighed the cost. Information from this review provides guidance toFeasibility Study for a Computerized Serials Control System in the Defense Communications Agency Technical and Management Information Center.DTIC Science & Technology1984-06-20AD-A162 Â±88 FEASIBILITY STUDY FOR A COMPUTERIZED SERIALS CONTROL 1/1 SYSTEM IN THE DEFENS (U) DEFENSE COMMUNICATIONS AGENCY WASHINGTON DC TECHNICAL...NATIONAL BUREAU OF STANDARDS- 1963-A 0FEASIBILITY STUDY FOR A COMPUTERIZED SERIALS CONTROL SYSTEM IN THE DEFENSE COMMUNICATIONS 0AGENCY TECHNICAL AND...ABSTRACT 21. ABSTRACT SECURITY CLASSIFICATION UNCLASSIFIED/UNLIMITED R1 SAME AS RPT. 0 DTIC USERS 0 UNCLASSIFIED 22&. NAME OF RESPONSIBLE INDIVIDUAL 22bA randomised controlled feasibility trial of Group Cognitive Behavioural Therapy for people with severe asthma.PubMedYorke  Janelle; Adair  Pauline; Doyle  Anne-Marie; Dubrow-Marshall  Linda; Fleming  Sharon; Holmes  Leanne; Menzies-Gow  Andrew; Niven  Rob; Pilling  Mark; Shuldham  Caroline2017-06-01Evidence for the efficacy of Cognitive Behavioural Therapy (CBT) in asthma is developing but it is not known if this translates to benefits in severe asthma or if a group approach is acceptable to this patient group. This study aimed to assess the feasibility and acceptability of Group-CBT in severe asthma. This was a two-centre  randomised controlled parallel group feasibility study. Eligible participants (patients with severe asthma and a clinically significant diagnosis of anxiety and/or depression - Hospital Anxiety and Depression Scale (HAD) score greater than 8 for the anxiety or depression sub-scale) received Group-CBT in weekly sessions for eight consecutive weeks and usual care or usual care only. Follow-up was for 16 weeks and end points were: Asthma Quality of Life Questionnaire  Asthma Control Questionnaire  HAD  Dyspnoea-12  EuroQual-5D and EuroQuol-VAS. 51 patients were randomised: 36% (51 out of 140) consent rate and attrition at week 16 was 12. Screening logs indicated that study take-up was influenced by patients living long distances from the treatment centre and inability to commit to the weekly demands of the programme. Drop-out was higher in Group-CBT compared due to inability to commit to the weekly programme because of poor health. Participants who contributed to focus group discussions reported that Group-CBT contributed to a better understanding of their illness and related approaches to anxiety management and acceptance of their asthma condition. Although weekly face-to-face sessions were challenging  this was the preferred method of delivery for these participants. This feasibility study shows that Group-CBT warrants further investigation as a potentially promising treatment option for patients with severe asthma. It has been possible but not easy to recruit and retain the sample. Options for a less demanding intervention schedule  such as less frequent face-to-face visits and the use of web-based interventions  require carefulResults of a feasibility randomised controlled study of the guidelines for exercise in multiple sclerosis project.PubMedLearmonth  Yvonne C; Adamson  Brynn C; Kinnett-Hopkins  Dominique; Bohri  Maria; Motl  Robert W2017-03-01There is increasing recognition that exercise is an efficacious strategy for managing many consequences of multiple sclerosis (MS)  yet persons with MS are not engaging in sufficient exercise for accruing health benefits. Poor exercise uptake might be associated with the design of previous research. We conducted a randomised controlled trial (RCT) for examining the feasibility of a 4-month home-based  exercise-training program designed based on recent physical activity guidelines for MS and supplemented by behavioural strategies for compliance. Feasibility was assessed in the domains of process (e.g.  recruitment)  resource (e.g.  monetary costs)  management (e.g.  personnel time requirements) and scientific outcomes (e.g.  treatment effect). We recruited persons with mild-to-moderate MS who were randomised into an intervention or wait-list control condition. Intervention participants received a pedometer  elastic resistance bands  DVD  training manual  calendars  log-book  video coaching calls and newsletters. Participants in both conditions completed home-based assessments before and after the 4-month period. Ninety-nine persons with MS were assessed for eligibility  and 57 were randomised. Fifty-one persons completed the study (90%). Total costs of the study were US $5331.03. Personnel time to conduct the study totaled 263h. Participants in the intervention group complied fully with 71% of all exercise sessions. There was a moderate increase in self-reported exercise behaviour of the intervention participants as measured by the Godin Leisure-Time Exercise Questionnaire (dâ‰¥0.5). The results support the feasibility and acceptability of a home-based exercise intervention based on physical activity guidelines and supplemented with behavioural strategies for adults with mild-to-moderate MS. Copyright Â© 2016 Elsevier Inc. All rights reserved.Formative research on the feasibility of hygiene interventions for influenza control in UK primary schools.PubMedSchmidt  Wolf-Peter; Wloch  Catherine; Biran  Adam; Curtis  Val; Mangtani  Punam2009-10-15Interventions to increase hand washing in schools have been advocated as a means to reduce the transmission of pandemic influenza and other infections. However  the feasibility and acceptability of effective school-based hygiene interventions is not clear. A pilot study in four primary schools in East London was conducted to establish the current need for enhanced hand hygiene interventions  identify barriers to their implementation and to test their acceptability and feasibility. The pilot study included key informant interviews with teachers and school nurses  interviews  group discussions and essay questions with the children  and testing of organised classroom hand hygiene activities. In all schools  basic issues of personal hygiene were taught especially in the younger age groups. However  we identified many barriers to implementing intensive hygiene interventions  in particular time constraints and competing health issues. Teachers' motivation to teach hygiene and enforce hygienic behaviour was primarily educational rather than immediate infection control. Children of all age groups had good knowledge of hygiene practices and germ transmission. The pilot study showed that intensive hand hygiene interventions are feasible and acceptable but only temporarily during a period of a particular health threat such as an influenza pandemic  and only if rinse-free hand sanitisers are used. However  in many settings there may be logistical issues in providing all schools with an adequate supply. In the absence of evidence on effectiveness  the scope for enhanced hygiene interventions in schools in high income countries aiming at infection control appears to be limited in the absence of a severe public health threat.Formative research on the feasibility of hygiene interventions for influenza control in UK primary schoolsPubMed CentralSchmidt  Wolf-Peter; Wloch  Catherine; Biran  Adam; Curtis  Val; Mangtani  Punam2009-01-01Background Interventions to increase hand washing in schools have been advocated as a means to reduce the transmission of pandemic influenza and other infections. However  the feasibility and acceptability of effective school-based hygiene interventions is not clear. Methods A pilot study in four primary schools in East London was conducted to establish the current need for enhanced hand hygiene interventions  identify barriers to their implementation and to test their acceptability and feasibility. The pilot study included key informant interviews with teachers and school nurses  interviews  group discussions and essay questions with the children  and testing of organised classroom hand hygiene activities. Results In all schools  basic issues of personal hygiene were taught especially in the younger age groups. However  we identified many barriers to implementing intensive hygiene interventions  in particular time constraints and competing health issues. Teachers' motivation to teach hygiene and enforce hygienic behaviour was primarily educational rather than immediate infection control. Children of all age groups had good knowledge of hygiene practices and germ transmission. Conclusion The pilot study showed that intensive hand hygiene interventions are feasible and acceptable but only temporarily during a period of a particular health threat such as an influenza pandemic  and only if rinse-free hand sanitisers are used. However  in many settings there may be logistical issues in providing all schools with an adequate supply. In the absence of evidence on effectiveness  the scope for enhanced hygiene interventions in schools in high income countries aiming at infection control appears to be limited in the absence of a severe public health threat. PMID:19832971Physiotherapy for sleep disturbance in chronic low back pain: a feasibility randomised controlled trialPubMed Central2010-01-01Background Sleep disturbance is becoming increasingly recognised as a clinically important symptom in people with chronic low back pain (CLBP  low back pain >12 weeks)  associated with physical inactivity and depression. Current research and international clinical guidelines recommend people with CLBP assume a physically active role in their recovery to prevent chronicity  but the high prevalence of sleep disturbance in this population may be unknowingly limiting their ability to participate in exercise-based rehabilitation programmes and contributing to poor outcomes. There is currently no knowledge concerning the effectiveness of physiotherapy on sleep disturbance in people with chronic low back pain and no evidence of the feasibility of conducting randomized controlled trials that comprehensively evaluate sleep as an outcome measure in this population. Methods/Design This study will evaluate the feasibility of a randomised controlled trial (RCT)  exploring the effects of three forms of physiotherapy (supervised general exercise programme  individualized walking programme and usual physiotherapy  which will serve as the control group) on sleep quality in people with chronic low back pain. A presenting sample of 60 consenting patients will be recruited in the physiotherapy department of Beaumont Hospital  Dublin  Ireland  and randomly allocated to one of the three groups in a concealed manner. The main outcomes will be sleep quality (self-report and objective measurement)  and self-reported functional disability  pain  quality of life  fear avoidance  anxiety and depression  physical activity  and patient satisfaction. Outcome will be evaluated at baseline  3 months and 6 months. Qualitative telephone interviews will be embedded in the research design to obtain feedback from a sample of participants' about their experiences of sleep monitoring  trial participation and interventions  and to inform the design of a fully powered future RCT. Planned analysis willThe Economics of Pollution; Part Three: Can Pollution Be Controlled? Teaching About: Can Pollution Be Controlled?ERIC Educational Resources Information CenterWolozin  Harold; Reilly  Patricia R.In this third of three articles on the economics of pollution control general statements from several sources present a background which questions our ability to devise the necessary tools to fight pollution  even if adequate expenditures of money are provided. In the struggle to control pollution  the economist  it is believed  can provideâ€¦TRX Suspension Training: A New Functional Training Approach for Older Adults - Development  Training Control and Feasibility.PubMedGaedtke  Angus; Morat  TobiasBecause of its proximity to daily activities functional training becomes more important for older adults. Sling training  a form of functional training  was primarily developed for therapy and rehabilitation. Due to its effects (core muscle activation  strength and balance improvements)  sling training may be relevant for older adults. However  to our knowledge no recent sling training program for healthy older adults included a detailed training control which is indeed an essential component in designing and implementing this type of training to reach positive effects. The purpose of this study was to develop a TRX Suspension Training for healthy older adults (TRX-OldAge) and to evaluate its feasibility. Eleven participants finished the 12 week intervention study. All participants trained in the TRX-OldAge whole-body workout which consists of seven exercises including 3-4 progressively advancing stages of difficulty for every exercise. At each stage  intensity could be increased through changes in position. Feasibility data was evaluated in terms of training compliance and a self-developed questionnaire for rating TRX-OldAge. The training compliance was 85 %. After study period  91 % of the participants were motivated to continue with the program. The training intensity  duration and frequency were rated as optimal. All participants noted positive effects whereas strength gains were the most. On the basis of the detailed information about training control  TRX-OldAge can be individually adapted for each older adult appropriate to its precondition  demands and preference.Feasibility of including cellular telephone numbers in random digit dialing for epidemiologic case-control studies.PubMedVoigt  Lynda F; Schwartz  Stephen M; Doody  David R; Lee  Spencer C; Li  Christopher I2011-01-01The usefulness of landline random digit dialing (RDD) in epidemiologic studies is threatened by the rapid increase in households with only cellular telephone service. This study assessed the feasibility of including cellular telephone numbers in RDD and differences between young adults with landline telephones and those with only cellular telephones. Between 2008 and 2009  a total of 9 023 cellular telephone numbers were called and 43.8% were successfully screened; 248 men and 249 women who resided in 3 Washington State counties  were 20-44 years of age  and used only cellular telephones were interviewed. They were compared with 332 men and 526 women with landline telephones interviewed as controls for 2 case-control studies conducted in parallel with cellular telephone interviewing. Cellular-only users were more likely to be college educated and less likely to have fathered/birthed a child than were their landline counterparts. Male cellular-only users were less likely to be obese and more likely to exercise  to be Hispanic  and to have lower incomes  while female cellular-only users were more likely to be single than landline respondents. Including cellular telephone numbers in RDD is feasible and should be incorporated into epidemiologic studies that rely on this method to ascertain subjects  although low screening rates could hamper the representativeness of such a sample.Developing and feasibility testing of data collection methods for an economic evaluation of a supported selfmanagement programme for adults with a learning disability and type 2 diabetes.PubMedO'Dwyer  John L; Russell  Amy M; Bryant  Louise D; Walwyn  Rebecca E A; Wright-Hughes  Alexandra M; Graham  Elizabeth H; Wright  Judy M; Meer  Shaista; Birtwistle  Jacqueline; Farrin  Amanda J; House  Allan O; Hulme  Claire T2018-01-01The challenges of conducting research with hard to reach vulnerable groups are particularly pertinent for people with learning disabilities. Data collection methods for previous cost and cost-effectiveness analyses of health and social care interventions targeting people with learning disabilities have relied on health care/health insurance records or data collection forms completed by the service provider rather than by people with learning disabilities themselves. This paper reports on the development and testing of data collection methods for an economic evaluation within a randomised controlled trial (RCT) for a supported self-management programme for people with mild/moderate learning disabilities and type 2 diabetes. A case finding study was conducted to identify types of health and social care use and data collection methods employed in previous studies with this population. Based on this evidence  resource use questionnaires for completion by GP staff and interviewer-administered participant questionnaires (covering a wider cost perspective and health-related quality of life) were tested within a feasibility RCT. Interviewer-administered questionnaires included the EQ-5D-3L (the NICE recommended measure for use in economic evaluation). Participants were adults >â€‰18Â years with a mild or moderate learning disability and type 2 diabetes  with mental capacity to give consent to research participation. Data collection for questionnaires completed by GP staff requesting data for the last 12 months proved time intensive and difficult. Whilst 82.3% (121/147) of questionnaires were returned  up to 17% of service use items were recorded as unknown. Subsequently  a shorter recall period (4Â months) led to a higher return rate but with a higher rate of missing data. Missing data for interviewer-administered participant questionnaires was >â€‰8% but the interviewers reported difficulty with participant recall. Almost 60% (48/80) of participants had difficultyThe impact of economic recession on infection prevention and control.PubMedO'Riordan  M; Fitzpatrick  F2015-04-01The economic recession that began in 2007 led to austerity measures and public sector cutbacks in many European countries. Reduced resource allocation to infection prevention and control (IPC) programmes is impeding prevention and control of tuberculosis  HIV and vaccine-preventable infections. In addition  higher rates of infectious disease in the community have a significant impact on hospital services  although the extent of this has not been studied. With a focus on quick deficit reduction  preventive services such IPC may be regarded as non-essential. Where a prevention programme succeeds in reducing disease burden to a low level  its very success can undermine the perceived need for the programme. To mitigate the negative effects of recession  we need to: educate our political leaders about the economic benefits of IPC; better quantify the costs of healthcare-associated infection; and evaluate the effects of budget cuts on healthcare outcomes and IPC activities. Copyright Â© 2015 The Healthcare Infection Society. Published by Elsevier Ltd. All rights reserved.Randomised controlled trial of rhinothermy for treatment of the common cold: a feasibility studyPubMed Centralvan de Hei  Susanne; McKinstry  Steven; Bardsley  George; Weatherall  Mark; Beasley  Richard; Fingleton  James2018-01-01Objective To determine the feasibility of a randomised controlled trial (RCT) of rhinothermy for the common cold. Design Open label  randomised  controlled feasibility study. Setting Single-centre research institute in New Zealand recruiting participants from the community. Participants 30 adult participants with symptoms of a common cold  presenting within 48â€‰hours of the onset of symptoms. Interventions Participants were randomly assigned 2:1 to receive either 35â€‰L/min of 100% humidified air at 41Â°C via high flow nasal cannulae  2â€‰hours per day for up to 5â€‰days (rhinothermy)  or vitamin C 250â€‰mg daily for 5â€‰days (control). Primary and secondary outcome measures The primary outcome was the proportion of screened candidates who were randomised. Secondary outcomes included: proportion of randomised participants who completed the study; modified Jackson scores from randomisation to 10 days after initiation of randomised regimen; time until feeling â€˜a lot betterâ€™ compared with study entry; time until resolution of symptoms or symptom score at 10 days postrandomisation; proportion of organisms identified by PCR analysis of nasal swabs taken at baseline; the patterns of use of the rhinothermy device; estimated adherence of the control group; and rhinothermy device tolerability. Results In all 30/79 (38%  95%â€‰CI 27% to 50%) of potential participants screened for eligibility were randomised. Rhinothermy was well tolerated  and all randomised participants completed the study (100%  95%â€‰CI 88% to 100%). The reduction from baseline in the modified Jackson score was greater with rhinothermy compared with control at days 2  3  4  5 and 6  with the maximum difference at day 4 (âˆ’6.4  95%â€‰CI âˆ’9.4 to âˆ’3.3). The substantial clinical benefit threshold for modified Jackson score was a 5-unit change. Conclusions This study shows that an RCT of rhinothermy compared with low-dose vitamin C in the treatment of the common cold is feasible. Trial registrationEconomic Effects of Introducing Alternative Salmonella Control Strategies in SwedenPubMed CentralSundstrÃ¶m  Kristian; WahlstrÃ¶m  Helene; Ivarsson  Sofie; Sternberg Lewerin  Susanna2014-01-01The objective of the study was to analyse the economic effects of introducing alternative Salmonella control strategies in Sweden. Current control strategies in Denmark and the Netherlands were used as benchmarks. The true number of human Salmonella cases was estimated by reconstructing the reporting pyramids for the various scenarios. Costs were calculated for expected changes in human morbidity (Salmonella and two of its sequelae)  for differences in the control programmes and for changes in cattle morbidity. The net effects (benefits minus costs) were negative in all scenarios (â‚¬ âˆ’5 to âˆ’105 million)  implying that it would not be cost-effective to introduce alternative control strategies in Sweden. This result was mainly due to an expected increase in the incidence of Salmonella in humans (6035â€“57108 reported and unreported new cases/year)  with expected additional costs of â‚¬ 5â€“55 million. Other increased costs were due to expected higher incidences of sequelae (â‚¬ 3â€“49 million) and a higher cattle morbidity (â‚¬ 4â€“8 million). Benefits in terms of lower control costs amounted to â‚¬ 4â€“7 million. PMID:24831797About the feasibilities of controlling the properties of thermoelectric energy converters using optical radiationNASA Astrophysics Data System (ADS)Kshevetsky  Oleg S.2018-01-01We represent evaluating analysis of the feasibilities for controlling the properties of thermoelectric energy converters using EM radiation in the regimes of cooling  heating  electromotive force generation  or electric current generation. Thus we investigate the influence of optical radiation both on electric conductivity and thermo-electromotive force coefficient of thermoelectric materials. We also discuss promising applications for controlling the properties of thermoelectric energy converters using EM radiation. We represent the results of experimental study of positionsensitive energy converters in the regimes of electromotive force generation and the electric current generation (in part  photo-thermoelectric position-sensitive temperature detectors)  position-sensitive photo-thermoelectric energy converters in the regimes of cooling  heating  parallel photoelectric and thermoelectric conversion of sun-light optical radiation into electric power.Markov Modeling of Component Fault Growth over a Derived Domain of Feasible Output Control Effort ModificationsNASA Technical Reports Server (NTRS)Bole  Brian; Goebel  Kai; Vachtsevanos  George2012-01-01This paper introduces a novel Markov process formulation of stochastic fault growth modeling  in order to facilitate the development and analysis of prognostics-based control adaptation. A metric representing the relative deviation between the nominal output of a system and the net output that is actually enacted by an implemented prognostics-based control routine  will be used to define the action space of the formulated Markov process. The state space of the Markov process will be defined in terms of an abstracted metric representing the relative health remaining in each of the system s components. The proposed formulation of component fault dynamics will conveniently relate feasible system output performance modifications to predictions of future component health deterioration.Assessing the feasibility of screening and providing brief advice for alcohol misuse in general dental practice: a clustered randomised control trial protocol for the DART studyPubMed CentralNtouva  Antiopi; Porter  Jessie; Crawford  Mike J; Britton  Annie; Gratus  Christine; Newton  Tim; Tsakos  Georgios; Heilmann  Anja; Pikhart  Hynek; Watt  Richard G2015-01-01Introduction Alcohol misuse is a significant public health problem with major health  social and economic consequences. Systematic reviews have reported that brief advice interventions delivered in various health service settings can reduce harmful drinking. Although the links between alcohol and oral health are well established and dentists come into contact with large numbers of otherwise healthy patients regularly  no studies have been conducted in the UK to test the feasibility of delivering brief advice about alcohol in general dental settings. Methods and analysis The Dental Alcohol Reduction Trial (DART) aims to assess the feasibility and acceptability of screening for alcohol misuse and delivering brief advice in patients attending National Health Service (NHS) general dental practices in North London. DART is a cluster randomised control feasibility trial and uses a mixed methods approach throughout the development  design  delivery and evaluation of the intervention. It will be conducted in 12 NHS general dental practices across North London and will include dental patients who drink above the recommended guidance  as measured by the Alcohol Use Disorders Identification Test (AUDIT-C) screening tool. The intervention involves 5â€…min of tailored brief advice delivered by dental practitioners during the patient's appointment. Feasibility and acceptability measures as well as suitability of proposed primary outcomes of alcohol consumption will be assessed. Initial economic evaluation will be undertaken. Recruitment and retention rates as well as acceptability of the study procedures from screening to follow-up will be measured. Ethics and dissemination Ethical approval was obtained from the Camden and Islington Research Ethics Committee. Study outputs will be disseminated via scientific publications  newsletters  reports and conference presentations to a range of professional and patient groups and stakeholders. Based on the results of the trialFeasibility study of aileron and spoiler control systems for large horizontal axis wind turbinesNASA Technical Reports Server (NTRS)Wentz  W. H.  Jr.; Snyder  M. H.; Calhoun  J. T.1980-01-01The feasibility of using aileron or spoiler controls as alternates to pitch control for large horizontal axis wind turbines was studied. The NASA Mod-0 100 kw machine was used as the basis for the study. Specific performance studies were conducted for 20% chord ailerons over the outboard 30% span  and for 10% chord spoilers over the same portion of the span. Both control systems utilized control deflections up to 60 deg. Results of the study show that either ailerons or spoilers can provide the control necessary to limit turbine power in high wind conditions. The aileron system  as designed  provides overspeed protection at hurricane wind speeds  low wind speed starting torque of 778 N-m (574 ft. lb) at 3.6 m/sec  and a 1.3 to 1.5% increase in annual energy compared to a fixed pitch rotor. The aileron control system preliminary design study includes aileron loads analysis and the design of a failsafe flyweight actuator for overspeed protection in the event of a hydraulic system failure.Feasibility of Decentralized Linear-Quadratic-Gaussian Control of Autonomous Distributed SpacecraftNASA Technical Reports Server (NTRS)Carpenter  J. Russell1999-01-01A distributed satellite formation  modeled as an arbitrary number of fully connected nodes in a network  could be controlled using a decentralized controller framework that distributes operations in parallel over the network. For such problems  a solution that minimizes data transmission requirements  in the context of linear-quadratic-Gaussian (LQG) control theory  was given by Speyer. This approach is advantageous because it is non-hierarchical  detected failures gracefully degrade system performance  fewer local computations are required than for a centralized controller  and it is optimal with respect to the standard LQG cost function. Disadvantages of the approach are the need for a fully connected communications network  the total operations performed over all the nodes are greater than for a centralized controller  and the approach is formulated for linear time-invariant systems. To investigate the feasibility of the decentralized approach to satellite formation flying  a simple centralized LQG design for a spacecraft orbit control problem is adapted to the decentralized framework. The simple design uses a fixed reference trajectory (an equatorial  Keplerian  circular orbit)  and by appropriate choice of coordinates and measurements is formulated as a linear time-invariant system.Clinical feasibility of interactive motion-controlled games for stroke rehabilitation.PubMedBower  Kelly J; Louie  Julie; Landesrocha  Yoseph; Seedy  Paul; Gorelik  Alexandra; Bernhardt  Julie2015-08-02Active gaming technologies  including the Nintendo Wii and Xbox Kinect  have become increasingly popular for use in stroke rehabilitation. However  these systems are not specifically designed for this purpose and have limitations. The aim of this study was to investigate the feasibility of using a suite of motion-controlled games in individuals with stroke undergoing rehabilitation. Four games  which utilised a depth-sensing camera (PrimeSense)  were developed and tested. The games could be played in a seated or standing position. Three games were controlled by movement of the torso and one by upper limb movement. Phase 1 involved consecutive recruitment of 40 individuals with stroke who were able to sit unsupported. Participants were randomly assigned to trial one game during a single session. Sixteen individuals from Phase 1 were recruited to Phase 2. These participants were randomly assigned to an intervention or control group. Intervention participants performed an additional eight sessions over four weeks using all four game activities. Feasibility was assessed by examining recruitment  adherence  acceptability and safety in both phases of the study. Forty individuals (mean age 63 years) completed Phase 1  with an average session time of 34 min. The majority of Phase 1 participants reported the session to be enjoyable (93 %)  helpful (80 %) and something they would like to include in their therapy (88 %). Sixteen individuals (mean age 61 years) took part in Phase 2  with an average of seven 26-min sessions over four weeks. Reported acceptability was high for the intervention group and improvements over time were seen in several functional outcome measures. There were no serious adverse safety events reported in either phase of the study; however  a number of participants reported minor increases in pain. A post-stroke intervention using interactive motion-controlled games shows promise as a feasible and potentially effective treatment approach. This paperAquatic Plant Control Research Program: Literature Review of Economic Valuation of Aquatic Plant ControlDTIC Science & Technology1991-02-01200 words) Aquatic plant control is necessary to maintain the flow of benefits for which water resources projects are constructed and operated (e.g...but little work has been performed by the Corps to evaluate the economic benefits resulting from aquatic plant control programs. This report reviewed...the applicability of the project evaluation guidance  Principles and Guidelines (P&G)  for the eval- uation of aquatic plant control benefits . It wasCluster randomised feasibility trial to improve the Control of Hypertension In Rural India (CHIRI): a study protocol.PubMedRiddell  Michaela A; Joshi  Rohina; Oldenburg  Brian; Chow  Clara; Thankappan  K R; Mahal  Ajay; Thomas  Nihal; Srikanth  Velandai K; Evans  Roger G; Kalyanram  Kartik; Kartik  Kamakshi; Maulik  Pallab K; Arabshahi  Simin; Varma  R P; Guggilla  Rama K; Suresh  Oduru; Mini  G K; D'Esposito  Fabrizio; Sathish  Thirunavukkarasu; Alim  Mohammed; Thrift  Amanda G2016-10-08Hypertension is emerging in rural populations of India. Barriers to diagnosis and treatment of hypertension may differ regionally according to economic development. Our main objectives are to estimate the prevalence  awareness  treatment and control of hypertension in 3 diverse regions of rural India; identify barriers to diagnosis and treatment in each setting and evaluate the feasibility of a community-based intervention to improve control of hypertension. This study includes 4 main activities: (1) assessment of risk factors  quality of life  socioeconomic position and barriers to changes in lifestyle behaviours in âˆ¼14â€…500 participants; (2) focus group discussions with individuals with hypertension and indepth interviews with healthcare providers  to identify barriers to control of hypertension; (3) use of a medicines-availability survey to determine the availability  affordability and accessibility of medicines and (4) trial of an intervention provided by Accredited Social Health Activists (ASHAs)  comprising group-based education and support for individuals with hypertension to self-manage blood pressure. Wards/villages/hamlets of a larger Mandal are identified as the primary sampling unit (PSU). PSUs are then randomly selected for inclusion in the cross-sectional survey  with further randomisation to intervention or control. Changes in knowledge of hypertension and risk factors  and clinical and anthropometric measures  are assessed. Evaluation of the intervention by participants provides insight into perceptions of education and support of self-management delivered by the ASHAs. Approval for the overall study was obtained from the Health Ministry's Screening Committee  Ministry of Health and Family Welfare (India)  institutional review boards at each site and Monash University. In addition to publication in peer-reviewed articles  results will be shared with federal  state and local government health officers  local healthcare providers and communitiesCluster randomised feasibility trial to improve the Control of Hypertension In Rural India (CHIRI): a study protocolPubMed CentralRiddell  Michaela A; Joshi  Rohina; Oldenburg  Brian; Chow  Clara; Thankappan  K R; Mahal  Ajay; Thomas  Nihal; Srikanth  Velandai K; Evans  Roger G; Kalyanram  Kartik; Kartik  Kamakshi; Maulik  Pallab K; Arabshahi  Simin; Varma  R P; Guggilla  Rama K; Suresh  Oduru; Mini  G K; D'Esposito  Fabrizio; Sathish  Thirunavukkarasu; Alim  Mohammed2016-01-01Introduction Hypertension is emerging in rural populations of India. Barriers to diagnosis and treatment of hypertension may differ regionally according to economic development. Our main objectives are to estimate the prevalence  awareness  treatment and control of hypertension in 3 diverse regions of rural India; identify barriers to diagnosis and treatment in each setting and evaluate the feasibility of a community-based intervention to improve control of hypertension. Methods and analysis This study includes 4 main activities: (1) assessment of risk factors  quality of life  socioeconomic position and barriers to changes in lifestyle behaviours in âˆ¼14â€…500 participants; (2) focus group discussions with individuals with hypertension and indepth interviews with healthcare providers  to identify barriers to control of hypertension; (3) use of a medicines-availability survey to determine the availability  affordability and accessibility of medicines and (4) trial of an intervention provided by Accredited Social Health Activists (ASHAs)  comprising group-based education and support for individuals with hypertension to self-manage blood pressure. Wards/villages/hamlets of a larger Mandal are identified as the primary sampling unit (PSU). PSUs are then randomly selected for inclusion in the cross-sectional survey  with further randomisation to intervention or control. Changes in knowledge of hypertension and risk factors  and clinical and anthropometric measures  are assessed. Evaluation of the intervention by participants provides insight into perceptions of education and support of self-management delivered by the ASHAs. Ethics and dissemination Approval for the overall study was obtained from the Health Ministry's Screening Committee  Ministry of Health and Family Welfare (India)  institutional review boards at each site and Monash University. In addition to publication in peer-reviewed articles  results will be shared with federal  state and local governmentExamining the feasibility of an economic analysis of dyadic developmental psychotherapy for children with maltreatment associated psychiatric problems in the United Kingdom.PubMedBoyer  Nicole R S; Boyd  Kathleen A; Turner-Halliday  Fiona; Watson  Nicholas; Minnis  Helen2014-12-10Children with maltreatment associated psychiatric problems are at increased risk of developing behavioural or mental health disorders. Dyadic Developmental Psychotherapy (DDP) was proposed as treatment for children with maltreatment histories in the USA  however  being new to the UK little is known of its effectiveness or cost-effectiveness. As part of an exploratory study  this paper explores the feasibility of undertaking economic analysis of DDP in the UK. Feasibility for economic analysis was determined by ensuring such analysis could meet key criteria for economic evaluation. Phone interviews were conducted with professionals (therapists trained and accredited or in the process of becoming accredited DDP practitioners). Three models were developed to represent alternative methods of DDP service delivery. Once appropriate comparators were determined  economic scenarios were constructed. Cost analyses were undertaken from a societal perspective. Finally  appropriate outcome measurement was explored through clinical opinion  literature and further discussions with clinical experts. Three DDP models were constructed: DDP Full-Basic  DDP Home-Based and DDP Long-Term. Two potential comparator interventions were identified and defined as Consultation with Carers and Individual Psychotherapy. Costs of intervention completion per case were estimated to be: Â£6 700 (DDP Full-Basic)  Â£7 100 (Consultations with Carers)  Â£7 200 (DDP Home-Based)  Â£11 400 (Individual Psychotherapy) and Â£14 500 (DDP Long-Term). None of the models of service delivery were found to currently measure effectiveness consistently. The Strengths and Difficulties Questionnaire (SDQ) was deemed an appropriate primary outcome measure  however  it does not cover all disorders DDP intends to treat and the SDQ is not a direct measure of health gain. Inclusion of quality of life measurement is required for comprehensive economic analysis. Economic analysis of DDP in the UK is feasible if vital nextFeasibility of reusing time-matched controls in an overlapping cohort.PubMedDelcoigne  BÃ©nÃ©dicte; Hagenbuch  Niels; Schelin  Maria Ec; Salim  Agus; LindstrÃ¶m  Linda S; Bergh  Jonas; Czene  Kamila; Reilly  Marie2018-06-01The methods developed for secondary analysis of nested case-control data have been illustrated only in simplified settings in a common cohort and have not found their way into biostatistical practice. This paper demonstrates the feasibility of reusing prior nested case-control data in a realistic setting where a new outcome is available in an overlapping cohort where no new controls were gathered and where all data have been anonymised. Using basic information about the background cohort and sampling criteria  the new cases and prior data are ""aligned"" to identify the common underlying study base. With this study base  a Kaplan-Meier table of the prior outcome extracts the risk sets required to calculate the weights to assign to the controls to remove the sampling bias. A weighted Cox regression  implemented in standard statistical software  provides unbiased hazard ratios. Using the method to compare cases of contralateral breast cancer to available controls from a prior study of metastases  we identified a multifocal tumor as a risk factor that has not been reported previously. We examine the sensitivity of the method to an imperfect weighting scheme and discuss its merits and pitfalls to provide guidance for its use in medical research studies.Feasibility of a Grocery Store Tour for Parents and Their Adolescents: A Randomized Controlled Pilot Study.PubMedNikolaus  Cassandra J; Graziose  Matthew M; Nickols-Richardson  Sharon MTo evaluate the feasibility of a grocery store tour for parents and their adolescents being led by adults or adolescent peers. Randomized controlled pilot study with surveys at baseline and post-program  and at 3- and 6-month follow-up. Midwestern midsized grocery stores. Sixty-one parents and their 71 11- to 14-year-old adolescents. Nutrition education during 1 90-minute grocery store tour. Process observations and participants' tour perceptions provided fidelity outcomes. Questionnaires quantitatively assessed participants' knowledge  self-efficacy  and tour strategy use. Chi-square and McNemar tests were used to analyze categorical data  and Kruskal-Wallis  Wilcoxon signed-rank  and Mann-Whitney U tests were employed for continuous variables (significance at PÂ <Â .05). Over 90% of tour tasks were rated as completed well for adult and peer leaders. Participants had positive tour perceptions but noted deficiencies in teen leaders' knowledge and leadership skills. Overall  parents and adolescents retained increased self-efficacy from pre-tour to post-tour intervals. Despite limited knowledge retention  parents reported they had increased (6.5Â Â±Â 4.19) healthful grocery shopping behaviors in the 6Â months after the intervention. Peers may feasibly lead grocery store tours but they may need additional resources and support to be highly effective. Copyright Â© 2017 The Authors. Published by Elsevier Inc. All rights reserved.Feasibility of conducting a randomised controlled trial of a cookstove intervention in rural MalawiPubMed CentralKachidiku  J.; Banda  H.; Kapanga  M.; Doyle  J. V.; Banda  E.; Fox  C.; Gordon  S. B.; Mortimer  K.2014-01-01BACKGROUND: Exposure to household air pollution (HAP) causes 4 million deaths annually  and strategies to reduce HAP exposure are urgently required. OBJECTIVE: To evaluate the acceptability and feasibility of conducting a trial of a cookstove intervention in rural Malawi. DESIGN: Non-smoking women were randomised to continuing to use an open fire (control) or to using a wood-burning clay cookstove (intervention). Symptom burden  oxygen saturation and exhaled carbon monoxide (eCO) were assessed at baseline and 7-day follow-up. A subset of women underwent HAP exposure monitoring. RESULTS: Of 51 women recruited  50 (98%) completed the main study. The methodology was acceptable to participants. Headache  back pain and cough were the most commonly reported symptoms at baseline and follow-up. Median eCO was within normal limits  but with a difference of 0.5 parts per million (ppm) in median change of eCO from baseline to follow-up seen between the two groups (P âˆ™ 0.035). The peak ambient CO concentration detected was 150 ppm. CONCLUSION: This study suggests that a large cookstove intervention trial in Malawi would be feasible with careful community sensitisation. Monitoring exposure to HAP is challenging  and further studies evaluating potential biomarkers of exposure  including eCO  should be undertaken. PMID:24429320The feasibility of conducting a randomised controlled trial comparing arthroscopic hip surgery to conservative care for patients with femoroacetabular impingement syndrome: the FASHIoN feasibility study.PubMedGriffin  D R; Dickenson  E J; Wall  P D H; Realpe  A; Adams  A; Parsons  N; Hobson  R; Achten  J; Costa  M L; Foster  N E; Hutchinson  C E; Petrou  S; Donovan  J L2016-10-01To determine whether it was feasible to perform a randomized controlled trial (RCT) comparing arthroscopic hip surgery to conservative care in patients with femoroacetabular impingement (FAI). This study had two phases: a pre-pilot and pilot RCT. In the pre-pilot  we conducted interviews with clinicians who treated FAI and with FAI patients to determine their views about an RCT. We developed protocols for operative and conservative care. In the pilot RCT  we determined the rates of patient eligibility  recruitment and retention  to investigate the feasibility of the protocol and we established methods to assess treatment fidelity. In the pre-pilot phase  32 clinicians were interviewed  of which 26 reported theoretical equipoise  but in example scenarios 7 failed to show clinical equipoise. Eighteen patients treated for FAI were also interviewed  the majority of whom felt that surgery and conservative care were acceptable treatments. Surgery was viewed by patients as a 'definitive solution'. Patients were motivated to participate in research but were uncomfortable about randomization. Randomization was more acceptable if the alternative was available at the end of the trial. In the pilot phase  151 patients were assessed for eligibility. Sixty were eligible and invited to take part in the pilot RCT; 42 consented to randomization. Follow-up was 100% at 12 months. Assessments of treatment fidelity were satisfactory. An RCT to compare arthroscopic hip surgery with conservative care in patients with FAI is challenging but feasible. Recruitment has started for a full RCT.Developing a placebo-controlled trial in surgery: issues of design  acceptability and feasibility.PubMedCampbell  M K; Entwistle  V A; Cuthbertson  B H; Skea  Z C; Sutherland  A G; McDonald  A M; Norrie  J D; Carlson  R V; Bridgman  S2011-02-21Surgical placebos are controversial. This in-depth study explored the design  acceptability  and feasibility issues relevant to designing a surgical placebo-controlled trial for the evaluation of the clinical and cost effectiveness of arthroscopic lavage for the management of people with osteoarthritis of the knee in the UK. Two surgeon focus groups at a UK national meeting for orthopaedic surgeons and one regional surgeon focus group (41 surgeons); plenary discussion at a UK national meeting for orthopaedic anaesthetists (130 anaesthetists); three focus groups with anaesthetists (one national  two regional; 58 anaesthetists); two focus groups with members of the patient organisation Arthritis Care (7 participants); telephone interviews with people on consultant waiting lists from two UK regional centres (15 participants); interviews with Chairs of UK ethics committees (6 individuals); postal surveys of members of the British Association of Surgeons of the Knee (382 surgeons) and members of the British Society of Orthopaedic Anaesthetists (398 anaesthetists); two centre pilot (49 patients assessed). There was widespread acceptance that evaluation of arthroscopic lavage had to be conducted with a placebo control if scientific rigour was not to be compromised. The choice of placebo surgical procedure (three small incisions) proved easier than the method of anaesthesia (general anaesthesia). General anaesthesia  while an excellent mimic  was more intrusive and raised concerns among some stakeholders and caused extensive discussion with local decision-makers when seeking formal approval for the pilot.Patients were willing to participate in a pilot with a placebo arm; although some patients when allocated to surgery became apprehensive about the possibility of receiving placebo  and withdrew. Placebo surgery was undertaken successfully. Our study illustrated the opposing and often strongly held opinions about surgical placebos  the ethical issues underpinning thisDeveloping a placebo-controlled trial in surgery: Issues of design  acceptability and feasibilityPubMed Central2011-01-01Background Surgical placebos are controversial. This in-depth study explored the design  acceptability  and feasibility issues relevant to designing a surgical placebo-controlled trial for the evaluation of the clinical and cost effectiveness of arthroscopic lavage for the management of people with osteoarthritis of the knee in the UK. Methods Two surgeon focus groups at a UK national meeting for orthopaedic surgeons and one regional surgeon focus group (41 surgeons); plenary discussion at a UK national meeting for orthopaedic anaesthetists (130 anaesthetists); three focus groups with anaesthetists (one national  two regional; 58 anaesthetists); two focus groups with members of the patient organisation Arthritis Care (7 participants); telephone interviews with people on consultant waiting lists from two UK regional centres (15 participants); interviews with Chairs of UK ethics committees (6 individuals); postal surveys of members of the British Association of Surgeons of the Knee (382 surgeons) and members of the British Society of Orthopaedic Anaesthetists (398 anaesthetists); two centre pilot (49 patients assessed). Results There was widespread acceptance that evaluation of arthroscopic lavage had to be conducted with a placebo control if scientific rigour was not to be compromised. The choice of placebo surgical procedure (three small incisions) proved easier than the method of anaesthesia (general anaesthesia). General anaesthesia  while an excellent mimic  was more intrusive and raised concerns among some stakeholders and caused extensive discussion with local decision-makers when seeking formal approval for the pilot. Patients were willing to participate in a pilot with a placebo arm; although some patients when allocated to surgery became apprehensive about the possibility of receiving placebo  and withdrew. Placebo surgery was undertaken successfully. Conclusions Our study illustrated the opposing and often strongly held opinions about surgical placebosFeasibility of using phase change materials to control the heat of hydration in massive concrete structures.PubMedChoi  Won-Chang; Khil  Bae-Soo; Chae  Young-Seok; Liang  Qi-Bo; Yun  Hyun-Do2014-01-01This paper presents experimental results that can be applied to select a possible phase change material (PCM)  such as a latent heat material (LHM)  to control the hydration heat in mass concrete structures. Five experimental tests (microconduction  simplified adiabatic temperature rise  heat  and compressive strength tests) were conducted to select the most desirable LHM out of seven types of inorganic PCM used in cement mortar and to determine the most suitable mix design. The results of these experimental tests were used to assess the feasibility of using PCM to reduce hydration heat in mass concrete that was examined. The experimental results show that cement mortar containing barium- [Ba(OH)2 Â· 8H2O] based PCM has the lowest amount of total hydration heat of the cement pastes. The barium-based PCM provides good latent heat properties that help to prevent volume change and microcracks caused by thermal stress in mass concrete.Feasibility of controlling speed-dependent low-frequency brake vibration amplification by modulating actuation pressureNASA Astrophysics Data System (ADS)Sen  Osman Taha; Dreyer  Jason T.; Singh  Rajendra2014-12-01In this article  a feasibility study of controlling the low frequency torque response of a disc brake system with modulated actuation pressure (in the open loop mode) is conducted. First  a quasi-linear model of the torsional system is introduced  and analytical solutions are proposed to incorporate the modulation effect. Tractable expressions for three different modulation schemes are obtained  and conditions that would lead to a reduction in the oscillatory amplitudes are identified. Second  these conditions are evaluated with a numerical model of the torsional system with clearance nonlinearity  and analytical solutions are verified in terms of the trends observed. Finally  a laboratory experiment with a solenoid valve is built to modulate actuation pressure with a constant duty cycle  and time-frequency domain data are acquired. Measurements are utilized to assess analytical observations  and all methods show that the speed-dependent brake torque amplitudes can be altered with an appropriate modulation of actuation pressure.Economic Benefit for Cuban Laurel Thrips Biological Control.PubMedShogren  C; Paine  T D2016-02-01The Cuban laurel thrips  Gynaikothrips ficorum Marchal (Thysanoptera: Phlaeothripidae)  is a critical insect pest of Ficus microcarpa in California urban landscapes and production nurseries. Female thrips feed and oviposit on young Ficus leaves  causing the expanding leaves to fold or curl into a discolored leaf gall. There have been attempts to establish specialist predator natural enemies of the thrips  but no success has been reported. We resampled the same areas in 2013-2014 where we had released Montandoniola confusa (= morguesi) Streito and Matocq (Hemiptera: Anthocoridae) in southern California in 1995 but had been unable to recover individuals in 1997-1998. Thrips galls were significantly reduced in all three of the locations in the recent samples compared with the earlier samples. M. confusa was present in all locations and appears to be providing successful biological control. The value of the biological control  the difference between street trees in good foliage condition and trees with poor foliage  was $58 766 166. If thrips damage reduced the foliage to very poor condition  the value of biological control was $73 402 683. Total cost for the project was $61 830. The benefit accrued for every dollar spent on the biological control of the thrips ranged from $950  if the foliage was in poor condition  to $1 187  if the foliage was in very poor condition. The value of urban forest is often underappreciated. Economic analyses that clearly demonstrate the very substantial rates of return on investment in successful biological control in urban forests provide compelling arguments for supporting future efforts. Â© The Authors 2015. Published by Oxford University Press on behalf of Entomological Society of America. All rights reserved. For Permissions  please email: journals.permissions@oup.com.Feasibility of a multicentre  randomised controlled trial of laparoscopic versus open colorectal surgery in the acute setting: the LaCeS feasibility trial protocol.PubMedHarji  Deena; Marshall  Helen; Gordon  Katie; Crow  Hannah; Hiley  Victoria; Burke  Dermot; Griffiths  Ben; Moriarty  Catherine; Twiddy  Maureen; O'Dwyer  John L; Verjee  Azmina; Brown  Julia; Sagar  Peter2018-02-22Acute colorectal surgery forms a significant proportion of emergency admissions within the National Health Service. There is limited evidence to suggest minimally invasive surgery may be associated with improved clinical outcomes in this cohort of patients. Consequently  there is a need to assess the clinical effectiveness and cost-effectiveness of laparoscopic surgery in the acute colorectal setting. However emergency colorectal surgical trials have previously been difficult to conduct due to issues surrounding recruitment and equipoise. The LaCeS (randomised controlled trial of Laparoscopic versus open Colorectal Surgery in the acute setting) feasibility trial will determine the feasibility of conducting a definitive  phase III trial of laparoscopic versus open acute colorectal resection. The LaCeS feasibility trial is a prospective  multicentre  single-blinded  parallel group  pragmatic randomised controlled feasibility trial. Patients will be randomised on a 1:1 basis to receive eitherlaparoscopic or open surgery. The trial aims to recruit at least 66 patients from five acute general surgical units across the UK. Patients over the age of 18 with a diagnosis of acute colorectal pathology requiring resection on clinical and radiological/endoscopic investigations  with a National Confidential Enquiry into Patient Outcome and Death classification of urgent will be considered eligible for participation. The primary outcome is recruitment. Secondary outcomes include assessing the safety profile of laparoscopic surgery using intraoperative and postoperative complication rates  conversion rates and patient-safety indicators as surrogate markers. Clinical and patient-reported outcomes will also be reported. The trial will contain an embedded qualitative study to assess clinician and patient acceptability of trial processes. The LaCeS feasibility trial is approved by the Yorkshire and The Humber  Bradford Leeds Research Ethics Committee (REC reference: 15/ YH/0542). TheAcceptability and feasibility of the 'DASH for Asthma' intervention in a randomized controlled trial pilot study.PubMedBlonstein  Andrea C; Lv  Nan; Camargo  Carlos A; Wilson  Sandra R; Buist  A Sonia; Rosas  Lisa G; Strub  Peg; Ma  Jun2016-08-01'DASH for Asthma' (n 90) was a 6-month randomized controlled trial that demonstrated potential benefits of a DASH (Dietary Approaches to Stop Hypertension) behavioural intervention for improving diet quality and asthma control by comparing intervention to usual care in adults with uncontrolled asthma. The present study examined acceptability and feasibility of the intervention from the perspective of intervention participants and lifestyle coaches. Grounded in Social Cognitive Theory  the 3-month intensive stage  including three individual and eight group sessions  focused on diet modifications and behavioural self-regulation. The 3-month maintenance stage contained telephone consultations. Participants and lifestyle coaches completed surveys including 5-point Likert scales and open-ended questions. We analysed data using descriptive and inductive content analyses. Forty-six intervention participants (survey response rate was 65-72 %) and two lifestyle coaches. Participants and lifestyle coaches were highly satisfied (all mean ratings >4) with individual and group sessions. Participants identified mastery of knowledge and skills (awareness  goal setting  self-monitoring  problem solving)  social learning (class members sharing experiences and ideas) and good coaching skills (reflective listening  empathy  motivational counselling) as important contributors to self-efficacy and programme satisfaction. Participants also valued personalized feedback received in individual sessions. Lifestyle coaches viewed participant engagement as a facilitator to effective sessions. Finally  participants and lifestyle coaches identified food tasting as beneficial for observational learning and facilitation of participant engagement. High class attendance and self-monitoring rate also reflected the high engagement among participants. The DASH behavioural intervention was feasible and highly acceptable to participants with uncontrolled asthma and lifestyle coaches.Heavy Lift Helicopter Flight Control System. Volume III. Automatic Flight Control System Development and Feasibility DemonstrationDTIC Science & Technology1977-09-01vdI1 SCCLRITY CLASSIFICATIOlN OF THIS PAGE(When DMae ffnifod) Block 20 (Cont): ------ AFCS control laws are examined. Associated documents are: Volume I...both the HII gain and LO gain outputs. Both were traced to defective components. In the former  the HII gain output amplifier AR4 was replaced and in...the latter  a relay in the relay module was defective . 613 S. . ......-. . . 6.2.2.4 ExcessivC Time Lag During the BARO altitude hold evaluation  theComputer Program for Assessing the Economic Feasibility of Solar Energy for Single Family Residences and Light Commercial ApplicationsNASA Technical Reports Server (NTRS)Forney  J. A.; Walker  D.; Lanier  M.1979-01-01Computer program  SHCOST  was used to perform economic analyses of operational test sites. The program allows consideration of the economic parameters which are important to the solar system user. A life cycle cost and cash flow comparison is made between a solar heating system and a conventional system. The program assists in sizing the solar heating system. A sensitivity study and plot capability allow the user to select the most cost effective system configuration.A feasibility randomised controlled trial of a motivational interviewing-based intervention for weight loss maintenance in adults.PubMedSimpson  Sharon A; McNamara  Rachel; Shaw  Christine; Kelson  Mark; Moriarty  Yvonne; Randell  Elizabeth; Cohen  David; Alam  M Fasihul; Copeland  Lauren; Duncan  Donna; Espinasse  Aude; Gillespie  David; Hill  Andy; Owen-Jones  Eleri; Tapper  Katy; Townson  Julia; Williams  Simon; Hood  Kerry2015-07-01. Economic analysis aimed to assess cost-effectiveness in terms of quality-adjusted life-years (QALYs). A total of 170 participants were randomised. Retention was good (84%) and adherence was excellent (intensive  83%; less intensive  91%). The between-group difference in mean BMI indicated the intensive arm had BMIs 1.0â€‰kg/m(2) lower than the controls [95% confidence interval (CI) -2.2 kg/m(2) to 0.2â€‰kg/m(2)]. Similarly  a potential difference was found in weight (average difference of 2.8â€‰kg  95% CI -6.1 kg to 0.5â€‰kg). The intensive arm had odds of maintaining on average 43% [odds ratio(OR) 1.4  95% CI 0.6 to 3.5] higher than controls. None of these findings were statistically significant. Further analyses controlling for level of adherence indicated that average BMI was 1.2â€‰kg/m(2) lower in the intensive arm than the control arm (95% CI -2.5â€‰kg/m(2) to 0.0â€‰kg/m(2)). The intensive intervention led to a statistically significant difference in weight (mean -3.7â€‰kg  95% CI -7.1â€‰kg to -0.3â€‰kg). The other secondary outcomes showed limited evidence of differences between groups. The intervention was delivered as planned  and both practitioners and participants were positive about the intervention and its impact. Although not powered to assess cost-effectiveness  results of this feasibility study suggest that neither intervention as currently delivered is likely to be cost-effective in routine practice. This is the first trial of an intervention for WLM in the UK  the intervention is feasible and acceptable  and retention and adherence were high. The main effectiveness outcome showed a promising mean difference in the intensive arm. Owing to the small sample size  we are limited in the conclusions we can draw. However  findings suggest that the intensive intervention may facilitate long-term weight maintenance and  therefore  further testing in an effectiveness trial may be indicated. Research examining WLM is in its infancy  further research is needed toFeasibility Study of Economics and Performance of Solar PV at the Atlas Industrial Park in Duluth  MinnesotaSciTech ConnectSteen  M.; Lisell  L.; Mosey  G.The U.S. Environmental Protection Agency (EPA) Region 5  in accordance with the RE-Powering America's Land initiative  selected the Atlas Industrial Park in Duluth  Minnesota  for a feasibility study of renewable energy production. The EPA provided funding to the National Renewable Energy Laboratory (NREL) to support a feasibility study of solar renewable energy generation at the Atlas Industrial Park. NREL provided technical assistance for this project but did not assess environmental conditions at the site beyond those related to the performance of a photovoltaic (PV) system. The purpose of this study is to assess the site for a possible PV installationmoreÂ Â» and estimate the cost  performance  and site impacts of different PV configurations. In addition  the study evaluates financing options that could assist in the implementation of a PV system at the site.Â«Â lessCulturally adaptive storytelling intervention versus didactic intervention to improve hypertension control in Vietnam: a cluster-randomized controlled feasibility trial.PubMedNguyen  Hoa L; Allison  Jeroan J; Ha  Duc A; Chiriboga  GermÃ¡n; Ly  Ha N; Tran  Hanh T; Nguyen  Cuong K; Dang  Diem M; Phan  Ngoc T; Vu  Nguyen C; Nguyen  Quang P; Goldberg  Robert J2017-01-01Vietnam is experiencing an epidemiologic transition with an increased prevalence of non-communicable diseases. Novel  large-scale  effective  and sustainable interventions to control hypertension in Vietnam are needed. We report the results of a cluster-randomized feasibility trial at 3Â months follow-up conducted in Hung Yen province  Vietnam  designed to evaluate the feasibility and acceptability of two community-based interventions to improve hypertension control: a ""storytelling"" intervention  ""We Talk about Our Hypertension "" and a didactic intervention. The storytelling intervention included stories about strategies for coping with hypertension  with patients speaking in their own words  and didactic content about the importance of healthy lifestyle behaviors including salt reduction and exercise. The didactic intervention included only didactic content. The storytelling intervention was delivered by two DVDs at 3-month intervals; the didactic intervention included only one installment. The trial was conducted in four communes  equally randomized to the two interventions. The mean age of the 160 study patients was 66Â years  and 54% were men. Most participants described both interventions as understandable  informative  and motivational. Between baseline and 3Â months  mean systolic blood pressure declined by 8.2Â mmHg (95% CI 4.1-12.2) in the storytelling group and by 5.5Â mmHg (95% CI 1.4-9.5) in the didactic group. The storytelling group also reported a significant increase in hypertension medication adherence. Both interventions were well accepted in several rural communities and were shown to be potentially effective in lowering blood pressure. A large-scale randomized trial is needed to compare the effectiveness of the two interventions in controlling hypertension. ClinicalTrials.gov  NCT02483780.Future Tense and Economic Decisions: Controlling for Cultural EvolutionPubMed CentralRoberts  SeÃ¡n G.; Winters  James; Chen  Keith2015-01-01A previous study by Chen demonstrates a correlation between languages that grammatically mark future events and their speakers' propensity to save  even after controlling for numerous economic and demographic factors. The implication is that languages which grammatically distinguish the present and the future may bias their speakers to distinguish them psychologically  leading to less future-oriented decision making. However  Chen's original analysis assumed languages are independent. This neglects the fact that languages are related  causing correlations to appear stronger than is warranted (Galton's problem). In this paper  we test the robustness of Chen's correlations to corrections for the geographic and historical relatedness of languages. While the question seems simple  the answer is complex. In general  the statistical correlation between the two variables is weaker when controlling for relatedness. When applying the strictest tests for relatedness  and when data is not aggregated across individuals  the correlation is not significant. However  the correlation did remain reasonably robust under a number of tests. We argue that any claims of synchronic patterns between cultural variables should be tested for spurious correlations  with the kinds of approaches used in this paper. However  experiments or case-studies would be more fruitful avenues for future research on this specific topic  rather than further large-scale cross-cultural correlational studies. PMID:26186527Future Tense and Economic Decisions: Controlling for Cultural Evolution.PubMedRoberts  SeÃ¡n G; Winters  James; Chen  Keith2015-01-01A previous study by Chen demonstrates a correlation between languages that grammatically mark future events and their speakers' propensity to save  even after controlling for numerous economic and demographic factors. The implication is that languages which grammatically distinguish the present and the future may bias their speakers to distinguish them psychologically  leading to less future-oriented decision making. However  Chen's original analysis assumed languages are independent. This neglects the fact that languages are related  causing correlations to appear stronger than is warranted (Galton's problem). In this paper  we test the robustness of Chen's correlations to corrections for the geographic and historical relatedness of languages. While the question seems simple  the answer is complex. In general  the statistical correlation between the two variables is weaker when controlling for relatedness. When applying the strictest tests for relatedness  and when data is not aggregated across individuals  the correlation is not significant. However  the correlation did remain reasonably robust under a number of tests. We argue that any claims of synchronic patterns between cultural variables should be tested for spurious correlations  with the kinds of approaches used in this paper. However  experiments or case-studies would be more fruitful avenues for future research on this specific topic  rather than further large-scale cross-cultural correlational studies.Economic implications of three strategies for the control of taeniasis.PubMedAlexander  Anu; John  K R; Jayaraman  T; Oommen  Anna; Venkata Raghava  M; Dorny  Pierre; Rajshekhar  Vedantam2011-11-01To evaluate the cost-effectiveness of three strategies for the control of taeniasis in a community  in terms of cost per case treated. A study was conducted in South India to determine the prevalence of taeniasis by screening stool samples from 653 randomly chosen subjects  for coproantigens. The costs incurred in the project were used to estimate the cost per case screened and treated. A one-way sensitivity analysis was carried out for varying rates of taeniasis  different screening strategies and mass therapy. Further sensitivity analysis was carried out with different manpower and test costs. The rate of taeniasis as detected by ELISA for coproantigen was 3 per 1000 (2 of 653 samples). Our study showed that mass therapy without screening for taeniasis would be the most economical strategy in terms of cost per case treated if field workers are employed exclusively for either mass therapy or screening. For each strategy  costs per case treated are higher at low prevalence of taeniasis  with a sharp rise below 15%. In places that are endemic for taeniasis and neurocysticercosis  mass therapy or screening for taeniasis should be considered. Screening by stool microscopy is not cost-effective in terms of cost per case of taeniasis treated owing to its low sensitivity. Although the cost per case of taeniasis treated is high at low prevalence of taeniasis for all options  incorporating mass therapy into existing mass drug distribution programmes might prove to be the most cost-effective control strategy. Â© 2011 Blackwell Publishing Ltd.Safety and feasibility of transcranial direct current stimulation in pediatric hemiparesis: randomized controlled preliminary study.PubMedGillick  Bernadette T; Feyma  Tim; Menk  Jeremiah; Usset  Michelle; Vaith  Amy; Wood  Teddi Jean; Worthington  Rebecca; Krach  Linda E2015-03-01Transcranial direct current stimulation (tDCS) is a form of noninvasive brain stimulation that has shown improved adult stroke outcomes. Applying tDCS in children with congenital hemiparesis has not yet been explored. The primary objective of this study was to explore the safety and feasibility of single-session tDCS through an adverse events profile and symptom assessment within a double-blind  randomized placebo-controlled preliminary study in children with congenital hemiparesis. A secondary objective was to assess the stability of hand and cognitive function. A double-blind  randomized placebo-controlled pretest/posttest/follow-up study was conducted. The study was conducted in a university pediatric research laboratory. Thirteen children  ages 7 to 18 years  with congenital hemiparesis participated. Adverse events/safety assessment and hand function were measured. Participants were randomly assigned to either an intervention group or a control group  with safety and functional assessments at pretest  at posttest on the same day  and at a 1-week follow-up session. An intervention of 10 minutes of 0.7 mA tDCS was applied to bilateral primary motor cortices. The tDCS intervention was considered safe if there was no individual decline of 25% or group decline of 2 standard deviations for motor evoked potentials (MEPs) and behavioral data and no report of adverse events. No major adverse events were found  including no seizures. Two participants did not complete the study due to lack of MEP and discomfort. For the 11 participants who completed the study  group differences in MEPs and behavioral data did not exceed 2 standard deviations in those who received the tDCS (n=5) and those in the control group (n=6). The study was completed without the need for stopping per medical monitor and biostatisticial analysis. A limitation of the study was the small sample size  with data available for 11 participants. Based on the results of this study  tDCS appears to be safeSafety and Feasibility of Transcranial Direct Current Stimulation in Pediatric Hemiparesis: Randomized Controlled Preliminary StudyPubMed CentralFeyma  Tim; Menk  Jeremiah; Usset  Michelle; Vaith  Amy; Wood  Teddi Jean; Worthington  Rebecca; Krach  Linda E.2015-01-01Background Transcranial direct current stimulation (tDCS) is a form of noninvasive brain stimulation that has shown improved adult stroke outcomes. Applying tDCS in children with congenital hemiparesis has not yet been explored. Objective The primary objective of this study was to explore the safety and feasibility of single-session tDCS through an adverse events profile and symptom assessment within a double-blind  randomized placebo-controlled preliminary study in children with congenital hemiparesis. A secondary objective was to assess the stability of hand and cognitive function. Design A double-blind  randomized placebo-controlled pretest/posttest/follow-up study was conducted. Setting The study was conducted in a university pediatric research laboratory. Participants Thirteen children  ages 7 to 18 years  with congenital hemiparesis participated. Measurements Adverse events/safety assessment and hand function were measured. Intervention Participants were randomly assigned to either an intervention group or a control group  with safety and functional assessments at pretest  at posttest on the same day  and at a 1-week follow-up session. An intervention of 10 minutes of 0.7 mA tDCS was applied to bilateral primary motor cortices. The tDCS intervention was considered safe if there was no individual decline of 25% or group decline of 2 standard deviations for motor evoked potentials (MEPs) and behavioral data and no report of adverse events. Results No major adverse events were found  including no seizures. Two participants did not complete the study due to lack of MEP and discomfort. For the 11 participants who completed the study  group differences in MEPs and behavioral data did not exceed 2 standard deviations in those who received the tDCS (n=5) and those in the control group (n=6). The study was completed without the need for stopping per medical monitor and biostatisticial analysis. Limitations A limitation of the study was the small sample size  with dataIdentifying continence options after stroke (ICONS): a cluster randomised controlled feasibility trial.PubMedThomas  Lois H; Watkins  Caroline L; Sutton  Christopher J; Forshaw  Denise; Leathley  Michael J; French  Beverley; Burton  Christopher R; Cheater  Francine; Roe  Brenda; Britt  David; Booth  Joanne; McColl  Elaine2014-12-23Urinary incontinence (UI) affects half of patients hospitalised after stroke and is often poorly managed. Cochrane systematic reviews have shown some positive impact of conservative interventions (such as bladder training) in reducing UI  but their effectiveness has not been demonstrated with stroke patients. We conducted a cluster randomised controlled feasibility trial of a systematic voiding programme (SVP) for the management of UI after stroke. Stroke services were randomised to receive SVP (nâ€‰=â€‰4)  SVP plus supported implementation (SVP+  nâ€‰=â€‰4)  or usual care (UC  nâ€‰=â€‰4).Feasibility outcomes were participant recruitment and retention. The main effectiveness outcome was presence or absence of UI at six and 12 weeks post-stroke. Additional effectiveness outcomes included were the effect of the intervention on different types of UI  continence status at discharge  UI severity  functional ability  quality of life  and death. It was possible to recruit patients (413; 164 SVP  125 SVP+  and 124 UC) and participant retention was acceptable (85% and 88% at six and 12 weeks  respectively). There was no suggestion of a beneficial effect on the main outcome at six (SVP versus UC: odds ratio (OR) 0.94  95% CI: 0.46 to 1.94; SVP+ versus UC: OR: 0.62  95% CI: 0.28 to 1.37) or 12 weeks (SVP versus UC: OR: 1.02  95% CI: 0.54 to 1.93; SVP+ versus UC: OR: 1.06  95% CI: 0.54 to 2.09).No secondary outcomes showed a strong suggestion of clinically meaningful improvement in SVP and/or SVP+ arms relative to UC at six or 12 weeks. However  at 12 weeks both intervention arms had higher estimated odds of continence than UC for patients with urge incontinence. The trial has met feasibility outcomes of participant recruitment and retention. It was not powered to demonstrate effectiveness  but there is some evidence of a potential reduction in the odds of specific types of incontinence. A full trial should now be considered. ISRCTN Registry  ISRCTN08609907  date ofInteractive web-based pulmonary rehabilitation programme: a randomised controlled feasibility trialPubMed CentralChaplin  Emma; Hewitt  Stacey; Apps  Lindsay; Bankart  John; Pulikottil-Jacob  Ruth; Boyce  Sally; Morgan  Mike; Williams  Johanna; Singh  Sally2017-01-01Objectives The aim of this study was to determine if an interactive web-based pulmonary rehabilitation (PR) programme is a feasible alternative to conventional PR. Design Randomised controlled feasibility trial. Setting Participants with a diagnosis of chronic obstructive pulmonary disease were recruited from PR assessments  primary care and community rehabilitation programmes. Patients randomised to conventional rehabilitation started the programme according to the standard care at their referred site on the next available date. Participants 103 patients were recruited to the study and randomised: 52 to conventional rehabilitation (mean (Â±SD) age 66 (Â±8) years  Medical Research Council (MRC) 3 (IQR2â€“4)); 51 to the web arm (mean (Â±SD) age 66 (Â±10) years  MRC 3 (IQR2â€“4)). Participants had to be willing to participate in either arm of the trial  have internet access and be web literate. Interventions Patients randomised to the web-based programme worked through the website  exercising and recording their progress as well as reading educational material. Conventional PR consisted of twice weekly  2 hourly sessions (an hour for exercise training and an hour for education). Outcome measures Recruitment rates  eligibility  patient preference and dropout and completion rates for both programmes were collected. Standard outcomes for a PR assessment including measures of exercise capacity and quality of life questionnaires were also evaluated. Results A statistically significant improvement (pâ‰¤0.01) was observed within each group in the endurance shuttle walk test (WEB: mean change 189Â±211.1; PR classes: mean change 184.5Â±247.4â€…s) and Chronic Respiratory disease Questionnaire-Dyspnoea (CRQ-D; WEB: mean change 0.7Â±1.2; PR classes: mean change 0.8Â±1.0). However  there were no significant differences between the groups in any outcome. Dropout rates were higher in the web-based programme (57% vs 23%). Conclusions An interactive web-based PR programme is feasibleInteractive web-based pulmonary rehabilitation programme: a randomised controlled feasibility trial.PubMedChaplin  Emma; Hewitt  Stacey; Apps  Lindsay; Bankart  John; Pulikottil-Jacob  Ruth; Boyce  Sally; Morgan  Mike; Williams  Johanna; Singh  Sally2017-03-31The aim of this study was to determine if an interactive web-based pulmonary rehabilitation (PR) programme is a feasible alternative to conventional PR. Randomised controlled feasibility trial. Participants with a diagnosis of chronic obstructive pulmonary disease were recruited from PR assessments  primary care and community rehabilitation programmes. Patients randomised to conventional rehabilitation started the programme according to the standard care at their referred site on the next available date. 103 patients were recruited to the study and randomised: 52 to conventional rehabilitation (mean (Â±SD) age 66 (Â±8) years  Medical Research Council (MRC) 3 (IQR2-4)); 51 to the web arm (mean (Â±SD) age 66 (Â±10) years  MRC 3 (IQR2-4)). Participants had to be willing to participate in either arm of the trial  have internet access and be web literate. Patients randomised to the web-based programme worked through the website  exercising and recording their progress as well as reading educational material. Conventional PR consisted of twice weekly  2 hourly sessions (an hour for exercise training and an hour for education). Recruitment rates  eligibility  patient preference and dropout and completion rates for both programmes were collected. Standard outcomes for a PR assessment including measures of exercise capacity and quality of life questionnaires were also evaluated. A statistically significant improvement (pâ‰¤0.01) was observed within each group in the endurance shuttle walk test (WEB: mean change 189Â±211.1; PR classes: mean change 184.5Â±247.4â€…s) and Chronic Respiratory disease Questionnaire-Dyspnoea (CRQ-D; WEB: mean change 0.7Â±1.2; PR classes: mean change 0.8Â±1.0). However  there were no significant differences between the groups in any outcome. Dropout rates were higher in the web-based programme (57% vs 23%). An interactive web-based PR programme is feasible and acceptable when compared with conventional PR. Future trials maybe around choice-based PRControl of water distribution networks with dynamic DMA topology using strictly feasible sequential convex programmingNASA Astrophysics Data System (ADS)Wright  Robert; Abraham  Edo; Parpas  Panos; Stoianov  Ivan2015-12-01The operation of water distribution networks (WDN) with a dynamic topology is a recently pioneered approach for the advanced management of District Metered Areas (DMAs) that integrates novel developments in hydraulic modeling  monitoring  optimization  and control. A common practice for leakage management is the sectorization of WDNs into small zones  called DMAs  by permanently closing isolation valves. This facilitates water companies to identify bursts and estimate leakage levels by measuring the inlet flow for each DMA. However  by permanently closing valves  a number of problems have been created including reduced resilience to failure and suboptimal pressure management. By introducing a dynamic topology to these zones  these disadvantages can be eliminated while still retaining the DMA structure for leakage monitoring. In this paper  a novel optimization method based on sequential convex programming (SCP) is outlined for the control of a dynamic topology with the objective of reducing average zone pressure (AZP). A key attribute for control optimization is reliable convergence. To achieve this  the SCP method we propose guarantees that each optimization step is strictly feasible  resulting in improved convergence properties. By using a null space algorithm for hydraulic analyses  the computations required are also significantly reduced. The optimized control is actuated on a real WDN operated with a dynamic topology. This unique experimental program incorporates a number of technologies set up with the objective of investigating pioneering developments in WDN management. Preliminary results indicate AZP reductions for a dynamic topology of up to 6.5% over optimally controlled fixed topology DMAs. This article was corrected on 12 JAN 2016. See the end of the full text for details.Eradication versus control for poliomyelitis: an economic analysis.PubMedThompson  Kimberly M; Tebbens  Radboud J Duintjer2007-04-21Worldwide eradication of wild polioviruses is likely to yield substantial health and financial benefits  provided we finish the job. Challenges in the four endemic areas combined with continuing demands for financial resources for eradication have led some to question the goal of eradication and to suggest switching to a policy of control. We developed a dynamic model  based on modelling of the currently endemic areas in India  to show the importance of maintaining and increasing the immunisation intensity to complete eradication and to illustrate how policies based on perception about high short-term costs or cost-effectiveness ratios without consideration of long-term benefits could undermine any eradication effort. An extended model assesses the economic implications and disease burden of a change in policy from eradication to control. Our results suggest that the intensity of immunisation must be increased to achieve eradication  and that even small decreases in intensity could lead to large outbreaks. This finding implies the need to pay even higher short-run costs than are currently being spent  which will further exacerbate concerns about continued investment in interventions with high perceived cost-effectiveness ratios. We show that a wavering commitment leads to a failure to eradicate  greater cumulative costs  and a much larger number of cases. We further show that as long as it is technically achievable  eradication offers both lower cumulative costs and cases than control  even with the costs of achieving eradication exceeding several billion dollars more. A low-cost control policy that relies only on routine immunisation for 20 years with discounted costs of more than $3500 million could lead to roughly 200 000 expected paralytic poliomyelitis cases every year in low-income countries  whereas a low-case control policy that keeps the number of cases at about 1500 per year could cost around $10 000 million discounted over the 20 years. Focusing on theVirtual Reality Exposure Therapy for the Treatment of Dental Phobia: A Controlled Feasibility Study.PubMedGujjar  Kumar Raghav; van Wijk  Arjen; Sharma  Ratika; de Jongh  Ad2018-05-01Virtual reality exposure therapy (VRET) has been used to treat a variety of fears and phobias. To determine the feasibility (i.e. safety and efficacy) of using VRET to treat dental phobia. Safety was evaluated by determining any adverse events or symptom exacerbation. Efficacy of VRET was evaluated by comparing the reduction in dental anxiety scores (measured 16 times within a 14-week study period  and at 6-month follow-up)  and its behavioural effects with that of an informational pamphlet (IP) on ten randomized patients with dental phobia using a controlled multiple baseline design. Participants' heart rate response during VRET  and their experience post-VRET  were indexed. No personal adverse events or symptom exacerbation occurred. Visual analysis and post-hoc intention-to-treat analysis showed a significantly greater decrease in dental anxiety scores [higher PND (percentage of non-overlap data) scores of 100% and lower POD (percentage of overlap data) of 0%  Modified Dental Anxiety Scale  F (1 8) = 8.61  p = 0.019  and Dental Fear Scale  F (1 8) = 10.53  p = 0.012]  and behavioural avoidance in the VRET compared with the IP group [d = 4.2 and -1.4  respectively). There was no increase in average heart rate during VRET. Of the nine treatment completers  six (four from the VRET group and two from the IP group) no longer had dental phobia at 6-month follow-up. Four of the five VRET participants  but none of the IP participants  scheduled a dental treatment appointment following the intervention. VRET is a feasible alternative for patients with dental phobia.Active Breathing Control for Hodgkin's Disease in Childhood and Adolescence: Feasibility  Advantages  and LimitsSciTech ConnectClaude  Line; Malet  Claude Phys.; Pommier  Pascal2007-04-01Purpose: The challenge in early Hodgkin's disease (HD) in children is to maintain good survival rates while sparing organs at risk. This study assesses the feasibility of active breathing control (ABC) in children  and compares normal tissue irradiation with and without ABC. Methods and Materials: Between May 2003 and June 2004  seven children with HD with mediastinal involvement  median age 15  were treated by chemotherapy and involved-field radiation therapy. A free-breathing computed tomography simulation scan and one additional scan during deep inspiration using ABC were performed. A comparison between planning treatment with clinical target volume including supraclavicular regions  mediastinum  andmoreÂ Â» hila was performed  both in free breathing and using ABC. Results: For a prescription of 36 Gy  pulmonary dose-volume histograms revealed a mean reduction in lung volume irradiated at more than 20 Gy (V20) and 30 Gy (V30) of 25% and 26%  respectively  using ABC (p = 0.016). The mean volume of heart irradiated at 30 Gy or more decreased from 15% to 12% (nonsignificant). The mean dose delivered to breasts in girls was small in both situations (less than 2 Gy) and stable with or without ABC. Considering axillary irradiation  the mean dose delivered to breasts remained low (<9 Gy)  without significant difference using ABC or not. The mean radiation dose delivered to thyroid was stable using ABC or not. Conclusions: Using ABC is feasible in childhood. The use of ABC decreases normal lung tissue irradiation. Concerning heart irradiation  a minimal gain is also shown. No significant change has been demonstrated concerning breast and thyroid irradiation.Â«Â lessEconomics of cutting wood parts with a laser under optical image analyzer controlTreesearchHenry E. Huber; Charles W. McMillin; Arthur Rasher1982-01-01A financial analysis using discounted cash-flow techniques was used to determine the economic feasibility of a new laser lumber processing system for use in a furniture rough mill. The projected cost of the system was $790 000 which would replace conventional crosscut and ripsaws costing $256 856. A financial analysis was made assuming only a 5 percent yield increase...Economics.PubMedPalley  Paul D; Parcero  Miriam E2015-10-01A review of literature during calendar year 2014 focused on environmental policies and sustainable development  and economic policies. This review is divided into these sections: sustainable development  irrigation  ecosystems and water management  climate change and disaster risk management  economic growth  water supply policies  water consumption  water price regulation  and water price valuation.Economics.PubMedPalley  Paul D; Parcero  Miriam E2016-10-01A review of literature in the calendar year 2015 dedicated to environmental policies and sustainable development  and economic policies. This review is divided into these sections: sustainable development  irrigation  ecosystems and water management  climate change and disaster risk management  economic growth  water supply policies  water consumption  water price regulation  and water price valuation.The economics of tobacco control: evidence from the International Tobacco Control (ITC) Policy Evaluation Project.PubMedTauras  John A; Chaloupka  Frank J; Quah  Anne Chiew Kin; Fong  Geoffrey T2014-03-01Over the past few decades  the importance of economic research in advancing tobacco control policies has become increasingly clear. Extensive research has demonstrated that increasing tobacco taxes and prices is the single most cost-effective tobacco control measure. The research contained in this supplement adds to this evidence and provides new insights into how smokers respond to tax and price changes using the rich data on purchase behaviours  brand choices  tax avoidance and evasion  and tobacco use collected systematically and consistently across countries and over time by the International Tobacco Control (ITC) Project. The findings from this research will help inform policymakers  public health professionals  advocates  and others seeking to maximise the public health and economic benefits from higher taxes.Physiotherapy Post Lumbar Discectomy: Prospective Feasibility and Pilot Randomised Controlled TrialPubMed CentralRushton  Alison; Goodwin  Peter C.2015-01-01Objectives To evaluate: acceptability and feasibility of trial procedures; distribution of scores on the Roland Morris Disability Questionnaire (RMDQ  planned primary outcome); and efficient working of trial components. Design and Setting A feasibility and external pilot randomised controlled trial (ISRCTN33808269  assigned 10/12/2012) was conducted across 2 UK secondary care outpatient physiotherapy departments associated with regional spinal surgery centres. Participants Consecutive consenting patients aged >18 years; post primary  single level  lumbar discectomy. Interventions Participants were randomised to either 1:1 physiotherapy outpatient management including patient leaflet  or patient leaflet alone. Main Outcome Measures Blinded assessments were made at 4 weeks post surgery (baseline) and 12 weeks post baseline (proposed primary end point). Secondary outcomes included: Global Perceived Effect  back/leg pain  straight leg raise  return to work/function  quality of life  fear avoidance  range of movement  medication  re-operation. Results At discharge  110 (44%) eligible patients gave consent to be contacted. 59 (54%) patients were recruited. Loss to follow up was 39% at 12 weeks  with one site contributing 83% losses. Mean (SD) RMDQ was 10.07 (5.58) leaflet and 10.52 (5.94) physiotherapy/leaflet at baseline; and 5.37 (4.91) leaflet and 5.53 (4.49) physiotherapy/leaflet at 12 weeks. 5.1% zero scores at 12 weeks illustrated no floor effect. Sensitivity to change was assessed at 12 weeks with mean (SD) change -4.53 (6.41)  95%CI -7.61 to -1.44 for leaflet; and -6.18 (5.59)  95%CI -9.01 to -3.30 for physiotherapy/leaflet. RMDQ mean difference (95%CI) between change from baseline to twelve weeks was 1.65(-2.46 to 5.75). Mean difference (95%CI) between groups at 12 weeks was -0.16 (-3.36 to 3.04). Participant adherence with treatment was good. No adverse events were reported. Conclusions Both interventions were acceptable  and it is promising that they bothIncreasing Opportunities for Inner-City Youth: The Feasibility of an Economic Empowerment Model in East Harlem and the South Bronx  New York*PubMed CentralSsewamala  Fred M.; Sperber  Elizabeth; Blake  Clair A.; Ilic  Vilma P.2011-01-01Youth of color are disproportionately likely to grow-up in poor  disadvantaged neighborhoods characterized by high levels of psychosocial stressors and inadequate supportive resources. Poverty and racial minority status correlate with an increased risk of high-school dropout  teen pregnancy  substance abuse  and sexually transmitted infections (STIs). Given these trends  child welfare researchers are developing various interventions to increase the protective resources and social opportunities available to youth of color. This article reports results of a preliminary  qualitative study that investigated the feasibility and acceptability of an economic empowerment intervention in the South Bronx and East Harlem  New York. Using focus groups and brief questionnaires with youth and their parents/guardians (N=24 dyads)  we explored attitudes toward youth educational savings accounts  financial planning classes  and mentorship for inner-city youth. Findings indicate a strong interest in an economic empowerment intervention among adolescents and their caregivers in these communities. These findings have implications for the design of larger-scale research programs that aim to improve inner-city youth's socio-economic wellbeing using economic empowerment models. PMID:22581997Actuator Feasibility Study for Active Control of Ducted Axial Fan NoiseNASA Technical Reports Server (NTRS)Simonich  John C.1994-01-01A feasibility study was performed to investigate actuator technology which is relevant for a particular application of active noise control for gas turbine stator vanes. This study investigated many different classes of actuators and ranked them on the order of applicability. The most difficult requirements the actuators had to meet were high frequency response  large amplitude deflections  and a thin profile. Based on this assessment  piezoelectric type actuators were selected as the most appropriate actuator class. Specifically  Rainbows (a new class of high performance piezoelectric actuators)  and unimorphs (a ceramic/metal composite) appeared best suited to the requirements. A benchtop experimental study was conducted. The performance of a variety of different actuators was examined  including high polymer films  flextensional actuators  miniature speakers  unimorphs  and Rainbows. The displacement/frequency response and phase characteristics of the actuators were measured. Physical limitations of actuator operation were also examined. This report includes the first known  high displacement  dynamic data obtained for Rainbow actuators. A new ""hard"" ceramic Rainbow actuator which does not appear to be limited in operation by self heating as ""soft"" ceramic Rainbows was designed  constructed and tested. The study concludes that a suitable actuator for active noise control in gas turbine engines can be achieved with state of the art materials and processing.Feasibility Study of Economics and Performance of Wind Turbine Generators at the Newport Indiana Chemical Depot SiteSciTech ConnectRoberts  Joseph Owen; Mosey  GailThe U.S. Environmental Protection Agency (EPA)  in accordance with the RE-Powering America's Land initiative  selected the Newport Indiana Chemical Depot site in Newport  Indiana  for a feasibility study of renewable energy production. The National Renewable Energy Laboratory (NREL) was contacted to provide technical assistance for this project. The purpose of this report is to assess the sitefor possible wind turbine electrical generator installation and estimate the cost  performance  and site impacts of different wind energy options. In addition  the report recommends financing options that could assist in the implementation of a wind system at the site.Feasibility Study of Economics and Performance of Solar Photovoltaics at the Santo Domingo Pueblo in Sandoval County  New MexicoSciTech ConnectGeiger  J.; Lisell  L.; Mosey  G.2013-07-01The U.S. Environmental Protection Agency (EPA)  in accordance with the RE-Powering America's Land initiative  selected the Pueblo of Santo Domingo in Sandoval County  New Mexico  for a renewable energy production feasibility study. The National Renewable Energy Laboratory (NREL) provided technical assistance for this project. The purpose of this report is to assess specific areas on the Pueblo for potential installation of photovoltaic (PV) systems and to estimate the cost  performance  and site impacts of different PV options. The report also recommends financing options that could assist in the implementation of these PV systems.Healthy Beyond Pregnancy  a Web-Based Intervention to Improve Adherence to Postpartum Care: Randomized Controlled Feasibility TrialPubMed CentralDonovan  Heidi; Wang  Stephanie; Weaver  Carrie; Grove  Jillian Rae; Facco  Francesca Lucia2017-01-01Background During the postpartum visit  health care providers address issues with short- and long-term implications for maternal and child health. Women with Medicaid insurance are less likely to return for a postpartum visit compared with women with private insurance. Behavioral economics acknowledges that people do not make exclusively rational choices  rather immediate gratification  cognitive and psychological biases  and social norms influence decision making. Drawing on insights from decision science  behavioral economists have examined how these biases can be modulated through carefully designed interventions. We have developed a Web-based tool  Healthy Beyond Pregnancy  that incorporates empirically derived concepts of behavioral economics to improve adherence rates to the postpartum visit. Objectives The primary objectives of this pilot study were to (1) refine and assess the usability of Healthy Beyond Pregnancy and (2) assess the feasibility of a randomized controlled trial (RCT) of the intervention. Methods We used a multistep process and multidisciplinary team of maternal-fetal medicine physicians  a behavioral economist  and researchers with expertise in behavioral interventions to design Healthy Beyond Pregnancy. We assessed the usability of the program with the Post-Study System Usability Questionnaire (PSSUQ)  a validated 7-point scale  and semistructured interviews with postpartum women. We then conducted a feasibility trial to determine the proportion of eligible women who were willing to participate in an RCT of Healthy Beyond Pregnancy and the proportion of women willing to complete the Web-based program. Exploratory outcomes of the pilot trial included attendance at the postpartum visit  uptake of long-acting reversible contraception  and uptake of any contraception. Results The median PSSUQ score for Healthy Beyond Pregnancy was 6.5 (interquartile range: 6.1-7) demonstrating high usability. Semistructured interviews (n=10) provided inHealthy Beyond Pregnancy  a Web-Based Intervention to Improve Adherence to Postpartum Care: Randomized Controlled Feasibility Trial.PubMedHimes  Katherine Park; Donovan  Heidi; Wang  Stephanie; Weaver  Carrie; Grove  Jillian Rae; Facco  Francesca Lucia2017-10-10During the postpartum visit  health care providers address issues with short- and long-term implications for maternal and child health. Women with Medicaid insurance are less likely to return for a postpartum visit compared with women with private insurance. Behavioral economics acknowledges that people do not make exclusively rational choices  rather immediate gratification  cognitive and psychological biases  and social norms influence decision making. Drawing on insights from decision science  behavioral economists have examined how these biases can be modulated through carefully designed interventions. We have developed a Web-based tool  Healthy Beyond Pregnancy  that incorporates empirically derived concepts of behavioral economics to improve adherence rates to the postpartum visit. The primary objectives of this pilot study were to (1) refine and assess the usability of Healthy Beyond Pregnancy and (2) assess the feasibility of a randomized controlled trial (RCT) of the intervention. We used a multistep process and multidisciplinary team of maternal-fetal medicine physicians  a behavioral economist  and researchers with expertise in behavioral interventions to design Healthy Beyond Pregnancy. We assessed the usability of the program with the Post-Study System Usability Questionnaire (PSSUQ)  a validated 7-point scale  and semistructured interviews with postpartum women. We then conducted a feasibility trial to determine the proportion of eligible women who were willing to participate in an RCT of Healthy Beyond Pregnancy and the proportion of women willing to complete the Web-based program. Exploratory outcomes of the pilot trial included attendance at the postpartum visit  uptake of long-acting reversible contraception  and uptake of any contraception. The median PSSUQ score for Healthy Beyond Pregnancy was 6.5 (interquartile range: 6.1-7) demonstrating high usability. Semistructured interviews (n=10) provided in-depth comments about users' experience andLinking Outdoor Recreation and Economic Development: A Feasibility Assessment of the Obed Wild and Scenic River  TennesseeTreesearchCharles B. Sims; Donald G. Hodges; Del Scruggs2004-01-01Rural economies in many parts of the United States have undergone significant changes over the past two decades. Faltering economies historically based on traditional economic sectors like agriculture and manufacturing are transitioning to retail and service sectors to support growth. One example of such an industry is resource-based recreation and tourism. Tourists...Real-time economic nonlinear model predictive control for wind turbine controlNASA Astrophysics Data System (ADS)Gros  Sebastien; Schild  Axel2017-12-01Nonlinear model predictive control (NMPC) is a strong candidate to handle the control challenges emerging in the modern wind energy industry. Recent research suggested that wind turbine (WT) control based on economic NMPC (ENMPC) can improve the closed-loop performance and simplify the task of controller design when compared to a classical NMPC approach. This paper establishes a formal relationship between the ENMPC controller and the classic NMPC approach  and compares empirically their closed-loop nominal behaviour and performance. The robustness of the performance is assessed for an inaccurate modelling of the tower fore-aft main frequency. Additionally  though a perfect wind preview is assumed here  the effect of having a limited horizon of preview of the wind speed via the LIght Detection And Ranging (LIDAR) sensor is investigated. Finally  this paper provides new algorithmic solutions for deploying ENMPC for WT control  and report improved computational times.Feasibility and Perceptions of Cell Phone-Based  Health-Related Communication With Adolescents in an Economically Depressed Area.PubMedSawni  Anju; Cederna-Meko  Crystal; LaChance  Jenny L; Buttigieg  Angie; Le  Quoc; Nunuk  Irene; Ang  Joyce; Burrell  Katherine M2017-02-01We examined the feasibility and perception of cell-based (texting  voicemail [VM]  and email/social media)  health-related communication with adolescents in Genesee County  MI  where 22% reside below the poverty level. Results of an anonymous survey found that 86% of respondents owned a cell phone  87% had data  96% texted  90.5% emailed/used social media  and 68% had VM. Most adolescents were interested in cell-based communication via texting (52%)  VM (37%)  and email/social media (31%). Interest in types of health communication included appointment reminders (99% texting; 94% VM; 95% email/social media)  shot reminders (84.5% texting; 74.5% VM; 81% email/social media)  call for test results (71.5% texting; 75% VM; 65% email/social media)  medication reminders (63% texting; 54% VM; 58% e-mail/social media)  and health tips (36% texting; 18.5% VM; 73% email/social media). Cell-based health-related communication with adolescents is feasible even within low socioeconomic status populations  primarily via texting. Health providers should embrace cell-based patient communication.Economic policies for tobacco control in developing countries.PubMedRoss  H; Chaloupka  F J2006-01-01Raising tobacco taxes can have an income distributional impact on the population. Since lower socio-economic groups usually smoke more  they also contribute more to total cigarette tax collection. Thus  those who can afford it least contribute the most in terms of tobacco taxes. This means that tobacco taxes are regressive. However  tobacco tax increases are likely to be progressive  decreasing the relative tax incidence on the poor  vis-Ã -vis the rich. This is based on the premise that the poor are likely to be more sensitive to price changes  and would thus reduce their cigarette consumption by a greater percentage than the rich in response to an excise tax-induced increase in cigarette prices. Recent empirical studies confirm this hypothesis by demonstrating that the price responsiveness of cigarette demand increases with income. Research in China confirmed that reducing cigarette expenditures could release household resources for spending on food  housing  and other goods that improve living standards. Therefore  in the long run  tobacco control measures will reduce social inequality.Feasibility study of automatic control of crew comfort in the shuttle Extravehicular Mobility Unit. [liquid cooled garment regulatorNASA Technical Reports Server (NTRS)Cook  D. W.1977-01-01Computer simulation is used to demonstrate that crewman comfort can be assured by using automatic control of the inlet temperature of the coolant into the liquid cooled garment when input to the controller consists of measurements of the garment inlet temperature and the garment outlet temperature difference. Subsequent tests using a facsimile of the control logic developed in the computer program confirmed the feasibility of such a design scheme.A randomised controlled feasibility trial of family and social network intervention for young people who misuse alcohol and drugs: study protocol (Y-SBNT).PubMedWatson  Judith; Back  Donna; Toner  Paul; Lloyd  Charlie; Day  Ed; Brady  Louca-Mai; Templeton  Lorna; Ambegaokar  Sangeeta; Parrott  Steve; Torgerson  David; Cocks  Kim; Gilvarry  Eilish; McArdle  Paul; Copello  Alex2015-01-01A growing body of research has identified family interventions to be effective in treating young people's substance use problems. However  despite this evidence  take-up of family-based approaches in the UK has been low. Key factors for this appear to include the resource-intensive nature of most family interventions which challenges implementation and delivery in many service settings and the cultural adaptation of approaches developed in the USA to a UK setting. This study aims to demonstrate the feasibility of recruiting young people to a specifically developed family- and wider social network-based intervention by testing an adapted version of adult social behaviour and network therapy (SBNT). A pragmatic  randomised controlled  open feasibility trial delivered in two services for young people in the UK. Potential participants are aged 12-18 years referred for drug or alcohol problems to either service. The main purpose of this study is to demonstrate the feasibility of recruiting young people to a specifically developed family and social network-based intervention. The feasibility and acceptability of this intervention will be measured by recruitment rates  treatment retention  follow-up rates and qualitative interviews. The feasibility of training staff from existing services to deliver this intervention will be explored. Using this opportunity to compare the effectiveness of the intervention against treatment as usual  Timeline Follow-Back interviews will document the proportion of days on which the main problem substance was used in the preceding 90-day period at each assessment point. The economic component will examine the feasibility of conducting a full incremental cost-effectiveness analysis of the two treatments. The study will also explore and develop models of patient and public involvement which support the involvement of young people in a study of this nature. An earlier phase of work adapted social behaviour and network therapy (adult approachSpace shuttle program information control and retrieval system feasibility study reportNASA Technical Reports Server (NTRS)Lingle  C. P.1973-01-01The feasibility of having a common information management network for space shuttle data  is studied. Identified are the information types required  sources and users of the information  and existing techniques for acquiring  storing and retrieving the data. The study concluded that a decentralized system is feasible  and described a recommended development plan for it.The impact of occupational therapy in Parkinson's disease: a randomized controlled feasibility study.PubMedSturkenboom  Ingrid H; Graff  Maud J; Borm  George F; Veenhuizen  Yvonne; Bloem  Bastiaan R; Munneke  Marten; Nijhuis-van der Sanden  Maria W2013-02-01To evaluate the feasibility of a randomized controlled trial including process and potential impact of occupational therapy in Parkinson's disease. Process and outcome were quantitatively and qualitatively evaluated in an exploratory multicentre  two-armed randomized controlled trial at three months. Forty-three community-dwelling patients with Parkinson's disease and difficulties in daily activities  their primary caregivers and seven occupational therapists. Ten weeks of home-based occupational therapy according to the Dutch guidelines of occupational therapy in Parkinson's disease versus no occupational therapy in the control group. Process evaluation measured accrual  drop-out  intervention delivery and protocol adherence. Primary outcome measures of patients assessed daily functioning: Canadian Occupational Performance Measure (COPM) and Assessment of Motor and Process Skills. Primary outcome for caregivers was caregiver burden: Zarit Burden Inventory. Participants' perspectives of the intervention were explored using questionnaires and in-depth interviews. Inclusion was 23% (43/189)  drop-out 7% (3/43) and unblinding of assessors 33% (13/40). Full intervention protocol adherence was 74% (20/27)  but only 60% (71/119) of baseline Canadian Occupational Performance Measure priorities were addressed in the intervention. The outcome measures revealed negligible to small effects in favour of the intervention group. Almost all patients and caregivers of the intervention group were satisfied with the results. They perceived: 'more grip on the situation' and used 'practical advices that make life easier'. Therapists were satisfied  but wished for a longer intervention period. The positive perceived impact of occupational therapy warrants a large-scale trial. Adaptations in instructions and training are needed to use the Canadian Occupational Performance Measure as primary outcome measure.Feasibility of outpatient fully integrated closed-loop control: first studies of wearable artificial pancreas.PubMedKovatchev  Boris P; Renard  Eric; Cobelli  Claudio; Zisser  Howard C; Keith-Hynes  Patrick; Anderson  Stacey M; Brown  Sue A; Chernavvsky  Daniel R; Breton  Marc D; Farret  Anne; Pelletier  Marie-JosÃ©e; Place  JÃ©rÃ´me; Bruttomesso  Daniela; Del Favero  Simone; Visentin  Roberto; Filippi  Alessio; Scotton  Rachele; Avogaro  Angelo; Doyle  Francis J2013-07-01To evaluate the feasibility of a wearable artificial pancreas system  the Diabetes Assistant (DiAs)  which uses a smart phone as a closed-loop control platform. Twenty patients with type 1 diabetes were enrolled at the Universities of Padova  Montpellier  and Virginia and at Sansum Diabetes Research Institute. Each trial continued for 42 h. The United States studies were conducted entirely in outpatient setting (e.g.  hotel or guest house); studies in Italy and France were hybrid hospital-hotel admissions. A continuous glucose monitoring/pump system (Dexcom Seven Plus/Omnipod) was placed on the subject and was connected to DiAs. The patient operated the system via the DiAs user interface in open-loop mode (first 14 h of study)  switching to closed-loop for the remaining 28 h. Study personnel monitored remotely via 3G or WiFi connection to DiAs and were available on site for assistance. The total duration of proper system communication functioning was 807.5 h (274 h in open-loop and 533.5 h in closed-loop)  which represented 97.7% of the total possible time from admission to discharge. This exceeded the predetermined primary end point of 80% system functionality. This study demonstrated that a contemporary smart phone is capable of running outpatient closed-loop control and introduced a prototype system (DiAs) for further investigation. Following this proof of concept  future steps should include equipping insulin pumps and sensors with wireless capabilities  as well as studies focusing on control efficacy and patient-oriented clinical outcomes.Economic Savings from Using Economic Incentives for Environmental Pollution Control (1999)EPA Pesticide FactsheetsEconomic incentives  such as emission taxes  effluent trading  deposit refund systems  information reporting requirements  liability for harm caused by pollution  and voluntary programs have the potential to achieve environmental objectives at lower cost.Economic evaluations and their use in infection prevention and control: a narrative review.PubMedRennert-May  Elissa; Conly  John; Leal  Jenine; Smith  Stephanie; Manns  Braden2018-01-01The objective of this review is to provide a comprehensive overview of the different types of economic evaluations that can be utilized by Infection Prevention and Control practitioners with a particular focus on the use of the quality adjusted life year  and its associated challenges. We also highlight existing economic evaluations published within Infection Prevention and Control  research gaps and future directions. Narrative Review. To date the majority of economic evaluations within Infection Prevention and Control are considered partial economic evaluations. Acknowledging the challenges  which include variable utilities within infection prevention and control  a lack of randomized controlled trials  and difficulty in modelling infectious diseases in general  future economic evaluation studies should strive to be consistent with published guidelines for economic evaluations. This includes the use of quality adjusted life years. Further research is required to estimate utility scores of relevance within Infection Prevention and Control.The Economics of Tobacco Control: Evidence from the International Tobacco Control (ITC) Policy Evaluation ProjectPubMed CentralTauras  John A.; Chaloupka  Frank J.; Quah  Anne Chiew Kin; Fong  Geoffrey T.2015-01-01Over the past few decades  the importance of economic research in advancing tobacco control policies has become increasingly clear. Extensive research has demonstrated that increasing tobacco taxes and prices is the single most cost-effective tobacco control measure. The research contained in this supplement adds to this evidence and provides new insights into how smokers respond to tax and price changes using the rich data on purchase behaviors  brand choices  tax avoidance and evasion  and tobacco use collected systematically and consistently across countries and over time by the ITC Project. The findings from this research will help inform policymakers  public health professionals  advocates  and others seeking to maximize the public health and economic benefits from higher taxes. PMID:24500268Thermal hydrolysis integration in the anaerobic digestion process of different solid wastes: energy and economic feasibility study.PubMedCano  R; Nielfa  A; Fdz-Polanco  M2014-09-01An economic assessment of thermal hydrolysis as a pretreatment to anaerobic digestion has been achieved to evaluate its implementation in full-scale plants. Six different solid wastes have been studied  among them municipal solid waste (MSW). Thermal hydrolysis has been tested with batch lab-scale tests  from which an energy and economic assessment of three scenarios is performed: with and without energy integration (recovering heat to produce steam in a cogeneration plant)  finally including the digestate management costs. Thermal hydrolysis has lead to an increase of the methane productions (up to 50%) and kinetics parameters (even double). The study has determined that a proper energy integration design could lead to important economic savings (5 â‚¬/t) and thermal hydrolysis can enhance up to 40% the incomes of the digestion plant  even doubling them when digestate management costs are considered. In a full-scale MSW treatment plant (30 000 t/year)  thermal hydrolysis would provide almost 0.5 Mâ‚¬/year net benefits. Copyright Â© 2014 Elsevier Ltd. All rights reserved.Cognitive bias modification for social anxiety in adults who stutter: a feasibility study of a randomised controlled trialPubMed CentralGascoine  Sally; Carroll  Amy; Humby  Kate; Kingston  Mary; Shepstone  Lee; Risebro  Helen; Mackintosh  Bundy; Thompson  Tammy Davidson; Hodgekins  Jo2017-01-01Objective To determine the feasibility and acceptability of a computerised treatment for social anxiety disorder for adults who stutter including identification of recruitment  retention and completion rates  large cost drivers and selection of most appropriate outcome measure(s) to inform the design of a future definitive trial. Design Two-group parallel design (treatment vs placebo)  double-blinded feasibility study. Participants: 31 adults who stutter. Intervention Attention training via an online probe detection task in which the stimuli were images of faces displaying neutral and disgusted expressions. Main outcome measures Psychological measures: Structured Clinical Interview Global Assessment of Functioning score; Liebowitz Social Anxiety Scale; Social Phobia and Anxiety Inventory; State-Trait Anxiety Inventory; Unhelpful Thoughts and Beliefs about Stuttering. Speech fluency: percent syllables stuttered. Economic evaluation: resource use questionnaire; EuroQol three-dimension questionnaire. Acceptability: Likert Scale questionnaire of experience of trial  acceptability of the intervention and randomisation procedure. Results Feasibility of recruitment strategy was demonstrated. Participant feedback indicated that the intervention and definitive trial  including randomisation  would be acceptable to adults who stutter. Of the 31 participants who were randomised  25 provided data at all three data collection points. Conclusions The feasibility study informed components of the intervention. Modifications to the design are needed before a definitive trial can be undertaken. Trial registration number I SRCTN55065978; Post-results. PMID:29061602Children Learning About Second-Hand Smoking: A Feasibility Cluster Randomized Controlled Trial.PubMedHuque  Rumana; Dogar  Omara; Cameron  Ian; Thomson  Heather; Amos  Amanda; Siddiqi  Kamran2015-12-01Exposure to second-hand smoke is a threat to children's health. We developed a school-based smoke-free intervention (SFI) to support families in implementing smoke-free homes in Bangladesh  and gathered preliminary evidence of its effectiveness. A feasibility cluster randomized controlled trial of SFI was conducted in 24 schools in Mirpur  an urban area within Dhaka. Using simple stratified randomization  schools were allocated to: Arm A (SFI only)  Arm B (SFI plus reminders)  and Arm C (the control group). A total of 781 year-5 children (10-12 years old) in the consenting schools  participated in the study. Outcomes including ""smoke-free homes"" and ""social visibility"" that is  not smoking in front of children at home were assessed through questionnaire-based children's surveys  administered by researchers  at baseline and at weeks 1  12  27  and 52 in all arms. ""Smoke-free homes"" were significantly higher in Arm A (odds ratio [OR] = 4.8; 95% CI = 2.6-9.0) and in Arm B (OR = 3.9; 95% CI = 2.0-7.5) than in Arm C  when controlled for the baseline levels  at year 1. Similarly  ""social visibility"" was significantly reduced in Arm A (OR = 5.8; 95% CI = 2.8-11.7) and in Arm B (OR = 7.2; 95% CI = 3.3-15.9) than Arm C  when controlled for the baseline levels  at year 1. We observed an increasing trend (Cochrane Armitage test statistic [Z] = 3.8; p < .0001) in homes becoming smoke-free with increasing intensity of the intervention (control < Arm A < Arm B)  and a decreasing trend (Z = -5.13; p < .0001) in social visibility at homes. SFI has the potential to encourage children to negotiate a smoke-free environment in their homes. Â© The Author 2015. Published by Oxford University Press on behalf of the Society for Research on Nicotine and Tobacco. All rights reserved. For permissions  please e-mail: journals.permissions@oup.com.Randomized controlled trial of asthma risk with paracetamol use in infancy--a feasibility study.PubMedRiley  J; Braithwaite  I; Shirtcliffe  P; Caswell-Smith  R; Hunt  A; Bowden  V; Power  S; Stanley  T; Crane  J; Ingham  T; Weatherall  M; Mitchell  E A; Beasley  R2015-02-01There is non-experimental evidence that paracetamol (acetaminophen) use may increase the risk of developing asthma. However  numerous methodological issues need to be resolved before undertaking a randomized controlled trial to investigate this hypothesis. To establish the feasibility of a randomized controlled trial of liberal paracetamol as usually given by parents/guardians vs. a comparator (restricted paracetamol in accordance with WHO guidelines  ibuprofen or placebo)  and childhood asthma risk. Questionnaires were completed by parents/guardians of infants admitted to Wellington Hospital with bronchiolitis to assess views about comparator treatments. Subsequently  infants of parents/guardians who provided informed consent were randomized to restricted or liberal paracetamol use for 3 months with paracetamol use recorded. Of 120 eligible participants  72 (60%) parents/guardians completed the questionnaire. Ibuprofen  restricted paracetamol and placebo were acceptable to 42 (58%)  29 (40%) and 9 (12%) parents/guardians  respectively. 36 (30%) infants were randomized to restricted or liberal paracetamol. Paracetamol use was greater for the liberal vs. restricted group for reported [Hodges-Lehmann estimator of difference 0.94 mg/kg/day (95% CI 0.2-3.52)  P = 0.02] and measured use [Hodges-Lehmann estimator of difference 2.11 mg/kg/day (95% CI 0.9-4.18)  P = 0.004]. The median reported and measured use of paracetamol was 2.0-fold and 3.5-fold greater in the liberal vs. restricted group. Although separation in paracetamol dosing is likely to be achieved with a liberal vs. restricted paracetamol regime  ibuprofen is the preferred comparator treatment in the proposed RCT of paracetamol use and risk of asthma in childhood. Â© 2014 John Wiley & Sons Ltd.Techno-economic feasibility of waste biorefinery: Using slaughtering waste streams as starting material for biopolyester production.PubMedShahzad  Khurram; Narodoslawsky  Michael; Sagir  Muhammad; Ali  Nadeem; Ali  Shahid; Rashid  Muhammad Imtiaz; Ismail  Iqbal Mohammad Ibrahim; Koller  Martin2017-09-01The utilization of industrial waste streams as input materials for bio-mediated production processes constitutes a current R&D objective not only to reduce process costs at the input side but in parallel  to minimize hazardous environmental emissions. In this context  the EU-funded project ANIMPOL elaborated a process for the production of polyhydroxyalkanoate (PHA) biopolymers starting from diverse waste streams of the animal processing industry. This article provides a detailed economic analysis of PHA production from this waste biorefinery concept  encompassing the utilization of low-quality biodiesel  offal material and meat and bone meal (MBM). Techno-economic analysis reveals that PHA production cost varies from 1.41 â‚¬/kg to 1.64 â‚¬/kg when considering offal on the one hand as waste  or  on the other hand  accounting its market price  while calculating with fixed costs for the co-products biodiesel (0.97 â‚¬/L) and MBM (350 â‚¬/t)  respectively. The effect of fluctuating market prices for offal materials  biodiesel  and MBM on the final PHA production cost as well as the investment payback time have been evaluated. Depending on the current market situation  the calculated investment payback time varies from 3.25 to 4.5years. Copyright Â© 2017 Elsevier Ltd. All rights reserved.Economics.ERIC Educational Resources Information CenterKemp  RodgerThis course presents basic economic concepts and explores issues such as how goods and services are produced and distributed  what affects costs and profits  and how wealth is spread around or concentrated. The course is designed to be used with students enrolled in an adult high school diploma program; course content is appropriate to meet socialâ€¦AGRI Grain Power ethanol-for-fuel project feasibility-study report. Volume II. Project marketing/economic/financial/ and organizationSciTech ConnectNot Available1981-04-01The AGRI GRAIN POWER (AGP) project  hereafter referred to as the Project  was formed to evaluate the commercial viability and assess the desireability of implementing a large grain based grass-roots anhydrous ethanol fuel project to be sited near Des Moines  Iowa. This report presents the results of a Project feasibility evaluation. The Project concept is based on involving a very strong managerial  financial and technical joint venture that is extremely expert in all facets of planning and implementing a large ethanol project; on locating the ethanol project at a highly desireable site; on utilizing a proven ethanol process; and onmoreÂ Â» developing a Project that is well suited to market requirements  resource availability and competitive factors. The results of marketing  economic  and financial studies are reported in this volume.Â«Â lessEnergy-environmental benefits and economic feasibility of anaerobic codigestion of Iberian pig slaughterhouse and tomato industry wastes in Extremadura (Spain).PubMedGonzÃ¡lez-GonzÃ¡lez  A; Cuadros  F; Ruiz-Celma  A; LÃ³pez-RodrÃ­guez  F2013-05-01Anaerobic digestion of Iberian pig slaughterhouse and tomato industry wastes  as well as codigestion operations from such residues  are reported to achieve 54-80% reduction in Chemical Oxygen Demand and 6-19 N m(3)/m(3) substrate methane production. Furthermore  0.79-0.88 m(3)water/m(3) substrate is seen to be recovered after the above mentioned operations  which might be used as irrigation water  and 0.12-0.21 m(3)agricultural amendment/m(3) substrate with 91-98% moisture content. The present paper also reports on the economic feasibility of both an anaerobic codigestion plant operating with 60% slaughterhouse wastes/40% tomato industry wastes (optimal ratio obtained in previous laboratory-scaled experiments)  and an anaerobic digestion plant for Iberian pig slaughterhouse waste. Payback times are reported as 14.86 and 3.73 years  respectively. Copyright Â© 2013 Elsevier Ltd. All rights reserved.Method for the technical  financial  economic and environmental pre-feasibility study of geothermal power plants by RETScreen - Ecuador's case study.PubMedMoya  Diego; Paredes  Juan; Kaparaju  Prasad2018-01-01RETScreen presents a proven focused methodology on pre-feasibility studies. Although this tool has been used to carry out a number of pre-feasibility studies of solar  wind  and hydropower projects; that is not the case for geothermal developments. This method paper proposes a systematic methodology to cover all the necessary inputs of the RETScreen-International Geothermal Project Model. As case study  geothermal power plant developments in the Ecuadorian context were analysed by RETScreen-International Geothermal Project Model. Three different scenarios were considered for analyses. Scenario I and II considered incentives of 132.1 USD/MWh for electricity generation and grants of 3 million USD. Scenario III considered the geothermal project with an electricity export price of 49.3 USD/MWh. Scenario III was further divided into IIIA and IIIB case studies. Scenario IIIA considered a 3 million USD grant while Scenario IIIB considered an income of 8.9 USD/MWh for selling heat in direct applications. Modelling results showed that binary power cycle was the most suitable geothermal technology to produce electricity along with aquaculture and greenhouse heating for direct use applications in all scenarios. Financial analyses showed that the debt payment would be 5.36 million USD/year under in Scenario I and III. The correspindig values for Scenario II was 7.06 million USD/year. Net Present Value was positive for all studied scenarios except for Scenario IIIA. Overall  Scenario II was identified as the most feasible project due to positive NPV with short payback period. Scenario IIIB could become financially attractive by selling heat for direct applications. The total initial investment for a 22â€¯MW geothermal power plant was 114.3 million USD (at 2017 costs). Economic analysis showed an annual savings of 24.3 million USD by avoiding fossil fuel electricity generation. More than 184 000 tCO 2 eq. could be avoided annually.DC-9/JT8D refan  Phase 1. [technical and economic feasibility of retrofitting DC-9 aircraft with refan engine to achieve desired acoustic levelsNASA Technical Reports Server (NTRS)1973-01-01Analyses and design studies were conducted on the technical and economic feasibility of installing the JT8D-109 refan engine on the DC-9 aircraft. Design criteria included minimum change to the airframe to achieve desired acoustic levels. Several acoustic configurations were studied with two selected for detailed investigations. The minimum selected acoustic treatment configuration results in an estimated aircraft weight increase of 608 kg (1 342 lb) and the maximum selected acoustic treatment configuration results in an estimated aircraft weight increase of 809 kg (1 784 lb). The range loss for the minimum and maximum selected acoustic treatment configurations based on long range cruise at 10 668 m (35 000 ft) altitude with a typical payload of 6 804 kg (15 000 lb) amounts to 54 km (86 n. mi.) respectively. Estimated reduction in EPNL's for minimum selected treatment show 8 EPNdB at approach  12 EPNdB for takeoff with power cutback  15 EPNdB for takeoff without power cutback and 12 EPNdB for sideline using FAR Part 36. Little difference was estimated in EPNL between minimum and maximum treatments due to reduced performance of maximum treatment. No major technical problems were encountered in the study. The refan concept for the DC-9 appears technically feasible and economically viable at approximately $1 000 000 per airplane. An additional study of the installation of JT3D-9 refan engine on the DC-8-50/61 and DC-8-62/63 aircraft is included. Three levels of acoustic treatment were suggested for DC-8-50/61 and two levels for DC-8-62/63. Results indicate the DC-8 technically can be retrofitted with refan engines for approximately $2 500 000 per airplane.A randomised controlled feasibility trial for an educational school-based mental health intervention: study protocol.PubMedChisholm  Katharine Elizabeth; Patterson  Paul; Torgerson  Carole; Turner  Erin; Birchwood  Max2012-03-22With the burden of mental illness estimated to be costing the English economy alone around Â£22.5 billion a year 1  coupled with growing evidence that many mental disorders have their origins in adolescence  there is increasing pressure for schools to address the emotional well-being of their students  alongside the stigma and discrimination of mental illness. A number of prior educational interventions have been developed and evaluated for this purpose  but inconsistency of findings  reporting standards  and methodologies have led the majority of reviewers to conclude that the evidence for the efficacy of these programmes remains inconclusive. A cluster randomised controlled trial design has been employed to enable a feasibility study of 'SchoolSpace'  an intervention in 7 UK secondary schools addressing stigma of mental illness  mental health literacy  and promotion of mental health. A central aspect of the intervention involves students in the experimental condition interacting with a young person with lived experience of mental illness  a stigma reducing technique designed to facilitate students' engagement in the project. The primary outcome is the level of stigma related to mental illness. Secondary outcomes include mental health literacy  resilience to mental illness  and emotional well-being. Outcomes will be measured pre and post intervention  as well as at 6 month follow-up. The proposed intervention presents the potential for increased engagement due to its combination of education and contact with a young person with lived experience of mental illness. Contact as a technique to reduce discrimination has been evaluated previously in research with adults  but has been employed in only a minority of research trials investigating the impact on youth. Prior to this study  the effect of contact on mental health literacy  resilience  and emotional well-being has not been evaluated to the authors' knowledge. If efficacious the intervention could provide aThe Economic and Risk Constraints in the Feasibility Analysis of Wireless Communications in Marine Corps Combat Operation CentersDTIC Science & Technology2013-09-01attacker can acquire and use against a wireless infrastructure. Wireless attack tool kits such as the â€œ Raspberry â€“ PI â€ (shown in Figure 10)  and...still use a tool such as the Raspberry â€“ PI to perform attacks against a network from outside the controlled area or even inside the controlled area...when considering an insider attack. Figure 10. (From www.howtodocomputing.blogspot.com  n.d.) Wireless â€“ PI is â€œa collection of pre-configuredThe acceptability and feasibility of a brief psychosocial intervention to reduce blood-borne virus risk behaviours among people who inject drugs: a randomised control feasibility trial of a psychosocial intervention (the PROTECT study) versus treatment as usual.PubMedGilchrist  Gail; Swan  Davina; Shaw  April; Keding  Ada; Towers  Sarah; Craine  Noel; Munro  Alison; Hughes  Elizabeth; Parrott  Steve; Strang  John; Taylor  Avril; Watson  Judith2017-03-21While opiate substitution therapy and injecting equipment provision (IEP) have reduced blood-borne viruses (BBV) among people who inject drugs (PWID)  some PWID continue to share injecting equipment and acquire BBV. Psychosocial interventions that address risk behaviours could reduce BBV transmission among PWID. A pragmatic  two-armed randomised controlled  open feasibility study of PWID attending drug treatment or IEP in four UK regions. Ninety-nine PWID were randomly allocated to receive a three-session manualised psychosocial group intervention and BBV transmission information booklet plus treatment as usual (TAU) (nâ€‰=â€‰52) or information booklet plus TAU (nâ€‰=â€‰47). The intervention was developed from evidence-based literature  qualitative interviews with PWID  key stakeholder consultations  and expert opinion. Recruitment rates  retention in treatment  follow-up completion rates and health economic data completion measured feasibility. Fifty-six percent (99/176) of eligible PWID were recruited. More participants attended at least one intervention session in London (10/16; 63%) and North Wales (7/13; 54%) than in Glasgow (3/12; 25%) and York (0/11). Participants who attended no sessions (nâ€‰=â€‰32) compared to those attending at least one (nâ€‰=â€‰20) session were more likely to be homeless (56 vs 25%  pâ€‰=â€‰0.044)  injected drugs for a greater number of days (median 25 vs 6.5  pâ€‰=â€‰0.019) and used a greater number of needles from an IEP in the last month (median 31 vs 20  pâ€‰=â€‰0.056). No adverse events were reported. 45.5% (45/99) were followed up 1Â month post-intervention. Feedback forms confirmed that the intervention was acceptable to both intervention facilitators and participants who attended it. Follow-up attendance was associated with fewer days of injecting in the last month (median 14 vs 27  pâ€‰=â€‰0.030) and fewer injections of cocaine (13 vs 30%  pâ€‰=â€‰0.063). Analysis of the questionnaires identified several service useRandomized Controlled Study on Safety and Feasibility of Transfusion Trigger Score of Emergency Operations.PubMedLiu  De-Xing; Liu  Jin; Zhang  Fan; Zhang  Qiu-Ying; Xie  Mian; Zhu  Zhao-Qiong2015-07-05-E group was totally (100%) conformed to the requirements of the transfusion guideline to RBC infusion  which was higher than that of the control group (81.25%)  P < 0.01.There were no statistical differences in utilization rates of autologous blood of the two groups; the utilization rates of allogeneic RBC  total allogeneic RBC and total RBC were 48.48%  51.5%  and 75.7% in POTTS-E group  which were lower than those of the control group (84.3%  84.3%  and 96.8%) P < 0.05 or P < 0.01. Per capita consumption of intraoperative allogeneic RBC  total allogeneic RBC and total RBC were 0 (0  3.0)  2.0 (0  4.0)  and 3.1 (0.81  6.0) in POTTS-E groups were all lower than those of control group (4.0 [2.0  4.0]  4.0 [2.0  6.0] and 5.8 [2.7  8.2])  P < 0.05 or P < 0.001. Peri-operative Transfusion Trigger Score-E evaluation scheme is used to guide the application of RBC. There are no differences in the recent prognosis of patients with the traditional transfusion guidelines. This scheme is safe; Compared with doctor experience-based subjective assessment  the scoring scheme was closer to patient physiological needs for transfusion and more reasonable; Utilization rate and the per capita consumption of RBC are obviously declined  which has clinical significance and is feasible. Based on the abovementioned three points  POTTS-E scores scheme is safe  reasonable  and practicable and has the value for carrying out multicenter and large sample clinical researches.A decision-making tool to determine economic feasibility and break-even prices for artisan cheese operations.PubMedDurham  Catherine A; Bouma  Andrea; Meunier-Goddik  Lisbeth2015-12-01Artisan cheese makers lack access to valid economic data to help them evaluate business opportunities and make important business decisions such as determining cheese pricing structure. The objective of this study was to utilize an economic model to evaluate the net present value (NPV)  internal rate of return  and payback period for artisan cheese production at different annual production volumes. The model was also used to determine the minimum retail price necessary to ensure positive NPV for 5 different cheese types produced at 4 different production volumes. Milk type  cheese yield  and aging time all affected variable costs. However  aged cheeses required additional investment for aging space (which needs to be larger for longer aging times)  as did lower yield cheeses (by requiring larger-volume equipment for pasteurization and milk handling). As the volume of milk required increased  switching from vat pasteurization to high-temperature  short-time pasteurization was necessary for low-yield cheeses before being required for high-yield cheeses  which causes an additional increase in investment costs. Because of these differences  high-moisture  fresh cow milk cheeses can be sold for about half the price of hard  aged goat milk cheeses at the largest production volume or for about two-thirds the price at the lowest production volume examined. For example  for the given model assumptions  at an annual production of 13 608kg of cheese (30 000 lb)  a fresh cow milk mozzarella should be sold at a minimum retail price of $27.29/kg ($12.38/lb)  whereas a goat milk Gouda needs a minimum retail price of $49.54/kg ($22.47/lb). Artisan cheese makers should carefully evaluate annual production volumes. Although larger production volumes decrease average fixed cost and improve production efficiency  production can reach volumes where it becomes necessary to sell through distributors. Because distributors might pay as little as 35% of retail price  the retail price needsPerformance adaptive training control strategy for recovering wrist movements in stroke patients: a preliminary  feasibility studyPubMed Central2009-01-01Background In the last two decades robot training in neuromotor rehabilitation was mainly focused on shoulder-elbow movements. Few devices were designed and clinically tested for training coordinated movements of the wrist  which are crucial for achieving even the basic level of motor competence that is necessary for carrying out ADLs (activities of daily life). Moreover  most systems of robot therapy use point-to-point reaching movements which tend to emphasize the pathological tendency of stroke patients to break down goal-directed movements into a number of jerky sub-movements. For this reason we designed a wrist robot with a range of motion comparable to that of normal subjects and implemented a self-adapting training protocol for tracking smoothly moving targets in order to facilitate the emergence of smoothness in the motor control patterns and maximize the recovery of the normal RoM (range of motion) of the different DoFs (degrees of Freedom). Methods The IIT-wrist robot is a 3 DoFs light exoskeleton device  with direct-drive of each DoF and a human-like range of motion for Flexion/Extension (FE)  Abduction/Adduction (AA) and Pronation/Supination (PS). Subjects were asked to track a variable-frequency oscillating target using only one wrist DoF at time  in such a way to carry out a progressive splinting therapy. The RoM of each DoF was angularly scanned in a staircase-like fashion  from the ""easier"" to the ""more difficult"" angular position. An Adaptive Controller evaluated online performance parameters and modulated both the assistance and the difficulty of the task in order to facilitate smoother and more precise motor command patterns. Results Three stroke subjects volunteered to participate in a preliminary test session aimed at verify the acceptability of the device and the feasibility of the designed protocol. All of them were able to perform the required task. The wrist active RoM of motion was evaluated for each patient at the beginning and at the endFeasibility of sulfide control in sewers by reuse of iron rich drinking water treatment sludge.PubMedSun  Jing; Pikaar  Ilje; Sharma  Keshab Raj; Keller  JÃ¼rg; Yuan  Zhiguo2015-03-15Dosage of iron salt is the most commonly used method for sulfide control in sewer networks but incurs high chemical costs. In this study  we experimentally investigate the feasibility of using iron rich drinking water treatment sludge for sulfide control in sewers. A lab-scale rising main sewer biofilm reactor was used. The sulfide concentration in the effluent decreased from 15.5 to 19.8Â mgS/L (without dosing) to below 0.7-2.3Â mgS/L at a sludge dosing rate achieving an iron to total dissolved inorganic sulfur molar ratio (Fe:S) of 1:1  with further removal of sulfide possible by prolonging the reaction time. In fact  batch tests revealed an Fe consumption to sulfide removal ratio of 0.5Â Â±Â 0.02 (mole:mole)  suggesting the possible occurrence of other reactions involving the removal of sulfide. Modelling revealed that the reaction between iron in sludge and sulfide has reaction orders of 0.65Â Â±Â 0.01 and 0.77Â Â±Â 0.02 with respect to the Fe and sulfide concentrations  respectively. The addition of sludge slightly increased the total chemical oxidation demand (tCOD) concentration (by approximately 12%) as expected  but decreased the soluble chemical oxidation demand (sCOD) concentration and methane formation by 7% and 20%  respectively. Some phosphate removal (13%) was also observed at the sludge dosing rate of 1:1 (Fe:S)  which is beneficial to nutrient removal from the wastewater. Overall  this study suggests that dosing iron-rich drinking water sludge to sewers could be an effective strategy for sulfide removal in sewer systems  which would also reduce the sludge disposal costs for drinking water treatment works. However  its potential side-effects on sewer sedimentation and on the wastewater treatment plant effluent remain to be investigated. Copyright Â© 2015 Elsevier Ltd. All rights reserved.The feasibility of a randomised controlled trial of physiotherapy for adults with joint hypermobility syndrome.PubMedPalmer  Shea; Cramp  Fiona; Clark  Emma; Lewis  Rachel; Brookes  Sara; Hollingworth  William; Welton  Nicky; Thom  Howard; Terry  Rohini; Rimes  Katharine A; Horwood  Jeremy2016-06-01Joint hypermobility syndrome (JHS) is a heritable disorder associated with laxity and pain in multiple joints. Physiotherapy is the mainstay of treatment  but there is little research investigating its clinical effectiveness. To develop a comprehensive physiotherapy intervention for adults with JHS; to pilot the intervention; and to conduct a pilot randomised controlled trial (RCT) to determine the feasibility of conducting a future definitive RCT. Patients' and health professionals' perspectives on physiotherapy for JHS were explored in focus groups (stage 1). A working group of patient research partners  clinicians and researchers used this information to develop the physiotherapy intervention. This was piloted and refined on the basis of patients' and physiotherapists' feedback (stage 2). A parallel two-arm pilot RCT compared 'advice' with 'advice and physiotherapy' (stage 3). Random allocation was via an automated randomisation service  devised specifically for the study. Owing to the nature of the interventions  it was not possible to blind clinicians or patients to treatment allocation. Stage 1 - focus groups were conducted in four UK locations. Stages 2 and 3 - piloting of the intervention and the pilot RCT were conducted in two UK secondary care NHS trusts. Stage 1 - patient focus group participants (nâ€‰=â€‰25  three men) were aged >â€‰18 years  had a JHS diagnosis and had received physiotherapy within the preceding 12 months. The health professional focus group participants (nâ€‰=â€‰16  three men; 14 physiotherapists  two podiatrists) had experience of managing JHS. Stage 2 - patient participants (nâ€‰=â€‰8) were aged >â€‰18 years  had a JHS diagnosis and no other musculoskeletal conditions causing pain. Stage 3 - patient participants for the pilot RCT (nâ€‰=â€‰29) were as for stage 2 but the lower age limit was 16 years. For the pilot RCT (stage 3) the advice intervention was a one-off session  supplemented by advice booklets. All participants could askHome-based neurologic music therapy for arm hemiparesis following stroke: results from a pilot  feasibility randomized controlled trialPubMed CentralStreet  Alexander J; Magee  Wendy L; Bateman  Andrew; Parker  Michael; Odell-Miller  Helen; Fachner  Jorg2017-01-01Objective: To assess the feasibility of a randomized controlled trial to evaluate music therapy as a home-based intervention for arm hemiparesis in stroke. Design: A pilot feasibility randomized controlled trial  with cross-over design. Randomization by statistician using computer-generated  random numbers concealed in opaque envelopes. Setting: Participantsâ€™ homes across Cambridgeshire  UK. Subjects: Eleven people with stroke and arm hemiparesis  3â€“60â€‰months post stroke  following discharge from community rehabilitation. Interventions: Each participant engaged in therapeutic instrumental music performance in 12 individual clinical contacts  twice weekly for six weeks. Main measures: Feasibility was estimated by recruitment from three community stroke teams over a 12-month period  attrition rates  completion of treatment and successful data collection. Structured interviews were conducted pre and post intervention to establish participant tolerance and preference. Action Research Arm Test and Nine-hole Peg Test data were collected at weeks 1  6  9  15 and 18  pre and post intervention by a blinded assessor. Results: A total of 11 of 14 invited participants were recruited (intervention nâ€‰=â€‰6  waitlist nâ€‰=â€‰5). In total  10 completed treatment and data collection. Conclusion: It cannot be concluded whether a larger trial would be feasible due to unavailable data regarding a number of eligible patients screened. Adherence to treatment  retention and interview responses might suggest that the intervention was motivating for participants. Trial registration: ClinicalTrials.gov identifier NCT 02310438. PMID:28643570Home-based neurologic music therapy for arm hemiparesis following stroke: results from a pilot  feasibility randomized controlled trial.PubMedStreet  Alexander J; Magee  Wendy L; Bateman  Andrew; Parker  Michael; Odell-Miller  Helen; Fachner  Jorg2018-01-01To assess the feasibility of a randomized controlled trial to evaluate music therapy as a home-based intervention for arm hemiparesis in stroke. A pilot feasibility randomized controlled trial  with cross-over design. Randomization by statistician using computer-generated  random numbers concealed in opaque envelopes. Participants' homes across Cambridgeshire  UK. Eleven people with stroke and arm hemiparesis  3-60â€‰months post stroke  following discharge from community rehabilitation. Each participant engaged in therapeutic instrumental music performance in 12 individual clinical contacts  twice weekly for six weeks. Feasibility was estimated by recruitment from three community stroke teams over a 12-month period  attrition rates  completion of treatment and successful data collection. Structured interviews were conducted pre and post intervention to establish participant tolerance and preference. Action Research Arm Test and Nine-hole Peg Test data were collected at weeks 1  6  9  15 and 18  pre and post intervention by a blinded assessor. A total of 11 of 14 invited participants were recruited (intervention nâ€‰=â€‰6  waitlist nâ€‰=â€‰5). In total  10 completed treatment and data collection. It cannot be concluded whether a larger trial would be feasible due to unavailable data regarding a number of eligible patients screened. Adherence to treatment  retention and interview responses might suggest that the intervention was motivating for participants. ClinicalTrials.gov identifier NCT 02310438.The Economics of Environmental Control: A Social Science PerspectiveERIC Educational Resources Information CenterDuncan  W. Jack1972-01-01This paper provides guidelines for primary and secondary social studies teachers for giving students information about environmental pollution. Economic statistics are cited to illustrate the critical nature of environmental problems and a re-educative'' approach is suggested as being most effective in developing attitudes necessary for problemâ€¦The feasibility of a pragmatic randomised controlled trial to compare usual care with usual care plus individualised homeopathy  in children requiring secondary care for asthma.PubMedThompson  E A; Shaw  A; Nichol  J; Hollinghurst  S; Henderson  A J; Thompson  T; Sharp  D2011-07-01To test the feasibility of a pragmatic trial design with economic evaluation and nested qualitative study  comparing usual care (UC) with UC plus individualised homeopathy  in children requiring secondary care for asthma. This included recruitment and retention  acceptability of outcome measures patients' and health professionals' views and experiences and a power calculation for a definitive trial. In a pragmatic parallel group randomised controlled trial (RCT) design  children on step 2 or above of the British Thoracic Society Asthma Guidelines (BTG) were randomly allocated to UC or UC plus a five visit package of homeopathic care (HC). Outcome measures included the Juniper Asthma Control Questionnaire  Quality of Life Questionnaire and a resource use questionnaire. Qualitative interviews were used to gain families' and health professionals' views and experiences. 226 children were identified from hospital clinics and related patient databases. 67 showed an interest in participating  39 children were randomised  18 to HC and 21 to UC. Evidence in favour of adjunctive homeopathic treatment was lacking. Economic evaluation suggests that the cost of additional consultations was not offset by the reduced cost of homeopathic remedies and the lower use of primary care by children in the homeopathic group. Qualitative data gave insights into the differing perspectives of families and health care professionals within the research process. A future study using this design is not feasible  further investigation of a potential role for homeopathy in asthma management might be better conducted in primary care with children with less severe asthma. Copyright Â© 2011 The Faculty of Homeopathy. Published by Elsevier Ltd. All rights reserved.A randomised controlled trial of six weeks of home enteral nutrition versus standard care after oesophagectomy or total gastrectomy for cancer: report on a pilot and feasibility study.PubMedBowrey  David J; Baker  Melanie; Halliday  Vanessa; Thomas  Anne L; Pulikottil-Jacob  Ruth; Smith  Karen; Morris  Tom; Ring  Arne2015-11-21Poor nutrition in the first months after oesophago-gastric resection is a contributing factor to the reduced quality of life seen in these patients. The aim of this pilot and feasibility study was to ascertain the feasibility of conducting a multi-centre randomised controlled trial to evaluate routine home enteral nutrition in these patients. Patients undergoing oesophagectomy or total gastrectomy were randomised to either six weeks of home feeding through a jejunostomy (intervention)  or treatment as usual (control). Intervention comprised overnight feeding  providing 50 % of energy and protein requirements  in addition to usual oral intake. Primary outcome measures were recruitment and retention rates at six weeks and six months. Nutritional intake  nutritional parameters  quality of life and healthcare costs were also collected. Interviews were conducted with a sample of participants  to ascertain patient and carer experiences. Fifty-four of 112 (48 %) eligible patients participated in the study over the 20 months. Study retention at six weeks was 41/54 patients (76 %) and at six months was 36/54 (67 %). At six weeks  participants in the control group had lost on average 3.9 kg more than participants in the intervention group (95 % confidence interval [CI] 1.6 to 6.2). These differences remained evident at three months (mean difference 2.5 kg  95 % CI -0.5 to 5.6) and at six months (mean difference 2.5 kg  95 % CI -1.2 to 6.1). The mean values observed in the intervention group for mid arm circumference  mid arm muscle circumference  triceps skin fold thickness and right hand grip strength were greater than for the control group at all post hospital discharge time points. The economic evaluation suggested that it was feasible to collect resource use and EQ-5D data for a full cost-effectiveness analysis. Thematic analysis of 15 interviews identified three main themes related to the intervention and the trial: 1) a positive experience  2) the reasons for takingEconomic value of biological control in integrated pest management of managed plant systems.PubMedNaranjo  Steven E; Ellsworth  Peter C; Frisvold  George B2015-01-07Biological control is an underlying pillar of integrated pest management  yet little focus has been placed on assigning economic value to this key ecosystem service. Setting biological control on a firm economic foundation would help to broaden its utility and adoption for sustainable crop protection. Here we discuss approaches and methods available for valuation of biological control of arthropod pests by arthropod natural enemies and summarize economic evaluations in classical  augmentative  and conservation biological control. Emphasis is placed on valuation of conservation biological control  which has received little attention. We identify some of the challenges of and opportunities for applying economics to biological control to advance integrated pest management. Interaction among diverse scientists and stakeholders will be required to measure the direct and indirect costs and benefits of biological control that will allow farmers and others to internalize the benefits that incentivize and accelerate adoption for private and public good.Sertraline Versus Placebo in Patients with Major Depressive Disorder Undergoing Hemodialysis: A Randomized  Controlled Feasibility Trial.PubMedFriedli  Karin; Guirguis  Ayman; Almond  Michael; Day  Clara; Chilcot  Joseph; Da Silva-Gane  Maria; Davenport  Andrew; Fineberg  Naomi A; Spencer  Benjamin; Wellsted  David; Farrington  Ken2017-02-07Depression is common in patients on hemodialysis  but data on the benefits and risks of antidepressants in this setting are limited. We conducted a multicenter  randomized  double-blind  placebo-controlled trial of sertraline over 6 months in patients on hemodialysis with depression to determine study feasibility  safety  and effectiveness. Patients on hemodialysis at five United Kingdom renal centers completed the Beck Depression Inventory II. Those scoring â‰¥16 and not already on treatment for depression were invited to undergo diagnostic interview to confirm major depressive disorder. Eligible patients with major depressive disorder were randomized to receive the study medication-either sertraline or placebo. Outcomes included recruitment and dropout rates  change in the Montgomery-Asberg Depression Rating Scale and Beck Depression Inventory II  and qualitative information to guide design of a large-scale trial. In total  709 patients were screened and enrolled between April of 2013 and October of 2014; 231 (32.6%) had Beck Depression Inventory II scores â‰¥16  and 68 (29%) of these were already receiving treatment for depression. Sixty-three underwent diagnostic interview  37 were diagnosed with major depressive disorder  and 30 were randomized; 21 completed the trial: eight of 15 on sertraline and 13 of 15 on placebo (P=0.05). Dropouts due to adverse and serious adverse events were greater in the sertraline group. All occurred in the first 3 months. Over 6 months  depression scores improved in both groups. Beck Depression Inventory II score fell from 29.1Â±8.4 to 17.3Â±12.4 (P<0.001)  and Montgomery-Asberg Depression Rating Scale score fell from 24.5Â±4.1 to 10.3Â±5.8 (P<0.001). There were no differences between sertraline and placebo groups. Although small  this is the largest randomized trial to date of antidepressant medication in patients on hemodialysis. Our results highlight recruitment issues. No benefit was observed  but trial size and the substantialMIDSHIPS: multicentre intervention designed for self-harm using interpersonal problem-solving: protocol for a randomised controlled feasibility study.PubMedCollinson  Michelle; Owens  David; Blenkiron  Paul; Burton  Kayleigh; Graham  Liz; Hatcher  Simon; House  Allan; Martin  Katie; Pembroke  Louise; Protheroe  David; Tubeuf  Sandy; Farrin  Amanda2014-05-10Around 150 000 people each year attend hospitals in England due to self-harm  many of them more than once. Over 5 000 people die by suicide each year in the UK  a quarter of them having attended hospital in the previous year because of self-harm. Self-harm is a major identifiable risk factor for suicide. People receive variable care at hospital; many are not assessed for their psychological needs and little psychological therapy is offered. Despite its frequent occurrence  we have no clear research evidence about how to reduce the repetition of self-harm. Some people who have self-harmed show less active ways of solving problems  and brief problem-solving therapies are considered the most promising psychological treatments. This is a pragmatic  individually randomised  controlled  feasibility study comparing interpersonal problem-solving therapy plus treatment-as-usual with treatment-as-usual alone  for adults attending a general hospital following self-harm. A total of 60 participants will be randomised equally between the treatment arms  which will be balanced with respect to the type of most recent self-harm event  number of previous self-harm events  gender and age. Feasibility objectives are as follows: a) To establish and field test procedures for implementing the problem-solving intervention; b) To determine the feasibility and best method of participant recruitment and follow up; c) To assess therapeutic delivery; d) To assess the feasibility of obtaining the definitive trial's primary and secondary outcomes; e) To assess the perceived burden and acceptability of obtaining the trial's self-reported outcome data; f) To inform the sample size calculation for the definitive trial. The results of this feasibility study will be used to determine the appropriateness of proceeding to a definitive trial and will allow us to design an achievable trial of interpersonal problem-solving therapy for adults who self-harm. Current Controlled Trials (ISRCTN54036115).Protocol for a feasibility cluster randomised controlled trial of a peer-led school-based intervention to increase the physical activity of adolescent girls (PLAN-A).PubMedSebire  Simon J; Edwards  Mark J; Campbell  Rona; Jago  Russell; Kipping  Ruth; Banfield  Kathryn; Tomkinson  Keeley; Garfield  Kirsty; Lyons  Ronan A; Simon  Joanne; Blair  Peter S; Hollingworth  William2016-01-01Physical activity levels are low amongst adolescent girls  and this population faces specific barriers to being active. Peer influences on health behaviours are important in adolescence and peer-led interventions might hold promise to change behaviour. This paper describes the protocol for a feasibility cluster randomised controlled trial of Peer-Led physical Activity iNtervention for Adolescent girls (PLAN-A)  a peer-led intervention aimed at increasing adolescent girls' physical activity levels. A two-arm cluster randomised feasibility trial will be conducted in six secondary schools (intervention n â€‰=â€‰4; control n â€‰=â€‰2) with year 8 (12-13Â years old) girls. The intervention will operate at a year group level and consist of year 8 girls nominating influential peers within their year group to become peer-supporters. Approximately 15Â % of the cohort will receive 3Â days of training about physical activity and interpersonal communication skills. Peer-supporters will then informally diffuse messages about physical activity amongst their friends for 10Â weeks. Data will be collected at baseline (time 0 (T0))  immediately after the intervention (time 1 (T1)) and 12Â months after baseline measures (time 2 (T2)). In this feasibility trial  the primary interest is in the recruitment of schools and participants (both year 8 girls and peer-supporters)  delivery and receipt of the intervention  data provision rates and identifying the cost categories for future economic analysis. Physical activity will be assessed using 7-day accelerometry  with the likely primary outcome in a fully-powered trial being daily minutes of moderate-to-vigorous physical activity. Participants will also complete psychosocial questionnaires at each time point: assessing motivation  self-esteem and peer physical activity norms. Data analysis will be largely descriptive and focus on recruitment  attendance and data provision rates. The findings will inform the sample size required for aActive Control of Fan Noise-Feasibility Study. Volume 1; Flyover System Noise StudiesNASA Technical Reports Server (NTRS)Kraft  Robert E.; Janardan  B. A.; Kontos  G. C.; Gliebe  P. R.1994-01-01A study has been completed to examine the potential reduction of aircraft flyover noise by the method of active noise control (ANC). It is assumed that the ANC system will be designed such that it cancels discrete tones radiating from the engine fan inlet or fan exhaust duct. Thus  without considering the engineering details of the ANC system design  tone levels are arbitrarily removed from the engine component noise spectrum and the flyover noise EPNL levels are compared with and without the presence of tones. The study was conducted for a range of engine cycles  corresponding to fan pressure ratios from 1.3 to 1.75. The major conclusions that can be drawn are that  for a fan pressure ratio of 1.75  ANC of tones gives about the same suppression as acoustic treatment without ANC  and for a fan pressure ratio of 1.45  ANC appears to offer less effectiveness than passive treatment. Additionally  ANC appears to be more effective at sideline and cutback conditions than at approach. Overall EPNL suppressions due to tone removal range from about 1 to 3 dB at takeoff engine speeds and from 1 to 5 db at approach speeds. Studies of economic impact of the installation of an ANC system for the four engine cases indicate increases of DOC ranging from 1 to 2 percent  favoring the lower fan pressure ratio engines. Further study is needed to confirm the results by examining additional engine data  particularly at low fan pressure ratios  and studying the details of the current results to obtain a more complete understanding. Further studies should also include determining the effects of combining passive and active treatment.Insecticide Resistance and Malaria Vector Control: The Importance of Fitness Cost Mechanisms in Determining Economically Optimal Control TrajectoriesPubMed CentralBrown  Zachary S.; Dickinson  Katherine L.; Kramer  Randall A.2014-01-01The evolutionary dynamics of insecticide resistance in harmful arthropods has economic implications  not only for the control of agricultural pests (as has been well studied)  but also for the control of disease vectors  such as malaria-transmitting Anopheles mosquitoes. Previous economic work on insecticide resistance illustrates the policy relevance of knowing whether insecticide resistance mutations involve fitness costs. Using a theoretical model  this article investigates economically optimal strategies for controlling malaria-transmitting mosquitoes when there is the potential for mosquitoes to evolve resistance to insecticides. Consistent with previous literature  we find that fitness costs are a key element in the computation of economically optimal resistance management strategies. Additionally  our models indicate that different biological mechanisms underlying these fitness costs (e.g.  increased adult mortality and/or decreased fecundity) can significantly alter economically optimal resistance management strategies. PMID:23448053Is high-intensity interval cycling feasible and more beneficial than continuous cycling for knee osteoarthritic patients? Results of a randomised control feasibility trial.PubMedKeogh  Justin W; Grigg  Josephine; Vertullo  Christopher J2018-01-01 attributed to one HIIT participant. Pre-post-test analyses indicated both groups significantly improved their WOMAC scores  with the HIIT group also significantly improving in the TUG and STS. The only significant between-group difference was observed in the TUG  whereby the HIIT group improved significantly more than the MICT group. No significant changes were observed in the Lequesne index  gait speed or body composition for either group. An unsupervised home-based HIIT cycle program appears somewhat feasible for middle-aged and older adults with knee OA and may produce similar improvements in health-related quality of life but greater improvements in physical function than MICT. These results need to be confirmed in larger randomised controlled trials to better elucidate the potential for HIIT to improve outcomes for those with knee OA. Additional research needs to identify and modify the potential barriers affecting the initiation and adherence to home-based HIIT cycling exercise programs by individuals with knee OA.Is high-intensity interval cycling feasible and more beneficial than continuous cycling for knee osteoarthritic patients? Results of a randomised control feasibility trialPubMed CentralGrigg  Josephine2018-01-01  with 24 of these attributed to one HIIT participant. Preâ€“post-test analyses indicated both groups significantly improved their WOMAC scores  with the HIIT group also significantly improving in the TUG and STS. The only significant between-group difference was observed in the TUG  whereby the HIIT group improved significantly more than the MICT group. No significant changes were observed in the Lequesne index  gait speed or body composition for either group. Discussion An unsupervised home-based HIIT cycle program appears somewhat feasible for middle-aged and older adults with knee OA and may produce similar improvements in health-related quality of life but greater improvements in physical function than MICT. These results need to be confirmed in larger randomised controlled trials to better elucidate the potential for HIIT to improve outcomes for those with knee OA. Additional research needs to identify and modify the potential barriers affecting the initiation and adherence to home-based HIIT cycling exercise programs by individuals with knee OA. PMID:29761054A Summary of Two Recent UAS Command and Control (C2) Communications Feasibility StudiesNASA Technical Reports Server (NTRS)Ponchak  Denise S.; Auld  Elisabeth; Church  Gary; Henriksen  Stephen2016-01-01In Spring of 2015  the NextGen Institute conducted two UAS C2 Communications Feasibility Studies on behalf of the FAA UAS Integration Office to develop two limited UAS C2 operational examples  each involving low-altitude BLOS (Beyond Line of Sight) Line of Communication (LOC) UAS applications  as part of assessing the myriad practical UAS C2 deployment challenges associated with these approaches. The studies investigated the feasibility of ""Point-to-Point"" (PTP) and ""Network"" approaches to UAS C2 to better understand potential user needs and to explore evolutionary paths to establishing a nation-wide system for delivering UAS C2 communications. This paper will summarize the solicitation  approach and results of the two studies teams led by Aviation Management Associates  Inc. and Exelis Inc.Conceptualizing threats to tobacco control from international economic agreements: the Brazilian experience.PubMedDrope  Jeffrey; McGrady  Benn; Bialous  Stella Aguinaga; Lencucha  Raphael; Silva  Vera Luiza da Costa E2017-10-19Using the results of dozens of interviews with key actors involved in tobacco control policymaking  we examine these actors' perceptions of threats to tobacco control policy efforts from international economic policies on trade and investment. We also evaluate  from a legal perspective  the genuine threats that exist or potential challenges that economic policies may pose to the Brazilian government's public health efforts. We find that most actors did not perceive these economic policies as a major threat to tobacco control. Objectively  we found that some threats do exist. For example  Brazil's attempt to ban most tobacco additives and flavorings continues to met resistance at the World Trade Organization.Protocol for a feasibility randomised controlled trial of the use of Physical ACtivity monitors in an Exercise Referral Setting: the PACERS study.PubMedHawkins  Jemma; Edwards  Michelle; Charles  Joanna; Jago  Russell; Kelson  Mark; Morgan  Kelly; Murphy  Simon; Oliver  Emily; Simpson  Sharon; Edwards  Rhiannon Tudor; Moore  Graham2017-01-01Exercise referral schemes are recommended by the National Institute for Clinical Excellence (NICE) for physical activity promotion among inactive patients with health conditions or risk factors. Whilst there is evidence for the initial effectiveness and cost-effectiveness of such schemes for increasing physical activity  evidence of long-term effects is limited. Techniques such as goal setting  self-monitoring and personalised feedback may support motivation for physical activity. Technologies such as activity monitoring devices provide an opportunity to enhance delivery of motivational techniques. This paper describes the PACERS study protocol  which aims to assess the feasibility and acceptability of implementing an activity monitor within the existing Welsh National Exercise Referral Scheme (NERS) and proposed evaluation methodology for a full-scale randomised controlled trial. The PACERS study consists of a pilot randomised controlled trial  process evaluation and exploratory economic analyses. Participants will be recruited from the generic pathway of the Welsh NERS and will be randomly assigned to receive the intervention or usual practice. Usual practice is a 16-week structured exercise programme; the intervention consists of an accelerometry-based activity monitor (MyWellnessKey) and an associated web platform (MyWellnessCloud). The primary outcomes are predefined progression criteria assessing the acceptability and feasibility of the intervention and feasibility of the proposed evaluation methodology. Postal questionnaires will be completed at baseline (time 0: T0)  16Â weeks after T0 (T1) and 12Â months after T0 (T2). Routinely collected data will also be accessed at the same time points. A sub-sample of intervention participants and exercise referral staff will be interviewed following initiation of intervention delivery and at the end of the study. The PACERS study seeks to assess the feasibility of adding a novel motivational component to an existingEconomic analysis of HPAI control in the Netherlands II: comparison of control strategies.PubMedLongworth  N; Mourits  M C M; Saatkamp  H W2014-06-01A combined epidemiological-economic modelling approach was used to analyse strategies for highly pathogenic avian influenza (HPAI) control for the Netherlands. The modelling framework used was InterSpread Plus (ISP)  a spatially based  stochastic and dynamic simulation model. A total of eight control strategies were analysed  including pre-emptive depopulation and vaccination strategies. The analysis was carried out for three different regions in the Netherlands: high-  medium- and low-density areas (HDA  MDA and LDA  respectively). The analysis included the veterinary impact (e.g. number of infected premises and duration)  but was particularly focused on the impact on direct costs (DC) and direct consequential costs. The efficient set of control strategies for HDA and MDA included strategies based on either pre-emptive depopulation only or combined vaccination and pre-emptive depopulation: D2 (pre-emptive depopulation within a radius of 2 km)  RV3 + D1 (ring vaccination within a radius of 3 km and additional pre-emptive depopulation within a radius of 1 km) and PV + D1 (preventive vaccination in non-affected HDAs and pre-emptive depopulation within a radius of 1 km in the affected HDA). Although control solely based on depopulation in most cases showed to be effective for LDA  pre-emptive depopulation showed to have an additional advantage in these areas  that is  prevention of 'virus jumps' to other areas. The pros and cons of the efficient control strategies were discussed  for example  public perception and risk of export restrictions. It was concluded that for the Netherlands control of HPAI preferably should be carried out using strategies including pre-emptive depopulation with or without vaccination. Particularly  the short- and long-term implications on export  that is  indirect consequential costs (ICC) and aftermath costs of these strategies  should be analysed further. Â© 2012 Blackwell Verlag GmbH.Cost-Effectiveness of Aflatoxin Control Methods: Economic IncentivesUSDA-ARS?s Scientific Manuscript databaseMultiple sectors in U.S. crop industries â€“ growers  elevators  handlers/shellers  processors  distributors  and consumers â€“ are affected by aflatoxin contamination of commodities  and have the potential to control it. Aflatoxin control methods at both preharvest and postharvest levels have been dev...Neutron economic reactivity control system for light water reactorsDOEpatentsLuce  Robert G.; McCoy  Daniel F.; Merriman  Floyd C.; Gregurech  Steve1989-01-01A neutron reactivity control system for a LWBR incorporating a stationary seed-blanket core arrangement. The core arrangement includes a plurality of contiguous hexagonal shaped regions. Each region has a central and a peripheral blanket area juxapositioned an annular seed area. The blanket areas contain thoria fuel rods while the annular seed area includes seed fuel rods and movable thoria shim control rods.Sub-marine groundwater for the supply of drinking water. A review of the hydro-geological potential and its technical and economical feasibility.NASA Astrophysics Data System (ADS)Haakon Bakken  Tor; Mangset  Lars Erik2010-05-01Sub-marine groundwater is water stored in aquifers under the sea-bed and is expected to be present in large quantities on the continental shelf. The proposed utilization of sub-marine groundwater as a new source of drinking water supply is a radical and new idea that has never been fully explored or tested anywhere in the world. In regions where access to raw water of acceptable quality is very limited and desalination of sea water is the only realistic alternative to increase the supply of potable water  utilization of sub-marine groundwater might play a role. A technical concept deemed suitable to the hydrological and geological characteristics of sub-marine water is proposed based on well-proven technology from the off-shore oil & gas sector. A course economic assessment of this concept is conducted based on judgmental cost estimates from experts in the hydro-geological and oil & gas domain. The technical concept uses a jackup or a barge with a modular rig during drilling  while a steel jacket with a modular rig or a sub-sea installation is assumed to be feasible technical solutions during production. The selection of technology will vary from case to case depending on factors such as the local off-shore conditions (wave/wind exposure  drilling depth  distance from shore  etc.)  required reliability of supply  access to/availability of technology and financial considerations. A standard reverse osmosis plant is proposed as treatment solution  given the assumed need to desalinate moderately saline water. The costs of each treatment step  as a function of raw water salinity are providing input to the subsequent economical estimates. The proposed treatment solution is assumed being a conservative choice of technology. The costs of producing drinking water from sub-marine groundwater are compared with desalination of sea water  given that this is the only realistic alternative. Based on a systematic risk assessment using the same comparative financial structure andRemote controlled robot assisted cardiac navigation: feasibility assessment and validation in a porcine model.PubMedGanji  Yusof; Janabi-Sharifi  Farrokh; Cheema  Asim N2011-12-01Despite the recent advances in catheter design and technology  intra-cardiac navigation during electrophysiology procedures remains challenging. Incorporation of imaging along with magnetic or robotic guidance may improve navigation accuracy and procedural safety. In the present study  the in vivo performance of a novel remote controlled Robot Assisted Cardiac Navigation System (RACN) was evaluated in a porcine model. The navigation catheter and target sensor were advanced to the right atrium using fluoroscopic and intra-cardiac echo guidance. The target sensor was positioned at three target locations in the right atrium (RA) and the navigation task was completed by an experienced physician using both manual and RACN guidance. The navigation time  final distance between the catheter tip and target sensor  and variability in final catheter tip position were determined and compared for manual and RACN guided navigation. The experiments were completed in three animals and five measurements recorded for each target location. The mean distance (mm) between catheter tip and target sensor at the end of the navigation task was significantly less using RACN guidance compared with manual navigation (5.02â€‰Â±â€‰0.31 vs. 9.66â€‰Â±â€‰2.88  pâ€‰=â€‰0.050 for high RA  9.19â€‰Â±â€‰1.13 vs. 13.0â€‰Â±â€‰1.00  pâ€‰=â€‰0.011 for low RA and 6.77â€‰Â±â€‰0.59 vs. 15.66â€‰Â±â€‰2.51  pâ€‰=â€‰0.003 for tricuspid valve annulus). The average time (s) needed to complete the navigation task was significantly longer by RACN guided navigation compared with manual navigation (43.31â€‰Â±â€‰18.19 vs. 13.54â€‰Â±â€‰1.36  pâ€‰=â€‰0.047 for high RA  43.71â€‰Â±â€‰11.93 vs. 22.71â€‰Â±â€‰3.79  pâ€‰=â€‰0.043 for low RA and 37.84â€‰Â±â€‰3.71 vs. 16.13â€‰Â±â€‰4.92  pâ€‰=â€‰0.003 for tricuspid valve annulus. RACN guided navigation resulted in greater consistency in performance compared with manual navigation as evidenced by lower variability in final distance measurements (0.41 vs. 0.99â€‰mm  pâ€‰=â€‰0Analyzing Crime and Crime Control: A Resource Guide. Economics-Political Science Series.ERIC Educational Resources Information CenterButterfield  Ruth I.; And OthersThis document  the fourth in a series of resource guides emphasizing economic-political analysis of contemporary public policies and issues  focuses on crime control. Designed as a three-week unit for secondary school students  the guide is presented in three sections. The introduction presents an economic and a political science framework forâ€¦A Randomized Controlled Trial of a Behavioral Economic Supplement to Brief Motivational Interventions for College DrinkingERIC Educational Resources Information CenterMurphy  James G.; Dennhardt  Ashley A.; Skidmore  Jessica R.; Borsari  Brian; Barnett  Nancy P.; Colby  Suzanne M.; Martens  Matthew P.2012-01-01Objective: Behavioral economic theory suggests that a reduction in substance use is most likely when there is an increase in rewarding substance-free activities. The goal of this randomized controlled clinical trial was to evaluate the incremental efficacy of a novel behavioral economic supplement (Substance-Free Activity Session [SFAS]) to aâ€¦Immediate chest X-ray for patients at risk of lung cancer presenting in primary care: randomised controlled feasibility trialPubMed CentralNeal  Richard D; Barham  Allan; Bongard  Emily; Edwards  Rhiannon Tudor; Fitzgibbon  Jim; Griffiths  Gareth; Hamilton  Willie; Hood  Kerenza; Nelson  Annmarie; Parker  David; Porter  Cath; Prout  Hayley; Roberts  Kirsty; Rogers  Trevor; Thomas-Jones  Emma; Tod  Angela; Yeo  Seow Tien; Hurt  Chris N2017-01-01Background: Achieving earlier stage diagnosis is one option for improving lung cancer outcomes in the United Kingdom. Patients with lung cancer typically present with symptoms to general practitioners several times before referral or investigation. Methods: We undertook a mixed methods feasibility individually randomised controlled trial (the ELCID trial) to assess the feasibility and inform the design of a definitive  fully powered  UK-wide  Phase III trial of lowering the threshold for urgent investigation of suspected lung cancer. Patients over 60  with a smoking history  presenting with new chest symptoms to primary care  were eligible to be randomised to intervention (urgent chest X-ray) or usual care. Results: The trial design and materials were acceptable to GPs and patients. We randomised 255 patients from 22 practices  although the proportion of eligible patients who participated was lower than expected. Survey responses (89%)  and the fidelity of the intervention (82% patients X-rayed within 3 weeks) were good. There was slightly higher anxiety and depression in the control arm in participants aged >75. Three patients (1.2%) were diagnosed with lung cancer. Conclusions: We have demonstrated the feasibility of individually randomising patients at higher risk of lung cancer  to a trial offering urgent investigation or usual care. PMID:28072761A low cost virtual reality system for home based rehabilitation of the arm following stroke: a randomised controlled feasibility trial.PubMedStanden  P J; Threapleton  K; Richardson  A; Connell  L; Brown  D J; Battersby  S; Platts  F; Burton  A2017-03-01To assess the feasibility of conducting a randomised controlled trial of a home-based virtual reality system for rehabilitation of the arm following stroke. Two group feasibility randomised controlled trial of intervention versus usual care. Patients' homes. Patients aged 18 or over  with residual arm dysfunction following stroke and no longer receiving any other intensive rehabilitation. Eight weeks' use of a low cost home-based virtual reality system employing infra-red capture to translate the position of the hand into game play or usual care. The primary objective was to collect information on the feasibility of a trial  including recruitment  collection of outcome measures and staff support required. Patients were assessed at three time points using the Wolf Motor Function Test  Nine-Hole Peg Test  Motor Activity Log and Nottingham Extended Activities of Daily Living. Over 15 months only 47 people were referred to the team. Twenty seven were randomised and 18 (67%) of those completed final outcome measures. Sample size calculation based on data from the Wolf Motor Function Test indicated a requirement for 38 per group. There was a significantly greater change from baseline in the intervention group on midpoint Wolf Grip strength and two subscales of the final Motor Activity Log. Training in the use of the equipment took a median of 230 minutes per patient. To achieve the required sample size  a definitive home-based trial would require additional strategies to boost recruitment rates and adequate resources for patient support.Managing with Learning Disability and Diabetes: OK-Diabetes - a case-finding study and feasibility randomised controlled trial.PubMedHouse  Allan; Bryant  Louise; Russell  Amy M; Wright-Hughes  Alexandra; Graham  Liz; Walwyn  Rebecca; Wright  Judy M; Hulme  Claire; O'Dwyer  John L; Latchford  Gary; Meer  Shaista; Birtwistle  Jacqueline C; Stansfield  Alison; Ajjan  Ramzi; Farrin  Amanda2018-05-01.1%  SD 1.4%]. The BMI of 65% of participants was >â€‰30â€‰kg/m 2 and of 21% was >â€‰40â€‰kg/m 2 . Many participants reported low mood  dissatisfaction with lifestyle and diabetes management and an interest in change. Non-response rates were high (45/147  31%) for medical data requested from the primary care team. In the RCT  82 participants were randomised. The mean baseline HbA 1c level was 56â€‰mmol/mol (SD 16.5â€‰mmol/mol; 7.3%  SD 1.5%) and the mean BMI was 34â€‰kg/m 2 (SD 7.6â€‰kg/m 2 ). All SSM sessions were completed by 35 out of 41 participants. The adherence measure was obtained in 37 out of 41 participants. The follow-up HbA 1c level and BMI was obtained for 75 out of 82 (91%) and 77 out of 82 (94%) participants  respectively. Most participants reported a positive experience of the intervention. A low response rate and difficulty understanding the EuroQol-5 Dimensions were challenges in obtaining data for an economic analysis. We recruited from only 60% of eligible general practices  and 90% of participants were on a general practice learning disability register  which meant that we did not recruit many participants from the wider population with milder learning disability. A definitive RCT is feasible and would need to recruit 194 participants per arm. The main barrier is the resource-intensive nature of recruitment. Future research is needed into the effectiveness of obesity treatments in this population  particularly estimating the longer-term outcomes that are important for health benefit. Research is also needed into improving ways of assessing quality of life in adults with a learning disability. Current Controlled Trials ISRCTN41897033. This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment ; Vol. 22  No. 26. See the NIHR Journals Library website for further project information.Feasibility of a Patient-Controlled Cognitive Behavioral Intervention for Pain  Fatigue  and Sleep Disturbance in CancerPubMed CentralKwekkeboom  Kristine L.; Abbott-Anderson  Kristen; Wanta  Britt2009-01-01Purpose To evaluate the feasibility of a patient-controlled cognitive-behavioral intervention for pain  fatigue  and sleep disturbance during treatment for advanced cancer  and to assess initial efficacy of the intervention in controlling symptoms. Design One-group pretest-posttest design. Setting Outpatient oncology clinics at a Comprehensive Cancer Center in the Midwestern United States. Sample 30 adults with advanced (recurrent or metastatic) colorectal  lung  prostate  or GYN cancer receiving chemotherapy or radiotherapy. Methods Participants completed baseline measures (demographics  symptom inventory) and received education and training to use an MP3 player loaded with 12 cognitive-behavioral strategies (e.g.  relaxation exercises  guided imagery  nature sound recordings). Participants used the strategies as needed for symptom management over the following 2-weeks  keeping a log of symptom ratings with each use. Following the two-week intervention  participants completed a second symptom inventory and an evaluation of the intervention. Main Research Variables Feasibility  patient-controlled cognitive-behavioral intervention  pain  fatigue  sleep disturbance. Findings 73% of the 43 eligible patients agreed to participate (N=30) and of these  90% (n=27) completed the study. The majority of participants reported that they enjoyed the intervention  had learned useful skills  and perceived improvement in their symptoms. Symptom scores at 2-weeks did not differ significantly from baseline  however significant reductions in pain  fatigue  and sleep disturbance severity were found in ratings made immediately before and after use of a cognitive-behavioral strategy. Conclusions The patient-controlled cognitive-behavioral intervention appears feasible for further study and could reduce day-to-day severity of co-occurring pain  fatigue  and sleep disturbance. Implications for Nursing A randomized controlled trial is necessary to test efficacy of the intervention for coFeasibility of ballistic strength training in sub-acute stroke: A randomized  controlled  assessor-blinded pilot study.PubMedHendrey  Genevieve; Clark  Ross A; Holland  Anne E; Mentiplay  Benjamin F; Davis  Carly; Windfeld-Lund  Cristie; Raymond  Melissa J; Williams  Gavin2018-05-30To establish the feasibility and effectiveness of a six week ballistic strength training protocol in people with stroke. Randomized  controlled  assessor-blinded study. Sub-acute inpatient rehabilitation. Consecutively admitted inpatients with a primary diagnosis of first ever stroke with lower limb weakness  functional ambulation category score of â‰¥3  and ability to walk â‰¥14m were screened for eligibility to recruit 30 participants for randomization. Participants were randomized to standard therapy or ballistic strength training three times per week for six weeks. The primary aim was to evaluate feasibility and outcomes included recruitment rate  participant retention and attrition  feasibility of the exercise protocol  therapist burden and participant safety. Secondary outcomes included measures of mobility  lower limb muscle strength  muscle power and quality of life. Thirty participants (11% of those screened) with mean age of 50 (SD 18) years were randomized. The median number of sessions attended was 15/18 and 17/18 for the ballistic and control groups respectively. Earlier than expected discharge home (n=4) and illness (n=7) were the most common reasons for non-attendance. Participants performed the exercises safely  with no study-related adverse events. There were significant (p<0.05) between-group changes favoring the ballistic group for comfortable gait velocity (mean difference (MD) 0.31m/s  95% confidence interval CI: 0.08 to 0.52)  muscle power  as measured by peak jump height (MD 8cm  95% CI: 3 to 13) and peak propulsive velocity (MD 64cm/s  95% CI: 17 to 112). Ballistic training was safe and feasible in select ambulant people with stroke. Similar rates of retention and attrition suggest that ballistic training was acceptable to patients. Secondary outcomes provide promising results that warrant further investigation in a larger trial. Copyright Â© 2018. Published by Elsevier Inc.Feasibility study from a randomized controlled trial of standard closure of a stoma site vs biological mesh reinforcement.PubMed2016-09-01Hernia formation occurs at closed stoma sites in up to 30% of patients. The Reinforcement of Closure of Stoma Site (ROCSS) randomized controlled trial is evaluating whether placement of biological mesh during stoma closure safely reduces hernia rates compared with closure without mesh  without increasing surgical or wound complications. This paper aims to report recruitment  deliverability and safety from the internal feasibility study. A multicentre  patient and assessor blinded  randomized controlled trial  delivered through surgical trainee research networks. A 90-patient internal feasibility study assessed recruitment  randomization  deliverability and early (30Â day) safety of the novel surgical technique (ClinicalTrials.gov registration number NCT02238964). The feasibility study recruited 90 patients from the 104 considered for entry (45 to mesh  45 to no mesh). Seven of eight participating centres randomized patients within 30Â days of opening. Overall  41% of stomas were created for malignant disease and 73% were ileostomies. No mesh-specific complications occurred. Thirty-one postoperative adverse events were experienced by 31 patients  including surgical site infection (9%) and postoperative ileus (6%). One mesh was removed for re-access to the abdominal cavity  for reasons unrelated to the mesh. Independent review by the Data Monitoring and Ethics Committee of adverse event data by treatment allocation found no safety concerns. Multicentre randomization to this trial of biological mesh is feasible  with no early safety concerns. Progression to the full Phase III trial has continued. ROCSS shows that trainee research networks can efficiently develop and deliver complex interventional surgical trials. Colorectal Disease Â© 2016 The Association of Coloproctology of Great Britain and Ireland.Individual music therapy for managing neuropsychiatric symptoms for people with dementia and their carers: a cluster randomised controlled feasibility study.PubMedHsu  Ming Hung; Flowerdew  Rosamund; Parker  Michael; Fachner  JÃ¶rg; Odell-Miller  Helen2015-07-18Previous research highlights the importance of staff involvement in psychosocial interventions targeting neuropsychiatric symptoms of dementia. Music therapy has shown potential effects  but it is not clear how this intervention can be programmed to involve care staff within the delivery of patients' care. This study reports initial feasibility and outcomes from a five month music therapy programme including weekly individual active music therapy for people with dementia and weekly post-therapy video presentations for their carers in care homes. 17 care home residents and 10 care staff were randomised to the music therapy intervention group or standard care control group. The cluster randomised  controlled trial included baseline  3-month  5-month and post-intervention 7-month measures of residents' symptoms and well-being. Carer-resident interactions were also assessed. Feasibility was based on carers' feedback through semi-structured interviews  programme evaluations and track records of the study. The music therapy programme appeared to be a practicable and acceptable intervention for care home residents and staff in managing dementia symptoms. Recruitment and retention data indicated feasibility but also challenges. Preliminary outcomes indicated differences in symptoms (13.42  95 % CI: [4.78 to 22.07; pâ€‰=â€‰0.006]) and in levels of wellbeing (-0.74  95 % CI: [-1.15 to -0.33; pâ€‰=â€‰0.003]) between the two groups  indicating that residents receiving music therapy improved. Staff in the intervention group reported enhanced caregiving techniques as a result of the programme. The data supports the value of developing a music therapy programme involving weekly active individual music therapy sessions and music therapist-carer communication. The intervention is feasible with modifications in a more rigorous evaluation of a larger sample size. Clinicaltrials.gov  number NCT01744600.Feasibility of the Enhancing Participation In the Community by improving Wheelchair Skills (EPIC Wheels) program: study protocol for a randomized controlled trialPubMed Central2013-01-01Background Many older adults rely on a manual wheelchair for mobility but typically receive little  if any  training on how to use their wheelchair effectively and independently. Standardized skill training is an effective intervention  but limited access to clinician trainers is a substantive barrier. Enhancing Participation in the Community by Improving Wheelchair Skills (EPIC Wheels) is a 1-month monitored home training program for improving mobility skills in older novice manual wheelchair users  integrating principles from andragogy and social cognitive theory. The purpose of this study is to determine whether feasibility indicators and primary clinical outcome measures of the EPIC Wheels program are sufficiently robust to justify conducting a subsequent multi-site randomized controlled trial. Methods A 2 Ã— 2 factorial randomized controlled trial at two sites will compare improvement in wheelchair mobility skills between an EPIC Wheels treatment group and a computer-game control group  with additional wheelchair use introduced as a second factor. A total of 40 community-dwelling manual wheelchair users at least 55 years old and living in two Canadian metropolitan cities (n = 20 Ã— 2) will be recruited. Feasibility indicators related to study process  resources  management  and treatment issues will be collected during data collection and at the end of the study period  and evaluated against proposed criteria. Clinical outcome measures will be collected at baseline (pre-randomization) and post-intervention. The primary clinical outcome measure is wheelchair skill capacity  as determined by the Wheelchair Skills Test  version 4.1. Secondary clinical outcome measures include wheelchair skill safety  satisfaction with performance  wheelchair confidence  life-space mobility  divided-attention  and health-related quality of life. Discussion The EPIC Wheels training program offers several innovative features. The convenient  portable  economical  and adaptableFeasibility of the Enhancing Participation In the Community by improving Wheelchair Skills (EPIC Wheels) program: study protocol for a randomized controlled trial.PubMedGiesbrecht  Edward M; Miller  William C; Eng  Janice J; Mitchell  Ian M; Woodgate  Roberta L; Goldsmith  Charles H2013-10-24Many older adults rely on a manual wheelchair for mobility but typically receive little  if any  training on how to use their wheelchair effectively and independently. Standardized skill training is an effective intervention  but limited access to clinician trainers is a substantive barrier. Enhancing Participation in the Community by Improving Wheelchair Skills (EPIC Wheels) is a 1-month monitored home training program for improving mobility skills in older novice manual wheelchair users  integrating principles from andragogy and social cognitive theory. The purpose of this study is to determine whether feasibility indicators and primary clinical outcome measures of the EPIC Wheels program are sufficiently robust to justify conducting a subsequent multi-site randomized controlled trial. A 2 Ã— 2 factorial randomized controlled trial at two sites will compare improvement in wheelchair mobility skills between an EPIC Wheels treatment group and a computer-game control group  with additional wheelchair use introduced as a second factor. A total of 40 community-dwelling manual wheelchair users at least 55 years old and living in two Canadian metropolitan cities (n = 20 Ã— 2) will be recruited. Feasibility indicators related to study process  resources  management  and treatment issues will be collected during data collection and at the end of the study period  and evaluated against proposed criteria. Clinical outcome measures will be collected at baseline (pre-randomization) and post-intervention. The primary clinical outcome measure is wheelchair skill capacity  as determined by the Wheelchair Skills Test  version 4.1. Secondary clinical outcome measures include wheelchair skill safety  satisfaction with performance  wheelchair confidence  life-space mobility  divided-attention  and health-related quality of life. The EPIC Wheels training program offers several innovative features. The convenient  portable  economical  and adaptable tablet-based  home program modelA feasible  economical  and accurate analytical method for simultaneous determination of six alkaloid markers in Aconiti Lateralis Radix Praeparata from different manufacturing sources and processing ways.PubMedZhang  Yi-Bei; DA  Juan; Zhang  Jing-Xian; Li  Shang-Rong; Chen  Xin; Long  Hua-Li; Wang  Qiu-Rong; Cai  Lu-Ying; Yao  Shuai; Hou  Jin-Jun; Wu  Wan-Ying; Guo  De-An2017-04-01Aconiti Lateralis Radix Praeparata (Fuzi) is a commonly used traditional Chinese medicine in clinic for its potency in restoring yang and rescuing from collapse. Aconiti alkaloids  mainly including monoester-diterpenoidaconitines (MDAs) and diester-diterpenoidaconitines (DDAs)  are considered to act as both bioactive and toxic constituents. In the present study  a feasible  economical  and accurate HPLC method for simultaneous determination of six alkaloid markers using the Single Standard for Determination of Multi-Components (SSDMC) method was developed and fully validated. Benzoylmesaconine was used as the unique reference standard. This method was proven as accurate (recovery varying between 97.5%-101.8%  RSD < 3%)  precise (RSD 0.63%-2.05%)  and linear (R > 0.999 9) over the concentration ranges  and subsequently applied to quantitative evaluation of 62 batches of samples  among which 45 batches were from good manufacturing practice (GMP) facilities and 17 batches from the drug market. The contents were then analyzed by principal component analysis (PCA) and homogeneity test. The present study provided valuable information for improving the quality standard of Aconiti Lateralis Radix Praeparata. The developed method also has the potential in analysis of other Aconitum species  such as Aconitum carmichaelii (prepared parent root) and Aconitum kusnezoffii (prepared root). Copyright Â© 2017 China Pharmaceutical University. Published by Elsevier B.V. All rights reserved.Economic feasibility study on the space-based production of methane gas from human waste through aerobic digestion for use as an orbit-maintenance propellant. Master's thesisSciTech ConnectFallstead  C.C.1985-12-01This project explores the economic feasibility of creating fuel energy in space from human waste with application toward space-station orbit maintenance. The energy-generating concept proposed in this study is anaerobic digestion. This process has four benefits for space application; 1) it can stabilize human waste products  2) it can reduce solid wastes  3) it can provide a fairly clear effluent for water recovery  and 4) it can provide a fuel in the form of a gas. The analysis is dependent upon a predetermined scenario defining the input load to the digester system and the size of the spacecraft. The size moreÂ Â» shape  and altitude of the vehicle determine the atmospheric drag that must be opposed to maintain the orbit. The basic elements of the study involve 1) simulation analysis of biochemistry  2) thermochemical analysis and  3) cost analysis using the Monte Carlo method. An alternative system to which the digester is compared is transport of conventional propellants from Earth. This alternative does not consider a replacement of the anaerobic digester with some other system to stabilize the waste products of the space station  or the additional benefits of the anaerobic digester listed above. The results of this study show a statistically significant advantage of the digester system over transported conventional propellants due to the high cost of space transportation.Â«Â lessTine cultivation effects on weed control  productivity  and economics of peanut under organic managementUSDA-ARS?s Scientific Manuscript databaseIdentifying effective weed control regimes for organic peanut has become paramount for improving the feasibility of organic production. Tine cultivation is a proven effective method at reducing in-row weed populations in several crops. Field trials were therefore conducted in 2008 and 2009 to asse...The feasibility of progressive resistance training in women with polycystic ovary syndrome: a pilot randomized controlled trial.PubMedVizza  Lisa; Smith  Caroline A; Swaraj  Soji; Agho  Kingsley; Cheema  Birinder S2016-01-01To evaluate the feasibility of executing a randomized controlled trial of progressive resistance training (PRT) in women with polycystic ovary syndrome (PCOS). Women with PCOS were randomized to an experimental (PRT) group or a no-exercise (usual care) control group. The PRT group was prescribed two supervised and two unsupervised (home-based) training sessions per week for 12Â weeks. Feasibility outcomes included recruitment and attrition  adherence  adverse events  and completion of assessments. Secondary outcomes  collected pre and post intervention  included a range of pertinent physiological  functional and psychological measures. Fifteen participants were randomised into the PRT group (nâ€‰=â€‰8) or control group (nâ€‰=â€‰7); five women (nâ€‰=â€‰2 in PRT group and nâ€‰=â€‰3 in control group) withdrew from the study. The most successful recruitment sources were Facebook (40Â %) and online advertisement (27Â %)  while least successful methods were referrals by clinicians  colleagues and flyers. In the PRT group  attendance to supervised sessions was higher (95Â %; standard deviation Â±6Â %) compared to unsupervised sessions (51Â %; standard deviation Â±28Â %). No adverse events were attributed to PRT. Change in menstrual cycle status was not significantly different between groups over time (pâ€‰=â€‰0.503). However  the PRT group significantly increased body weight (pâ€‰=â€‰0.01)  BMI (pâ€‰=â€‰0.04)  lean mass (pâ€‰=â€‰0.01)  fat-free mass (pâ€‰=â€‰0.005) and lower body strength (pâ€‰=â€‰0.03)  while reducing waist circumference (pâ€‰=â€‰0.03) and HbA1c (pâ€‰=â€‰0.033) versus the control group. The PRT group also significantly improved across several domains of disease-specific and general health-related quality of life  depression  anxiety and exercise self-efficacy. A randomized controlled trial of PRT in PCOS would be feasible  and this mode of exercise may elicit a therapeutic effect on clinically important outcomes in this cohort. The success of a largeENGINEERING AND ECONOMIC FACTORS AFFECTING THE INSTALLATION OF CONTROL TECHNOLOGIES FOR MULTIPOLLUTANT STRATEGIESEPA Science InventoryThe report evaluates the engineering and economic factors associated with installing air pollution control technologies to meet the requirements of strategies to control sulfur dioxide (SO2)  oxides of nitrogen (NOX)  and mercury under the Clear Skies Act multipollutant control s...A new educational film control for use in studies of active mind-body therapies: acceptability and feasibility.PubMedInnes  Kim E; Selfe  Terry Kit; Alexander  Gina K; Taylor  Ann Gill2011-05-01The study objectives were to ascertain whether a novel educational film class is an acceptable and feasible comparison group for a randomized controlled trial regarding the effects of an active mind-body therapy on cardiovascular disease risk in postmenopausal women. Seventy-five (75) participants attended a baseline assessment visit and were randomly assigned to either a yoga group or an educational film (control) group. Both groups attended two 90-minute classes/week for 8 weeks  followed by a second assessment visit. Those not attending the second assessment were classified as dropouts. Over 60 films covering a range of topics relevant to the study population were evaluated; 15 were selected by consensus of at least 2 researchers and 1 layperson. Each film session followed the same format: an informal greeting period  viewing of the film  and a 15-minute postfilm discussion. To determine acceptability and feasibility of the film class  potential between-group differences in dropout and attendance were examined  and participant feedback given during class and on end-of-study questionnaires were evaluated. The relation between group assignment and dropout was not significant (Ï‡(2) [1  Nâ€‰=â€‰75]â€‰=â€‰0.14  pâ€‰=â€‰0.71). One-way analysis of variance (ANOVA) indicated no significant between-group difference in number of classes attended for the yoga (Xâ€‰=â€‰13.67â€‰Â±â€‰3.10) versus film group (13.26â€‰Â±â€‰1.97)  F(1 63)â€‰=â€‰0.39  pâ€‰=â€‰0.53). Participant feedback regarding the film program was positive. These findings support the feasibility and acceptability of this educational film control. Easy to standardize and tailor to a variety of populations  this film program may offer an attractive alternative to the more traditional educational control.Sham-controlled  randomized  feasibility trial of acupuncture for prevention of radiation-induced xerostomia among patients with nasopharyngeal carcinomaPubMed CentralMeng  Zhiqiang; Garcia  M. Kay; Hu  Chaosu; Chiang  Joseph; Chambers  Mark; Rosenthal  David I.; Peng  Huiting; Wu  Caijun; Zhao  Qi; Zhao  Genming; Liu  Luming; Spelman  Amy; Palmer  J. Lynn; Wei  Qi; Cohen  Lorenzo2013-01-01Background Xerostomia (dry mouth) after head/neck radiation is a common problem among cancer patients. Quality of life (QOL) is impaired  and available treatments are of little benefit. This trial determined the feasibility of conducting a sham-controlled trial of acupuncture and whether acupuncture could prevent xerostomia among head/neck patients undergoing radiotherapy. Methods A sham controlled  feasibility trial was conducted at Fudan University Shanghai Cancer Center  Shanghai  China among patients with nasopharyngeal carcinoma undergoing radiotherapy. To determine feasibility of a sham procedure  23 patients were randomized to real acupuncture (N = 11) or to sham acupuncture (N = 12). Patients were treated 3 times/week during their course of radiotherapy. Subjective measures were the Xerostomia Questionnaire (XQ) and MD Anderson Symptom Inventory for Head and Neck Cancer (MDASI-HN). Objective measures were unstimulated whole salivary flow rates (UWSFR) and stimulated salivary flow rates (SSFR). Patients were followed for 1 month after radiotherapy. Results XQ scores for acupuncture were significantly lower than sham controls starting in week 3 and lasted through the 1-month follow-up (all Pâ€™s < 0.001 except for week 3  which was 0.006)  with clinically significant differences as follows: week 6 â€“ RR 0.28 [95% CI  0.10  0.79]; week 11- RR 0.17 [95% CI  0.03  1.07]. Similar findings were seen for MDASI-HN scores and MDASI-Intrusion scores. Group differences for UWSFR and SSFR were not found. Conclusions In this small pilot study  true acupuncture given concurrently with radiotherapy significantly reduced xerostomia symptoms and improved QOL when compared with sham acupuncture. Large-scale  multi-center  randomized  placebo-controlled trials are now needed. PMID:22285177Feasibility of Pilates exercise to decrease falls risk: a pilot randomized controlled trial in community-dwelling older people.PubMedBarker  Anna L; Talevski  Jason; Bohensky  Megan A; Brand  Caroline A; Cameron  Peter A; Morello  Renata T2016-10-01To evaluate the feasibility of Pilates exercise in older people to decrease falls risk and inform a larger trial. Pilot Randomized controlled trial. Community physiotherapy clinic. A total of 53 community-dwelling people aged â©¾60â€‰years (mean age  69.3â€‰years; age range  61-84). A 60-minute Pilates class incorporating best practice guidelines for exercise to prevent falls  performed twice weekly for 12â€‰weeks. All participants received a letter to their general practitioner with falls risk information  fall and fracture prevention education and home exercises. Indicators of feasibility included: acceptability (recruitment  retention  intervention adherence and participant experience survey); safety (adverse events); and potential effectiveness (fall  fall injury and injurious fall rates; standing balance; lower limb strength; and flexibility) measured at 12 and 24â€‰weeks. Recruitment was achievable but control group drop-outs were high (23%). Of the 20 participants who completed the intervention  19 (95%) attended â©¾75% of the classes and reported classes were enjoyable and would recommend them to others. The rate of fall injuries at 24â€‰weeks was 42% lower and injurious fall rates 64% lower in the Pilates group  however  was not statistically significant (Pâ€‰=â€‰0.347 and Pâ€‰=â€‰0.136). Standing balance  lower-limb strength and flexibility improved in the Pilates group relative to the control group (Pâ€‰<â€‰0.05). Estimates suggest a future definitive study would require 804 participants to detect a difference in fall injury rates. A definitive randomized controlled trial analysing the effect of Pilates in older people would be feasible and is warranted given the acceptability and potential positive effects of Pilates on fall injuries and fall risk factors. The protocol for this study is registered with the Australian and New Zealand Clinical Trials Registry (ACTRN1262000224820). Â© The Author(s) 2015.A New Educational Film Control for Use in Studies of Active Mindâ€“Body Therapies: Acceptability and FeasibilityPubMed CentralSelfe  Terry Kit; Alexander  Gina K.; Taylor  Ann Gill2011-01-01Abstract Objectives The study objectives were to ascertain whether a novel educational film class is an acceptable and feasible comparison group for a randomized controlled trial regarding the effects of an active mindâ€“body therapy on cardiovascular disease risk in postmenopausal women. Methods Seventy-five (75) participants attended a baseline assessment visit and were randomly assigned to either a yoga group or an educational film (control) group. Both groups attended two 90-minute classes/week for 8 weeks  followed by a second assessment visit. Those not attending the second assessment were classified as dropouts. Over 60 films covering a range of topics relevant to the study population were evaluated; 15 were selected by consensus of at least 2 researchers and 1 layperson. Each film session followed the same format: an informal greeting period  viewing of the film  and a 15-minute postfilm discussion. To determine acceptability and feasibility of the film class  potential between-group differences in dropout and attendance were examined  and participant feedback given during class and on end-of-study questionnaires were evaluated. Results The relation between group assignment and dropout was not significant (Ï‡2 [1  Nâ€‰=â€‰75]â€‰=â€‰0.14  pâ€‰=â€‰0.71). One-way analysis of variance (ANOVA) indicated no significant between-group difference in number of classes attended for the yoga (Xâ€‰=â€‰13.67â€‰Â±â€‰3.10) versus film group (13.26â€‰Â±â€‰1.97)  F(1 63)â€‰=â€‰0.39  pâ€‰=â€‰0.53). Participant feedback regarding the film program was positive. Conclusions These findings support the feasibility and acceptability of this educational film control. Easy to standardize and tailor to a variety of populations  this film program may offer an attractive alternative to the more traditional educational control. PMID:21554109Improving BP control through electronic communications: an economic evaluation.PubMedFishman  Paul A; Cook  Andrea J; Anderson  Melissa L; Ralston  James D; Catz  Sheryl L; Carrell  David; Carlson  James; Green  Beverly B2013-09-01Web-based collaborative approaches to managing chronic illness show promise for both improving health outcomes and increasing the efficiency of the healthcare system. Analyze the cost-effectiveness of the Electronic Communications and Home Blood Pressure Monitoring to Improve Blood Pressure Control (e-BP) study  a randomized controlled trial that used a patient-shared electronic medical record  home blood pressure (BP) monitoring  and web-based pharmacist care to improve BP control (<140/90 mm Hg). Incremental cost-effectiveness analysis conducted from a health plan perspective. Cost-effectiveness of home BP monitoring and web-based pharmacist care estimated for percent change in patients with controlled BP and cost per mm Hg in diastolic and systolic BP relative to usual care and home BP monitoring alone. A 1% improvement in number of patients with controlled BP using home BP monitoring and web-based pharmacist care-the e-BP program-costs $16.65 (95% confidence interval: 15.37- 17.94) relative to home BP monitoring and web training alone. Each mm HG reduction in systolic and diastolic BP achieved through the e-BP program costs $65.29 (59.91-70.67) relativeto home BP monitoring and web tools only. Life expectancy was increased at an incremental cost of $1850 (1635-2064) and $2220 (1745-2694) per year of life saved for men and women  respectively. Web-based collaborative care can be used to achieve BP control at a relatively low cost. Future research should examine the cost impact of potential long-term clinical improvements.Smoking Cessation Program for Inpatients with Substance Use Disorder: A Quasi-Randomized Controlled Trial of Feasibility and Efficacy.PubMedRÃ¼ther  Tobias; Ruderer  Amelie; Wirth  Christina; Schuler  Veronika; Lang  Verena; Linhardt  Andrea; KrÃ¶ger  Christoph B; Pogarell  Oliver2016-01-01The present study investigated the feasibility  acceptance and efficacy of a newly developed cognitive behavioral program for smoking cessation/reduction ('Rethink your Smoking' program  RSP) in inpatients with substance use disorder (SUD). One hundred ninety-nine inpatients with SUD were randomly assigned to either the RSP (n = 101) or a minimal intervention (MI) program (n = 98). In addition  participants were offered optional nicotine replacement therapy. Data from a group of patients with SUD without any intervention (control group  n = 78) were included in the analyses for comparison. Assessments were performed at admission  discharge and follow-up after 3 and 6 months. RSP proved to be feasible and was well accepted by participants. Patients in both interventions showed lower scores for physical nicotine dependence and number of cigarettes smoked per day and higher scores for various motivational parameters at discharge and 3 months later. Both interventions were superior to no intervention  but no differences were found between the RSP and MI. A smoking cessation/reduction program is feasible for substance-dependent in-patients undergoing detoxification. Although the RSP appears to be effective in terms of harm reduction in in-patients with SUD  more cost- and time-efficient programs might also be suitable for this population. Â© 2016 S. Karger AG  Basel.Culturally adaptive storytelling method to improve hypertension control in Vietnam - ""We talk about our hypertension"": study protocol for a feasibility cluster-randomized controlled trial.PubMedAllison  Jeroan J; Nguyen  Hoa L; Ha  Duc A; Chiriboga  GermÃ¡n; Ly  Ha N; Tran  Hanh T; Phan  Ngoc T; Vu  Nguyen C; Kim  Minjin; Goldberg  Robert J2016-01-14Vietnam is experiencing an epidemiologic transition with an increased prevalence of non-communicable diseases. At present  the major risk factors for cardiovascular disease (CVD) are either on the rise or at alarming levels in Vietnam; inasmuch  the burden of CVD will continue to increase in this country unless effective prevention and control measures are put in place. A national survey in 2008 found that the prevalence of hypertension (HTN) was approximately 25Â % among Vietnamese adults and it increased with advancing age. Therefore  novel  large-scale  and sustainable interventions for public health education to promote engagement in the process of detecting and treating HTN in Vietnam are urgently needed. A feasibility randomized trial will be conducted in Hung Yen province  Vietnam to evaluate the feasibility and acceptability of a novel community-based intervention using the ""storytelling"" method to enhance the control of HTN in adults residing in four rural communities. The intervention will center on stories about living with HTN  with patients speaking in their own words. The stories will be obtained from particularly eloquent patients  or ""video stars "" identified during Story Development Groups. The study will involve two phases: (i) developing a HTN intervention using the storytelling method  which is designed to empower patients to facilitate changes in their lifestyle practices  and (ii) conducting a feasibility cluster-randomized trial to investigate the feasibility  acceptability  and potential efficacy of the intervention compared with usual care in HTN control among rural residents. The trial will be conducted at four communes  and within each commune  25 individuals 50Â years or older with HTN will be enrolled in the trial resulting in a total sample size of 100 patients. This feasibility trial will provide the necessary groundwork for a subsequent large-scale  fully powered  cluster-randomized controlled trial to test the efficacy of our novelEconomic benefit of fertility control in wild horse populationsUSGS Publications WarehouseBartholow  J.2007-01-01I projected costs for several contraceptive treatments that could be used by the Bureau of Land Management (BLM) to manage 4 wild horse (Equus caballus) populations. Potential management alternatives included existing roundup and selective removal methods combined with contraceptives of different duration and effectiveness. I projected costs for a 20-year economic life using the WinEquus?? wild horse population model and state-by-state cost estimates reflecting BLM's operational expenses. Findings revealed that 1) currently available 2-year contraceptives in most situations are capable of reducing variable operating costs by 15%  2) experimental 3-year contraceptives may be capable of reducing costs by 18%  and 3) combining contraceptives with modest changes to herd sex ratio (e.g.  55-60% M) could trim costs by 30%. Predicted savings can increase when contraception is applied in conjunction with a removal policy that targets horses aged 0-4 years instead of 0-5 years. However  reductions in herd size result in greater variation in annual operating expenses. Because the horse program's variable operating costs make up about half of the total program costs (which include other fixed costs)  contraceptive application and management can only reduce total costs by 14%  saving about $6.1 million per year. None of the contraceptive options I examined eliminated the need for long-term holding facilities over the 20-year period simulated  but the number of horses held may be reduced by about 17% with contraceptive treatment. Cost estimates were most sensitive to the oldest age adoptable and per-day holding costs. The BLM will experience significant cost savings as carefully designed contraceptive programs become widespread in the wild horse herds it manages.Counselling versus low-intensity cognitive behavioural therapy for persistent sub-threshold and mild depression (CLICD): a pilot/feasibility randomised controlled trial.PubMedFreire  Elizabeth; Williams  Christopher; Messow  Claudia-Martina; Cooper  Mick; Elliott  Robert; McConnachie  Alex; Walker  Andrew; Heard  Deborah; Morrison  Jill2015-08-15 measures. It is feasible to recruit participants and successfully deliver both interventions in a primary care setting to patients with subthreshold and mild depression; however recruiting requires significant input at the general practices. The evidence from this study suggests that short-term Person-Centred Counselling and Low-Intensity Cognitive Behaviour Therapy are potentially effective and their effectiveness should be evaluated in a larger randomised controlled study which includes a health economic evaluation. Current Controlled Trials ISRCTN60972025 .Hospital Wage and Price Controls: Lessons From the Economic Stabilization ProgramPubMed CentralOzminkowski  Ronald J.; Gaumer  Gary; Coit  Anne Jenny; Gabay  Mary1994-01-01The Clinton Administration has implied that short-run failures to control health care costs may cause a reexamination of wage and price controls as elements of comprehensive health care reform. The most recent imposition of mandatory wage and price controls was the Economic Stabilization Program (ESP) of the early 1970s. We analyze trends in hospitals' economic behavior and utilization before  during  and after ESP. We also review the relevant literature to estimate ESP's impact  considering other factors that influence hospital behavior. Noting important changes in the hospital industry since the 1970s  we conclude that ESP had limited effect and that similar controls would have little effect today. PMID:10142369Inpatient Massage Therapy Versus Music Therapy Versus Usual Care: A Mixed-methods Feasibility Randomized Controlled TrialPubMed CentralCornelio-Flores  Oscar; Lemaster  Chelsey; Hernandez  Maria; Fong  Calvin; Resnick  Kirsten; Wardle  Jon; Hanser  Suzanne; Saper  Robert2017-01-01Background Little is known about the feasibility of providing massage or music therapy to medical inpatients at urban safety-net hospitals or the impact these treatments may have on patient experience. Objective To determine the feasibility of providing massage and music therapy to medical inpatients and to assess the impact of these interventions on patient experience. Design Single-center 3-arm feasibility randomized controlled trial. Setting Urban academic safety-net hospital. Patients Adult inpatients on the Family Medicine ward. Interventions Massage therapy consisted of a standardized protocol adapted from a previous perioperative study. Music therapy involved a preference assessment  personalized compact disc  music-facilitated coping  singing/playing music  and/or songwriting. Credentialed therapists provided the interventions. Measurements Patient experience was measured with the Hospital Consumer Assessment of Healthcare Providers and Systems (HCAHPS) within 7 days of discharge. We compared the proportion of patients in each study arm reporting â€œtop boxâ€ scores for the following a priori HCAHPS domains: pain management  recommendation of hospital  and overall hospital rating. Responses to additional open-ended postdischarge questions were transcribed  coded independently  and analyzed for common themes. Results From July to December 2014  90 medical inpatients were enrolled; postdischarge data were collected on 68 (76%) medical inpatients. Participants were 70% females  43% non-Hispanic black  and 23% Hispanic. No differences between groups were observed on HCAHPS. The qualitative analysis found that massage and music therapy were associated with improved overall hospital experience  pain management  and connectedness to the massage or music therapist. Conclusions Providing music and massage therapy in an urban safety-net inpatient setting was feasible. There was no quantitative impact on HCAHPS. Qualitative findings suggest benefits related to anTask-Oriented Training with Computer Games for People with Rheumatoid Arthritis or Hand Osteoarthritis: A Feasibility Randomized Controlled Trial.PubMedSrikesavan  Cynthia Swarnalatha; Shay  Barbara; Szturm  Tony2016-09-13To examine the feasibility of a clinical trial on a novel  home-based task-oriented training with conventional hand exercises in people with rheumatoid arthritis or hand osteoarthritis. To explore the experiences of participants who completed their respective home exercise programmes. Thirty volunteer participants aged between 30 and 60 years and diagnosed with rheumatoid arthritis or hand osteoarthritis were proposed for a single-center  assessor-blinded  randomized controlled trial ( ClinicalTrials.gov : NCT01635582). Participants received task-oriented training with interactive computer games and objects of daily life or finger mobility and strengthening exercises. Both programmes were home based and were done four sessions per week with 20 minutes each session for 6 weeks. Major feasibility outcomes were number of volunteers screened  randomized  and retained; completion of blinded assessments  exercise training  and home exercise sessions; equipment and data management; and clinical outcomes of hand function. Reaching the recruitment target in 18 months and achieving exercise compliance >80% were set as success criteria. Concurrent with the trial  focus group interviews explored experiences of those participants who completed their respective programmes. After trial initiation  revisions in inclusion criteria were required to promote recruitment. A total of 17 participants were randomized and 15 were retained. Completion of assessments  exercise training  and home exercise sessions; equipment and data collection and management demonstrated excellent feasibility. Both groups improved in hand function outcomes and exercise compliance was above 85%. Participants perceived both programmes as appropriate and acceptable. Participants who completed task-oriented training also agreed that playing different computer games was enjoyable  engaging  and motivating. Findings demonstrate initial evidence on recruitment  feasibility of trial procedures  and acceptability ofFeasibility and safety of xenon compared with sevoflurane anaesthesia in coronary surgical patients: a randomized controlled pilot study.PubMedStoppe  C; Fahlenkamp  A V; Rex  S; Veeck  N C; Gozdowsky  S C; SchÃ¤lte  G; Autschbach  R; Rossaint  R; Coburn  M2013-09-01To date  only limited data exist about the use of xenon as an anaesthetic agent in patients undergoing cardiac surgery. The favourable cardio- and neuroprotective properties of xenon might attenuate postoperative complications  improve outcome  and reduce the incidence of delirium. Thus  the aims of this study were to investigate the feasibility and safety of balanced xenon anaesthesia in patients undergoing cardiac surgery and to gather pilot data for a future randomized multicentre study. Thirty patients undergoing elective coronary artery bypass grafting were enrolled in this randomized  single-blind controlled trial. They were randomized to receive balanced general anaesthesia with either xenon (45-50 vol%) or sevoflurane (1-1.4 vol%). The primary outcome was the occurrence of adverse events (AEs). Secondary outcome parameters were feasibility criteria (bispectral index  perioperative haemodynamic  and respiratory profile) and safety parameters (dosage of study treatments  renal function  intraoperative blood loss  need for inotropic support  regional cerebral tissue oxygenation). Furthermore  at predefined time points  systemic and pulmonary haemodynamics were assessed by the use of a pulmonary artery catheter. There were no patient characteristic differences between the groups. Patients undergoing xenon anaesthesia did not differ with respect to the incidence of AE (6 vs 8  P=0.464) compared with the sevoflurane group. No differences were detected regarding secondary feasibility and safety criteria. The haemodynamic and respiratory profile was comparable between the treatment groups. Balanced xenon anaesthesia is feasible and safe compared with sevoflurane anaesthesia in patients undergoing coronary artery bypass surgery. Acronym CARDIAX: A pre- and post-coronary artery bypass graft implantation disposed application of xenon. Clinical trial registration ClinicalTrials.gov: NCT01285271; EudraCT-number: 2010-023942-63. Approved by the ethics committee 'EthikFeasibility  safety  and efficacy of aerobic training in pretreated patients with metastatic breast cancer: A randomized controlled trial.PubMedScott  Jessica M; Iyengar  Neil M; Nilsen  Tormod S; Michalski  Meghan; Thomas  Samantha M; Herndon  James; Sasso  John; Yu  Anthony; Chandarlapaty  Sarat; Dang  Chau T; Comen  Elizabeth A; Dickler  Maura N; Peppercorn  Jeffrey M; Jones  Lee W2018-04-06The investigation of exercise training in metastatic breast cancer has received minimal attention. This study determined the feasibility and safety of aerobic training in metastatic breast cancer. Sixty-five women (age  21-80 years) with metastatic (stage IV) breast cancer (57% were receiving chemotherapy  and >40% hadâ€‰â‰¥â€‰2 lines of prior therapy) were allocated to an aerobic training group (nâ€‰=â€‰33) or a stretching group (nâ€‰=â€‰32). Aerobic training consisted of 36 supervised treadmill walking sessions delivered thrice weekly between 55% and 80% of peak oxygen consumption (VO 2peak ) for 12 consecutive weeks. Stretching was matched to aerobic training with respect to location  frequency  duration  and intervention length. The primary endpoint was aerobic training feasibility  which was a priori defined as the lost to follow-up (LTF) rate (<20%) and attendance (â‰¥70%). Secondary endpoints were safety  objective outcomes (VO 2peak and functional capacity)  and patient-reported outcomes (PROs; quality of life). One of the 33 patients (3%) receiving aerobic training was LTF  whereas the mean attendance rate was 63%â€‰Â±â€‰30%. The rates of permanent discontinuation and dose modification were 27% and 49%  respectively. Intention-to-treat analyses indicated improvements in PROs  which favored the attention control group (P valuesâ€‰>â€‰.05). Per protocol analyses indicated that 14 of 33 patients (42%) receiving aerobic training had acceptable tolerability (relative dose intensityâ€‰â‰¥â€‰70%)  and this led to improvements in VO 2peak and functional capacity (P valuesâ€‰<â€‰.05). Aerobic training at the dose and schedule tested is safe but not feasible for a significant proportion of patients with metastatic breast cancer. The acceptable feasibility and promising benefit for select patients warrant further evaluation in a dose-finding phase 1/2 study. Cancer 2018. Â© 2018 American Cancer Society. Â© 2018 American Cancer Society.Inpatient Massage Therapy Versus Music Therapy Versus Usual Care: A Mixed-methods Feasibility Randomized Controlled Trial.PubMedRoseen  Eric J; Cornelio-Flores  Oscar; Lemaster  Chelsey; Hernandez  Maria; Fong  Calvin; Resnick  Kirsten; Wardle  Jon; Hanser  Suzanne; Saper  Robert2017-01-01Little is known about the feasibility of providing massage or music therapy to medical inpatients at urban safety-net hospitals or the impact these treatments may have on patient experience. To determine the feasibility of providing massage and music therapy to medical inpatients and to assess the impact of these interventions on patient experience. Single-center 3-arm feasibility randomized controlled trial. Urban academic safety-net hospital. Adult inpatients on the Family Medicine ward. Massage therapy consisted of a standardized protocol adapted from a previous perioperative study. Music therapy involved a preference assessment  personalized compact disc  music-facilitated coping  singing/playing music  and/or songwriting. Credentialed therapists provided the interventions. Patient experience was measured with the Hospital Consumer Assessment of Healthcare Providers and Systems (HCAHPS) within 7 days of discharge. We compared the proportion of patients in each study arm reporting ""top box"" scores for the following a priori HCAHPS domains: pain management  recommendation of hospital  and overall hospital rating. Responses to additional open-ended postdischarge questions were transcribed  coded independently  and analyzed for common themes. From July to December 2014  90 medical inpatients were enrolled; postdischarge data were collected on 68 (76%) medical inpatients. Participants were 70% females  43% non-Hispanic black  and 23% Hispanic. No differences between groups were observed on HCAHPS. The qualitative analysis found that massage and music therapy were associated with improved overall hospital experience  pain management  and connectedness to the massage or music therapist. Providing music and massage therapy in an urban safety-net inpatient setting was feasible. There was no quantitative impact on HCAHPS. Qualitative findings suggest benefits related to an improved hospital experience  pain management  and connectedness to the massage or music therapist.Changing physical activity behaviour for people with multiple sclerosis: protocol of a randomised controlled feasibility trial (iStep-MS).PubMedRyan  Jennifer M; Fortune  Jennifer; Stennett  Andrea; Kilbride  Cherry; Anokye  Nana; Victor  Christina; Hendrie  Wendy; Abdul  Mohamed; DeSouza  Lorraine; Lavelle  Grace; Brewin  Debbie; David  Lee; Norris  Meriel2017-11-15Although physical activity may reduce disease burden  fatigue and disability  and improve quality of life among people with multiple sclerosis (MS)  many people with MS are physically inactive and spend significant time in sedentary behaviour. Behaviour change interventions may assist people with MS to increase physical activity and reduce sedentary behaviour. However  few studies have investigated their effectiveness using objective measures of physical activity  particularly in the long term. Further  interventions that have proven effective in the short term may not be feasible in clinical practice because of the large amount of support provided. The iStep-MS trial aims to determine the safety  feasibility and acceptability of a behaviour change intervention to increase physical activity and reduce sedentary behaviour among people with MS. Sixty people with MS will be randomised (1:1 ratio) to receive a 12-week intervention or usual care only. The intervention consists of four physical activity consultations with a physiotherapist supported by a handbook and pedometer. Outcomes assessed at baseline  12 weeks and 9 months are physical activity (ActiGraph wGT3X-BT accelerometer)  sedentary behaviour (activPAL3Âµ)  self-reported activity and sitting time  walking capability  fatigue  self-efficacy  participation  quality of life and health service use. The safety of the intervention will be determined by assessing change in pain and fatigue and the incidence of adverse events during the follow-up period. A parallel process evaluation will assess the feasibility and acceptability of the intervention through assessment of fidelity to the programme and semistructured interviews exploring participants' and therapists' experiences of the intervention. The feasibility of conducting an economic evaluation will be determined by collecting data on quality of life and resource use. Research ethics committee approval has been granted from Brunel University London. Results ofChanging physical activity behaviour for people with multiple sclerosis: protocol of a randomised controlled feasibility trial (iStep-MS)PubMed CentralRyan  Jennifer M; Fortune  Jennifer; Stennett  Andrea; Kilbride  Cherry; Anokye  Nana; Victor  Christina; Hendrie  Wendy; Abdul  Mohamed; DeSouza  Lorraine; Lavelle  Grace; Brewin  Debbie; David  Lee; Norris  Meriel2017-01-01Introduction Although physical activity may reduce disease burden  fatigue and disability  and improve quality of life among people with multiple sclerosis (MS)  many people with MS are physically inactive and spend significant time in sedentary behaviour. Behaviour change interventions may assist people with MS to increase physical activity and reduce sedentary behaviour. However  few studies have investigated their effectiveness using objective measures of physical activity  particularly in the long term. Further  interventions that have proven effective in the short term may not be feasible in clinical practice because of the large amount of support provided. The iStep-MS trial aims to determine the safety  feasibility and acceptability of a behaviour change intervention to increase physical activity and reduce sedentary behaviour among people with MS. Methods and analysis Sixty people with MS will be randomised (1:1 ratio) to receive a 12-week intervention or usual care only. The intervention consists of four physical activity consultations with a physiotherapist supported by a handbook and pedometer. Outcomes assessed at baseline  12 weeks and 9 months are physical activity (ActiGraph wGT3X-BT accelerometer)  sedentary behaviour (activPAL3Âµ)  self-reported activity and sitting time  walking capability  fatigue  self-efficacy  participation  quality of life and health service use. The safety of the intervention will be determined by assessing change in pain and fatigue and the incidence of adverse events during the follow-up period. A parallel process evaluation will assess the feasibility and acceptability of the intervention through assessment of fidelity to the programme and semistructured interviews exploring participantsâ€™ and therapistsâ€™ experiences of the intervention. The feasibility of conducting an economic evaluation will be determined by collecting data on quality of life and resource use. Ethics and dissemination Research ethics committeeEffectiveness and cost-effectiveness of a group-based pain self-management intervention for patients undergoing total hip replacement: feasibility study for a randomized controlled trial.PubMedWylde  Vikki; Marques  Elsa; Artz  Neil; Blom  Ashley; Gooberman-Hill  Rachael2014-05-20Total hip replacement (THR) is a common elective surgical procedure and can be effective for reducing chronic pain. However  waiting times can be considerable. A pain self-management intervention may provide patients with skills to more effectively manage their pain and its impact during their wait for surgery. This study aimed to evaluate the feasibility of conducting a randomized controlled trial to assess the effectiveness and cost-effectiveness of a group-based pain self-management course for patients undergoing THR. Patients listed for a THR at one orthopedic center were posted a study invitation pack. Participants were randomized to attend a pain self-management course plus standard care or standard care only. The lay-led course was delivered by Arthritis Care and consisted of two half-day sessions prior to surgery and one full-day session after surgery. Participants provided outcome and resource-use data using a diary and postal questionnaires prior to surgery and one month  three months and six months after surgery. Brief telephone interviews were conducted with non-participants to explore barriers to participation. Invitations were sent to 385 eligible patients and 88 patients (23%) consented to participate. Interviews with 57 non-participants revealed the most common reasons for non-participation were views about the course and transport difficulties. Of the 43 patients randomized to the intervention group  28 attended the pre-operative pain self-management sessions and 11 attended the post-operative sessions. Participant satisfaction with the course was high  and feedback highlighted that patients enjoyed the group format. Retention of participants was acceptable (83% of recruited patients completed follow-up) and questionnaire return rates were high (72% to 93%)  with the exception of the pre-operative resource-use diary (35% return rate). Resource-use completion rates allowed for an economic evaluation from the health and social care payer perspectiveMIDSHIPS: Multicentre Intervention Designed for Self-Harm using Interpersonal Problem-Solving: protocol for a randomised controlled feasibility studyPubMed Central2014-01-01Background Around 150 000 people each year attend hospitals in England due to self-harm  many of them more than once. Over 5 000 people die by suicide each year in the UK  a quarter of them having attended hospital in the previous year because of self-harm. Self-harm is a major identifiable risk factor for suicide. People receive variable care at hospital; many are not assessed for their psychological needs and little psychological therapy is offered. Despite its frequent occurrence  we have no clear research evidence about how to reduce the repetition of self-harm. Some people who have self-harmed show less active ways of solving problems  and brief problem-solving therapies are considered the most promising psychological treatments. Methods/Design This is a pragmatic  individually randomised  controlled  feasibility study comparing interpersonal problem-solving therapy plus treatment-as-usual with treatment-as-usual alone  for adults attending a general hospital following self-harm. A total of 60 participants will be randomised equally between the treatment arms  which will be balanced with respect to the type of most recent self-harm event  number of previous self-harm events  gender and age. Feasibility objectives are as follows: a) To establish and field test procedures for implementing the problem-solving intervention; b) To determine the feasibility and best method of participant recruitment and follow up; c) To assess therapeutic delivery; d) To assess the feasibility of obtaining the definitive trialâ€™s primary and secondary outcomes; e) To assess the perceived burden and acceptability of obtaining the trialâ€™s self-reported outcome data; f) To inform the sample size calculation for the definitive trial. Discussion The results of this feasibility study will be used to determine the appropriateness of proceeding to a definitive trial and will allow us to design an achievable trial of interpersonal problem-solving therapy for adults who self-harm. TrialFeasibility and effects of a physical exercise programme in adults with myotonic dystrophy type 1: a randomized controlled pilot study.PubMedKierkegaard  Marie; Harms-Ringdahl  Karin; EdstrÃ¶m  Lars; WidÃ©n Holmqvist  Lotta; TollbÃ¤ck  Anna2011-07-01To investigate the feasibility and effects of a physical exercise programme on functioning and health-related quality of life in adults with myotonic dystrophy type 1. A randomized controlled trial. Thirty-five adults with myotonic dystrophy type 1. After stratification for level of functioning  study participants were assigned by lot to either a training group or a control group. Training-group participants attended a 60-minute comprehensive group-training programme  Friskis&SvettisÂ® Open Doors  twice a week for 14 weeks. The six-minute walk test was the primary outcome measure and the timed-stands test  the timed up-and-go test  the Epworth sleepiness scale and the Short Form-36 health survey were secondary outcome measures. Intention-to-treat analyses revealed no significant differences in any outcome measures  except for an increased between-group difference after intervention in the Short Form-36 mental health subscale and a decrease in the vitality subscale for the control group. The programme was well tolerated and many training-group participants perceived subjective changes for the better. No negative effects were reported. The Friskis&SvettisÂ® Open Doors programme was feasible for adults with myotonic dystrophy type 1 who had been screened for cardiac involvement  had distal or mild-to-moderate proximal muscle impairment  and no severe cognitive impairments. No beneficial or detrimental effects were evident.Reactions to a Remote-Controlled Video-Communication Robot in Seniors' Homes: A Pilot Study of Feasibility and AcceptancePubMed CentralSeelye  Adriana M.; Larimer  Nicole; Maxwell  Shoshana; Kearns  Peter; Kaye  Jeffrey A.2012-01-01Abstract Objective: Remote telepresence provided by tele-operated robotics represents a new means for obtaining important health information  improving older adults' social and daily functioning and providing peace of mind to family members and caregivers who live remotely. In this study we tested the feasibility of use and acceptance of a remotely controlled robot with video-communication capability in independently living  cognitively intact older adults. Materials and Methods: A mobile remotely controlled robot with video-communication ability was placed in the homes of eight seniors. The attitudes and preferences of these volunteers and those of family or friends who communicated with them remotely via the device were assessed through survey instruments. Results: Overall experiences were consistently positive  with the exception of one user who subsequently progressed to a diagnosis of mild cognitive impairment. Responses from our participants indicated that in general they appreciated the potential of this technology to enhance their physical health and well-being  social connectedness  and ability to live independently at home. Remote users  who were friends or adult children of the participants  were more likely to test the mobility features and had several suggestions for additional useful applications. Conclusions: Results from the present study showed that a small sample of independently living  cognitively intact older adults and their remote collaterals responded positively to a remote controlled robot with video-communication capabilities. Research is needed to further explore the feasibility and acceptance of this type of technology with a variety of patients and their care contacts. PMID:23082794Reactions to a remote-controlled video-communication robot in seniors' homes: a pilot study of feasibility and acceptance.PubMedSeelye  Adriana M; Wild  Katherine V; Larimer  Nicole; Maxwell  Shoshana; Kearns  Peter; Kaye  Jeffrey A2012-12-01Remote telepresence provided by tele-operated robotics represents a new means for obtaining important health information  improving older adults' social and daily functioning and providing peace of mind to family members and caregivers who live remotely. In this study we tested the feasibility of use and acceptance of a remotely controlled robot with video-communication capability in independently living  cognitively intact older adults. A mobile remotely controlled robot with video-communication ability was placed in the homes of eight seniors. The attitudes and preferences of these volunteers and those of family or friends who communicated with them remotely via the device were assessed through survey instruments. Overall experiences were consistently positive  with the exception of one user who subsequently progressed to a diagnosis of mild cognitive impairment. Responses from our participants indicated that in general they appreciated the potential of this technology to enhance their physical health and well-being  social connectedness  and ability to live independently at home. Remote users  who were friends or adult children of the participants  were more likely to test the mobility features and had several suggestions for additional useful applications. Results from the present study showed that a small sample of independently living  cognitively intact older adults and their remote collaterals responded positively to a remote controlled robot with video-communication capabilities. Research is needed to further explore the feasibility and acceptance of this type of technology with a variety of patients and their care contacts.Scout fourth stage attitude and velocity control (AVC) system feasibility studyNASA Technical Reports Server (NTRS)Byars  L. B.1975-01-01The feasibility of incorporating a guidance system in the Scout fourth stage to achieve a significant improvement in expected payload delivery accuracy is studied. The technical investigations included the determination of the AVC equipment performance requirements  establishment of qualification and acceptance test levels  generation of layouts illustrating design approaches for the upper D and payload transition sections to incorporate the hardware  and the preparation of a vendor bid package. Correction concepts  utilizing inertial velocity and attitude  were identified and evaluated. Fourth stage attitude adjustments as determined from inertial velocity variation through the first three stages and a final velocity correction based upon the measured in-plane component errors at injection were employed. Results show radical reductions in apogee-perigee deviations.Feasibility of Autonomous Monitoring of CO2 Leakage in Aquifers: Results From Controlled Laboratory ExperimentsNASA Astrophysics Data System (ADS)Versteeg  R.; Leger  E.; Dafflon  B.2016-12-01Geologic sequestration of CO2 is one of the primary proposed approaches for reducing total atmospheric CO2 concentrations. MVAA (Monitoring  Verification  Accounting and Assessment) of CO2 sequestration is an essential part of the geologic CO2 sequestration cycle. MVAA activities need to meet multiple operational  regulatory and environmental objectives  including ensuring the protection of underground sources of drinking water. Anticipated negative consequences of CO2 leakage into groundwater  besides possible brine contamination and release of gaseous CO2  include a significant increase of dissolved CO2 into shallow groundwater systems  which will decrease groundwater pH and can potentially mobilize naturally occurring trace metals and ions that are commonly absorbed to or contained in sediments. Autonomous electrical geophysical monitoring in aquifers has the potential of allowing for rapid and automated detection of CO2 leakage. However  while the feasibility of such monitoring has been demonstrated by a number of different field experiments  automated interpretation of complex electrical resistivity data requires the development of quantitative relationships between complex electrical resistivity signatures and dissolved CO2 in the aquifer resulting from leakage Under a DOE SBIR funded effort we performed multiple tank scale experiments in which we investigated complex electrical resistivity signatures associated with dissolved CO2 plumes in saturated sediments. We also investigated the feasibility of distinguishing CO2 leakage signatures from signatures associated with other processes such as salt water movement  temperature variations and other variations in chemical or physical conditions. In addition to these experiments we also numerically modeled the tank experiments. These experiments showed that (a) we can distinguish CO2 leakage signatures from other signatures  (b) CO2 leakage signatures have a consistent characteristic  (c) laboratory experimentsIntegrated Power/Attitude Control System (IPACS) study. Volume 1: Feasibility studies. [application of flywheels for power storage and generationNASA Technical Reports Server (NTRS)Notti  J. E.; Cormack  A.  III; Schmill  W. C.1974-01-01An Integrated Power/Attitude Control System (IPACS) concept consisting of an array of spinning flywheels  with or without gimbals  capable of performing the dual function of power storage and generation  as well as attitude control has been investigated. This system provides attitude control through momentum storage  and replaces the storage batteries onboard the spacecraft. The results of the investigation are presented in two volumes. The trade-off studies performed to establish the feasibility  cost effectiveness  required level of development  and boundaries of application of IPACS to a wide variety of spacecraft are discussed. The conceptual designs for a free-flying research application module (RAM)  and for a tracking and data relay satellite (TDRS) are presented. Results from dynamic analyses and simulations of the IPACS conceptual designs are included.Ambulatory (24 h) blood pressure and arterial stiffness measurement in Marfan syndrome patients: a case control feasibility and pilot study.PubMedHillebrand  Matthias; Nouri  Ghazaleh; Hametner  Bernhard; Parragh  Stephanie; KÃ¶ster  Jelena; Mortensen  Kai; Schwarz  Achim; von Kodolitsch  Yskert; Wassertheurer  Siegfried2016-05-06The aim of this work is the investigation of measures of ambulatory brachial and aortic blood pressure and indices of arterial stiffness and aortic wave reflection in Marfan patients. A case-control study was conducted including patients with diagnosed Marfan syndrome following Ghent2 nosology and healthy controls matched for sex  age and daytime brachial systolic blood pressure. For each subject a 24 h ambulatory blood pressure and 24 h pulse wave analysis measurement was performed. All parameters showed a circadian pattern whereby pressure dipping was more pronounced in Marfan patients. During daytime only Marfan patients with aortic root surgery showed increased pulse wave velocity. In contrast  various nighttime measurements  wave reflection determinants and circadian patterns showed a significant difference. The findings of our study provide evidence that ambulatory measurement of arterial stiffness parameters is feasible and that these determinants are significantly different in Marfan syndrome patients compared to controls in particular at nighttime. Further investigation is therefore indicated.FUZZY LOGIC CONTROL OF ELECTRIC MOTORS AND MOTOR DRIVES: FEASIBILITY STUDYEPA Science InventoryThe report gives results of a study (part 1) of fuzzy logic motor control (FLMC). The study included: 1) reviews of existing applications of fuzzy logic  of motor operation  and of motor control; 2) a description of motor control schemes that can utilize FLMC; 3) selection of a m...The Men's Safer Sex project: intervention development and feasibility randomised controlled trial of an interactive digital intervention to increase condom use in men.PubMedBailey  Julia V; Webster  Rosie; Hunter  Rachael; Griffin  Mark; Freemantle  Nicholas; Rait  Greta; Estcourt  Claudia; Michie  Susan; Anderson  Jane; Stephenson  Judith; Gerressu  Makeda; Ang  Chee Siang; Murray  Elizabeth2016-12-01This report details the development of the Men's Safer Sex website and the results of a feasibility randomised controlled trial (RCT)  health economic assessment and qualitative evaluation. (1) Develop the Men's Safer Sex website to address barriers to condom use; (2) determine the best design for an online RCT; (3) inform the methods for collecting and analysing health economic data; (4) assess the Sexual Quality of Life (SQoL) questionnaire and European Quality of Life-5 Dimensions  three-level version (EQ-5D-3L) to calculate quality-adjusted life-years (QALYs); and (5) explore clinic staff and men's views of online research methodology. (1) Website development: we combined evidence from research literature and the views of experts ( n â€‰=â€‰18) and male clinic users ( n â€‰=â€‰43); (2) feasibility RCT: 159 heterosexually active men were recruited from three sexual health clinics and were randomised by computer to the Men's Safer Sex website plus usual care ( n â€‰=â€‰84) or usual clinic care only ( n â€‰=â€‰75). Men were invited to complete online questionnaires at 3  6  9 and 12 months  and sexually transmitted infection (STI) diagnoses were recorded from clinic notes at 12 months; (3) health economic evaluation: we investigated the impact of using different questionnaires to calculate utilities and QALYs (the EQ-5D-3L and SQoL questionnaire)  and compared different methods to collect resource use; and (4) qualitative evaluation: thematic analysis of interviews with 11 male trial participants and nine clinic staff  as well as free-text comments from online outcome questionnaires. (1) Software errors and clinic Wi-Fi access presented significant challenges. Response rates for online questionnaires were poor but improved with larger vouchers (from 36% with Â£10 to 50% with Â£30). Clinical records were located for 94% of participants for STI diagnoses. There were no group differences in condomless sex with female partners [incidence rate ratio (IRR) 1.01  95""FIND Technology"": investigating the feasibility  efficacy and safety of controller-free interactive digital rehabilitation technology in an inpatient stroke population: study protocol for a randomized controlled trial.PubMedBird  M L; Cannell  J; Callisaya  M L; Moles  E; Rathjen  A; Lane  K; Tyson  A; Smith  S2016-04-16Stroke results in significant disability  which can be reduced by physical rehabilitation. High levels of repetition and activity are required in rehabilitation  but patients are typically sedentary. Using clinically relevant and fun computer games may be one way to achieve increased activity in rehabilitation. A single-blind randomized controlled trial will be conducted to evaluate the feasibility  efficacy and safety of novel stroke-specific rehabilitation software. This software uses controller-free client interaction and inertial motion sensors. Elements of feasibility include recruitment into the trial  ongoing participation (adherence and dropout)  perceived benefit  enjoyment and ease of use of the games. Efficacy will be determined by measuring activity and using upper-limb tasks as well as measures of balance and mobility. The hypothesis that the intervention group will have increased levels of physical activity within rehabilitation and improved physical outcomes compared with the control group will be tested. Results from this study will provide a basis for discussion of feasibility of this interactive video technological solution in an inpatient situation. Differences in activity levels between groups will be the primary measure of efficacy. It will also provide data on measures of upper-limb function  balance and mobility. ACTRN12614000427673 . Prospectively registered 17 April 2014.A low cost virtual reality system for home based rehabilitation of the arm following stroke: a randomised controlled feasibility trialPubMed CentralStanden  PJ; Threapleton  K; Richardson  A; Connell  L; Brown  DJ; Battersby  S; Platts  F; Burton  A2016-01-01Objective: To assess the feasibility of conducting a randomised controlled trial of a home-based virtual reality system for rehabilitation of the arm following stroke. Design: Two group feasibility randomised controlled trial of intervention versus usual care. Setting: Patientsâ€™ homes. Participants: Patients aged 18 or over  with residual arm dysfunction following stroke and no longer receiving any other intensive rehabilitation. Interventions: Eight weeksâ€™ use of a low cost home-based virtual reality system employing infra-red capture to translate the position of the hand into game play or usual care. Main measures: The primary objective was to collect information on the feasibility of a trial  including recruitment  collection of outcome measures and staff support required. Patients were assessed at three time points using the Wolf Motor Function Test  Nine-Hole Peg Test  Motor Activity Log and Nottingham Extended Activities of Daily Living. Results: Over 15 months only 47 people were referred to the team. Twenty seven were randomised and 18 (67%) of those completed final outcome measures. Sample size calculation based on data from the Wolf Motor Function Test indicated a requirement for 38 per group. There was a significantly greater change from baseline in the intervention group on midpoint Wolf Grip strength and two subscales of the final Motor Activity Log. Training in the use of the equipment took a median of 230 minutes per patient. Conclusions: To achieve the required sample size  a definitive home-based trial would require additional strategies to boost recruitment rates and adequate resources for patient support. PMID:27029939An intervention to support stroke survivors and their carers in the longer term (LoTS2Care): study protocol for a cluster randomised controlled feasibility trial.PubMedForster  Anne; Hartley  Suzanne; Barnard  Lorna; Ozer  Seline; Hardicre  Natasha; Crocker  Tom; Fletcher  Marie; Moreau  Lauren; Atkinson  Ross; Hulme  Claire; Holloway  Ivana; Schmitt  Laetitia; House  Allan; Hewison  Jenny; Richardson  Gillian; Farrin  Amanda2018-06-11Despite the evidence that many stroke survivors report longer term unmet needs  the provision of longer term care is limited. To address this  we are conducting a programme of research to develop an evidence-based and replicable longer term care strategy. The developed complex intervention (named New Start)  which includes needs identification  exploration of social networks and components of problem solving and self-management  was designed to improve quality of life by addressing unmet needs and increasing participation. A multicentre  cluster randomised controlled feasibility trial designed to inform the design of a possible future definitive cluster randomised controlled trial (cRCT) and explore the potential clinical and cost-effectiveness of New Start. Ten stroke services across the UK will be randomised on a 1:1 basis either to implement New Start or continue with usual care only. New Start will be delivered by trained facilitators and will be offered to all stroke survivors within the services allocated to the intervention arm. Stroke survivors will be eligible for the trial if they are 4-6 months post-stroke and residing in the community. Carers (if available) will also be invited to take part. Invitation to participate will be initiated by post and outcome measures will be collected via postal questionnaires at 3  6 and 9 months after recruitment. Outcome data relating to perceived health and disability  wellbeing and quality of life as well as unmet needs will be collected. A 'study within a trial' (SWAT)Â is planned to determine the most acceptable format in which to provide the postal questionnaires. Details of health and social care service usage will also be collected to inform the economic evaluation. The feasibility of recruiting services and stroke survivors to the trial and of collecting postal outcomes will be assessed and the potential for effectiveness will be investigated. An embedded process evaluation (reported separately) will assessExploring the feasibility and acceptability of couple-based psychosexual support following prostate cancer surgery: study protocol for a pilot randomised controlled trialPubMed Central2014-01-01Background Men who undergo surgery for prostate cancer frequently experience significant side-effects including urinary and sexual dysfunction. These difficulties can lead to anxiety  depression and reduced quality of life. Many partners also experience psychological distress. An additional impact can be on the couple relationship  with changes to intimacy  and unmet psychosexual supportive needs in relation to sexual recovery and rehabilitation. The aim of this exploratory randomised controlled trial pilot study is to determine the feasibility and acceptability of a novel family-relational-psychosexual intervention to support intimacy and reduce distress among couples following prostate cancer surgery and to estimate the efficacy of this intervention. Methods/Design The intervention will comprise six sessions of psychosexual and relationship support delivered by experienced couple-support practitioners. Specialist training in delivering the intervention will be provided to practitioners and they will be guided by a detailed treatment manual based on systemic principles. Sixty-eight couples will be randomised to receive either the intervention or standard care (comprising usual follow-up hospital appointments). A pre-test  post-test design will be used to test the feasibility of the intervention (baseline  end of intervention and six-month follow-up) and its acceptability to couples and healthcare professionals (qualitative interviews). Both individual and relational outcome measures will assess sexual functioning  anxiety and depression  couple relationship  use of health services and erectile dysfunction medication/technologies. An economic analysis will estimate population costs of the intervention  compared to usual care  using simple modelling to evaluate the affordability of the intervention. Discussion Given the increasing incidence and survival of post-operative men with prostate cancer  it is timely and appropriate to determine the feasibility of aA comparison of remote therapy  face to face therapy and an attention control intervention for people with aphasia: a quasi-randomised controlled feasibility study.PubMedWoolf  Celia; Caute  Anna; Haigh  Zula; Galliers  Julia; Wilson  Stephanie; Kessie  Awurabena; Hirani  Shashi; Hegarty  Barbara; Marshall  Jane2016-04-01To test the feasibility of a randomised controlled trial comparing face to face and remotely delivered word finding therapy for people with aphasia. A quasi-randomised controlled feasibility study comparing remote therapy delivered from a University lab  remote therapy delivered from a clinical site  face to face therapy and an attention control condition. A University lab and NHS outpatient service. Twenty-one people with aphasia following left hemisphere stroke. Eight sessions of word finding therapy  delivered either face to face or remotely  were compared to an attention control condition comprising eight sessions of remotely delivered supported conversation. The remote conditions used mainstream video conferencing technology. Feasibility was assessed by recruitment and attrition rates  participant observations and interviews  and treatment fidelity checking. Effects of therapy on word retrieval were assessed by tests of picture naming and naming in conversation. Twenty-one participants were recruited over 17 months  with one lost at baseline. Compliance and satisfaction with the intervention was good. Treatment fidelity was high for both remote and face to face delivery (1251/1421 therapist behaviours were compliant with the protocol). Participants who received therapy improved on picture naming significantly more than controls (mean numerical gains: 20.2 (remote from University); 41 (remote from clinical site); 30.8 (face to face); 5.8 (attention control); P <.001). There were no significant differences between groups in the assessment of conversation. Word finding therapy can be delivered via mainstream internet video conferencing. Therapy improved picture naming  but not naming in conversation. Â© The Author(s) 2015.Feasibility and Safety of Substituting Lung Ultrasonography for Chest Radiography When Diagnosing Pneumonia in Children: A Randomized Controlled Trial.PubMedJones  Brittany Pardue; Tay  Ee Tein; Elikashvili  Inna; Sanders  Jennifer E; Paul  Audrey Z; Nelson  Bret P; Spina  Louis A; Tsung  James W2016-07-01Chest radiography (CXR) is the test of choice for diagnosing pneumonia. Lung ultrasonography (LUS) has been shown to be accurate for diagnosing pneumonia in children and may be an alternative to CXR. Our objective was to determine the feasibility and safety of substituting LUS for CXR when evaluating children suspected of having pneumonia. We conducted a randomized control trial comparing LUS with CXR in 191 children from birth to 21 years of age suspected of having pneumonia in an ED. Patients in the investigational arm underwent LUS. If there was clinical uncertaintyÂ after ultrasonography  physicians had the option to perform CXR. Patients in theÂ control arm underwent sequential imaging with CXR followed by LUS. The primary outcomeÂ was the rate of CXR reduction; secondary outcomes were missed pneumonia  subsequent unscheduled health-care visits  and adverse events between the investigational and control arms. There was a 38.8%Â reduction (95%Â CI  30.0%-48.9%) in CXR among investigational subjects compared with no reduction (95%Â CI  0.0%-3.6%) in the control group. Novice and experienced physician-sonologists achieved 30.0%Â and 60.6%Â reduction in CXR use  respectively. There were no cases of missed pneumonia among all study participants (investigational arm  0.0%: 95%Â CI  0.0%-2.9%; control arm  0.0%: 95%Â CI  0.0%-3.0%)  or differences in adverse events  or subsequent unscheduled health-care visits between arms. It may be feasible and safe to substitute LUS for CXR when evaluating children suspected of having pneumonia with no missed cases of pneumonia or increase in rates of adverse events. ClinicalTrials.gov; No.: NCT01654887; URL: www.clinicaltrials.gov. Copyright Â© 2016 The Authors. Published by Elsevier Inc. All rights reserved.Feasibility of personalised remote long-term follow-up of people with cochlear implants: a randomised controlled trialPubMed CentralKitterick  Padraig; Weal  Mark; Margol-Gromada  Magdalena2018-01-01Introduction Substantial resources are required to provide lifelong postoperative care to people with cochlear implants. Most patients visit the clinic annually. We introduced a person-centred remote follow-up pathway  giving patients telemedicine tools to use at home so they would only visit the centre when intervention was required. Objectives To assess the feasibility of comparing a remote care pathway with the standard pathway in adults using cochlear implants. Design Two-arm randomised controlled trial. Randomisation used a minimisation approach  controlling for potential confounding factors. Participant blinding was not possible  but baseline measures occurred before allocation. Setting University of Southampton Auditory Implant Service: provider of National Health Service care. Participants 60 adults who had used cochlear implants for at least 6 months. Interventions Control group (n=30) followed usual care pathway. Remote care group (n=30) received care remotely for 6 months incorporating: home hearing in noise test  online support tool and self-adjustment of device (only 10 had compatible equipment). Main outcome measures Primary: change in patient activation; measured using the Patient Activation Measure. Secondary: change in hearing and quality of life; qualitative feedback from patients and clinicians. Results One participant in the remote care group dropped out. The remote care group showed a greater increase in patient activation than the control group. Changes in hearing differed between the groups. The remote care group improved on the Triple Digit Test hearing test; the control group perceived their hearing was worse on the Speech  Spatial and Qualities of Hearing Scale questionnaire. Quality of life remained unchanged in both groups. Patients and clinicians were generally positive about remote care tools and wanted to continue. Conclusions Adults with cochlear implants were willing to be randomised and complied with the protocol. PersonalisedFeasibility of overnight closed-loop control based on hourly blood glucose measurements.PubMedPatte  Caroline; Pleus  Stefan; Galley  Paul; Weinert  Stefan; Haug  Cornelia; Freckmann  Guido2012-07-01Safe and effective closed-loop control (artificial pancreas) is the ultimate goal of insulin delivery. In this study  we examined the performance of a closed-loop control algorithm used for the overnight time period to safely achieve a narrow target range of blood glucose (BG) concentrations prior to breakfast. The primary goal was to compare the quality of algorithm control during repeated overnight experiments. Twenty-three subjects with type 1 diabetes performed 2 overnight experiments on each of three visits at the study site  resulting in 138 overnight experiments. On the first evening  the subject's insulin therapy was applied; on the second  the insulin was delivered by an algorithm based on subcutaneous continuous glucose measurements (including meal control) until midnight. Overnight closed-loop control was applied between midnight and 6 a.m. based on hourly venous BG measurements during the first and second nights. The number of BG values within the target range (90-150 mg/dl) increased from 52.9% (219 out of 414 measurements) during the first nights to 72.2% (299 out of 414 measurements) during the second nights (p < .001  Ï‡Â²-test). The occurrence of hypoglycemia interventions was reduced from 14 oral glucose interventions  the latest occurring at 2:36 a.m. during the first nights  to 1 intervention occurring at 1:02 a.m. during the second nights (p < .001  Ï‡Â²-test). Overnight controller performance improved when optimized initial control was given; this was suggested by the better metabolic control during the second night. Adequate controller run-in time seems to be important for achieving good overnight control. In addition  the findings demonstrate that hourly BG data are sufficient for the closed-loop control algorithm tested to achieve appropriate glycemic control. Â© 2012 Diabetes Technology Society.Effects of virtual rehabilitation versus conventional physical therapy on postural control  gait  and cognition of patients with Parkinson's disease: study protocol for a randomized controlled feasibility trial.PubMedSilva  Keyte Guedes; De Freitas  Tatiana Beline; DonÃ¡  FlÃ¡via; GananÃ§a  Fernando Freitas; Ferraz  Henrique Ballalai; Torriani-Pasin  Camila; Pompeu  JosÃ© Eduardo2017-01-01There is an association among postural instability  gait dysfunction  and cognitive impairment in subjects with Parkinson's disease (PD). Difficulty in dividing attention  response inhibition  and visuospatial attention deficiencies may contribute to the impairment of motor performance during daily activities. There are strong evidences that physical therapy can prevent physical and cognitive decline in individuals with PD. Recently  the European Physiotherapy Guideline (EPG) was developed based on randomized clinical trials about the effectiveness of the physical therapy to improve the functional deficiencies of individuals with PD. The EPG did not include the use of promising new intervention as virtual reality in PD due the lack of studies about its safety  feasibility and effectiveness. Therefore  this study protocol had as objective to evaluate the feasibility  safety and effectiveness of a physical therapy program-based on the European Physiotherapy Guideline (EPG) compared to Kinect-based training on postural control  gait  cognition  and quality of life (QoL) of Individuals with PD. A single-blind  parallel  randomized  controlled feasibility trial will be conducted with a sample of 32 individuals diagnosed with idiopathic PD. Participants will be allocated into control group (CG) and experimental group (EG). The intervention of the CG will be conventional physical therapy  and the intervention of the EG will be a supervised practice of five Kinect games. Both groups will perform 14 sessions of 1Â h each one  twice a week over 7Â weeks. Process outcomes will be safety  feasibility  adherence  and acceptability. Safety will be assessed by the proportion of participants who experienced intervention-related adverse events or any serious adverse event during the study period. Feasibility will be assessed through the scores of the games recorded in all training sessions. Adherence will be assessed through the participant's attendance. Acceptability will be theComponents of the costs of controlling quality: a transaction cost economics approach.PubMedStiles  R A; Mick  S S1997-01-01This article identifies the components that contribute to a healthcare organization's costs in controlling quality. A central tenet of our argument is that at its core  quality is the result of a series of transactions among members of a diverse network. Transaction cost economics is applied internally to analyze intraorganizational transactions that contribute to quality control  and questions for future research are posed.Tele-mentored damage-control and emergency trauma surgery: A feasibility study using live-tissue models.PubMedDawe  Philip; Kirkpatrick  Andrew; Talbot  Max; Beckett  Andrew; Garraway  Naisan; Wong  Heather; Hameed  Syed Morad2018-05-01Damage-control and emergency surgical procedures in trauma have the potential to save lives. They may occasionally not be performed due to clinician inexperience or lack of comfort and knowledge. Canadian Armed Forces (CAF) non-surgeon Medical Officers (MOs) participated in a live tissue training exercise. They received tele-mentoring assistance using a secure video-conferencing application on a smartphone/tablet platform. Feasibility of tele-mentored surgery was studied by measuring their effectiveness at completing a set series of tasks in this pilot study. Additionally  their comfort and willingness to perform studied procedures was gauged using pre- and post-study surveys. With no pre-procedural teaching  participants were able to complete surgical airway  chest tube insertion and resuscitative thoracotomy with 100% effectiveness with no noted complications. Comfort level and willingness to perform these procedures were improved with tele-mentoring. Participants felt that tele-mentored surgery would benefit their performance of resuscitative thoracotomy most. The use of tele-mentored surgery to assist non-surgeon clinicians in the performance of damage-control and emergency surgical procedures is feasible. More study is required to validate its effectiveness. Copyright Â© 2018 Elsevier Inc. All rights reserved.Engaging women with an embodied conversational agent to deliver mindfulness and lifestyle recommendations: A feasibility randomized control trial.PubMedGardiner  Paula M; McCue  Kelly D; Negash  Lily M; Cheng  Teresa; White  Laura F; Yinusa-Nyahkoon  Leanne; Jack  Brian W; Bickmore  Timothy W2017-09-01This randomized controlled trial evaluates the feasibility of using an Embodied Conversational Agent (ECA) to teach lifestyle modifications to urban women. Women were randomized to either 1) an ECA (content included: mindfulness  stress management  physical activity  and healthy eating) or 2) patient education sheets mirroring same content plus a meditation CD/MP3 once a day for one month. General outcome measures included: number of stress management techniques used  physical activity levels  and eating patterns. Sixty-one women ages 18 to 50 were enrolled. On average  51% identified as white  26% as black  23% as other races; and 20% as Hispanic. The major stress management techniques reported at baseline were: exercise (69%)  listening to music (70%)  and social support (66%). After one month  women randomized to the ECA significantly decreased alcohol consumption to reduce stress (p=0.03) and increased daily fruit consumption by an average of 2 servings compared to the control (p=0.04). It is feasible to use an ECA to promote health behaviors on stress management and healthy eating among diverse urban women. Compared to patient information sheets  ECAs provide promise as a way to teach healthy lifestyle behaviors to diverse urban women. Copyright Â© 2017 Elsevier B.V. All rights reserved.Feasibility of Self Powered Actuation for Flow  Separation and Vibration ControlNASA Technical Reports Server (NTRS)Shyam  Vikram; Bak  Dillon; Izadnegahdar  Alain2015-01-01A gas turbine engine is anywhere from 40-50% efficient. A large amount of energy is wasted as heat. Some of this heat is recoverable through the use of energy harvesting and can be used for powering on-board systems or for storing energy in batteries to replace auxiliary power units (APUs). As hybrid electric aircraft become more common  the use of energy harvesting will see increasingly more benefit and become commonplace in gas turbine engines. For electric aircraft with motors  TEGs would be beneficial for reclaiming waste heat from electric motors. The primary focus of this work was to evaluate the feasibility of harvesting energy from the hot section of a gas turbine engine (for a single aisle Boeing 737 thrust class) using thermoelectric generators (TEGs). The resulting heat could be used to power on-board actuation mechanisms such as plasma actuators and piezoelectric actuators. The work is a result of a two year NASA Center Innovation Fund from 2009 to 2011. The trade-off between thermoelectric harvesting and blade surface temperature were studied to ensure that blade durability is not adversely impacted by embedding a low thermal conductivity TEG. Calculations show that.5-10 Watts can be harvested per blade depending on flow conditions and on the thermoelectric material chosen. BiTe and SiGe were used for this analysis and future thermoelectric generators or multiferroic alloys could considerably improve power output.An electromechanical swing-phase-controlled prosthetic knee joint for conversion of physiological energy to electrical energy: feasibility study.PubMedAndrysek  Jan; Chau  Gilbert2007-12-01Microprocessor-controlled prostheses facilitate a more natural and efficient gait for individuals with above-knee amputations by continually adjusting the level of swing-phase damping. One caveat associated with these technologies is that the user must charge the onboard batteries on a daily basis. It is  therefore  the aim of this study to examine the feasibility of using an electromechanical system to provide prosthetic swing-phase damping and  concomitantly  the function of converting physiological energy that is normally dissipated during the swing phase  to electrical energy. Gait data from a single subject and data from a kinematic simulator were used to develop an empirical model. The findings in this study indicate that an electromagnetic system has appropriate characteristics for use in swing-phase control and also has the potential to recover energy under particular conditions.Optimal control theory determination of feasible return-to-launch-site aborts for the HL-20 Personnel Launch System vehicleNASA Technical Reports Server (NTRS)Dutton  Kevin E.1994-01-01The personnel launch system (PLS) being studied by NASA is a system to complement the space shuttle and provide alternative access to space. The PLS consists of a manned spacecraft launched by an expendable launch vehicle (ELV). A candidate for the manned spacecraft is the HL-20 lifting body. In the event of an ELV malfunction during the initial portion of the ascent trajectory  the HL-20 will separate from the rocket and perform an unpowered return to launch site (RTLS) abort. This work details an investigation  using optimal control theory  of the RTLS abort scenario. The objective of the optimization was to maximize final altitude. With final altitude as the cost function  the feasibility of an RTLS abort at different times during the ascent was determined. The method of differential inclusions was used to determine the optimal state trajectories  and the optimal controls were then calculated from the optimal states and state rates.Prostate cancer - evidence of exercise and nutrition trial (PrEvENT): study protocol for a randomised controlled feasibility trial.PubMedHackshaw-McGeagh  Lucy; Lane  J Athene; Persad  Raj; Gillatt  David; Holly  Jeff M P; Koupparis  Anthony; Rowe  Edward; Johnston  Lyndsey; Cloete  Jenny; Shiridzinomwa  Constance; Abrams  Paul; Penfold  Chris M; Bahl  Amit; Oxley  Jon; Perks  Claire M; Martin  Richard2016-03-07A growing body of observational evidence suggests that nutritional and physical activity interventions are associated with beneficial outcomes for men with prostate cancer  including brisk walking  lycopene intake  increased fruit and vegetable intake and reduced dairy consumption. However  randomised controlled trial data are limited. The 'Prostate Cancer: Evidence of Exercise and Nutrition Trial' investigates the feasibility of recruiting and randomising men diagnosed with localised prostate cancer and eligible for radical prostatectomy to interventions that modify nutrition and physical activity. The primary outcomes are randomisation rates and adherence to the interventions at 6 months following randomisation. The secondary outcomes are intervention tolerability  trial retention  change in prostate specific antigen level  change in diet  change in general physical activity levels  insulin-like growth factor levels  and a range of related outcomes  including quality of life measures. The trial is factorial  randomising men to both a physical activity (brisk walking or control) and nutritional (lycopene supplementation or increased fruit and vegetables with reduced dairy consumption or control) intervention. The trial has two phases: men are enrolled into a cohort study prior to radical prostatectomy  and then consented after radical prostatectomy into a randomised controlled trial. Data are collected at four time points (cohort baseline  true trial baseline and 3 and 6 months post-randomisation). The Prostate Cancer: Evidence of Exercise and Nutrition Trial aims to determine whether men with localised prostate cancer who are scheduled for radical prostatectomy can be recruited into a cohort and subsequently randomised to a 6-month nutrition and physical activity intervention trial. If successful  this feasibility trial will inform a larger trial to investigate whether this population will gain clinical benefit from long-term nutritional and physical activityFeasibility and acceptability of insecticide-treated plastic sheeting (ITPS) for vector control in Papua New GuineaPubMed Central2012-01-01Background This study assessed the feasibility and acceptability of utilizing insecticide-treated plastic sheeting (ITPS) as a malaria control intervention in Papua New Guinea (PNG). Methods ZeroVectorÂ® ITPS was installed in 40 homes across four study sites representing a cross section of malaria transmission risk and housing style. Structured questionnaires were completed at the time of ITPS installation (n=40) and at four weeks post installation (n=40) with the household head. Similarly  group interviews with the male and/or female household heads were completed at installation (n=5) and four-week follow-up (n=4). Results ZeroVectorÂ® ITPS was successfully installed in a range of homes employing traditional and/or modern building materials in PNG. The ITPS installations remained intact over the course of the four-week trial period and were highly acceptable to both male and female household heads. No dissatisfaction with the ITPS product was reported at four-week follow-up; however  the installation process was time consuming  participants reported a reduction in mosquito net use following ITPS installation and many participants expressed concern about the longevity of ITPS over the longer term. Conclusion ZeroVectorÂ® ITPS installation is feasible and highly acceptable in a diverse range of PNG contexts and is likely to be favourably received as a vector control intervention if accessible en masse. A longer-term evaluation is required before firm policy or public health decisions can be made regarding the potential application of ITPS in the national malaria control programme. The positive study findings suggest a longer-term evaluation of this promising malaria control intervention warrants consideration. PMID:23046535Cerebral Oximetry Monitoring to Maintain Normal Cerebral Oxygen Saturation during High-risk Cardiac Surgery: A Randomized Controlled Feasibility Trial.PubMedDeschamps  Alain; Hall  Richard; Grocott  Hilary; Mazer  C David; Choi  Peter T; Turgeon  Alexis F; de Medicis  Etienne; BussiÃ¨res  Jean S; Hudson  Christopher; Syed  Summer; Seal  Doug; Herd  Stuart; Lambert  Jean; Denault  AndrÃ©; Deschamps  Alain; Mutch  Alan; Turgeon  Alexis; Denault  Andre; Todd  Andrea; Jerath  Angela; Fayad  Ashraf; Finnegan  Barry; Kent  Blaine; Kennedy  Brent; Cuthbertson  Brian H; Kavanagh  Brian; Warriner  Brian; MacAdams  Charles; Lehmann  Christian; Fudorow  Christine; Hudson  Christopher; McCartney  Colin; McIsaac  Dan; Dubois  Daniel; Campbell  David; Mazer  David; Neilpovitz  David; Rosen  David; Cheng  Davy; Drapeau  Dennis; Dillane  Derek; Tran  Diem; Mckeen  Dolores; Wijeysundera  Duminda; Jacobsohn  Eric; Couture  Etienne; de Medicis  Etienne; Alam  Fahad; Abdallah  Faraj; Ralley  Fiona E; Chung  Frances; Lellouche  Francois; Dobson  Gary; Germain  Genevieve; Djaiani  George; Gilron  Ian; Hare  Gregory; Bryson  Gregory; Clarke  Hance; McDonald  Heather; Roman-Smith  Helen; Grocott  Hilary; Yang  Homer; Douketis  James; Paul  James; Beaubien  Jean; BussiÃ¨res  Jean; Pridham  Jeremy; Armstrong  J N; Parlow  Joel; Murkin  John; Gamble  Jonathan; Duttchen  Kaylene; Karkouti  Keyvan; Turner  Kim; Baghirzada  Leyla; Szabo  Linda; Lalu  Manoj; Wasowicz  Marcin; Bautista  Michael; Jacka  Michael; Murphy  Michael; Schmidt  Michael; Verret  MichaÃ«l; Perrault  Michel-Antoine; Beaudet  Nicolas; Buckley  Norman; Choi  Peter; MacDougall  Peter; Jones  Philip; Drolet  Pierre; Beaulieu  Pierre; Taneja  Ravi; Martin  Rene; Hall  Richard; George  Ronald; Chun  Rosa; McMullen  Sarah; Beattie  Scott; Sampson  Sonia; Choi  Stephen; Kowalski  Stephen; McCluskey  Stuart; Syed  Summer; Boet  Sylvain; Ramsay  Tim; Saha  Tarit; Mutter  Thomas; Chowdhury  Tumul; Uppal  Vishal; Mckay  William2016-04-01Cerebral oxygen desaturation during cardiac surgery has been associated with adverse perioperative outcomes. Before a large multicenter randomized controlled trial (RCT) on the impact of preventing desaturations on perioperative outcomes  the authors undertook a randomized prospective  parallel-arm  multicenter feasibility RCT to determine whether an intervention algorithm could prevent desaturations. Eight Canadian sites randomized 201 patients between April 2012 and October 2013. The primary outcome was the success rate of reversing cerebral desaturations below 10% relative to baseline in the intervention group. Anesthesiologists were blinded to the cerebral saturation values in the control group. Intensive care unit personnel were blinded to cerebral saturation values for both groups. Secondary outcomes included the area under the curve of cerebral desaturation load  enrolment rates  and a 30-day follow-up for adverse events. Cerebral desaturations occurred in 71 (70%) of the 102 intervention group patients and 56 (57%) of the 99 control group patients (P = 0.04). Reversal was successful in 69 (97%) of the intervention group patients. The mean cerebral desaturation load (SD) in the operating room was smaller for intervention group patients compared with control group patients (104 [217] %.min vs. 398 [869] %.min  mean difference  -294; 95% CI  -562 to -26; P = 0.03). This was also true in the intensive care unit (P = 0.02). There were no differences in adverse events between the groups. Study sites were successful in reversal of desaturation  patient recruitment  randomization  and follow-up in cardiac surgery  supporting the feasibility of conducting a large multicenter RCT.Feasibility and Efficacy of an mHealth Game for Managing Anxiety: ""Flowy"" Randomized Controlled Pilot Trial and Design Evaluation.PubMedPham  Quynh; Khatib  Yasmin; Stansfeld  Stephen; Fox  Simon; Green  Tobias2016-02-01Meeting the complex needs of patients with chronic common mental health disorders (CMHDs) may be the greatest challenge facing organized medical practice. On the basis of a well-established and proven theoretical foundation for controlled respiration as a behavioral intervention for CMHDs  as well as preliminary evidence that gamification can improve health outcomes through increasing patient engagement  this randomized controlled pilot study evaluated the feasibility and clinical efficacy of a mobile health game called ""Flowy"" ( www.flowygame.com ) that digitally delivered breathing retraining exercises for anxiety  panic  and hyperventilation symptom management. We designed an unblinded  Web-based  parallel-group randomized controlled trial focusing on feasibility  clinical efficacy  and design proof of concept. In the intervention condition (nâ€‰=â€‰31)  participants received free access to ""Flowy"" for 4 weeks. In the control condition (nâ€‰=â€‰32)  participants were placed on a waitlist for 4 weeks before being offered free access to ""Flowy."" Online measurements using psychological self-report questionnaires were made at 2 and 4 weeks post-baseline. At trial conclusion  participants found ""Flowy"" acceptable as an anxiety management intervention. ""Flowy"" engaged participants sufficiently to endorse proactive gameplay. Intent-to-treat analysis revealed a reduction in anxiety  panic  and self-report hyperventilation scores in both trial arms  with the intervention arm experiencing greater quality of life. Participants perceived ""Flowy"" as a fun and useful intervention  proactively used ""Flowy"" as part of their care  and would recommend ""Flowy"" to family and friends. Our results suggest that a digital delivery of breathing retraining exercises through a mobile health game can manage anxiety  panic  and hyperventilation symptoms associated with CMHDs.Feasibility and acceptability of insecticide-treated plastic sheeting (ITPS) for vector control in Papua New Guinea.PubMedPulford  Justin; Tandrapah  Anthony; Atkinson  Jo-An; Kaupa  Brown; Russell  Tanya; Hetzel  Manuel W2012-10-09This study assessed the feasibility and acceptability of utilizing insecticide-treated plastic sheeting (ITPS) as a malaria control intervention in Papua New Guinea (PNG). ZeroVectorÂ® ITPS was installed in 40 homes across four study sites representing a cross section of malaria transmission risk and housing style. Structured questionnaires were completed at the time of ITPS installation (n=40) and at four weeks post installation (n=40) with the household head. Similarly  group interviews with the male and/or female household heads were completed at installation (n=5) and four-week follow-up (n=4). ZeroVectorÂ® ITPS was successfully installed in a range of homes employing traditional and/or modern building materials in PNG. The ITPS installations remained intact over the course of the four-week trial period and were highly acceptable to both male and female household heads. No dissatisfaction with the ITPS product was reported at four-week follow-up; however  the installation process was time consuming  participants reported a reduction in mosquito net use following ITPS installation and many participants expressed concern about the longevity of ITPS over the longer term. ZeroVectorÂ® ITPS installation is feasible and highly acceptable in a diverse range of PNG contexts and is likely to be favourably received as a vector control intervention if accessible en masse. A longer-term evaluation is required before firm policy or public health decisions can be made regarding the potential application of ITPS in the national malaria control programme. The positive study findings suggest a longer-term evaluation of this promising malaria control intervention warrants consideration.Feasibility Analysis and Evaluation of an Adaptive Tracked Vehicle Suspension and Control SystemDTIC Science & Technology1975-06-01CONTROL SYSTEM FINAL REPORT JUNE 1975 Contract No. DAAE07-72-C-017 D D C â€¢W 6 1976 B t> y Robert M. Salemka National Water Lift Company A...spring rate which is as soft as a hydropneumatic system. 3.3 Adaptive Control The adaptive control was achieved by switching the jounce damping relief...inherently included in this type of system. The solenoid valves are of the normally closed type so that with no electrical power   the system willFeasibility of ultra-low-volume indoor space spraying for dengue control in Southern Thailand.PubMedDitsuwan  Thanittha; Liabsuetrakul  Tippawan; Ditsuwan  Vallop; Thammapalo  Suwich2013-02-01To assess the feasibility of conducting standard indoor space spraying using ultra-low-volume (SID-ULV) in terms of willingness to pay (WTP) and ability to pay (ATP) and ability to conduct space spraying by local administrative organisations (LAO) in lower Southern Thailand. Cross-sectional study. The executive leaders of each LAO were asked to state their WTP and ATP for SID-ULV. Willingness to pay was measured by the payment card and open-ended question methods. Ability to pay was calculated using the budget allocation for space spraying and estimated expenditure for SID-ULV. Ability to conduct the SID-ULV was assessed by interviewing the spraymen. Average WTP and ATP were calculated and uncertainties were estimated using a bootstrapping technique. Ninty-three percent of executive leaders were willing to pay for SID-ULV. The average WTP per case was USD 259 (95% confidence interval [CI] 217-303). Thirty-eight percent of all LAO had actual ATP and 60% had ideal ATP. The average annual budget allocated for space spraying was USD 2327 (95% CI: 1654-3138). The amount of money LAO were willing to pay did not vary significantly between their different types  but ATP did. Thirty-two percent of spraymen could not complete all nine procedures of SID-ULV. Although WTP for SID-ULV space spraying was high  ATP was low  which revealed the flexibility of budget allocation for SID-ULV in each LAO. The spraymen require training in SID-ULV space spraying. Â© 2012 Blackwell Publishing Ltd.Design of a variable width pulse generator feasible for manual or automatic controlNASA Astrophysics Data System (ADS)Vegas  I.; Antoranz  P.; Miranda  J. M.; Franco  F. J.2017-01-01A variable width pulse generator featuring more than 4-V peak amplitude and less than 10-ns FWHM is described. In this design the width of the pulses is controlled by means of the control signal slope. Thus  a variable transition time control circuit (TTCC) is also developed  based on the charge and discharge of a capacitor by means of two tunable current sources. Additionally  it is possible to activate/deactivate the pulses when required  therefore allowing the creation of any desired pulse pattern. Furthermore  the implementation presented here can be electronically controlled. In conclusion  due to its versatility  compactness and low cost it can be used in a wide variety of applications.Investigating the feasibility of using quick response codes in highway construction for document control.DOT National Transportation Integrated Search2015-07-01Highway construction takes place in remote locations  making document control challenging. Frequent changes in a project can cause errors  : reworks  and schedule delays due to the time taken to disseminate these changes to the field or due to using ...Joint crisis plans for people with borderline personality disorder: feasibility and outcomes in a randomised controlled trial.PubMedBorschmann  Rohan; Barrett  Barbara; Hellier  Jennifer M; Byford  Sarah; Henderson  Claire; Rose  Diana; Slade  Mike; Sutherby  Kim; Szmukler  George; Thornicroft  Graham; Hogg  Joanna; Moran  Paul2013-05-01People with borderline personality disorder frequently experience crises. To date  no randomised controlled trials (RCTs) of crisis interventions for this population have been published. To examine the feasibility of recruiting and retaining adults with borderline personality disorder to a pilot RCT investigating the potential efficacy and cost-effectiveness of using a joint crisis plan. An RCT of joint crisis plans for community-dwelling adults with borderline personality disorder (trial registration: ISRCTN12440268). The primary outcome measure was the occurrence of self-harming behaviour over the 6-month period following randomisation. Secondary outcomes included depression  anxiety  engagement and satisfaction with services  quality of life  well-being and cost-effectiveness. In total  88 adults out of the 133 referred were eligible and were randomised to receive a joint crisis plan in addition to treatment as usual (TAU; n = 46) or TAU alone (n = 42). This represented approximately 75% of our target sample size and follow-up data were collected on 73 (83.0%) participants. Intention-to-treat analysis revealed no significant differences in the proportion of participants who reported self-harming (odds ratio (OR) = 1.9  95% CI 0.53-6.5  P = 0.33) or the frequency of self-harming behaviour (rate ratio (RR) = 0.74  95% CI 0.34-1.63  P = 0.46) between the two groups at follow-up. No significant differences were observed between the two groups on any of the secondary outcome measures or costs. It is feasible to recruit and retain people with borderline personality disorder to a trial of joint crisis plans and the intervention appears to have high face validity with this population. However  we found no evidence of clinical efficacy in this feasibility study.Modifying Alcohol Consumption to Reduce Obesity: A Randomized Controlled Feasibility Study of a Complex Community-based Intervention for Men.PubMedIrvine  Linda; Crombie  Iain K; Cunningham  Kathryn B; Williams  Brian; Sniehotta  Falko F; Norrie  John; Melson  Ambrose J; Jones  Claire; Rice  Peter; Slane  Peter W; Achison  Marcus; McKenzie  Andrew; Dimova  Elena D; Allan  Sheila2017-11-01Being obese and drinking more than 14 units of alcohol per week places men at very high risk of developing liver disease. This study assessed the feasibility of a trial to reduce alcohol consumption. It tested the recruitment strategy  engagement with the intervention  retention and study acceptability. Men aged 35-64 years who drank >21 units of alcohol per week and had a BMI > 30 were recruited by two methods: from GP patient registers and by community outreach. The intervention was delivered by a face to face session followed by a series of text messages. Trained lay people (Study Coordinators) delivered the face to face session. Participants were followed up for 5 months from baseline to measure weekly alcohol consumption and BMI. The recruitment target of 60 was exceeded  with 69 men recruited and randomized. At baseline  almost all the participants (95%) exceeded the threshold for a 19-fold increase in the risk of dying from liver disease. The intervention was delivered with high fidelity. A very high follow-up rate was achieved (98%) and the outcomes for the full trial were measured. Process evaluation showed that participants responded as intended to key steps in the behaviour change strategy. The acceptability of the study methods was high: e.g. 80% of men would recommend the study to others. This feasibility study identified a group at high risk of liver disease. It showed that a full trial could be conducted to test the effectiveness and cost-effectiveness of the intervention. Current controlled trials: ISRCTN55309164. National Institute for Health Research Health Technology Assessment (NIHR HTA). This feasibility study recruited 69 men at high risk of developing liver disease. The novel intervention  to reduce alcohol consumption through the motivation of weight loss  was well received. A very high follow-up rate was achieved. Process evaluation showed that participants engaged with key components of the behaviour change strategy. Â© The Author 2017Modifying Alcohol Consumption to Reduce Obesity: A Randomized Controlled Feasibility Study of a Complex Community-based Intervention for MenPubMed CentralIrvine  Linda; Crombie  Iain K; Cunningham  Kathryn B; Williams  Brian; Sniehotta  Falko F; Norrie  John; Melson  Ambrose J; Jones  Claire; Rice  Peter; Slane  Peter W; Achison  Marcus; McKenzie  Andrew; Dimova  Elena D; Allan  Sheila2017-01-01Abstract Objectives Being obese and drinking more than 14 units of alcohol per week places men at very high risk of developing liver disease. This study assessed the feasibility of a trial to reduce alcohol consumption. It tested the recruitment strategy  engagement with the intervention  retention and study acceptability. Methods Men aged 35â€“64 years who drank >21 units of alcohol per week and had a BMI > 30 were recruited by two methods: from GP patient registers and by community outreach. The intervention was delivered by a face to face session followed by a series of text messages. Trained lay people (Study Coordinators) delivered the face to face session. Participants were followed up for 5 months from baseline to measure weekly alcohol consumption and BMI. Results The recruitment target of 60 was exceeded  with 69 men recruited and randomized. At baseline  almost all the participants (95%) exceeded the threshold for a 19-fold increase in the risk of dying from liver disease. The intervention was delivered with high fidelity. A very high follow-up rate was achieved (98%) and the outcomes for the full trial were measured. Process evaluation showed that participants responded as intended to key steps in the behaviour change strategy. The acceptability of the study methods was high: e.g. 80% of men would recommend the study to others. Conclusions This feasibility study identified a group at high risk of liver disease. It showed that a full trial could be conducted to test the effectiveness and cost-effectiveness of the intervention. Trial registration Current controlled trials: ISRCTN55309164. Trial funding National Institute for Health Research Health Technology Assessment (NIHR HTA). Short summary This feasibility study recruited 69 men at high risk of developing liver disease. The novel intervention  to reduce alcohol consumption through the motivation of weight loss  was well received. A very high follow-up rate was achieved. Process evaluation showed thatSocial facilitation maintenance treatment for adults with obesity: study protocol for a randomised-controlled feasibility study (SFM study).PubMedHilbert  Anja2016-08-31The long-term success of non-surgical weight loss treatment in adults with obesity is limited by substantial relapse  and only a few evidence-based weight loss maintenance treatments exist. This clinical trial investigates the feasibility and efficacy of a social facilitation maintenance programme for weight loss maintenance  tailored to meet the needs of obese adults who have undergone a lifestyle weight loss intervention. In a single-centre  open feasibility trial  72 adults currently or previously obese or overweight who have undergone a lifestyle weight loss intervention are centrally randomised to 4â€…months of social facilitation maintenance treatment or treatment as a usual control condition. In 16 outpatient group sessions  the social facilitation maintenance treatment  based on a socioecological model and on evidence supporting social facilitation as a key process in maintaining weight loss  focuses on promoting interpersonal relationships to build up a healthy lifestyle for long-term weight loss maintenance. Primary outcome is the amount of weight regain at 6-month follow-up  compared with pre-treatment weight  derived from measured body weight. Secondary outcomes address feasibility  including recruitment  attrition  assessment non-completion  compliance and patients' programme evaluation; and in comparison with pre-weight loss maintenance  social and interpersonal functioning  eating behaviour and physical activity  psychological and physical symptoms  body composition and risk of comorbidity  and quality of life at post-treatment and follow-up assessments. The study was approved by the Ethical Committee at the University of Leipzig (165-13-15072013). The study results will be disseminated through peer-reviewed publications. DRKS00005182. Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://www.bmj.com/company/products-services/rights-and-licensing/The feasibility of determining the effectiveness and cost-effectiveness of medication organisation devices compared with usual care for older people in a community setting: systematic review  stakeholder focus groups and feasibility randomised controlled trial.PubMedBhattacharya  Debi; Aldus  Clare F; Barton  Garry; Bond  Christine M; Boonyaprapa  Sathon; Charles  Ian S; Fleetcroft  Robert; Holland  Richard; Jerosch-Herold  Christina; Salter  Charlotte; Shepstone  Lee; Walton  Christine; Watson  Steve; Wright  David J2016-07-01Medication organisation devices (MODs) provide compartments for a patient's medication to be organised into the days of the week and the recommended times the medication should be taken. To define the optimal trial design for testing the clinical effectiveness and cost-effectiveness of MODs. The feasibility study comprised a systematic review and focus groups to inform a randomised controlled trial (RCT) design. The resulting features were tested on a small scale  using a 2â€‰Ã—â€‰2 factorial design to compare MODs with usual packaging and to compare weekly with monthly supply. The study design was then evaluated. Potential participants were identified by medical practices. Aged over 75 years  prescribed at least three solid oral dosage form medications  unintentionally non-adherent and self-medicating. Participants were excluded if deemed by their health-care team to be unsuitable. One of three MODs widely used in routine clinical practice supplied either weekly or monthly. To identify the most effective method of participant recruitment  to estimate the prevalence of intentional and unintentional non-adherence in an older population  to provide a point estimate of the effect size of MODs relative to usual care and to determine the feasibility and acceptability of trial participation. The systematic review included MOD studies of any design reporting medication adherence  health and social outcomes  resource utilisation or dispensing or administration errors. Focus groups with patients  carers and health-care professionals supplemented the systematic review to inform the RCT design. The resulting design was implemented and then evaluated through questionnaires and group discussions with participants and health-care professionals involved in trial delivery. Studies on MODs are largely of poor quality. The relationship between adherence and health outcomes is unclear. Of the limited studies reporting health outcomes  some reported a positive relationship while someEconomic Model Predictive Control of Bihormonal Artificial Pancreas System Based on Switching Control and Dynamic R-parameter.PubMedTang  Fengna; Wang  Youqing2017-11-01Blood glucose (BG) regulation is a long-term task for people with diabetes. In recent years  more and more researchers have attempted to achieve automated regulation of BG using automatic control algorithms  called the artificial pancreas (AP) system. In clinical practice  it is equally important to guarantee the treatment effect and reduce the treatment costs. The main motivation of this study is to reduce the cure burden. The dynamic R-parameter economic model predictive control (R-EMPC) is chosen to regulate the delivery rates of exogenous hormones (insulin and glucagon). It uses particle swarm optimization (PSO) to optimize the economic cost function and the switching logic between insulin delivery and glucagon delivery is designed based on switching control theory. The proposed method is first tested on the standard subject; the result is compared with the switching PID and the switching MPC. The effect of the dynamic R-parameter on improving the control performance is illustrated by comparing the results of the EMPC and the R-EMPC. Finally  the robustness tests on meal change (size and timing)  hormone sensitivity (insulin and glucagon)  and subject variability are performed. All results show that the proposed method can improve the control performance and reduce the economic costs. The simulation results verify the effectiveness of the proposed algorithm on improving the tracking performance  enhancing robustness  and reducing economic costs. The method proposed in this study owns great worth in practical application.Timely and complete publication of economic evaluations alongside randomized controlled trials.PubMedThorn  Joanna C; Noble  Sian M; Hollingworth  William2013-01-01Little is known about the extent and nature of publication bias in economic evaluations. Our objective was to determine whether economic evaluations are subject to publication bias by considering whether economic data are as likely to be reported  and reported as promptly  as effectiveness data. Trials that intended to conduct an economic analysis and ended before 2008 were identified in the International Standard Randomised Controlled Trial Number (ISRCTN) register; a random sample of 100 trials was retrieved. Fifty comparator trials were randomly drawn from those not identified as intending to conduct an economic study. The trial start and end dates  estimated sample size and funder type were extracted. For trials planning economic evaluations  effectiveness and economic publications were sought; publication dates and journal impact factors were extracted. Effectiveness abstracts were assessed for whether they reached a firm conclusion that one intervention was most effective. Primary investigators were contacted about reasons for non-publication of results  or reasons for differential publication strategies for effectiveness and economic results. Trials planning an economic study were more likely to be funded by government (pÂ =Â 0.01) and larger (pÂ =Â 0.003) than other trials. The trials planning an economic evaluation had a mean of 6.5 (range 2.7-13.2) years since the trial end in which to publish their results. Effectiveness results were reported by 70 %  while only 43 % published economic evaluations (pÂ <Â 0.001). Reasons for non-publication of economic results included the intervention being ineffective  and staffing issues. Funding source  time since trial end and length of study were not associated with a higher probability of publishing the economic evaluation. However  studies that were small or of unknown size were significantly less likely to publish economic evaluations than large studies (pÂ <Â 0.001). The authors' confidence in labelling oneFeasibility study of transmission of OTV camera control information in the video vertical blanking intervalNASA Technical Reports Server (NTRS)White  Preston A.  III1994-01-01The Operational Television system at Kennedy Space Center operates hundreds of video cameras  many remotely controllable  in support of the operations at the center. This study was undertaken to determine if commercial NABTS (North American Basic Teletext System) teletext transmission in the vertical blanking interval of the genlock signals distributed to the cameras could be used to send remote control commands to the cameras and the associated pan and tilt platforms. Wavelength division multiplexed fiberoptic links are being installed in the OTV system to obtain RS-250 short-haul quality. It was demonstrated that the NABTS transmission could be sent over the fiberoptic cable plant without excessive video quality degradation and that video cameras could be controlled using NABTS transmissions over multimode fiberoptic paths as long as 1.2 km.The safety climate in primary care (SAP-C) study: study protocol for a randomised controlled feasibility study.PubMedLydon  SinÃ©ad; Cupples  Margaret E; Hart  Nigel; Murphy  Andrew W; Faherty  Aileen; O'Connor  Paul2016-01-01Research on patient safety has focused largely on secondary care settings  and there is a dearth of knowledge relating to safety culture or climate  and safety climate improvement strategies  in the context of primary care. This is problematic given the high rates of usage of primary care services and the myriad of opportunities for clinical errors daily. The current research programme aimed to assess the effectiveness of an intervention derived from the Scottish Patient Safety Programme in Primary Care. The intervention consists of safety climate measurement and feedback and patient chart audit using the trigger review method. The purpose of this paper is to describe the background to this research and to present the methodology of this feasibility study in preparation for a future definitive RCT. The SAP-C study is a feasibility study employing a randomised controlled pretest-posttest design that will be conducted in 10 general practices in the Republic of Ireland and Northern Ireland. Five practices will receive the safety climate intervention over a 9-month period. The five practices in the control group will continue care as usual but will complete the GP-SafeQuest safety climate questionnaire at baseline (month 1) and at the terminus of the intervention (month 9). The outcomes of the study include process evaluation metrics (i.e. rates of participant recruitment and retention  rates of completion of safety climate measures  qualitative data regarding participants' perceptions of the intervention's potential efficacy  acceptability  and sustainability)  patient safety culture in intervention and control group practices at posttest  and instances of undetected patient harm identified through patient chart audit using the trigger review method. The planned study investigates an intervention to improve safety climate in Irish primary care settings. The resulting data may inform our knowledge of the frequency of undetected patient safety incidents in primary careLeap motion controlled videogame-based therapy for rehabilitation of elderly patients with subacute stroke: a feasibility pilot study.PubMedIosa  Marco; Morone  Giovanni; Fusco  Augusto; Castagnoli  Marcello; Fusco  Francesca Romana; Pratesi  Luca; Paolucci  Stefano2015-08-01The leap motion controller (LMC) is a new optoelectronic system for capturing motion of both hands and controlling a virtual environment. Differently from previous devices  it optoelectronically tracks the fine movements of fingers neither using glows nor markers. This pilot study explored the feasibility of adapting the LMC  developed for videogames  to neurorehabilitation of elderly with subacute stroke. Four elderly patients (71.50 Â± 4.51 years old) affected by stroke in subacute phase were enrolled and tested in a cross-over pilot trial in which six sessions of 30 minutes of LMC videogame-based therapy were added on conventional therapy. Measurements involved participation to the sessions  evaluated by means of the Pittsburgh Rehabilitation Participation Scale  hand ability and grasp force evaluated respectively by means of the Abilhand Scale and by means of the dynamometer. Neither adverse effects nor spasticity increments were observed during LMC training. Participation to the sessions was excellent in three patients and very good in one patient during the LMC trial. In this period  patients showed a significantly higher improvement in hand abilities (P = 0.028) and grasp force (Pâ€‰=â€‰0.006). This feasibility pilot study was the first one using leap motion controller for conducting a videogame-based therapy. This study provided a proof of concept that LMC can be a suitable tool even for elderly patients with subacute stroke. LMC training was in fact performed with a high level of active participation  without adverse effects  and contributed to increase the recovery of hand abilities.Feasibility and efficacy of a robotic device for hand rehabilitation in hemiplegic stroke patients: a randomized pilot controlled study.PubMedVanoglio  Fabio; Bernocchi  Palmira; MulÃ¨  Chiara; Garofali  Francesca; Mora  Chiara; Taveggia  Giovanni; Scalvini  Simonetta; Luisa  Alberto2017-03-01The purpose of the study was to evaluate the feasibility and efficacy of robot-assisted hand rehabilitation in improving arm function abilities in sub-acute hemiplegic patients. Randomized controlled pilot study. Inpatient rehabilitation centers. Thirty hemiplegic stroke patients (Ashworth spasticity index <3) were recruited and randomly divided into a Treatment group (TG) and Control group (CG). Patients in the TG received intensive hand training with Gloreha  a hand rehabilitation glove that provides computer-controlled  repetitive  passive mobilization of the fingers  with multisensory feedback. Patients in the CG received the same amount of time in terms of conventional hand rehabilitation. Hand motor function (Motricity Index  MI)  fine manual dexterity (Nine Hole Peg Test  NHPT) and strength (Grip and Pinch test) were measured at baseline and after rehabilitation  and the differences  (Î”) mean(standard deviation)  compared between groups. Results Twenty-seven patients concluded the program: 14 in the TG and 13 in the CG. None of the patients refused the device and only one adverse event of rheumatoid arthritis reactivation was reported. Baseline data did not differ significantly between the two groups. In TG  Î”MI 23(16.4)  Î”NHPT 0.16(0.16)  Î”GRIP 0.27(0.23) and Î”PINCH 0.07(0.07) were significantly greater than in CG  Î”MI 5.2(9.2)  Î”NHPT 0.02(0.07)  Î”GRIP 0.03(0.06) and Î”PINCH 0.02(0.03)] ( p=0.002  p=0.009  p=0.003 and p=0.038  respectively). Gloreha Professional is feasible and effective in recovering fine manual dexterity and strength and reducing arm disability in sub-acute hemiplegic patients.Feasibility of a randomized controlled trial to evaluate the impact of decision boxes on shared decision-making processes.PubMedGiguere  Anik Mc; Labrecque  Michel; LÃ©garÃ©  France; Grad  Roland; Cauchon  Michel; Greenway  Matthew; Haynes  R Brian; Pluye  Pierre; Syed  Iqra; Banerjee  Debi; Carmichael  Pierre-Hugues; Martin  MÃ©lanie2015-02-25Decision boxes (DBoxes) are two-page evidence summaries to prepare clinicians for shared decision making (SDM). We sought to assess the feasibility of a clustered Randomized Controlled Trial (RCT) to evaluate their impact. A convenience sample of clinicians (nurses  physicians and residents) from six primary healthcare clinics who received eight DBoxes and rated their interest in the topic and satisfaction. After consultations  their patients rated their involvement in decision-making processes (SDM-Q-9 instrument). We measured clinic and clinician recruitment rates  questionnaire completion rates  patient eligibility rates  and estimated the RCT needed sample size. Among the 20 family medicine clinics invited to participate in this study  four agreed to participate  giving an overall recruitment rate of 20%. Of 148 clinicians invited to the study  93 participated (63%). Clinicians rated an interest in the topics ranging 6.4-8.2 out of 10 (with 10 highest) and a satisfaction with DBoxes of 4 or 5 out of 5 (with 5 highest) for 81% DBoxes. For the future RCT  we estimated that a sample size of 320 patients would allow detecting a 9% mean difference in the SDM-Q-9 ratings between our two arms (0.02 ICC; 0.05 significance level; 80% power). Clinicians' recruitment and questionnaire completion rates support the feasibility of the planned RCT. The level of interest of participants for the DBox topics  and their level of satisfaction with the Dboxes demonstrate the acceptability of the intervention. Processes to recruit clinics and patients should be optimized.General or Spinal Anaesthetic for Vaginal Surgery in Pelvic Floor Disorders (GOSSIP): a feasibility randomised controlled trial.PubMedPurwar  B; Ismail  K M; Turner  N; Farrell  A; Verzune  M; Annappa  M; Smith  I; El-Gizawy  Zeiad; Cooper  J C2015-08-01Spinal anaesthesia (SA) and general anaesthesia (GA) are widely used techniques for vaginal surgery for pelvic floor disorders with inconclusive evidence of the superiority of either. We conducted a randomised controlled trial (RCT) to assess the feasibility of a full scale RCT aiming to examine the effect of anaesthetic mode for vaginal surgery on operative  patient reported and length of hospital stay (LOHS) outcomes. Patients undergoing vaginal surgery  recruited through a urogynaecology service in a University teaching hospital  were randomised to receive either GA or SA. Patients were followed up for 12 weeks postoperatively. Pain was measured on a visual analogue scale; nausea was assessed with a four-point verbal rating scale. Patient's subjective perception of treatment outcome  quality of life (QoL) and functional outcomes were assessed using the International Consultation on Incontinence Modular Questionnaire (ICIQ) on vaginal symptoms and the SF-36 questionnaire. Sixty women were randomised  29 to GA and 31 to SA. The groups were similar in terms of age and type of vaginal surgery performed. No statistically significant differences were noted between the groups with regard to pain  nausea  quality of life (QoL)  functional outcomes as well as length of stay in the postoperative recovery room  use of analgesia postoperatively and LOHS. This study has demonstrated that a full RCT is feasible and should focus on the length of hospital stay in a subgroup of patients undergoing vaginal surgery where SA may help to facilitate enhanced recovery or day surgery.Feasibility and reliability of a virtual reality oculus platform to measure sensory integration for postural control in young adults.PubMedLubetzky  Anat V; Kary  Erinn E; Harel  Daphna; Hujsak  Bryan; Perlin  Ken2018-01-24Using Unity for the Oculus Development-Kit 2  we have developed an affordable  portable virtual reality platform that targets the visuomotor domain  a missing link in current clinical assessments of postural control. Here  we describe the design and technical development as well as report its feasibility with regards to cybersickness and test-retest reliability in healthy young adults. Our virtual reality paradigm includes two functional scenes ('City' and 'Park') and four moving dots scenes. Twenty-one healthy young adults were tested twice  one to two weeks apart. They completed a simulator sickness questionnaire several times per session. Their postural sway response was recorded from a forceplate underneath their feet while standing on the floor  stability trainers  or a Both Sides Up (BOSU) ball. Sample entropy  postural displacement  velocity  and excursion were calculated and compared between sessions given the visual and surface conditions. Participants reported slight-to-moderate transient side effects. Intra-Class Correlation values mostly ranged from 0.5 to 0.7 for displacement and velocity  were above 0.5 (stability trainer conditions) and above 0.4 (floor mediolateral conditions) for sample entropy  and minimal for excursion. Our novel portable VR platform was found to be feasible and reliable in healthy young adults.A double-blind randomized placebo-controlled feasibility study evaluating individualized homeopathy in managing pain of knee osteoarthritis.PubMedKoley  Munmun; Saha  Subhranil; Ghosh  Shubhamoy2015-07-01Few homeopathic complexes seemed to produce significant effects in osteoarthritis; still  individualized homeopathy remained untested. We evaluated the feasibility of conducting an efficacy trial of individualized homeopathy in osteoarthritis. A prospective  parallel-arm  double-blind  randomized  placebo-controlled pilot study was conducted from January to October 2014 involving 60 patients (homeopathy  n = 30; placebo  n = 30) who were suffering from acute painful episodes of knee osteoarthritis and visiting the outpatient clinic of Mahesh Bhattacharyya Homeopathic Medical College and Hospital  West Bengal  India. Statistically significant reduction was achieved in 3 visual analog scales (measuring pain  stiffness  and loss of function) and Osteoarthritis Research Society International scores in both groups over 2 weeks (P < .05); however  group differences were not significant (P > .05). Overall  homeopathy did not appear to be superior to placebo; still  further rigorous evaluation in this design involving a larger sample size seems feasible in future. Clinical Trials Registry  India (CTRI/2014/05/004589). Â© The Author(s) 2015.Bridges self-management program for people with stroke in the community: A feasibility randomized controlled trial.PubMedMcKenna  Suzanne; Jones  Fiona; Glenfield  Pauline; Lennon  Sheila2015-07-01Enabling self-management behaviors is considered important in order to develop coping strategies and confidence for managing life with a long-term condition. However  there is limited research into stroke-specific self-management interventions. The aim of this randomized controlled trial was to evaluate the feasibility of delivering the Bridges stroke self-management program in addition to usual stroke rehabilitation compared with usual rehabilitation only. Participants recruited from the referrals to a community stroke team were randomly allocated to the Bridges stroke self-management program  receiving either one session of up to one-hour per week over a six-week period in addition to usual stroke rehabilitation  or usual rehabilitation only. Feasibility was measured using a range of methods to determine recruitment and retention; adherence to the program; suitability and variability of outcome measures used; application and fidelity of the program; and acceptability of the program to patients  carers and professionals. Twenty-five people were recruited to the study over a 13-month period. Eight out of the 12 participants in the Bridges stroke self-management program received all six sessions; there was one withdrawal from the study. There were changes in outcomes between the two groups. Participants who received the Bridges stroke self-management program appeared to have a greater change in self-efficacy  functional activity  social integration and quality of life over the six-week intervention period and showed less decline in mood and quality of life at the three-month follow-up. Professionals found the program acceptable to use in practice  and feedback from participants was broadly positive. The findings from this study appear promising  but questions remain regarding the feasibility of delivering the Bridges stroke self-management program in addition to usual rehabilitation. The dose response of receiving the program cannot be ruled out  and the next stageResistance training as supportive measure in advanced cancer patients undergoing TKI therapy-a controlled feasibility trial.PubMedRosenberger  F; Wiskemann  J; Vallet  S; Haag  G M; Schembri  E; JÃ¤ger  D; GrÃ¼llich  C2017-12-01While there is growing evidence for positive effects of progressive resistance training in curatively treated cancer patients  data on advanced cancer patients are scarce. This pilot study aimed at investigating for the first time feasibility and effects of progressive resistance training in advanced cancer patients undergoing tyrosine kinase inhibitor (TKI) therapy. Patients starting a TKI-based anti-tumor therapy were assigned to a resistance training group (RT  12Â weeks of progressive machine-based resistance training 2Ã—/week) or a control group (CON  treatment as usual) until 10 patients had finished in each group (RT 80% males  90% renal cell carcinoma  65Â Â±Â 11Â years  CON 80% males  70% renal cell carcinoma  61Â Â±Â 6Â years). Primary endpoint was feasibility. Furthermore  fatigue (MFI)  quality of life (QoL  EORTC QLQC30)  and muscle strength were assessed. Testing occurred at baseline and after 12Â weeks. Training was feasible in 9 out of 10 participants and no serious adverse events occurred. It had beneficial effects on muscle strength (maximum voluntary isometric contraction of the quadriceps: RT +11Â Â±Â 9Â Nm  CON -13Â Â±Â 25Â Nm  pÂ =Â 0.005)  but not on fatigue (general fatigue score RT +0.3Â Â±Â 4.1  CON -1.5Â Â±Â 3.0  pÂ =Â 0.223) or QoL (global QoL score RT -5.6Â Â±Â 16.1  CON -2.0Â Â±Â 18.2  pÂ =Â 0.617). Progressive machine-based resistance training appears feasible in the majority of advanced cancer patients undergoing TKI therapy. However  its positive effects on muscle strength do not seem to be associated with positive effects on fatigue or quality of life. Future studies should therefore compare whether home-based training is more beneficial for patient-reported outcomes. NCT01645150.Feasibility Analysis of Moving Bank Multiple Model Adaptive Estimation and Control AlgorithmsDTIC Science & Technology1984-12-01REPRbOtUCED AT’G0VERPKMtNT;_CPWNSV’ C AA :’- 0 a ’i IT .3. :: .. (..â€¢ j :. -;-...   .... ... .. . . LLJâ€¢ D Â±nUTO STJ ~ N TIC â€¢â€¢â€¢   .TPÂ° DI.TEIIUTOnj...sliding’b tnk estimator/controller j .; compared to a bench- viii mark of a single Kalman filtIr/LQ controller that has (ar- -  tificial) knowledge of...the system under consideration be described by the following: x(tiÃ·1 ) )sâ€¢(ti+Ã· ti) j (ti) + Bd(ti)u(ti) Gd(ti)d(ti) 2( H(ti)x(ti) + (ti) where  lettingGlobal tobacco control and economic norms: an analysis of normative commitments in Kenya  Malawi and Zambia.PubMedLencucha  Raphael; Reddy  Srikanth K; Labonte  Ronald; Drope  Jeffrey; Magati  Peter; Goma  Fastone; Zulu  Richard; Makoka  Donald2018-04-01Tobacco control norms have gained momentum over the past decade. To date 43 of 47 Sub-Saharan African countries are party to the Framework Convention on Tobacco Control (FCTC). The near universal adoption of the FCTC illustrates the increasing strength of these norms  although the level of commitment to implement the provisions varies widely. However  tobacco control is enmeshed in a web of international norms that has bearing on how governments implement and strengthen tobacco control measures. Given that economic arguments in favor of tobacco production remain a prominent barrier to tobacco control efforts  there is a continued need to examine how economic sectors frame and mobilize their policy commitments to tobacco production. This study explores the proposition that divergence of international norms fosters policy divergence within governments. This study was conducted in three African countries: Kenya  Malawi  and Zambia. These countries represent a continuum of tobacco control policy  whereby Kenya is one of the most advanced countries in Africa in this respect  whereas Malawi is one of the few countries that is not a party to the FCTC and has implemented few measures. We conducted 55 key informant interviews (Zambiaâ€‰=â€‰23; Kenyaâ€‰=â€‰17; Malawiâ€‰=â€‰15). Data analysis involved deductive coding of interview transcripts and notes to identify reference to international norms (i.e. commitments  agreements  institutions)  coupled with an inductive analysis that sought to interpret the meaning participants ascribe to these norms. Our analysis suggests that commitments to tobacco control have yet to penetrate non-health sectors  who perceive tobacco control as largely in conflict with international economic norms. The reasons for this perceived conflict seems to include: (1) an entrenched and narrow conceptualization of economic development norms  (2) the power of economic interests to shape policy discourses  and (3) a structural divide between sectors inFeasibility and acceptability of training community health workers in ear and hearing care in Malawi: a cluster randomised controlled trial.PubMedMulwafu  Wakisa; Kuper  Hannah; Viste  Asgaut; Goplen  Frederik K2017-10-11To assess the feasibility and acceptability of training community health workers (CHWs) in ear and hearing care  and their ability to identify patients with ear and hearing disorders. Cluster randomised controlled trial (RCT). Health centres in Thyolo district  Malawi. Ten health centres participated  5 intervention (29 CHWs) and 5 control (28 CHWs). Intervention CHWs received 3 days of training in primary ear and hearing care  while among control CHWs  training was delayed for 6 months. Both groups were given a pretest that assessed knowledge about ear and hearing care  only the intervention group was given the posttest on the third day of training. The intervention group was given 1â€‰month to identify patients with ear and hearing disorders in their communities  and these people were screened for hearing disorders by ear  nose and throat clinical specialists. Primary outcome measure was improvement in knowledge of ear and hearing care among CHWs after the training. Secondary outcome measures were number of patients with ear or hearing disorders identified by CHWs and number recorded at health centres during routine activities  and the perceived feasibility and acceptability of the intervention. The average overall correct answers increased from 55% to 68% (95% CI 65 to 71) in the intervention group (p<0.001). A total of 1739 patients with potential ear and hearing disorders were identified by CHWs and 860 patients attended the screening camps  of whom 400 had hearing loss (73 patients determined through bilateral fail on otoacoustic emissions  327 patients through audiometry). Where cause could be determined  the most common cause of ear and hearing disorders was chronic suppurative otitis media followed by impacted wax. The intervention was perceived as feasible and acceptable to implement. Training was effective in improving the knowledge of CHW in ear and hearing care in Malawi and allowing them to identify patients with ear and hearing disorders. ThisThe Congress Should Control Federal Credit Programs to Promote Economic Stabilization.DTIC Science & Technology1981-10-21economic stability since 1960. The current rate of direct and guaranteed loan flows will exceed $70 billion annually in fiscal 1981. Recently  the Congress and the Administration have proposed a credit budget to limit the rapid growth of Federal credit. GAO demonstrates in this report that the best point of program control is the amount of the interest rate subsidy. Controlling subsidy levels rather than program activity levels would allocate credit efficiently and would  at the same time  lead to Federal credit flows that would contribute to the economic stabilizationCognitive Control and Individual Differences in Economic Ultimatum Decision-MakingPubMed CentralDe Neys  Wim; Novitskiy  Nikolay; Geeraerts  Leen; Ramautar  Jennifer; Wagemans  Johan2011-01-01Much publicity has been given to the fact that people's economic decisions often deviate from the rational predictions of standard economic models. In the classic ultimatum game  for example  most people turn down financial gains by rejecting unequal monetary splits. The present study points to neglected individual differences in this debate. After participants played the ultimatum game we tested for individual differences in cognitive control capacity of the most and least economic responders. The key finding was that people who were higher in cognitive control  as measured by behavioral (Go/No-Go performance) and neural (No-Go N2 amplitude) markers  did tend to behave more in line with the standard models and showed increased acceptance of unequal splits. Hence  the cognitively highest scoring decision-makers were more likely to maximize their monetary payoffs and adhere to the standard economic predictions. Findings question popular claims with respect to the rejection of standard economic models and the irrationality of human economic decision-making. PMID:22096522Implementing Randomised Control Trials in Open and Distance Learning: A Feasibility StudyERIC Educational Resources Information CenterHerodotou  Christothea; Heiser  Sarah; Rienties  Bart2017-01-01Randomised control trials (RCTs) are an evidence-based research approach which has not yet been adopted and widely used in open and distance education to inform educational policy and practice. Despite the challenges entailed in their application  RCTs hold the power to robustly evaluate the effects of educational interventions in distanceâ€¦Joint-Specific Play Controller for Upper Extremity Therapy: Feasibility Study in Children With Wrist ImpairmentPubMed CentralWilkins  Megan M.; Basseches  Benjamin; Schwartz  Joel B.; Kerman  Karen; Trask  Christine; Brideau  Holly; Crisco  Joseph J.2016-01-01Background Challenges with any therapeutic program for children include the level of the child's engagement or adherence. Capitalizing on one of the primary learning avenues of children  play  the approach described in this article is to develop therapeutic toy and game controllers that require specific and repetitive joint movements to trigger toy/game activation. Objective The goal of this study was to evaluate a specially designed wrist flexion and extension play controller in a cohort of children with upper extremity motor impairments (UEMIs). The aim was to understand the relationship among controller play activity  measures of wrist and forearm range of motion (ROM) and spasticity  and ratings of fun and difficulty. Design This was a cross-sectional study of 21 children (12 male  9 female; 4â€“12 years of age) with UEMIs. Methods All children participated in a structured in-clinic play session during which measurements of spasticity and ROM were collected. The children were fitted with the controller and played with 2 toys and 2 computer games for 5 minutes each. Wrist flexion and extension motion during play was recorded and analyzed. In addition  children rated the fun and difficulty of play. Results Flexion and extension goal movements were repeatedly achieved by children during the play session at an average frequency of 0.27 Hz. At this frequency  15 minutes of play per day would result in approximately 1 700 targeted joint motions per week. Play activity was associated with ROM measures  specifically supination  but toy perception ratings of enjoyment and difficulty were not correlated with clinical measures. Limitations The reported results may not be representative of children with more severe UEMIs. Conclusions These outcomes indicate that the therapeutic controllers elicited repetitive goal movements and were adaptable  enjoyable  and challenging for children of varying ages and UEMIs. PMID:27197824Joint-Specific Play Controller for Upper Extremity Therapy: Feasibility Study in Children With Wrist Impairment.PubMedWilcox  Bethany J; Wilkins  Megan M; Basseches  Benjamin; Schwartz  Joel B; Kerman  Karen; Trask  Christine; Brideau  Holly; Crisco  Joseph J2016-11-01Challenges with any therapeutic program for children include the level of the child's engagement or adherence. Capitalizing on one of the primary learning avenues of children  play  the approach described in this article is to develop therapeutic toy and game controllers that require specific and repetitive joint movements to trigger toy/game activation. The goal of this study was to evaluate a specially designed wrist flexion and extension play controller in a cohort of children with upper extremity motor impairments (UEMIs). The aim was to understand the relationship among controller play activity  measures of wrist and forearm range of motion (ROM) and spasticity  and ratings of fun and difficulty. This was a cross-sectional study of 21 children (12 male  9 female; 4-12 years of age) with UEMIs. All children participated in a structured in-clinic play session during which measurements of spasticity and ROM were collected. The children were fitted with the controller and played with 2 toys and 2 computer games for 5 minutes each. Wrist flexion and extension motion during play was recorded and analyzed. In addition  children rated the fun and difficulty of play. Flexion and extension goal movements were repeatedly achieved by children during the play session at an average frequency of 0.27 Hz. At this frequency  15 minutes of play per day would result in approximately 1 700 targeted joint motions per week. Play activity was associated with ROM measures  specifically supination  but toy perception ratings of enjoyment and difficulty were not correlated with clinical measures. The reported results may not be representative of children with more severe UEMIs. These outcomes indicate that the therapeutic controllers elicited repetitive goal movements and were adaptable  enjoyable  and challenging for children of varying ages and UEMIs. Â© 2016 American Physical Therapy Association.Economics of infection control surveillance technology: cost-effective or just cost?PubMedFuruno  Jon P; Schweizer  Marin L; McGregor  Jessina C; Perencevich  Eli N2008-04-01Previous studies have suggested that informatics tools  such as automated alert and decision support systems  may increase the efficiency and quality of infection control surveillance. However  little is known about the cost-effectiveness of these tools. We focus on 2 types of economic analyses that have utility in assessing infection control interventions (cost-effectiveness analysis and business-case analysis) and review the available literature on the economics of computerized infection control surveillance systems. Previous studies on the effectiveness of computerized infection control surveillance have been limited to assessments of whether these tools increase the sensitivity and specificity of surveillance over traditional methods. Furthermore  we identified only 2 studies that assessed the costs associated with computerized infection control surveillance. Thus  it remains unknown whether computerized infection control surveillance systems are cost-effective and whether use of these systems improves patient outcomes. The existing data are insufficient to allow for a summary conclusion on the cost-effectiveness of infection control surveillance technology. All future studies of computerized infection control surveillance systems should aim to collect outcomes and economic data to inform decision making and assist hospitals with completing business-cases analyses.Feasibility and benefits of laminar flow control on supersonic cruise airplanesNASA Technical Reports Server (NTRS)Powell  A. G.; Agrawal  S.; Lacey  T. R.1989-01-01An evaluation was made of the applicability and benefits of laminar flow control (LFC) technology to supersonic cruise airplanes. Ancillary objectives were to identify the technical issues critical to supersonic LFC application  and to determine how those issues can be addressed through flight and wind-tunnel testing. Vehicle types studied include a Mach 2.2 supersonic transport configuration  a Mach 4.0 transport  and two Mach 2-class fighter concepts. Laminar flow control methodologies developed for subsonic and transonic wing laminarization were extended and applied. No intractible aerodynamic problems were found in applying LFC to airplanes of the Mach 2 class  even ones of large size. Improvements of 12 to 17 percent in lift-drag ratios were found. Several key technical issues  such as contamination avoidance and excresence criteria were identified. Recommendations are made for their resolution. A need for an inverse supersonic wing design methodology is indicated.Feasibility of using piezoelectric actuators to control launch vehicle acoustics and structural vibrationsNASA Astrophysics Data System (ADS)Niezrecki  Christopher; Cudney  Harley H.2000-06-01Future launch vehicle payload fairings will be manufactured form advanced lightweight composite materials. The loss of distributed mass causes a significant increase in the internal acoustic environment  causing a severe threat to the payload. Using piezoelectric actuators to control the fairing vibration and the internal acoustic environment has been proposed. To help determine the acoustic control authority of piezoelectric actuators mounted on a rocket fairing  the internal acoustic response created by the actuators needs to be determined. In this work  the internal acoustic response of a closed simply-supported (SS) cylinder actuated by piezoelectric (PZT) actuators is determined using a n impedance model for the actuator and boundary element analysis. The experimentally validated model is used to extrapolate results for a SS cylinder that emulates a Minotaur payload fairing. The internal cylinder acoustic levels are investigated for PZT actuation between 35 and 400 Hz. Significant reductions in the structural response due to increased damping do not equate to similar reductions in the acoustic SPLs for the cylinder. The sound levels at the acoustic resonant frequencies are essentially unaffected by the significant increase in structural damping while the acoustic level sat the structural resonant frequencies are mildly reduced. The interior acoustic response of the cylinder is dominated by the acoustic modes and therefore significant reductions in the overall interior acoustic levels will not be achieved if only the structural resonances are controlled. As the actuation frequency is reduced  the number of actuators required to generate acoustic levels commensurate to that found in the fairing increases to impractical values. Below approximately 100 Hz  the current demands reach levels that are extremely difficult to achieve with a practical system. The results of this work imply that PZT actuators do not have the authority to control the payload fairingFeasibility of EMG-Based Control of Shoulder Muscle FNS Via Artificial Neural NetworkDTIC Science & Technology2001-10-25assuming that just two paralyzed muscles (pectoralis major and latissimus dorsi ) were stimulated. Further  the needed activations of these â€œstimulated...injuries at C5-C6 typically result in paralysis of several important shoulder muscles (e.g.  pectoralis major  latissimus dorsi   and serratus anterior...of several important muscles (e.g.  pectoralis major and latissimus dorsi ) but retain at least partial voluntary control over a number of otherImplementation of atomic layer etching of silicon: Scaling parameters  feasibility  and profile controlSciTech ConnectRanjan  Alok  E-mail: alok.ranjan@us.tel.com; Wang  Mingmei; Sherpa  Sonam D.2016-05-15Atomic or layer by layer etching of silicon exploits temporally segregated self-limiting adsorption and material removal steps to mitigate the problems associated with continuous or quasicontinuous (pulsed) plasma processes: selectivity loss  damage  and profile control. Successful implementation of atomic layer etching requires careful choice of the plasma parameters for adsorption and desorption steps. This paper illustrates how process parameters can be arrived at through basic scaling exercises  modeling and simulation  and fundamental experimental tests of their predictions. Using chlorine and argon plasma in a radial line slot antenna plasma source as a platform  the authors illustrate how cycle time  ionmoreÂ Â» energy  and radical to ion ratio can be manipulated to manage the deviation from ideality when cycle times are shortened or purges are incomplete. Cell based Monte Carlo feature scale modeling is used to illustrate profile outcomes. Experimental results of atomic layer etching processes are illustrated on silicon line and space structures such that iso-dense bias and aspect ratio dependent free profiles are produced. Experimental results also illustrate the profile control margin as processes move from atomic layer to multilayer by layer etching. The consequence of not controlling contamination (e.g.  oxygen) is shown to result in deposition and roughness generation.Â«Â lessA Design to Investigate the Feasibility and Effects of Partnered Ballroom Dancing on People With Parkinson Disease: Randomized Controlled Trial ProtocolPubMed CentralRoberts  Lisa; Pickering  Ruth; Roberts  Helen Clare; Wiles  Rose; Kunkel  Dorit; Hulbert  Sophia; Robison  Judy; Fitton  Carolyn2014-01-01Background Self-help and physical leisure activities has become increasingly important in the maintenance of safe and functional mobility among an increasingly elderly population. Preventing the cycle of deterioration  falling  inactivity  dependency  and secondary complications in people with Parkinson disease (PD) is a priority. Research has shown that people with PD are interested in dance and although the few existing trials are small  initial proof of principle trials from the United States have demonstrated beneficial effects on balance control  gait  and activity levels. To our knowledge  there has been no research into long-term effects  cost effectiveness  the influence on spinal posture and turning  or the personal insights of dance participants. Objective The purpose of this study was to determine the methodological feasibility of conducting a definitive phase III trial to evaluate the benefits of dance in people with PD. We will build on the proof of principle trials by addressing gaps in knowledge  focusing on areas of greatest methodological uncertainty; the choice of dances and intensity of the program; for the main trial  the availability of partners  the suitability of the currently envisaged primary outcomes  balance and spinal posture; and the key costs of delivering and participating in a dance program to inform economic evaluation. Methods Fifty participants (mild-to-moderate condition) will be randomized to the control (usual care) or experimental (dance plus usual care) groups at a ratio of 15:35. Dance will be taught by professional teachers in a dance center in the South of England. Each participant in the experimental group will dance with his or her spouse  a friend  or a partner from a bank of volunteers. A blinded assessor will complete clinical measures and self-reported ability at baseline  and at 3 and 6 months after randomization. A qualitative study of a subgroup of participants and partners will examine userâ€™s views about theAggression Following Traumatic brain injury: Effectiveness of Risperidone (AFTER): study protocol for a feasibility randomised controlled trial.PubMedDeb  Shoumitro; Leeson  Verity; Aimola  Lina; Bodani  Mayur; Li  Lucia; Weaver  Tim; Sharp  David; Crawford  Mike2018-06-21Traumatic brain injury (TBI) is a major public health concern and many people develop long-lasting physical and neuropsychiatric consequences following a TBI. Despite the emphasis on physical rehabilitation  it is the emotional and behavioural consequences that have greater impact on people with TBI and their families. One such problem behaviour is aggression which can be directed towards others  towards property or towards the self. Aggression is reported to be common after TBI (37-71%) and causes major stress for patients and their families. Both drug and non-drug interventions are used to manage this challenging behaviour  but the evidence-base for these interventions is poor and no drugs are currently licensed for the treatment of aggression following TBI. The most commonly used drugs for this purpose are antipsychotics  particularly second-generation drugs such as risperidone. Despite this widespread use  randomised controlled trials (RCTs) of antipsychotic drugs  including risperidone  have not been conducted. We have  therefore  set out to test the feasibility of conducting an RCT of this drug for people who have aggressive behaviour following TBI. We will examine the feasibility of conducting a placebo-controlled  double-blind RCT of risperidone for the management of aggression in adults with TBI and also assess participants' views about their experience of taking part in the study. We will randomise 50 TBI patients from secondary care services in four centres in London and Kent to up to 4Â mg of risperidone orally or an inert placebo and follow them up 12Â weeks later. Participants will be randomised to active or control treatment in a 1:1 ratio via an external and remote web-based randomisation service. Participants will be assessed at baseline and 12-week follow-up using a battery of assessment scales to measure changes in aggressive behaviour (MOAS  IRQ) as well as global functioning (GOS-E  CGI)  quality of life (EQ-5D-5L  SF-12) and mental healthAquatic therapy for children with Duchenne muscular dystrophy: a pilot feasibility randomised controlled trial and mixed-methods process evaluation.PubMedHind  Daniel; Parkin  James; Whitworth  Victoria; Rex  Saleema; Young  Tracey; Hampson  Lisa; Sheehan  Jennie; Maguire  Chin; Cantrill  Hannah; Scott  Elaine; Epps  Heather; Main  Marion; Geary  Michelle; McMurchie  Heather; Pallant  Lindsey; Woods  Daniel; Freeman  Jennifer; Lee  Ellen; Eagle  Michelle; Willis  Tracey; Muntoni  Francesco; Baxter  Peter2017-05-01 (30% of target) were randomised to AT ( n â€‰=â€‰8) or control ( n â€‰=â€‰4). People in the AT ( n â€‰=â€‰8) and control ( n â€‰=â€‰2: attrition because of parental report) arms contributed outcome data. The mean change in NSAA score at 6 months was -5.5 [standard deviation (SD) 7.8] for LBT and -2.8 (SD 4.1) in the AT arm. One boy suffered pain and fatigue after AT  which resolved the same day. Physiotherapists and parents valued AT and believed that it should be delivered in community settings. The independent rater considered AT optimised for three out of eight children  with other children given programmes that were too extensive and insufficiently focused. The estimated NHS costs of 6-month service were between Â£1970 and Â£2734 per patient. The focus on delivery in hospitals limits generalisability. Neither a full-scale frequentist randomised controlled trial (RCT) recruiting in the UK alone nor a twice-weekly open-ended AT course delivered at tertiary centres is feasible. Further intervention development research is needed to identify how community-based pools can be accessed  and how families can link with each other and community physiotherapists to access tailored AT programmes guided by highly specialised physiotherapists. Bayesian RCTs may be feasible; otherwise  time series designs are recommended. Current Controlled Trials ISRCTN41002956. This project was funded by the National Institute for Health Research (NIHR) Health Technology Assessment programme and will be published in full in Health Technology Assessment ; Vol. 21  No. 27. See the NIHR Journals Library website for further project information.Hospital at Home care for older patients with cognitive impairment: a protocol for a randomised controlled feasibility trial.PubMedPouw  Maaike A; Calf  Agneta H; van Munster  Barbara C; Ter Maaten  Jan C; Smidt  Nynke; de Rooij  Sophia E2018-03-27An acute hospital admission is a stressful life event for older people  particularly for those with cognitive impairment. The hospitalisation is often complicated by hospital-associated geriatric syndromes  including delirium and functional loss  leading to functional decline and nursing home admission. Hospital at Home care aims to avoid hospitalisation-associated adverse outcomes in older patients with cognitive impairment by providing hospital care in the patient's own environment. This randomised  non-blinded feasibility trial aims to assess the feasibility of conducting a randomised controlled trial in terms of the recruitment  use and acceptability of Hospital at Home care for older patients with cognitive impairment. The quality of care will be evaluated and the advantages and disadvantages of the Hospital at Home care programme compared with usual hospital care. Eligible patients will be randomised either to Hospital at Home care in their own environment or usual hospital care. The intervention consists of hospital level care provided at patients' homes  including visits from healthcare professionals  diagnostics (laboratory tests  blood cultures) and treatment. The control group will receive usual hospital care. Measurements will be conducted at baseline  during admission  at discharge and at 3 and 6â€‰months after the baseline assessment. Institutional ethics approval has been granted. The findings will be disseminated through public lectures  professional and scientific conferences  as well as peer-reviewed journal articles. The study findings will contribute to knowledge on the implementation of Hospital at Home care for older patients with cognitive disorders. The results will be used to inform and support strategies to deliver eligible care to older patients with cognitive impairment. e020313; Pre-results. Â© Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2018. All rights reserved. No commercial use isFeasibility of personalised remote long-term follow-up of people with cochlear implants: a randomised controlled trial.PubMedCullington  Helen; Kitterick  Padraig; Weal  Mark; Margol-Gromada  Magdalena2018-04-20Substantial resources are required to provide lifelong postoperative care to people with cochlear implants. Most patients visit the clinic annually. We introduced a person-centred remote follow-up pathway  giving patients telemedicine tools to use at home so they would only visit the centre when intervention was required. To assess the feasibility of comparing a remote care pathway with the standard pathway in adults using cochlear implants. Two-arm randomised controlled trial. Randomisation used a minimisation approach  controlling for potential confounding factors. Participant blinding was not possible  but baseline measures occurred before allocation. University of Southampton Auditory Implant Service: provider of National Health Service care. 60 adults who had used cochlear implants for at least 6 months. Control group (n=30) followed usual care pathway.Remote care group (n=30) received care remotely for 6 months incorporating: home hearing in noise test  online support tool and self-adjustment of device (only 10 had compatible equipment). Primary: change in patient activation; measured using the Patient Activation Measure.Secondary: change in hearing and quality of life; qualitative feedback from patients and clinicians. One participant in the remote care group dropped out. The remote care group showed a greater increase in patient activation than the control group. Changes in hearing differed between the groups. The remote care group improved on the Triple Digit Test hearing test; the control group perceived their hearing was worse on the Speech  Spatial and Qualities of Hearing Scale questionnaire. Quality of life remained unchanged in both groups. Patients and clinicians were generally positive about remote care tools and wanted to continue. Adults with cochlear implants were willing to be randomised and complied with the protocol. Personalised remote care for long-term follow-up is feasible and acceptable  leading to more empowered patients. ISRCTN14644286Force Myography to Control Robotic Upper Extremity Prostheses: A Feasibility StudyPubMed CentralCho  Erina; Chen  Richard; Merhi  Lukas-Karim; Xiao  Zhen; Pousett  Brittany; Menon  Carlo2016-01-01Advancement in assistive technology has led to the commercial availability of multi-dexterous robotic prostheses for the upper extremity. The relatively low performance of the currently used techniques to detect the intention of the user to control such advanced robotic prostheses  however  limits their use. This article explores the use of force myography (FMG) as a potential alternative to the well-established surface electromyography. Specifically  the use of FMG to control different grips of a commercially available robotic hand  Bebionic3  is investigated. Four male transradially amputated subjects participated in the study  and a protocol was developed to assess the prediction accuracy of 11 grips. Different combinations of grips were examined  ranging from 6 up to 11 grips. The results indicate that it is possible to classify six primary grips important in activities of daily living using FMG with an accuracy of above 70% in the residual limb. Additional strategies to increase classification accuracy  such as using the available modes on the Bebionic3  allowed results to improve up to 88.83 and 89.00% for opposed thumb and non-opposed thumb modes  respectively. PMID:27014682Feasibility and Acceptability of a Web-Based Treatment with Telephone Support for Postpartum Women With Anxiety: Randomized Controlled Trial.PubMedAshford  Miriam T; Olander  Ellinor K; Rowe  Heather; Fisher  Jane Rw; Ayers  Susan2018-04-20Postpartum anxiety can have adverse effects on the mother and child if left untreated. Time constraints and stigma are common barriers to postpartum treatment. Web-based treatments offer potential flexibility and anonymity. What Am I Worried About (WaWa) is a self-guided treatment based on cognitive-behavioral and mindfulness principles for women experiencing postpartum anxiety. WaWa was developed in Australia and consists of 9 modules with optional weekly telephone support. WaWa was adapted to a Web-based version for use in England (Internet-based What Am I Worried About  iWaWa). This study aimed to investigate the feasibility (engagement and usability) and acceptability (usefulness  satisfaction  and helpfulness) of iWaWa among English postpartum women with anxiety. Postpartum (<12 months) women with mild-to-severe anxiety were recruited anonymously via social media during an 8-week period. Participants were randomized to the iWaWa treatment (8 weeks) or wait-list control group. Treatment and study feasibility and acceptability were assessed after the treatment  and anxiety symptoms were assessed at baseline  8 weeks postrandomization  and 12 weeks postrandomization (treatment group only) using Web-based questionnaires. Semistructured telephone interviews were carried out after the treatment period for a more in-depth exploration of treatment acceptability and feasibility. A total of 89 eligible women were recruited through social media and randomized into the treatment (n=46) or wait-list control group (n=43). Women were predominantly Caucasian  well-educated  married  on maternity leave  first-time mothers and reported moderate levels of anxiety. Dropout rates were high  especially in the treatment group (treatment: 82%  38/46; wait-list control: 51%  22/43). A total of 26 women started iWaWa with only 2 women completing all 9 modules. Quantitative and qualitative data suggest iWaWa was experienced as generally useful and helpful. Participants enjoyed iA Study of Economical Incentives for Voltage Profile Control Method in Future Distribution NetworkNASA Astrophysics Data System (ADS)Tsuji  Takao; Sato  Noriyuki; Hashiguchi  Takuhei; Goda  Tadahiro; Tange  Seiji; Nomura  ToshioIn a future distribution network  it is difficult to maintain system voltage because a large number of distributed generators are introduced to the system. The authors have proposed â€œvoltage profile control methodâ€ using power factor control of distributed generators in the previous work. However  the economical disbenefit is caused by the active power decrease when the power factor is controlled in order to increase the reactive power. Therefore  proper incentives must be given to the customers that corporate to the voltage profile control method. Thus  in this paper  we develop a new rules which can decide the economical incentives to the customers. The method is tested in one feeder distribution network model and its effectiveness is shown.Feasibility and efficacy of wearable devices for upper limb rehabilitation in patients with chronic stroke: a randomized controlled pilot study.PubMedLin  Li-Fong; Lin  Yi-Jia; Lin  Zi-Hao; Chuang  Li-Yun; Hsu  Wei-Chun; Lin  Yuan-Hsiang2017-06-19Wearable devices based on inertial measurement units through wireless sensor networks have many applications such as real-time motion monitoring and functional outcome assessment of stroke rehabilitation. However  additional investigations are warranted to validate their clinical value  particularly in detecting the synergy patterns of movements after stroke. To explore the feasibility and efficacy of wearable devices for upper limb rehabilitation in patients with chronic stroke and to compare the intervention effects (e.g.  neurological recovery  active range of motion  and deviation angle) with those in a control group. A single-blind  randomized-controlled pilot study. Rehabilitation ward. A total of 18 patients with chronic stroke were randomly distributed into a device group and control group. Both groups received conventional rehabilitation; nevertheless  the device group was additionally subjected to 15 daily sessions at least three times a week for 5 weeks. The outcome measures included the upper extremity subscores of the Fugl-Meyer assessment  active range of motion  and deviation angle. These measurements were performed pre- and post-treatment. All five Fugl-Meyer assessment subscores improved in both the device and control groups after intervention; in particular  the ""shoulder/elbow/forearm"" subscore (p = 0.02  0.03) and ""total score"" (p = 0.03  0.03) substantially improved. The active range of motion of shoulder flexion and abduction substantially improved at pre-post treatment in both the device (p = 0.02  0.03) and control (p = 0.02  0.03) groups. The deviation angle of shoulder external rotation during shoulder abduction substantially improved in the device group (p = 0.02)  but not in the control group. The designed wearable devices are practical and efficient for use in chronic patients with stroke. Wearable devices are expected to be useful for future internet-of-things rehabilitation clinical trials at home and in long-term care institutions.Randomized Controlled Trial of Teaching Methods: Do Classroom Experiments Improve Economic Education in High Schools?ERIC Educational Resources Information CenterEisenkopf  Gerald; Sulser  Pascal A.2016-01-01The authors present results from a comprehensive field experiment at Swiss high schools in which they compare the effectiveness of teaching methods in economics. They randomly assigned classes into an experimental and a conventional teaching group  or a control group that received no specific instruction. Both teaching treatments improve economicâ€¦Biological control of aflatoxin is effective and economical in Mississippi field trialsUSDA-ARS?s Scientific Manuscript databaseAflatoxin contamination of corn is a major grain quality issue and can be a major economic limiting factor to Mississippi corn farmers. Biological control products based on aflatoxin non-producing strains of Aspergillus flavus are commercially available to prevent the contamination of corn with afl...Feasibility of a feedback control of atomic self-organization in an optical cavitySciTech ConnectIvanov  D. A.  E-mail: ivanov-den@yandex.ru; Ivanova  T. Yu.Many interesting nonlinear effects are based on the strong interaction of motional degrees of freedom of atoms with an optical cavity field. Among them is the spatial self-organization of atoms in a pattern where the atoms group in either odd or even sites of the cavity-induced optical potential. An experimental observation of this effect can be simplified by using  along with the original cavity-induced feedback  an additional electronic feedback based on the detection of light leaking the cavity and the control of the optical potential for the atoms. Following our previous study  we show that this approach is more efficientmoreÂ Â» from the laser power perspective than the original scheme without the electronic feedback.Â«Â lessStochastic road excitation and control feasibility in a 2D linear tyre modelNASA Astrophysics Data System (ADS)Rustighi  E.; Elliott  S. J.2007-03-01For vehicle under normal driving conditions and speeds above 30-40 km/h the dominating internal and external noise source is the sound generated by the interaction between the tyre and the road. This paper presents a simple model to predict tyre behaviour in the frequency range up to 400 Hz  where the dominant vibration is two dimensional. The tyre is modelled as an elemental system  which permits the analysis of the low-frequency tyre response when excited by distributed stochastic displacements in the contact patch. A linear model has been used to calculate the contact forces from the road roughness and thus calculate the average spectral properties of the resulting radial velocity of the tyre in one step from the spectral properties of the road roughness. Such a model has also been used to provide an estimate of the potential effect of various active control strategies for reducing the tyre vibrations.Job retention vocational rehabilitation for employed people with inflammatory arthritis (WORK-IA): a feasibility randomized controlled trial.PubMedHammond  Alison; O'Brien  Rachel; Woodbridge  Sarah; Bradshaw  Lucy; Prior  Yeliz; Radford  Kate; Culley  June; Whitham  Diane; Ruth Pulikottil-Jacob2017-07-21Inflammatory arthritis leads to work disability  absenteeism and presenteeism (i.e. at-work productivity loss) at high cost to individuals  employers and society. A trial of job retention vocational rehabilitation (VR) in the United States identified this helped people keep working. The effectiveness of this VR in countries with different socioeconomic policies and conditions  and its impact on absenteeism  presenteeism and health  are unknown. This feasibility study tested the acceptability of this VR  modified for the United Kingdom  compared to written advice about managing work problems. To help plan a randomized controlled trial  we tested screening  recruitment  intervention delivery  response rates  applicability of the control intervention and identified the relevant primary outcome. A feasibility randomized controlled trial with rheumatoid  psoriatic or inflammatory arthritis patients randomized to receive either job retention VR or written information only (the WORK-IA trial). Following three days VR training  rheumatology occupational therapists provided individualised VR on a one to one basis. VR included work assessment  activity diaries and action planning  and (as applicable) arthritis self-management in the workplace  ergonomics  fatigue and stress management  orthoses  employment rights and support services  assistive technology  work modifications  psychological and disclosure support  workplace visits and employer liaison. Fifty five (10%) people were recruited from 539 screened. Follow-up response rates were acceptable at 80%. VR was delivered with fidelity. VR was more acceptable than written advice only (7.8 versus 6.7). VR took on average 4Â h at a cost of Â£135 per person. Outcome assessment indicated VR was better than written advice in reducing presenteeism (Work Limitations Questionnaire (WLQ) change score mean: VRÂ =Â -12.4 (SD 13.2); controlÂ =Â -2.5 (SD 15.9)  absenteeism  perceived risk of job loss and improving pain and health statusFeasibility study of using statistical process control to customized quality assurance in proton therapySciTech ConnectRah  Jeong-Eun; Oh  Do Hoon; Shin  DonghoPurpose: To evaluate and improve the reliability of proton quality assurance (QA) processes and  to provide an optimal customized tolerance level using the statistical process control (SPC) methodology. Methods: The authors investigated the consistency check of dose per monitor unit (D/MU) and range in proton beams to see whether it was within the tolerance level of the daily QA process. This study analyzed the difference between the measured and calculated ranges along the central axis to improve the patient-specific QA process in proton beams by using process capability indices. Results: The authors established a customized tolerance level of Â±2% formoreÂ Â» D/MU and Â±0.5 mm for beam range in the daily proton QA process. In the authorsâ€™ analysis of the process capability indices  the patient-specific range measurements were capable of a specification limit of Â±2% in clinical plans. Conclusions: SPC methodology is a useful tool for customizing the optimal QA tolerance levels and improving the quality of proton machine maintenance  treatment delivery  and ultimately patient safety.Â«Â lessImmune Checkpoints in Leprosy: Immunotherapy As a Feasible Approach to Control Disease Progression.PubMedLima  Hayana Ramos; Gasparoto  ThaÃ­s Helena; de Souza Malaspina  Tatiana Salles; Marques  VinÃ­cius Rizzo; Vicente  Marina Jurado; Marcos  Elaine Camarinha; Souza  Fabiana Corvolo; Nogueira  Maria Renata Sales; Barreto  Jaison AntÃ´nio; Garlet  Gustavo Pompermaier; da Silva  JoÃ£o Santana; Brito-de-Souza  VÃ¢nia Nieto; Campanelli  Ana Paula2017-01-01Leprosy remains a health problem in several countries. Current management of patients with leprosy is complex and requires multidrug therapy. Nonetheless  antibiotic treatment is insufficient to prevent nerve disabilities and control Mycobacterium leprae . Successful infectious disease treatment demands an understanding of the host immune response against a pathogen. Immune-based therapy is an effective treatment option for malignancies and infectious diseases. A promising therapeutic approach to improve the clinical outcome of malignancies is the blockade of immune checkpoints. Immune checkpoints refer to a wide range of inhibitory or regulatory pathways that are critical for maintaining self-tolerance and modulating the immune response. Programmed cell-death protein-1 (PD-1)  programmed cell death ligand-1 (PD-L1)  cytotoxic T-lymphocyte-associated protein 4  and lymphocyte-activation gene-3 are the most important immune checkpoint molecules. Several pathogens  including M. leprae   are supposed to utilize these mechanisms to evade the host immune response. Regulatory T cells and expression of co-inhibitory molecules on lymphocytes induce specific T-cell anergy/exhaustion  leading to disseminated and progressive disease. From this perspective  we outline how the co-inhibitory molecules PD-1  PD-L1  and Th1/Th17 versus Th2/Treg cells are balanced  how antigen-presenting cell maturation acts at different levels to inhibit T cells and modulate the development of leprosy  and how new interventions interfere with leprosy development.Feasibility study of using statistical process control to customized quality assurance in proton therapy.PubMedRah  Jeong-Eun; Shin  Dongho; Oh  Do Hoon; Kim  Tae Hyun; Kim  Gwe-Ya2014-09-01To evaluate and improve the reliability of proton quality assurance (QA) processes and  to provide an optimal customized tolerance level using the statistical process control (SPC) methodology. The authors investigated the consistency check of dose per monitor unit (D/MU) and range in proton beams to see whether it was within the tolerance level of the daily QA process. This study analyzed the difference between the measured and calculated ranges along the central axis to improve the patient-specific QA process in proton beams by using process capability indices. The authors established a customized tolerance level of Â±2% for D/MU and Â±0.5 mm for beam range in the daily proton QA process. In the authors' analysis of the process capability indices  the patient-specific range measurements were capable of a specification limit of Â±2% in clinical plans. SPC methodology is a useful tool for customizing the optimal QA tolerance levels and improving the quality of proton machine maintenance  treatment delivery  and ultimately patient safety.Feasibility and effectiveness of the baby friendly community initiative in rural Kenya: study protocol for a randomized controlled trial.PubMedKimani-Murage  Elizabeth W; Kimiywe  Judith; Kabue  Mark; Wekesah  Frederick; Matiri  Evelyn; Muhia  Nelson; Wanjohi  Milka; Muriuki  Peterrock; Samburu  Betty; Kanyuira  James N; Young  Sera L; Griffiths  Paula L; Madise  Nyovani J; McGarvey  Stephen T2015-09-28Interventions promoting optimal infant and young child nutrition could prevent a fifth of under-5 deaths in countries with high mortality. Poor infant and young child feeding practices are widely documented in Kenya  with potential detrimental effects on child growth  health and survival. Effective strategies to improve these practices are needed. This study aims to pilot implementation of the Baby Friendly Community Initiative (BFCI)  a global initiative aimed at promoting optimal infant and young child feeding practices  to determine its feasibility and effectiveness with regards to infant feeding practices  nutrition and health outcomes in a rural setting in Kenya. The study  employing a cluster-randomized trial design  will be conducted in rural Kenya. A total of 12 clusters  constituting community units within the government's Community Health Strategy  will be randomized  with half allocated to the intervention and the other half to the control arm. A total of 812 pregnant women and their respective children will be recruited into the study. The mother-child pairs will be followed up until the child is 6 months old. Recruitment will last approximately 1 year from January 2015  and the study will run for 3 years  from 2014 to 2016. The intervention will involve regular counseling and support of mothers by trained community health workers and health professionals on maternal  infant and young child nutrition. Regular assessment of knowledge  attitudes and practices on maternal  infant and young child nutrition will be done  coupled with assessment of nutritional status of the mother-child pairs and morbidity for the children. Statistical methods will include analysis of covariance  multinomial logistic regression and multilevel modeling. The study is funded by the NIH and USAID through the Program for Enhanced Research (PEER) Health. Findings from the study outlined in this protocol will inform potential feasibility and effectiveness of a communityIllness Management & Recovery (IMR) in the Netherlands; a naturalistic pilot study to explore the feasibility of a randomized controlled trial.PubMedRoosenschoon  Bert-Jan; van Weeghel  Jaap; Bogaards  Moniek; Deen  Mathijs L; Mulder  Cornelis L2016-11-09Illness Management & Recovery (IMR) is a curriculum-based program for people with severe and persistent mental illness. To date  four randomized controlled trials (RCTs) have been published on it. As these produced mixed results  we conducted a pilot study to test the feasibility of conducting a new RCT in a Dutch psychiatric institute. Because our primary objective was to evaluate support for implementing IMR on a broader scale  we examined participant recruitment  client outcomes  and clients' and clinicians' satisfaction. Secondary objectives were to evaluate fidelity  trainers' training and supervision  and to explore program duration  dropout  and client characteristics related to dropout. For reporting  we used the checklist for pilot studies adopted from the CONSORT Statement. This program evaluation included a process-evaluation and an outcome evaluation with a One Group Pre-Posttest Design (Nâ€‰=â€‰81). Interviews and internal reports were used to monitor participant numbers  program duration  dropout  and completers' characteristics. Clients' and clinicians' satisfaction and provision of trainers' training and supervision were assessed through interviews. Fidelity was assessed on the IMR Fidelity Scale; client outcomes were assessed on the IMR scale (client and clinician versions) and the Recovery Markers Questionnaire (RMQ). Eighty-one participants were recruited of 167 people who were assessed for eligibility. Completers and clinicians were satisfied  and scores for completers improved significantly on the IMR scale (clinician version) (dâ€‰=â€‰0.84) and RMQ (dâ€‰=â€‰0.52)  and not significantly on the IMR scale client version (dâ€‰=â€‰0.41). Mean fidelity was good  but three groups had only moderate fidelity. Our feasibility criterion for trainers' education and supervision was partly attained. Dropout from treatment was 51Â %; female participants and people who scored higher on both IMR-scales at baseline had a significantly lower chance of droppingFeasibility and effects of preventive home visits for at-risk older people: design of a randomized controlled trial.PubMedCutchin  Malcolm P; Coppola  Susan; Talley  Vibeke; Svihula  Judie; Catellier  Diane; Shank  Kendra Heatwole2009-12-03The search for preventive methods to mitigate functional decline and unwanted relocation by older adults living in the community is important. Preventive home visit (PHV) models use infrequent but regular visits to older adults by trained practitioners with the goal of maintaining function and quality of life. Evidence about PHV efficacy is mixed but generally supportive. Yet interventions have rarely combined a comprehensive (biopsychosocial) occupational therapy intervention protocol with a home visit to older adults. There is a particular need in the USA to create and examine such a protocol. The study is a single-blind randomized controlled pilot trial designed to assess the feasibility  and to obtain preliminary efficacy estimates  of an intervention consisting of preventive home visits to community-dwelling older adults. An occupational therapy-based preventive home visit (PHV) intervention was developed and is being implemented and evaluated using a repeated measures design. We recruited a sample of 110 from a population of older adults (75+) who were screened and found to be at-risk for functional decline. Participants are currently living in the community (not in assisted living or a skilled nursing facility) in one of three central North Carolina counties. After consent  participants were randomly assigned into experimental and comparison groups. The experimental group receives the intervention 4 times over a 12 month follow-up period while the comparison group receives a minimal intervention of mailed printed materials. Pre- and post-intervention measures are being gathered by questionnaires administered face-to-face by a treatment-blinded research associate. Key outcome measures include functional ability  participation  life satisfaction  self-rated health  and depression. Additional information is collected from participants in the experimental group during the intervention to assess the feasibility of the intervention and potential modifiersInvestigating the feasibility of temperature-controlled accelerated drug release testing for an intravaginal ring.PubMedExternbrink  Anna; Clark  Meredith R; Friend  David R; Klein  Sandra2013-11-01The objective of the present study was to investigate if temperature can be utilized to accelerate drug release from NuvaringÂ®  a reservoir type intravaginal ring based on polyethylene vinyl acetate copolymer that releases a constant dose of contraceptive steroids over a duration of 3 weeks. The reciprocating holder apparatus (USP 7) was utilized to determine real-time and accelerated etonogestrel release from ring segments. It was demonstrated that drug release increased with increasing temperature which can be attributed to enhanced drug diffusion. An Arrhenius relationship of the zero-order release constants was established  indicating that temperature is a valid parameter to accelerate drug release from this dosage form and that the release mechanism is maintained under these accelerated test conditions. Accelerated release tests are particularly useful for routine quality control to assist during batch release of extended release formulations that typically release the active over several weeks  months or even years  since they can increase the product shelf life. The accelerated method should therefore be able to discriminate between formulations with different release characteristics that can result from normal manufacturing variance. In the case of NuvaringÂ®  it is well known that the process parameters during the extrusion process strongly influence the polymeric structure. These changes in the polymeric structure can affect the permeability which  in turn  is reflected in the release properties. Results from this study indicate that changes in the polymeric structure can lead to a different temperature dependence of the release rate  and as a consequence  the accelerated method can become less sensitive to detect changes in the release properties. When the accelerated method is utilized during batch release  it is therefore important to take this possible restriction into account and to evaluate the accelerated method with samples from nonChallenges associated with recruiting multigenerational  multicultural families into a randomised controlled trial: Balancing feasibility with validity.PubMedHughes  Donna; Hutchinson  Amanda; Prichard  Ivanka; Chapman  Janine; Wilson  Carlene2015-07-01Recruitment of participants into research studies has become an increasingly difficult task with justifiable criticisms of representativeness of samples. The difficulties of recruitment are exacerbated when the study is longitudinal  requires multiple members from one family and incorporates people from non-dominant ethnic backgrounds. This paper describes a complex trial's recruitment process. Family groups were required for a longitudinal randomised controlled trial investigating links between health and dietary behaviours with an aim to improve primary prevention health messages and initiatives. To be representative of the multi-ethnic composition of the South Australian population  families from three of South Australia's largest ethnic backgrounds were invited to participate. Of these  only families with participating members spanning three generations were enrolled  so that links between health and lifestyle behaviours with possible generational ties could be investigated. Immense difficulties were faced during recruitment and significant modifications to the initial recruitment plan were necessary to enable the enrolment of 96 families. Challenges faced included lack of response to recruitment materials displaying complex eligibility criteria and different response outcomes from different communities. Solutions implemented included simplifying materials and tailoring recruitment activities to specific communities' needs. This trial's recruitment journey will be used as a case study to highlight the practicalities of recruiting for complex trials. Recommendations will be provided for future researchers seeking to recruit multigenerational  multi-ethnic families into the same study  along with issues to consider regarding the implications of the recruitment journey on the integrity of a complex trial and the potential threats to internal validity. Copyright Â© 2015 Elsevier Inc. All rights reserved.Feasibility study for epidemic prevention and control in a regional hospital.PubMedChen  Yung-Liang; Yeh  Ming-Yang; Huang  Shau-Yen; Liu  Chi-Ming; Sun  Chi-Chen; Lu  Hsu-Feng; Chiu  Tsan-Hung; Hsia  Te-Chun; Chung  Jing-Gung2012-03-01Epidemic prevention policies in hospitals address issues such as  indoor air quality control  cleanliness of medical staff clothing and employee hand-washing procedures. Our hospital employed Bio-Kil to treat air-conditioning filters and nursing staff uniforms. We also assessed the efficacy of different detergents. Using Bio-Kil technology  the mean bacterial count in the air was reduced from 108.8 CFU/h/plate (n=420) to 68.6 CFU/h/plate (n=630). On the lower hems of the Bio-Kil-treated gowns  the mean bacterial count was 1 201 CFU/100 cm(2)  markedly lower than the bacterial count of 7 753 CFU/100 cm(2)  found on the parts of the gowns not treated with Bio-Kil (p=0.0401). On the cuffs of sleeves treated with Bio-Kil  the mean count was 1 165 CFU/100 cm(2)  markedly lower than that of 2 131 CFU/100 cm(2)  found on the cuffs not treated with Bio-Kil (p=0.0073). With regard to the mean bacterial eradication rates of antimicrobial solutions  Steridal Solution  75% alcohol and Bio-Kil (3rd generation) were shown to be the most effective  with rates exceeding 80%. Hibiscrub with paper towels and Fresh Protect Skin were the second most effective. Bio-Kil (1st generation)  tap water with paper towels  liquid hand soap with paper towels and ozone water were the least effective. One important observation was that hand-washing without the use of paper towels increased the bacterial count by as much as 84% . Bio-Kil is effective in reducing bacterial counts in the air  on nursing staff uniforms and is an effective detergent.Semi-Individualized Homeopathy Add-On Versus Usual Care Only for Premenstrual Disorders: A Randomized  Controlled Feasibility Study.PubMedKlein-Laansma  Christien T; Jong  Mats; von Hagens  Cornelia; Jansen  Jean Pierre C H; van Wietmarschen  Herman; Jong  Miek C2018-03-22Premenstrual syndrome and premenstrual dysphoric disorder (PMS/PMDD) bother a substantial number of women. Homeopathy seems a promising treatment  but it needs investigation using reliable study designs. The feasibility of organizing an international randomized pragmatic trial on a homeopathic add-on treatment (usual care [UC] + HT) compared with UC alone was evaluated. A multicenter  randomized  controlled pragmatic trial with parallel groups. The study was organized in general and private homeopathic practices in the Netherlands and Sweden and in an outpatient university clinic in Germany. Women diagnosed as having PMS/PMDD  based on prospective daily rating by the daily record of severity of problems (DRSP) during a period of 2 months  were included and randomized. Women were to receive UC + HT or UC for 4 months. Homeopathic medicine selection was according to a previously tested prognostic questionnaire and electronic algorithm. Usual care was as provided by the women's general practitioner according to their preferences. Before and after treatment  the women completed diaries (DRSP)  the measure yourself concerns and well-being  and other questionnaires. Intention-to-treat (ITT) and per protocol (PP) analyses were performed. In Germany  the study could not proceed because of legal limitations. In Sweden  recruitment proved extremely difficult. In the Netherlands and Sweden  60 women were randomized (UC + HT: 28; UC: 32)  data of 47/46 women were analyzed (ITT/PP). After 4 months  relative mean change of DRSP scores in the UC + HT group was significantly better than in the UC group (pâ€‰=â€‰0.03). With respect to recruitment and different legal status  it does not seem feasible to perform a larger  international  pragmatic randomized trial on (semi-)individualized homeopathy for PMS/PMDD. Since the added value of HT compared with UC was demonstrated by significant differences in symptom score changes  further studies are warranted.Promoting Physical Activity in Low-Active Adolescents via Facebook: A Pilot Randomized Controlled Trial to Test Feasibility.PubMedWÃ³jcicki  Thomas R; Grigsby-Toussaint  Diana; Hillman  Charles H; Huhman  Marian; McAuley  Edward2014-10-30The World Wide Web is an effective method for delivering health behavior programs  yet major limitations remain (eg  cost of development  time and resource requirements  limited interactivity). Social media  however  has the potential to deliver highly customizable and socially interactive behavioral interventions with fewer constraints. Thus  the evaluation of social media as a means to influence health behaviors is warranted. The objective of this trial was to examine and demonstrate the feasibility of using an established social networking platform (ie  Facebook) to deliver an 8 week physical activity intervention to a sample of low-active adolescents (N=21; estimated marginal mean age 13.48 years). Participants were randomized to either an experimental (ie  Behavioral) or attentional control (ie  Informational) condition. Both conditions received access to a restricted-access  study-specific Facebook group where the group's administrator made two daily wall posts containing youth-based physical activity information and resources. Primary outcomes included physical activity as assessed by accelerometry and self-report. Interactions and main effects were examined  as well as mean differences in effect sizes. Analyses revealed significant improvements over time on subjectively reported weekly leisure-time physical activity (F1 18=8.426  P=.009  Î·2 = .319). However  there was no interaction between time and condition (F1 18=0.002  P=.968  Î·2 = .000). There were no significant time or interaction effects among the objectively measured physical activity variables. Examination of effect sizes revealed moderate-to-large changes in physical activity outcomes. Results provide initial support for the feasibility of delivery of a physical activity intervention to low-active adolescents via social media. Whether by employing behavioral interventions via social media can result in statistically meaningful changes in health-related behaviors and outcomes remains to beEconomic support to improve tuberculosis treatment outcomes in South Africa: a pragmatic cluster-randomized controlled trial.PubMedLutge  Elizabeth; Lewin  Simon; Volmink  Jimmy; Friedman  Irwin; Lombard  Carl2013-05-28Poverty undermines adherence to tuberculosis treatment. Economic support may both encourage and enable patients to complete treatment. In South Africa  which carries a high burden of tuberculosis  such support may improve the currently poor outcomes of patients on tuberculosis treatment. The aim of this study was to test the feasibility and effectiveness of delivering economic support to patients with pulmonary tuberculosis in a high-burden province of South Africa. This was a pragmatic  unblinded  two-arm cluster-randomized controlled trial  where 20 public sector clinics acted as clusters. Patients with pulmonary tuberculosis in intervention clinics (nâ€‰=â€‰2 107) were offered a monthly voucher of ZAR120.00 (approximately US$15) until the completion of their treatment. Vouchers were redeemed at local shops for foodstuffs. Patients in control clinics (nâ€‰=â€‰1 984) received usual tuberculosis care. Intention to treat analysis showed a small but non-significant improvement in treatment success rates in intervention clinics (intervention 76.2%; control 70.7%; risk difference 5.6% (95% confidence interval: -1.2%  12.3%)  Pâ€‰=â€‰0.107). Low fidelity to the intervention meant that 36.2% of eligible patients did not receive a voucher at all  32.3% received a voucher for between one and three months and 31.5% received a voucher for four to eight months of treatment. There was a strong dose-response relationship between frequency of receipt of the voucher and treatment success (P <0.001). Our pragmatic trial has shown that  in the real world setting of public sector clinics in South Africa  economic support to patients with tuberculosis does not significantly improve outcomes on treatment. However  the low fidelity to the delivery of our voucher meant that a third of eligible patients did not receive it. Among patients in intervention clinics who received the voucher at least once  treatment success rates were significantly improved. Further operational research isFeasibility of optimizing trimetazidine dihydrochloride release from controlled porosity osmotic pump tablets of directly compressed coresPubMed CentralHabib  Basant A.; Rehim  Randa T. Abd El; Nour  Samia A.2013-01-01The aim of this study was to develop and optimize Trimetazidine dihydrochloride (TM) controlled porosity osmotic pump (CPOP) tablets of directly compressed cores. A 23 full factorial design was used to study the influence of three factors namely: PEG400 (10% and 25% based on coating polymer weight)  coating level (10% and 20% of tablet core weight) and hole diameter (0 â€œno holeâ€ and 1Â mm). Other variables such as tablet cores  coating mixture of ethylcellulose (4%) and dibutylphthalate (2%) in 95% ethanol and pan coating conditions were kept constant. The responses studied (Yi) were cumulative percentage released after 2Â h (Q%2h)  6Â h (Q%6h)  12Â h (Q%12h) and regression coefficient of release data fitted to zero order equation (RSQzero)  for Y1  Y2  Y3  and Y4  respectively. Polynomial equations were used to study the influence of different factors on each response individually. Response surface methodology and multiple response optimization were used to search for an optimized formula. Response variables for the optimized formula were restricted to 10%Â â©½Â Y1Â â©½Â 20%  40%Â â©½Â Y2Â â©½Â 60%  80%Â â©½Â Y3Â â©½Â 100%  and Y4Â >Â 0.9. The statistical analysis of the results revealed that PEG400 had positive effects on Q%2h  Q%6h and Q%12h  hole diameter had positive effects on all responses and coating level had positive effect on Q%6h  Q%12h and negative effect on RSQzero. Full three factor interaction (3FI) equations were used for representation of all responses except Q%2h which was represented by reduced (3FI) equation. Upon exploring the experimental space  no formula in the tested range could satisfy the required constraints. Thus  direct compression of TM cores was not suitable for formation of CPOP tablets. Preliminary trials of CPOP tablets with wet granulated cores were promising with an intact membrane for 12Â h and high RSQzero. Further improvement of these formulations to optimize TM release will be done in further studies. PMID:25685502Feasibility of Gamified Mobile Service Aimed at Physical Activation in Young Men: Population-Based Randomized Controlled Study (MOPO)PubMed CentralPyky  Riitta; Ahola  Riikka; Kangas  Maarit; Siirtola  Pekka; Luoto  Tim; Enwald  Heidi; IkÃ¤heimo  Tiina M; RÃ¶ning  Juha; KeinÃ¤nen-Kiukaanniemi  Sirkka; MÃ¤ntysaari  Matti; Korpelainen  Raija; JÃ¤msÃ¤  Timo2017-01-01Background The majority of young people do not meet the recommendations on physical activity for health. New innovative ways to motivate young people to adopt a physically active lifestyle are needed. Objective The study aimed to study the feasibility of an automated  gamified  tailored Web-based mobile service aimed at physical and social activation among young men. Methods A population-based sample of 496 young men (mean age 17.8 years [standard deviation 0.6]) participated in a 6-month randomized controlled trial (MOPO study). Participants were randomized to an intervention (n=250) and a control group (n=246). The intervention group was given a wrist-worn physical activity monitor (Polar Active) with physical activity feedback and access to a gamified Web-based mobile service  providing fitness guidelines  tailored health information  advice of youth services  social networking  and feedback on physical activity. Through the trial  the physical activity of the men in the control group was measured continuously with an otherwise similar monitor but providing only the time of day and no feedback. The primary outcome was the feasibility of the service based on log data and questionnaires. Among completers  we also analyzed the change in anthropometry and fitness between baseline and 6 months and the change over time in weekly time spent in moderate to vigorous physical activity. Results Mobile service users considered the various functionalities related to physical activity important. However  compliance of the service was limited  with 161 (64.4%  161/250) participants visiting the service  118 (47.2%  118/250) logging in more than once  and 41 (16.4%  41/250) more than 5 times. Baseline sedentary time was higher in those who uploaded physical activity data until the end of the trial (P=.02). A total of 187 (74.8%  187/250) participants in the intervention and 167 (67.9%  167/246) in the control group participated in the final measurements. There were noFeasibility of Gamified Mobile Service Aimed at Physical Activation in Young Men: Population-Based Randomized Controlled Study (MOPO).PubMedLeinonen  Anna-Maiju; Pyky  Riitta; Ahola  Riikka; Kangas  Maarit; Siirtola  Pekka; Luoto  Tim; Enwald  Heidi; IkÃ¤heimo  Tiina M; RÃ¶ning  Juha; KeinÃ¤nen-Kiukaanniemi  Sirkka; MÃ¤ntysaari  Matti; Korpelainen  Raija; JÃ¤msÃ¤  Timo2017-10-10The majority of young people do not meet the recommendations on physical activity for health. New innovative ways to motivate young people to adopt a physically active lifestyle are needed. The study aimed to study the feasibility of an automated  gamified  tailored Web-based mobile service aimed at physical and social activation among young men. A population-based sample of 496 young men (mean age 17.8 years [standard deviation 0.6]) participated in a 6-month randomized controlled trial (MOPO study). Participants were randomized to an intervention (n=250) and a control group (n=246). The intervention group was given a wrist-worn physical activity monitor (Polar Active) with physical activity feedback and access to a gamified Web-based mobile service  providing fitness guidelines  tailored health information  advice of youth services  social networking  and feedback on physical activity. Through the trial  the physical activity of the men in the control group was measured continuously with an otherwise similar monitor but providing only the time of day and no feedback. The primary outcome was the feasibility of the service based on log data and questionnaires. Among completers  we also analyzed the change in anthropometry and fitness between baseline and 6 months and the change over time in weekly time spent in moderate to vigorous physical activity. Mobile service users considered the various functionalities related to physical activity important. However  compliance of the service was limited  with 161 (64.4%  161/250) participants visiting the service  118 (47.2%  118/250) logging in more than once  and 41 (16.4%  41/250) more than 5 times. Baseline sedentary time was higher in those who uploaded physical activity data until the end of the trial (P=.02). A total of 187 (74.8%  187/250) participants in the intervention and 167 (67.9%  167/246) in the control group participated in the final measurements. There were no differences in the change in anthropometry andThe management of Otitis Media with Effusion in children with cleft palate (mOMEnt): a feasibility study and economic evaluation.PubMedBruce  Iain; Harman  Nicola; Williamson  Paula; Tierney  Stephanie; Callery  Peter; Mohiuddin  Syed; Payne  Katherine; Fenwick  Elisabeth; Kirkham  Jamie; O'Brien  Kevin2015-08-01Cleft lip and palate are among the most common congenital malformations  with an incidence of around 1 in 700. Cleft palate (CP) results in impaired Eustachian tube function  and 90% of children with CP have otitis media with effusion (OME) histories. There are several approaches to management  including watchful waiting  the provision of hearing aids (HAs) and the insertion of ventilation tubes (VTs). However  the evidence underpinning these strategies is unclear and there is a need to determine which treatment is the most appropriate. To identify the optimum study design  increase understanding of the impact of OME  determine the value of future research and develop a core outcome set (COS) for use in future studies. The management of Otitis Media with Effusion in children with cleft palate (mOMEnt) study had four key components: (i) a survey evaluation of current clinical practice in each cleft centre; (ii) economic modelling and value of information (VOI) analysis to determine if the extent of existing decision uncertainty justifies the cost of further research; (iii) qualitative research to capture patient and parent opinion regarding willingness to participate in a trial and important outcomes; and (iv) the development of a COS for use in future effectiveness trials of OME in children with CP. The survey was carried out by e-mail with cleft centres. The qualitative research interviews took place in patients' homes. The COS was developed with health professionals and parents using a web-based Delphi exercise and a consensus meeting. Clinicians working in the UK cleft centres  and parents and patients affected by CP and identified through two cleft clinics in the UK  or through the Cleft Lip and Palate Association. The clinician survey revealed that care was predominantly delivered via a 'hub-and-spoke' model; there was some uncertainty about treatment strategies; it is not current practice to insert VTs at the time of palate repair; centres were in a positionFeasibility of an online mindfulness-based program for patients with melanoma: study protocol for a randomised controlled trial.PubMedRussell  Lahiru; Ugalde  Anna; Milne  Donna; Krishnasamy  Meinir; O Seung Chul  Eric; Austin  David W; Chambers  Richard; Orellana  Liliana; Livingston  Patricia M2018-04-13People with a melanoma diagnosis are at risk of recurrence  developing a new primary or experiencing disease progression. Previous studies have suggested that fear of a cancer recurrence is clinically relevant in this group of patients and  if not addressed  can lead to distress. Mindfulness-based interventions have been shown to alleviate symptoms of anxiety and depression among various groups of cancer patients. Online mindfulness-based interventions have the potential to reach people unable to attend face-to-face interventions due to limitations such as cancer-related illness  transportation or time constraints. This study aims to (1) examine whether individuals with a melanoma diagnosis are willing to participate and adhere to a 6-week online mindfulness-based intervention and (2) explore potential benefits of the program on fear of cancer recurrence  worries  rumination  perceived stress and trait mindfulness to inform the design of a clinical trial. This is a single-site randomised controlled trial of a feasibility study. Seventy-five participants with stage 2c or 3 melanoma will be recruited from a melanoma outpatient clinic and randomised (2:1) either to an online mindfulness-based program (intervention) or to usual care (control). The intervention is a 6-week program specifically developed for this study. It consists of videos describing the concept of mindfulness  short daily guided meditation practices (5-10Â min)  automated meditation reminders and instructions for applying mindfulness in daily life to enhance wellbeing. All participants will complete questionnaires at baseline and at 6-week post-randomisation. Participants in the control group will be given access to the online program at the end of the study. Primary outcomes are overall recruitment; retention; extent of questionnaire completion; and usability and acceptability of  and adherence to  the program. The secondary outcomes are fear of cancer recurrence  worries  rumination  perceivedThe feasibility of a randomized controlled trial of esophagectomy for esophageal cancer - the ROMIO (Randomized Oesophagectomy: Minimally Invasive or Open) study: protocol for a randomized controlled trialPubMed Central2014-01-01Background There is a need for evidence of the clinical effectiveness of minimally invasive surgery for the treatment of esophageal cancer  but randomized controlled trials in surgery are often difficult to conduct. The ROMIO (Randomized Open or Minimally Invasive Oesophagectomy) study will establish the feasibility of a main trial which will examine the clinical and cost-effectiveness of minimally invasive and open surgical procedures for the treatment of esophageal cancer. Methods/Design A pilot randomized controlled trial (RCT)  in two centers (University Hospitals Bristol NHS Foundation Trust and Plymouth Hospitals NHS Trust) will examine numbers of incident and eligible patients who consent to participate in the ROMIO study. Interventions will include esophagectomy by: (1) open gastric mobilization and right thoracotomy  (2) laparoscopic gastric mobilization and right thoracotomy  and (3) totally minimally invasive surgery (in the Bristol center only). The primary outcomes of the feasibility study will be measures of recruitment  successful development of methods to monitor quality of surgery and fidelity to a surgical protocol  and development of a core outcome set to evaluate esophageal cancer surgery. The study will test patient-reported outcomes measures to assess recovery  methods to blind participants  assessments of surgical morbidity  and methods to capture cost and resource use. ROMIO will integrate methods to monitor and improve recruitment using audio recordings of consultations between recruiting surgeons  nurses  and patients to provide feedback for recruiting staff. Discussion The ROMIO study aims to establish efficient methods to undertake a main trial of minimally invasive surgery versus open surgery for esophageal cancer. Trial registration The pilot trial has Current Controlled Trials registration number ISRCTN59036820(25/02/2013) at http://www.controlled-trials.com; the ROMIO trial record at that site gives a link to the original version ofActive Control of Fan Noise: Feasibility Study. Volume 4; Flyover System Noise StudiesNASA Technical Reports Server (NTRS)Kraft  R. E.; Janardan  B. A.; Gliebe  P. R.; Kontos  G. C.1996-01-01An extension of a prior study has been completed to examine the potential reduction of aircraft flyover noise by the method of active noise control (ANC). It is assumed that the ANC system will be designed such that it cancels discrete tones radiating from the engine fan inlet or fan exhaust duct  at least to the extent that they no longer protrude above the surrounding broadband noise levels. Thus  without considering the engineering details of the ANC system design  tone levels am arbitrarily removed from the engine component noise spectrum and the flyover noise EPNL levels are compared with and without the presence of tones. The study was conducted for a range of engine cycles  corresponding to fan pressure ratios of 1.3  1.45  1.6  and 1.75. This report is an extension of an effort reported previously. The major conclusions drawn from the prior study  which was restricted to fan pressure ratios of 1.45 and 1.75  are that  for a fan pressure ratio of 1.75  ANC of tones gives about the same suppression as acoustic treatment without ANC. For a fan pressure ratio of 1.45  ANC appears to offer less effectiveness from passive treatment. In the present study  the other two fan pressure ratios are included in a more detailed examination of the benefits of the ANC suppression levels. The key results of this extended study are the following observations: (1) The maximum overall benefit obtained from suppression of BPF alone was 2.5 EPNdB at high fan speeds. The suppression benefit increases with increase in fan pressure ratio (FPR)  (2) The maximum overall benefit obtained from suppression of the first three harmonics was 3 EPNdB at high speeds. Suppression benefit increases with increase in FPR  (3) At low FPR  only about 1.0 EPNdB maximum reduction was obtained. Suppression is primarily from reduction of BPF at high FPR values and from the combination of tones at low FPR  (4) The benefit from ANC is about the same as the benefit from passive treatment at fan pressureA Feasibility Randomised Controlled Trial of the New Orleans Intervention for Infant Mental Health: A Study ProtocolPubMed CentralFitzpatrick  Bridie; Watson  Nicholas; Cotmore  Richard; Wilson  Philip; Donaldson  Julia; Boyd  Kathleen; Zeanah  Charles; Norrie  John; Messow  Martina; Turner  Fiona; Irving  Susan2013-01-01Child maltreatment is associated with life-long social  physical  and mental health problems. Intervening early to provide maltreated children with safe  nurturing care can improve outcomes. The need for prompt decisions about permanent placement (i.e.  regarding adoption or return home) is internationally recognised. However  a recent Glasgow audit showed that many maltreated children â€œrevolveâ€ between birth families and foster carers. This paper describes the protocol of the first exploratory randomised controlled trial of a mental health intervention aimed at improving placement permanency decisions for maltreated children. This trial compares an infant's mental health intervention with the new enhanced service as usual for maltreated children entering care in Glasgow. As both are new services  the trial is being conducted from a position of equipoise. The outcome assessment covers various fields of a child's neurodevelopment to identify problems in any ESSENCE domain. The feasibility  reliability  and developmental appropriateness of all outcome measures are examined. Additionally  the potential for linkage with routinely collected data on health and social care and  in the future  education is explored. The results will inform a definitive randomised controlled trial that could potentially lead to long lasting benefits for the Scottish population and which may be applicable to other areas of the world. This trial is registered with ClinicalTrials.gov (NC01485510). PMID:24023537Capacity building of AYUSH practitioners to study the feasibility of their involvement in non-communicable disease prevention and controlPubMed CentralKumar  Dinesh; Raina  Sunil Kumar; Bhardwaj  A. K.; Chander  Vishav2012-01-01Background: Sharing of public health knowledge and skills by professionals in allopathic system of medicine with Ayurveda  Yoga  and Naturopathy  Unani  Siddha and Homeopathy (AYUSH) professionals in India has always been considered as part of integrating the health system in India. But till date  a curriculum has not been framed for follow-up. Materials and Methods: A training course was developed for AYUSH professionals in India on the public health principles for the prevention and control of non-communicable diseases (NCDs). Three course chairs interacted with international and national public health and AYUSH experts  and the curriculum for a 3-month course was developed. Results: The curriculum comprised interactive lectures  problem-based exercise  field visits  and research protocol development. A total of four participants  nominated by the World Health Organization  India  were trained during the course  with significant (P = 0.00) improvement in knowledge from 53.2 to 80.0 points. Conclusion: A novel and feasible public health course for complementary and alternative medicine professionals on the public health principles for NCDsâ€™ prevention and control is needed to bridge the demand gap for public health professionals in India. PMID:24167339Feasibility of controlling CD38-CAR T cell activity with a Tet-on inducible CAR designPubMed CentralPoels  RenÃ©e; Mulders  Manon J.; van de Donk  Niels W. C. J.; Themeli  Maria; Lokhorst  Henk M.; Mutis  Tuna2018-01-01Recent clinical advances with chimeric antigen receptor (CAR) T cells have led to the accelerated clinical approval of CD19-CARs to treat acute lymphoblastic leukemia. The CAR T cell therapy is nevertheless associated with toxicities  especially if the CARs are not entirely tumor-specific. Therefore  strategies for controlling the CAR T cell activity are required to improve their safety profile. Here  by using the multiple myeloma (MM)-associated CD38 molecule as target molecule  we tested the feasibility and utility of a doxycycline (DOX) inducible Tet-on CD38-CAR design to control the off-target toxicities of CAR T cells. Using CARs with high affinity to CD38  we demonstrate that this strategy allows the proper induction of CD38-CARs and CAR-mediated T cell cytotoxicity in a DOX-dose dependent manner. Especially when the DOX dose was limited to 10ng/ml  its removal resulted in a relatively rapid decay of CAR- related off-tumor effects within 24 hours  indicating the active controllability of undesired CAR activity. This Tet-on CAR design also allowed us to induce the maximal anti-MM cytotoxic activity of affinity-optimized CD38-CAR T cells  which already display a low toxicity profile  hereby adding a second level of safety to these cells. Collectively  these results indicate the possibility to utilize this DOX inducible CAR-design to actively regulate the CAR-mediated activities of therapeutic T cells. We therefore conclude that the Tet-on system may be more advantageous above suicide-genes to control the potential toxicities of CAR T cells without the need to destroy them permanently. PMID:29847570Robust Economic Control Decision Method of Uncertain System on Urban Domestic Water Supply.PubMedLi  Kebai; Ma  Tianyi; Wei  Guo2018-03-31As China quickly urbanizes  urban domestic water generally presents the circumstances of both rising tendency and seasonal cycle fluctuation. A robust economic control decision method for dynamic uncertain systems is proposed in this paper. It is developed based on the internal model principle and pole allocation method  and it is applied to an urban domestic water supply system with rising tendency and seasonal cycle fluctuation. To achieve this goal  first a multiplicative model is used to describe the urban domestic water demand. Then  a capital stock and a labor stock are selected as the state vector  and the investment and labor are designed as the control vector. Next  the compensator subsystem is devised in light of the internal model principle. Finally  by using the state feedback control strategy and pole allocation method  the multivariable robust economic control decision method is implemented. The implementation with this model can accomplish the urban domestic water supply control goal  with the robustness for the variation of parameters. The methodology presented in this study may be applied to the water management system in other parts of the world  provided all data used in this study are available. The robust control decision method in this paper is also applicable to deal with tracking control problems as well as stabilization control problems of other general dynamic uncertain systems.Robust Economic Control Decision Method of Uncertain System on Urban Domestic Water SupplyPubMed CentralLi  Kebai; Ma  Tianyi; Wei  Guo2018-01-01As China quickly urbanizes  urban domestic water generally presents the circumstances of both rising tendency and seasonal cycle fluctuation. A robust economic control decision method for dynamic uncertain systems is proposed in this paper. It is developed based on the internal model principle and pole allocation method  and it is applied to an urban domestic water supply system with rising tendency and seasonal cycle fluctuation. To achieve this goal  first a multiplicative model is used to describe the urban domestic water demand. Then  a capital stock and a labor stock are selected as the state vector  and the investment and labor are designed as the control vector. Next  the compensator subsystem is devised in light of the internal model principle. Finally  by using the state feedback control strategy and pole allocation method  the multivariable robust economic control decision method is implemented. The implementation with this model can accomplish the urban domestic water supply control goal  with the robustness for the variation of parameters. The methodology presented in this study may be applied to the water management system in other parts of the world  provided all data used in this study are available. The robust control decision method in this paper is also applicable to deal with tracking control problems as well as stabilization control problems of other general dynamic uncertain systems. PMID:29614749Feasibility and cost-effectiveness of a multidisciplinary home-telehealth intervention programme to reduce falls among elderly discharged from hospital: study protocol for a randomized controlled trial.PubMedGiordano  Alessandro; Bonometti  Gian Pietro; Vanoglio  Fabio; Paneroni  Mara; Bernocchi  Palmira; Comini  Laura; Giordano  Amerigo2016-12-07Fall incidents are the third cause of chronic disablement in elderly according to the World Health Organization (WHO). Recent meta-analyses shows that a multifactorial falls risk assessment and management programmes are effective in all older population studied. However  the application of these programmes may not be the same in all National health care setting and  consequently  needs to be evaluated by cost-effectiveness studies before to plan this intervention in regular care. In Italy structured collaboration between hospital staff and primary care is generally lacking and the role of Information and Communication Technologies (ICT) in a fall prevention programme at home has never been explored. This will be a two-group randomised controlled trial aiming to evaluate the effects of a home-based intervention programme delivered by a multidisciplinary health team. The home tele-management programme  previously adopted in our Institute for chronic patients  will be proposed to elderly people affected by chronic diseases at high risk of falling at hospital discharge. The programme will involve the hospital staff and will be managed thanks to the collaboration between hospital and primary care setting. Patients will be followed for 6Â months after hospital discharge. A nurse-tutor telephone support and tele-exercise will characterize the intervention programme. People in the control group will receive usual care. The main outcome measure of the study will be the percentage of patients sustaining a fall during the 6-months follow-up period. An economic evaluation will be performed from a societal perspective and will involve calculating cost-effectiveness and cost utility ratios. To date  no adequately powered studies have investigated the effect of the Information and Communication Technologies (ICT) in a home fall prevention program. We aim the program will be feasible in terms of intensity and characteristics  but particularly in terms of patient and providerA bio-economic analysis of harvest control rules for the Northeast Arctic cod fishery.PubMedEikeset  Anne Maria; Richter  Andries P; Dankel  Dorothy J; Dunlop  Erin S; Heino  Mikko; Dieckmann  Ulf; Stenseth  Nils Chr2013-05-01Harvest control rules (HCRs) have been implemented for many fisheries worldwide. However  in most instances  those HCRs are not based on the explicit feedbacks between stock properties and economic considerations. This paper develops a bio-economic model that evaluates the HCR adopted in 2004 by the Joint Norwegian-Russian Fishery Commission to manage the world's largest cod stock  Northeast Arctic cod (NEA). The model considered here is biologically and economically detailed  and is the first to compare the performance of the stock's current HCR with that of alternative HCRs derived with optimality criteria. In particular  HCRs are optimized for economic objectives including fleet profits  economic welfare  and total yield and the emerging properties are analyzed. The performance of these optimal HCRs was compared with the currently used HCR. This paper show that the current HCR does in fact comes very close to maximizing profits. Furthermore  the results reveal that the HCR that maximizes profits is the most precautionary one among the considered HCRs. Finally  the HCR that maximizes yield leads to un-precautionary low levels of biomass. In these ways  the implementation of the HCR for NEA cod can be viewed as a success story that may provide valuable lessons for other fisheries.A bio-economic analysis of harvest control rules for the Northeast Arctic cod fisheryPubMed CentralEikeset  Anne Maria; Richter  Andries P.; Dankel  Dorothy J.; Dunlop  Erin S.; Heino  Mikko; Dieckmann  Ulf; Stenseth  Nils Chr.2013-01-01Harvest control rules (HCRs) have been implemented for many fisheries worldwide. However  in most instances  those HCRs are not based on the explicit feedbacks between stock properties and economic considerations. This paper develops a bio-economic model that evaluates the HCR adopted in 2004 by the Joint Norwegianâ€“Russian Fishery Commission to manage the world's largest cod stock  Northeast Arctic cod (NEA). The model considered here is biologically and economically detailed  and is the first to compare the performance of the stock's current HCR with that of alternative HCRs derived with optimality criteria. In particular  HCRs are optimized for economic objectives including fleet profits  economic welfare  and total yield and the emerging properties are analyzed. The performance of these optimal HCRs was compared with the currently used HCR. This paper show that the current HCR does in fact comes very close to maximizing profits. Furthermore  the results reveal that the HCR that maximizes profits is the most precautionary one among the considered HCRs. Finally  the HCR that maximizes yield leads to un-precautionary low levels of biomass. In these ways  the implementation of the HCR for NEA cod can be viewed as a success story that may provide valuable lessons for other fisheries. PMID:26525860The use of global positional satellite location in dementia: a feasibility study for a randomised controlled trialPubMed Central2014-01-01Background Getting lost outside is stressful for people with dementia and their caregivers and a leading cause of long-term institutionalisation. Although Global Positional Satellite (GPS) location has been promoted to facilitate safe walking  reduce caregiversâ€™ anxiety and enable people with dementia to remain at home  there is little high quality evidence about its acceptability  effectiveness or cost-effectiveness. This observational study explored the feasibility of recruiting and retaining participants  and the acceptability of outcome measures  to inform decisions about the feasibility of a randomised controlled trial (RCT). Methods People with dementia who had been provided with GPS devices by local social-care services and their caregivers were invited to participate in this study. We undertook interviews with people with dementia  caregivers and professionals to explore the perceived utility and challenges of GPS location  and assessed quality of life (QoL) and mental health. We piloted three methods of calculating resource use: caregiver diary; bi-monthly telephone questionnaires; and interrogation of health and social care records. We asked caregivers to estimate the time spent searching if participants became lost before and whilst using GPS. Results Twenty people were offered GPS locations services by social-care services during the 8-month recruitment period. Of these  14 agreed to be referred to the research team  12 of these participated and provided data. Eight people with dementia and 12 caregivers were interviewed. Most participants and professionals were very positive about using GPS. Only one person completed a diary. Resource use  anxiety and depression and QoL questionnaires were considered difficult and were therefore declined by some on follow-up. Social care records were time consuming to search and contained many omissions. Caregivers estimated that GPS reduced searching time although the accuracy of this was not objectively verifiedFeasibility and effects of newly developed balance control trainer for mobility and balance in chronic stroke patients: a randomized controlled trial.PubMedLee  So Hyun; Byun  Seung Deuk; Kim  Chul Hyun; Go  Jin Young; Nam  Hyeon Uk; Huh  Jin Seok; Jung  Tae Du2012-08-01To investigate the feasibility and effects of balance training with a newly developed Balance Control Trainer (BCT) that applied the concept of vertical movement for the improvements of mobility and balance in chronic stroke patients. Forty chronic stroke patients were randomly assigned to an experimental or a control group. The experimental group (n=20) underwent training with a BCT for 20 minutes a day  5 days a week for 4 weeks  in addition to concurrent conventional physical therapy. The control group (n=20) underwent only conventional therapy for 4 weeks. All participants were assessed by: the Functional Ambulation Categories (FAC)  10-meter Walking Test (10mWT)  Timed Up and Go test (TUG)  Berg Balance Scale (BBS)  Korean Modified Barthel Index (MBI)  and Manual Muscle Test (MMT) before training  and at 2 and 4 weeks of training. There were statistically significant improvements in all parameters except knee extensor power at 2 weeks of treatment  and in all parameters except MBI which showed further statistically significant progress in the experimental group over the next two weeks (p<0.05). Statistically significant improvements on all measurements were observed in the experimental group after 4 weeks total. Comparing the two groups at 2 and 4 weeks of training respectively  10mWT  TUG  and BBS showed statistically more significant improvements in the experimental group (p<0.05). Balance training with a newly developed BCT is feasible and may be an effective tool to improve balance and gait in ambulatory chronic stroke patients. Furthermore  it may provide additional benefits when used in conjunction with conventional therapies.Evaluating the Feasibility of a Gardening and Nutrition Intervention with a Matched Contact-Control Physical Activity Intervention Targeting YouthERIC Educational Resources Information CenterAlexander  Ramine; Hill  Jennie; Grier  Karissa; MacAuley  Lorien; McKenzie  Alisa; Totten  Tadashi; Porter  Kathleen; Zoellner  Jamie2016-01-01The study reported here involved Cooperative Extension as a key research partner and was guided by a community-based participatory research approach and a feasibility study framework. The research objective was to assess four indicators of feasibility (i.e.  acceptability  demand  implementation  and limited-effectiveness) of a gardening andâ€¦Efficacy and feasibility of a novel tri-modal robust exercise prescription in a retirement community: a randomized  controlled trial.PubMedBaker  Michael K; Kennedy  David J; Bohle  Philip L; Campbell  Deena S; Knapman  Leona; Grady  Jodie; Wiltshire  James; McNamara  Maria; Evans  William J; Atlantis  Evan; Fiatarone Singh  Maria A2007-01-01To test the feasibility and efficacy of current guidelines for multimodal exercise programs in older adults. Randomized  controlled trial. Retirement village. Thirty-eight subjects (14 men and 24 women) aged 76.6 +/- 6.1. A wait list control or 10 weeks of supervised exercise consisting of high-intensity (80% of one-repetition maximum (1RM)) progressive resistance training (PRT) 3 days per week  moderate-intensity (rating of perceived exertion 11 to 14/20) aerobic training 2 days per week  and progressive balance training 1 day per week. Blinded assessments of dynamic muscle strength (1RM)  balance  6-minute walk  gait velocity  chair stand  stair climb  depressive symptoms  self-efficacy  and habitual physical activity level. Higher baseline strength and psychological well-being were associated with better functional performance. Strength gains over 10 weeks averaged 39+/-31% in exercise  versus 21+/-24% in controls (P=.10)  with greater improvements in hip flexion (P=.01)  hip abduction (P=.02)  and chest press (P=.04) in the exercise group. Strength adaptations were greatest in exercises in which the intended continuous progressive overload was achieved. Stair climb power (12.3+/-15%  P=.002) and chair stand time (-7.1+/-15%  P=.006) improved significantly and similarly in both groups. Reduction in depressive symptoms was significantly related to compliance (attendance rate r=-0.568  P=.009  PRT progression in loading r=-0.587  P=.02  and total volume of aerobic training r=-0.541  P=.01)  as well as improvements in muscle strength (r=-0.498  P=.002). Robust physical and psychological adaptations to exercise are linked  although volumes and intensities of multiple exercise modalities sufficient to cause significant adaptation appear difficult to prescribe and adhere to simultaneously in older adults.Preliminary efficacy and feasibility of embedding high intensity interval training into the school day: A pilot randomized controlled trial.PubMedCostigan  S A; Eather  N; Plotnikoff  R C; Taaffe  D R; Pollock  E; Kennedy  S G; Lubans  D R2015-01-01Current physical activity and fitness levels among adolescents are low  increasing the risk of chronic disease. Although the efficacy of high intensity interval training (HIIT) for improving metabolic health is now well established  it is not known if this type of activity can be effective to improve adolescent health. The primary aim of this study is to assess the effectiveness and feasibility of embedding HIIT into the school day. A 3-arm pilot randomized controlled trial was conducted in one secondary school in Newcastle  Australia. Participants (nÂ =Â 65; mean ageÂ =Â 15.8(0.6) years) were randomized into one of three conditions: aerobic exercise program (AEP) (nÂ =Â 21)  resistance and aerobic exercise program (RAP) (nÂ =Â 22) and control (nÂ =Â 22). The 8-week intervention consisted of three HIIT sessions per week (8-10Â min/session)  delivered during physical education (PE) lessons or at lunchtime. Assessments were conducted at baseline and post-intervention to detect changes in cardiorespiratory fitness (multi-stage shuttle-run)  muscular fitness (push-up  standing long jump tests)  body composition (Body Mass Index (BMI)  BMI-z scores  waist circumference) and physical activity motivation (questionnaire)  by researchers blinded to treatment allocation. Intervention effects for outcomes were examined using linear mixed models  and Cohen's d effect sizes were reported. Participants in the AEP and RAP groups had moderate intervention effects for waist circumference (pÂ =Â 0.024)  BMI-z (pÂ =Â 0.037) and BMI (not significant) in comparison to the control group. A small intervention effect was also evident for cardiorespiratory fitness in the RAP group.Camino Verde (The Green Way): evidence-based community mobilisation for dengue control in Nicaragua and Mexico: feasibility study and study protocol for a randomised controlled trial.PubMedAndersson  Neil; Arostegui  Jorge; Nava-Aguilera  Elizabeth; Harris  Eva; Ledogar  Robert J2017-05-30Since the Aedes aegypti mosquitoes that transmit dengue virus can breed in clean water  WHO-endorsed vector control strategies place sachets of organophosphate pesticide  temephos (Abate)  in household water storage containers. These and other pesticide-dependent approaches have failed to curb the spread of dengue and multiple dengue virus serotypes continue to spread throughout tropical and subtropical regions worldwide. A feasibility study in Managua  Nicaragua  generated instruments  intervention protocols  training schedules and impact assessment tools for a cluster randomised controlled trial of community-based approaches to vector control comprising an alternative strategy for dengue prevention and control in Nicaragua and Mexico. The Camino Verde (Green Way) is a pragmatic parallel group trial of pesticide-free dengue vector control  adding effectiveness to the standard government dengue control. A random sample from the most recent census in three coastal regions of Guerrero state in Mexico will generate 90 study clusters and the equivalent sampling frame in Managua  Nicaragua will generate 60 clusters  making a total of 150 clusters each of 137-140 households. After a baseline study  computer-driven randomisation will allocate to intervention one half of the sites  stratified by country  evidence of recent dengue virus infection in children aged 3-9Â years and  in Nicaragua  level of community organisation. Following a common evidence-based education protocol  each cluster will develop and implement its own collective interventions including house-to-house visits  school-based programmes and inter-community visits. After 18Â months  a follow-up study will compare dengue history  serological evidence of recent dengue virus infection (via measurement of anti-dengue virus antibodies in saliva samples) and entomological indices between intervention and control sites. Our hypothesis is that informed community mobilisation adds effectiveness in controllingFeasibility and preliminary efficacy of the 'HEYMAN' healthy lifestyle program for young men: a pilot randomised controlled trial.PubMedAshton  Lee M; Morgan  Philip J; Hutchesson  Melinda J; Rollo  Megan E; Collins  Clare E2017-01-13In young men  unhealthy lifestyle behaviours can be detrimental to their physical and/or mental health and set them on a negative health trajectory into adulthood. Despite this  there is a lack of evidence to guide development of effective health behaviour change interventions for young men. This study assessed the feasibility and preliminary efficacy of the 'HEYMAN' (Harnessing Ehealth to enhance Young men's Mental health  Activity and Nutrition) healthy lifestyle program for young men. A pilot RCT with 50 young men aged 18-25 years randomised to the HEYMAN intervention (nâ€‰=â€‰26) or waitlist control (nâ€‰=â€‰24). HEYMAN was a 3-month intervention  targeted for young men to improve eating habits  activity levels and well-being. Intervention development was informed by a participatory research model (PRECEDE-PROCEED). Intervention components included eHealth support (website  wearable device  Facebook support group)  face-to-face sessions (group and individual)  a personalised food and nutrient report  home-based resistance training equipment and a portion control tool. Outcomes included: feasibility of research procedures (recruitment  randomisation  data collection and retention) and of intervention components. Generalized linear mixed models estimated the treatment effect at 3-months for the primary outcomes: pedometer steps/day  diet quality  well-being and several secondary outcomes. A 7-week recruitment period was required to enrol 50 young men. A retention rate of 94% was achieved at 3-months post-intervention. Retained intervention participants (nâ€‰=â€‰24) demonstrated reasonable usage levels for most program components and also reported reasonable levels of program component acceptability for attractiveness  comprehension  usability  support  satisfaction and ability to persuade  with scores ranging from 3.0 to 4.6 (maximum 5). No significant intervention effects were observed for the primary outcomes of steps/day (1012.7  95% CIâ€‰=â€‰-506.2  2531Tumor control probability reduction in gated radiotherapy of non-small cell lung cancers: a feasibility study.PubMedSiochi  R Alfredo; Kim  Yusung; Bhatia  Sudershan2014-10-16We studied the feasibility of evaluating tumor control probability (TCP) reductions for tumor motion beyond planned gated radiotherapy margins. Tumor motion was determined from cone-beam CT projections acquired for patient setup  intrafraction respiratory traces  and 4D CTs for five non-small cell lung cancer (NSCLC) patients treated with gated radiotherapy. Tumors were subdivided into 1 mm sections whose positions and doses were determined for each beam-on time point. (The dose calculation model was verified with motion phantom measurements.) The calculated dose distributions were used to generate the treatment TCPs for each patient. The plan TCPs were calculated from the treatment planning dose distributions. The treatment TCPs were compared to the plan TCPs for various models and parameters. Calculated doses matched phantom measurements within 0.3% for up to 3 cm of motion. TCP reductions for excess motion greater than 5mm ranged from 1.7% to 11.9%  depending on model parameters  and were as high as 48.6% for model parameters that simulated an individual patient. Repeating the worst case motion for all fractions increased TCP reductions by a factor of 2 to 3  while hypofractionation decreased these reductions by as much as a factor of 3. Treatment motion exceeding gating margins by more than 5 mm can lead to considerable TCP reductions. Appropriate margins for excess motion are recommended  unless applying daily tumor motion verification and adjusting thegating window.Update to a protocol for a feasibility cluster randomised controlled trial of a peer-led school-based intervention to increase the physical activity of adolescent girls (PLAN-A).PubMedSebire  Simon J; Edwards  Mark J; Campbell  Rona; Jago  Russell; Kipping  Ruth; Banfield  Kathryn; Kadir  Bryar; Garfield  Kirsty; Lyons  Ronan A; Blair  Peter S; Hollingworth  William2016-01-01Physical activity levels are low amongst adolescent girls  and this population faces specific barriers to being active. Peer influences on health behaviours are important in adolescence  and peer-led interventions might hold promise to change behaviour. This paper describes the protocol for a feasibility cluster randomised controlled trial of Peer-Led physical Activity iNtervention for Adolescent girls (PLAN-A)  a peer-led intervention aimed at increasing adolescent girls' physical activity levels. In addition  this paper describes an update that has been made to the protocol for the PLAN-A feasibility cluster randomised controlled trial. A two-arm cluster randomised feasibility trial will be conducted in six secondary schools (intervention n â€‰=â€‰4; control n â€‰=â€‰2) with year 8 (12-13Â years old) girls. The intervention will operate at a year group level and consist of year 8 girls nominating influential peers within their year group to become peer supporters. Approximately 15% of the cohort will receive 3Â days of training about physical activity and interpersonal communication skills. Peer supporters will then informally diffuse messages about physical activity amongst their friends for 10Â weeks. Data will be collected at baseline (time 0 (T0))  immediately after the intervention (time 1 (T1)) and 12Â months after baseline measures (time 2 (T2)). In this feasibility trial  the primary interest is in the recruitment of schools and participants (both year 8 girls and peer supporters)  delivery and receipt of the intervention  data provision rates and identifying the cost categories for future economic analysis. Physical activity will be assessed using 7-day accelerometry  with the likely primary outcome in a fully powered trial being daily minutes of moderate-to-vigorous physical activity. Participants will also complete psychosocial questionnaires at each time point: assessing motivation  self-esteem and peer physical activity norms. Data analysis will beThe use of dispersion modeling to determine the feasibility of vegetative environmental buffers (VEBS) at controlling odor dispersionNASA Astrophysics Data System (ADS)Weber  Eric E.Concentrated animal feeding operations (CAFOs) have been experiencing increased resistance from surrounding residents making construction of new facilities or expansion of existing ones increasingly limited (Jacobson et al.  2002). Such concerns often include the impact of nuisance odor on peoplesâ€™ lives and on the environment (Huang and Miller  2006). Vegetative environmental buffers (VEBs) have been suggested as a possible odor control technology. They have been found to impact odor plume dispersion and have shown the possibility of being an effective tool for odor abatement when used alone or in combination with other technologies (Lin et al.  2006). The main objective of this study was to use Gaussian-type dispersion modeling to determine the feasibility of use and the effectiveness of a VEB at controlling the spread of odor from a swine feeding operation. First  wind tunnel NH3 dispersion trends were compared to model generated dispersion trends to determine the accuracy of the model at handling VEB dispersion. Next  facility-scale (northern Missouri specific) model simulations with and without a VEB were run to determine its viability as an option for dispersion reduction. Finally  dispersion forecasts that integrated numerical weather forecasts were developed and compared to collected concentration data to determine forecast accuracy. The results of this study found that dispersion models can be used to simulate dispersion around a VEB. AERMOD-generated dispersion trends were found to follow similar patterns of decreasing downwind concentration to those of both wind tunnel simulations and previous research. This shows that a VEB can be incorporated into AERMOD and that the model can be used to determine its effectiveness as an odor control option. The results of this study also showed that a VEB has an effect on odor dispersion by reducing downwind concentrations. This was confirmed by both wind tunnel and AERMOD simulations of dispersion displayingThe effectiveness and feasibility of TREAT (Tailoring Research Evidence and Theory) journal clubs in allied health: a randomised controlled trial.PubMedWenke  Rachel J; Thomas  Rae; Hughes  Ian; Mickan  Sharon2018-05-09Journal clubs (JC) may increase clinicians' evidence-based practice (EBP) skills and facilitate evidence uptake in clinical practice  however there is a lack of research into their effectiveness in allied health. We investigated the effectiveness of a structured JC that is Tailored According to Research Evidence And Theory (TREAT) in improving EBP skills and practice compared to a standard JC format for allied health professionals. Concurrently  we explored the feasibility of implementing TREAT JCs in a healthcare setting  by evaluating participating clinicians' perceptions and satisfaction. We conducted an explanatory mixed methods study involving a cluster randomised controlled trial with a nested focus group for the intervention participants. Nine JCs with 126 allied health participants were randomly allocated to receive either the TREAT or standard JC format for 1Â h/month for 6Â months. We conducted pre-post measures of EBP skills and attitudes using the EBP questionnaire and Assessing Competence in Evidence-Based Medicine tool and a tailored satisfaction and practice change questionnaire. Post-intervention  we also conducted a focus group with TREAT participants to explore their perceptions of the format. There were no significant differences between JC formats in EBP skills  knowledge or attitudes or influence on clinical practice  with participants maintaining intermediate level skills across time points. Participants reported significantly greater satisfaction with the organisation of the TREAT format. Participants in both groups reported positive changes to clinical practice. Perceived outcomes to the TREAT format and facilitating mechanisms were identified including the use of an academic facilitator  group appraisal approach and consistent appraisal tools which assisted skill development and engagement. It is feasible to implement an evidence-based JC for allied health clinicians. While clinicians were more satisfied with the TREAT format  it did notRandomized controlled trial of Family Nurture Intervention in the NICU: assessments of length of stay  feasibility and safety.PubMedWelch  Martha G; Hofer  Myron A; Stark  Raymond I; Andrews  Howard F; Austin  Judy; Glickstein  Sara B; Ludwig  Robert J; Myers  Michael M2013-09-24While survival rates for preterm infants have increased  the risk for adverse long-term neurodevelopmental and behavioral outcomes remains very high. In response to the need for novel  evidence-based interventions that prevent such outcomes  we have assessed Family Nurture Intervention (FNI)  a novel dual mother-infant intervention implemented while the infant is in the Neonatal Intensive Care Unit (NICU). Here  we report the first trial results  including the primary outcome measure  length of stay in the NICU and  the feasibility and safety of its implementation in a high acuity level IV NICU. The FNI trial is a single center  parallel-group  randomized controlled trial at Morgan Stanley Children's Hospital for mothers and their singleton or twin infants of 26-34Â weeks gestation. Families were randomized to standard care (SC) or (FNI). FNI was implemented by nurture specialists trained to facilitate affective communication between mother and infant during specified calming interactions. These interactions included scent cloth exchange  sustained touch  vocal soothing and eye contact  wrapped or skin-to-skin holding  plus family-based support interactions. A total of 826 infants born between 26 and 34Â weeks during the 3.5Â year study period were admitted to the NICU. After infant and mother screening plus exclusion due to circumstances that prevented the family from participating  373 infants were eligible for the study. Of these  we were unable to schedule a consent meeting with 56  and consent was withheld by 165. Consent was obtained for 150 infants from 115 families. The infants were block randomized to groups of Nâ€‰=â€‰78  FNI and Nâ€‰=â€‰72  SC. Sixteen (9.6%) of the randomized infants did not complete the study to home discharge  7% of those randomized to SC and 12% of FNI infants. Mothers in the intervention group engaged in 3 to 4 facilitated one- to two-hour sessions/week. Intent to treat analyses revealed no significant difference between groups inHome-based Reach-to-Grasp training for people after stroke is feasible: a pilot randomised controlled trial.PubMedTurton  A J; Cunningham  P; van Wijck  F; Smartt  Hjm; Rogers  C A; Sackley  C M; Jowett  S; Wolf  S L; Wheatley  K; van Vliet  P2017-07-01To determine feasibility of a randomised controlled trial (RCT) of home-based Reach-to-Grasp training after stroke. single-blind parallel group RCT. Residual arm deficit less than 12 months post-stroke. Reach-to-Grasp training in 14 one-hour therapist's visits over 6 weeks  plus one hour self-practice per day (total 56 hours). Usual care. Action Research Arm Test (ARAT)  Wolf Motor Function Test (WMFT)  pre-randomisation  7  12  24 weeks post-randomisation. Forty-seven participants (Reach-to-Grasp=24  usual care=23) were randomised over 17 months. Reach-to-Grasp participants received a median (IQR) 14 (13 14) visits  and performed 157 (96 211) repetitions per visit; plus 30 minutes (22 45) self-practice per day. Usual care participants received 10.5 (5 14) therapist visits  comprising 38.6 (30 45) minutes of arm therapy with 16 (6 24) repetitions of functional tasks per visit. Median ARAT scores in the reach-to-grasp group were 8.5 (3.0 24.0) at baseline and 14.5 (3.5 26.0) at 24 weeks compared to median of 4 at both time points (IQR: baseline (3.0 14.0)  24 weeks (3.0 30.0)) in the usual-care group. Median WMFT tasks completed at baseline and 24 weeks were 6 (3.0 11.5) and 8.5 (4.5 13.5) respectively in the reach-to-grasp group and 4 (3.0 10.0)  6 (3.0 14.0) in the usual care group. Incidence of arm pain was similar between groups. The study was stopped before 11 patients reached the 24 weeks assessment. An RCT of home-based Reach-to-Grasp training after stroke is feasible and safe. With ARAT being our preferred measure it is estimated that 240 participants will be needed for a future two armed trial.Costs of Rabies Control: An Economic Calculation Method Applied to Flores IslandPubMed CentralWera  Ewaldus; Velthuis  Annet G. J.; Geong  Maria; Hogeveen  Henk2013-01-01Background Rabies is a zoonotic disease that  in most human cases  is fatal once clinical signs appear. The disease transmits to humans through an animal bite. Dogs are the main vector of rabies in humans on Flores Island  Indonesia  resulting in about 19 human deaths each year. Currently  rabies control measures on Flores Island include mass vaccination and culling of dogs  laboratory diagnostics of suspected rabid dogs  putting imported dogs in quarantine  and pre- and post-exposure treatment (PET) of humans. The objective of this study was to estimate the costs of the applied rabies control measures on Flores Island. Methodology/principal findings A deterministic economic model was developed to calculate the costs of the rabies control measures and their individual cost components from 2000 to 2011. The inputs for the economic model were obtained from (i) relevant literature  (ii) available data on Flores Island  and (iii) experts such as responsible policy makers and veterinarians involved in rabies control measures in the past. As a result  the total costs of rabies control measures were estimated to be US$1.12 million (range: US$0.60â€“1.47 million) per year. The costs of culling roaming dogs were the highest portion  about 39 percent of the total costs  followed by PET (35 percent)  mass vaccination (24 percent)  pre-exposure treatment (1.4 percent)  and others (1.3 percent) (dog-bite investigation  diagnostic of suspected rabid dogs  trace-back investigation of human contact with rabid dogs  and quarantine of imported dogs). Conclusions/significance This study demonstrates that rabies has a large economic impact on the government and dog owners. Control of rabies by culling dogs is relatively costly for the dog owners in comparison with other measures. Providing PET for humans is an effective way to prevent rabies  but is costly for government and does not provide a permanent solution to rabies in the future. PMID:24386244Training balance with opto-kinetic stimuli in the home: a randomized controlled feasibility study in people with pure cerebellar disease.PubMedBunn  Lisa M; Marsden  Jonathan F; Giunti  Paola; Day  Brian L2015-02-01To investigate the feasibility of a randomized controlled trial of a home-based balance intervention for people with cerebellar ataxia. A randomized controlled trial design. Intervention and assessment took place in the home environment. A total of 12 people with spinocerebellar ataxia type 6 were randomized into a therapy or control group. Both groups received identical assessments at baseline  four and eight weeks. Therapy group participants undertook balance exercises in front of optokinetic stimuli during weeks 4-8  while control group participants received no intervention. Test-retest reliability was analysed from outcome measures collected twice at baseline and four weeks later. Feasibility issues were evaluated using daily diaries and end trial exit interviews. The home-based training intervention with opto-kinetic stimuli was feasible for people with pure ataxia  with one drop-out. Test-retest reliability is strong (intraclass correlation coefficient >0.7) for selected outcome measures evaluating balance at impairment and activity levels. Some measures reveal trends towards improvement for those in the therapy group. Sample size estimations indicate that Bal-SARA scores could detect a clinically significant change of 0.8 points in this functional balance score if 80 people per group were analysed in future trials. Home-based targeted training of functional balance for people with pure cerebellar ataxia is feasible and the outcome measures employed are reliable. Â© The Author(s) 2014.The simultaneous detection of trivalent & hexavalent chromium in exhaled breath condensate: A feasibility study comparing workers and controls.PubMedLeese  Elizabeth; Morton  Jackie; Gardiner  Philip H E; Carolan  Vikki A2017-04-01The analytical method outlined in this feasibility study has been used to show that trivalent chromium (Cr(III)) and hexavalent chromium (Cr(VI)) can be detected and measured in exhaled breath condensate (EBC) samples. EBC samples and urine samples were collected from a cohort of 58 workers occupationally exposed to hexavalent chromium compounds and 22 unexposed volunteers (control group). Levels of Cr(III) and Cr(VI) were determined in EBC samples and total chromium levels were determined in urine samples. Pre and post working week samples for both EBC and urine were collected in tandem. Total chromium in urine samples was analysed by inductively coupled plasma mass spectrometry (ICP-MS). Analysis of Cr(III) and Cr(VI) in EBC samples used a hyphenated micro liquid chromatography (Î¼LC) system coupled to an ICP-MS. Separation was achieved using an anion exchange micro-sized column. The results showed that the occupationally exposed workers had significantly higher levels of Cr(III) and Cr(VI) in their EBC samples than the control group  as well as higher levels of total chromium in their urine samples. However  for the exposed workers no significant difference was found between pre and post working week EBC samples for either Cr(III) or Cr(VI). This study has established that Cr(III) and Cr(VI) can simultaneously be detected and measured in 'real' EBC samples and will help in understanding inhalation exposure. Crown Copyright Â© 2016. Published by Elsevier GmbH. All rights reserved.Randomized Controlled Feasibility Trial of Intranasal Ketamine Compared to Intranasal Fentanyl for Analgesia in Children with Suspected Extremity Fractures.PubMedReynolds  Stacy L; Bryant  Kathleen K; Studnek  Jonathan R; Hogg  Melanie; Dunn  Connell; Templin  Megan A; Moore  Charity G; Young  James R; Walker  Katherine Rivera; Runyon  Michael S2017-12-01We compared the tolerability and efficacy of intranasal subdissociative ketamine to intranasal fentanyl for analgesia of children with acute traumatic pain and investigated the feasibility of a larger noninferiority trial that could investigate the potential opioid-sparing effects of intranasal ketamine. This randomized controlled trial compared 1 mg/kg intranasal ketamine to 1.5 Î¼g/kg intranasal fentanyl in children 4 to 17 years old with acute pain from suspected isolated extremity fractures presenting to an urban Level II pediatric trauma center from December 2015 to November 2016. Patients  parents  treating physicians  and outcome assessors were blinded to group allocation. The primary outcome  a tolerability measure  was the frequency of cumulative side effects and adverse events within 60 minutes of drug administration. The secondary outcomes included the difference in mean pain score reduction at 20 minutes  the proportion of patients achieving a clinically significant reduction in pain in 20 minutes  total dose of opioid pain medication in morphine equivalents/kg/hour (excluding study drug) required during the emergency department (ED) stay  and the feasibility of enrolling children presenting to the ED in acute pain into a randomized trial conducted under U.S. regulations. All patients were monitored until 6 hours after their last dose of study drug or until admission to the hospital ward or operating room. Of 629 patients screened  87 received the study drug and 82 had complete data for the primary outcome (41 patients in each group). The median (interquartile range) age was 8 (6-11) years and 62% were male. Baseline pain scores were similar among patients randomized to receive ketamine (73Â Â±Â 26) and fentanyl (69Â Â±Â 26; mean difference [95% CI]Â = 4 [-7 to 15]). The cumulative number of side effects was 2.2 times higher in the ketamine group  but there were no serious adverse events and no patients in either group required intervention. The mostFeasibility and effectiveness of a low cost campaign on antibiotic prescribing in Italy: community level  controlled  non-randomised trial.PubMedFormoso  Giulio; Paltrinieri  Barbara; Marata  Anna Maria; Gagliotti  Carlo; Pan  Angelo; Moro  Maria Luisa; Capelli  Oreste; Magrini  Nicola2013-09-12To test the hypothesis that a multifaceted  local public campaign could be feasible and influence antibiotic prescribing for outpatients. Community level  controlled  non-randomised trial. Provinces of Modena and Parma in Emilia-Romagna  northern Italy  November 2011 to February 2012. 1 150 000 residents of Modena and Parma (intervention group) and 3 250 000 residents in provinces in the same region but where no campaign had been implemented (control group). Campaign materials (mainly posters  brochures  and advertisements on local media  plus a newsletter on local antibiotic resistance targeted at doctors and pharmacists). General practitioners and paediatricians in the intervention area participated in designing the campaign messages. Primary outcome was the average change in prescribing rates of antibiotics for outpatient in five months  measured as defined daily doses per 1000 inhabitants/day  using health districts as the unit of analysis. Antibiotic prescribing was reduced in the intervention area compared with control area (-4.3%  95% confidence interval -7.1% to -1.5%). This result was robust to ""sensitivity analysis"" modifying the baseline period from two months (main analysis) to one month. A higher decrease was observed for penicillins resistant to Î² lactamase and a lower decrease for penicillins susceptible to Î² lactamase  consistent with the content of the newsletter on antibiotic resistance directed at health professionals. The decrease in expenditure on antibiotics was not statistically significant in a district level analysis with a two month baseline period (main analysis)  but was statistically significant in sensitivity analyses using either a one month baseline period or a more powered doctor level analysis. Knowledge and attitudes of the target population about the correct use of antibiotics did not differ between the intervention and control areas. A local low cost information campaign targeted at citizens  combined with a newsletter onEconomic evaluations of tobacco control mass media campaigns: a systematic reviewPubMed CentralAtusingwize  Edwinah; Lewis  Sarah; Langley  Tessa2015-01-01Background International evidence shows that mass media campaigns are effective tobacco control interventions. However  they require substantial investment; a key question is whether their costs are justified by their benefits. The aim of this study was to systematically and comprehensively review economic evaluations of tobacco control mass media campaigns. Methods An electronic search of databases and grey literature was conducted to identify all published economic evaluations of tobacco control mass media campaigns. The authors reviewed studies independently and assessed the quality of studies using the Drummond 10-point checklist. A narrative synthesis was used to summarise the key features and quality of the identified studies. Results 10 studies met the inclusion criteria and were included in the review. All the studies included a cost effectiveness analysis  a cost utility analysis or both. The methods were highly heterogeneous  particularly in terms of the types of costs included. On the whole  studies were well conducted  but the interventions were often poorly described in terms of campaign content and intensity  and cost information was frequently inadequate. All studies concluded that tobacco control mass media campaigns are a cost effective public health intervention. Conclusions The evidence on the cost effectiveness of tobacco control mass media campaigns is limited  but of acceptable quality and consistently suggests that they offer good value for money. PMID:24985730Economics of avian influenza management and control in a world with competing agendas.PubMedMcLeod  Anni2010-03-01This article explores the economic and related institutional issues at macro and micro levels  in different production systems and in different countries that influence avian influenza (AI) management and control. It does this by examining three groups of stakeholders with different agendas and concerns. For the ""international community "" the overriding driver has been and still is concern for human safety. This is reflected in the high level of contributions to emergency response programs  a strong focus on pandemic prevention and preparedness  and the pressure put on countries to develop prevention and control plans. For the most influential countries and companies in the global poultry sector  those that control the largest commercial poultry populations  trade growth and stability are major concerns. Private investment in biosecurity  reorganization of supply chains  and an increasing interest in compartments are all indications of a perceived need to secure the boundaries. Poor poultry-keeping households must focus on dayto-day livelihoods and food security  whereas small-scale commercial producers are driven by small margins and short credit cycles. Although these people operate a little differently  they have in common a necessity to focus on the short term and a limited willingness and ability to invest in their flocks. There is also very little information that we can provide either of them on financially viable ways to upgrade their enterprises. Noncompliance or partial compliance with AI regulations often makes good economic sense. Different highly pathogenic AI management and control measures are economically viable in different circumstances. The article discusses the positive and less-positive impacts created by each stakeholder perspective and the conflicts and trade-offs that can arise  and suggests some approaches for reconciling differences and thus improving AI control.Economic-Oriented Stochastic Optimization in Advanced Process Control of Chemical ProcessesPubMed CentralDobos  LÃ¡szlÃ³; KirÃ¡ly  AndrÃ¡s; Abonyi  JÃ¡nos2012-01-01Finding the optimal operating region of chemical processes is an inevitable step toward improving economic performance. Usually the optimal operating region is situated close to process constraints related to product quality or process safety requirements. Higher profit can be realized only by assuring a relatively low frequency of violation of these constraints. A multilevel stochastic optimization framework is proposed to determine the optimal setpoint values of control loops with respect to predetermined risk levels  uncertainties  and costs of violation of process constraints. The proposed framework is realized as direct search-type optimization of Monte-Carlo simulation of the controlled process. The concept is illustrated throughout by a well-known benchmark problem related to the control of a linear dynamical system and the model predictive control of a more complex nonlinear polymerization process. PMID:23213298TIGA-CUB - manualised psychoanalytic child psychotherapy versus treatment as usual for children aged 5-11 years with treatment-resistant conduct disorders and their primary carers: study protocol for a randomised controlled feasibility trial.PubMedEdginton  Elizabeth; Walwyn  Rebecca; Burton  Kayleigh; Cicero  Robert; Graham  Liz; Reed  Sadie; Tubeuf  Sandy; Twiddy  Maureen; Wright-Hughes  Alex; Ellis  Lynda; Evans  Dot; Hughes  Tom; Midgley  Nick; Wallis  Paul; Cottrell  David2017-09-15) therapeutic delivery  treatment retention and attendance  intervention adherence rates  (4) follow-up data collection  and (5) statistical  health economics  process evaluation  and qualitative outcomes. TIGA-CUB will provide important information on the feasibility and potential challenges of undertaking a confirmatory RCT to evaluate the effectiveness and cost-effectivenessÂ of mPCP. Current Controlled Trials  ID: ISRCTN86725795 . Registered on 31 May 2016.An economic evaluation of vector control in the age of a dengue vaccine.PubMedFitzpatrick  Christopher; Haines  Alexander; Bangert  Mathieu; Farlow  Andrew; Hemingway  Janet; Velayudhan  Raman2017-08-01Dengue is a rapidly emerging vector-borne Neglected Tropical Disease  with a 30-fold increase in the number of cases reported since 1960. The economic cost of the illness is measured in the billions of dollars annually. Environmental change and unplanned urbanization are conspiring to raise the health and economic cost even further beyond the reach of health systems and households. The health-sector response has depended in large part on control of the Aedes aegypti and Ae. albopictus (mosquito) vectors. The cost-effectiveness of the first-ever dengue vaccine remains to be evaluated in the field. In this paper  we examine how it might affect the cost-effectiveness of sustained vector control. We employ a dynamic Markov model of the effects of vector control on dengue in both vectors and humans over a 15-year period  in six countries: Brazil  Columbia  Malaysia  Mexico  the Philippines  and Thailand. We evaluate the cost (direct medical costs and control programme costs) and cost-effectiveness of sustained vector control  outbreak response and/or medical case management  in the presence of a (hypothetical) highly targeted and low cost immunization strategy using a (non-hypothetical) medium-efficacy vaccine. Sustained vector control using existing technologies would cost little more than outbreak response  given the associated costs of medical case management. If sustained use of existing or upcoming technologies (of similar price) reduce vector populations by 70-90%  the cost per disability-adjusted life year averted is 2013 US$ 679-1331 (best estimates) relative to no intervention. Sustained vector control could be highly cost-effective even with less effective technologies (50-70% reduction in vector populations) and in the presence of a highly targeted and low cost immunization strategy using a medium-efficacy vaccine. Economic evaluation of the first-ever dengue vaccine is ongoing. However  even under very optimistic assumptions about a highly targeted and lowAn economic evaluation of vector control in the age of a dengue vaccinePubMed CentralHaines  Alexander; Bangert  Mathieu; Farlow  Andrew; Hemingway  Janet; Velayudhan  Raman2017-01-01Introduction Dengue is a rapidly emerging vector-borne Neglected Tropical Disease  with a 30-fold increase in the number of cases reported since 1960. The economic cost of the illness is measured in the billions of dollars annually. Environmental change and unplanned urbanization are conspiring to raise the health and economic cost even further beyond the reach of health systems and households. The health-sector response has depended in large part on control of the Aedes aegypti and Ae. albopictus (mosquito) vectors. The cost-effectiveness of the first-ever dengue vaccine remains to be evaluated in the field. In this paper  we examine how it might affect the cost-effectiveness of sustained vector control. Methods We employ a dynamic Markov model of the effects of vector control on dengue in both vectors and humans over a 15-year period  in six countries: Brazil  Columbia  Malaysia  Mexico  the Philippines  and Thailand. We evaluate the cost (direct medical costs and control programme costs) and cost-effectiveness of sustained vector control  outbreak response and/or medical case management  in the presence of a (hypothetical) highly targeted and low cost immunization strategy using a (non-hypothetical) medium-efficacy vaccine. Results Sustained vector control using existing technologies would cost little more than outbreak response  given the associated costs of medical case management. If sustained use of existing or upcoming technologies (of similar price) reduce vector populations by 70â€“90%  the cost per disability-adjusted life year averted is 2013 US$ 679â€“1331 (best estimates) relative to no intervention. Sustained vector control could be highly cost-effective even with less effective technologies (50â€“70% reduction in vector populations) and in the presence of a highly targeted and low cost immunization strategy using a medium-efficacy vaccine. Discussion Economic evaluation of the first-ever dengue vaccine is ongoing. However  even under very optimisticEconomic analysis of atmospheric mercury emission control for coal-fired power plants in China.PubMedAncora  Maria Pia; Zhang  Lei; Wang  Shuxiao; Schreifels  Jeremy; Hao  Jiming2015-07-01Coal combustion and mercury pollution are closely linked  and this relationship is particularly relevant in China  the world's largest coal consumer. This paper begins with a summary of recent China-specific studies on mercury removal by air pollution control technologies and then provides an economic analysis of mercury abatement from these emission control technologies at coal-fired power plants in China. This includes a cost-effectiveness analysis at the enterprise and sector level in China using 2010 as a baseline and projecting out to 2020 and 2030. Of the control technologies evaluated  the most cost-effective is a fabric filter installed upstream of the wet flue gas desulfurization system (FF+WFGD). Halogen injection (HI) is also a cost-effective mercury-specific control strategy  although it has not yet reached commercial maturity. The sector-level analysis shows that 193 tons of mercury was removed in 2010 in China's coal-fired power sector  with annualized mercury emission control costs of 2.7 billion Chinese Yuan. Under a projected 2030 Emission Control (EC) scenario with stringent mercury limits compared to Business As Usual (BAU) scenario  the increase of selective catalytic reduction systems (SCR) and the use of HI could contribute to 39 tons of mercury removal at a cost of 3.8 billion CNY. The economic analysis presented in this paper offers insights on air pollution control technologies and practices for enhancing atmospheric mercury control that can aid decision-making in policy design and private-sector investments. Copyright Â© 2015. Published by Elsevier B.V.Demand Controlled Economizer Cycles: A Direct Digital Control Scheme for Heating  Ventilating  and Air Conditioning Systems DTIC Science & Technology1984-05-01Control Ignored any error of 1/10th degree or less. This was done by setting the error term E and the integral sum PREINT to zero If then absolute value of...signs of two errors jeq tdiff if equal  jump clr @preint else zero integal sum tdiff mov @diff rl fetch absolute value of OAT-RAT ci rl 25 is...includes a heating coil and thermostatic control to maintain the air in this path at an elevated temperature  typically around 80 degrees Farenheit (80 FVibrating vaginal balls to improve pelvic floor muscle performance in women after childbirth: a protocol for a randomised controlled feasibility trial.PubMedOblasser  Claudia; McCourt  Christine; Hanzal  Engelbert; Christie  Janice2016-04-01This paper presents a feasibility trial protocol the purpose of which is to prepare for a future randomised controlled trial to determine the effectiveness of vibrating vaginal pelvic floor training balls for postpartum pelvic floor muscle rehabilitation. Vibrating vaginal pelvic floor training balls are available in Austria to enhance women's pelvic floor muscles and thus prevent or treat urinary incontinence and other pelvic floor problems following childbirth. Nonetheless  there is currently little empirical knowledge to substantiate their use or assess their relative effectiveness in comparison to current standard care  which involves pelvic floor muscle exercises. Single blind  randomised controlled feasibility trial with two parallel groups. It is planned to recruit 56 postpartum women in Vienna  who will be randomised into one of two intervention groups to use either vibrating vaginal balls or a comparator pelvic floor muscle exercises for 12Â weeks. As this is a feasibility study  study design features (recruitment  selection  randomisation  intervention concordance  data collection methods and tools) will be assessed and participants' views and experiences will be surveyed. Tested outcome measures  collected before and after the intervention  will be pelvic floor muscle performance as reported by participants and measured by perineometry. Descriptive and inferential statistics and content analysis will serve the preparation of the future trial. The results of this feasibility trial will inform the design and conduct of a full randomised controlled trial and provide insight into the experiences of women regarding the interventions and study participation. Â© 2015 John Wiley & Sons Ltd.Internet remote control of pump settings for postoperative continuous peripheral nerve blocks: a feasibility study in 59 patients.PubMedMacaire  P; Nadhari  M; Greiss  H; Godwin  A; Elhanfi  O; Sainudeen  S; Abdul  M; Capdevila  X2014-01-01During continuous peripheral nerve blocks  infusion adjustments are essential for postoperative analgesia without side effects. Beside  physicians and nurse visits related to pump's settings and monitoring are time consuming and costly. We hypothesized that a remote control of pump's settings  by telemedicine transmission  adjusted to patients' feedbacks  is feasible and interesting in optimizing patient's postoperative pain management. Fifty-nine ASA physical status I and II patients were included. Ropivacaine 0.2% was infused during 72 h in CPNB catheters. After returning to the surgical ward  the patient was allowed to answer a 10 indicators questionnaire 3 times a day (8.00 AM  2.00 PM  8.00 PM)  or unlimited on patient's demand. This information was transmitted from the pump to a server through the Internet. If one indicator was out of the predefined thresholds  the anesthesiologist in charge was immediately informed by texto on his cell phone. The anesthesiologist connected to the website  checked the data from the patient and modified the settings of the pump by remote control according to a written protocol. The changes need a secure access with a password and a confirmation. The number of settings changes  the time to realize the procedure and the adverse events related to the technique were noted. When the catheter was removed  the pump was unassigned to the patient and the data archived. Thirty sciatic  24 femoral and 5 interscalene catheters were inserted in 59 patients. Five catheters were accidentally removed before the end of the 72-h period. The median VAS pain values at rest and during movement were respectively at 2 and 3. Sixteen patients complained about numbness promoting 2 (0-3) changes in pump settings; 9 about motor blockade with 1 (0-2) change; 5 about difficulties for physiotherapy with 1 (0-3) change. The mean time of pump settings modification after response to questionnaire or voluntarily patient's alert was 15 Â± 2.2 minutes. EarlyEconomic evaluation of factorial randomised controlled trials: challenges  methods and recommendationsPubMed CentralGray  Alastair2017-01-01Increasing numbers of economic evaluations are conducted alongside randomised controlled trials. Such studies include factorial trials  which randomise patients to different levels of two or more factors and can therefore evaluate the effect of multiple treatments alone and in combination. Factorial trials can provide increased statistical power or assess interactions between treatments  but raise additional challenges for trialâ€based economic evaluations: interactions may occur more commonly for costs and qualityâ€adjusted lifeâ€years (QALYs) than for clinical endpoints; economic endpoints raise challenges for transformation and regression analysis; and both factors must be considered simultaneously to assess which treatment combination represents best value for money. This article aims to examine issues associated with factorial trials that include assessment of costs and/or costâ€effectiveness  describe the methods that can be used to analyse such studies and make recommendations for health economists  statisticians and trialists. A hypothetical worked example is used to illustrate the challenges and demonstrate ways in which economic evaluations of factorial trials may be conducted  and how these methods affect the results and conclusions. Ignoring interactions introduces bias that could result in adopting a treatment that does not make best use of healthcare resources  while considering all interactions avoids bias but reduces statistical power. We also introduce the concept of the opportunity cost of ignoring interactions as a measure of the bias introduced by not taking account of all interactions. We conclude by offering recommendations for planning  analysing and reporting economic evaluations based on factorial trials  taking increased analysis costs into account. Â© 2017 The Authors. Statistics in Medicine published by John Wiley & Sons Ltd. PMID:28470760Economic feasibility of biochemical processes for the upgrading of crudes and the removal of sulfur  nitrogen  and trace metals from crude oil -- Benchmark cost establishment of biochemical processes on the basis of conventional downstream technologies. Final report FY95SciTech ConnectPremuzic  E.T.1996-08-01During the past several years  a considerable amount of work has been carried out showing that microbially enhanced oil recovery (MEOR) is promising and the resulting biotechnology may be deliverable. At Brookhaven National Laboratory (BNL)  systematic studies have been conducted which dealt with the effects of thermophilic and thermoadapted bacteria on the chemical and physical properties of selected types of crude oils at elevated temperatures and pressures. Current studies indicate that during the biotreatment several chemical and physical properties of crude oils are affected. The oils are (1) emulsified; (2) acidified; (3) there is a qualitative and quantitative change inmoreÂ Â» light and heavy fractions of the crudes; (4) there are chemical changes in fractions containing sulfur compounds; (5) there is an apparent reduction in the concentration of trace metals; and (6) the qualitative and quantitative changes appear to be microbial species dependent; and (7) there is a distinction between biodegraded and biotreated oils. The downstream biotechnological crude oil processing research performed thus far is of laboratory scale and has focused on demonstrating the technical feasibility of downstream processing with different types of biocatalysts under a variety of processing conditions. Quantitative economic analysis is the topic of the present project which investigates the economic feasibility of the various biochemical downstream processes which hold promise in upgrading of heavy crudes  such as those found in California  e.g.  Monterey-type  Midway Sunset  Honda crudes  and others.Â«Â lessEconomic modeling of fault tolerant flight control systems in commercial applicationsNASA Technical Reports Server (NTRS)Finelli  G. B.1982-01-01This paper describes the current development of a comprehensive model which will supply the assessment and analysis capability to investigate the economic viability of Fault Tolerant Flight Control Systems (FTFCS) for commercial aircraft of the 1990's and beyond. An introduction to the unique attributes of fault tolerance and how they will influence aircraft operations and consequent airline costs and benefits is presented. Specific modeling issues and elements necessary for accurate assessment of all costs affected by ownership and operation of FTFCS are delineated. Trade-off factors are presented  aimed at exposing economically optimal realizations of system implementations  resource allocation  and operating policies. A trade-off example is furnished to graphically display some of the analysis capabilities of the comprehensive simulation model now being developed.Feasibility and limits of inguinal hernia repair under local anaesthesia in a limited resource environment: a prospective controlled study.PubMedBourgouin  S; Goudard  Y; Montcriol  A; Bordes  J; Nau  A; Balandraud  P2017-10-01Local anaesthesia (LA) has proven effective for inguinal hernia repair in developed countries. Hernias in low to middle income countries represent a different issue. The aim of this study was to analyse the feasibility of LA for African hernia repairs in a limited resource environment. Data from patients who underwent herniorrhaphy under LA or spinal anaesthesia (SA) by the 6th and 7th Forward Surgical Team were prospectively collected. All of the patients benefited from a transversus abdominis plane (TAP) block for postoperative analgesia. Primary endpoints concerned the pain response and conversion to general anaesthesia. Secondary endpoints concerned the complication and recurrence rates. Predictors of LA failure were then identified. In all  189 inguinal hernias were operated during the study period  and 119 patients fulfilled the inclusion criteria: 57 LA and 62 SA. Forty-eight percent of patients presented with inguinoscrotal hernias. Local anaesthesia led to more pain during surgery and necessitated more administration of analgesics but resulted in fewer micturition difficulties and better postoperative pain control. Conversion rates were not different. Inguinoscrotal hernia and a time interval <50Â min between the TAP block and skin incision were predictors of LA failure. Forty-four patients were followed-up at one month. No recurrence was noted. Local anaesthesia is a safe alternative to SA. Small or medium hernias can easily be performed under LA in rural centres  but inguinoscrotal hernias required an ultrasound-guided TAP block performed 50 min before surgery to achieve optimal analgesia  and should be managed only in centres equipped with ultrasonography.BTS randomised feasibility study of active symptom control with or without chemotherapy in malignant pleural mesothelioma: ISRCTN 54469112.PubMedMuers  M F; Rudd  R M; O'Brien  M E R; Qian  W; Hodson  A; Parmar  M K B; Girling  D J2004-02-01The incidence of mesothelioma is rising rapidly in the UK. There is no generally accepted standard treatment. The BTS recommends active symptom control (ASC). It is not known whether chemotherapy in addition prolongs survival or provides worthwhile palliation with acceptable toxicity. Palliation as recorded by patients has been fully reported for only two regimens: mitomycin  vinblastine  and cisplatin (MVP)  and vinorelbine (N). The BTS and collaborators planned to conduct a phase III randomised trial comparing ASC only  ASC+MVP  and ASC+N in 840 patients with survival as the primary outcome measure. The aim of the present study was to assess the acceptability of the trial design to patients and the suitability of two standard quality of life (QL) questionnaires for mesothelioma. Collaborating centres registered all new patients with mesothelioma. Those eligible and giving informed consent completed EORTC QLQ-C30+LC13 and FACT-L QL questionnaires and were randomised between all three or any two of (1) ASC only  (2) ASC+4 cycles of MVP  and (3) ASC+12 weekly doses of N. During 1 year  242 patients were registered of whom 109 (45%) were randomised (55% of the 197 eligible patients). Fifty two patients from 20 centres were randomised to an option including ASC only. This translates into a rate of 312 per year from 60 centres interested in collaborating in the phase III trial. The EORTC QL questionnaire was superior to FACT-L in terms of completeness of data and patient preference. Clinically relevant palliation was achieved with ASC. The planned phase III trial is feasible.Economic consequences of paratuberculosis control in dairy cattle: A stochastic modeling study.PubMedSmith  R L; Al-Mamun  M A; GrÃ¶hn  Y T2017-03-01The cost of paratuberculosis to dairy herds  through decreased milk production  early culling  and poor reproductive performance  has been well-studied. The benefit of control programs  however  has been debated. A recent stochastic compartmental model for paratuberculosis transmission in US dairy herds was modified to predict herd net present value (NPV) over 25 years in herds of 100 and 1000 dairy cattle with endemic paratuberculosis at initial prevalence of 10% and 20%. Control programs were designed by combining 5 tests (none  fecal culture  ELISA  PCR  or calf testing)  3 test-related culling strategies (all test-positive  high-positive  or repeated positive)  2 test frequencies (annual and biannual)  3 hygiene levels (standard  moderate  or improved)  and 2 cessation decisions (testing ceased after 5 negative whole-herd tests or testing continued). Stochastic dominance was determined for each herd scenario; no control program was fully dominant for maximizing herd NPV in any scenario. Use of the ELISA test was generally preferred in all scenarios  but no paratuberculosis control was highly preferred for the small herd with 10% initial prevalence and was frequently preferred in other herd scenarios. Based on their effect on paratuberculosis alone  hygiene improvements were not found to be as cost-effective as test-and-cull strategies in most circumstances. Global sensitivity analysis found that economic parameters  such as the price of milk  had more influence on NPV than control program-related parameters. We conclude that paratuberculosis control can be cost effective  and multiple control programs can be applied for equivalent economic results. Copyright Â© 2017 Elsevier B.V. All rights reserved.Active Control of Fan Noise: Feasibility Study. Volume 3; Active Fan Noise Cancellation in the NASA Lewis Active Noise Control Fan FacilityNASA Technical Reports Server (NTRS)Pla  Frederic G.; Hu  Ziqiang; Sutliff  Daniel L.1996-01-01This report describes the Active Noise Cancellation (ANC) System designed by General Electric and tested in the NASA Lewis Research Center's (LERC) 48 inch Active Noise Control Fan (ANCF). The goal of this study is to assess the feasibility of using wall mounted secondary acoustic sources and sensors within the duct of a high bypass turbofan aircraft engine for global active noise cancellation of fan tones. The GE ANC system is based on a modal control approach. A known acoustic mode propagating in the fan duct is canceled using an array of flush-mounted compact sound sources. The canceling modal signal is generated by a modal controller. Inputs to the controller are signals from a shaft encoder and from a microphone array which senses the residual acoustic mode in the duct. The key results are that the (6 0) was completely eliminated at the 920 Hz design frequency and substantially reduced elsewhere. The total tone power was reduced 6.8 dB (out of a possible 9.8 dB). Farfield reductions of 15 dB (SPL) were obtained. The (4 0) and (4 1) modes were reduced simultaneously yielding a 15 dB PWL decrease. The results indicate that global attenuation of PWL at the target frequency was obtained in the aft quadrant using an ANC actuator and sensor system totally contained within the duct. The quality of the results depended on precise mode generation. High spillover into spurious modes generated by the ANC actuator array caused less than optimum levels of PWL reduction. The variation in spillover is believed to be due to calibration procedure  but must be confirmed in subsequent tests.Economical launching and accelerating control strategy for a single-shaft parallel hybrid electric busNASA Astrophysics Data System (ADS)Yang  Chao; Song  Jian; Li  Liang; Li  Shengbo; Cao  Dongpu2016-08-01This paper presents an economical launching and accelerating mode  including four ordered phases: pure electrical driving  clutch engagement and engine start-up  engine active charging  and engine driving  which can be fit for the alternating conditions and improve the fuel economy of hybrid electric bus (HEB) during typical city-bus driving scenarios. By utilizing the fast response feature of electric motor (EM)  an adaptive controller for EM is designed to realize the power demand during the pure electrical driving mode  the engine starting mode and the engine active charging mode. Concurrently  the smoothness issue induced by the sequential mode transitions is solved with a coordinated control logic for engine  EM and clutch. Simulation and experimental results show that the proposed launching and accelerating mode and its control methods are effective in improving the fuel economy and ensure the drivability during the fast transition between the operation modes of HEB.Maximum Power Point tracking charge controllers for telecom applications -- Analysis and economicsSciTech ConnectWills  R.H.Simple charge controllers connect photovoltaic modules directly to the battery bank resulting in a significant power loss if the battery bank voltage differs greatly from the PV Maximum Power Point (MPP) voltage. Recent modeling work at AES has shown that dc-dc converter type MPP tracking charge controllers can deliver more than 30% more energy from PV modules to the battery when the PV modules are cool and the battery state of charge is low--this is typically both the worst case condition (i.e.  winter) and also the design condition that determines the PV array size. Economic modeling  based on typical telecommoreÂ Â» system installed costs shows benefits of more than $3/Wp for MPPT over conventional charge controllers in this application--a value that greatly exceeds the additional cost of the dc-dc converter.Â«Â lessImprovement of Insulin Sensitivity by Isoenergy High Carbohydrate Traditional Asian Diet: A Randomized Controlled Pilot Feasibility StudyPubMed CentralHsu  William C.; Lau  Ka Hei Karen; Matsumoto  Motonobu; Moghazy  Dalia; Keenan  Hillary; King  George L.2014-01-01The prevalence of diabetes is rising dramatically among Asians  with increased consumption of the typical Western diet as one possible cause. We explored the metabolic responses in East Asian Americans (AA) and Caucasian Americans (CA) when transitioning from a traditional Asian diet (TAD) to a typical Western diet (TWD)  which has not been reported before. This 16-week randomized control pilot feasibility study  included 28AA and 22CA who were at risk of developing type 2 diabetes. Eight weeks of TAD were provided to all participants  followed by 8 weeks of isoenergy TWD (intervention) or TAD (control). Anthropometric measures  lipid profile  insulin resistance and inflammatory markers were assessed. While on TAD  both AA and CA improved in insulin AUC (âˆ’960.2 ÂµU/mLÃ—h  Pâ€Š=â€Š0.001) and reduced in weight (âˆ’1.6 kg; P<0.001)  body fat (âˆ’1.7%  P<0.001) and trunk fat (âˆ’2.2%  P<0.001). Comparing changes from TAD to TWD  AA had a smaller weight gain (âˆ’1.8 to 0.3 kg  P<0.001) than CA (âˆ’1.4 to 0.9 kg  Pâ€Š=â€Š0.001)  but a greater increase in insulin AUC (AA: âˆ’1402.4 to 606.2 ÂµU/mLÃ—h  Pâ€Š=â€Š0.015 vs CA: âˆ’466.0 to 223.5 ÂµU/mLÃ—h  Pâ€Š=â€Š0.034) and homeostatic static model assessment-insulin resistance (HOMA-IR) (AA: âˆ’0.3 to 0.2  Pâ€Š=â€Š0.042 vs CA: âˆ’0.1 to 0.0  Pâ€Š=â€Š0.221). Despite efforts to maintain isoenergy state and consumption of similar energy  TAD induced weight loss and improved insulin sensitivity in both groups  while TWD worsened the metabolic profile. Trial Registration: ClinicalTrials.gov NCT00379548 PMID:25226279Can paramedics use FRAX (the WHO Fracture Risk Assessment Tool) to help GPs improve future fracture risk in patients who fall? Protocol for a randomised controlled feasibility study.PubMedClarke  Shane; Bradley  Rachel; Simmonds  Bethany; Salisbury  Chris; Benger  Jonathan; Marques  Elsa; Greenwood  Rosemary; Shepstone  Lee; Robinson  Maria; Appleby-Fleming  John; Gooberman-Hill  Rachael2014-09-03Currently identification  and therefore  management of patients at risk of osteoporotic fracture in the UK is suboptimal. As the majority of patients who fracture have fallen  it follows that people who fall can usefully be targeted in any programme that aims to reduce osteoporotic fracture. Targeting vulnerable patients who are likely to benefit from intervention may help shift the management of fracture prevention into primary care  away from emergency departments. Paramedics who attend to patients who have fallen may be well placed to assess future fracture risk  using the Fracture Risk Assessment Tool (FRAX) and communicate that information directly to general practitioners (GPs). This feasibility study takes the form of a pragmatic  randomised controlled trial aimed at exploring and refining issues of study design  recruitment  retention  sample size and acceptability preceding a large-scale study with fracture as the end point. Patients (aged >50) who fall  call an ambulance  are attended by a study paramedic and give verbal consent will be asked FRAX and fall questions. Patients who subsequently formally consent to participation will be randomised to control (usual care) or intervention groups. Intervention will constitute transmission of calculated future fracture risk to the patients' GP with suitable  evidence-based recommendations for investigation or treatment. 3 months after the index fall  data (proportion of patients in each group undergoing investigation or starting new treatment  quality of life and health economic) will be collected and analysed using descriptive statistics. A nested qualitative study will explore issues of acceptability and study design with patients  paramedics and GPs. This protocol was approved by NRES Committee South Central Oxford C in October 2012. Research Ethics Committee ref.12/SC/0604. The study findings will be disseminated through peer-reviewed journals  conference presentations and local public events. A publicationGeologic and hydrologic controls on the economic potential of hydrothermal systems associated with upper crustal plutonsNASA Astrophysics Data System (ADS)Weis  Philipp; Driesner  Thomas; Scott  Samuel; Lecumberri-Sanchez  Pilar2016-04-01Heat and mass transport in hydrothermal systems associated with upper crustal magmatic intrusions can result in resources with large economic potential (Kesler  1994). Active hydrothermal systems can form high-enthalpy geothermal reservoirs with the possibility for renewable energy production. Fossil continental or submarine hydrothermal systems may have formed ore deposits at variable crustal depths  which can be mined near today's surface with an economic profit. In both cases  only the right combination of first-order geologic and hydrologic controls may lead to the formation of a significant resource. To foster exploration for these hydrothermal georesources  we need to improve our understanding of subsurface fluxes of mass and energy by combining numerical process modelling  observations at both active and fossil systems  as well as knowledge of fluid and rock properties and their interactions in natural systems. The presentation will highlight the role of non-linear fluid properties  phase separation  salt precipitation  fluid mixing  permeability structure  hydraulic fracturing and the transition from brittle to ductile rock behavior as major geologic and hydrologic controls on the formation of high-enthalpy and supercritical geothermal resources (Scott et al.  2015)  and magmatic-hydrothermal mineral resources  such as porphyry copper  massive sulfide and epithermal gold deposits (Lecumberri-Sanchez et al.  2015; Weis  2015). References: Kesler  S. E.  1994: Mineral Resources  economics and the environment  New York  McMillan  391. Lecumberri-Sanchez  P.  Steele-MacInnis  M.  Weis  P.  Driesner  T.  Bodnar  R.J. (2015): Salt precipitation in magmatic-hydrothermal systems associated with upper crustal plutons. Geology  v. 43  p. 1063-1066  doi:10.1130/G37163.1 Scott  S.  Driesner  T.  Weis  P. (2015): Geologic controls on supercritical geothermal resources above magmatic intrusions. Nature Communications  6:7837 doi: 10.1038/ncomms8837 Weis  P. (2015): The[Economic assessment in health and environment from control of persistent organic pollutants in Colombia].PubMedGarcÃ­a-Ubaque  CÃ©sar A; GarcÃ­a-Ubaque  Juan C; Vaca-BohÃ³rquez  Martha L2015-12-01Objective To estimate the economic benefits related to environment and health in the context of the implementation of the Stockholm Convention for the control of Persistent Organic Pollutants in the country. The estimation was conducted based on two scenarios: non-compliance with the agreement and compliance with the Convention. Gross profit was derived from the difference in present value between the health and environmental costs that are assumed in each scenario. Results Gross profit by decreasing health costs arising from the implementation of the Convention was estimated at USD $ 511 and USD $ 501 million. By introducing variables such as management costs and agreement on potential benefits for access to international markets  the benefits to the country were estimated at between USD $1 631 and USD $ 3 118 million. Discussion Despite the economic benefits generated by lower expenditure on health for the Convention implementation  the costs associated with reducing pollutant emissions generated a negative balance  compensated only by the expectation of higher revenues for international market access. We consider this initial economic assessment an important contribution  but it should be reviewed to include valuation methodologies involving other social profitability variables and different scenarios for emerging technologies  new scientific knowledge about these pollutants  changes in legislation and / or changes in trade agreement conditions  among others.Feasibility and Effectiveness of a Web-Based Positive Psychology Program for Youth Mental Health: Randomized Controlled TrialPubMed CentralHorswood  Deserae; Burckhardt  Rowan; Lum  Alistair; Hadzi-Pavlovic  Dusan; Parker  Gordon2014-01-01Background Youth mental health is a significant public health concern due to the high prevalence of mental health problems in this population and the low rate of those affected seeking help. While it is increasingly recognized that prevention is better than cure  most youth prevention programs have utilized interventions based on clinical treatments (eg  cognitive behavioral therapy) with inconsistent results. Objective This study explores the feasibility of the online delivery of a youth positive psychology program  Bite Back  to improve the well-being and mental health outcomes of Australian youth. Further aims were to examine rates of adherence and attrition  and to investigate the programâ€™s acceptability. Methods Participants (N=235) aged 12-18 years were randomly assigned to either of two conditions: Bite Back (n=120) or control websites (n=115). The Bite Back website comprised interactive exercises and information across a variety of positive psychology domains; the control condition was assigned to neutral entertainment-based websites that contained no psychology information. Participants in both groups were instructed to use their allocated website for 6 consecutive weeks. Participants were assessed pre- and postintervention on the Depression Anxiety Stress Scale-Short form (DASS-21) and the Short Warwick-Edinburgh Mental Well-Being Scale (SWEMWBS). Results Of the 235 randomized participants  154 (65.5%) completed baseline and post measures after 6 weeks. Completers and dropouts were equivalent in demographics  the SWEMWBS  and the depression and anxiety subscales of the DASS-21  but dropouts reported significantly higher levels of stress than completers. There were no differences between the Bite Back and control conditions at baseline on demographic variables  DASS-21  or SWEMWBS scores. Qualitative data indicated that 49 of 61 Bite Back users (79%) reported positive experiences using the website and 55 (89%) agreed they would continue to use it afterFeasibility and effectiveness of a web-based positive psychology program for youth mental health: randomized controlled trial.PubMedManicavasagar  Vijaya; Horswood  Deserae; Burckhardt  Rowan; Lum  Alistair; Hadzi-Pavlovic  Dusan; Parker  Gordon2014-06-04Youth mental health is a significant public health concern due to the high prevalence of mental health problems in this population and the low rate of those affected seeking help. While it is increasingly recognized that prevention is better than cure  most youth prevention programs have utilized interventions based on clinical treatments (eg  cognitive behavioral therapy) with inconsistent results. This study explores the feasibility of the online delivery of a youth positive psychology program  Bite Back  to improve the well-being and mental health outcomes of Australian youth. Further aims were to examine rates of adherence and attrition  and to investigate the program's acceptability. Participants (N=235) aged 12-18 years were randomly assigned to either of two conditions: Bite Back (n=120) or control websites (n=115). The Bite Back website comprised interactive exercises and information across a variety of positive psychology domains; the control condition was assigned to neutral entertainment-based websites that contained no psychology information. Participants in both groups were instructed to use their allocated website for 6 consecutive weeks. Participants were assessed pre- and postintervention on the Depression Anxiety Stress Scale-Short form (DASS-21) and the Short Warwick-Edinburgh Mental Well-Being Scale (SWEMWBS). Of the 235 randomized participants  154 (65.5%) completed baseline and post measures after 6 weeks. Completers and dropouts were equivalent in demographics  the SWEMWBS  and the depression and anxiety subscales of the DASS-21  but dropouts reported significantly higher levels of stress than completers. There were no differences between the Bite Back and control conditions at baseline on demographic variables  DASS-21  or SWEMWBS scores. Qualitative data indicated that 49 of 61 Bite Back users (79%) reported positive experiences using the website and 55 (89%) agreed they would continue to use it after study completion. Compared to the",operational feasibility, 'Personal computer',https://www.science.gov/topicpages/e/economic%2Bfeasibility%2Bcontrol,'hendrie computer'
" Free content  libre content  or free information  is any kind of functional work  work of art  or other creative content that meets the definition of a free cultural work.[1]A free cultural work (free content) is  according to the definition of Free Cultural Works  one that has no significant legal restriction on people's freedom to: Free content encompasses all works in the public domain and also those copyrighted works whose licenses honor and uphold the freedoms mentioned above. Because the Berne Convention in most countries by default grants copyright holders monopolistic control over their creations  copyright content must be explicitly declared free  usually by the referencing or inclusion of licensing statements from within the work. Although there are a great many different definitions in regular everyday use  free content is legally very similar  if not like an identical twin  to open content. An analogy is the use of the rival terms free software and open source  which describe ideological differences rather than legal ones.[3][4][5] For instance  the Open Knowledge Foundation's Open Definition describes ""open"" as synonymous to the definition of free in the ""Definition of Free Cultural Works"" (as also in the Open Source Definition and Free Software Definition).[6] For such free/open content both movements recommend the same three Creative Commons licenses  the CC BY  CC BY-SA  and CC0.[7][8][9][10]Copyright is a legal concept  which gives the author or creator of a work legal control over the duplication and public performance of his or her work. In many jurisdictions  this is limited by a time period after which the works then enter the public domain. Copyright laws are a balance between the rights of creators of intellectual and artistic works and the rights of others to build upon those works. During the time period of copyright the author's work may only be copied  modified  or publicly performed with the consent of the author  unless the use is a fair use. Traditional copyright control limits the use of the work of the author to those who either pay royalties to the author for usage of the authors content  or limit their use to fair use. Secondly it limits the use of content whose author cannot be found.[11] Finally it creates a perceived barrier between authors by limiting derivative works  such as mashups and collaborative content[12]The public domain is a range of creative works whose copyright has expired  or was never established; as well as ideas and facts[nb 1] which are ineligible for copyright. A public domain work is a work whose author has either relinquished to the public  or no longer can claim control over  the distribution and usage of the work. As such any person may manipulate  distribute  or otherwise utilize the work  without legal ramifications. A work in the public domain or released under a permissive licence may be referred to as ""copycenter"".[13]Copyleft is a play on the word copyright and describes the practice of using copyright law to remove restrictions on distributing copies and modified versions of a work.[14] The aim of copyleft is to use the legal framework of copyright to enable non-author parties to be able to reuse and  in many licensing schemes  modify content that is created by an author. Unlike works in the public domain  the author still maintains copyright over the material  however the author has granted a non-exclusive license to any person to distribute  and often modify  the work. Copyleft licenses require that any derivative works be distributed under the same terms  and that the original copyright notices be maintained. A symbol commonly associated with copyleft is a reversal of the copyright symbol  facing the other way; the opening of the C points left rather than right. Unlike the copyright symbol  the copyleft symbol does not have a codified meaning.[15]Projects that provide free content exist in several areas of interest  such as software  academic literature  general literature  music  images  video  and engineering. Technology has reduced the cost of publication and reduced the entry barrier sufficiently to allow for the production of widely disseminated materials by individuals or small groups. Projects to provide free literature and multimedia content have become increasingly prominent owing to the ease of dissemination of materials that is associated with the development of computer technology. Such dissemination may have been too costly prior to these technological developments. In media  which includes textual  audio  and visual content  free licensing schemes such as some of the licenses made by Creative Commons have allowed for the dissemination of works under a clear set of legal permissions. Not all of the Creative Commons’ licenses are entirely free: their permissions may range from very liberal general redistribution and modification of the work to a more restrictive redistribution-only licensing. Since February 2008  Creative Commons licenses which are entirely free carry a badge indicating that they are ""approved for free cultural works"".[16] Repositories exist which exclusively feature free material and provide content such as photographs  clip art  music [17] and literature .[18] While extensive reuse of free content from one website in another website is legal  it is usually not sensible because of the duplicate content problem. Wikipedia is amongst the most well known databases of user uploaded free content on the web. While the vast majority of content on Wikipedia is free content  some copyrighted material is hosted under Fair-use criteria. Free and open-source software  which is also often referred to as open source software and free software  is a maturing technology with major companies utilising free software to provide both services and technology to both end users and technical consumers. The ease of dissemination has allowed for increased modularity  which allows for smaller groups to contribute to projects as well as simplifying collaboration. Open source development models have been classified as having a similar peer-recognition and collaborative benefit incentives that are typified by more classical fields such as scientific research  with the social structures that result from this incentive model decreasing production cost.[19] Given sufficient interest in a software component  by using peer-to-peer distribution methods  distribution costs of software may be reduced  removing the burden of infrastructure maintenance from developers. As distribution resources are simultaneously provided by consumers  these software distribution models are scalable  that is the method is feasible regardless of the number of consumers. In some cases  free software vendors may use peer-to-peer technology as a method of dissemination.[20] In general  project hosting and code distribution is not a problem for the most of free projects as a number of providers offer them these services free. Free content principles have been translated into fields such as engineering  where designs and engineering knowledge can be readily shared and duplicated  in order to reduce overheads associated with project development. Open design principles can be applied in engineering and technological applications  with projects in mobile telephony  small-scale manufacture [21] the automotive industry [22][23] and even agricultural areas.[24] Technologies such as distributed manufacturing can allow computer-aided manufacturing and computer-aided design techniques to be able to develop small-scale production of components for the development of new  or repair of existing  devices. Rapid fabrication technologies underpin these developments  which allow end users of technology to be able to construct devices from pre-existing blueprints  using software and manufacturing hardware to convert information into physical objects. In academic work  the majority of works are not free  although the percentage of works that are open access is growing rapidly. Open access refers to online research outputs that are free of all restrictions on access (e.g. access tolls) and free of many restrictions on use (e.g. certain copyright and license restrictions).[25] Authors may see open access publishing as a method of expanding the audience that is able to access their work to allow for greater impact of the publication  or may support it for ideological reasons.[26][27][28] Open access publishers such as PLOS and Biomed Central provide capacity for review and publishing of free works; though such publications are currently more common in science than humanities. Various funding institutions and governing research bodies have mandated that academics must produce their works to be open-access  in order to qualify for funding  such as the National Institutes of Health   RCUK (effective 2016) and the EU (effective 2020).[29][30][31][32] At an institutional level some universities  such as the Massachusetts Institute of Technology (MIT)  have adopted open access publishing by default by introducing their own mandates.[33] Some mandates may permit delayed publication and may charge researchers for open access publishing.[34][35]Open content publication has been seen as a method of reducing costs associated with information retrieval in research  as universities typically pay to subscribe for access to content that is published through traditional means[10][36][37] whilst improving journal quality by discouraging the submission of research articles of reduced quality.[10] Subscriptions for non-free content journals may be expensive for universities to purchase  though the article are written and peer-reviewed by academics themselves at no cost to the publisher. This has led to disputes between publishers and some universities over subscription costs  such as the one which occurred between the University of California and the Nature Publishing Group.[38][39] For teaching purposes  some universities  including MIT  provide freely available course content  such as lecture notes  video resources and tutorials. This content is distributed via Internet resources to the general public. Publication of such resources may be either by a formal institution-wide program [40] or alternately via informal content provided by individual academics or departments. Any country has its own law and legal system  sustained by its legislation  a set of law-documents — documents containing statutory obligation rules  usually law and created by legislatures.  In a democratic country  each law-document is published as open media content  is in principle a free content; but in general there are no explicit license attributed for each law-document  so the license must be interpreted  is a implied license. Only few countries have explicit licenses in its law-documents  as the UK's Open Government Licence (a CC-BY compatible license). In the other countries  the implied license comes from its proper rules (general laws and rules about copyright in government works). The automatic protection provided by Berne Convention not apply to law-documents: Article 2.4 excludes the official texts from the automatic protection. It is also possible to ""inherit"" the license from context. The set of country's law-documents is made available through national repositories. Examples of law-document open repositories: LexML Brazil  Legislation.gov.uk  N-Lex of EU countries. In general a law-document is offered in more than one (open) official version  but the main one is that published by a government gazette. So  law-documents can eventually inherit license expressed by the repository or by the gazette that contains it. ",public domain software, 'Personal computer',https://en.wikis.website/wiki/Free_content,'hendrie computer'
"Guidance for Quality Assurance Project Plans  EPA QA/G-5EPA Pesticide Factsheetsprovides guidance to EPA employees and other organizations involved in developing Quality Assurance (QA) Project Plans that address the specifications listed in EPA Requirements for QA Project Plans (QA/R-5)MoniQA: a general approach to monitor quality assuranceNASA Astrophysics Data System (ADS)Jacobs  J.; Deprez  T.; Marchal  G.; Bosmans  H.2006-03-01MoniQA (""Monitor Quality Assurance"") is a new  non-commercial  independent quality assurance software application developed in our medical physics team. It is a complete Java TM - based modular environment for the evaluation of radiological viewing devices and it thus fits in the global quality assurance network of our (film less) radiology department. The purpose of the software tool is to guide the medical physicist through an acceptance protocol and the radiologist through a constancy check protocol by presentation of the necessary test patterns and by automated data collection. Data are then sent to a central management system for further analysis. At the moment more than 55 patterns have been implemented  which can be grouped in schemes to implement protocols (i.e. AAPMtg18  DIN and EUREF). Some test patterns are dynamically created and 'drawn' on the viewing device with random parameters as is the case in a recently proposed new pattern for constancy testing. The software is installed on 35 diagnostic stations (70 monitors) in a film less radiology department. Learning time was very limited. A constancy check -with the new pattern that assesses luminance decrease  resolution problems and geometric distortion- takes only 2 minutes and 28 seconds per monitor. The modular approach of the software allows the evaluation of new or emerging test patterns. We will report on the software and its usability: practicality of the constancy check tests in our hospital and on the results from acceptance tests of viewing stations for digital mammography.THE IMPORTANCE OF A SUCCESSFUL QUALITY ASSURANCE (QA) PROGRAM FROM A RESEARCH MANAGER'S PERSPECTIVEEPA Science InventoryThe paper discusses the Air Pollution Prevention and Control Division's Quality Assurance (QA) program and the approaches used to meet QA requirements in the Division. The presentation is a technical manager's perspective of the Division's requirements for and approach to QA in i...Web Implementation of Quality Assurance (QA) for X-ray Units in Balkanic Medical Institutions.PubMedUroÅ¡eviÄ‡  Vlade; RistiÄ‡  Olga; MiloÅ¡eviÄ‡  Danijela; KoÅ¡utiÄ‡  DuÅ¡ko2015-08-01Diagnostic radiology is the major contributor to the total dose of the population from all artificial sources. In order to reduce radiation exposure and optimize diagnostic x-ray image quality  it is necessary to increase the quality and efficiency of quality assurance (QA) and audit programs. This work presents a web application providing completely new QA solutions for x-ray modalities and facilities. The software gives complete online information (using European standards) with which the corresponding institutions and individuals can evaluate and control a facility's Radiation Safety and QA program. The software enables storage of all data in one place and sharing the same information (data)  regardless of whether the measured data is used by an individual user or by an authorized institution. The software overcomes the distance and time separation of institutions and individuals who take part in QA. Upgrading the software will enable assessment of the medical exposure level to ionizing radiation.[A Quality Assurance (QA) System with a Web Camera for High-dose-rate Brachytherapy].PubMedHirose  Asako; Ueda  Yoshihiro; Oohira  Shingo; Isono  Masaru; Tsujii  Katsutomo; Inui  Shouki; Masaoka  Akira; Taniguchi  Makoto; Miyazaki  Masayoshi; Teshima  Teruki2016-03-01The quality assurance (QA) system that simultaneously quantifies the position and duration of an (192)Ir source (dwell position and time) was developed and the performance of this system was evaluated in high-dose-rate brachytherapy. This QA system has two functions to verify and quantify dwell position and time by using a web camera. The web camera records 30 images per second in a range from 1 425 mm to 1 505 mm. A user verifies the source position from the web camera at real time. The source position and duration were quantified with the movie using in-house software which was applied with a template-matching technique. This QA system allowed verification of the absolute position in real time and quantification of dwell position and time simultaneously. It was evident from the verification of the system that the mean of step size errors was 0.31Â±0.1 mm and that of dwell time errors 0.1Â±0.0 s. Absolute position errors can be determined with an accuracy of 1.0 mm at all dwell points in three step sizes and dwell time errors with an accuracy of 0.1% in more than 10.0 s of the planned time. This system is to provide quick verification and quantification of the dwell position and time with high accuracy at various dwell positions without depending on the step size.LOVE CANAL MONITORING PROGRAM. GCA QA/QC (QUALITY ASSURANCE/QUALITY CONTROL) SUMMARY REPORTEPA Science InventoryOne of the most important responsibilities of the Love Canal prime contractor was the institution and maintenance of a quality assurance program. An important objective of the quality assurance program was to alert the subcontractors to the importance of high quality work on thei...HANDBOOK: QUALITY ASSURANCE/QUALITY CONTROL (QA/QC) PROCEDURES FOR HAZARDOUS WASTE INCINERATIONEPA Science InventoryResource Conservation and Recovery Act regulations for hazardous waste incineration require trial burns by permit applicants. uality Assurance Project Plan (QAPjP) must accompany a trial burn plan with appropriate quality assurance/quality control procedures. uidance on the prepa...Review of the Constellation Level II Safety  Reliability  and Quality Assurance (SR&QA) Requirements Documents during Participation in the Constellation Level II SR&QA ForumNASA Technical Reports Server (NTRS)Cameron  Kenneth D.; Gentz  Steven J.; Beil  Robert J.; Minute  Stephen A.; Currie  Nancy J.; Scott  Steven S.; Thomas  Walter B.  III; Smiles  Michael D.; Schafer  Charles F.; Null  Cynthia H.;   2009-01-01At the request of the Exploration Systems Mission Directorate (ESMD) and the Constellation Program (CxP) Safety  Reliability; and Quality Assurance (SR&QA) Requirements Director  the NASA Engineering and Safety Center (NESC) participated in the Cx SR&QA Requirements forum. The Requirements Forum was held June 24-26; 2008  at GRC's Plum Brook Facility. The forums purpose was to gather all stakeholders into a focused meeting to help complete the process of refining the CxP to refine its Level II SR&QA requirements or defining project-specific requirements tailoring. Element prime contractors had raised specific questions about the wording and intent of many requirements in areas they felt were driving costs without adding commensurate value. NESC was asked to provide an independent and thorough review of requirements that contractors believed were driving Program costs  by active participation in the forum. This document contains information from the forum.Tropospheric NO2 retrieved from OMI  GOME(-2)  and SCIAMACHY within the Quality Assurance For Essential Climate Variables (QA4ECV) project: retrieval improvement  harmonization  and quality assuranceNASA Astrophysics Data System (ADS)Folkert Boersma  K.2017-04-01One of the prime targets of the EU-project Quality Assurance for Essential Climate Variables (QA4ECV  www.qa4ecv.eu) is the generation and subsequent quality assurance of harmonized  long-term data records of ECVs or precursors thereof. Here we report on a new harmonized and improved retrieval algorithm for NO2 columns and its application to spectra measured by the GOME  SCIAMACHY  OMI  and GOME-2(A) sensors over the period 1996-2016. Our community 'best practices' algorithm is based on the classical 3-step DOAS method. It benefits from a thorough comparison and iteration of spectral fitting and air mass factor calculation approaches between IUP Bremen  BIRA  Max Planck Institute for Chemistry  KNMI  WUR  and a number of external partners. For step 1 of the retrieval  we show that improved spectral calibration and the inclusion of liquid water and intensity-offset correction terms in the fitting procedure  lead to 10-30% smaller NO2 slant columns  in better agreement with independent measurements. Moreover  the QA4ECV NO2 slant columns show 15-35% lower uncertainties relative to earlier versions of the spectral fitting algorithm. For step 2  the stratospheric correction  the algorithm relies on the assimilation of NO2 slant columns over remote regions in the Tracer Model 5 (TM5-MP) chemistry transport model. The representation of stratospheric NOy in the model is improved by nudging towards ODIN HNO3:O3 ratios  leading to more realistic NO2 concentrations in the free-running mode  which is relevant at high latitudes near the terminator. The coupling to TM5-Mass Parallel also allows the calculation of air mass factors (AMFs  step 3) from a priori NO2 vertical profiles simulated at a spatial resolution of 1Â°Ã—1Â°  so that hotspot gradients are better resolved in the a priori profile shapes. Other AMF improvements include the use of improved cloud information  and a correction for photon scattering in a spherical atmosphere. Preliminary comparisons indicate that theSU-E-T-646: Quality Assurance of Truebeam Multi-Leaf Collimator Using a MLC QA PhantomSciTech ConnectZhang  J; Lu  J; Hong  D2015-06-15Purpose: To perform a routine quality assurance procedure for Truebeam multi-leaf collimator (MLC) using MLC QA phantom  verify the stability and reliability of MLC during the treatment. Methods: MLC QA phantom is a specialized phantom for MLC quality assurance (QA)  and contains five radio-opaque spheres that are embedded in an â€œLâ€ shape. The phantom was placed isocentrically on the Truebeam treatment couch for the tests. A quality assurance plan was setted up in the Eclipse v10.0  the fields that need to be delivered in order to acquire the necessary images  the MLC shapes can then be obtained by the images.moreÂ Â» The images acquired by the electronic portal imaging device (EPID)  and imported into the PIPSpro software for the analysis. The tests were delivered twelve weeks (once a week) to verify consistency of the delivery  and the images are acquired in the same manner each time. Results: For the Leaf position test  the average position error was 0.23mmÂ±0.02mm (range: 0.18mmâˆ¼0.25mm). The Leaf width was measured at the isocenter  the average error was 0.06mmÂ±0.02mm (range: 0.02mmâˆ¼0.08mm) for the Leaf width test. Multi-Port test showed the dynamic leaf shift error  the average error was 0.28mmÂ±0.03mm (range: 0.2mmâˆ¼0.35mm). For the leaf transmission test  the average inter-leaf leakage value was 1.0%Â±0.17% (range: 0.8%âˆ¼1.3%) and the average inter-bank leakage value was 32.6%Â±2.1% (range: 30.2%âˆ¼36.1%). Conclusion: By the test of 12 weeks  the MLC system of the Truebeam is running in a good condition and the MLC system can be steadily and reliably carried out during the treatment. The MLC QA phantom is a useful test tool for the MLC QA.Â«Â lessImproving spot-scanning proton therapy patient specific quality assurance with HPlusQA  a second-check dose calculation engine.PubMedMackin  Dennis; Li  Yupeng; Taylor  Michael B; Kerr  Matthew; Holmes  Charles; Sahoo  Narayan; Poenisch  Falk; Li  Heng; Lii  Jim; Amos  Richard; Wu  Richard; Suzuki  Kazumichi; Gillin  Michael T; Zhu  X Ronald; Zhang  Xiaodong2013-12-01The purpose of this study was to validate the use of HPlusQA  spot-scanning proton therapy (SSPT) dose calculation software developed at The University of Texas MD Anderson Cancer Center  as second-check dose calculation software for patient-specific quality assurance (PSQA). The authors also showed how HPlusQA can be used within the current PSQA framework. The authors compared the dose calculations of HPlusQA and the Eclipse treatment planning system with 106 planar dose measurements made as part of PSQA. To determine the relative performance and the degree of correlation between HPlusQA and Eclipse  the authors compared calculated with measured point doses. Then  to determine how well HPlusQA can predict when the comparisons between Eclipse calculations and the measured dose will exceed tolerance levels  the authors compared gamma index scores for HPlusQA versus Eclipse with those of measured doses versus Eclipse. The authors introduce the Î±Î²Î³ transformation as a way to more easily compare gamma scores. The authors compared measured and calculated dose planes using the relative depth  zâˆ•R Ã— 100%  where z is the depth of the measurement and R is the proton beam range. For relative depths than less than 80%  both Eclipse and HPlusQA calculations were within 2 cGy of dose measurements on average. When the relative depth was greater than 80%  the agreement between the calculations and measurements fell to 4 cGy. For relative depths less than 10%  the Eclipse and HPlusQA dose discrepancies showed a negative correlation  -0.21. Otherwise  the correlation between the dose discrepancies was positive and as large as 0.6. For the dose planes in this study  HPlusQA correctly predicted when Eclipse had and had not calculated the dose to within tolerance 92% and 79% of the time  respectively. In 4 of 106 cases  HPlusQA failed to predict when the comparison between measurement and Eclipse's calculation had exceeded the tolerance levels of 3% for dose and 3 mm forBUILDING ""BRIDGES"" WITH QUALITY ASSURANCEEPA Science InventoryThe papr describes how  rather than building ""bridges"" across centuries  quality assurance (QA) personnel have the opportunity to build bridges across technical disciplines  between public and private organizations  and between different QA groups. As reviewers and auditors of a...Spacelab data processing facility (SLDPF) quality assurance (QA)/data accounting (DA) expert systems - Transition from prototypes to operational systemsNASA Technical Reports Server (NTRS)Basile  Lisa1988-01-01The SLDPF is responsible for the capture  quality monitoring processing  accounting  and shipment of Spacelab and/or Attached Shuttle Payloads (ASP) telemetry data to various user facilities. Expert systems will aid in the performance of the quality assurance and data accounting functions of the two SLDPF functional elements: the Spacelab Input Processing System (SIPS) and the Spacelab Output Processing System (SOPS). Prototypes were developed for each as independent efforts. The SIPS Knowledge System Prototype (KSP) used the commercial shell OPS5+ on an IBM PC/AT; the SOPS Expert System Prototype used the expert system shell CLIPS implemented on a Macintosh personal computer. Both prototypes emulate the duties of the respective QA/DA analysts based upon analyst input and predetermined mission criteria parameters  and recommended instructions and decisions governing the reprocessing  release  or holding for further analysis of data. These prototypes demonstrated feasibility and high potential for operational systems. Increase in productivity  decrease of tedium  consistency  concise historical records  and a training tool for new analyses were the principal advantages. An operational configuration  taking advantage of the SLDPF network capabilities  is under development with the expert systems being installed on SUN workstations. This new configuration in conjunction with the potential of the expert systems will enhance the efficiency  in both time and quality  of the SLDPF's release of Spacelab/AST data products.Spacelab data processing facility (SLDPF) Quality Assurance (QA)/Data Accounting (DA) expert systems: Transition from prototypes to operational systemsNASA Technical Reports Server (NTRS)Basile  Lisa1988-01-01The SLDPF is responsible for the capture  quality monitoring processing  accounting  and shipment of Spacelab and/or Attached Shuttle Payloads (ASP) telemetry data to various user facilities. Expert systems will aid in the performance of the quality assurance and data accounting functions of the two SLDPF functional elements: the Spacelab Input Processing System (SIPS) and the Spacelab Output Processing System (SOPS). Prototypes were developed for each as independent efforts. The SIPS Knowledge System Prototype (KSP) used the commercial shell OPS5+ on an IBM PC/AT; the SOPS Expert System Prototype used the expert system shell CLIPS implemented on a Macintosh personal computer. Both prototypes emulate the duties of the respective QA/DA analysts based upon analyst input and predetermined mission criteria parameters  and recommended instructions and decisions governing the reprocessing  release  or holding for further analysis of data. These prototypes demonstrated feasibility and high potential for operational systems. Increase in productivity  decrease of tedium  consistency  concise historial records  and a training tool for new analyses were the principal advantages. An operational configuration  taking advantage of the SLDPF network capabilities  is under development with the expert systems being installed on SUN workstations. This new configuration in conjunction with the potential of the expert systems will enhance the efficiency  in both time and quality  of the SLDPF's release of Spacelab/AST data products.SU-F-T-459: ArcCHECK Machine QA : Highly Efficient Quality Assurance Tool for VMAT  SRS & SBRT Linear Accelerator DeliverySciTech ConnectMhatre  V; Patwe  P; Dandekar  PPurpose: Quality assurance (QA) of complex linear accelerators is critical and highly time consuming. ArcCHECK Machine QA tool is used to test geometric and delivery aspects of linear accelerator. In this study we evaluated the performance of this tool. Methods: Machine QA feature allows user to perform quality assurance tests using ArcCHECK phantom. Following tests were performed 1) Gantry Speed 2) Gantry Rotation 3) Gantry Angle 4)MLC/Collimator QA 5)Beam Profile Flatness & Symmetry. Data was collected on trueBEAM stX machine for 6 MV for a period of one year. The Gantry QA test allows to view errors in gantry angle moreÂ Â» rotation & assess how accurately the gantry moves around the isocentre. The MLC/Collimator QA tool is used to analyze & locate the differences between leaf bank & jaw position of linac. The flatness & Symmetry test quantifies beam flatness & symmetry in IEC-y & x direction. The Gantry & Flatness/Symmetry test can be performed for static & dynamic delivery. Results: The Gantry speed was 3.9 deg/sec with speed maximum deviation around 0.3 deg/sec. The Gantry Isocentre for arc delivery was 0.9mm & static delivery was 0.4mm. The maximum percent positive & negative difference was found to be 1.9 % & â€“ 0.25 % & maximum distance positive & negative diff was 0.4mm & â€“ 0.3 mm for MLC/Collimator QA. The Flatness for Arc delivery was 1.8 % & Symmetry for Y was 0.8 % & X was 1.8 %. The Flatness for gantry 0Â° 270Â° 90Â° & 180Â° was 1.75 1.9 1.8 & 1.6% respectively & Symmetry for X & Y was 0.8 0.6% for 0Â°  0.6 0.7% for 270Â°  0.6 1% for 90Â° & 0.6 0.7% for 180Â°. Conclusion: ArcCHECK Machine QA is an useful tool for QA of Modern linear accelerators as it tests both geometric & delivery aspects. This is very important for VMAT  SRS & SBRT treatments.Â«Â lessThoughts on Internal and External Quality AssuranceERIC Educational Resources Information CenterZhang  Jianxin2012-01-01Quality assurance of higher education is made up of two parts: internal quality assurance (IQA) and external quality assurance (EQA). Both belong to a union of the coexistence and balance of yin and yang. But in reality there exists a paradox of ""confusion of quality assurance (QA) subject consciousness  singularity of social QA and lack of QAâ€¦Improving spot-scanning proton therapy patient specific quality assurance with HPlusQA  a second-check dose calculation engineSciTech ConnectMackin  Dennis; Li  Yupeng; Taylor  Michael B.Purpose: The purpose of this study was to validate the use of HPlusQA  spot-scanning proton therapy (SSPT) dose calculation software developed at The University of Texas MD Anderson Cancer Center  as second-check dose calculation software for patient-specific quality assurance (PSQA). The authors also showed how HPlusQA can be used within the current PSQA framework.Methods: The authors compared the dose calculations of HPlusQA and the Eclipse treatment planning system with 106 planar dose measurements made as part of PSQA. To determine the relative performance and the degree of correlation between HPlusQA and Eclipse  the authors compared calculated with measured point doses.moreÂ Â» Then  to determine how well HPlusQA can predict when the comparisons between Eclipse calculations and the measured dose will exceed tolerance levels  the authors compared gamma index scores for HPlusQA versus Eclipse with those of measured doses versus Eclipse. The authors introduce the Î±Î²Î³ transformation as a way to more easily compare gamma scores.Results: The authors compared measured and calculated dose planes using the relative depth  z/R Ã— 100%  where z is the depth of the measurement and R is the proton beam range. For relative depths than less than 80%  both Eclipse and HPlusQA calculations were within 2 cGy of dose measurements on average. When the relative depth was greater than 80%  the agreement between the calculations and measurements fell to 4 cGy. For relative depths less than 10%  the Eclipse and HPlusQA dose discrepancies showed a negative correlation  âˆ’0.21. Otherwise  the correlation between the dose discrepancies was positive and as large as 0.6. For the dose planes in this study  HPlusQA correctly predicted when Eclipse had and had not calculated the dose to within tolerance 92% and 79% of the time  respectively. In 4 of 106 cases  HPlusQA failed to predict when the comparison between measurement and Eclipse's calculation had exceeded the tolerance levels ofEPA Region 9 Guidance for Quality Assurance Program Plans - R9qa/03.2EPA Pesticide FactsheetsIn order for decision makers to have confidence in the quality of environmental data used to support their decisions  the organization must have structured and documented process for quality in place.Material quality assurance risk assessment.DOT National Transportation Integrated Search2013-01-01Over the past two decades the role of SHA has shifted from quality control (QC) of materials and : placement techniques to quality assurance (QA) and acceptance. The role of the Office of Materials : Technology (OMT) has been shifting towards assuran...Quality assurance in radiotherapy.PubMedKouloulias  V E2003-03-01In 1999  the European Organisation for Research and Treatment of Cancer (EORTC)  being a European pioneer in the field of cancer research as well as in quality assurance (QA)  launched an Emmanuel van der Schueren fellowship for QA in radiotherapy. In this paper  the work that has been done during the first E. van der Schueren fellowship is reported  focusing on four phase III EORTC clinical trials: 22921 for rectal cancer  22961 and 22991 for prostate cancer and 22922 for breast cancer. A historical review of the QA programme of the EORTC Radiotherapy group during the past 20 years is included.Evaluation of procedures for quality assurance specificationsDOT National Transportation Integrated Search2004-10-01The objective of this project was to develop a comprehensive quality assurance (QA) manual  supported by scientific evidence and statistical theory  which provides step-by-step procedures and instructions for developing effective and efficient QA spe...Material quality assurance risk assessment : [summary].DOT National Transportation Integrated Search2013-01-01With the shift from quality control (QC) of materials and placement techniques : to quality assurance (QA) and acceptance over the years  the role of the Office : of Materials Technology (OMT) has been shifting towards assurance of : material quality...SU-F-T-251: The Quality Assurance for the Heavy Patient Load Department in the Developing Country: The Primary Experience of An Entire Workflow QA Process Management in RadiotherapySciTech ConnectXie  J; Wang  J; Peng  JPurpose: To implement an entire workflow quality assurance (QA) process in the radiotherapy department and to reduce the error rates of radiotherapy based on the entire workflow management in the developing country. Methods: The entire workflow QA process management starts from patient registration to the end of last treatment including all steps through the entire radiotherapy process. Error rate of chartcheck is used to evaluate the the entire workflow QA process. Two to three qualified senior medical physicists checked the documents before the first treatment fraction of every patient. Random check of the treatment history during treatment was also performed.moreÂ Â» A total of around 6000 patients treatment data before and after implementing the entire workflow QA process were compared from May  2014 to December  2015. Results: A systemic checklist was established. It mainly includes patientâ€™s registration  treatment plan QA  information exporting to OIS(Oncology Information System)  documents of treatment QAand QA of the treatment history. The error rate derived from the chart check decreases from 1.7% to 0.9% after our the entire workflow QA process. All checked errors before the first treatment fraction were corrected as soon as oncologist re-confirmed them and reinforce staff training was accordingly followed to prevent those errors. Conclusion: The entire workflow QA process improved the safety  quality of radiotherapy in our department and we consider that our QA experience can be applicable for the heavily-loaded radiotherapy departments in developing country.Â«Â lessA rapid communication from the AAPM Task Group 201: recommendations for the QA of external beam radiotherapy data transfer. AAPM TG 201: quality assurance of external beam radiotherapy data transfer.PubMedSiochi  R Alfredo; Balter  Peter; Bloch  Charles D; Santanam  Lakshmi; Blodgett  Kurt; Curran  Bruce H; Engelsman  Martijn; Feng  Wenzheng; Mechalakos  Jim; Pavord  Dan; Simon  Tom; Sutlieff  Steven; Zhu  X Ronald2010-12-04The transfer of radiation therapy data among the various subsystems required for external beam treatments is subject to error. Hence  the establishment and management of a data transfer quality assurance program is strongly recommended. It should cover the QA of data transfers of patient specific treatments  imaging data  manually handled data and historical treatment records. QA of the database state (logical consistency and information integrity) is also addressed to ensure that accurate data are transferred.TU-FG-201-01: 18-Month Clinical Experience of a Linac Daily Quality Assurance (QA) Solution Using Only EPID and OBISciTech ConnectCai  B; Sun  B; Yaddanapudi  SPurpose: To describe the clinical use of a Linear Accelerator (Linac) DailyQA system with only EPID and OBI. To assess the reliability over an 18-month period and improve the robustness of this system based on QA failure analysis. Methods: A DailyQA solution utilizing an in-house designed phantom  combined EPID and OBI image acquisitions  and a web-based data analysis and reporting system was commissioned and used in our clinic to measure geometric  dosimetry and imaging components of a Varian Truebeam Linac. During an 18-month period (335 working days)  the Daily QA results  including the output constancy  beam flatness and symmetry  uniformity moreÂ Â» TPR20/10  MV and KV imaging quality  were collected and analyzed. For output constancy measurement  an independent monthly QA system with an ionization chamber (IC) and annual/incidental TG51 measurements with ADCL IC were performed and cross-compared to Daily QA system. Thorough analyses were performed on the recorded QA failures to evaluate the machine performance  optimize the data analysis algorithm  adjust the tolerance setting and improve the training procedure to prevent future failures. Results: A clinical workflow including beam delivery  data analysis  QA report generation and physics approval was established and optimized to suit daily clinical operation. The output tests over the 335 working day period cross-correlated with the monthly QA system within 1.3% and TG51 results within 1%. QA passed with one attempt on 236 days out of 335 days. Based on the QA failures analysis  the Gamma criteria is revised from (1%  1mm) to (2%  1mm) considering both QA accuracy and efficiency. Data analysis algorithm is improved to handle multiple entries for a repeating test. Conclusion: We described our 18-month clinical experience on a novel DailyQA system using only EPID and OBI. The long term data presented demonstrated the system is suitable and reliable for Linac daily QA.Â«Â lessQuality Assurance.ERIC Educational Resources Information CenterMassachusetts Career Development Inst.  Springfield.This booklet is one of six texts from a workplace literacy curriculum designed to assist learners in facing the increased demands of the workplace. The booklet contains five sections that cover the following topics: (1) importance of reliability; (2) meaning of quality assurance; (3) historical development of quality assurance; (4) statisticalâ€¦Quality Assurance: Administrator's Panacea or Pandemonium.ERIC Educational Resources Information CenterComerford  Ralph; Silverman  Wade H.Where mental health administrators used to rely on subjective judgments of senior clinicians to evaluate the effectiveness of mental health services  they now rely more on a quality assurance (QA) plan. The primary motive for undertaking a QA program should be better service. QA may start out being very expensive in terms of personnel andâ€¦The Concepts of Quality  Quality Assurance and Quality EnhancementERIC Educational Resources Information CenterElassy  Noha2015-01-01Purpose: This paper aims to critically review and discuss different definitions of the concepts of quality  quality assurance (QA) and quality enhancement (QE) in higher education (HE) with presenting critical perspectives of the literature. Design/methodology/approach: The paper looks at literature concerns with the meaning of quality  QA and QE â€¦QUALITY SCIENCE AND QUALITY ASSURANCE: OBSERVATIONS OR AN ENVIRONMENTAL SCIENTISTEPA Science Inventory-- ABSTRACT The purpose of this manuscript is to examine the relationship between quality science (QS) and quality assurance (QA). Many research scientists definitely want to do QS  but are afraid or do not want to do QA because they are intimidated by the QA proc...References on EPA Quality Assurance Project PlansEPA Pesticide FactsheetsProvides requirements for the conduct of quality management practices  including quality assurance (QA) and quality control (QC) activities  for all environmental data collection and environmental technology programs performed by or for this Agency.Revision 2 of the Enbridge Quality Assurance Project PlanEPA Pesticide FactsheetsThis Quality Assurance Project Plan (QAPP) presents Revision 2 of the organization  objectives  planned activities  and specific quality assurance/quality control (QA/QC) procedures associated with the Enbridge Marshall Pipeline Release Project.SU-F-BRE-16: VMAT Commissioning and Quality Assurance (QA) of An Elekta Synergy-STM Linac Using ICOM Test HarnessTMSciTech ConnectNguyen  A; Ironwood CRC  Phoenix  AZ; Rajaguru  P2014-06-15Purpose: To establish a set of tests based on the iCOM software that can be used to commission and perform periodic QA of VMAT delivery on the Elekta Synergy-S  commonly known as the Beam Modulator (BM). Methods: iCOM is used to create and deliver customized treatment fields to characterize the system in terms of 1) MLC positioning accuracy under static and dynamic delivery with full gantry rotation  2) MLC positioning with known errors  3) Maximum dose rate  4) Maximum MLC speed  5) Maximum gantry speed  6) Synchronization: gantry speed versus dose rate  and 7) Synchronization: MLC speed versus dose rate.moreÂ Â» The resulting images were captured on the iView GT and exported in DICOM format to Dosimetry Checkâ„¢ system for visual and quantitative analysis. For the initial commissioning phase  the system tests described should be supplemented with extensive patient QAs covering all clinically relevant treatment sites. Results: The system performance test suite showed that on our Synergy-S  MLC positioning was accurate under both static and dynamic deliveries. Intentional errors of 1 mm were also easily identified on both static and dynamic picket fence tests. Maximum dose rate was verified with stop watch to be consistently between 475-480 MU/min. Maximum gantry speed and MLC speed were 5.5 degree/s and 2.5 cm/s respectively. After accounting for beam flatness  both synchronization tests  gantry versus dose rate and MLC speed versus dose rate  were successful as the fields were uniform across the strips and there were no obvious cold/hot spots. Conclusion: VMAT commissioning and quality assurance should include machine characterization tests in addition to patient QAs. Elekta iCOM is a valuable tool for the design of customized VMAT field with specific MU  MLC leaf positions  dose rate  and indirect control of MLC and gantry speed at each of its control points.Â«Â lessQuality Assurance Project Plan Development ToolEPA Pesticide FactsheetsThis tool contains information designed to assist in developing a Quality Assurance (QA) Project Plan that meets EPA requirements for projects that involve surface or groundwater monitoring and/or the collection and analysis of water samples.Quality Assurance in Turkish Higher EducationERIC Educational Resources Information CenterBugday Ince  Sehriban; Gounko  Tatiana2014-01-01The implementation of quality assurance (QA) is one of the most challenging reform areas for Turkey due to the unique organization of its higher education system. This paper explores the development of QA systems in Turkish universities. Using a qualitative case study approach  the authors examine how Turkey accomplishes the goal of implementingâ€¦Development of a harmonised multi sensor retrieval scheme for HCHO within the Quality Assurance For Essential Climate Variables (QA4ECV) projectNASA Astrophysics Data System (ADS)De Smedt  Isabelle; Richter  Andreas; Beirle  Steffen; Danckaert  Thomas; Van Roozendael  Michel; Yu  Huan; BÃ¶sch  Tim; Hilboll  Andreas; Peters  Enno; Doerner  Steffen; Wagner  Thomas; Wang  Yang; Lorente  Alba; Eskes  Henk; Van Geffen  Jos; Boersma  Folkert2016-04-01One of the main goals of the QA4ECV project is to define community best-practices for the generation of multi-decadal ECV data records from satellite instruments. QA4ECV will develop retrieval algorithms for the Land ECVs surface albedo  leaf area index (LAI)  and fraction of active photosynthetic radiation (fAPAR)  as well as for the Atmosphere ECV ozone and aerosol precursors nitrogen dioxide (NO2)  formaldehyde (HCHO)  and carbon monoxide (CO). Here we assess best practices and provide recommendations for the retrieval of HCHO. Best practices are established based on (1) a detailed intercomparison exercise between the QA4ECV partner's for each specific algorithm processing steps  (2) the feasibility of implementation  and (3) the requirement to generate consistent multi-sensor multi-decadal data records. We propose a fitting window covering the 328.5-346 nm spectral interval for the morning sensors (GOME  SCIAMACHY and GOME-2) and an extension to 328.5-359 nm for OMI and GOME-2  allowed by improved quality of the recorded spectra. A high level of consistency between group algorithms is found when the retrieval settings are carefully aligned. However  the retrieval of slant columns is highly sensitive to any change in the selected settings. The use of a mean background radiance as DOAS reference spectrum allows for a stabilization of the retrievals. A background correction based on the reference sector method is recommended for implementation in the QA4ECV HCHO algorithm as it further reduces retrieval uncertainties. HCHO AMFs using different radiative transfer codes show a good overall consistency when harmonized settings are used. As for NO2  it is proposed to use a priori HCHO profiles from the TM5 model. These are provided on a 1Â°x1Â° latitude-longitude grid.Quality assurance guides health reform in Jordan.PubMedAbubaker  W; Abdulrahman  M1996-01-01In November 1995  a World Bank mission went to Jordan to conduct a study of the health sector. The study recommended three strategies to reform the health sector: decentralization of Ministry of Health (MOH) management; improvement of clinical practices  quality of care  and consumer satisfaction; and adoption of treatment protocols and standards. The MOH chose quality assurance (QA) methods and quality management (QM) techniques to accomplish these reforms. The Monitoring and QA Directorate oversees QA applications within MOH. It also institutes and develops the capacity of local QA units in the 12 governorates. The QA units implement and monitor day-to-day QA activities. The QM approach encompasses quality principles: establish objectives; use a systematic approach; teach lessons learned and applicable research; use QA training to teach quality care  quality improvement  and patient satisfaction; educate health personnel about QM approaches; use assessment tools and interviews; measure the needs and expectations of local health providers and patients; ensure feedback on QA improvement projects; ensure valid and reliable data; monitor quality improvement efforts; standardize systemic data collection and outcomes; and establish and disseminate QA standards and performance improvement efforts. The Jordan QA Project has helped with the successful institutionalization of a QA system at both the central and local levels. The bylaws of the QA councils and committees require team participation in the decision-making process. Over the last two years  the M&QA Project has adopted 21 standards for nursing  maternal and child health care centers  pharmacies  and medications. The Balqa pilot project has developed 44 such protocols. Quality improvement (COUGH) studies have examined hyper-allergy  analysis of patient flow rate  redistribution of nurses  vaccine waste  and anemic pregnant women. There are a considerable number of on-going clinical and non-clinical COUGH studiesRhetoric and Reality: The Irish Experience of Quality AssuranceERIC Educational Resources Information CenterFitzsimons  Camilla2017-01-01This paper shares the Irish adult educator's experiences of Quality Assurance (QA). Educators are found to be largely supportive of QA but contradictions emerge. These include philosophical tensions  inconsistent moderation and incongruence between the stated values of QA and a more powerful government-led employability discourse.FINDING THE BALANCE - QUALITY ASSURANCE REQUIREMENTS VS. RESEARCH NEEDSEPA Science InventoryInvestigators often misapply quality assurance (QA) procedures and may consider QA as a hindrance to developing test plans for sampling and analysis. If used properly  however  QA is the driving force for collecting the right kind and proper amount of data. Researchers must use Q...FINDING THE BALANCE - QUALITY ASSURANCE REQUIREMENTS VS. RESEARCH NEEDSEPA Science InventoryInvestigators often misapply quality assurance (QA) procedures and may consider QA as a hindrance to developing test plans forsampling and analysis. If used properly  however  QA is the driving force for collecting the right kind and proper amount of data.Researchers must...Evaluation of a Standardized Method of Quality Assurance in Mental Health Records: A Pilot StudyERIC Educational Resources Information CenterBradshaw  Kelsey M.; Donohue  Bradley; Fayeghi  Jasmine; Lee  Tiffany; Wilks  Chelsey R.; Ross  Brendon2016-01-01The widespread adoption of research-supported treatments by mental health providers has facilitated empirical development of quality assurance (QA) methods. Research in this area has focused on QA systems aimed at assuring the integrity of research-supported treatment implementation  while examination of QA systems to assure appropriateâ€¦Data Validation & Laboratory Quality Assurance for Region 9EPA Pesticide FactsheetsIn all hazardous site investigations it is essential to know the quality of the data used for decision-making purposes. Validation of data requires that appropriate quality assurance and quality control (QA/QC) procedures be followed.Quality Assurance in Post-Secondary Education: Some Common ApproachesERIC Educational Resources Information CenterLaw  Dennis Chung Sea2010-01-01Purpose: The common approaches to quality assurance (QA)  as practiced by most post-secondary education institutions for internal quality monitoring and most QA authorities for external quality monitoring (EQM)  have been considered by many researchers as having largely failed to address the essence of educational quality. The purpose of thisâ€¦Quality Assurance for Clinical TrialsPubMed CentralIbbott  Geoffrey S.; Haworth  Annette; Followill  David S.2013-01-01Cooperative groups  of which the Radiation Therapy Oncology Group is one example  conduct national clinical trials that often involve the use of radiation therapy. In preparation for such a trial  the cooperative group prepares a protocol to define the goals of the trial  the rationale for its design  and the details of the treatment procedure to be followed. The Radiological Physics Center (RPC) is one of several quality assurance (QA) offices that is charged with assuring that participating institutions deliver doses that are clinically consistent and comparable. The RPC does this by conducting a variety of independent audits and credentialing processes. The RPC has compiled data showing that credentialing can help institutions comply with the requirements of a cooperative group clinical protocol. Phantom irradiations have been demonstrated to exercise an institutionâ€™s procedures for planning and delivering advanced external beam techniques (1â€“3). Similarly  RPC data indicate that a rapid review of patient treatment records or planning procedures can improve compliance with clinical trials (4). The experiences of the RPC are presented as examples of the contributions that a national clinical trials QA center can make to cooperative group trials. These experiences illustrate the critical need for comprehensive QA to assure that clinical trials are successful and cost-effective. The RPC is supported by grants CA 10953 and CA 81647 from the National Cancer Institute  NIH  DHHS. PMID:24392352Quality assurance for gamma knivesSciTech ConnectJones  E.D.; Banks  W.W.; Fischer  L.E.1995-09-01This report describes and summarizes the results of a quality assurance (QA) study of the Gamma Knife  a nuclear medical device used for the gamma irradiation of intracranial lesions. Focus was on the physical aspects of QA and did not address issues that are essentially medical  such as patient selection or prescription of dose. A risk-based QA assessment approach was used. Sample programs for quality control and assurance are included. The use of the Gamma Knife was found to conform to existing standards and guidelines concerning radiation safety and quality control of external beam therapies (shielding  safety reviews  radiation surveys moreÂ Â» interlock systems  exposure monitoring  good medical physics practices  etc.) and to be compliant with NRC teletherapy regulations. There are  however  current practices for the Gamma Knife not covered by existing  formalized regulations  standards  or guidelines. These practices have been adopted by Gamma Knife users and continue to be developed with further experience. Some of these have appeared in publications or presentations and are slowly finding their way into recommendations of professional organizations.Â«Â less78 FR 37850 - Quality Assurance Program Requirements (Operations)Federal Register 2010  2011  2012  2013  20142013-06-24... NUCLEAR REGULATORY COMMISSION [NRC-2013-0021] Quality Assurance Program Requirements (Operations... Regulatory Commission (NRC) is issuing a revision to Regulatory Guide (RG) 1.33  ``Quality Assurance Program... managerial and administrative Quality Assurance (QA) controls for nuclear power plants during operations...EPA Guidance for Geospatially Related Quality Assurance Project PlansEPA Pesticide FactsheetsThis March 2003 document discusses EPA's Quality Assurance (QA) Project Plan as a tool for project managers and planners to document the type and quality of data and information needed for making environmental decisionsQuality assurance program for isotopic power systemsNASA Astrophysics Data System (ADS)Hannigan  R. L.; Harnar  R. R.1982-12-01The Sandia National Laboratories Quality Assurance Program that applies to non-weapon (reimbursable) Radioisotopic Thermoelectric Generators is summarized. The program was implemented over the past 16 years on power supplies used in various space and terrestrial systems. The quality assurance (QA) activity of the program is in support of the Department of Energy  Office of Space Nuclear Projects. Basic elements of the program are described and examples of program documentation are presented.Quality Assurance in Online Education: The Universitas 21 Global ApproachERIC Educational Resources Information CenterChua  Alton; Lam  Wing2007-01-01Despite the proliferation of online education  concerns remain about the quality of online programmes. Quality assurance (QA) has become a prominent issue  not only for educational institutions and accreditors  but also for students and employers alike. This paper describes some of the rather unique QA processes used at Universitas 21 Globalâ€¦Quality Assurance in Higher Education: A Review of LiteratureERIC Educational Resources Information CenterRyan  Tricia2015-01-01This paper examines the literature surrounding quality assurance in global higher education. It provides an overview of accreditation as a mechanism to ensure quality in higher education  examines models of QA  and explores the concept of quality (including definitions of quality and quality assurance). In addition  this paper provides a review ofâ€¦Multinational Quality AssuranceERIC Educational Resources Information CenterKinser  Kevin2011-01-01Multinational colleges and universities pose numerous challenges to the traditional models of quality assurance that are designed to validate domestic higher education. When institutions cross international borders  at least two quality assurance protocols are involved. To guard against fraud and abuse  quality assurance in the host country isâ€¦Quality assurance in materials and constructionDOT National Transportation Integrated Search2007-06-01This review is a product of the FHWA 2006  National Review Program (NRP). Quality Assurance (QA) was selected for review in 2006 because the program was ranked as one of the top five areas of interest for review by FHWA. Over the last 10 years an ave...University Administrators' Conceptions of Quality and Approaches to Quality AssuranceERIC Educational Resources Information CenterGoff  Lori2017-01-01As the quality of university education garners increasingly more interest in both the public and in the literature  and as quality assurance (QA) processes are developed and implemented within universities around the world  it is important to carefully consider what is meant by the term quality. This study attempts to add to the literatureâ€¦Taxonomy-Based Approaches to Quality Assurance of OntologiesPubMed CentralPerl  Yehoshua; Ochs  Christopher2017-01-01Ontologies are important components of health information management systems. As such  the quality of their content is of paramount importance. It has been proven to be practical to develop quality assurance (QA) methodologies based on automated identification of sets of concepts expected to have higher likelihood of errors. Four kinds of such sets (called QA-sets) organized around the themes of complex and uncommonly modeled concepts are introduced. A survey of different methodologies based on these QA-sets and the results of applying them to various ontologies are presented. Overall  following these approaches leads to higher QA yields and better utilization of QA personnel. The formulation of additional QA-set methodologies will further enhance the suite of available ontology QA tools. PMID:29158885Analytical approaches to quality assurance and quality control in rangeland monitoring dataUSDA-ARS?s Scientific Manuscript databaseProducing quality data to support land management decisions is the goal of every rangeland monitoring program. However  the results of quality assurance (QA) and quality control (QC) efforts to improve data quality are rarely reported. The purpose of QA and QC is to prevent and describe non-sampling...College Quality Assurance Assurances. Mendip Papers 020.ERIC Educational Resources Information CenterSallis  E.; Hingley  P.This paper discusses the increasing interest in quality assurance in British education including its measurement and management through the introduction of a quality assurance system. The reasons and benefits of beginning a quality assurance system are discussed  and questions of what constitutes quality  whether it is quality in factâ€¦Quality Assurance of Joint Degree Programs from the Perspective of Quality Assurance Agencies: Experience in East AsiaERIC Educational Resources Information CenterHou  Yung-Chi; Ince  Martin; Tsai  Sandy; Wang  Wayne; Hung  Vicky; Lin Jiang  Chung; Chen  Karen Hui-Jung2016-01-01Joint degree programs have gained popularity in East Asia  due to the growth of transnational higher education in the region since 2000. However  the external quality assurance (QA) and accreditation of joint degree programs is a challenge for QA agencies  as it normally involves the engagement of several institutions and multiple nationalâ€¦222-S Laboratory Quality Assurance Plan. Revision 1SciTech ConnectMeznarich  H.K.1995-07-31This Quality Assurance Plan provides quality assurance (QA) guidance  regulatory QA requirements (e.g.  10 CFR 830.120)  and quality control (QC) specifications for analytical service. This document follows the U.S Department of Energy (DOE) issued Hanford Analytical Services Quality Assurance Plan (HASQAP). In addition  this document meets the objectives of the Quality Assurance Program provided in the WHC-CM-4-2  Section 2.1. Quality assurance elements required in the Guidelines and Specifications for Preparing Quality Assurance Program Plans (QAMS-004) and Interim Guidelines and Specifications for Preparing Quality Assurance Project Plans (QAMS-005) from the US Environmental Protection Agency (EPA) are covered throughout this document. A qualitymoreÂ Â» assurance index is provided in the Appendix A. This document also provides and/or identifies the procedural information that governs laboratory operations. The personnel of the 222-S Laboratory and the Standards Laboratory including managers  analysts  QA/QC staff  auditors  and support staff shall use this document as guidance and instructions for their operational and quality assurance activities. Other organizations that conduct activities described in this document for the 222-S Laboratory shall follow this QA/QC document.Â«Â lessQuality Assurance: Patient Chart ReviewsNASA Astrophysics Data System (ADS)Oginni  B. M.; Odero  D. O.2009-07-01Recent developments in radiation therapy have immensely impacted the way the radiation dose is delivered to patients undergoing radiation treatments. However  the fundamental quality assurance (QA) issues underlying the radiation therapy still remain the accuracy of the radiation dose and the radiation safety. One of the major duties of clinical medical physicists in the radiation therapy departments still revolves around ensuring the accuracy of dose delivery to the planning target volume (PTV)  the reduction of unintended radiation to normal organs and minimization of the radiation exposure to the medical personnel based on ALARA (as low as reasonably achievable) principle. Many of the errors in radiation therapy can be minimized through a comprehensive program of periodic checks. One of the QA procedures on the patient comes in the form of chart reviews which could be in either electronic or paper-based format. We present the quality assurance procedures that have to be performed on the patient records from the beginning and periodically to the end of the treatment  based on the guidelines from the American Association of Physicists in Medicine (AAPM) and American College of Physicians (ACP).SU-F-T-587: Quality Assurance of Stereotactic Radiosurgery (SRS) and Stereotactic Body Radiation Therapy (SBRT) for Patient Specific Plans: A Comparison Between MATRIXX and Delta4 QA DevicesSciTech ConnectTsai  YC; Lu  SH; Chen  LH2016-06-15Purpose: Patient-specific quality assurance (QA) is necessary to accurately deliver high dose radiation to the target  especially for stereotactic radiosurgery (SRS) and stereotactic body radiation therapy (SBRT). Unlike previous 2 dimensional (D) array QA devices  Delta{sup 4} can verify the dose delivery in 3D. In this study  the difference between calculated and measured dose distribution was compared with two QA devices (MATRIXX and Delta{sup 4}) to evaluate the delivery accuracy. Methods: Twenty-seven SRS/SBRT plans with VMAT were verified with point-dose and dose-map analysis. We use an ion chamber (A1SL  0.053cc) for point-dose measurement. For verification of the dose map  themoreÂ Â» differences between the calculated and measured doses were analyzed with a gamma index using MATRIXX and Delta{sup 4} devices. The passing criteria for gamma evaluation were set at 3 mm for distance-to-agreement (DTA) and 3% for dose-difference. A gamma index less than 1 was defined as the verification passing the criteria and satisfying at least 95% of the points. Results: The mean prescribed dose and fraction was 40 Â± 14.41 Gy (range: 16â€“60) and 10 Â± 2.35 fractions (range: 1â€“8)  respectively. In point dose analysis  the differences between the calculated and measured doses were all less than 5% (mean: 2.12 Â± 1.13%; range: âˆ’0.55% to 4.45%). In dose-map analysis  the average passing rates were 99.38 Â± 0.96% (range: 95.31â€“100%) and 100 Â± 0.12% (range: 99.5%â€“100%) for MATRIXX and Delta{sup 4}  respectively. Even using criteria of 2%/2 mm  the passing rate of Delta{sup 4} was still more than 95% (mean: 99 Â± 1.08%; range: 95.6%â€“100%). Conclusion: Both MATRIXX and Delta{sup 4} offer accurate and efficient verification for SRS/SBRT plans. The results measured by MATRIXX and Delta{sup 4} dosimetry systems are similar for SRS/SBRT performed with the VMAT technique.Â«Â lessEvolution of Internal Quality Assurance at One University--A Case StudyERIC Educational Resources Information CenterO'Sullivan  David2017-01-01Purpose: Quality assurance (QA) at one University has evolved over the past 15 years through emerging National and European standards  various leadership initiatives and through the engagement of key stakeholders in co-designing and implementing internal QA processes. In 2000  the QA process was focussed mainly on quality review (QR) that involvedâ€¦A framework for institutionalizing quality assurance.PubMedSilimperi  Diana R; Franco  Lynne Miller; Veldhuyzen van Zanten  Tisna; MacAulay  Catherine2002-12-01To develop a framework to support the institutionalization of quality assurance (QA). The framework for institutionalizing QA consists of a model of eight essential elements and a 'roadmap' for the process of institutionalization. The essential elements are the building blocks required for implementing and sustaining QA activities. Core QA activities include defining  measuring and improving quality. The essential elements are grouped under three categories: the internal enabling environment (internal to the organization or system)  organizing for quality  and support functions. The enabling environment contains the essential elements of leadership  policy  core values  and resources. Organizing for quality includes the structure for implementing QA. Three essential elements are primarily support functions: capacity building  communication and information  and rewarding quality. The model can be applied at the level of an organization or a system. The paper also describes the process of institutionalizing QA  starting from a state of preawareness  passing through four phases (awareness  experiential  expansion  and consolidation)  and culminating in a state of maturity. The process is not linear; an organization may regress  vacillate between phases  or even remain stagnant. Some phases (e.g. awareness and experiential) may occur simultaneously. The framework has been introduced in nearly a dozen countries in Latin America and Africa. The conceptual model has been used to support strategic planning and directing Ministry of Health work plans  and also as a resource for determining the elements necessary to strengthen and sustain QA. The next step will be the development and evaluation of an assessment tool to monitor developmental progress in the institutionalization of QA.RAVEN Quality Assurance ActivitiesSciTech ConnectCogliati  Joshua Joseph2015-09-01This report discusses the quality assurance activities needed to raise the Quality Level of Risk Analysis in a Virtual Environment (RAVEN) from Quality Level 3 to Quality Level 2. This report also describes the general RAVEN quality assurance activities. For improving the quality  reviews of code changes have been instituted  more parts of testing have been automated  and improved packaging has been created. For upgrading the quality level  requirements have been created and the workflow has been improved.QUALITY ASSURANCE AND QUALITY CONTROL FOR WASTE CONTAINMENT FACILITIES. Project SummaryEPA Science InventoryIt is generally agreed that both quality assurance (QA) and quality control (QC) are essential to the proper installation and eventual performance of environmentally safe and secure waste containment systems. Even further  there are both manufacturing and construction aspects to...Quality control and quality assurance of hot mix asphalt construction in Delaware.DOT National Transportation Integrated Search2006-07-01Since the mid 60s the Federal Highway Administration began to encourage : Departments of Transportation and Contractors toward the use of quality control and : quality assurance (QA/QC) specifications  which are statistically based. : For example ...Quality Assurance of E-learning. ENQA Workshop Report 14ERIC Educational Resources Information CenterGrifoll  Josep; Huertas  Esther; Prades  Anna; Rodriguez  Sebastian; Rubin  Yuri; Mulder  Fred; Ossiannilsson  Ebba2010-01-01E-learning in the European Higher Education Area has stampeded its way to the foreground of the Quality Assurance (QA) forum  and has become a key issue among quality assurance agencies and institutions in the European Higher Education Area (EHEA). Because internet-based learning is currently such a relevant topic  there is a dire need for theâ€¦The Landscape of Quality Assurance in Distance EducationERIC Educational Resources Information CenterScull  W. Reed; Kendrick  David; Shearer  Rick; Offerman  Dana2011-01-01Distance education permeates the field of professional and continuing education to such an extent that quality assurance (QA) is a topic no distance educator or administrator should avoid. Quality assurance is an issue not just for continuing education but also for higher education generally. Given the disruptive impact of distance education andâ€¦Quality assurance in transition.PubMedBlumenfeld  S N1993-06-01This paper outlines the early approaches to quality assurance  and its transition from business to health care. It then describes the development of the more recent trends in quality assurance of Total Quality Management and Continuous Quality Improvement and discusses the strengths and weaknesses of these approaches. The paper then goes on to show how these approaches have been modified for application to peripheral health services in developing countries through the work of the Primary Health Care Operations Research Project and the Quality Assurance Project.Development and Testing of a Nuclear Quality Assurance/Quality Control Technician Curriculum. Final Report.ERIC Educational Resources Information CenterEspy  John; And OthersA project was conducted to field test selected first- and second-year courses in a postsecondary nuclear quality assurance/quality control (QA/QC) technician curriculum and to develop the teaching/learning modules for seven technical specialty courses remaining in the QA/QC technician curriculum. The field testing phase of the project involved theâ€¦STRATEGIC PLAN FOR GEOGRAPHIC INFORMATION SYSTEM (GIS) QUALITY ASSURANCE IN THE EPAEPA Science InventoryThe EPA GIS-QA Team was created to fill the gap between the EPA Quality Assurance (QA) and Geographic Information Systems (GIS) communities. All EPA Offices and Regions were invited to participate. Currently  the EPA GIS-QA Team consists of members from the EPA Regional Offices...The NCI Thesaurus quality assurance life cycle.PubMedde Coronado  Sherri; Wright  Lawrence W; Fragoso  Gilberto; Haber  Margaret W; Hahn-Dantona  Elizabeth A; Hartel  Francis W; Quan  Sharon L; Safran  Tracy; Thomas  Nicole; Whiteman  Lori2009-06-01The National Cancer Institute Enterprise Vocabulary Services (NCI EVS) uses a wide range of quality assurance (QA) techniques to maintain and extend NCI Thesaurus (NCIt). NCIt is a reference terminology and biomedical ontology used in a growing number of NCI and other systems that extend from translational and basic research through clinical care to public information and administrative activities. Both automated and manual QA techniques are employed throughout the editing and publication cycle  which includes inserting and editing NCIt in NCI Metathesaurus. NCI EVS conducts its own additional periodic and ongoing content QA. External reviews  and extensive evaluation by and interaction with EVS partners and other users  have also played an important part in the QA process. There have always been tensions and compromises between meeting the needs of dependent systems and providing consistent and well-structured content; external QA and feedback have been important in identifying and addressing such issues. Currently  NCI EVS is exploring new approaches to broaden external participation in the terminology development and QA process.[Cross-sectoral quality assurance in ambulatory care].PubMedAlbrecht  Martin; Loos  Stefan; Otten  Marcus2013-01-01Overcoming rigid sectoral segmentation in healthcare has also become a health policy target in quality assurance. With the Act to Enhance Competition in Statutory Health Insurance (GKV-WSG) coming into effect  quality assurance measures are to be designed in a cross-sectoral fashion for in- and outpatient sectors equally. An independent institution is currently mandated to develop specific quality indicators for eleven indications. For three of these operating tests have already been commissioned by the Federal Joint Committee. This article depicts the major results of a feasibility study  including a compliance cost estimate  for the aforementioned indications of cross-sectoral quality assurance (cQA). In conclusion  a number of both practical and conceptual basic challenges are still to be resolved prior to the full implementation of cQA  such as a sufficient specification to activate documentation requirements and an inspection system capable of separating actual quality problems from documentary deficits. So far  a comprehensive cost-utility analysis of cQA has not been provided  in particular with comparison to existing QA systems. In order to optimise cost and utility of cQA an evidence-based approach is required for both the extension of cQA areas and for QA provisions. Copyright Â© 2013. Published by Elsevier GmbH.Implementing hospital quality assurance policies in Iran: balancing licensing  annual evaluation  inspections and quality management systems.PubMedAghaei Hashjin  Asgar; Delgoshaei  Bahram; Kringos  Dionne S; Tabibi  Seyed Jamaladin; Manouchehri  Jila; Klazinga  Niek S2015-01-01The purpose of this paper is to provide an overview of applied hospital quality assurance (QA) policies in Iran. A mixed method (quantitative data and qualitative document analysis) study was carried out between 1996 and 2010. The QA policy cycle forms a tight monitoring system to assure hospital quality by combining mandatory and voluntary methods in Iran. The licensing  annual evaluation and grading  and regulatory inspections statutorily implemented by the government as a national package to assure and improve hospital care quality  while implementing quality management systems (QMS) was voluntary for hospitals. The government's strong QA policy legislation role and support has been an important factor for successful QA implementation in Iran  though it may affected QA assessment independency and validity. Increased hospital evaluation independency and repositioning  updating standards  professional involvement and effectiveness studies could increase QA policy impact and maturity. The study highlights the current QA policy implementation cycle in Iranian hospitals. It provides a basis for further quality strategy development in Iranian hospitals and elsewhere. It also raises attention about finding the optimal balance between different QA policies  which is topical for many countries. This paper describes experiences when implementing a unique approach  combining mandatory and voluntary QA policies simultaneously in a developing country  which has invested considerably over time to improve hospital quality. The experiences with a mixed obligatory/voluntary approach and comprehensive policies in Iran may contain lessons for policy makers in developing and developed countries.Reliability and quality assurance on the MOD 2 wind systemNASA Technical Reports Server (NTRS)Mason  W. E. B.; Jones  B. G.1981-01-01The Safety  Reliability  and Quality Assurance (R&QA) approach developed for the largest wind turbine generator  the Mod 2  is described. The R&QA approach assures that the machine is not hazardous to the public or to the operating personnel  is operated unattended on a utility grid  demonstrates reliable operation  and helps establish the quality assurance and maintainability requirements for future wind turbine projects. The significant guideline consisted of a failure modes and effects analysis (FMEA) during the design phase  hardware inspections during parts fabrication  and three simple documents to control activities during machine construction and operation.National Ignition Facility quality assurance program plan revision 2SciTech ConnectWolfe  C R1998-06-01NIF Project activities will be conducted in a manner consistent with the guidance and direction of the DOE Order on Quality Assurance (414.1)  the LLNL QA Program  and the Laser Directorate QA Plan. Quality assurance criteria will be applied in a graded manner to achieve a balance between the rigor of application of QA measures and the scale  cost  and complexity of the work involved. Accountability for quality is everyone's  extending from the Project Manager through established lines of authority to all Project personnel  who are responsible for the requisite quality of their own work. The NLF QA Program willmoreÂ Â» be implemented by personnel conducting their activities to meet requirements and expectations  according to established plans and procedures that reflect the way business is to be conducted on the Project.Â«Â lessQuality Assurance for Essential Climate VariablesNASA Astrophysics Data System (ADS)Folkert Boersma  K.; Muller  Jan-Peter2015-04-01Satellite data are of central interest to the QA4ECV project. Satellites have revolutionized the Earth's observation system of climate change and air quality over the past three decades  providing continuous data for the entire Earth. However  many users of these data are lost in the fog as to the quality of these satellite data. Because of this  the European Union expressed in its 2013 FP7 Space Research Call a need for reliable  traceable  and understandable quality information on satellite data records that could serve as a blueprint contribution to a future Copernicus Climate Change Service. The potential of satellite data to benefit climate change and air quality services is too great to be ignored. QA4ECV therefore bridges the gap between end-users of satellite data and the satellite data products. We are developing an internationally acceptable Quality Assurance (QA) framework that provides understandable and traceable quality information for satellite data used in climate and air quality services. Such a framework should deliver the historically linked long-term data sets that users need  in a format that they can readily use. QA4ECV has approached more than 150 users and suppliers of satellite data to collect their needs and expectations. The project will use their response as a guideline for developing user-friendly tools to obtain information on the completeness  accuracy  and fitness-for-purpose of the satellite datasets. QA4ECV collaborates with 4 joint FP7 Space projects in reaching out to scientists  policy makers  and other end-users of satellite data to improve understanding of the special challenges -and also opportunities- of working with satellite data for climate and air quality purposes. As a demonstration of its capacity  QA4ECV will generate multi-decadal climate data records for 3 atmospheric ECV precursors (nitrogen dioxide  formaldehyde  and carbon monoxide) and 3 land ECVs (albedo  leaf area index and absorbed photosynthetically activeQAIT: a quality assurance issue tracking tool to facilitate the improvement of clinical data quality.PubMedZhang  Yonghong; Sun  Weihong; Gutchell  Emily M; Kvecher  Leonid; Kohr  Joni; Bekhash  Anthony; Shriver  Craig D; Liebman  Michael N; Mural  Richard J; Hu  Hai2013-01-01In clinical and translational research as well as clinical trial projects  clinical data collection is prone to errors such as missing data  and misinterpretation or inconsistency of the data. A good quality assurance (QA) program can resolve many such errors though this requires efficient communications between the QA staff and data collectors. Managing such communications is critical to resolving QA problems but imposes a major challenge for a project involving multiple clinical and data processing sites. We have developed a QA issue tracking (QAIT) system to support clinical data QA in the Clinical Breast Care Project (CBCP). This web-based application provides centralized management of QA issues with role-based access privileges. It has greatly facilitated the QA process and enhanced the overall quality of the CBCP clinical data. As a stand-alone system  QAIT can supplement any other clinical data management systems and can be adapted to support other projects. Copyright Â© 2012 Elsevier Ireland Ltd. All rights reserved.Quality Assurance and Control Considerations in Environmental Measurements and MonitoringNASA Astrophysics Data System (ADS)Sedlet  Jacob1982-06-01Quality assurance and quality control have become accepted as essential parts of all environmental surveillance  measurements  and monitoring programs  both nuclear and non-nuclear. The same principles and details apply to each. It is primarily the final measurement technique that differs. As the desire and need to measure smaller amounts of pollutants with greater accuracy has increased  it has been recognized that quality assurance and control programs are cost-effective in achieving the expected results. Quality assurance (QA) consists of all the actions necessary to provide confidence in the results. Quality control (QC) is a part of QA  and consists of those actions and activities that permit the control of the individual steps in the environmental program. The distinction between the two terms is not always clearly defined  but a sharp division is not necessary. The essential principle of QA and QC is a commitment to high quality results. The essential components of a QA and QC program are a complete  written procedures manual for all parts of the environmental program  the use of standard or validated procedures  participation in applicable interlaboratory comparison or QA programs  replicate analysis and measurement  training of personnel  and a means of auditing or checking that the QA and QC programs are properly conducted. These components are discussed below in some detail.Quality assurance and ergonomics in the mammography department.PubMedReynolds  April2014-01-01Quality assurance (QA) in mammography is a system of checks that helps ensure the proper functioning of imaging equipment and processes. Ergonomics is a scientific approach to arranging the work environment to reduce the risk of work-related injuries while increasing staff productivity and job satisfaction. This article reviews both QA and ergonomics in mammography and explains how they work together to create a safe and healthy environment for radiologic technologists and their patients. QA and quality control requirements in mammography are discussed  along with ergonomic best practices in the mammography setting.Quality assurance in European pharmacy education and training*PubMed CentralGuimarÄes Morais  Jose A.; Cavaco  Afonso M.; Rombaut  Bart; Rouse  Michael J.; Atkinson  JeffreyA survey of quality assurance (QA) systems in European faculties of pharmacy was carried out under the auspices of the European Association of Faculties of Pharmacy PHARMINE consortium. A questionnaire based on the quality criteria of the International Pharmaceutical Federation and the Accreditation Council for Pharmacy Education (USA) was sent out to European faculties. Replies were obtained from 28 countries. Just above half has a working QA system. QA scores were high concerning matters such as complete curriculum and training  use of European Credit Transfer System  studentsâ€™ representation and promotion of professional behavior. QA scores were low concerning matters such as evaluation of achievement of mission and goals  and financial resources. The PHARMINE consortium now has a basis upon which to elaborate and promote QA in European pharmacy faculties. PMID:24198856Quality Assurance and Improvement Practice in Mental Health Agencies: Roles  Activities  Targets and ContributionsPubMed CentralMcMillen  Curtis; Zayas  Luis E.; Books  Samantha; Lee  Madeline2009-01-01Accompanying the rise in the number of mental health agency personnel tasked with quality assurance and improvement (QA/I) responsibilities is an increased need to understand the nature of the work these professionals undertake. Four aspects of the work of quality assurance and improvement (QA/I) professionals in mental health were explored in this qualitative study: their perceived roles  their major activities  their QA/I targets  and their contributions. In-person interviews were conducted with QA/I professionals at 16 mental health agencies. Respondents perceived their roles at varying levels of complexity  focused on different targets  and used different methods to conduct their work. Few targets of QA/I work served as indicators of high quality care. Most QA/I professionals provided concrete descriptions of how they had improved agency services  while others could describe none. Accreditation framed much of agency QA/I work  perhaps to its detriment. PMID:18688707Read Code Quality AssurancePubMed CentralSchulz  Erich; Barrett  James W.; Price  Colin1998-01-01As controlled clinical vocabularies assume an increasing role in modern clinical information systems  so the issue of their quality demands greater attention. In order to meet the resulting stringent criteria for completeness and correctness  a quality assurance system comprising a database of more than 500 rules is being developed and applied to the Read Thesaurus. The authors discuss the requirement to apply quality assurance processes to their dynamic editing database in order to ensure the quality of exported products. Sources of errors include human  hardware  and software factors as well as new rules and transactions. The overall quality strategy includes prevention  detection  and correction of errors. The quality assurance process encompasses simple data specification  internal consistency  inspection procedures and  eventually  field testing. The quality assurance system is driven by a small number of tables and UNIX scripts  with â€œbusiness rulesâ€ declared explicitly as Structured Query Language (SQL) statements. Concurrent authorship  client-server technology  and an initial failure to implement robust transaction control have all provided valuable lessons. The feedback loop for error management needs to be short. PMID:9670131[Integrated quality assurance].PubMedBÃ¶gel  K; StÃ¶hr  K1994-07-01The definition of terms and connotation of ""Quality""  ""Quality Assurance"" and ""Integration"" lead to an analysis and understanding of inhibiting and fostering factors of the ""Health Triad"" of people  animals and environment. Although ""Quality"" is largely or ultimately determined by the consumer  there are considerable differences as this term is applied by (a) the individual consumer  (b) the dynamic producer defending or gaining markets  (c) those engaged in traditional product manufacturing  or (d) governments setting (minimum) requirements for the sake of free trade. ""Quality Assurance"" offers cooperation of partners all along the food chain from ""pasture to table"". The managerial process turned into a continuum of responsibility and agreement on processes and product characteristics. This overcomes the disadvantages of strategies stressing distinct defense barriers. In practice this philosophy of a predominant role of defence barriers proved largely partnership destructive  in that it permitted to shift responsibilities for failures and to claim administrative competence according to momentary situations and interests. ""Integrated Quality Assurance"" means mutual agreement of two or more partners along the food chain (e. g. feed producers  farmers  animal health industry  veterinarians and food processors) on product characteristics and production methods. It involves essential system elements including facilities  materials  manpower  information  transport  management etc. Different principles and procedures of quality assurance have been introduced in practice  including agriculture and food processing. These different approaches are not mutually exclusive but largely of complementary nature.(ABSTRACT TRUNCATED AT 250 WORDS)Quality Assurance in Post-Secondary Education: The Student ExperienceERIC Educational Resources Information CenterLaw  Dennis Chung Sea2010-01-01Purpose: A major focus of the recent research into the quality of post-secondary education is the centrality of the student experience. The purpose of this paper is to review the literature on studies addressing such a focus to shed light on how quality assurance (QA) practices can be improved. Design/methodology/approach: The paper reviews someâ€¦Quality Assurance for AllERIC Educational Resources Information CenterCheung  Peter P. T.; Tsui  Cecilia B. S.2010-01-01For higher education reform  most decision-makers aspire to achieving a higher participation rate and a respectable degree of excellence with diversity at the same time. But very few know exactly how. External quality assurance is a fair basis for differentiation but there can be doubt and resistance in some quarters. Stakeholder interests differâ€¦Quality Assurance Program DescriptionSciTech ConnectHalford  Vaughn Edward; Ryder  Ann MarieEffective May 1  2017  led by a new executive leadership team  Sandia began operating within a new organizational structure. National Technology and Engineering Solutions of Sandia (Sandiaâ€™s) Quality Assurance Program (QAP) was established to assign responsibilities and authorities  define workflow policies and requirements  and provide for the performance and assessment of work.Software quality assurance | NewsScience.gov WebsitesMeasure was removed: ""Sufficient level of detail in the requirements to develop test cases."" ; This control measure was removed since the sufficient level of detail needed to develop test cases is recorded for all test cases. (Note: This is mandatory for applications graded with a High Quality AssuranceAutomating linear accelerator quality assurance.PubMedEckhause  Tobias; Al-Hallaq  Hania; Ritter  Timothy; DeMarco  John; Farrey  Karl; Pawlicki  Todd; Kim  Gwe-Ya; Popple  Richard; Sharma  Vijeshwar; Perez  Mario; Park  SungYong; Booth  Jeremy T; Thorwarth  Ryan; Moran  Jean M2015-10-01The purpose of this study was 2-fold. One purpose was to develop an automated  streamlined quality assurance (QA) program for use by multiple centers. The second purpose was to evaluate machine performance over time for multiple centers using linear accelerator (Linac) log files and electronic portal images. The authors sought to evaluate variations in Linac performance to establish as a reference for other centers. The authors developed analytical software tools for a QA program using both log files and electronic portal imaging device (EPID) measurements. The first tool is a general analysis tool which can read and visually represent data in the log file. This tool  which can be used to automatically analyze patient treatment or QA log files  examines the files for Linac deviations which exceed thresholds. The second set of tools consists of a test suite of QA fields  a standard phantom  and software to collect information from the log files on deviations from the expected values. The test suite was designed to focus on the mechanical tests of the Linac to include jaw  MLC  and collimator positions during static  IMRT  and volumetric modulated arc therapy delivery. A consortium of eight institutions delivered the test suite at monthly or weekly intervals on each Linac using a standard phantom. The behavior of various components was analyzed for eight TrueBeam Linacs. For the EPID and trajectory log file analysis  all observed deviations which exceeded established thresholds for Linac behavior resulted in a beam hold off. In the absence of an interlock-triggering event  the maximum observed log file deviations between the expected and actual component positions (such as MLC leaves) varied from less than 1% to 26% of published tolerance thresholds. The maximum and standard deviations of the variations due to gantry sag  collimator angle  jaw position  and MLC positions are presented. Gantry sag among Linacs was 0.336 Â± 0.072 mm. The standard deviation in MLCSoftware Quality Assurance MetricsNASA Technical Reports Server (NTRS)McRae  Kalindra A.2004-01-01Software Quality Assurance (SQA) is a planned and systematic set of activities that ensures conformance of software life cycle processes and products conform to requirements  standards and procedures. In software development  software quality means meeting requirements and a degree of excellence and refinement of a project or product. Software Quality is a set of attributes of a software product by which its quality is described and evaluated. The set of attributes includes functionality  reliability  usability  efficiency  maintainability  and portability. Software Metrics help us understand the technical process that is used to develop a product. The process is measured to improve it and the product is measured to increase quality throughout the life cycle of software. Software Metrics are measurements of the quality of software. Software is measured to indicate the quality of the product  to assess the productivity of the people who produce the product  to assess the benefits derived from new software engineering methods and tools  to form a baseline for estimation  and to help justify requests for new tools or additional training. Any part of the software development can be measured. If Software Metrics are implemented in software development  it can save time  money  and allow the organization to identify the caused of defects which have the greatest effect on software development. The summer of 2004  I worked with Cynthia Calhoun and Frank Robinson in the Software Assurance/Risk Management department. My task was to research and collect  compile  and analyze SQA Metrics that have been used in other projects that are not currently being used by the SA team and report them to the Software Assurance team to see if any metrics can be implemented in their software assurance life cycle process.Quality assurance of the gene ontology using abstraction networks.PubMedOchs  Christopher; Perl  Yehoshua; Halper  Michael; Geller  James; Lomax  Jane2016-06-01The gene ontology (GO) is used extensively in the field of genomics. Like other large and complex ontologies  quality assurance (QA) efforts for GO's content can be laborious and time consuming. Abstraction networks (AbNs) are summarization networks that reveal and highlight high-level structural and hierarchical aggregation patterns in an ontology. They have been shown to successfully support QA work in the context of various ontologies. Two kinds of AbNs  called the area taxonomy and the partial-area taxonomy  are developed for GO hierarchies and derived specifically for the biological process (BP) hierarchy. Within this framework  several QA heuristics  based on the identification of groups of anomalous terms which exhibit certain taxonomy-defined characteristics  are introduced. Such groups are expected to have higher error rates when compared to other terms. Thus  by focusing QA efforts on anomalous terms one would expect to find relatively more erroneous content. By automatically identifying these potential problem areas within an ontology  time and effort will be saved during manual reviews of GO's content. BP is used as a testbed  with samples of three kinds of anomalous BP terms chosen for a taxonomy-based QA review. Additional heuristics for QA are demonstrated. From the results of this QA effort  it is observed that different kinds of inconsistencies in the modeling of GO can be exposed with the use of the proposed heuristics. For comparison  the results of QA work on a sample of terms chosen from GO's general population are presented.Quality Assurance for University Teaching.ERIC Educational Resources Information CenterEllis  Roger  Ed.This book  written from a British perspective  presents 17 papers on quality assurance in teaching at the university level. The first eight papers address issues of assuring quality and include: (1) ""Quality Assurance for University Teaching; Issues and Approaches"" (Roger Ellis); (2) ""A British Standard for Universityâ€¦Quality assurance  training  and certification in ozone air pollution studiesTreesearchSusan Schilling; Paul Miller; Brent Takemoto1996-01-01Uniform  or standard  measurement methods of data are critical to projects monitoring change to forest systems. Standardized methods  with known or estimable errors  contribute greatly to the confidence associated with decisions on the basis of field data collections (Zedaker and Nicholas 1990). Quality assurance (QA) for the measurement process includes operations and...Inferring random component distributions from environmental measurements for quality assuranceUSDA-ARS?s Scientific Manuscript databaseEnvironmental measurement programs can add value by providing not just accurate data  but also a measure of that accuracy. While quality assurance (QA) has been recognized as necessary since almost the beginning of automated weather measurement  it has received less attention than the data proper. M...Assuring Quality in E-Learning Course Design: The RoadmapERIC Educational Resources Information CenterVlachopoulos  Dimitrios2016-01-01Quality Assurance (QA) concepts and applications in Higher Education (HE) emerge from evolving meanings related to HE's dynamic relationship with social  economic  cultural  and technological developments. The latter has been redefined by the growth spurred by the forms distance and online education acquired during the last decades. Creating aâ€¦Quality Assurance and Gender Discrimination in English Universities: An InvestigationERIC Educational Resources Information CenterSmith  Jayne2008-01-01The present paper argues that university quality assurance (QA) promotes a masculinist culture leading to systemic discrimination against female academics. The analysis relates to the question of what it is about academic life that results in persistent gender inequality. Based on an ethnographically informed comparative study  textual/discourseâ€¦Perspectives on Quality and Quality Assurance in Learner Support Areas at Three Southeast Asian Open UniversitiesERIC Educational Resources Information CenterDarojat  Ojat; Nilson  Michelle; Kaufman  David2015-01-01While quality measures in higher education in general have gained significant and growing attention over the past 30Â years  questions remain about quality in open universities. This research was an international comparative case study focusing on perceptions of quality and quality assurance (QA) in learner support areas at open universities. Theâ€¦Overall Quality Assurance Project Plan  Remedial Investigation/Feasibility Study Fort Sheridan  Illinois  Volume 1.DTIC Science & Technology1995-03-15billion volume ppm parts per million PT pole-mounted PTFE polytetrafluoro-ethylene PUF polyurethane foam PVC polyvinyl chloride QA quality assurance...and Illinois Environmental Protection Agency (IEPA) quality assurance (QA) objectives. The format of the OQAPP is based on ""Interim Guidelines and...County. The till material deposited in the Fort Sheridan region has been classified as the Wadsworth Till Member of the Wedron Formation . This tillThe quality assurance liaison: Combined technical and quality assurance supportNASA Astrophysics Data System (ADS)Bolivar  S. L.; Day  J. L.1993-03-01The role of the quality assurance liaison  the responsibilities of this position  and the evolutionary changes in duties over the last six years are described. The role of the quality assurance liaison has had a very positive impact on the Los Alamos Yucca Mountain Site Characterization (YW) quality assurance program. Having both technical and quality assurance expertise  the quality assurance liaisons are able to facilitate communications with scientists on quality assurance issues and requirements  thereby generating greater productivity in scientific investigations. The quality assurance liaisons help ensure that the scientific community knows and implements existing requirements  is aware of new or changing regulations  and is able to conduct scientific work within Project requirements. The influence of the role of the quality assurance liaison can be measured by an overall improvement in attitude of the staff regarding quality assurance requirements and improved job performance  as well as a decrease in deficiencies identified during both internal and external audits and surveillances. This has resulted in a more effective implementation of quality assurance requirements.A Functional Model of Quality Assurance for Psychiatric Hospitals and Corresponding Staffing Requirements.ERIC Educational Resources Information CenterKamis-Gould  Edna; And Others1991-01-01A model for quality assurance (QA) in psychiatric hospitals is described. Its functions (general QA  utilization review  clinical records  evaluation  management information systems  risk management  and infection control)  subfunctions  and corresponding staffing requirements are reviewed. This model was designed to foster standardization in QAâ€¦Quality Assurance in Gerontological and Geriatric Training Programs: The European CaseERIC Educational Resources Information CenterPolitynska  Barbara; van Rijsselt  Rene J. T.; Lewko  Jolanta; Philp  Ian; Figueiredo  Daniella; De Sousa  Lilliana2012-01-01Quality assurance (QA) in gerontological and geriatric education programs is regarded as essential to maintain standards  strengthen accountability  improve readability of qualifications  and facilitate professional mobility. In this article the authors present a summary of international developments in QA and elaborate four international trends â€¦Quality Assurance and Risk Management: A Survey of Dental Schools and Recommendations for Integrated Program Management.ERIC Educational Resources Information CenterFredekind  Richard E.; Cuny  Eve J.; Nadershahi  Nader A.2002-01-01Surveyed U.S. and Canadian dental schools about integration of quality assurance (QA) and risk management (RM) and what mechanisms have been most effective in measuring accomplishments. Main findings included that a majority of schools had a written QA program and committee and many reported significant changes resulting from the program; overâ€¦Walking the Line: Quality Assurance Policy Development and Implementation in Vi?t NamERIC Educational Resources Information CenterMadden  Meggan2014-01-01Although Vi?t Nam's experiences with quality assurance (QA) policy development have been influenced by its relationships with  and funding from  the World Bank and regional organizations  the state-centric values of the Socialist Republic of Vi?t Nam still navigate the implementation process. The development of QA in Vietnamese higher educationâ€¦Quality assurance and accreditation.PubMed1997-01-01In 1996  the Joint Commission International (JCI)  which is a partnership between the Joint Commission on Accreditation of Healthcare Organizations and Quality Healthcare Resources  Inc.  became one of the contractors of the Quality Assurance Project (QAP). JCI recognizes the link between accreditation and quality  and uses a collaborative approach to help a country develop national quality standards that will improve patient care  satisfy patient-centered objectives  and serve the interest of all affected parties. The implementation of good standards provides support for the good performance of professionals  introduces new ideas for improvement  enhances the quality of patient care  reduces costs  increases efficiency  strengthens public confidence  improves management  and enhances the involvement of the medical staff. Such good standards are objective and measurable; achievable with current resources; adaptable to different institutions and cultures; and demonstrate autonomy  flexibility  and creativity. The QAP offers the opportunity to approach accreditation through research efforts  training programs  and regulatory processes. QAP work in the area of accreditation has been targeted for Zambia  where the goal is to provide equal access to cost-effective  quality health care; Jordan  where a consensus process for the development of standards  guidelines  and policies has been initiated; and Ecuador  where JCI has been asked to help plan an approach to the evaluation and monitoring of the health care delivery system.Construction quality assurance reportSciTech ConnectRoscha  V.1994-09-08This report provides a summary of the construction quality assurance (CQA) observation and test results  including: The results of the geosynthetic and soil materials conformance testing. The observation and testing results associates with the installation of the soil liners. The observation and testing results associated with the installation of the HDPE geomembrane liner systems. The observation and testing results associated with the installation of the leachate collection and removal systems. The observation and testing results associated with the installation of the working surfaces. The observation and testing results associated with in-plant manufacturing process. Summary of submittal reviews by Golder ConstructionmoreÂ Â» Services  Inc. The submittal and certification of the piping material specifications. The observation and verification associated of the Acceptance Test Procedure results of the operational equipment functions. Summary of the ECNs which are incorporated into the project.Â«Â lessAnatomic modeling using 3D printing: quality assurance and optimization.PubMedLeng  Shuai; McGee  Kiaran; Morris  Jonathan; Alexander  Amy; Kuhlmann  Joel; Vrieze  Thomas; McCollough  Cynthia H; Matsumoto  Jane2017-01-01The purpose of this study is to provide a framework for the development of a quality assurance (QA) program for use in medical 3D printing applications. An interdisciplinary QA team was built with expertise from all aspects of 3D printing. A systematic QA approach was established to assess the accuracy and precision of each step during the 3D printing process  including: image data acquisition  segmentation and processing  and 3D printing and cleaning. Validation of printed models was performed by qualitative inspection and quantitative measurement. The latter was achieved by scanning the printed model with a high resolution CT scanner to obtain images of the printed model  which were registered to the original patient images and the distance between them was calculated on a point-by-point basis. A phantom-based QA process  with two QA phantoms  was also developed. The phantoms went through the same 3D printing process as that of the patient models to generate printed QA models. Physical measurement  fit tests  and image based measurements were performed to compare the printed 3D model to the original QA phantom  with its known size and shape  providing an end-to-end assessment of errors involved in the complete 3D printing process. Measured differences between the printed model and the original QA phantom ranged from -0.32 mm to 0.13 mm for the line pair pattern. For a radial-ulna patient model  the mean distance between the original data set and the scanned printed model was -0.12 mm (ranging from -0.57 to 0.34 mm)  with a standard deviation of 0.17 mm. A comprehensive QA process from image acquisition to completed model has been developed. Such a program is essential to ensure the required accuracy of 3D printed models for medical applications.Quality Assurance and Accreditation in Higher Education: India vis-Ã -vis European CountriesERIC Educational Resources Information CenterDey  Niradhar2011-01-01Quality assurance (QA) and accreditation in higher education include the systematic management and assessment of procedures to monitor performance and to address areas of improvement. In the context of globalization  without assuring the quality of higher education programmes it is not possible to ensure credit transfer and student mobility  toâ€¦Quality Assurance and Quality Control Practices for Rehabilitation of Sewer and Water MainsEPA Science InventoryAs part of the US Environmental Protection Agency (EPA)â€™s Aging Water Infrastructure Research Program  several areas of research are being pursued  including a review of quality assurance and quality control (QA/QC) practices and acceptance testing during the installation of reha...Quality Assurance and Quality Control Practices For Rehabilitation of Sewer and Water MainsEPA Science InventoryAs part of the US Environmental Protection Agency (EPA)â€™s Aging Water Infrastructure Research Program  several areas of research are being pursued including a review of quality assurance and quality control (QA/QC) practices and acceptance testing during the installation of rehab...Power Supplies for Space Systems Quality Assurance by Sandia LaboratoriesDOE R&D Accomplishments DatabaseHannigan  R. L.; Harnar  R. R.1976-07-01The Sandia Laboratories` participation in Quality Assurance programs for Radioisotopic Thermoelectric Generators which have been used in space systems over the past 10 years is summarized. Basic elements of this QA program are briefly described and recognition of assistance from other Sandia organizations is included. Descriptions of the various systems for which Sandia has had the QA responsibility are presented  including SNAP 19 (Nimbus  Pioneer  Viking)  SNAP 27 (Apollo)  Transit  Multi Hundred Watt (LES 8/9 and MJS)  and a new program  High Performance Generator Mod 3. The outlook for Sandia participation in RTG programs for the next several years is noted.Quality assurance  an administrative means to a managerial end: Part IV.PubMedClark  G B1992-01-01This is the fourth and final part of a series of articles on laboratory quality surveillance. Part I addressed the historical background of medical quality assurance. Part II covered surveillance guidelines of the Joint Commission on Accreditation of Healthcare Organizations (JCAHO) and the College of American Pathologists with emphasis on quality assurance (QA) and the ten-step process. Part III focused on the JCAHO transition from QA to quality assessment and improvement. Part IV concludes the series by discussing the systematic identification of quality indicators in the total quality management and continuous quality improvement environment.Developing cross-sectoral quality assurance for cataract surgery in the statutory quality assurance program of the German health care system: Experiences and lessons learned.PubMedBramesfeld  Anke; Pauletzki  JÃ¼rgen; Behrenz  Lars; Szecsenyi  Joachim; Willms  Gerald; Broge  BjÃ¶rn2015-08-01Since 2001  statutory external quality assurance (QA) for hospital care has been in place in the German health system. In 2009  the decision was taken to expand it to cross-sectoral procedures. This novel and unprecedented form of national QA aims at (1) making the quality procedures comparable that are provided both in inpatient and outpatient care  (2) following-up outcomes of hospital care after patients' discharge and (3) measuring the quality of complex treatment chains across interfaces. As a pioneer procedure a QA procedure in cataract surgery QA was developed. Using this as an example  challenges of cross-sectoral QA are highlighted. These challenges relate  in particular  to three technical problems: triggering cases for documentation  following-up patients' after hospital discharge  and the burden of documentation in outpatient care. These problems resulted finally in the haltering of the development of the QA procedure. However  the experiences gained with this first development of cross-sectoral QA inspired the reorientation and further development of the field in Germany. Future cross-sectoral QA will rigorously aim at keeping burden of documentation small. It will draw data for QA mainly at three sources: routine data  patient surveys and peer reviews using indicators. Policy implications of this reorientation are discussed. Copyright Â© 2015 Elsevier Ireland Ltd. All rights reserved.Recent Trends in Quality AssuranceERIC Educational Resources Information CenterAmaral  Alberto; Rosa  Maria Joao2010-01-01In this paper we present a brief description of the evolution of quality assurance in Europe  paying particular attention to its relationship to the rising loss of trust in higher education institutions. We finalise by analysing the role of the European Commission in the setting up of new quality assurance mechanisms that tend to promoteâ€¦Quality Assurance Specifications for Planetary Protection AssaysNASA Astrophysics Data System (ADS)Baker  AmyAs the European Space Agency planetary protection (PP) activities move forward to support the ExoMars and other planetary missions  it will become necessary to increase staffing of labo-ratories that provide analyses for these programs. Standardization of procedures  a comprehen-sive quality assurance program  and unilateral training of personnel will be necessary to ensure that the planetary protection goals and schedules are met. The PP Quality Assurance/Quality Control (QAQC) program is designed to regulate and monitor procedures performed by labora-tory personnel to ensure that all work meets data quality objectives through the assembly and launch process. Because personnel time is at a premium and sampling schedules are often de-pendent on engineering schedules  it is necessary to have flexible staffing to support all sampling requirements. The most productive approach to having a competent and flexible work force is to establish well defined laboratory procedures and training programs that clearly address the needs of the program and the work force. The quality assurance specification for planetary protection assays has to ensure that labora-tories and associated personnel can demonstrate the competence to perform assays according to the applicable standard AD4. Detailed subjects included in the presentation are as follows: â€¢ field and laboratory control criteria â€¢ data reporting â€¢ personnel training requirements and certification â€¢ laboratory audit criteria. Based upon RD2 for primary and secondary validation and RD3 for data quality objectives  the QAQC will provide traceable quality assurance safeguards by providing structured laboratory requirements for guidelines and oversight including training and technical updates  standardized documentation  standardized QA/QC checks  data review and data archiving.Project officer's perspective: quality assurance as a management tool.PubMedHeiby  J1993-06-01Advances in the management of health programs in less developed countries (LDC) have not kept pace with the progress of the technology used. The US Agency for International Development mandated the Quality Assurance Project (QAP) to provide quality improvement technical assistance to primary health care systems in LDCs while developing appropriate quality assurance (QA) strategies. The quality of health care in recent years in the US and Europe focused on the introduction of management techniques developed for industry into health systems. The experience of the QAP and its predecessor  the PRICOR Project  shows that quality improvement techniques facilitate measurement of quality of care. A recently developed WHO model for the management of the sick child provides scientifically based standards for actual care. Since 1988  outside investigators measuring how LDC clinicians perform have revealed serious deficiencies in quality compared with the program's own standards. This prompted developed of new QA management initiatives: 1) communicating standards clearly to the program staff; 2) actively monitoring actual performance corresponds to these standards; and 3) taking action to improve performance. QA means that managers are expected to monitor service delivery  undertake problem solving  and set specific targets for quality improvement. Quality improvement methods strengthen supervision as supervisors can objectively assess health worker performance. QA strengthens the management functions that support service delivery  e.g.  training  records management  finance  logistics  and supervision. Attention to quality can contribute to improved health worker motivation and effective incentive programs by recognition for a job well done and opportunities for learning new skills. These standards can also address patient satisfaction. QA challenges managers to aim for the optimal level of care attainable.LABORATORY AND FIELD AUDITS AS PART OF THE EPA (ENVIRONMENTAL PROTECTION AGENCY) HAZARDOUS WASTE ENGINEERING RESEARCH LABORATORY (HWERL) QUALITY ASSURANCE PROGRAMEPA Science InventoryAudits are an important and integral part of the EPA Hazardous Waste Engineering Research Laboratory (HWERL) Quality Assurance (QA) Program. As part of the overall QA program  audits are used to determine contractor compliance with quality assurance plans and to assess the overal...Technical aspects of quality assurance in radiation oncologyPubMed CentralSaw  CB; Ferenci  MS; Wanger  H2008-01-01The technical aspects of quality assurance (QA) in radiation oncology as practice in the United States will be reviewed and updated in the spirit of offering the experience to the radiation oncology communities in the Asia-Pacific region. The word â€œtechnicalâ€ is used to express the organisational components or processes and not the materials within the QA program. A comprehensive QA program in radiation oncology will have an official statement declaring the quality plan for effective patient care services it provides in a document. The QA program will include all aspects of patient care: physical  clinical  and medical aspects of the services. The document will describe the organisational structure  responsibilities  checks and procedures  and resources allocated to ensure the successful implementation of the quality of patient management. Regulatory guidelines and guidelines from accreditation agencies should be incorporated in the QA program to ensure compliance. The organisational structure will have a multidisciplinary QA committee that has the authority to evaluate continuously the effectiveness of the QA program to provide prompt corrective recommendations and to request feedback as needed to monitor the response. The continuous monitoring aspects require meetings to be held at regular intervals with the minutes of the meetings officially recorded and documented. To ensure that a QA program is effective  the program itself should be audited for quality at regular intervals at least annually. It has been recognised that the current QA program has not kept abreast with the rapid implementation of new and advanced radiation therapy technologies with the most recent in image-based radiation therapy technology. The societal bodies (ASTRO and AAPM) and federal agency (NCI) acknowledge this inadequacy and have held workshops to address this issue. The challenges for the societal bodies and federal agency are numerous that include (a) the prescriptive methodologyHelical tomotherapy quality assurance with ArcCHECKSciTech ConnectChapman  David; Barnett  Rob; Yartsev  Slav  E-mail: slav.yartsev@lhsc.on.ca2014-07-01To design a quality assurance (QA) procedure for helical tomotherapy that measures multiple beam parameters with 1 delivery and uses a rotating gantry to simulate treatment conditions. The customized QA procedure was preprogrammed on the tomotherapy operator station. The dosimetry measurements were performed using an ArcCHECK diode array and an A1SL ion chamber inserted in the central holder. The ArcCHECK was positioned 10 cm above the isocenter so that the 21-cm diameter detector array could measure the 40-cm wide tomotherapy beam. During the implementation of the new QA procedure  separate comparative measurements were made using ion chambers in both liquidmoreÂ Â» and solid water  the tomotherapy onboard detector array  and a MapCHECK diode array for a period of 10 weeks. There was good agreement (within 1.3%) for the beam output and cone ratio obtained with the new procedure and the routine QA measurements. The measured beam energy was comparable (0.3%) to solid water measurement during the 10-week evaluation period  excluding 2 of the 10 measurements with unusually high background. The symmetry reading was similarly compromised for those 2 weeks  and on the other weeks  it deviated from the solid water reading by âˆ¼2.5%. The ArcCHECK phantom presents a suitable alternative for performing helical tomotherapy QA  provided the background is collected properly. The proposed weekly procedure using ArcCHECK and water phantom makes the QA process more efficient.Â«Â lessDeveloping a quality assurance program for online services.PubMed CentralHumphries  A W; Naisawald  G V1991-01-01A quality assurance (QA) program provides not only a mechanism for establishing training and competency standards  but also a method for continuously monitoring current service practices to correct shortcomings. The typical QA cycle includes these basic steps: select subject for review  establish measurable standards  evaluate existing services using the standards  identify problems  implement solutions  and reevaluate services. The Claude Moore Health Sciences Library (CMHSL) developed a quality assurance program for online services designed to evaluate services against specific criteria identified by research studies as being important to customer satisfaction. These criteria include reliability  responsiveness  approachability  communication  and physical factors. The application of these criteria to the library's existing online services in the quality review process is discussed with specific examples of the problems identified in each service area  as well as the solutions implemented to correct deficiencies. The application of the QA cycle to an online services program serves as a model of possible interventions. The use of QA principles to enhance online service quality can be extended to other library service areas. PMID:1909197Developing a quality assurance program for online services.PubMedHumphries  A W; Naisawald  G V1991-07-01A quality assurance (QA) program provides not only a mechanism for establishing training and competency standards  but also a method for continuously monitoring current service practices to correct shortcomings. The typical QA cycle includes these basic steps: select subject for review  establish measurable standards  evaluate existing services using the standards  identify problems  implement solutions  and reevaluate services. The Claude Moore Health Sciences Library (CMHSL) developed a quality assurance program for online services designed to evaluate services against specific criteria identified by research studies as being important to customer satisfaction. These criteria include reliability  responsiveness  approachability  communication  and physical factors. The application of these criteria to the library's existing online services in the quality review process is discussed with specific examples of the problems identified in each service area  as well as the solutions implemented to correct deficiencies. The application of the QA cycle to an online services program serves as a model of possible interventions. The use of QA principles to enhance online service quality can be extended to other library service areas.Redesigning Radiotherapy Quality Assurance: Opportunities to Develop an Efficient  Evidence-Based System to Support Clinical Trials-Report of the National Cancer Institute Work Group on Radiotherapy Quality AssuranceSciTech ConnectBekelman  Justin E.  E-mail: bekelman@uphs.upenn.edu; Deye  James A.; Vikram  Bhadrasain2012-07-01Purpose: In the context of national calls for reorganizing cancer clinical trials  the National Cancer Institute sponsored a 2-day workshop to examine challenges and opportunities for optimizing radiotherapy quality assurance (QA) in clinical trial design. Methods and Materials: Participants reviewed the current processes of clinical trial QA and noted the QA challenges presented by advanced technologies. The lessons learned from the radiotherapy QA programs of recent trials were discussed in detail. Four potential opportunities for optimizing radiotherapy QA were explored  including the use of normal tissue toxicity and tumor control metrics  biomarkers of radiation toxicity  new radiotherapy modalities such asmoreÂ Â» proton beam therapy  and the international harmonization of clinical trial QA. Results: Four recommendations were made: (1) to develop a tiered (and more efficient) system for radiotherapy QA and tailor the intensity of QA to the clinical trial objectives (tiers include general credentialing  trial-specific credentialing  and individual case review); (2) to establish a case QA repository; (3) to develop an evidence base for clinical trial QA and introduce innovative prospective trial designs to evaluate radiotherapy QA in clinical trials; and (4) to explore the feasibility of consolidating clinical trial QA in the United States. Conclusion: Radiotherapy QA can affect clinical trial accrual  cost  outcomes  and generalizability. To achieve maximum benefit  QA programs must become more efficient and evidence-based.Â«Â lessRedesigning radiotherapy quality assurance: opportunities to develop an efficient  evidence-based system to support clinical trials--report of the National Cancer Institute Work Group on Radiotherapy Quality Assurance.PubMedBekelman  Justin E; Deye  James A; Vikram  Bhadrasain; Bentzen  Soren M; Bruner  Deborah; Curran  Walter J; Dignam  James; Efstathiou  Jason A; FitzGerald  T J; Hurkmans  Coen; Ibbott  Geoffrey S; Lee  J Jack; Merchant  Thomas E; Michalski  Jeff; Palta  Jatinder R; Simon  Richard; Ten Haken  Randal K; Timmerman  Robert; Tunis  Sean; Coleman  C Norman; Purdy  James2012-07-01In the context of national calls for reorganizing cancer clinical trials  the National Cancer Institute sponsored a 2-day workshop to examine challenges and opportunities for optimizing radiotherapy quality assurance (QA) in clinical trial design. Participants reviewed the current processes of clinical trial QA and noted the QA challenges presented by advanced technologies. The lessons learned from the radiotherapy QA programs of recent trials were discussed in detail. Four potential opportunities for optimizing radiotherapy QA were explored  including the use of normal tissue toxicity and tumor control metrics  biomarkers of radiation toxicity  new radiotherapy modalities such as proton beam therapy  and the international harmonization of clinical trial QA. Four recommendations were made: (1) to develop a tiered (and more efficient) system for radiotherapy QA and tailor the intensity of QA to the clinical trial objectives (tiers include general credentialing  trial-specific credentialing  and individual case review); (2) to establish a case QA repository; (3) to develop an evidence base for clinical trial QA and introduce innovative prospective trial designs to evaluate radiotherapy QA in clinical trials; and (4) to explore the feasibility of consolidating clinical trial QA in the United States. Radiotherapy QA can affect clinical trial accrual  cost  outcomes  and generalizability. To achieve maximum benefit  QA programs must become more efficient and evidence-based. Copyright Â© 2012 Elsevier Inc. All rights reserved.Template for updating regulations in QA manualsSciTech ConnectWhite  M.G.; Banerjee  B.1992-01-01Recently  the U.S. Department of Energy (DOE) issued new quality assurance (QA) orders to reflect current policies for conduct and operation of DOE-authorized programs and facilities. Establishing traceability to new QA criteria and requirements from former multidraft orders  QA manuals  and guidance documentation for DOE-funded work can be confusing. Identified critical considerations still must be addressed. Most of the newly stated QA criteria can be cross referenced  where applicable  to former QA plans and manuals. Where additional criteria occur  new procedures may be required  together with revisions in QA plans and manuals.Software Quality Assurance Audits GuidebooksNASA Technical Reports Server (NTRS)1990-01-01The growth in cost and importance of software to NASA has caused NASA to address the improvement of software development across the agency. One of the products of this program is a series of guidebooks that define a NASA concept of the assurance processes that are used in software development. The Software Assurance Guidebook  NASA-GB-A201  issued in September  1989  provides an overall picture of the NASA concepts and practices in software assurance. Second level guidebooks focus on specific activities that fall within the software assurance discipline  and provide more detailed information for the manager and/or practitioner. This is the second level Software Quality Assurance Audits Guidebook that describes software quality assurance audits in a way that is compatible with practices at NASA Centers.Modernization of software quality assuranceNASA Technical Reports Server (NTRS)Bhaumik  Gokul1988-01-01The customers satisfaction depends not only on functional performance  it also depends on the quality characteristics of the software products. An examination of this quality aspect of software products will provide a clear  well defined framework for quality assurance functions  which improve the life-cycle activities of software development. Software developers must be aware of the following aspects which have been expressed by many quality experts: quality cannot be added on; the level of quality built into a program is a function of the quality attributes employed during the development process; and finally  quality must be managed. These concepts have guided our development of the following definition for a Software Quality Assurance function: Software Quality Assurance is a formal  planned approach of actions designed to evaluate the degree of an identifiable set of quality attributes present in all software systems and their products. This paper is an explanation of how this definition was developed and how it is used.[Quality assurance and quality improvement. Personal experiences and intentions].PubMedRoche  B G; Sommer  C1995-01-01In may 1994 we were selected by the surgical Swiss association to make a study about quality in USA. During our travel we visited 3 types of institutions: Hospitals  National Institute of standard and Technology  Industry  Johnson & Johnson. We appreciate to compare 2 types of quality programs: Quality Assurance (QA) and Continuous Quality Improvement (CQI). In traditional healthcare circles  QA is the process established to meet external regulatory requirements and to assure that patient care is consistent with established standards. In a modern quality terms  QA outside of healthcare means designing a product or service  as well as controlling its production  so well that quality is inevitable. The ideas of W. Edward Deming is that there is never improvement just by inspection. He developed a theory based on 14 principles. A productive work is accomplished through processes. Understanding the variability of processes is a key to improve quality. Quality management sees each person in an organisation as part of one or more processes. The job of every worker is to receive the work of others  add value to that work  and supply it to the next person in the process. This is called the triple role the workers as customer  processor  and supplier. The main source of quality defects is problems in the process. The old assumption is that quality fails when people do the right thing wrong; the new assumption is that  more often  quality failures arise when people do the wrong think right. Exhortation  incentives and discipline of workers are unlikely to improve quality. If quality is failing when people do their jobs as designed  then exhorting them to do better is managerial nonsense. Modern quality theory is customer focused. Customers are identified internally and externally. The modern approach to quality is thoroughly grounded in scientific and statistical thinking. Like in medicine  the symptom is a defect in quality. The therapist of process must perform diagnosticQUALITY ASSURANCE: THE THREAD THAT WEAVES TOGETHER THE FABRIC OF DIVERSE DISCIPLINESEPA Science InventoryMature Quality Assurance (QA) programs do not call for high quality! However  they most often demand known quality. We can intuitively sense quality in our daily lives. Protection of the environment is  in part  dependent on the quality of data used in decision making. Wh...Redesigning Radiotherapy Quality Assurance: Opportunities to Develop an Efficient  Evidence-Based System to Support Clinical TrialsPubMed CentralBekelman  Justin E.; Deye  James A.; Vikram  Bhadrasain; Bentzen  Soren M.; Bruner  Deborah; Curran  Walter J.; Dignam  James; Efstathiou  Jason A.; FitzGerald  T. J.; Hurkmans  Coen; Ibbott  Geoffrey S.; Lee  J. Jack; Merchant  Timothy E.; Michalski  Jeff; Palta  Jatinder R.; Simon  Richard; Ten Haken  Randal K.; Timmerman  Robert; Tunis  Sean; Coleman  C. Norman; Purdy  James2012-01-01Background In the context of national calls for reorganizing cancer clinical trials  the National Cancer Institute (NCI) sponsored a two day workshop to examine the challenges and opportunities for optimizing radiotherapy quality assurance (QA) in clinical trial design. Methods Participants reviewed the current processes of clinical trial QA and noted the QA challenges presented by advanced technologies. Lessons learned from the radiotherapy QA programs of recent trials were discussed in detail. Four potential opportunities for optimizing radiotherapy QA were explored  including the use of normal tissue toxicity and tumor control metrics  biomarkers of radiation toxicity  new radiotherapy modalities like proton beam therapy  and the international harmonization of clinical trial QA. Results Four recommendations were made: 1) Develop a tiered (and more efficient) system for radiotherapy QA and tailor intensity of QA to clinical trial objectives. Tiers include (i) general credentialing  (ii) trial specific credentialing  and (iii) individual case review; 2) Establish a case QA repository; 3) Develop an evidence base for clinical trial QA and introduce innovative prospective trial designs to evaluate radiotherapy QA in clinical trials; and 4) Explore the feasibility of consolidating clinical trial QA in the United States. Conclusion Radiotherapy QA may impact clinical trial accrual  cost  outcomes and generalizability. To achieve maximum benefit  QA programs must become more efficient and evidence-based. PMID:22425219Saving Quality from Quality Assurance. PerspectiveERIC Educational Resources Information CenterStephenson  Sandra L.2004-01-01The word 'quality' has become a 'central term in the lexicon of contemporary higher education and a major point of interest to various interest groups'. As quality assurance systems have developed around the world  certain assumptions are becoming alarmingly widespread: for example that quality assurance is new to higher education  that qualityâ€¦Radiation shielding quality assuranceNASA Astrophysics Data System (ADS)Um  DallsunFor the radiation shielding quality assurance  the validity and reliability of the neutron transport code MCNP  which is now one of the most widely used radiation shielding analysis codes  were checked with lot of benchmark experiments. And also as a practical example  follows were performed in this thesis. One integral neutron transport experiment to measure the effect of neutron streaming in iron and void was performed with Dog-Legged Void Assembly in Knolls Atomic Power Laboratory in 1991. Neutron flux was measured six different places with the methane detectors and a BF-3 detector. The main purpose of the measurements was to provide benchmark against which various neutron transport calculation tools could be compared. Those data were used in verification of Monte Carlo Neutron & Photon Transport Code  MCNP  with the modeling for that. Experimental results and calculation results were compared in both ways  as the total integrated value of neutron fluxes along neutron energy range from 10 KeV to 2 MeV and as the neutron spectrum along with neutron energy range. Both results are well matched with the statistical error +/-20%. MCNP results were also compared with those of TORT  a three dimensional discrete ordinates code which was developed by Oak Ridge National Laboratory. MCNP results are superior to the TORT results at all detector places except one. This means that MCNP is proved as a very powerful tool for the analysis of neutron transport through iron & air and further it could be used as a powerful tool for the radiation shielding analysis. For one application of the analysis of variance (ANOVA) to neutron and gamma transport problems  uncertainties for the calculated values of critical K were evaluated as in the ANOVA on statistical data.Maintaining High Quality Data and Consistency Across a Diverse Flux Network: The Ameriflux QA/QC Technical TeamNASA Astrophysics Data System (ADS)Chan  S.; Billesbach  D. P.; Hanson  C. V.; Biraud  S.2014-12-01The AmeriFlux quality assurance and quality control (QA/QC) technical team conducts short term (<2 weeks) intercomparisons using a portable eddy covariance system (PECS) to maintain high quality data observations and data consistency across the AmeriFlux network (http://ameriflux.lbl.gov/). Site intercomparisons identify discrepancies between the in situ and portable measurements and calculated fluxes. Findings are jointly discussed by the site staff and the QA/QC team to improve in the situ observations. Despite the relatively short duration of an individual site intercomparison  the accumulated record of all site visits (numbering over 100 since 2002) is a unique dataset. The ability to deploy redundant sensors provides a rare opportunity to identify  quantify  and understand uncertainties in eddy covariance and ancillary measurements. We present a few specific case studies from QA/QC site visits to highlight and share new and relevant findings related to eddy covariance instrumentation and operation.QA program plan plutonium stabilization and handling project W-460SciTech ConnectSCHULTZ  J.W.This Quality Assurance Program Plan (QAPP) identifies Project Quality Assurance (QA) program requirements for all parties participating in the design  procurement  demolition  construction  installation  inspection and testing for Project W-460.Comprehensive quality assurance phantom for the small animal radiation research platform (SARRP)PubMed CentralJermoumi  M.; Korideck  H.; Bhagwat  M.; Zygmanski  P.; Makrigiogos  G.M.; Berbeco  R.I.; Cormack  R.C.; Ngwa  W.2016-01-01Purpose To develop and test the suitability and performance of a comprehensive quality assurance (QA) phantom for the Small Animal Radiation Research Platform (SARRP). Methods and materials A QA phantom was developed for carrying out daily  monthly and annual QA tasks including: imaging  dosimetry and treatment planning system (TPS) performance evaluation of the SARRP. The QA phantom consists of 15 (60 Ã— 60 Ã— 5 mm3) kV-energy tissue equivalent solid water slabs. The phantom can incorporate optically stimulated luminescence dosimeters (OSLD)  Mosfet or film. One slab  with inserts and another slab with hole patterns are particularly designed for image QA. Results Output constancy measurement results showed daily variations within 3%. Using the Mosfet in phantom as target  results showed that the difference between TPS calculations and measurements was within 5%. Annual QA results for the Percentage depth dose (PDD) curves  lateral beam profiles  beam flatness and beam profile symmetry were found consistent with results obtained at commissioning. PDD curves obtained using film and OSLDs showed good agreement. Image QA was performed monthly  with image-quality parameters assessed in terms of CBCT image geometric accuracy  CT number accuracy  image spatial resolution  noise and image uniformity. Conclusions The results show that the developed QA phantom can be employed as a tool for comprehensive performance evaluation of the SARRP. The study provides a useful reference for development of a comprehensive quality assurance program for the SARRP and other similar small animal irradiators  with proposed tolerances and frequency of required tests. PMID:25964129An introduction to quality assurance.PubMedRiggs  D G1989-10-01Although initially applied within the manufacturing sectors of industry the benefits of quality assurance to both specifiers and customers alike are rapidly being realised by all sectors of business and industry.[Development of quality assurance/quality control web system in radiotherapy].PubMedOkamoto  Hiroyuki; Mochizuki  Toshihiko; Yokoyama  Kazutoshi; Wakita  Akihisa; Nakamura  Satoshi; Ueki  Heihachi; Shiozawa  Keiko; Sasaki  Koji; Fuse  Masashi; Abe  Yoshihisa; Itami  Jun2013-12-01Our purpose is to develop a QA/QC (quality assurance/quality control) web system using a server-side script language such as HTML (HyperText Markup Language) and PHP (Hypertext Preprocessor)  which can be useful as a tool to share information about QA/QC in radiotherapy. The system proposed in this study can be easily built in one's own institute  because HTML can be easily handled. There are two desired functions in a QA/QC web system: (i) To review the results of QA/QC for a radiotherapy machine  manuals  and reports necessary for routinely performing radiotherapy through this system. By disclosing the results  transparency can be maintained  (ii) To reveal a protocol for QA/QC in one's own institute using pictures and movies relating to QA/QC for simplicity's sake  which can also be used as an educational tool for junior radiation technologists and medical physicists. By using this system  not only administrators  but also all staff involved in radiotherapy  can obtain information about the conditions and accuracy of treatment machines through the QA/QC web system.Study of quality assurance regulations for linear accelerators in Korea: A comparison study between the current status in Korea and the international guidelinesNASA Astrophysics Data System (ADS)Lee  Hyunho; Jeong  Seonghoon; Jo  Yunhui; Yoon  Myonggeun2015-07-01Quality assurance (QA) for medical linear accelerators is indispensable for appropriate cancer treatment. Some international organizations and advanced Western countries have provided QA guidelines for linear accelerators. Currently  QA regulations for linear accelerators in Korean hospitals specify a system in which each hospital stipulates its independent hospital-based protocols for QA procedures (HP_QAPs) and conducts QA based on those HP_QAPs while regulatory authorities verify whether items under those HP_QAPs have been performed. However  because this regulatory method cannot guarantee the quality of universal treatment and QA items with tolerance criteria are different in many hospitals  the presentation of standardized QA items and tolerance criteria is essential. In this study  QA items in HP_QAPs from various hospitals and those presented by international organizations  such as the International Atomic Energy Agency  the European Union  and the American Association of Physicist in Medicine  and by advanced Western countries  such as the USA  the UK  and Canada  were compared. Concordance rates between QA items for linear accelerators that were presented by the aforementioned organizations and those currently being implemented in Korean hospitals were shown to exhibit a daily QA of 50%  a weekly QA of 22%  a monthly QA of 43%  and an annual QA of 65%  and the overall concordance rates of all QA items were approximately 48%. In the comparison between QA items being implemented in Korean hospitals and those being implemented in advanced Western countries  concordance rates were shown to exhibit a daily QA of 50%  a weekly QA of 33%  a monthly QA of 60%  and an annual QA of 67%  and the overall concordance rates of all QA items were approximately 57%. The results of this study indicate that the HP_QAPs currently implemented by Korean hospitals as QA standards for linear accelerators used in radiation therapy do not meet international standards. If thisRedefining and expanding quality assurance.PubMedRobins  J L1992-12-01To meet the current standards of excellence necessary for blood establishments  we have learned from industry that a movement toward organization-wide quality assurance/total quality management must be made. Everyone in the organization must accept responsibility for participating in providing the highest quality products and services. Quality must be built into processes and design systems to support these quality processes. Quality assurance has been redefined to include a quality planning function described as the most effective way of designing quality into processes. A formalized quality planning process must be part of quality assurance. Continuous quality improvement has been identified as the strategy every blood establishment must support while striving for error-free processing as the long-term objective. The auditing process has been realigned to support and facilitate this same objective. Implementing organization-wide quality assurance/total quality management is one proven plan for guaranteeing the quality of the 20 million products that are transfused into 4 million patients each year and for moving toward the new order.The Columbia River Protection Supplemental Technologies Quality Assurance Project PlanSciTech ConnectFix  N. J.The U.S. Department of Energy (DOE) has conducted interim groundwater remedial activities on the Hanford Site since the mid-1990s for several groundwater contamination plumes. DOE established the Columbia River Protection Supplemental Technologies Project (Technologies Project) in 2006 to evaluate alternative treatment technologies. The objectives for the technology project are as follows: develop a 300 Area polyphosphate treatability test to immobilize uranium  design and test infiltration of a phosphate/apatite technology for Sr-90 at 100-N  perform carbon tetrachloride and chloroform attenuation parameter studies  perform vadose zone chromium characterization and geochemistry studies  perform in situ biostimulation of chromium studies for a reducing barriermoreÂ Â» at 100-D  and perform a treatability test for phytoremediation for Sr-90 at 100-N. This document provides the quality assurance guidelines that will be followed by the Technologies Project. This Quality Assurance Project Plan is based on the quality assurance requirements of DOE Order 414.1C  Quality Assurance  and 10 CFR 830  Subpart A--Quality Assurance Requirements as delineated in Pacific Northwest National Laboratoryâ€™s Standards-Based Management System. In addition  the technology project is subject to the Environmental Protection Agency (EPA) Requirements for Quality Assurance Project Plans (EPA/240/B-01/003  QA/R-5). The Hanford Analytical Services Quality Assurance Requirements Documents (HASQARD  DOE/RL-96-68) apply to portions of this project and to the subcontractors. HASQARD requirements are discussed within applicable sections of this plan.Â«Â lessHow Are the Results of Quality Assurance Programs Used to Inform Practices at a Distance Higher Education?ERIC Educational Resources Information CenterDarojat  Ojat2018-01-01This paper is to examine the implementation of quality assurance (QA) programs in distance higher education. Different challenges related to the development of QA programs at a distance higher institution and how to manage and implement the programs are discussed to show how the programs have been used to ensure the survival of the institution. Aâ€¦Quality Assurance in Education: Current Debates. A Report on a SOED-Sponsored Seminar (Stirling  Scotland  United Kingdom  June 1992).ERIC Educational Resources Information CenterStronach  Ian  Ed.Proceedings of a workshop held at the University of Stirling  Scotland  to critically examine issues in quality assurance (QA) in education are provided in this document. QA is the generic title for a series of business-management models that have been applied to educational contexts to describe and promote school effectiveness. Five papers andâ€¦Quality Assurance and Foreign Languages--Reflecting on Oral Assessment Practices in Two University Spanish Language Programs in AustraliaERIC Educational Resources Information CenterDÃ­az  Adriana R.; Hortiguera  Hugo; Espinoza Vera  Marcia2015-01-01In the era of quality assurance (QA)  close scrutiny of assessment practices has been intensified worldwide across the board. However  in the Australian context  trends in QA efforts have not reached the field of modern/foreign languages. This has largely resulted in leaving the establishment of language proficiency benchmarking up to individualâ€¦Multi-Site Quality Assurance Project Plan for Wisconsin Public Service Corporation  Peoples Gas Light and Coke Company  and North Shore GasEPA Pesticide FactsheetsThis Multi-Site QAPP presents the organization  data quality objectives (DQOs)  a set of anticipated activities  sample analysis  data handling and specific Quality Assurance/Quality Control (QA/QC) procedures associated with Studies done in EPA Region 5A comprehensive and efficient daily quality assurance for PBS proton therapyNASA Astrophysics Data System (ADS)Actis  O.; Meer  D.; KÃ¶nig  S.; Weber  D. C.; Mayor  A.2017-03-01There are several general recommendations for quality assurance (QA) measures  which have to be performed at proton therapy centres. However  almost each centre uses a different therapy system. In particular  there is no standard procedure for centres employing pencil beam scanning and each centre applies a specific QA program. Gantry 2 is an operating therapy system which was developed at PSI and relies on the most advanced technological innovations. We developed a comprehensive daily QA program in order to verify the main beam characteristics to assure the functionality of the therapy delivery system and the patient safety system. The daily QA program entails new hardware and software solutions for a highly efficient clinical operation. In this paper  we describe a dosimetric phantom used for verifying the most critical beam parameters and the software architecture developed for a fully automated QA procedure. The connection between our QA software and the database allows us to store the data collected on a daily basis and use it for trend analysis over longer periods of time. All the data presented here have been collected during a time span of over two years  since the beginning of the Gantry 2 clinical operation in 2013. Our procedure operates in a stable way and delivers the expected beam quality. The daily QA program takes only 20â€‰min. At the same time  the comprehensive approach allows us to avoid most of the weekly and monthly QA checks and increases the clinical beam availability.Quality assurance of intensity-modulated radiation therapy.PubMedPalta  Jatinder R; Liu  Chihray; Li  Jonathan G2008-01-01The current paradigm for the quality assurance (QA) program for intensity-modulated radiation therapy (IMRT) includes QA of the treatment planning system  QA of the delivery system  and patient-specific QA. Although the IMRT treatment planning and delivery system is the same as for conventional three-dimensional conformal radiation therapy  it has more parameters to coordinate and verify. Because of complex beam intensity modulation  each IMRT field often includes many small irregular off-axis fields  resulting in isodose distributions for each IMRT plan that are more conformal than those from conventional treatment plans. Therefore  these features impose a new and more stringent set of QA requirements for IMRT planning and delivery. The generic test procedures to validate dose calculation and delivery accuracy for both treatment planning and IMRT delivery have to be customized for each type of IMRT planning and delivery strategy. The rationale for such an approach is that the overall accuracy of IMRT delivery is incumbent on the piecewise uncertainties in both the planning and delivery processes. The end user must have well-defined evaluation criteria for each element of the planning and delivery process. Such information can potentially be used to determine a priori the accuracy of IMRT planning and delivery.The Effect of Job Performance Aids on Quality AssuranceSciTech ConnectFosshage  ErikJob performance aids (JPAs) have been studied for many decades in a variety of disciplines and for many different types of tasks  yet this is the first known research experiment using JPAs in a quality assurance (QA) context. The objective of this thesis was to assess whether a JPA has an effect on the performance of a QA observer performing the concurrent dual verification technique for a basic assembly task. The JPA used in this study was a simple checklist  and the design borrows heavily from prior research on task analysis and other human factors principles. The assembly task andmoreÂ Â» QA construct of concurrent dual verification are consistent with those of a high consequence manufacturing environment. Results showed that the JPA had only a limited effect on QA performance in the context of this experiment. However  there were three important and unexpected findings that may draw interest from a variety of practitioners. First  a novel testing methodology sensitive enough to measure the effects of a JPA on performance was created. Second  the discovery that there are different probabilities of detection for different types of error in a QA context may be the most far-reaching results. Third  these results highlight the limitations of concurrent dual verification as a control against defects. It is hoped that both the methodology and results of this study are an effective baseline from which to launch future research activities.Â«Â less[Quality assurance in interventional cardiology].PubMedGÃ¼lker  H2009-10-01Quality assurance in clinical studies aiming at approval of pharmaceutical products is submitted to strict rules  controls and auditing regulations. Comparative instruments to ensure quality in diagnostic and therapeutic procedures are not available in interventional cardiology  likewise in other fields of cardiovascular medicine. Quality assurance simply consists of ""quality registers"" with basic data not externally controlled. Based on the experiences of clinical studies and their long history of standardization it is assumed that these data may be severely flawed thus being inappropriate to set standards for diagnostic and therapeutic strategies. The precondition for quality assurance are quality data. In invasive coronary angiography and intervention medical indications  the decision making process interventional versus surgical revascularization  technical performance and after - care are essential aspects affecting quality of diagnostics and therapy. Quality data are externally controlled data. To collect quality data an appropriate infrastructure is a necessary precondition which is not existent. For an appropriate infrastructure investments have to be done both to build up as well as to sustain the necessary preconditions. As long as there are no infrastructure and no investments there will be no ""quality data"". There exist simply registers of data which are not proved to be a basis for significant assurance and enhancement in quality in interventional coronary cardiology. Georg Thieme Verlag KG Stuttgart  New York.Smartphone application for mechanical quality assurance of medical linear accelerators.PubMedKim  Hwiyoung; Lee  Hyunseok; Park  Jong In; Choi  Chang Heon; Park  So-Yeon; Kim  Hee Jung; Kim  Young Suk; Ye  Sung-Joon2017-06-07Mechanical quality assurance (QA) of medical linear accelerators consists of time-consuming and human-error-prone procedures. We developed a smartphone application system for mechanical QA. The system consists of two smartphones: one attached to a gantry for obtaining real-time information on the mechanical parameters of the medical linear accelerator  and another displaying real-time information via a Bluetooth connection with the former. Motion sensors embedded in the smartphone were used to measure gantry and collimator rotations. Images taken by the smartphone's high-resolution camera were processed to evaluate accuracies of jaw-positioning  crosshair centering and source-to-surface distance (SSD). The application was developed using Android software development kit and OpenCV library. The accuracy and precision of the system was validated against an optical rotation stage and digital calipers  prior to routine QA measurements of five medical linear accelerators. The system accuracy and precision in measuring angles and lengths were determined to be 0.05â€‰â€‰Â±â€‰â€‰0.05Â° and 0.25â€‰â€‰Â±â€‰â€‰0.14â€‰mm  respectively. The mean absolute errors (MAEs) in QA measurements of gantry and collimator rotation were 0.05â€‰â€‰Â±â€‰â€‰0.04Â° and 0.05â€‰â€‰Â±â€‰â€‰0.04Â°  respectively. The MAE in QA measurements of light field was 0.39â€‰â€‰Â±â€‰â€‰0.36â€‰mm. The MAEs in QA measurements of crosshair centering and SSD were 0.40â€‰â€‰Â±â€‰â€‰0.35â€‰mm and 0.41â€‰â€‰Â±â€‰â€‰0.32â€‰mm  respectively. In conclusion  most routine mechanical QA procedures could be performed using the smartphone application system with improved precision and within a shorter time-frame  while eliminating potential human errors.A conceptual study of automatic and semi-automatic quality assurance techniques for round image processingNASA Technical Reports Server (NTRS)1983-01-01This report summarizes the results of a study conducted by Engineering and Economics Research (EER)  Inc. under NASA Contract Number NAS5-27513. The study involved the development of preliminary concepts for automatic and semiautomatic quality assurance (QA) techniques for ground image processing. A distinction is made between quality assessment and the more comprehensive quality assurance which includes decision making and system feedback control in response to quality assessment.Implications of the South African Constitution on Quality Assurance in Higher EducationERIC Educational Resources Information CenterMammen  K. John2006-01-01The article addresses the concept of quality assurance (QA) and its relation to quality in higher education which itself is a component of total quality management. It then examines the regulatory policies for higher education followed by the meaning of the concept of democracy in the South African Constitution and its impact and implications onâ€¦10 CFR 71.37 - Quality assurance.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance. 71.37 Section 71.37 Energy NUCLEAR... Package Approval Â§ 71.37 Quality assurance. (a) The applicant shall describe the quality assurance program... quality assurance program that are applicable to the particular package design under consideration...Total quality assuranceNASA Astrophysics Data System (ADS)Louzon  E.1989-12-01Quality  cost  and schedule are three factors affecting the competitiveness of a company; they require balancing so that products of acceptable quality are delivered  on time and at a competitive cost. Quality costs comprise investment in quality maintenance and failure costs which arise from failure to maintain standards. The basic principle for achieving the required quality at minimum cost is that of prevention of failures  etc.  through production control  attention to manufacturing practices  and appropriate management and training. Total quality control involves attention to the product throughout its life cycle  including in-service performance evaluation  servicing  and maintenance.Quality Assurance 1992-2012ERIC Educational Resources Information CenterBrown  Roger2012-01-01As the author's contribution to a series marking the Golden Jubilee of the Association of University Administrators  he reflects on changes in quality assurance over the past twenty years and speculates on what the future may hold for quality as the association moves into a new and very different competitive regime. He begins by discussing theâ€¦Assuring Quality in Education Evaluation.ERIC Educational Resources Information CenterTrochim  William M. K.; Visco  Ronald J.1986-01-01A number of quality assurance educational evaluation methods are illustrated. Evaluation data obtained from the Providence  Rhode Island  school district are used. The methods are: (1) from auditing  internal control; (2) from accounting  double bookkeeping; and (3) from industrial quality control  acceptance sampling and cumulative percentageâ€¦Quality assurance in forensic odontologyPubMedSolheim  T2018-05-30Quality assurance or quality control is a term and concept coming from the industry. Here it is most important. All products must have a minimum quality and variation in size  for example  must be kept within certain strict limits. There must be a system to control this. May be not every single product is controlled  but spot tests must be taken. Measures must be taken to improve the quality if it is not good enough. This concept has been transferred to medicine  odontology  and consequently also to forensic odontology. These areas have in common with industry the production of that certain products. However  they are usually handmade and not produced in an industrial process. In addition  dentistry is a great deal of art and judgement and quality control of these factors may be difficult. In this paper  I will focus on forensic odontology. What are the problems? What can we do and cannot do? In addition  how can we assure the quality of the work  the assessment and conclusion  and the report? I have some personal opinions on that and I will give some suggestions. Quality assurance on an international level is difficult. Conditions and juridical systems are different in different countries. Especially forensic odontologists are different and have different opinions. This presentation will be relevant to the ongoing discussion and attempts at revising the IOFOS' guidelines for quality assurance.Managing the Quality of Environmental Data in EPA Region 9EPA Pesticide FactsheetsEPA Pacific Southwest  Region 9's Quality Assurance (QA) section's primary mission is to effectively oversee and carry out the Quality System and Quality Management Plan  and project-level quality assurance and quality control (QA/QC) activities.GEOSPATIAL IT/IM QA CHECKLISTEPA Science InventoryQuality assurance (QA) of information technology (IT) and Information Management (IM) systems help to ensure that the end product is of known quality and integrity. As the complexity of IT & IM processes increase  so does the need for regular QA evaluation. The areas revi...Involving mental health service users in quality assurancePubMed CentralWeinstein  Jenny2006-01-01Abstract Objectiveâ€‚ This study compares the process and outcomes of two approaches to engaging mental health (MH) service users in the quality assurance (QA) process. Backgroundâ€‚ QA plays a significant role in health and care services  including those delivered in the voluntary sector. The importance of actively  rather than passively  involving service users in evaluation and service development has been increasingly recognized during the last decade. Designâ€‚ This retrospective smallâ€scale study uses document analysis to compare two QA reviews of a MH Day Centre  one that took place in 1998 as a traditional inspectionâ€type event and one that took place in 2000 as a collaborative process with a userâ€led QA agenda. Setting and participantsâ€‚ The project was undertaken with staff  volunteers and service users in a voluntary sector MH Day Centre. Interventionâ€‚ The study compares the management  style  evaluation tools and service user responses for the two reviews; it considers staff perspectives and discusses the implications of a collaborative  userâ€led QA process for service development. Resultsâ€‚ The first traditional topâ€“down inspectionâ€type QA event had less ownership from service users and staff and served the main purpose of demonstrating that services met organizational standards. The second review  undertaken collaboratively with a userâ€led agenda focused on different priorities  evolving a new approach to seeking usersâ€™ views and achieving a higher response rate. Conclusionsâ€‚ Because both users and staff had participated in most aspects of the second review they were more willing to work together and action plan to improve the service. It is suggested that the process contributed to an evolving ethos of more effective quality improvement and user involvement within the organization. PMID:16677189The Practice of a Quality Assurance System in Open and Distance Learning: A Case Study at Universitas Terbuka Indonesia (The Indonesia Open University)ERIC Educational Resources Information CenterBelawati  Tian; Zuhairi  Amin2007-01-01Quality assurance for distance higher education is one of the main concerns among institutions and stakeholders today. This paper examines the experiences of Universitas Terbuka (UT)  which has initiated and implemented an innovative strategy of quality assurance (QA) for continuous improvement. The credo of the UT quality assurance system isâ€¦Quality Assurance Made Easy.ERIC Educational Resources Information CenterVillemaire  LorryDesigned to help adult learners realize the importance and necessity of implementing continuous quality improvement (CQI) in a rapidly changing  competitive  and modern world of work  this document presents a comprehensive explanation of CQI. The following topics are discussed in the book's introduction and seven chapters: importance of quality inâ€¦An Automatic Image Processing Workflow for Daily Magnetic Resonance Imaging Quality Assurance.PubMedPeltonen  Juha I; MÃ¤kelÃ¤  Teemu; Sofiev  Alexey; Salli  Eero2017-04-01The performance of magnetic resonance imaging (MRI) equipment is typically monitored with a quality assurance (QA) program. The QA program includes various tests performed at regular intervals. Users may execute specific tests  e.g.  daily  weekly  or monthly. The exact interval of these measurements varies according to the department policies  machine setup and usage  manufacturer's recommendations  and available resources. In our experience  a single image acquired before the first patient of the day offers a low effort and effective system check. When this daily QA check is repeated with identical imaging parameters and phantom setup  the data can be used to derive various time series of the scanner performance. However  daily QA with manual processing can quickly become laborious in a multi-scanner environment. Fully automated image analysis and results output can positively impact the QA process by decreasing reaction time  improving repeatability  and by offering novel performance evaluation methods. In this study  we have developed a daily MRI QA workflow that can measure multiple scanner performance parameters with minimal manual labor required. The daily QA system is built around a phantom image taken by the radiographers at the beginning of day. The image is acquired with a consistent phantom setup and standardized imaging parameters. Recorded parameters are processed into graphs available to everyone involved in the MRI QA process via a web-based interface. The presented automatic MRI QA system provides an efficient tool for following the short- and long-term stability of MRI scanners.QA/QC in the laboratorySciTech ConnectHood  F.C.1992-05-01Quality assurance and quality control (QA/QC) of analytical chemistry laboratory activities are essential to the validity and usefulness of resultant data. However  in themselves  conventional QA/QC measures will not always ensure that fraudulent data are not generated. Conventional QA/QC measures are based on the assumption that work will be done in good faith; to assure against fraudulent practices  QA/QC measures must be tailored to specific analyses protocols in anticipation of intentional misapplication of those protocols. Application of specific QA/QC measures to ensure against fraudulent practices result in an increased administrative burden being placed on the analytical process; accordingly  in keepingmoreÂ Â» with graded QA philosophy  data quality objectives must be used to identify specific points of concern for special control to minimize the administrative impact.Â«Â lessA practical implementation of physics quality assurance for photon adaptive radiotherapy.PubMedCai  Bin; Green  Olga L; Kashani  Rojano; Rodriguez  Vivian L; Mutic  Sasa; Yang  Deshan2018-03-14The fast evolution of technology in radiotherapy (RT) enabled the realization of adaptive radiotherapy (ART). However  the new characteristics of ART pose unique challenges for efficiencies and effectiveness of quality assurance (QA) strategies. In this paper  we discuss the necessary QAs for ART and introduce a practical implementation. A previously published work on failure modes and effects analysis (FMEA) of ART is introduced first to explain the risks associated with ART sub-processes. After a brief discussion of QA challenges  we review the existing QA strategies and tools that might be suitable for each ART step. By introducing the MR-guided online ART QA processes developed at our institute  we demonstrate a practical implementation. The limitations and future works to develop more robust and efficient QA strategies are discussed at the end. Copyright Â© 2018. Published by Elsevier GmbH.Innovative Quality-Assurance Strategies for Tuberculosis Surveillance in the United StatesPubMed CentralManangan  Lilia Ponce; Tryon  Cheryl; Magee  Elvin; Miramontes  Roque2012-01-01Introduction. The Centers for Disease Control and Prevention (CDC)'s National Tuberculosis Surveillance System (NTSS) is the national repository of tuberculosis (TB) data in the United States. Jurisdictions report to NTSS through the Report of Verified Case of Tuberculosis (RVCT) form that transitioned to a web-based system in 2009. Materials and Methods. To improve RVCT data quality  CDC conducted a quality assurance (QA) needs assessment to develop QA strategies. These include QA components (case detection  data accuracy  completeness  timeliness  data security  and confidentiality); sample tools such as National TB Indicators Project (NTIP) to identify TB case reporting discrepancies; comprehensive training course; resource guide and toolkit. Results and Discussion. During Julyâ€“September 2011  73 staff from 34 (57%) of 60 reporting jurisdictions participated in QA training. Participants stated usefulness of sharing jurisdictions' QA methods; 66 (93%) wrote that the QA tools will be effective for their activities. Several jurisdictions reported implementation of QA tools pertinent to their programs. Data showed >8% increase in NTSS and NTIP enrollment through Secure Access Management Services  which monitors system usage  from August 2011â€“February 2012. Conclusions. Despite challenges imposed by web-based surveillance systems  QA strategies can be developed with innovation and collaboration. These strategies can also be used by other disease programs to ensure high data quality. PMID:22685648A national analytical quality assurance program: Developing guidelines and analytical tools for the forest inventory and analysis programTreesearchPhyllis C. Adams; Glenn A. Christensen2012-01-01A rigorous quality assurance (QA) process assures that the data and information provided by the Forest Inventory and Analysis (FIA) program meet the highest possible standards of precision  completeness  representativeness  comparability  and accuracy. FIA relies on its analysts to check the final data quality prior to release of a StateÃ¢Â€Â™s data to the national FIA...Statistical process control analysis for patient quality assurance of intensity modulated radiation therapyNASA Astrophysics Data System (ADS)Lee  Rena; Kim  Kyubo; Cho  Samju; Lim  Sangwook; Lee  Suk; Shim  Jang Bo; Huh  Hyun Do; Lee  Sang Hoon; Ahn  Sohyun2017-11-01This study applied statistical process control to set and verify the quality assurances (QA) tolerance standard for our hospital's characteristics with the criteria standards that are applied to all the treatment sites with this analysis. Gamma test factor of delivery quality assurances (DQA) was based on 3%/3 mm. Head and neck  breast  prostate cases of intensity modulated radiation therapy (IMRT) or volumetric arc radiation therapy (VMAT) were selected for the analysis of the QA treatment sites. The numbers of data used in the analysis were 73 and 68 for head and neck patients. Prostate and breast were 49 and 152 by MapCHECK and ArcCHECK respectively. C p value of head and neck and prostate QA were above 1.0  C pml is 1.53 and 1.71 respectively  which is close to the target value of 100%. C pml value of breast (IMRT) was 1.67  data values are close to the target value of 95%. But value of was 0.90  which means that the data values are widely distributed. C p and C pml of breast VMAT QA were respectively 1.07 and 2.10. This suggests that the VMAT QA has better process capability than the IMRT QA. Consequently  we should pay more attention to planning and QA before treatment for breast Radiotherapy.Measuring and Assuring the Quality of Home Health CarePubMed CentralShaughnessy  Peter W.; Crisler  Kathryn S.; Schlenker  Robert E.; Arnold  Angela G.; Kramer  Andrew M.; Powell  Martha C.; Hittle  David F.1994-01-01The growth in home health care in the United States since 1970  and the exponential increase in the provision of Medicare-covered home health services over the past 5 years  underscores the critical need to assess the effectiveness of home health care in our society. This article presents conceptual and applied topics and approaches involved in assessing effectiveness through measuring the outcomes of home health care. Definitions are provided for a number of terms that relate to quality of care  outcome measures  risk adjustment  and quality assurance (QA) in home health care. The goal is to provide an overview of a potential systemwide approach to outcome-based QA that has its basis in a partnership between the home health industry and payers or regulators. PMID:10140157Assuring quality in narrative analysis.PubMedBailey  P H1996-04-01Many nurse-researchers using qualitative strategies have been concerned with assuring quality in their work. The early literature reveals that the concepts of validity and reliability  as understood from the positivist perspective  are somehow inappropriate and inadequate when applied to interpretive research. More recent literature suggests that because of the positivist and interpretive paradigms are epistemologically divergent  the transfer of quality criteria from one perspective to the other is not automatic or even reasonable. The purpose of this article  therefore  is to clarify what the terms quality  trustworthiness  credibility  authenticity  and goodness mean in qualitative research findings. The process of assuring quality  validation  in qualitative research will be discussed within the context of the interpretive method  narrative analysis. A brief review of quality in narrative analysis nursing research will also be presented.Quality assurance of radiotherapy in cancer treatment: toward improvement of patient safety and quality of care.PubMedIshikura  Satoshi2008-11-01The process of radiotherapy (RT) is complex and involves understanding of the principles of medical physics  radiobiology  radiation safety  dosimetry  radiation treatment planning  simulation and interaction of radiation with other treatment modalities. Each step in the integrated process of RT needs quality control and quality assurance (QA) to prevent errors and to give high confidence that patients will receive the prescribed treatment correctly. Recent advances in RT  including intensity-modulated and image-guided RT  focus on the need for a systematic RTQA program that balances patient safety and quality with available resources. It is necessary to develop more formal error mitigation and process analysis methods  such as failure mode and effect analysis  to focus available QA resources optimally on process components. External audit programs are also effective. The International Atomic Energy Agency has operated both an on-site and off-site postal dosimetry audit to improve practice and to assure the dose from RT equipment. Several countries have adopted a similar approach for national clinical auditing. In addition  clinical trial QA has a significant role in enhancing the quality of care. The Advanced Technology Consortium has pioneered the development of an infrastructure and QA method for advanced technology clinical trials  including credentialing and individual case review. These activities have an impact not only on the treatment received by patients enrolled in clinical trials  but also on the quality of treatment administered to all patients treated in each institution  and have been adopted globally; by the USA  Europe and Japan also.E-Learning Quality Assurance: A Process-Oriented Lifecycle ModelERIC Educational Resources Information CenterAbdous  M'hammed2009-01-01Purpose: The purpose of this paper is to propose a process-oriented lifecycle model for ensuring quality in e-learning development and delivery. As a dynamic and iterative process  quality assurance (QA) is intertwined with the e-learning development process. Design/methodology/approach: After reviewing the existing literature  particularlyâ€¦Comprehensive quality assurance phantom for cardiovascular imaging systemsNASA Astrophysics Data System (ADS)Lin  Pei-Jan P.1998-07-01With the advent of high heat loading capacity x-ray tubes  high frequency inverter type generators  and the use of spectral shaping filters  the automatic brightness/exposure control (ABC) circuit logic employed in the new generation of angiographic imaging equipment has been significantly reprogrammed. These new angiographic imaging systems are designed to take advantage of the power train capabilities to yield higher contrast images while maintaining  or lower  the patient exposure. Since the emphasis of the imaging system design has been significantly altered  the system performance parameters one is interested and the phantoms employed for the quality assurance must also change in order to properly evaluate the imaging capability of the cardiovascular imaging systems. A quality assurance (QA) phantom has been under development in this institution and was submitted to various interested organizations such as American Association of Physicists in Medicine (AAPM)  Society for Cardiac Angiography & Interventions (SCA&I)  and National Electrical Manufacturers Association (NEMA) for their review and input. At the same time  in an effort to establish a unified standard phantom design for the cardiac catheterization laboratories (CCL)  SCA&I and NEMA have formed a joint work group in early 1997 to develop a suitable phantom. The initial QA phantom design has since been accepted to serve as the base phantom by the SCA&I- NEMA Joint Work Group (JWG) from which a comprehensive QA Phantom is being developed.Helical tomotherapy quality assurance with ArcCHECK.PubMedChapman  David; Barnett  Rob; Yartsev  Slav2014-01-01To design a quality assurance (QA) procedure for helical tomotherapy that measures multiple beam parameters with 1 delivery and uses a rotating gantry to simulate treatment conditions. The customized QA procedure was preprogrammed on the tomotherapy operator station. The dosimetry measurements were performed using an ArcCHECK diode array and an A1SL ion chamber inserted in the central holder. The ArcCHECK was positioned 10cm above the isocenter so that the 21-cm diameter detector array could measure the 40-cm wide tomotherapy beam. During the implementation of the new QA procedure  separate comparative measurements were made using ion chambers in both liquid and solid water  the tomotherapy onboard detector array  and a MapCHECK diode array for a period of 10 weeks. There was good agreement (within 1.3%) for the beam output and cone ratio obtained with the new procedure and the routine QA measurements. The measured beam energy was comparable (0.3%) to solid water measurement during the 10-week evaluation period  excluding 2 of the 10 measurements with unusually high background. The symmetry reading was similarly compromised for those 2 weeks  and on the other weeks  it deviated from the solid water reading by ~2.5%. The ArcCHECK phantom presents a suitable alternative for performing helical tomotherapy QA  provided the background is collected properly. The proposed weekly procedure using ArcCHECK and water phantom makes the QA process more efficient. Copyright Â© 2014 American Association of Medical Dosimetrists. Published by Elsevier Inc. All rights reserved.Daily quality assurance phantom for ultrasound image guided radiation therapyPubMed CentralDrever  Laura2007-01-01A simple phantom was designed  constructed  tested  and clinically implemented for daily quality assurance (QA) of an ultrasoundâ€imageâ€guided radiation therapy (USâ€IGRT) system  the Restitu Ultrasound system (Resonant Medical  Montreal  QC). The phantom consists of a high signal echogenic background gel surrounding a low signal hypoechoic eggâ€shaped target. Daily QA checks involve ultrasound imaging of the phantom and segmenting of the embedded target using the automated tools available on the USâ€IGRT system. This process serves to confirm system hardware and software functions and  in particular  accurate determination of the target position. Experiments were conducted to test the stability of the phantom at room temperature  its tissueâ€mimicking properties  the reproducibility of target position measurements  and the usefulness of the phantom as a daily QA device. The phantom proved stable at room temperature  exhibited no evidence of bacterial or fungal invasion in 9 months  and showed limited desiccation (resulting in a monthly reduction in ultrasoundâ€measured volume of approximately 0.2 cm3). Furthermore  the phantom was shown to be nearly tissueâ€mimicking  with speed of sound in the phantom estimated to be 0.8% higher than that assumed by the scanner calibration. The phantom performs well in a clinical setting  owing to its light weight and ease of operation. It provides reproducible measures of target position even with multiple users. At our center  the phantom is being used for daily QA of the USâ€IGRT system with clinically acceptable tolerances of Â±1 cm3 on target volume and Â±2 mm on target position. For routine daily QA  this phantom is a good alternative to the manufacturerâ€supplied calibration phantom  and we recommended that that larger phantom be reserved for less frequent  more detailed QA checks and system calibration. PACS numbers: 87.66.Xa  87.63.DfEmployer-Led Quality AssuranceERIC Educational Resources Information CenterTyszko  Jason A.2017-01-01Recent criticism of higher education accreditation has prompted calls for reform and sparked interest in piloting alternative quality assurance methods that better address student learning and employment outcomes. Although this debate has brought much needed attention to improving the outcomes of graduates and safeguarding federal investment inâ€¦Assuring Quality in Collaborative Provision.ERIC Educational Resources Information CenterBocock  Jean; Edwards  Judith1998-01-01This bulletin is intended to help British further education colleges clarify their rationale for entering into collaborative programs  assess prospective partners  define and implement good practice at all stages of provision  and establish rigorous quality assurance procedures. Following an introduction  Further Education Funding Councilâ€¦Quality Assurance in School HealthERIC Educational Resources Information CenterNewell  Susan; Schoenike  Sumner L.; Lisko  Elaine A.2003-01-01School nurses need to become more influential administrators  managers  and entrepreneurs. They must learn to lead and collaborate effectively in designing  implementing  and evaluating coordinated school health programs. Quality assurance is an essential ingredient in this process that requires accurate  timely  and confidential incidentâ€¦Quality assurance and quality control in mammography: a review of available guidance worldwide.PubMedReis  ClÃ¡udia; Pascoal  Ana; Sakellaris  Taxiarchis; Koutalonis  Manthos2013-10-01Review available guidance for quality assurance (QA) in mammography and discuss its contribution to harmonise practices worldwide. Literature search was performed on different sources to identify guidance documents for QA in mammography available worldwide in international bodies  healthcare providers  professional/scientific associations. The guidance documents identified were reviewed and a selection was compared for type of guidance (clinical/technical)  technology and proposed QA methodologies focusing on dose and image quality (IQ) performance assessment. Fourteen protocols (targeted at conventional and digital mammography) were reviewed. All included recommendations for testing acquisition  processing and display systems associated with mammographic equipment. All guidance reviewed highlighted the importance of dose assessment and testing the Automatic Exposure Control (AEC) system. Recommended tests for assessment of IQ showed variations in the proposed methodologies. Recommended testing focused on assessment of low-contrast detection  spatial resolution and noise. QC of image display is recommended following the American Association of Physicists in Medicine guidelines. The existing QA guidance for mammography is derived from key documents (American College of Radiology and European Union guidelines) and proposes similar tests despite the variations in detail and methodologies. Studies reported on QA data should provide detail on experimental technique to allow robust data comparison. Countries aiming to implement a mammography/QA program may select/prioritise the tests depending on available technology and resources. â€¢An effective QA program should be practical to implement in a clinical setting. â€¢QA should address the various stages of the imaging chain: acquisition  processing and display. â€¢AEC system QC testing is simple to implement and provides information on equipment performance.Quality assurance grading guidelines for research and development at DOE facilitiesSciTech ConnectPowell  T.B.; Morris  R.N.1993-01-01The quality assurance (QA) requirements for the US Department of Energy (DOE) are established in DOE Order 5700.6C. This order is applicable for all DOE departmental elements  management  and maintenance and operating contractors and requires that documented Quality Assurance Programs (QAPs) are prepared at all levels; it has one attachment. The DOE Office of Energy Research (DOE-ER) has issued a standard to ensure implementation of the full intent of this order in the ER community.Automation of a Linear Accelerator Dosimetric Quality Assurance ProgramNASA Astrophysics Data System (ADS)Lebron Gonzalez  Sharon H.According to the American Society of Radiation Oncology  two-thirds of all cancer patients will receive radiation therapy during their illness with the majority of the treatments been delivered by a linear accelerator (linac). Therefore  quality assurance (QA) procedures must be enforced in order to deliver treatments with a machine in proper conditions. The overall goal of this project is to automate the linac's dosimetric QA procedures by analyzing and accomplishing various tasks. First  the photon beam dosimetry (i.e. total scatter correction factor  infinite percentage depth dose (PDD) and profiles) were parameterized. Parameterization consists of defining the parameters necessary for the specification of a dosimetric quantity model creating a data set that is portable and easy to implement for different applications including: beam modeling data input into a treatment planning system (TPS)  comparing measured and TPS modelled data  the QA of a linac's beam characteristics  and the establishment of a standard data set for comparison with other data  etcetera. Second  this parameterization model was used to develop a universal method to determine the radiation field size of flattened (FF)  flattening-filter-free (FFF) and wedge beams which we termed the parameterized gradient method (PGM). Third  the parameterized model was also used to develop a profile-based method for assessing the beam quality of photon FF and FFF beams using an ionization chamber array. The PDD and PDD change was also predicted from the measured profile. Lastly  methods were created to automate the multileaf collimator (MLC) calibration and QA procedures as well as the acquisition of the parameters included in monthly and annual photon dosimetric QA. A two field technique was used for the calculation of the MLC leaf relative offsets using an electronic portal imaging device (EPID). A step-and-shoot technique was used to accurately acquire the radiation field size  flatness  symmetry  outputSimultaneous analysis and quality assurance for diffusion tensor imaging.PubMedLauzon  Carolyn B; Asman  Andrew J; Esparza  Michael L; Burns  Scott S; Fan  Qiuyun; Gao  Yurui; Anderson  Adam W; Davis  Nicole; Cutting  Laurie E; Landman  Bennett A2013-01-01Diffusion tensor imaging (DTI) enables non-invasive  cyto-architectural mapping of in vivo tissue microarchitecture through voxel-wise mathematical modeling of multiple magnetic resonance imaging (MRI) acquisitions  each differently sensitized to water diffusion. DTI computations are fundamentally estimation processes and are sensitive to noise and artifacts. Despite widespread adoption in the neuroimaging community  maintaining consistent DTI data quality remains challenging given the propensity for patient motion  artifacts associated with fast imaging techniques  and the possibility of hardware changes/failures. Furthermore  the quantity of data acquired per voxel  the non-linear estimation process  and numerous potential use cases complicate traditional visual data inspection approaches. Currently  quality inspection of DTI data has relied on visual inspection and individual processing in DTI analysis software programs (e.g. DTIPrep  DTI-studio). However  recent advances in applied statistical methods have yielded several different metrics to assess noise level  artifact propensity  quality of tensor fit  variance of estimated measures  and bias in estimated measures. To date  these metrics have been largely studied in isolation. Herein  we select complementary metrics for integration into an automatic DTI analysis and quality assurance pipeline. The pipeline completes in 24 hours  stores statistical outputs  and produces a graphical summary quality analysis (QA) report. We assess the utility of this streamlined approach for empirical quality assessment on 608 DTI datasets from pediatric neuroimaging studies. The efficiency and accuracy of quality analysis using the proposed pipeline is compared with quality analysis based on visual inspection. The unified pipeline is found to save a statistically significant amount of time (over 70%) while improving the consistency of QA between a DTI expert and a pool of research associates. Projection of QA metrics to a lowSimultaneous Analysis and Quality Assurance for Diffusion Tensor ImagingPubMed CentralLauzon  Carolyn B.; Asman  Andrew J.; Esparza  Michael L.; Burns  Scott S.; Fan  Qiuyun; Gao  Yurui; Anderson  Adam W.; Davis  Nicole; Cutting  Laurie E.; Landman  Bennett A.2013-01-01Diffusion tensor imaging (DTI) enables non-invasive  cyto-architectural mapping of in vivo tissue microarchitecture through voxel-wise mathematical modeling of multiple magnetic resonance imaging (MRI) acquisitions  each differently sensitized to water diffusion. DTI computations are fundamentally estimation processes and are sensitive to noise and artifacts. Despite widespread adoption in the neuroimaging community  maintaining consistent DTI data quality remains challenging given the propensity for patient motion  artifacts associated with fast imaging techniques  and the possibility of hardware changes/failures. Furthermore  the quantity of data acquired per voxel  the non-linear estimation process  and numerous potential use cases complicate traditional visual data inspection approaches. Currently  quality inspection of DTI data has relied on visual inspection and individual processing in DTI analysis software programs (e.g. DTIPrep  DTI-studio). However  recent advances in applied statistical methods have yielded several different metrics to assess noise level  artifact propensity  quality of tensor fit  variance of estimated measures  and bias in estimated measures. To date  these metrics have been largely studied in isolation. Herein  we select complementary metrics for integration into an automatic DTI analysis and quality assurance pipeline. The pipeline completes in 24 hours  stores statistical outputs  and produces a graphical summary quality analysis (QA) report. We assess the utility of this streamlined approach for empirical quality assessment on 608 DTI datasets from pediatric neuroimaging studies. The efficiency and accuracy of quality analysis using the proposed pipeline is compared with quality analysis based on visual inspection. The unified pipeline is found to save a statistically significant amount of time (over 70%) while improving the consistency of QA between a DTI expert and a pool of research associates. Projection of QA metrics to a lowQuality assurance and improvement: the Pediatric Regional Anesthesia Network.PubMedPolaner  David M; Martin  Lynn D2012-01-01Quality assurance and improvement (QA/QI) is a critical activity in medicine. The use of large-scale collaborative databases is increasingly essential to obtain enough reports with which to establish standards of practice and define the incidence of complications and risk/benefit ratios for rare events. Such projects can enhance local QA/QI endeavors by enabling institutions to obtain benchmark data against which to compare their performance and can be used for prospective analyses of inter-institutional differences to determine 'best practice'. The pediatric regional anesthesia network (PRAN) is such a project. The first data cohort is currently being analyzed and offers insight into how such data can be used to detect trends in adverse events and improve care. Â© 2011 Blackwell Publishing Ltd.Quality assurance testing of acoustic doppler current profiler transform matricesUSGS Publications WarehouseArmstrong  Brandy; Fulford  Janice M.; Thibodeaux  Kirk G.2015-01-01The U.S. Geological Survey (USGS) Hydrologic Instrumentation Facility (HIF) is nationally responsible for the design  testing  evaluation  repair  calibration  warehousing  and distribution of hydrologic instrumentation in use within the USGS Water Mission Area (WMA). The HIF's Hydraulic Laboratory has begun routine quality assurance (QA) testing and documenting the performance of every USGS WMA acoustic Doppler current profiler (ADCP) used for making velocity and discharge measurements. All existing ADCPs are being registered and tracked in a database maintained by the HIF  and called for QA checks in the HIF's Hydraulic Laboratory on a 3- year cycle. All new ADCPs purchased directly from the manufacturer as well as ADCPs sent to the HIF or the manufacturer for repair are being registered and tracked in the database and QA checked in the laboratory before being placed into service. Meters failing the QA check are sent directly to the manufacturer for repairs and rechecked by HIF or removed from service. Although this QA program is specific to the SonTek1Â and Teledyne RD Instruments1  ADCPs most commonly used within the WMA  it is the intent of the USGS Office of Surface Water and the HIF to expand this program to include all bottom tracking ADCPs as they become available and more widely used throughout the WMA. As part of the HIF QA process  instruments are inspected for physical damage  the instrument must pass the ADCP diagnostic self-check tests  the temperature probe must be within Â± 2 degrees Celsius of a National Institute of Standards and Technology traceable reference thermometer and the distance made good over a fixed distance must meet the manufacturer's specifications (+/-0.25% or +/-1% difference). The transform matrix is tested by conducting distance-made-good (DMG) tests comparing the straight-line distance from bottom tracking to the measured tow-track distance. The DMG test is conducted on each instrument twice in the forward and reversePhotovoltaic system criteria documents. Volume 2: Quality assurance criteria for photovoltaic applicationsNASA Technical Reports Server (NTRS)Koenig  John C.; Billitti  Joseph W.; Tallon  John M.1979-01-01Quality assurance criteria are described for manufacturers and installers of solar photovoltaic tests and applications. Quality oriented activities are outlined to be pursued by the contractor/subcontractor to assure the physical and operational quality of equipment produced is included. In the broad sense  guidelines are provided for establishing a QA organization if none exists. Mainly  criteria is provided to be considered in any PV quality assurance plan selected as appropriate by the responsible Field Center. A framework is established for a systematic approach to ensure that photovoltaic tests and applications are constructed in a timely and cost effective manner.10 CFR 76.93 - Quality assurance.Code of Federal Regulations  2013 CFR2013-01-01... 10 Energy 2 2013-01-01 2013-01-01 false Quality assurance. 76.93 Section 76.93 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) CERTIFICATION OF GASEOUS DIFFUSION PLANTS Safety Â§ 76.93 Quality assurance. The Corporation shall establish  maintain  and execute a quality assurance program satisfying each of...10 CFR 76.93 - Quality assurance.Code of Federal Regulations  2012 CFR2012-01-01... 10 Energy 2 2012-01-01 2012-01-01 false Quality assurance. 76.93 Section 76.93 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) CERTIFICATION OF GASEOUS DIFFUSION PLANTS Safety Â§ 76.93 Quality assurance. The Corporation shall establish  maintain  and execute a quality assurance program satisfying each of...10 CFR 76.93 - Quality assurance.Code of Federal Regulations  2014 CFR2014-01-01... 10 Energy 2 2014-01-01 2014-01-01 false Quality assurance. 76.93 Section 76.93 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) CERTIFICATION OF GASEOUS DIFFUSION PLANTS Safety Â§ 76.93 Quality assurance. The Corporation shall establish  maintain  and execute a quality assurance program satisfying each of...10 CFR 76.93 - Quality assurance.Code of Federal Regulations  2011 CFR2011-01-01... 10 Energy 2 2011-01-01 2011-01-01 false Quality assurance. 76.93 Section 76.93 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) CERTIFICATION OF GASEOUS DIFFUSION PLANTS Safety Â§ 76.93 Quality assurance. The Corporation shall establish  maintain  and execute a quality assurance program satisfying each of...30 CFR 74.9 - Quality assurance.Code of Federal Regulations  2014 CFR2014-07-01... 30 Mineral Resources 1 2014-07-01 2014-07-01 false Quality assurance. 74.9 Section 74.9 Mineral... DUST SAMPLING DEVICES Requirements for Continuous Personal Dust Monitors Â§ 74.9 Quality assurance. (a) General requirements. The applicant shall establish and maintain a quality control system that assures...40 CFR 30.54 - Quality assurance.Code of Federal Regulations  2010 CFR2010-07-01... 40 Protection of Environment 1 2010-07-01 2010-07-01 false Quality assurance. 30.54 Section 30.54... NON-PROFIT ORGANIZATIONS Post-Award Requirements Reports and Records Â§ 30.54 Quality assurance. If the... data generation  the grantee shall develop and implement quality assurance practices consisting of...10 CFR 76.93 - Quality assurance.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance. 76.93 Section 76.93 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) CERTIFICATION OF GASEOUS DIFFUSION PLANTS Safety Â§ 76.93 Quality assurance. The Corporation shall establish  maintain  and execute a quality assurance program satisfying each of...40 CFR 194.22 - Quality assurance.Code of Federal Regulations  2010 CFR2010-07-01... 40 Protection of Environment 24 2010-07-01 2010-07-01 false Quality assurance. 194.22 Section 194... General Requirements Â§ 194.22 Quality assurance. (a)(1) As soon as practicable after April 9  1996  the Department shall adhere to a quality assurance program that implements the requirements of ASME NQA-1-1989...40 CFR 31.45 - Quality assurance.Code of Federal Regulations  2010 CFR2010-07-01... 40 Protection of Environment 1 2010-07-01 2010-07-01 false Quality assurance. 31.45 Section 31.45... Requirements Reports  Records  Retention  and Enforcement Â§ 31.45 Quality assurance. If the grantee's project... quality assurance practices consisting of policies  procedures  specifications  standards  and...Quality Assurance and the Shift towards Private Governance in Higher Education: Europeanisation through the Back Door?ERIC Educational Resources Information CenterHartmann  Eva2017-01-01This contribution focuses on quality assurance (QA) agencies in the sphere of higher education. It develops a theoretical framework that interrelates systems theory with Gramsci's theory of hegemony with a view to situating this new control of universities in the broader context of a further differentiation of society and emerging heterarchicalâ€¦INTERIM EPA GUIDANCE FOR GEOSPATIAL-RELATED QUALITY ASSURANCE PROJECT PLANSEPA Science InventoryThis guidance supplements EPA Guidance for Quality Assurance Project Plans (EPA QA/G-5)  in that the focus here is on collection and use of geospatial rather than other environmental data (e.g.  strictly chemical or biological data)  including unique aspects of data storage  retr...USEPA QUALITY ASSURANCE AUDITOR IS SCHEDULED FOR A VISIT. WHAT CAN I EXPECT?EPA Science InventoryEnvironmental studies involving data collection activities conducted by or for the United States Environmental Protection Agency (USEPA) are required to undergo a review of their data collection activities. his review is usually in the form of an independent quality assurance (QA...76 FR 54800 - International Business Machines (IBM)  Software Group Business Unit  Quality Assurance Group  San...Federal Register 2010  2011  2012  2013  20142011-09-02... Machines (IBM)  Software Group Business Unit  Quality Assurance Group  San Jose  California; Notice of... workers of International Business Machines (IBM)  Software Group Business Unit  Optim Data Studio Tools QA... February 2  2011 (76 FR 5832). The subject worker group supplies acceptance testing services  design...EPA Region 3 Quality Management PlansEPA Pesticide FactsheetsHas links to resources that describe the Region's Quality Assurance Program  which is a collection of the Region's ongoing quality assurance (QA) policies  procedures  responsibilities and management systems.Quality control and assurance for validation of DOS/I measurementsNASA Astrophysics Data System (ADS)Cerussi  Albert; Durkin  Amanda; Kwong  Richard; Quang  Timothy; Hill  Brian; Tromberg  Bruce J.; MacKinnon  Nick; Mantulin  William W.2010-02-01Ongoing multi-center clinical trials are crucial for Biophotonics to gain acceptance in medical imaging. In these trials  quality control (QC) and assurance (QA) are key to success and provide ""data insurance"". Quality control and assurance deal with standardization  validation  and compliance of procedures  materials and instrumentation. Specifically  QC/QA involves systematic assessment of testing materials  instrumentation performance  standard operating procedures  data logging  analysis  and reporting. QC and QA are important for FDA accreditation and acceptance by the clinical community. Our Biophotonics research in the Network for Translational Research in Optical Imaging (NTROI) program for breast cancer characterization focuses on QA/QC issues primarily related to the broadband Diffuse Optical Spectroscopy and Imaging (DOS/I) instrumentation  because this is an emerging technology with limited standardized QC/QA in place. In the multi-center trial environment  we implement QA/QC procedures: 1. Standardize and validate calibration standards and procedures. (DOS/I technology requires both frequency domain and spectral calibration procedures using tissue simulating phantoms and reflectance standards  respectively.) 2. Standardize and validate data acquisition  processing and visualization (optimize instrument software-EZDOS; centralize data processing) 3. Monitor  catalog and maintain instrument performance (document performance; modularize maintenance; integrate new technology) 4. Standardize and coordinate trial data entry (from individual sites) into centralized database 5. Monitor  audit and communicate all research procedures (database  teleconferences  training sessions) between participants ensuring ""calibration"". This manuscript describes our ongoing efforts  successes and challenges implementing these strategies.Evaluation of surface resistivity measurements as an alternative to the rapid chloride permeability test for quality assurance and acceptance : technical summary.DOT National Transportation Integrated Search2011-07-01This project investigated the use of a surface resistivity device as an indication of concretes ability to resist chloride ion penetration for use in quality assurance (QA) and acceptance of high performance concrete (HPC). : The objectives of thi...Quality Assurance Results for a Commercial Radiosurgery System: A Communication.PubMedRuschin  Mark; Lightstone  Alexander; Beachey  David; Wronski  Matt; Babic  Steven; Yeboah  Collins; Lee  Young; Soliman  Hany; Sahgal  Arjun2015-10-01The purpose of this communication is to inform the radiosurgery community of quality assurance (QA) results requiring attention in a commercial FDA-approved linac-based cone stereo-tactic radiosurgery (SRS) system. Standard published QA guidelines as per the American Association of Physics in Medicine (AAPM) were followed during the SRS system's commissioning process including end-to-end testing  cone concentricity testing  image transfer verification  and documentation. Several software and hardware deficiencies that were deemed risky were uncovered during the process and QA processes were put in place to mitigate these risks during clinical practice. In particular  the present work focuses on daily cone concentricity testing and commissioning-related findings associated with the software. Cone concentricity/alignment is measured daily using both optical light field inspection  as well as quantitative radiation field tests with the electronic portal imager. In 10 out of 36 clini-cal treatments  adjustments to the cone position had to be made to align the cone with the collimator axis to less than 0.5 mm and on two occasions the pre-adjustment measured offset was 1.0 mm. Software-related errors discovered during commissioning included incorrect transfer of the isocentre in DICOM coordinates  improper handling of non-axial image sets  and complex handling of beam data  especially for multi-target treatments. QA processes were established to mitigate the occurrence of the software errors. With proper QA processes  the reported SRS system complies with tolerances set out in established guidelines. Discussions with the vendor are ongoing to address some of the hardware issues related to cone alignment. Â© The Author(s) 2014.Defense Contract Management Agency Santa Ana Quality Assurance Oversight Needs lmprovementDTIC Science & Technology2013-04-19Management Agency Santa Ana Quality Assurance Oversight Needs Improvement What We Did We determined whether the Defense Contract Management Agency (DCMA...for critical safety items (CSIs). For this audit  we reviewed QA oversight of four contracts valued at about $278 million. What We Found The DCMA...limited assurance that 18 507 critical safety items  consisting of T-11 parachutes  oxygen masks  drone parachutes  and breathing apparatuses metConducting Graduate Tracer Studies for Quality Assurance in East African Universities: A Focus on Graduate Students Voices on Quality CultureERIC Educational Resources Information CenterBadiru  Egesah Omar; Wahome  Mary2016-01-01The purpose of this paper is to propose a guide for graduate trace studies (GTS) to be adopted by universities and other higher education institutions (HEIs) in East Africa. Their essential role notwithstanding  graduate tracer studies present viable opportunities through which quality assurance (QA) can be institutionalized and mainstreamed inâ€¦Quality Assurance and Quality Control  Part 2.PubMedAkers  Michael J2015-01-01The tragedy surrounding the New England Compounding Center and contaminated steroid syringe preparations clearly points out what can happen if quality-assurance and quality-control procedures are not strictly practiced in the compounding of sterile preparations. This article is part 2 of a two-part article on requirements to comply with United States Pharmacopeia general chapters <797> and <1163> with respect to quality assurance of compounded sterile preparations. Part 1 covered documentation requirements  inspection procedures  compounding accuracy checks  and part of a discussion on bacterial endotoxin testing. Part 2 covers sterility testing  the completion from part 1 on bacterial endotoxin testing  a brief dicussion of United States Pharmacopeia <1163>  and advances in pharmaceutical quality systems.Electronic laboratory quality assurance program: A method of enhancing the prosthodontic curriculum and addressing accreditation standards.PubMedMoghadam  Marjan; Jahangiri  Leila2015-08-01An electronic quality assurance (eQA) program was developed to replace a paper-based system and to address standards introduced by the Commission on Dental Accreditation (CODA) and to improve educational outcomes. This eQA program provides feedback to predoctoral dental students on prosthodontic laboratory steps at New York University College of Dentistry. The purpose of this study was to compare the eQA program of performing laboratory quality assurance with the former paper-based format. Fourth-year predoctoral dental students (n=334) who experienced both the paper-based and the electronic version of the quality assurance program were surveyed about their experiences. Additionally  data extracted from the eQA program were analyzed to identify areas of weakness in the curriculum. The study findings revealed that 73.8% of the students preferred the eQA program to the paper-based version. The average number of treatments that did not pass quality assurance standards was 119.5 per month. This indicated a 6.34% laboratory failure rate. Further analysis of these data revealed that 62.1% of the errors were related to fixed prosthodontic treatment  27.9% to partial removable dental prostheses  and 10% to complete removable dental prostheses in the first 18 months of program implementation. The eQA program was favored by dental students who have experienced both electronic and paper-based versions of the system. Error type analysis can yield the ability to create customized faculty standardization sessions and refine the didactic and clinical teaching of the predoctoral students. This program was also able to link patient care activity with the student's laboratory activities  thus addressing the latest requirements of the CODA regarding the competence of graduates in evaluating laboratory work related to their patient care. Copyright Â© 2015 Editorial Council for the Journal of Prosthetic Dentistry. Published by Elsevier Inc. All rights reserved.Comprehensive quality assurance phantom for the small animal radiation research platform (SARRP).PubMedJermoumi  M; Korideck  H; Bhagwat  M; Zygmanski  P; Makrigiogos  G M; Berbeco  R I; Cormack  R C; Ngwa  W2015-07-01To develop and test the suitability and performance of a comprehensive quality assurance (QA) phantom for the Small Animal Radiation Research Platform (SARRP). A QA phantom was developed for carrying out daily  monthly and annual QA tasks including: imaging  dosimetry and treatment planning system (TPS) performance evaluation of the SARRP. The QA phantom consists of 15 (60 Ã— 60 Ã— 5 mm(3)) kV-energy tissue equivalent solid water slabs. The phantom can incorporate optically stimulated luminescence dosimeters (OSLD)  Mosfet or film. One slab  with inserts and another slab with hole patterns are particularly designed for image QA. Output constancy measurement results showed daily variations within 3%. Using the Mosfet in phantom as target  results showed that the difference between TPS calculations and measurements was within 5%. Annual QA results for the Percentage depth dose (PDD) curves  lateral beam profiles  beam flatness and beam profile symmetry were found consistent with results obtained at commissioning. PDD curves obtained using film and OSLDs showed good agreement. Image QA was performed monthly  with image-quality parameters assessed in terms of CBCT image geometric accuracy  CT number accuracy  image spatial resolution  noise and image uniformity. The results show that the developed QA phantom can be employed as a tool for comprehensive performance evaluation of the SARRP. The study provides a useful reference for development of a comprehensive quality assurance program for the SARRP and other similar small animal irradiators  with proposed tolerances and frequency of required tests. Copyright Â© 2015 Associazione Italiana di Fisica Medica. Published by Elsevier Ltd. All rights reserved.48 CFR 246.470 - Government contract quality assurance actions.Code of Federal Regulations  2010 CFR2010-10-01... quality assurance actions. 246.470 Section 246.470 Federal Acquisition Regulations System DEFENSE ACQUISITION REGULATIONS SYSTEM  DEPARTMENT OF DEFENSE CONTRACT MANAGEMENT QUALITY ASSURANCE Government Contract Quality Assurance 246.470 Government contract quality assurance actions. ...Safety  Reliability  and Quality Assurance Provisions for the Office of Aeronautics  Exploration and Technology CentersNASA Technical Reports Server (NTRS)1991-01-01This Handbook establishes general safety  reliability  and quality assurance (SR&QA) guidelines for use on flight and ground-based projects conducted at the Ames  Langley  and Lewis Research Centers  hereafter identified as the Office of Aeronautics  Exploration and Technology (OAET) Centers. This document is applicable to all projects and operations conducted at these Centers except for those projects covered by more restrictive provisions such as the Space Shuttle  Space Station  and unmanned spacecraft programs. This Handbook is divided into two parts. The first (Chapters 1 and 2) establishes the SR&QA guidelines applicable to the OAET Centers  and the second (Appendices A  B  C  and D) provides examples and definitions for the total SR&QA program. Each center should implement SR&QA programs using these guidelines with tailoring appropriate to the special projects conducted by each Center. This Handbook is issued in loose-leaf form and will be revised by page changes.Smartphone application for mechanical quality assurance of medical linear acceleratorsNASA Astrophysics Data System (ADS)Kim  Hwiyoung; Lee  Hyunseok; In Park  Jong; Choi  Chang Heon; Park  So-Yeon; Kim  Hee Jung; Kim  Young Suk; Ye  Sung-Joon2017-06-01Mechanical quality assurance (QA) of medical linear accelerators consists of time-consuming and human-error-prone procedures. We developed a smartphone application system for mechanical QA. The system consists of two smartphones: one attached to a gantry for obtaining real-time information on the mechanical parameters of the medical linear accelerator  and another displaying real-time information via a Bluetooth connection with the former. Motion sensors embedded in the smartphone were used to measure gantry and collimator rotations. Images taken by the smartphoneâ€™s high-resolution camera were processed to evaluate accuracies of jaw-positioning  crosshair centering and source-to-surface distance (SSD). The application was developed using Android software development kit and OpenCV library. The accuracy and precision of the system was validated against an optical rotation stage and digital calipers  prior to routine QA measurements of five medical linear accelerators. The system accuracy and precision in measuring angles and lengths were determined to be 0.05â€‰â€‰Â±â€‰â€‰0.05Â° and 0.25â€‰â€‰Â±â€‰â€‰0.14â€‰mm  respectively. The mean absolute errors (MAEs) in QA measurements of gantry and collimator rotation were 0.05â€‰â€‰Â±â€‰â€‰0.04Â° and 0.05â€‰â€‰Â±â€‰â€‰0.04Â°  respectively. The MAE in QA measurements of light field was 0.39â€‰â€‰Â±â€‰â€‰0.36â€‰mm. The MAEs in QA measurements of crosshair centering and SSD were 0.40â€‰â€‰Â±â€‰â€‰0.35â€‰mm and 0.41â€‰â€‰Â±â€‰â€‰0.32â€‰mm  respectively. In conclusion  most routine mechanical QA procedures could be performed using the smartphone application system with improved precision and within a shorter time-frame  while eliminating potential human errors.Quality assurance for gastrointestinal endoscopy.PubMedAllen  John I2012-09-01This review concerns quality assurance for gastrointestinal endoscopic procedures  especially colonoscopy and will emphasize research and guidelines published since January 2011. Important articles from previous years have been included for background. Critical lapses in endoscope processing and administration of intravenous sedation alerted us to the infection risk of endoscopy. Increases in cost of colonoscopy  evidence for overuse and studies demonstrating missed cancers have led some to question the value of endoscopy. Despite these setbacks  the National Polyp Study (NPS) consortium published their long-term follow-up of the original NPS patients and confirmed that colonoscopy with polyp removal can reduce the risk of colorectal cancer for an extended period. In this article  we will focus on ways to improve the value of outpatient colonoscopy. The United States national quality improvement agenda recently became organized into a more coordinated effort spearheaded by several public and private entities. They comprise the infrastructure by which performance measures are developed and implemented as accountability standards. Understanding wherein a gastroenterology (GI) practice fits into this infrastructure and learning ways we can improve our endoscopic practice is important for physicians who provide this vital service to patients. This article will provide a roadmap for developing a quality assurance program for endoscopic practice.EPA Quality Assurance Policy StatementEPA Pesticide FactsheetsThis document may be of assistance in applying the New Source Review (NSR) air permitting regulations including the Prevention of Significant Deterioration (PSD) requirements. This document is part of the NSR Policy and Guidance Database. Some documents in the database are a scanned or retyped version of a paper photocopy of the original. Although we have taken considerable effort to quality assure the documents  some may contain typographical errors. Contact the office that issued the document if you need a copy of the original.[Physical and technical quality assurance in German breast cancer screening: progress report of the Reference Center Muenster after three years].PubMedSommer  A; Girnus  R; Wendt  B; Czwoydzinski  J; WÃ¼stenbecker  C; Heindel  W; Lenzen  H2009-05-01German breast cancer screening is monitored by a large physical quality assurance program. This report refers to the first experiences of the Reference Center (RC) Muenster after three years of the technical quality control of digital and analog mammography units (MU). This paper also shows whether the presently used quality assurance (QA) method is able to ensure that the MUs in the screening program are functioning without any serious problems. RC Muenster supervises 95 units (May 2008). The daily  weekly and monthly quality assurance of these units is controlled by web-based QA software named ""MammoConrol"" and developed by RC Muenster. The annual QA for the units must be conducted in the form of an on-site inspection by medical physics experts of the RC and is scored by an objective ranking system. The results of these QA routines were evaluated and analyzed for this paper. During the period from 3/1/2006 to 5/31/2008  8 % of the analog systems and 1 % of the digital systems exhibited problems in the daily QA. For 9 % of the analog MUs and 17 % of the digital MUs  failures appeared in the monthly QA. In the annual control  86.7 % of the analog units exhibited slight problems and 13.3 % had serious problems. With respect to the digital units  12 % were without any defects  58 % had slight problems  27 % had serious failures and 3 % had to be reported to the responsible authorities and were temporarily shut down. The special quality control requirements for German breast cancer screening  including annual on-site checks of the units  have shown in the last three years that QA with a high monitoring standard can be ensured for a large number of decentralized MUs. The currently used QA method sufficiently ensures that the screening program is technically safe. Further studies must show whether the density and focus of the QA measures must be reconfigured.Quality Assurance in Stem Cell Banking: Emphasis on Embryonic and Induced Pluripotent Stem Cell Banking.PubMedKallur  TherÃ©se; Blomberg  Pontus; Stenfelt  Sonya; Tryggvason  Kristian; Hovatta  Outi2017-01-01For quality assurance (QA) in stem cell banking  a planned system is needed to ensure that the banked products  stem cells  meet the standards required for research  clinical use  and commercial biotechnological applications. QA is process oriented  avoids  or minimizes unacceptable product defects  and particularly encompasses the management and operational systems of the bank  as well as the ethical and legal frameworks. Quality control (QC ) is product oriented and therefore ensures the stem cells of a bank are what they are expected to be. Testing is for controlling  not assuring  product quality  and is therefore a part of QC   not QA. Like QA  QC is essential for banking cells for quality research and translational application (Schwartz et al.  Lancet 379:713-720  2012). Human embryonic stem cells (hESCs)  as cells derived from donated supernumerary embryos from in vitro fertilization (IVF) therapy  are different from other stem cell types in resulting from an embryo that has had two donors . This imposes important ethical and legal constraints on the utility of the cells  which  together with quite specific culture conditions  require special attention in the QA system. Importantly  although the origin and derivation of induced pluripotent stem cells (iPSCs ) differ from that of hESCs  many of the principles of QA for hESC banking are applicable to iPSC banking (Stacey et al.  Cell Stem Cell 13:385-388  2013). Furthermore  despite differences between the legal and regulatory frameworks for hESC and iPSC banking between different countries  the requirements for QA are being harmonized (Stacey et al.  Cell Stem Cell 13:385-388  2013; International Stem Cell Banking Initiative  Stem Cell Rev 5:301-314  2009).An open source automatic quality assurance (OSAQA) tool for the ACR MRI phantom.PubMedSun  Jidi; Barnes  Michael; Dowling  Jason; Menk  Fred; Stanwell  Peter; Greer  Peter B2015-03-01Routine quality assurance (QA) is necessary and essential to ensure MR scanner performance. This includes geometric distortion  slice positioning and thickness accuracy  high contrast spatial resolution  intensity uniformity  ghosting artefact and low contrast object detectability. However  this manual process can be very time consuming. This paper describes the development and validation of an open source tool to automate the MR QA process  which aims to increase physicist efficiency  and improve the consistency of QA results by reducing human error. The OSAQA software was developed in Matlab and the source code is available for download from http://jidisun.wix.com/osaqa-project/. During program execution QA results are logged for immediate review and are also exported to a spreadsheet for long-term machine performance reporting. For the automatic contrast QA test  a user specific contrast evaluation was designed to improve accuracy for individuals on different display monitors. American College of Radiology QA images were acquired over a period of 2 months to compare manual QA and the results from the proposed OSAQA software. OSAQA was found to significantly reduce the QA time from approximately 45 to 2 min. Both the manual and OSAQA results were found to agree with regard to the recommended criteria and the differences were insignificant compared to the criteria. The intensity homogeneity filter is necessary to obtain an image with acceptable quality and at the same time keeps the high contrast spatial resolution within the recommended criterion. The OSAQA tool has been validated on scanners with different field strengths and manufacturers. A number of suggestions have been made to improve both the phantom design and QA protocol in the future.In pursuit of quality by viable quality assurance system: the controllers' perceptions.PubMedAziz  Anwar2011-01-01Patients  families and communities expect safe  competent and compassionate nursing care that has always been a core value of nursing. To meet these expectations  a valid and reliable quality assurance (QA) system is crucial to ensure that nurse-graduates are competent  confident and fit to practice. The QA approach is seen to be fundamental for quality improvement  it would be appropriate to consider its influence in the nursing education in Pakistan as the current situation is evident of non-existence of such a system to assure its quality. The data is drawn from a qualitative case study conducted in 2004. Among a purposive sample of 71 nurses inclusive of a group of Controllers were interviewed on one-to-one basis. Interviews were audio taped to reduce the risk of any misinterpretation and to facilitate the exact description of data as it was said. The non-directive  semi-structured and open-ended questionnaire was used to collect data. Thematic analysis of verbatim transcripts of the interviews was done. The study findings reveal a unanimous desire of the nurses to gauge quality of nurse education through efficient and effective quality assurance system. A crucial need is felt to develop a viable quality assurance system to ensure approved level of quality in nursing education to deliver the right care to the right patient at the right time  every time. The continuous quality assurance and improvement (CQAI) framework based on Deming Quality Cycle (Plan  Do  Check and Act) could facilitate appropriate designing and development of mechanism.A quality assurance program for clinical PDTNASA Astrophysics Data System (ADS)Dimofte  Andreea; Finlay  Jarod; Ong  Yi Hong; Zhu  Timothy C.2018-02-01Successful outcome of Photodynamic therapy (PDT) depends on accurate delivery of prescribed light dose. A quality assurance program is necessary to ensure that light dosimetry is correctly measured. We have instituted a QA program that include examination of long term calibration uncertainty of isotropic detectors for light fluence rate  power meter head intercomparison for laser power  stability of the light-emitting diode (LED) light source integrating sphere as a light fluence standard  laser output and calibration of in-vivo reflective fluorescence and absorption spectrometers. We examined the long term calibration uncertainty of isotropic detector sensitivity  defined as fluence rate per voltage. We calibrate the detector using the known calibrated light fluence rate of the LED light source built into an internally baffled 4"" integrating sphere. LED light sources were examined using a 1mm diameter isotropic detector calibrated in a collimated beam. Wavelengths varying from 632nm to 690nm were used. The internal LED method gives an overall calibration accuracy of +/- 4%. Intercomparison among power meters was performed to determine the consistency of laser power and light fluence rate measured among different power meters. Power and fluence readings were measured and compared among detectors. A comparison of power and fluence reading among several power heads shows long term consistency for power and light fluence rate calibration to within 3% regardless of wavelength. The standard LED light source is used to calibrate the transmission difference between different channels for the diffuse reflective absorption and fluorescence contact probe as well as isotropic detectors used in PDT dose dosimeter.Quality Assurance in Chinese Higher EducationERIC Educational Resources Information CenterLi  Yuan2010-01-01Quality assurance has been integrated into the fabric of higher education in China  with the issue of quality in higher education--how to evaluate it and how to enhance it--now taking centre stage in Chinese higher education. In the past decade  the development of quality assurance in Chinese higher education has covered a broad spectrum ofâ€¦7 CFR 652.7 - Quality assurance.Code of Federal Regulations  2010 CFR2010-01-01... 7 Agriculture 6 2010-01-01 2010-01-01 false Quality assurance. 652.7 Section 652.7 Agriculture... AGRICULTURE SUPPORT ACTIVITIES TECHNICAL SERVICE PROVIDER ASSISTANCE General Provisions Â§ 652.7 Quality assurance. (a) NRCS will review  in consultation with the Farm Service Agency  as appropriate  the quality...A reference standard-based quality assurance program for radiology.PubMedLiu  Patrick T; Johnson  C Daniel; Miranda  Rafael; Patel  Maitray D; Phillips  Carrie J2010-01-01The authors have developed a comprehensive radiology quality assurance (QA) program that evaluates radiology interpretations and procedures by comparing them with reference standards. Performance metrics are calculated and then compared with benchmarks or goals on the basis of published multicenter data and meta-analyses. Additional workload for physicians is kept to a minimum by having trained allied health staff members perform the comparisons of radiology reports with the reference standards. The performance metrics tracked by the QA program include the accuracy of CT colonography for detecting polyps  the false-negative rate for mammographic detection of breast cancer  the accuracy of CT angiography detection of coronary artery stenosis  the accuracy of meniscal tear detection on MRI  the accuracy of carotid artery stenosis detection on MR angiography  the accuracy of parathyroid adenoma detection by parathyroid scintigraphy  the success rate for obtaining cortical tissue on ultrasound-guided core biopsies of pelvic renal transplants  and the technical success rate for peripheral arterial angioplasty procedures. In contrast with peer-review programs  this reference standard-based QA program minimizes the possibilities of reviewer bias and erroneous second reviewer interpretations. The more objective assessment of performance afforded by the QA program will provide data that can easily be used for education and management conferences  research projects  and multicenter evaluations. Additionally  such performance data could be used by radiology departments to demonstrate their value over nonradiology competitors to referring clinicians  hospitals  patients  and third-party payers. Copyright 2010 American College of Radiology. Published by Elsevier Inc. All rights reserved.Assessment Report Sandia National Laboratories Fuel Cycle Technologies Quality Assurance Evaluation of FY15 SNL FCT M2 Milestone DeliverablesSciTech ConnectAppel  Gordon JohnSandia National Laboratories (SNL) Fuel Cycle Technologies (FCT) program activities are conducted in accordance with FCT Quality Assurance Program Document (FCT-QAPD) requirements. The FCT-QAPD interfaces with SNL approved Quality Assurance Program Description (SNL-QAPD) as explained in the Sandia National Laboratories QA Program Interface Document for FCT Activities (Interface Document). This plan describes SNL's FY16 assessment of SNL's FY15 FCT M2 milestone deliverable's compliance with program QA requirements  including SNL R&A requirements. The assessment is intended to confirm that SNL's FY15 milestone deliverables contain the appropriate authenticated review documentation and that there is a copy marked with SNL R&A numbers.Quantitative Approach to Failure Mode and Effect Analysis for Linear Accelerator Quality AssuranceSciTech ConnectO'Daniel  Jennifer C.  E-mail: jennifer.odaniel@duke.edu; Yin  Fang-FangPurpose: To determine clinic-specific linear accelerator quality assurance (QA) TG-142 test frequencies  to maximize physicist time efficiency and patient treatment quality. Methods and Materials: A novel quantitative approach to failure mode and effect analysis is proposed. Nine linear accelerator-years of QA records provided data on failure occurrence rates. The severity of test failure was modeled by introducing corresponding errors into head and neck intensity modulated radiation therapy treatment plans. The relative risk of daily linear accelerator QA was calculated as a function of frequency of test performance. Results: Although the failure severity was greatest for daily imaging QA (imaging vsmoreÂ Â» treatment isocenter and imaging positioning/repositioning)  the failure occurrence rate was greatest for output and laser testing. The composite ranking results suggest thatÂ performing output and lasers tests daily  imaging versus treatment isocenter and imaging positioning/repositioning tests weekly  and optical distance indicator and jaws versus light field tests biweekly would be acceptable for non-stereotactic radiosurgery/stereotactic body radiation therapy linear accelerators. Conclusions: Failure mode and effect analysis is a useful tool to determine the relative importance of QA tests from TG-142. Because there are practical time limitations on how many QA tests can be performed  this analysis highlights which tests are the mostÂ important and suggests the frequency of testing based on each test's risk priority number.Â«Â lessDevelopment and implementation of a comprehensive quality assurance program at a community endoscopy facility.PubMedHilsden  Robert Jay; Rostom  Alaa; DubÃ©  Catherine; Pontifex  Darlene; McGregor  S Elizabeth; Bridges  Ronald J2011-10-01Quality assurance (QA) is a process that includes the systematic evaluation of a service  institution of improvements and ongoing evaluation to ensure that effective changes were made. QA is a fundamental component of any organized colorectal cancer screening program. However  it should play an equally important role in opportunistic screening. Establishing the processes and procedures for a comprehensive QA program can be a daunting proposition for an endoscopy unit. The present article describes the steps taken to establish a QA program at the Forzani & MacPhail Colon Cancer Screening Centre (Calgary  Alberta) - a colorectal cancer screening centre and nonhospital endoscopy unit that is dedicated to providing colorectal cancer screening-related colonoscopies. Lessons drawn from the authors' experience may help others develop their own initiatives. The Global Rating Scale  a quality assessment and improvement tool developed for the gastrointestinal endoscopy services of the United Kingdom's National Health Service  was used as the framework to develop the QA program. QA activities include monitoring the patient experience through surveys  creating endoscopist report cards on colonoscopy performance  tracking and evaluating adverse events and monitoring wait times.Underground Test Area Quality Assurance Project Plan Nevada National Security Site  Nevada  Revision 0SciTech ConnectIrene FarnhamThis Quality Assurance Project Plan (QAPP) provides the overall quality assurance (QA) program requirements and general quality practices to be applied to the U.S. Department of Energy (DOE)  National Nuclear Security Administration Nevada Site Office (NNSA/NSO) Underground Test Area (UGTA) Sub-Project (hereafter the Sub-Project) activities. The requirements in this QAPP are consistent with DOE Order 414.1C  Quality Assurance (DOE  2005); U.S. Environmental Protection Agency (EPA) Guidance for Quality Assurance Project Plans for Modeling (EPA  2002); and EPA Guidance on the Development  Evaluation  and Application of Environmental Models (EPA  2009). The QAPP Revision 0 supersedes DOE--341  Underground Test Area Quality AssurancemoreÂ Â» Project Plan  Nevada Test Site  Nevada  Revision 4.Â«Â lessApplication of Quality Assurance Strategies in Diagnostics and Clinical Support Services in Iranian HospitalsPubMed CentralAghaei Hashjin  Asgar; Kringos  Dionne; Ravaghi  Hamid; Manoochehri  Jila; Gorji  Hassan Abolghasem; Klazinga  Niek S.2015-01-01Background: Iran has a widespread diagnostics and clinical support services (DCSS) network that plays a crucial role in providing diagnostic and clinical support services to both inpatient and outpatient care. However  very little is known on the application of quality assurance (QA) policies in DCSS units. This study explores the extent of application of eleven QA strategies in DCSS units within Iranian hospitals and its association with hospital characteristics. Methods: A descriptive cross-sectional study was conducted in 2009/2010. Data were collected from 554 DCSS units among 84 hospitals. Results: The average reported application rate for the QA strategies ranged from 57%-94% in the DCSS units. Most frequently reported were checking drugs expiration dates (94%)  pharmacopoeia availability (92%)  equipment calibration (87%) and identifying responsibilities (86%). Least reported was external auditing of the DCSS (57%). The clinical chemistry and microbiology laboratories (84%)  pharmacies  blood bank services (83%) reported highest average application rates across all questioned QA strategies. Lowest application rates were reported in human tissue banks (50%). There was no significant difference between the reported application rates in DCSS in the general/specialized  teaching/research  nonteaching/research hospitals with the exception of pharmacies and radiology departments. They reported availability of a written QA plan significantly more often in research hospitals. Nearly all QA strategies were reported to be applied significantly more often in the DCSS of Social Security Organization (SSO) and private-for-profit hospitals than in governmental hospitals. Conclusion: There is still room for strengthening the managerial cycle of QA systems and accountability in the DCSS in Iranian hospitals. Getting feedback  change and learning through application of specific QA strategies (eg  external/internal audits) can be improved. Both the effectiveness of QAApplication of Quality Assurance Strategies in Diagnostics and Clinical Support Services in Iranian Hospitals.PubMedAghaei Hashjin  Asgar; Kringos  Dionne; Ravaghi  Hamid; Manoochehri  Jila; Gorji  Hassan Abolghasem; Klazinga  Niek S2015-05-20Iran has a widespread diagnostics and clinical support services (DCSS) network that plays a crucial role in providing diagnostic and clinical support services to both inpatient and outpatient care. However  very little is known on the application of quality assurance (QA) policies in DCSS units. This study explores the extent of application of eleven QA strategies in DCSS units within Iranian hospitals and its association with hospital characteristics. A descriptive cross-sectional study was conducted in 2009/2010. Data were collected from 554 DCSS units among 84 hospitals. The average reported application rate for the QA strategies ranged from 57%-94% in the DCSS units. Most frequently reported were checking drugs expiration dates (94%)  pharmacopoeia availability (92%)  equipment calibration (87%) and identifying responsibilities (86%). Least reported was external auditing of the DCSS (57%). The clinical chemistry and microbiology laboratories (84%)  pharmacies  blood bank services (83%) reported highest average application rates across all questioned QA strategies. Lowest application rates were reported in human tissue banks (50%). There was no significant difference between the reported application rates in DCSS in the general/specialized  teaching/research  nonteaching/research hospitals with the exception of pharmacies and radiology departments. They reported availability of a written QA plan significantly more often in research hospitals. Nearly all QA strategies were reported to be applied significantly more often in the DCSS of Social Security Organization (SSO) and private-for-profit hospitals than in governmental hospitals. There is still room for strengthening the managerial cycle of QA systems and accountability in the DCSS in Iranian hospitals. Getting feedback  change and learning through application of specific QA strategies (eg  external/internal audits) can be improved. Both the effectiveness of QA strategies in practice  and the application ofDEMONSTRATION AND QUALITY ASSURANCE PROJECT ...EPA Pesticide FactsheetsA demonstration of field portable/mobile technologies for measuring trace elements in soil and sediments was conducted under the U.S. Environmental Protection Agency Superfund Innovative Technology Evaluation (SITE) Program. The demonstration took place from January 24 to 28  2005  at the Kennedy Athletic  Recreational and Social Park at Kennedy Space Center on Merritt Island  Florida. The purpose of the demonstration was to verify the performance of various instruments that employ X-ray fluorescence (XRF) measurement technologies for the determination of 13 toxic elements in a variety of soil and sediment samples. Instruments from the technology developers listed below were demonstrated. o Innov-X Systems  Inc.o NITON LLC (2 instruments ) o Oxford Instruments Portable Division (formerly Metorex  Inc.) .Oxford Instruments Analytical .Rigaku  Inc.o RONTEC USA Inc.o Xcalibur XRF Services Inc. (Division of Elvatech Ltd. ) This demonstration plan describes the procedures that will be used to verify the performance and cost of the XRF instruments provided by these technology developers. The plan incorporates the quality assurance and quality control elements needed to generate data of sufficient quality to perform this verification. A separate innovative technology verification report (ITVR) will be prepared for each instrument. The objective of this program is to promote the acceptance and use of innovative field technologies by providing well-documented perforFIELD DEMONSTRATION AND QUALITY ASSURANCE ...EPA Pesticide FactsheetsThe Demonstration of innovative field devices for the measurement of mercury in soil and sediment is being conducted under the EPA's SITE Program in February 2003 at the United States Department of Energy's (DOE) Oak Ridge National Laboratory (ORNL) in Oak Ridge  Tennessee and the Tennessee Department of Environment and Conservation's Department of Energy Oversight facility in Oak Ridge  Tennessee. The primary purpose of the Demonstration is to evaluate innovative field devices for the measurement of mercury in soil and sediment based on their performance and cost as compared to a conventional  off-site laboratory analytical method. The five field measurement devices listed below will be demonstrated: .Metorex's X-M ET 2000 Metal Master Analyzer  X-Ray Fluorescence Analyzer .Milestone Inc.'s Direct Mercury Analyzer (DMA-80)  Thermal Decomposition Instrument.NITON's XL-700 Series Multi-Element Analyzer  X-Ray Fluorescence Analyzer .Ohio Lumex's RA-915+ Portable Mercury Analyzer  Atomic Absorption Spectrometer  Thermal Decompostion Attachment RP 91C .MTI  Inc.'s PDV 5000 Hand Held Instrument  Anodic Stripping Voltamm eter<1). This Demonstration Plan describes the procedures that will be used to verify the performance and cost of each field measurement device. The plan incorporates the quality assurance and quality control elements needed to generate data of sufficient quality to document each device's performance and cost. A separate Innovative Technology VerificaDEMONSTRATION AND QUALITY ASSURANCE PROJECT ...EPA Pesticide FactsheetsThe demonstration of technologies for determining the presence of dioxin in soil and sediment is being conducted under the U.S. Environmental Protection Agency Superfund Innovative Technology Evaluation Program in Saginaw  Michigan  at Green Point Environmental Learning Center from approximately April 26 to May 6  2004. The primary purpose of the demonstration is to evaluate innovative monitoring technologies. The technologies listed below will be demonstrated. .AhRC PCRTM Kit  Hybrizyme Corporation .Ah-IMMUNOASSY@ Kit  Paralsian  Inc. .Coplanar PCB Immunoassay Kit  Abraxis LLC .DF-l Dioxin/Furan Immunoassay Kit  CAPE Technologies L.L.C. .CALUX@ by Xenobiotic Detection Systems  Inc- .Dioxin ELISA Kit  Wako Pure Chemical Industries LTD. This demonstration plan describes the procedures that will be used to verify the performance and cost of these technologies. The plan incorporates the quality assurance and quality control elements needed to generate data of sufficient quality to document each technology's performance and cost. A separate innovative technology verification report (ITVR) will.be prepared for each technology. The ITVRs will present the demonstration findings associated with the demonstration objectives. The objective of this program is to promote the acceptance and use of innovative field technologies by providing well-documented performance and cost data obtained from field demonstrations.Integrating Microscopic Analysis into Existing Quality Assurance ProcessesNASA Astrophysics Data System (ADS)FrÃ¼hberger  Peter; Stephan  Thomas; Beyerer  JÃ¼rgenWhen technical goods  like mainboards and other electronic components  are produced  quality assurance (QA) is very important. To achieve this goal  different optical microscopes can be used to analyze a variety of specimen to gain comprehensive information by combining the acquired sensor data. In many industrial processes  cameras are used to examine these technical goods. Those cameras can analyze complete boards at once and offer a high level of accuracy when used for completeness checks. When small defects  e.g. soldered points  need to be examined in detail  those wide area cameras are limited. Microscopes with large magnification need to be used to analyze those critical areas. But microscopes alone cannot fulfill this task within a limited time schedule  because microscopic analysis of complete motherboards of a certain size is time demanding. Microscopes are limited concerning their depth of field and depth of focus  which is why additional components like XY moving tables need to be used to examine the complete surface. Yet today's industrial production quality standards require a 100 % control of the soldered components within a given time schedule. This level of quality  while keeping inspection time low  can only be achieved when combining multiple inspection devices in an optimized manner. This paper presents results and methods of combining industrial cameras with microscopy instrumenting a classificatory based approach intending to keep already deployed QA processes in place but extending them with the purpose of increasing the quality level of the produced technical goods while maintaining high throughput.QA/QC in the laboratory. Session FSciTech ConnectHood  F.C.1992-05-01Quality assurance and quality control (QA/QC) of analytical chemistry laboratory activities are essential to the validity and usefulness of resultant data. However  in themselves  conventional QA/QC measures will not always ensure that fraudulent data are not generated. Conventional QA/QC measures are based on the assumption that work will be done in good faith; to assure against fraudulent practices  QA/QC measures must be tailored to specific analyses protocols in anticipation of intentional misapplication of those protocols. Application of specific QA/QC measures to ensure against fraudulent practices result in an increased administrative burden being placed on the analytical process; accordingly  in keepingmoreÂ Â» with graded QA philosophy  data quality objectives must be used to identify specific points of concern for special control to minimize the administrative impact.Â«Â lessClinical implementation and error sensitivity of a 3D quality assurance protocol for prostate and thoracic IMRTPubMed CentralCotter  Christopher; Turcotte  Julie Catherine; Crawford  Bruce; Sharp  Gregory; Mah'D  Mufeed2015-01-01This work aims at three goals: first  to define a set of statistical parameters and plan structures for a 3D pretreatment thoracic and prostate intensityâ€modulated radiation therapy (IMRT) quality assurance (QA) protocol; secondly  to test if the 3D QA protocol is able to detect certain clinical errors; and third  to compare the 3D QA method with QA performed with single ion chamber and 2D gamma test in detecting those errors. The 3D QA protocol measurements were performed on 13 prostate and 25 thoracic IMRT patients using IBA's COMPASS system. For each treatment planning structure included in the protocol  the following statistical parameters were evaluated: average absolute dose difference (AADD)  percent structure volume with absolute dose difference greater than 6% (ADD6)  and 3D gamma test. To test the 3D QA protocol error sensitivity  two prostate and two thoracic stepâ€andâ€shoot IMRT patients were investigated. Errors introduced to each of the treatment plans included energy switched from 6 MV to 10 MV  multileaf collimator (MLC) leaf errors  linac jaws errors  monitor unit (MU) errors  MLC and gantry angle errors  and detector shift errors. QA was performed on each plan using a single ion chamber and 2D array of ion chambers for 2D and 3D QA. Based on the measurements performed  we established a uniform set of tolerance levels to determine if QA passes for each IMRT treatment plan structure: maximum allowed AADD is 6%; maximum 4% of any structure volume can be with ADD6 greater than 6%  and maximum 4% of any structure volume may fail 3D gamma test with test parameters 3%/3Â mm DTA. Out of the three QA methods tested the single ion chamber performed the worst by detecting 4 out of 18 introduced errors  2D QA detected 11 out of 18 errors  and 3D QA detected 14 out of 18 errors. PACS number: 87.56.Fc PMID:26699299Quality assurance and quality control of geochemical dataâ€”A primer for the research scientistUSGS Publications WarehouseGeboy  Nicholas J.; Engle  Mark A.2011-01-01Geochemistry is a constantly expanding science. More and more  scientists are employing geochemical tools to help answer questions about the Earth and earth system processes. Scientists may assume that the responsibility of examining and assessing the quality of the geochemical data they generate is not theirs but rather that of the analytical laboratories to which their samples have been submitted. This assumption may be partially based on knowledge about internal and external quality assurance and quality control (QA/QC) programs in which analytical laboratories typically participate. Or there may be a perceived lack of time or resources to adequately examine data quality. Regardless of the reason  the lack of QA/QC protocols can lead to the generation and publication of erroneous data. Because the interpretations drawn from the data are primary products to U.S. Geological Survey (USGS) stakeholders  the consequences of publishing erroneous results can be significant. The principal investigator of a scientific study ultimately is responsible for the quality and interpretation of the project's findings  and thus must also play a role in the understanding  implementation  and presentation of QA/QC information about the data. Although occasionally ignored  QA/QC protocols apply not only to procedures in the laboratory but also in the initial planning of a research study and throughout the life of the project. Many of the tenets of developing a sound QA/QC program or protocols also parallel the core concepts of developing a good study: What is the main objective of the study? Will the methods selected provide data of enough resolution to answer the hypothesis? How should samples be collected? Are there known or unknown artifacts or contamination sources in the sampling and analysis methods? Assessing data quality requires communication between the scientists responsible for designing the study and those collecting samples  analyzing samples  treating data  andSU-G-201-01: An Automated Treatment Plan Quality Assurance Program for High-Dose Rate (HDR) Brachytherapy with a VaginalCylinder ApplicatorSciTech ConnectZhou  Y; Tan  J; Jiang  SPurpose: Plan specific quality assurance (QA) is an important step in high dose rate (HDR) brachytherapy to ensure the integrity of a treatment plan. The conventional approach is to assemble a set of plan screen-captures in a document and have an independent plan-checker to verify it. Not only is this approach cumbersome and time-consuming  using a document also limits the items that can be verified  hindering plan quality and patient safety. We have initiated efforts to develop a web-based HDR brachytherapy QA system called AutoBrachy QA  for comprehensive and efficient QA. This abstract reports a new plugin in this systemmoreÂ Â» for the QA of a cylinder HDR brachytherapy treatment. Methods: A cylinder plan QA module was developed using Python. It was plugged into our AutoBrachy QA system. This module extracted information from CT images and treatment plan. Image processing techniques were employed to obtain geometric parameters  e.g. cylinder diameter. A comprehensive set of eight geometrical and eight dosimetric features of the plan were validated against user specified planning parameter  such as prescription value  treatment depth and length  etc. A PDF document was generated  consisting of a summary QA sheet with all the QA results  as well as images showing plan details. Results: The cylinder QA program has been implemented in our clinic. To date  it has been used in 11 patient cases and was able to successfully perform QA tests in all of them. The QA program reduced the average plan QA time from 7 min using conventional manual approach to 0.5 min. Conclusion: Being a new module in our AutoBrachy QA system  an automated treatment plan QA module for cylinder HDR brachytherapy has been successfully developed and clinically implemented. This module improved clinical workflow and plan integrity compared to the conventional manual approach.Â«Â lessQuality Assurance in Sub-Saharan AfricaERIC Educational Resources Information CenterMateru  Peter; Righetti  Petra2010-01-01This article assesses the status and practice of higher education quality assurance in sub-Saharan Africa  focusing on degree-granting tertiary institutions. A main finding is that structured national-level quality assurance processes in African higher education are a very recent phenomenon and that most countries face major capacity constraints.â€¦Quality Assurance Reconsidered: A Case StudyERIC Educational Resources Information CenterGynnild  Vidar2007-01-01This article examines an external evaluation of the quality assurance system at the Norwegian University of Science and Technology (NTNU) conducted by The Norwegian Agency for Quality Assurance in Higher Education (NOKUT). The external audit report along with internal reports provided by the seven faculties of the university served as the majorâ€¦Exploring Quality Assurance in Sixth Form CollegesERIC Educational Resources Information CenterStoten  David William2012-01-01Purpose: This paper aims to focus on the changing nature of quality assurance systems within the sixth form college sector. Design/methodology/approach: Ten sixth form colleges were surveyed across England and staff from varying levels within college hierarchies questioned about how quality assurance systems were implemented. Research involvedâ€¦Academic Achievement Standards and Quality AssuranceERIC Educational Resources Information CenterSadler  D. Royce2017-01-01Quality assurance processes have been applied to many aspects of higher education  including teaching  learning and assessment. At least in the latter domain  quality assurance needs its fundamental tenets critically scrutinised. A common but inadequate approach has been to identify and promote learning environment changes ""likely toâ€¦30 CFR 14.8 - Quality assurance.Code of Federal Regulations  2010 CFR2010-07-01... 30 Mineral Resources 1 2010-07-01 2010-07-01 false Quality assurance. 14.8 Section 14.8 Mineral Resources MINE SAFETY AND HEALTH ADMINISTRATION  DEPARTMENT OF LABOR TESTING  EVALUATION  AND APPROVAL OF... Quality assurance. Applicants granted an approval or an extension of approval under this Part must: (a) In...30 CFR 7.7 - Quality assurance.Code of Federal Regulations  2010 CFR2010-07-01... 30 Mineral Resources 1 2010-07-01 2010-07-01 false Quality assurance. 7.7 Section 7.7 Mineral Resources MINE SAFETY AND HEALTH ADMINISTRATION  DEPARTMENT OF LABOR TESTING  EVALUATION  AND APPROVAL OF MINING PRODUCTS TESTING BY APPLICANT OR THIRD PARTY General Â§ 7.7 Quality assurance. Applicants granted...30 CFR 15.8 - Quality assurance.Code of Federal Regulations  2010 CFR2010-07-01... 30 Mineral Resources 1 2010-07-01 2010-07-01 false Quality assurance. 15.8 Section 15.8 Mineral Resources MINE SAFETY AND HEALTH ADMINISTRATION  DEPARTMENT OF LABOR TESTING  EVALUATION  AND APPROVAL OF... Â§ 15.8 Quality assurance. (a) Applicants granted an approval or an extension of approval under this...48 CFR 2453.246 - Quality Assurance.Code of Federal Regulations  2010 CFR2010-10-01... 48 Federal Acquisition Regulations System 6 2010-10-01 2010-10-01 true Quality Assurance. 2453.246 Section 2453.246 Federal Acquisition Regulations System DEPARTMENT OF HOUSING AND URBAN DEVELOPMENT CLAUSES AND FORMS FORMS Prescription of Forms 2453.246 Quality Assurance. ...Ontario's Quality Assurance Framework: A Critical ResponseERIC Educational Resources Information CenterHeap  James2013-01-01Ontario's Quality Assurance Framework (QAF) is reviewed and found not to meet all five criteria proposed for a strong quality assurance system focused on student learning. The QAF requires a statement of student learning outcomes and a method and means of assessing those outcomes  but it does not require that data on achievement of intendedâ€¦SU-E-T-627: Failure Modes and Effect Analysis for Monthly Quality Assurance of Linear AcceleratorSciTech ConnectXie  J; Xiao  Y; Wang  J2014-06-15Purpose: To develop and implement a failure mode and effect analysis (FMEA) on routine monthly Quality Assurance (QA) tests (physical tests part) of linear accelerator. Methods: A systematic failure mode and effect analysis method was performed for monthly QA procedures. A detailed process tree of monthly QA was created and potential failure modes were defined. Each failure mode may have many influencing factors. For each factor  a risk probability number (RPN) was calculated from the product of probability of occurrence (O)  the severity of effect (S)  and detectability of the failure (D). The RPN scores are in a range ofmoreÂ Â» 1 to 1000  with higher scores indicating stronger correlation to a given influencing factor of a failure mode. Five medical physicists in our institution were responsible to discuss and to define the O  S  D values. Results: 15 possible failure modes were identified and all RPN scores of all influencing factors of these 15 failue modes were from 8 to 150  and the checklist of FMEA in monthly QA was drawn. The system showed consistent and accurate response to erroneous conditions. Conclusion: The influencing factors of RPN greater than 50 were considered as highly-correlated factors of a certain out-oftolerance monthly QA test. FMEA is a fast and flexible tool to develop an implement a quality management (QM) frame work of monthly QA  which improved the QA efficiency of our QA team. The FMEA work may incorporate more quantification and monitoring fuctions in future.Â«Â lessA survey on auditing  quality assurance systems and legal frameworks in five selected slaughterhouses in Bulawayo  south-western Zimbabwe.PubMedMasanganise  Kaurai E; Matope  Gift; Pfukenyi  Davies M2013-01-01The purpose of this study was to explore the audits  quality assurance (QA) programmes and legal frameworks used in selected abattoirs in Zimbabwe and slaughterhouse workers' perceptions on their effectiveness. Data on slaughterhouse workers was gathered through a self-completed questionnaire and additional information was obtained from slaughterhouse and government records. External auditing was conducted mainly by the Department of Veterinary Public Health with little contribution from third parties. Internal auditing was restricted to export abattoirs. The checklist used on auditing lacked objective assessment criteria and respondents cited several faults in the current audit system. Most respondents (> 50.0%) knew the purposes and benefits of audit and QA inspections. All export abattoirs had QA programmes such as hazard analysis critical control point and ISO 9001 (a standard used to certify businesses' quality management systems) but their implementation varied from minimal to nil. The main regulatory defect observed was lack of requirements for a QA programme. Audit and quality assurance communications to the selected abattoirs revealed a variety of non-compliances with most respondents revealing that corrective actions to audit (84.3%) and quality assurance (92.3%) shortfalls were not done. A high percentage of respondents indicated that training on quality (76.8%) and regulations (69.8%) was critical. Thus  it is imperative that these abattoirs develop a food safety management system comprising of QA programmes  a microbial assessment scheme  regulatory compliance  standard operating procedures  internal and external auditing and training of workers.Quality control and quality assurance in genotypic data for genome-wide association studiesPubMed CentralLaurie  Cathy C.; Doheny  Kimberly F.; Mirel  Daniel B.; Pugh  Elizabeth W.; Bierut  Laura J.; Bhangale  Tushar; Boehm  Frederick; Caporaso  Neil E.; Cornelis  Marilyn C.; Edenberg  Howard J.; Gabriel  Stacy B.; Harris  Emily L.; Hu  Frank B.; Jacobs  Kevin; Kraft  Peter; Landi  Maria Teresa; Lumley  Thomas; Manolio  Teri A.; McHugh  Caitlin; Painter  Ian; Paschall  Justin; Rice  John P.; Rice  Kenneth M.; Zheng  Xiuwen; Weir  Bruce S.2011-01-01Genome-wide scans of nucleotide variation in human subjects are providing an increasing number of replicated associations with complex disease traits. Most of the variants detected have small effects and  collectively  they account for a small fraction of the total genetic variance. Very large sample sizes are required to identify and validate findings. In this situation  even small sources of systematic or random error can cause spurious results or obscure real effects. The need for careful attention to data quality has been appreciated for some time in this field  and a number of strategies for quality control and quality assurance (QC/QA) have been developed. Here we extend these methods and describe a system of QC/QA for genotypic data in genome-wide association studies. This system includes some new approaches that (1) combine analysis of allelic probe intensities and called genotypes to distinguish gender misidentification from sex chromosome aberrations  (2) detect autosomal chromosome aberrations that may affect genotype calling accuracy  (3) infer DNA sample quality from relatedness and allelic intensities  (4) use duplicate concordance to infer SNP quality  (5) detect genotyping artifacts from dependence of Hardy-Weinberg equilibrium (HWE) test p-values on allelic frequency  and (6) demonstrate sensitivity of principal components analysis (PCA) to SNP selection. The methods are illustrated with examples from the â€˜Gene Environment Association Studiesâ€™ (GENEVA) program. The results suggest several recommendations for QC/QA in the design and execution of genome-wide association studies. PMID:20718045Quality Assurance Planning for Region 9EPA Pesticide FactsheetsThe ultimate success of an environmental program or project depends on the quality of the environmental data collected and used in decision-making. EPA has developed guidances to help state and tribal governments develop Quality Assurance Program Plans.Printed Circuit Board Quality AssuranceNASA Technical Reports Server (NTRS)Sood  Bhanu2016-01-01PCB Assurance Summary: PCB assurance actives are informed by risk in context of the Project. Lessons are being applied across Projects for continuous improvements. Newer component technologies  smaller/high pitch devices: tighter and more demanding PCB designs: Identifying new research areas. New materials  designs  structures and test methods.Training  Quality Assurance Factors  and Tools Investigation: a Work Report and Suggestions on Software Quality AssuranceNASA Technical Reports Server (NTRS)Lee  Pen-Nan1991-01-01Previously  several research tasks have been conducted  some observations were obtained  and several possible suggestions have been contemplated involving software quality assurance engineering at NASA Johnson. These research tasks are briefly described. Also  a brief discussion is given on the role of software quality assurance in software engineering along with some observations and suggestions. A brief discussion on a training program for software quality assurance engineers is provided. A list of assurance factors as well as quality factors are also included. Finally  a process model which can be used for searching and collecting software quality assurance tools is presented.40 CFR 136.7 - Quality assurance and quality control.Code of Federal Regulations  2014 CFR2014-07-01... quality control elements  where applicable  into the laboratory's documented standard operating procedure... quality control elements must be clearly documented in the written standard operating procedure for each... Methods contains QA/QC procedures in the Part 1000 section of the Standard Methods Compendium. The...40 CFR 136.7 - Quality assurance and quality control.Code of Federal Regulations  2013 CFR2013-07-01... quality control elements  where applicable  into the laboratory's documented standard operating procedure... quality control elements must be clearly documented in the written standard operating procedure for each... Methods contains QA/QC procedures in the Part 1000 section of the Standard Methods Compendium. The...40 CFR 136.7 - Quality assurance and quality control.Code of Federal Regulations  2012 CFR2012-07-01... quality control elements  where applicable  into the laboratory's documented standard operating procedure... quality control elements must be clearly documented in the written standard operating procedure for each... Methods contains QA/QC procedures in the Part 1000 section of the Standard Methods Compendium. The...10 CFR 63.144 - Quality assurance program change.Code of Federal Regulations  2013 CFR2013-01-01... assurance program information that duplicates language in quality assurance regulatory guides and quality... 10 Energy 2 2013-01-01 2013-01-01 false Quality assurance program change. 63.144 Section 63.144... REPOSITORY AT YUCCA MOUNTAIN  NEVADA Quality Assurance Â§ 63.144 Quality assurance program change. Changes to...10 CFR 63.144 - Quality assurance program change.Code of Federal Regulations  2014 CFR2014-01-01... assurance program information that duplicates language in quality assurance regulatory guides and quality... 10 Energy 2 2014-01-01 2014-01-01 false Quality assurance program change. 63.144 Section 63.144... REPOSITORY AT YUCCA MOUNTAIN  NEVADA Quality Assurance Â§ 63.144 Quality assurance program change. Changes to...10 CFR 63.144 - Quality assurance program change.Code of Federal Regulations  2012 CFR2012-01-01... assurance program information that duplicates language in quality assurance regulatory guides and quality... 10 Energy 2 2012-01-01 2012-01-01 false Quality assurance program change. 63.144 Section 63.144... REPOSITORY AT YUCCA MOUNTAIN  NEVADA Quality Assurance Â§ 63.144 Quality assurance program change. Changes to...Transforming an EPA QA/R-2 quality management plan into an ISO 9002 quality management system.PubMedKell  R A; Hedin  C M; Kassakhian  G H; Reynolds  E S2001-01-01The Environmental Protection Agency's (EPA) Office of Emergency and Remedial Response (OERR) requires environmental data of known quality to support Superfund hazardous waste site projects. The Quality Assurance Technical Support (QATS) Program is operated by Shaw Environmental and Infrastructure  Inc. to provide EPA's Analytical Operations Center (AOC) with performance evaluation samples  reference materials  on-site laboratory auditing capabilities  data audits (including electronic media data audits)  methods development  and other support services. The new QATS contract awarded in November 2000 required that the QATS Program become ISO 9000 certified. In a first for an EPA contractor  the QATS staff and management successfully transformed EPA's QA/R-2 type Quality Management Plan into a Quality Management System (QMS) that complies with the requirements of the internationally recognized ISO 9002 standard and achieved certification in the United States  Canada  and throughout Europe. The presentation describes how quality system elements of ISO 9002 were implemented on an already existing quality system. The psychological and organizational challenges of the culture change in QATS' day-to-day operations will be discussed for the benefit of other ISO 9000 aspirants.SWiFT Software Quality Assurance Plan.SciTech ConnectBerg  Jonathan CharlesThis document describes the software development practice areas and processes which contribute to the ability of SWiFT software developers to provide quality software. These processes are designed to satisfy the requirements set forth by the Sandia Software Quality Assurance Program (SSQAP). APPROVALS SWiFT Software Quality Assurance Plan (SAND2016-0765) approved by: Department Manager SWiFT Site Lead Dave Minster (6121) Date Jonathan White (6121) Date SWiFT Controls Engineer Jonathan Berg (6121) Date CHANGE HISTORY Issue Date Originator(s) Description A 2016/01/27 Jon Berg (06121) Initial release of the SWiFT Software Quality Assurance PlanInternational Perspectives on Quality Assurance and New Techniques in Radiation Medicine: Outcomes of an IAEA ConferenceSciTech ConnectShortt  Ken; Davidsson  Lena; Hendry  Jolyon2008-05-01The International Atomic Energy Agency organized an international conference called  'Quality Assurance and New Techniques in Radiation Medicine' (QANTRM). It dealt with quality assurance (QA) in all aspects of radiation medicine (diagnostic radiology  nuclear medicine  and radiotherapy) at the international level. Participants discussed QA issues pertaining to the implementation of new technologies and the need for education and staff training. The advantage of developing a comprehensive and harmonized approach to QA covering both the technical and the managerial issues was emphasized to ensure the optimization of benefits to patient safety and effectiveness. The necessary coupling between medical radiation imaging andmoreÂ Â» radiotherapy was stressed  particularly for advanced technologies. However  the need for a more systematic approach to the adoption of advanced technologies was underscored by a report on failures in intensity-modulated radiotherapy dosimetry auditing tests in the United States  which could imply inadequate implementation of QA for these new technologies. A plenary session addressed the socioeconomic impact of introducing advanced technologies in resource-limited settings. How shall the dual gaps  one in access to basic medical services and the other in access to high-quality modern technology  be addressed?.Â«Â lessInternational perspectives on quality assurance and new techniques in radiation medicine: outcomes of an IAEA conference.PubMedShortt  Ken; Davidsson  Lena; Hendry  Jolyon; Dondi  Maurizio; Andreo  Pedro2008-01-01The International Atomic Energy Agency organized an international conference called  ""Quality Assurance and New Techniques in Radiation Medicine"" (QANTRM). It dealt with quality assurance (QA) in all aspects of radiation medicine (diagnostic radiology  nuclear medicine  and radiotherapy) at the international level. Participants discussed QA issues pertaining to the implementation of new technologies and the need for education and staff training. The advantage of developing a comprehensive and harmonized approach to QA covering both the technical and the managerial issues was emphasized to ensure the optimization of benefits to patient safety and effectiveness. The necessary coupling between medical radiation imaging and radiotherapy was stressed  particularly for advanced technologies. However  the need for a more systematic approach to the adoption of advanced technologies was underscored by a report on failures in intensity-modulated radiotherapy dosimetry auditing tests in the United States  which could imply inadequate implementation of QA for these new technologies. A plenary session addressed the socioeconomic impact of introducing advanced technologies in resource-limited settings. How shall the dual gaps  one in access to basic medical services and the other in access to high-quality modern technology  be addressed?owl-qa | Informatics Technology for Cancer Research (ITCR)Cancer.govowl-qa is an OWL-based QA tool for cancer study CDEs. The tool uses the combination of the NCI Thesaurus and additional disjointness axioms to detect potential errors and duplications in the data element definitions. The tool comprises three modules: Data Integration and Services Module; Compositional Expression Transformation Module; and OWL-based Quality Assurance Module.Improving patient safety through quality assurance.PubMedRaab  Stephen S2006-05-01Anatomic pathology laboratories use several quality assurance tools to detect errors and to improve patient safety. To review some of the anatomic pathology laboratory patient safety quality assurance practices. Different standards and measures in anatomic pathology quality assurance and patient safety were reviewed. Frequency of anatomic pathology laboratory error  variability in the use of specific quality assurance practices  and use of data for error reduction initiatives. Anatomic pathology error frequencies vary according to the detection method used. Based on secondary review  a College of American Pathologists Q-Probes study showed that the mean laboratory error frequency was 6.7%. A College of American Pathologists Q-Tracks study measuring frozen section discrepancy found that laboratories improved the longer they monitored and shared data. There is a lack of standardization across laboratories even for governmentally mandated quality assurance practices  such as cytologic-histologic correlation. The National Institutes of Health funded a consortium of laboratories to benchmark laboratory error frequencies  perform root cause analysis  and design error reduction initiatives  using quality assurance data. Based on the cytologic-histologic correlation process  these laboratories found an aggregate nongynecologic error frequency of 10.8%. Based on gynecologic error data  the laboratory at my institution used Toyota production system processes to lower gynecologic error frequencies and to improve Papanicolaou test metrics. Laboratory quality assurance practices have been used to track error rates  and laboratories are starting to use these data for error reduction initiatives.SU-E-T-649: Quality Assurances for Proton Therapy Delivery EquipmentSciTech ConnectArjomandy  B; Kase  Y; Flanz  J2015-06-15Purpose: The number of proton therapy centers has increased dramatically over the past decade. Currently  there is no comprehensive set of guidelines that addresses quality assurance (QA) procedures for the different technologies used for proton therapy. The AAPM has charged task group 224 (TG-224) to provide recommendations for QA required for accurate and safe dose delivery  using existing and next generation proton therapy delivery equipment. Methods: A database comprised of QA procedures and tolerance limits was generated from many existing proton therapy centers in and outside of the US. These consist of proton therapy centers that possessed double scattering  uniformmoreÂ Â» scanning  and pencil beams delivery systems. The diversity in beam delivery systems as well as the existing devices to perform QA checks for different beam parameters is the main subject of TG-224. Based on current practice at the clinically active proton centers participating in this task group  consensus QA recommendations were developed. The methodologies and requirements of the parameters that must be verified for consistency of the performance of the proton beam delivery systems are discussed. Results: TG-224 provides procedures and QA checks for mechanical  imaging  safety and dosimetry requirements for different proton equipment. These procedures are categorized based on their importance and their required frequencies in order to deliver a safe and consistent dose. The task group provides daily  weekly  monthly  and annual QA check procedures with their tolerance limits. Conclusions: The procedures outlined in this protocol provide sufficient information to qualified medical physicists to perform QA checks for any proton delivery system. Execution of these procedures should provide confidence that proton therapy equipment is functioning as commissioned for patient treatment and delivers dose safely and accurately within the established tolerance limits. The report will be publishedChemical Reactivity Testing for the National Spent Nuclear Fuel Program. Quality Assurance Project PlanSciTech ConnectNewsom  H.C.This quality assurance project plan (QAPjP) summarizes requirements used by Lockheed Martin Energy Systems  Incorporated (LMES) Development Division at Y-12 for conducting chemical reactivity testing of Department of Energy (DOE) owned spent nuclear fuel  sponsored by the National Spent Nuclear Fuel Program (NSNFP). The requirements are based on the NSNFP Statement of Work PRO-007 (Statement of Work for Laboratory Determination of Uranium Hydride Oxidation Reaction Kinetics.) This QAPjP will utilize the quality assurance program at Y-12  QA-101PD  revision 1  and existing implementing procedures for the most part in meeting the NSNFP Statement of Work PRO-007 requirements  exceptions will be noted.The NCS code of practice for the quality assurance and control for volumetric modulated arc therapyNASA Astrophysics Data System (ADS)Mans  Anton; Schuring  Danny; Arends  Mark P.; Vugts  Cornelia A. J. M.; Wolthaus  Jochem W. H.; Lotz  Heidi T.; Admiraal  Marjan; Louwe  Rob J. W.; Ã–llers  Michel C.; van de Kamer  Jeroen B.2016-10-01In 2010  the NCS (Netherlands Commission on Radiation Dosimetry) installed a subcommittee to develop guidelines for quality assurance and control for volumetric modulated arc therapy (VMAT) treatments. The report (published in 2015) has been written by Dutch medical physicists and has therefore  inevitably  a Dutch focus. This paper is a condensed version of these guidelines  the full report in English is freely available from the NCS website www.radiationdosimetry.org. After describing the transition from IMRT to VMAT  the paper addresses machine quality assurance (QA) and treatment planning system (TPS) commissioning for VMAT. The final section discusses patient specific QA issues such as the use of class solutions  measurement devices and dose evaluation methods.Assuring quality in high-consequence engineeringSciTech ConnectHoover  Marcey L.; Kolb  Rachel R.2014-03-01In high-consequence engineering organizations  such as Sandia  quality assurance may be heavily dependent on staff competency. Competency-dependent quality assurance models are at risk when the environment changes  as it has with increasing attrition rates  budget and schedule cuts  and competing program priorities. Risks in Sandia's competency-dependent culture can be mitigated through changes to hiring  training  and customer engagement approaches to manage people  partners  and products. Sandia's technical quality engineering organization has been able to mitigate corporate-level risks by driving changes that benefit all departments  and in doing so has assured Sandia's commitment to excellence in high-consequence engineering and national service.78 FR 7816 - Quality Assurance Program Requirements (Operations)Federal Register 2010  2011  2012  2013  20142013-02-04... NUCLEAR REGULATORY COMMISSION [NRC-2013-0021] Quality Assurance Program Requirements (Operations...)  DG-1300  ``Quality Assurance Program Requirements (Operations).'' DATES: Submit comments by April 1... CFR Part 50  Appendix B  ``Quality Assurance Criteria for Nuclear power Plants and Fuel Reprocessing...The quality assurance-risk management interface.PubMedLittle  N1992-08-01Involvement with both risk management and quality assurance programs has led many authors to the conclusion that the fundamental differences between these activities are  in fact  very small. ""At the point of overlap  it is almost impossible to distinguish the purposes and methods of both functions from one another."" ""Good risk management includes real improvement in patient care through organized quality assurance activities."" The interface between a proactive risk management program and a quality assurance program is dynamic and can serve the legitimate interests of both. There is little to be gained by thinking of them as separate entities and much to be gained by sharing the lessons of both. If one thinks of risk management in terms of ""risk"" to quality patient care  and that ""assuring quality"" is the most productive type of risk management  then there is no practical reason to separate one from the other.Principles and Practices for Quality Assurance and Quality ControlUSGS Publications WarehouseJones  Berwyn E.1999-01-01Quality assurance and quality control are vital parts of highway runoff water-quality monitoring projects. To be effective  project quality assurance must address all aspects of the project  including project management responsibilities and resources  data quality objectives  sampling and analysis plans  data-collection protocols  data quality-control plans  data-assessment procedures and requirements  and project outputs. Quality control ensures that the data quality objectives are achieved as planned. The historical development and current state of the art of quality assurance and quality control concepts described in this report can be applied to evaluation of data from prior projects.Collection of post mortem data: DVI protocols and quality assurance.PubMedKvaal  Sigrid I2006-05-15In many countries forensic odontologists are members of the Disaster Victim Identification (DVI) team. As part of their post mortem (PM) tasks work on the incident site may include securing and preserving the dental material and evidence before transport to the mortuary. In the autopsy room the main aim is to register the PM dental status. Photographs and radiographs are essential documentations in addition to a conventional registration of the dental status. Abbreviations in the registration may be used if agreed with the ante mortem (AM) team. Dental age estimation may be an aid in the sorting process and especially in victims without previous dental treatment. Interpol has a form set as part of their DVI manual. Forensic odontologists working in pairs and checking each other will act as quality assurance (QA) as suggested by International Organization for Forensic Odonto-Stomatology (IOFOS). Direct entry into the computer program as part of the registration in the autopsy room may save time and manpower.John F. Kennedy Space Center  Safety  Reliability  Maintainability and Quality Assurance  Survey and Audit ProgramNASA Technical Reports Server (NTRS)1994-01-01This document is the product of the KSC Survey and Audit Working Group composed of civil service and contractor Safety  Reliability  and Quality Assurance (SR&QA) personnel. The program described herein provides standardized terminology  uniformity of survey and audit operations  and emphasizes process assessments rather than a program based solely on compliance. The program establishes minimum training requirements  adopts an auditor certification methodology  and includes survey and audit metrics for the audited organizations as well as the auditing organization.Feasibility study of using statistical process control to customized quality assurance in proton therapySciTech ConnectRah  Jeong-Eun; Oh  Do Hoon; Shin  DonghoPurpose: To evaluate and improve the reliability of proton quality assurance (QA) processes and  to provide an optimal customized tolerance level using the statistical process control (SPC) methodology. Methods: The authors investigated the consistency check of dose per monitor unit (D/MU) and range in proton beams to see whether it was within the tolerance level of the daily QA process. This study analyzed the difference between the measured and calculated ranges along the central axis to improve the patient-specific QA process in proton beams by using process capability indices. Results: The authors established a customized tolerance level of Â±2% formoreÂ Â» D/MU and Â±0.5 mm for beam range in the daily proton QA process. In the authorsâ€™ analysis of the process capability indices  the patient-specific range measurements were capable of a specification limit of Â±2% in clinical plans. Conclusions: SPC methodology is a useful tool for customizing the optimal QA tolerance levels and improving the quality of proton machine maintenance  treatment delivery  and ultimately patient safety.Â«Â lessFeasibility study of using statistical process control to customized quality assurance in proton therapy.PubMedRah  Jeong-Eun; Shin  Dongho; Oh  Do Hoon; Kim  Tae Hyun; Kim  Gwe-Ya2014-09-01To evaluate and improve the reliability of proton quality assurance (QA) processes and  to provide an optimal customized tolerance level using the statistical process control (SPC) methodology. The authors investigated the consistency check of dose per monitor unit (D/MU) and range in proton beams to see whether it was within the tolerance level of the daily QA process. This study analyzed the difference between the measured and calculated ranges along the central axis to improve the patient-specific QA process in proton beams by using process capability indices. The authors established a customized tolerance level of Â±2% for D/MU and Â±0.5 mm for beam range in the daily proton QA process. In the authors' analysis of the process capability indices  the patient-specific range measurements were capable of a specification limit of Â±2% in clinical plans. SPC methodology is a useful tool for customizing the optimal QA tolerance levels and improving the quality of proton machine maintenance  treatment delivery  and ultimately patient safety.DeepQA: improving the estimation of single protein model quality with deep belief networks.PubMedCao  Renzhi; Bhattacharya  Debswapna; Hou  Jie; Cheng  Jianlin2016-12-05Protein quality assessment (QA) useful for ranking and selecting protein models has long been viewed as one of the major challenges for protein tertiary structure prediction. Especially  estimating the quality of a single protein model  which is important for selecting a few good models out of a large model pool consisting of mostly low-quality models  is still a largely unsolved problem. We introduce a novel single-model quality assessment method DeepQA based on deep belief network that utilizes a number of selected features describing the quality of a model from different perspectives  such as energy  physio-chemical characteristics  and structural information. The deep belief network is trained on several large datasets consisting of models from the Critical Assessment of Protein Structure Prediction (CASP) experiments  several publicly available datasets  and models generated by our in-house ab initio method. Our experiments demonstrate that deep belief network has better performance compared to Support Vector Machines and Neural Networks on the protein model quality assessment problem  and our method DeepQA achieves the state-of-the-art performance on CASP11 dataset. It also outperformed two well-established methods in selecting good outlier models from a large set of models of mostly low quality generated by ab initio modeling methods. DeepQA is a useful deep learning tool for protein single model quality assessment and protein structure prediction. The source code  executable  document and training/test datasets of DeepQA for Linux is freely available to non-commercial users at http://cactus.rnet.missouri.edu/DeepQA/ .Maintenance quality assurance peer exchange 2.DOT National Transportation Integrated Search2009-04-01This report documents a comprehensive study of twenty three maintenance quality assurance : (MQA) programs throughout the United States and Canada. The policies and standards of : each program were synthesized to create a general assessment on the co...Optimal procedures for quality assurance specificationsDOT National Transportation Integrated Search2003-04-01This manual is a comprehensive guide that a highway agency can use when developing new  or modifying existing  acceptance plans and quality assurance specifications. It provides necessary instruction and illustrative examples to lead the agency throu...Quality Assurance in Biobanking for Pre-Clinical ResearchPubMed CentralSimeon-Dubach  Daniel; Zeisberger  Steffen M.; Hoerstrup  Simon P.2016-01-01It is estimated that not less than USD 28 billion are spent each year in the USA alone on irreproducible pre-clinical research  which is not only a fundamental loss of investment and resources but also a strong inhibitor of efficiency for upstream processes regarding the translation towards clinical applications and therapies. The issues and cost of irreproducibility has mainly been published on pre-clinical research. In contrast to pre-clinical research  test material is often being transferred into humans in clinical research. To protect treated human subjects and guarantee a defined quality standard in the field of clinical research  the manufacturing and processing infrastructures have to strictly follow and adhere to certain (inter-)national quality standards. It is assumed and suggested by the authors that by an implementation of certain quality standards within the area of pre-clinical research  billions of USD might be saved and the translation phase of promising pre-clinical results towards clinical applications may substantially be improved. In this review  we discuss how an implementation of a quality assurance (QA) management system might positively improve sample quality and sustainability within pre-clinically focused biobank infrastructures. Biobanks are frequently positioned at the very beginning of the biomedical research value chain  and  since almost every research material has been stored in a biobank during the investigated life cycle  biobanking seems to be of substantial importance from this perspective. The role model of a QA-regulated biobank structure can be found in biobanks within the context of clinical research organizations such as in regenerative medicine clusters. PMID:27781023Quality assurance programs for pressure ulcers.PubMedXakellis  G C1997-08-01Traditional medical quality assurance programs are beginning to incorporate the principles of continuous quality improvement pioneered by Juran and Deming. Strategies for incorporating these principles into a long-term care facility are described  and two examples of successful implementation of continuous quality improvement programs for pressure ulcers are presented.10 CFR 26.137 - Quality assurance and quality control.Code of Federal Regulations  2013 CFR2013-01-01... validation of analytical procedures. Quality assurance procedures must be designed  implemented  and reviewed... resolving any technical  methodological  or administrative errors in the licensee testing facility's testing...10 CFR 26.137 - Quality assurance and quality control.Code of Federal Regulations  2010 CFR2010-01-01... validation of analytical procedures. Quality assurance procedures must be designed  implemented  and reviewed... resolving any technical  methodological  or administrative errors in the licensee testing facility's testing...10 CFR 26.137 - Quality assurance and quality control.Code of Federal Regulations  2011 CFR2011-01-01... validation of analytical procedures. Quality assurance procedures must be designed  implemented  and reviewed... resolving any technical  methodological  or administrative errors in the licensee testing facility's testing...10 CFR 26.137 - Quality assurance and quality control.Code of Federal Regulations  2012 CFR2012-01-01... validation of analytical procedures. Quality assurance procedures must be designed  implemented  and reviewed... resolving any technical  methodological  or administrative errors in the licensee testing facility's testing...10 CFR 26.137 - Quality assurance and quality control.Code of Federal Regulations  2014 CFR2014-01-01... validation of analytical procedures. Quality assurance procedures must be designed  implemented  and reviewed... resolving any technical  methodological  or administrative errors in the licensee testing facility's testing...Experience with modified aerospace reliability and quality assurance method for wind turbinesNASA Technical Reports Server (NTRS)Klein  W. E.1982-01-01The SR&QA approach assures that the machine is not hazardous to the public or operating personnel  can operate unattended on a utility grid  demonstrates reliability operation  and helps establish the quality assurance and maintainability requirements for future wind turbine projects. The approach consisted of modified failure modes and effects analysis (FMEA) during the design phase  minimal hardware inspection during parts fabrication  and three simple documents to control activities during machine construction and operation. Five years experience shows that this low cost approach works well enough that it should be considered by others for similar projects.Capturing  using  and managing quality assurance knowledge for shuttle post-MECO flight designNASA Technical Reports Server (NTRS)Peters  H. L.; Fussell  L. R.; Goodwin  M. A.; Schultz  Roger D.1991-01-01Ascent initialization values used by the Shuttle's onboard computer for nominal and abort mission scenarios are verified by a six degrees of freedom computer simulation. The procedure that the Ascent Post Main Engine Cutoff (Post-MECO) group uses to perform quality assurance (QA) of the simulation is time consuming. Also  the QA data  checklists and associated rationale  though known by the group members  is not sufficiently documented  hindering transfer of knowledge and problem resolution. A new QA procedure which retains the current high level of integrity while reducing the time required to perform QA is needed to support the increasing Shuttle flight rate. Documenting the knowledge is also needed to increase its availability for training and problem resolution. To meet these needs  a knowledge capture process  embedded into the group activities  was initiated to verify the existing QA checks  define new ones  and document all rationale. The resulting checks were automated in a conventional software program to achieve the desired standardization  integrity  and time reduction. A prototype electronic knowledge base was developed with Macintosh's HyperCard to serve as a knowledge capture tool and data storage.Use of Data Quality Index in Student Feedback for Quality Assurance of Engineering Programmes at the Military Technological College  Muscat  OmanERIC Educational Resources Information CenterKhan  Wasi Uz Zaman; AlAjmi  Abdullah Ahmed Ali; Al Zubaidy  Sarim2018-01-01This case study was undertaken to assess the effectiveness of the modifications into the engineering programmes adopted by the Military Technological College (MTC) to satisfy the needs of Omani armed forces. It discusses the role of Quality Assurance (QA) in engineering education and accreditation process in the context of four engineeringâ€¦Quality assurance of the SCOPE 1 trial in oesophageal radiotherapy.PubMedWills  Lucy; Maggs  Rhydian; Lewis  Geraint; Jones  Gareth; Nixon  Lisette; Staffurth  John; Crosby  Tom2017-11-15SCOPE 1 was the first UK based multi-centre trial involving radiotherapy of the oesophagus. A comprehensive radiotherapy trials quality assurance programme was launched with two main aims: 1. To assist centres  where needed  to adapt their radiotherapy techniques in order to achieve protocol compliance and thereby enable their participation in the trial. 2. To support the trial's clinical outcomes by ensuring the consistent planning and delivery of radiotherapy across all participating centres. A detailed information package was provided and centres were required to complete a benchmark case in which the delineated target volumes and organs at risk  dose distribution and completion of a plan assessment form were assessed prior to recruiting patients into the trial. Upon recruiting  the quality assurance (QA) programme continued to monitor the outlining and planning of radiotherapy treatments. Completion of a questionnaire was requested in order to gather information about each centre's equipment and techniques relating to their trial participation and to assess the impact of the trial nationally on standard practice for radiotherapy of the oesophagus. During the trial  advice was available for individual planning issues  and was circulated amongst the SCOPE 1 community in response to common areas of concern using bulletins. 36 centres were supported through QA processes to enable their participation in SCOPE1. We discuss the issues which have arisen throughout this process and present details of the benchmark case solutions  centre questionnaires and on-trial protocol compliance. The range of submitted benchmark case GTV volumes was 29.8-67.8cm 3 ; and PTV volumes 221.9-513.3Â cm 3 . For the dose distributions associated with these volumes  the percentage volume of the lungs receiving 20Gy (V20Gy) ranged from 20.4 to 33.5%. Similarly  heart V40Gy ranged from 16.1 to 33.0%. Incidence of incorrect outlining of OAR volumes increased from 50% of centres at benchmarkA quality assured surface wind database in Eastern CanadaNASA Astrophysics Data System (ADS)Lucio-Eceiza  E. E.; GonzÃ¡lez-Rouco  J. F.; Navarro  J.; Beltrami  H.; JimÃ©nez  P. A.; GarcÃ­a-Bustamante  E.; Hidalgo  A.2012-04-01This work summarizes the results of a Quality Assurance (QA) procedure applied to wind data centred over a wide area in Eastern Canada. The region includes the provinces of Quebec  Prince Edward Island  New Brunswick  Nova Scotia  Newfoundland  Labrador and parts of the north-eastern U.S. (Maine  New Hampshire  Massachusetts  New York and Vermont). The data set consists of 527 stations compiled from three different sources: 344 land sites from Environment Canada (EC; 1940-2009)  40 buoys distributed over the East Coast and the Canadian Great Lakes provided by the Department of Fisheries and Oceans (DFO; 1988-2008)  and 143 land sites over both eastern Canada and north-eastern U.S. provided by the National Center of Atmospheric Research (NCAR; 1975-2007). The complexity of the QA process is enhanced in this case by the variety of institutional observational protocols that lead to different temporal resolutions (hourly  3-h and 6-h)  unit systems (km/h in EC; m/s in DFO and knots in NCAR)  time references (e.g. UTC  UTC+1  UTC-5  UTC-4)  etc. Initial corrections comprised the establishment of common reference systems for time (UTC) and units (MKS). The QA applied on the resulting dataset is structured in three steps that involve the detection and correction of: manipulation errors (i.e. repetitions); unrealistic values and ranges in wind module and direction; abnormally low (e.g. long constant periods) and high variations (e.g. extreme values and inhomogeneities). Results from the first step indicate 22 sites (8 EC; 14 DFO) showing temporal patterns that are unrealistically repeated along the stations. After the QA is applied  the dataset will be subject to statistical and dynamical downscaling studies. The statistical approaches will allow for an understanding of the wind field variability related to changes in the large scale atmospheric circulation as well as their dependence on local/regional features like topography  land-sea contrasts  snow/ice presence  etc[Quality assurance in ENT tumor surgery].PubMedEckel  H E; Streppel  M; Schmalenbach  K; Volling  P; Schrappe  M; Dietz  A; Bootz  F2000-12-01Quality control is of special importance in head and neck oncology since the quality of medical care constitutes a vital parameter for the diseased patient. In contrast to other medical specialties  no quality assurance program for head and neck cancer patients has yet been established in Germany. Therefore  a survey was conducted to assess the quality assurance instruments that are in use today in otorhinolaryngology-head and neck (ORL-HNS) centers. In a nationwide survey  questionnaires were sent out to 146 German ORL-HNS departments (the return rate was 75%). 56% of all departments apply dedicated quality assurance processes  and 38% have appointed a formal quality assurance officer. Interdisciplinary oncological conferences are held in the vast majority of all departments with the participation of radiation oncologists in 86 (78%)  medical oncologists in 84 (76%)  diagnostic radiologists in 82 (74%)  and pathologists in 73 (66%). Morbidity-mortality conferences are held in seven departments (6%). A standardized follow-up of oncological patients is carried out in 95 units (86%)  and 53 departments use computer-assisted data bases to organize their follow-up data (48%). A wide variety of documentation systems is in use throughout the country: 78 units (71%) offer formal follow-up to their oncological patients. This survey documents a wide-spread interest in quality assurance procedures. Many individual efforts are being undertaken. However  no uniform quality assurance or auditing system is currently in use in Germany nor is a commonly accepted data base available. The ability to offer oncological follow-up within the national social security system is generally considered indispensable for the maintenance of high-quality oncological care in ORL-HNS departments.Portland cement concrete pavement review of QC/QA data 2000 through 2009.DOT National Transportation Integrated Search2011-04-01This report analyzes the Quality Control/Quality Assurance (QC/QA) data for Portland cement concrete pavement : (PCCP) awarded in the years 2000 through 2009. Analysis of the overall performance of the projects is accomplished by : reviewing the Calc...Develop a Methodology to Evaluate the Effectiveness of QC/QA Specifications (Phase II)DOT National Transportation Integrated Search1998-08-01The Texas Department of Transportation (TxDOT) has been implementing statistically based quality control/quality assurance (QC/QA) specifications for hot mix asphalt concrete pavements since the early 1990s. These specifications have been continuousl...10 CFR 72.140 - Quality assurance requirements.Code of Federal Regulations  2014 CFR2014-01-01... 10 Energy 2 2014-01-01 2014-01-01 false Quality assurance requirements. 72.140 Section 72.140... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.140 Quality assurance requirements. (a) Purpose. This subpart describes quality assurance...10 CFR 72.140 - Quality assurance requirements.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance requirements. 72.140 Section 72.140... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.140 Quality assurance requirements. (a) Purpose. This subpart describes quality assurance...10 CFR 72.140 - Quality assurance requirements.Code of Federal Regulations  2011 CFR2011-01-01... 10 Energy 2 2011-01-01 2011-01-01 false Quality assurance requirements. 72.140 Section 72.140... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.140 Quality assurance requirements. (a) Purpose. This subpart describes quality assurance...10 CFR 72.140 - Quality assurance requirements.Code of Federal Regulations  2012 CFR2012-01-01... 10 Energy 2 2012-01-01 2012-01-01 false Quality assurance requirements. 72.140 Section 72.140... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.140 Quality assurance requirements. (a) Purpose. This subpart describes quality assurance...10 CFR 72.140 - Quality assurance requirements.Code of Federal Regulations  2013 CFR2013-01-01... 10 Energy 2 2013-01-01 2013-01-01 false Quality assurance requirements. 72.140 Section 72.140... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.140 Quality assurance requirements. (a) Purpose. This subpart describes quality assurance...23 CFR 637.207 - Quality assurance program.Code of Federal Regulations  2010 CFR2010-04-01... 23 Highways 1 2010-04-01 2010-04-01 false Quality assurance program. 637.207 Section 637.207... CONSTRUCTION INSPECTION AND APPROVAL Quality Assurance Procedures for Construction Â§ 637.207 Quality assurance program. (a) Each STD's quality assurance program shall provide for an acceptance program and an...10 CFR 71.103 - Quality assurance organization.Code of Federal Regulations  2012 CFR2012-01-01... contractors  agents  or consultants  the work of establishing and executing the quality assurance program  or... 10 Energy 2 2012-01-01 2012-01-01 false Quality assurance organization. 71.103 Section 71.103... Quality Assurance Â§ 71.103 Quality assurance organization. (a) The licensee  2 certificate holder  and...10 CFR 71.103 - Quality assurance organization.Code of Federal Regulations  2014 CFR2014-01-01... contractors  agents  or consultants  the work of establishing and executing the quality assurance program  or... 10 Energy 2 2014-01-01 2014-01-01 false Quality assurance organization. 71.103 Section 71.103... Quality Assurance Â§ 71.103 Quality assurance organization. (a) The licensee  2 certificate holder  and...10 CFR 71.103 - Quality assurance organization.Code of Federal Regulations  2013 CFR2013-01-01... contractors  agents  or consultants  the work of establishing and executing the quality assurance program  or... 10 Energy 2 2013-01-01 2013-01-01 false Quality assurance organization. 71.103 Section 71.103... Quality Assurance Â§ 71.103 Quality assurance organization. (a) The licensee  2 certificate holder  and...[Quality assurance of emergency medical work].PubMedSunde  H G1995-03-30Patients attending a casualty department often have diseases or injuries needing urgent medical attention. Early and correct diagnosis and treatment may be of major importance for the medical outcome. The continuity of staff is often low  with many doctors and nurses working part time. This may represent a threat to the quality of the medical work. Quality assurance at a casualty department through good training  introduction of written rules  a good flow of information to the staff and local licensing of doctors are factors which can assure that the quality of the medical service remains the best. This paper presents the work done at The TromsÃ¸ Municipal Casualty Department to assure the quality of the medical service to the population.Quality Assurance in Distance Learning LibrariesERIC Educational Resources Information CenterTripathi  Manorama; Jeevan  V. K. J.2009-01-01Purpose: The paper aims to study how the present distance learning libraries can improve upon their existing services and introduce new ones to enhance quality of services to distance learners. Design/methodology/approach: The paper includes a review of literature on quality assurance in open and distance education in general and student supportâ€¦Quality Assurance in University Guidance ServicesERIC Educational Resources Information CenterSimon  Alexandra2014-01-01In Europe there is no common quality assurance framework for the delivery of guidance in higher education. Using a case study approach in four university career guidance services in England  France and Spain  this article aims to study how quality is implemented in university career guidance services in terms of strategy  standards and models â€¦The New English Quality Assurance RegimeERIC Educational Resources Information CenterBrown  Roger2011-01-01England is developing a new quality assurance regime that will come into effect in October 2011. A new funding regime will operate from the following year  together with new rules to ease the participation of private higher education providers. This article describes and analyses the new quality and funding regimes. It argues that the greaterâ€¦ENHANCING SCIENTIFIC COLLABORATION THROUGH QUALITY ASSURANCEEPA Science InventoryThe basic features of the Quality Assurance Program have been in existence since the early 1980's  but this poster will highlight some topics that have emerged more recently  in particular the Agency's laboratory competency policy  the information quality guidelines  and scientif...Ensuring Quality Assurance in Vocational EducationERIC Educational Resources Information CenterIdialu  Ethel E.2013-01-01Vocational education emphasises skill acquisition. Quality assurance in vocational education is a concept that is concerned with high performance involving activities with vocational education such as teaching  learning  infrastructures  students' behaviour and the entire academic process. Quality vocational education refers to input and output ofâ€¦Quality Assurance of Chemical Measurements.ERIC Educational Resources Information CenterTaylor  John K.1981-01-01Reviews aspects of quality control (methods to control errors) and quality assessment (verification that systems are operating within acceptable limits) including an analytical measurement system  quality control by inspection  control charts  systematic errors  and use of SRMs  materials for which properties are certified by the National Bureauâ€¦Cervical cancer screening in Europe: Quality assurance and organisation of programmes.PubMedElfstrÃ¶m  K Miriam; Arnheim-DahlstrÃ¶m  Lisen; von Karsa  Lawrence; Dillner  Joakim2015-05-01Cervical screening programmes have reduced cervical cancer incidence and mortality but the level of success is highly variable between countries. Organisation of programmes is essential for equity and cost-effectiveness. However  there are differences in effectiveness  also among organised programmes. In order to identify the key organisational components that determine effectiveness  we performed a Europe-wide survey on the current status of organisation and organised quality assurance (QA) measures in cervical cancer prevention programmes  as well as organisation-associated costs. A comprehensive questionnaire was developed through systematic review of literature and existing guidelines. The survey was sent to programme organisers  Ministries of Health and experts in 34 European Union (EU) and European Free Trade Agreement (EFTA) countries. Detailed aspects of programme organisation  quality assurance  monitoring  evaluation and corresponding line-item costs were recorded. Documentation of programme guidelines  protocols and publications was requested. Twenty-nine of 34 countries responded. The results showed that organised efforts for QA  monitoring and evaluation were carried out to a differing extent and were not standardised  making it difficult to compare the cost-effectiveness of organisation and QA strategies. Most countries found it hard to estimate the costs associated with launching and operating the organised programme. To our knowledge  this is the first questionnaire to request detailed information on the actual organisation and QA of programmes. The results of this survey can be used as a basis for further development of standardised guidelines on organisation and QA of cervical cancer screening programmes in Europe. Copyright Â© 2015 Elsevier Ltd. All rights reserved.Quality assurance and organizational effectiveness in hospitals.PubMed CentralHetherington  R W1982-01-01The purpose of this paper is to explore some aspects of a general theoretical model within which research on the organizational impacts of quality assurance programs in hospitals may be examined. Quality assurance is conceptualized as an organizational control mechanism  operating primarily through increased formalization of structures and specification of procedures. Organizational effectiveness is discussed from the perspective of the problem-solving theory of organizations  wherein effective organizations are those which maintain at least average performance in all four system problem areas simultaneously (goal-attainment  integration  adaptation and pattern-maintenance). It is proposed that through the realization of mutual benefits for both professionals and the bureaucracy  quality assurance programs can maximize such effective performance in hospitals. PMID:7096096Radiation oncology and medical physicists quality assurance in British Columbia Cancer Agency Provincial Prostate Brachytherapy Program.PubMedKeyes  Mira; Morris  William James; Spadinger  Ingrid; Araujo  Cynthia; Cheung  Arthur; Chng  Nick; Crook  Juanita; Halperin  Ross; Lapointe  Vince; Miller  Stacy; Pai  Howard; Pickles  Tom2013-01-01To describe in detail British Columbia (BC) Cancer Agency (BCCA) Provincial Prostate Brachytherapy (PB) Quality Assurance (QA) Program. The BCCA PB Program was established in 1997. It operates as one system  unified and supported by electronic and information systems  making it a single PB treatment provider for province of BC and Yukon. To date  >4000 patients have received PB (450 implants in 2011)  making it the largest program in Canada. The Program maintains a large provincial prospective electronic database with records on all patients  including disease characteristics  risk stratification  pathology  preplan and postimplant dosimetric data  follow-up of prostate-specific antigen  and toxicity outcomes. QA was an integral part of the program since its inception. A formal QA Program was established in 2002  with key components that include: unified eligibility criteria and planning system  comprehensive database  physics and oncologist training and mentorship programs  peer review process  individual performance outcomes and feedback process  structured continuing education and routine assessment of the program's dosimetry  toxicity and prostate-specific antigen outcomes  administration and program leadership that promotes a strong culture of patient safety. The emphasis on creating a robust  broad-based network of skilled providers has been achieved by the program's requirements for training  education  and the QA process. The formal QA process is considered a key factor for the success of cancer control outcomes achieved at BCCA. Although this QA model may not be wholly transferable to all PB programs  some of its key components may be applicable to other programs to ensure quality in PB and patient safety. Crown Copyright Â© 2013. Published by Elsevier Inc. All rights reserved.Quality Assurance Through Quality Improvement and Professional Development in the National Breast and Cervical Cancer Early Detection ProgramPubMed CentralSiegl  Elvira J.; Miller  Jacqueline W.; Khan  Kris; Harris  Susan E.2015-01-01Quality assurance (QA) is the process of providing evidence that the outcome meets the established standards. Quality improvement (QI)  by contrast  is the act of methodically developing ways to meet acceptable quality standards and evaluating current processes to improve overall performance. In the case of the National Breast and Cervical Cancer Early Detection Program (NBCCEDP)  the desired outcome is the delivery of quality health care services to program clients. The NBCCEDP provides professional development to ensure that participating providers have current knowledge of evidence-based clinical standards regarding breast and cervical cancer screening and diagnosis and are monitoring women with abnormal screening results for timely follow-up. To assess the quality of clinical care provided to NBCCEDP clients  performance data are collected by NBCCEDP grantees and compared against predetermined Centers for Disease Control and Prevention (CDC) benchmarks known as Data Quality Indicator Guides. In this article  the authors describe 1) the development and use of indicators for QI in the NBCCEDP and 2) the professional development activities implemented to improve clinical outcomes. QA identifies problems  whereas QI systematically corrects them. The quality of service delivery and improved patient outcomes among NBCCEDP grantees has enhanced significantly because of continuous monitoring of performance and professional development. By using QA  NBCCEDP grantees can maximize the quality of patient screening  diagnostic services  and follow-up. Examples of grantee activities to maintain quality of care are also described in this report. PMID:25099901Loch Vale Watershed Project quality assurance report  1995-1998USGS Publications WarehouseAllstott  E.J.; Bashkin  Michael A.; Baron  Jill S.1999-01-01The Loch Vale Watershed (LVWS) project was initiated in 1980 by the National Park Service with funding from the Aquatic Effects Research Program of the National Acid Precipitation Assessment Program. Initial research objectives were to understand the processes that would either mitigate or accelerate the effects of pollution on soil and surface water chemistry  and to build a record in which long-term trends could be identified and examined.It is important for all data collected in Loch Vale to meet the high standards of quality set forth in previous LVWS QA/QC reports and LVWS Methods Manuals. Given the ever-widening usage of data collected in Loch Vale  it is equally important to provide users of that data with a report assuring that all data are sound. Parameters covered in this report are the quality of meteorological measurements  hydrological measurements  surface water chemistry  and similarities in catch efficiency of two raingage types in Loch Vale for the period of 1995-1998.Routine sampling of weather conditions  precipitation chemistry  and stream/lake water chemistry began in 1982. Since then  all samples and data have been analyzed according to widely accepted and published methods. Weather data have been collected  analyzed  and stored by LVWS project personnel. Methods for the handling of meteorological data are well documented (Denning 1988  Edwards 1991  Newkirk 1995 and Allstott 1995). Precipitation chemistry has always been collected according to National Atmospheric Deposition Program protocol (Bigelow 1988)  and analyzed at the Central Analytical Laboratory of the Illinois State Water Survey in Champaign  IL. QA/QC procedures of the National Atmospheric Deposition Program are well documented (Aubertin 1990). Protocols for sampling surface waters are also well documented (Newkirk 1995). Analysis of surface water chemistry has been performed using standard EPA protocol at the US Forest Service's Rocky Mt. Station Biogeochemistry Laboratory sinceSU-G-BRB-02: An Open-Source Software Analysis Library for Linear Accelerator Quality AssuranceSciTech ConnectKerns  J; Yaldo  DPurpose: Routine linac quality assurance (QA) tests have become complex enough to require automation of most test analyses. A new data analysis software library was built that allows physicists to automate routine linear accelerator quality assurance tests. The package is open source  code tested  and benchmarked. Methods: Images and data were generated on a TrueBeam linac for the following routine QA tests: VMAT  starshot  CBCT  machine logs  Winston Lutz  and picket fence. The analysis library was built using the general programming language Python. Each test was analyzed with the library algorithms and compared to manual measurements taken at the timemoreÂ Â» of acquisition. Results: VMAT QA results agreed within 0.1% between the library and manual measurements. Machine logs (dynalogs & trajectory logs) were successfully parsed; mechanical axis positions were verified for accuracy and MLC fluence agreed well with EPID measurements. CBCT QA measurements were within 10 HU and 0.2mm where applicable. Winston Lutz isocenter size measurements were within 0.2mm of TrueBeamâ€™s Machine Performance Check. Starshot analysis was within 0.2mm of the Winston Lutz results for the same conditions. Picket fence images with and without a known error showed that the library was capable of detecting MLC offsets within 0.02mm. Conclusion: A new routine QA software library has been benchmarked and is available for use by the community. The library is open-source and extensible for use in larger systems.Â«Â less48 CFR 37.604 - Quality assurance surveillance plans.Code of Federal Regulations  2013 CFR2013-10-01... surveillance plans. 37.604 Section 37.604 Federal Acquisition Regulations System FEDERAL ACQUISITION REGULATION... assurance surveillance plans. Requirements for quality assurance and quality assurance surveillance plans are in Subpart 46.4. The Government may either prepare the quality assurance surveillance plan or...48 CFR 37.604 - Quality assurance surveillance plans.Code of Federal Regulations  2014 CFR2014-10-01... surveillance plans. 37.604 Section 37.604 Federal Acquisition Regulations System FEDERAL ACQUISITION REGULATION... assurance surveillance plans. Requirements for quality assurance and quality assurance surveillance plans are in Subpart 46.4. The Government may either prepare the quality assurance surveillance plan or...48 CFR 37.604 - Quality assurance surveillance plans.Code of Federal Regulations  2010 CFR2010-10-01... surveillance plans. 37.604 Section 37.604 Federal Acquisition Regulations System FEDERAL ACQUISITION REGULATION... assurance surveillance plans. Requirements for quality assurance and quality assurance surveillance plans are in Subpart 46.4. The Government may either prepare the quality assurance surveillance plan or...48 CFR 37.604 - Quality assurance surveillance plans.Code of Federal Regulations  2012 CFR2012-10-01... surveillance plans. 37.604 Section 37.604 Federal Acquisition Regulations System FEDERAL ACQUISITION REGULATION... assurance surveillance plans. Requirements for quality assurance and quality assurance surveillance plans are in Subpart 46.4. The Government may either prepare the quality assurance surveillance plan or...48 CFR 37.604 - Quality assurance surveillance plans.Code of Federal Regulations  2011 CFR2011-10-01... surveillance plans. 37.604 Section 37.604 Federal Acquisition Regulations System FEDERAL ACQUISITION REGULATION... assurance surveillance plans. Requirements for quality assurance and quality assurance surveillance plans are in Subpart 46.4. The Government may either prepare the quality assurance surveillance plan or...Web-Based Quality Assurance Process Drives Improvements in Obstetric Ultrasound in 5 Low- and Middle-Income CountriesPubMed CentralSwanson  Jonathan O; Plotner  David; Franklin  Holly L; Swanson  David L; Lokomba Bolamba  Victor; Lokangaka  Adrien; Sayury Pineda  Irma; Figueroa  Lester; Garces  Ana; Muyodi  David; Esamai  Fabian; Kanaiza  Nancy; Mirza  Waseem; Naqvi  Farnaz; Saleem  Sarah; Mwenechanya  Musaku; Chiwila  Melody; Hamsumonde  Dorothy; McClure  Elizabeth M; Goldenberg  Robert L; Nathan  Robert O2016-01-01ABSTRACT High quality is important in medical imaging  yet in many geographic areas  highly skilled sonographers are in short supply. Advances in Internet capacity along with the development of reliable portable ultrasounds have created an opportunity to provide centralized remote quality assurance (QA) for ultrasound exams performed at rural sites worldwide. We sought to harness these advances by developing a web-based tool to facilitate QA activities for newly trained sonographers who were taking part in a cluster randomized trial investigating the role of limited obstetric ultrasound to improve pregnancy outcomes in 5 low- and middle-income countries. We were challenged by connectivity issues  by country-specific needs for website usability  and by the overall need for a high-throughput system. After systematically addressing these needs  the resulting QA website helped drive ultrasound quality improvement across all 5 countries. It now offers the potential for adoption by future ultrasound- or imaging-based global health initiatives. PMID:28031304Specific application for Oak Ridge National Laboratory dismantlement of Building 3004. Appendix A -- Quality assurance plan; Appendix B -- Records management planSciTech ConnectNONEThis quality assurance (QA) plan defines the QA requirements for the dismantlement and removal of Building 3004 at Oak Ridge National Laboratory (ORNL). The building is a four-story wooden trained structure with wooden siding  which resides approximately 150 ft west of the Bulk Shielding Reactor  and only several feet away from the visitors entrance to the Graphite Reactor museum. Complete descriptions and sketches are in the Performance Specification document for this project. This project is being conducted as a non-CERCLA maintenance action. This plan is an appendix to the QA plan for the ORNL Environmental Restoration (ER) Program. ORNL/ER-225  whichmoreÂ Â» is the source of the project QA requirements  tailors those QA requirements to the specific needs of this project as defined in ORNL/ER-225. Project-specific description and organization are also provided in this plan. Appendix B  Records Management Plan  is included.Â«Â lessA novel quality assurance method in a university teaching paediatric radiology department.PubMedGallet  J M; Reed  M H; Hlady  J2000-08-01Primary diagnostic equipment in a paediatric radiology department must perform at optimal levels at all times. The Children's Hospital Radiology Department in Winnipeg  Canada  has developed an impartial means of reporting radiographic image quality. The main objectives of this study programme were two-fold. First  to monitor diagnostic X-ray equipment performance  and second  to improve the resultant image quality as a means of implementing the fundamental concepts of continuous quality improvement. Reading radiologists completed a quality assurance (QA) card when they identified a radiographic image quality problem. The cards were subsequently collected by the clinical instructor who then informed  in confidence  the radiographers of the written comments or concerns. QA cards have been conspicuously installed in the paediatric radiology reading room since the middle of 1993. Since its inception  equipment malfunction has been monitored and indicators for improving image quality developed. This component of the QA programme has shown itself to be a successful means of communicating with radiographers in maintaining superior image quality.Quality Assurance in the Presence of VariabilityNASA Astrophysics Data System (ADS)Lauenroth  Kim; Metzger  Andreas; Pohl  KlausSoftware Product Line Engineering (SPLE) is a reuse-driven development paradigm that has been applied successfully in information system engineering and other domains. Quality assurance of the reusable artifacts of the product line (e.g. requirements  design  and code artifacts) is essential for successful product line engineering. As those artifacts are reused in several products  a defect in a reusable artifact can affect several products of the product line. A central challenge for quality assurance in product line engineering is how to consider product line variability. Since the reusable artifacts contain variability  quality assurance techniques from single-system engineering cannot directly be applied to those artifacts. Therefore  different strategies and techniques have been developed for quality assurance in the presence of variability. In this chapter  we describe those strategies and discuss in more detail one of those strategies  the so called comprehensive strategy. The comprehensive strategy aims at checking the quality of all possible products of the product line and thus offers the highest benefits  since it is able to uncover defects in all possible products of the product line. However  the central challenge for applying the comprehensive strategy is the complexity that results from the product line variability and the large number of potential products of a product line. In this chapter  we present one concrete technique that we have developed to implement the comprehensive strategy that addresses this challenge. The technique is based on model checking technology and allows for a comprehensive verification of domain artifacts against temporal logic properties.The on-site quality-assurance system for Hyper Suprime-Cam: OSQAHNASA Astrophysics Data System (ADS)Furusawa  Hisanori; Koike  Michitaro; Takata  Tadafumi; Okura  Yuki; Miyatake  Hironao; Lupton  Robert H.; Bickerton  Steven; Price  Paul A.; Bosch  James; Yasuda  Naoki; Mineo  Sogo; Yamada  Yoshihiko; Miyazaki  Satoshi; Nakata  Fumiaki; Koshida  Shintaro; Komiyama  Yutaka; Utsumi  Yousuke; Kawanomoto  Satoshi; Jeschke  Eric; Noumaru  Junichi; Schubert  Kiaina; Iwata  Ikuru; Finet  Francois; Fujiyoshi  Takuya; Tajitsu  Akito; Terai  Tsuyoshi; Lee  Chien-Hsiu2018-01-01We have developed an automated quick data analysis system for data quality assurance (QA) for Hyper Suprime-Cam (HSC). The system was commissioned in 2012-2014  and has been offered for general observations  including the HSC Subaru Strategic Program  since 2014 March. The system provides observers with data quality information  such as seeing  sky background level  and sky transparency  based on quick analysis as data are acquired. Quick-look images and validation of image focus are also provided through an interactive web application. The system is responsible for the automatic extraction of QA information from acquired raw data into a database  to assist with observation planning  assess progress of all observing programs  and monitor long-term efficiency variations of the instrument and telescope. Enhancements of the system are being planned to facilitate final data analysis  to improve the HSC archive  and to provide legacy products for astronomical communities.7 CFR 90.102 - Quality assurance review.Code of Federal Regulations  2011 CFR2011-01-01... INTRODUCTION Quality Assurance Â§ 90.102 Quality assurance review. (a) Each laboratory performing tests and... review of the adequacy of quality control measures taken by the laboratory for the standardized method of...7 CFR 90.102 - Quality assurance review.Code of Federal Regulations  2012 CFR2012-01-01... INTRODUCTION Quality Assurance Â§ 90.102 Quality assurance review. (a) Each laboratory performing tests and... review of the adequacy of quality control measures taken by the laboratory for the standardized method of...7 CFR 90.102 - Quality assurance review.Code of Federal Regulations  2013 CFR2013-01-01... INTRODUCTION Quality Assurance Â§ 90.102 Quality assurance review. (a) Each laboratory performing tests and... review of the adequacy of quality control measures taken by the laboratory for the standardized method of...7 CFR 90.102 - Quality assurance review.Code of Federal Regulations  2014 CFR2014-01-01... INTRODUCTION Quality Assurance Â§ 90.102 Quality assurance review. (a) Each laboratory performing tests and... review of the adequacy of quality control measures taken by the laboratory for the standardized method of...Quality Assurance through ISO 9000.ERIC Educational Resources Information CenterZuckerman  Amy2000-01-01Created in 1987 by the International Organization for Standardization  in Geneva  Switzerland  ISO 9000 is attempting to develop a world standard to help companies and other institutions measure and monitor their quality-control efforts. This article describes four school districts' successful efforts to secure ISO 9000 certification. (MLH)Quality Assurance of Real-Time Oceanographic Data from the Cabled Array of the Ocean Observatories InitiativeNASA Astrophysics Data System (ADS)Kawka  O. E.; Nelson  J. S.; Manalang  D.; Kelley  D. S.2016-02-01The Cabled Array component of the NSF-funded Ocean Observatories Initiative (OOI) provides access to real-time physical  chemical  geological  and biological data from water column and seafloor platforms/instruments at sites spanning the southern half of the Juan de Fuca Plate. The Quality Assurance (QA) program for OOI data is designed to ensure that data products meet OOI science requirements. This overall data QA plan establishes the guidelines for assuring OOI data quality and summarizes Quality Control (QC) protocols and procedures  based on best practices  which can be utilized to ensure the highest quality data across the OOI program. This presentation will highlight  specifically  the QA/QC approach being utilized for the OOI Cabled Array infrastructure and data and will include a summary of both shipboard and shore-based protocols currently in use. Aspects addressed will be pre-deployment instrument testing and calibration checks  post-deployment and pre-recovery field verification of data  and post-recovery ""as-found"" testing of instruments. Examples of QA/QC data will be presented and specific cases of cabled data will be discussed in the context of quality assessments and adjustment/correction of OOI datasets overall for inherent sensor drift and/or instrument fouling.Assuring Quality in Online Course DeliveryERIC Educational Resources Information CenterMatuga  Julia M.; Wooldridge  Deborah G.; Poirier  Sandra2011-01-01This paper examines the critical issue of assuring quality online course delivery by examining four key components of online teaching and learning. The topic of course delivery is viewed as a cultural issue that permeates processes from the design of an online course to its evaluation. First  the authors examine and review key components of andâ€¦Quality Assurance: Enhancing or Threatening Higher Education?ERIC Educational Resources Information CenterTaousanidis  Nikolaos I.; Antoniadou  Myrofora A.2010-01-01There is an increasing marketization of commodity services and  the authors argue  higher education is suffering heavily from this trend. Higher education institutions (HEIs) are currently subject to quality assurance and other externally imposed procedures that have been successfully applied in the private sector. This article analyses theâ€¦SWMM 5 REDEVELOPMENT QUALITY ASSURANCE PROGRAMEPA Science InventoryEPA recently released a new version of the Storm Water Management Model (SWMM) that combines a new interface with a completely re-written computational engine. The SWMM redevelopment project proceeded under a Quality Assurance Project Plan (QAPP) that describes methods and proced...Quality Assurance for Higher Education Franchising.ERIC Educational Resources Information CenterYorke  Mantz1993-01-01The practice of ""franchising"" higher education programs  or provision of educational programs through vendors  is examined as it occurs in the United Kingdom as a result of recent educational policy changes. A set of principles for assuring the quality of such programs is proposed. (MSE)Quality Assurance of University Education: Whose Responsibility?ERIC Educational Resources Information CenterIbijola  Elizabeth Yinka2015-01-01This study sought the opinion of stakeholders in university education  to know who should be responsible for quality assurance of university education in Nigeria. Descriptive research of survey design was employed in the study. The population consisted of all public university staff members  students and the employers of Nigerian universityâ€¦Quality Assurance in Higher Education in ZimbabweERIC Educational Resources Information CenterGarwe  Evelyn Chiyevo2014-01-01The purpose of this paper is to furnish local and global stakeholders with detailed information regarding the development and current status of quality assurance in the Zimbabwean higher education sector. The study used document analysis  observation and interviews with key informants as sources of data. This paper addresses the dearth ofâ€¦Software quality assurance plan for GCSNASA Technical Reports Server (NTRS)Duncan  Stephen E.; Bailey  Elizabeth K.1990-01-01The software quality assurance (SQA) function for the Guidance and Control Software (GCS) project which is part of a software error studies research program is described. The SQA plan outlines all of the procedures  controls  and audits to be carried out by the SQA organization to ensure adherence to the policies  procedures  and standards for the GCS project.REGIONAL AIR POLLUTION STUDY  QUALITY ASSURANCE AUDITSEPA Science InventoryRAPS Quality Assurance audits were conducted under this Task Order in continuation of the audit program previously conducted under Task Order No. 58. Quantitative field audits were conducted of the Regional Air Monitoring System (RAMS) Air Monitoring Stations  Local Air Monitorin...Quality Assurance in Distance and Open LearningERIC Educational Resources Information CenterMahafzah  Mohammed Hasan2012-01-01E-learning has become an increasingly important teaching and learning mode in educational institutions and corporate training. The evaluation of E-learning  however  is essential for the quality assurance of E-learning courses. This paper constructs a three-phase evaluation model for E-learning courses  which includes development  process  andâ€¦30 CFR 14.8 - Quality assurance.Code of Federal Regulations  2014 CFR2014-07-01... 30 Mineral Resources 1 2014-07-01 2014-07-01 false Quality assurance. 14.8 Section 14.8 Mineral Resources MINE SAFETY AND HEALTH ADMINISTRATION  DEPARTMENT OF LABOR TESTING  EVALUATION  AND APPROVAL OF... Standards and Technology  U.S. Department of Commerce or other nationally or internationally recognized...30 CFR 14.8 - Quality assurance.Code of Federal Regulations  2012 CFR2012-07-01... 30 Mineral Resources 1 2012-07-01 2012-07-01 false Quality assurance. 14.8 Section 14.8 Mineral Resources MINE SAFETY AND HEALTH ADMINISTRATION  DEPARTMENT OF LABOR TESTING  EVALUATION  AND APPROVAL OF... Standards and Technology  U.S. Department of Commerce or other nationally or internationally recognized...30 CFR 14.8 - Quality assurance.Code of Federal Regulations  2011 CFR2011-07-01... 30 Mineral Resources 1 2011-07-01 2011-07-01 false Quality assurance. 14.8 Section 14.8 Mineral Resources MINE SAFETY AND HEALTH ADMINISTRATION  DEPARTMENT OF LABOR TESTING  EVALUATION  AND APPROVAL OF... Standards and Technology  U.S. Department of Commerce or other nationally or internationally recognized...Nursing Quality Assurance: The Wisconsin SystemERIC Educational Resources Information CenterHover  Julie; Zimmer  Marie J.1978-01-01Evaluation model guidelines for hospital departments of nursing to use in their nursing quality assurance programs are presented as developed in Wisconsin. Four essential components of the Wisconsin outcome evaluation system are criteria  assessment  standards  and improvement of care. Sample tests and charts are included in the article. (MF)Production and quality assurance automation in the Goddard Space Flight Center Flight Dynamics FacilityNASA Technical Reports Server (NTRS)Chapman  K. B.; Cox  C. M.; Thomas  C. W.; Cuevas  O. O.; Beckman  R. M.1994-01-01The Flight Dynamics Facility (FDF) at the NASA Goddard Space Flight Center (GSFC) generates numerous products for NASA-supported spacecraft  including the Tracking and Data Relay Satellites (TDRS's)  the Hubble Space Telescope (HST)  the Extreme Ultraviolet Explorer (EUVE)  and the space shuttle. These products include orbit determination data  acquisition data  event scheduling data  and attitude data. In most cases  product generation involves repetitive execution of many programs. The increasing number of missions supported by the FDF has necessitated the use of automated systems to schedule  execute  and quality assure these products. This automation allows the delivery of accurate products in a timely and cost-efficient manner. To be effective  these systems must automate as many repetitive operations as possible and must be flexible enough to meet changing support requirements. The FDF Orbit Determination Task (ODT) has implemented several systems that automate product generation and quality assurance (QA). These systems include the Orbit Production Automation System (OPAS)  the New Enhanced Operations Log (NEOLOG)  and the Quality Assurance Automation Software (QA Tool). Implementation of these systems has resulted in a significant reduction in required manpower  elimination of shift work and most weekend support  and improved support quality  while incurring minimal development cost. This paper will present an overview of the concepts used and experiences gained from the implementation of these automation systems.Quality assurance methodology for Varian RapidArc treatment plansPubMed CentralCirino  Eileen T.; Xiong  Li; Mower  Herbert W.2010-01-01With the commercial introduction of the Varian RapidArc  a new modality for treatment planning and delivery  the need has arisen for consistent and efficient techniques for performing patientâ€specific quality assurance (QA) tests. In this paper we present our methodology for a RapidArc treatment plan QA procedure. For our measurements we used a 2D diode array (MapCHECK) embedded at 5 cm water equivalent depth in MapPHAN 5 phantom and an Exradin A16 ion chamber placed in six different positions in a cylindrical homogeneous phantom (QUASAR). We also checked the MUs for the RapidArc plans by using independent software (RadCalc). The agreement between Eclipse calculations and MapCHECK/MapPHAN 5 measurements was evaluated using both absolute distanceâ€toâ€agreement (DTA) and gamma index with 10% dose threshold (TH)  3% dose difference (DD)  and 3 mm DTA. The average agreement was 94.4% for the DTA approach and 96.3% for the gamma index approach. In highâ€dose areas  the discrepancy between calculations and ion chamber measurements using the QUASAR phantom was within 4.5% for prostate cases. For the RadCalc calculations  we used the average SSD along the arc; however  for some patients the agreement for the MUs obtained with RadCalc versus Eclipse was inadequate (discrepancy>5%). In these cases  the plan was divided into partial arc plans so that RadCalc could perform a better estimation of the MUs. The discrepancy was further reduced to within ~4% using this approach. Regardless of the variation in prescribed dose and location of the treated areas  we obtained very good results for all patients studied in this paper. PACS number: 87.55.QrEvaluation of a laboratory quality assurance pilot programme for malaria diagnostics in low-transmission areas of Kenya  2013.PubMedWanja  Elizabeth; Achilla  Rachel; Obare  Peter; Adeny  Rose; Moseti  Caroline; Otieno  Victor; Morang'a  Collins; Murigi  Ephantus; Nyamuni  John; Monthei  Derek R; Ogutu  Bernhards; Buff  Ann M2017-05-25One objective of the Kenya National Malaria Strategy 2009-2017 is scaling access to prompt diagnosis and effective treatment. In 2013  a quality assurance (QA) pilot was implemented to improve accuracy of malaria diagnostics at selected health facilities in low-transmission counties of Kenya. Trends in malaria diagnostic and QA indicator performance during the pilot are described. From June to December 2013  28 QA officers provided on-the-job training and mentoring for malaria microscopy  malaria rapid diagnostic tests and laboratory QA/quality control (QC) practices over four 1-day visits at 83 health facilities. QA officers observed and recorded laboratory conditions and practices and cross-checked blood slides for malaria parasite presence  and a portion of cross-checked slides were confirmed by reference laboratories. Eighty (96%) facilities completed the pilot. Among 315 personnel at pilot initiation  13% (nÂ =Â 40) reported malaria diagnostics training within the previous 12Â months. Slide positivity ranged from 3 to 7%. Compared to the reference laboratory  microscopy sensitivity ranged from 53 to 96% and positive predictive value from 39 to 53% for facility staff and from 60 to 96% and 52 to 80%  respectively  for QA officers. Compared to reference  specificity ranged from 88 to 98% and negative predictive value from 98 to 99% for health-facility personnel and from 93 to 99% and 99%  respectively  for QA officers. The kappa value ranged from 0.48-0.66 for facility staff and 0.57-0.84 for QA officers compared to reference. The only significant test performance improvement observed for facility staff was for specificity from 88% (95% CI 85-90%) to 98% (95% CI 97-99%). QA/QC practices  including use of positive-control slides  internal and external slide cross-checking and recording of QA/QC activities  all increased significantly across the pilot (pÂ <Â 0.001). Reference material availability also increased significantly; availability of six microscopy jobPoster - Thur Eve - 10: Long term stability of VMAT quality assurance parameters using an EPID.PubMedPekar  J; Diamond  K R2012-07-01The rapidly growing use of volumetric modulated arc therapy (VMAT) treatments in radiation therapy calls for a quantitative  automated  and reliable quality assurance (QA) procedure that can be used routinely in the clinical setting. In this work  we present a series VMAT QA procedures used to assess dynamic multi-leaf collimator (MLC) positional accuracy  variable dose-rate accuracy  and MLC leaf speed accuracy. The QA procedures were performed using amorphous silicon electronic portal imaging devices (EPID) to determine the long term stability of the measured parameters on two Varian linear accelerators. The measurements were repeated weekly on both linear accelerators for a period of three months and the EPID images were analyzed using custom Matlab software. The results of the picket fence tests indicate that MLC leaf positions can be identified to within 0.11 mm and 0.15 mm for static gantry delivery and VMAT delivery respectively. In addition  the dose-rate  gantry speed and MLC leaf speed tests both show very good stability over the measurement period. The measurements thus far  suggest that a number of the dosimetry tests may be suitable for quarterly QA for Varian iX and Trilogy linacs. However  additional measurements are required to confirm the frequency with which each test is required for safe and reliable VMAT delivery at our centre. Â© 2012 American Association of Physicists in Medicine.Technical Note: Unified imaging and robotic couch quality assurance.PubMedCook  Molly C; Roper  Justin; Elder  Eric S; Schreibmann  Eduard2016-09-01To introduce a simplified quality assurance (QA) procedure that integrates tests for the linac's imaging components and the robotic couch. Current QA procedures for evaluating the alignment of the imaging system and linac require careful positioning of a phantom at isocenter before image acquisition and analysis. A complementary procedure for the robotic couch requires an initial displacement of the phantom and then evaluates the accuracy of repositioning the phantom at isocenter. We propose a two-in-one procedure that introduces a custom software module and incorporates both checks into one motion for increased efficiency. The phantom was manually set with random translational and rotational shifts  imaged with the in-room imaging system  and then registered to the isocenter using a custom software module. The software measured positioning accuracy by comparing the location of the repositioned phantom with a CAD model of the phantom at isocenter  which is physically verified using the MV port graticule. Repeatability of the custom software was tested by an assessment of internal marker location extraction on a series of scans taken over differing kV and CBCT acquisition parameters. The proposed method was able to correctly position the phantom at isocenter within acceptable 1 mm and 1Â° SRS tolerances  verified by both physical inspection and the custom software. Residual errors for mechanical accuracy were 0.26 mm vertically  0.21 mm longitudinally  0.55 mm laterally  0.21Â° in pitch  0.1Â° in roll  and 0.67Â° in yaw. The software module was shown to be robust across various scan acquisition parameters  detecting markers within 0.15 mm translationally in kV acquisitions and within 0.5 mm translationally and 0.3Â° rotationally across CBCT acquisitions with significant variations in voxel size. Agreement with vendor registration methods was well within 0.5 mm; differences were not statistically significant. As compared to the current two-step approach  the proposedPractical use of a plastic scintillator for quality assurance of electron beam therapy.PubMedYogo  Katsunori; Tatsuno  Yuya; Tsuneda  Masato; Aono  Yuki; Mochizuki  Daiki; Fujisawa  Yoshiki; Matsushita  Akihiro; Ishigami  Minoru; Ishiyama  Hiromichi; Hayakawa  Kazushige2017-06-07Quality assurance (QA) of clinical electron beams is essential for performing accurate and safe radiation therapy. However  with advances in radiation therapy  QA has become increasingly labor-intensive and time-consuming. In this paper  we propose a tissue-equivalent plastic scintillator for quick and easy QA of clinical electron beams. The proposed tool comprises a plastic scintillator plate and a charge-coupled device camera that enable the scintillation light by electron beams to be recorded with high sensitivity and high spatial resolution. Further  the Cerenkov image is directly subtracted from the scintillation image to discriminate Cerenkov emissions and accurately measure the dose profiles of electron beams with high spatial resolution. Compared with conventional methods  discrepancies in the depth profile improved from 7% to 2% in the buildup region via subtractive corrections. Further  the output brightness showed good linearity with dose  good reproducibility (deviations below 1%)  and dose rate independence (within 0.5%). The depth of 50% dose measured with the tool  an index of electron beam quality  was withinâ€‰â€‰Â±0.5â€‰mm of that obtained with an ionization chamber. Lateral brightness profiles agreed with the lateral dose profiles to within 4% and no significant improvement was obtained using Cerenkov corrections. Field size agreed to within 0.5â€‰mm with those obtained with ionization chamber. For clinical QA of electron boost treatment  a disk scintillator that mimics the shape of a patient's breast is applied. The brightness distribution and dose  calculated using a treatment planning system  was generally acceptable for clinical use  except in limited zones. Overall  the proposed plastic scintillator plate tool efficiently performs QA for electron beam therapy and enables simultaneous verification of output constancy  beam quality  depth  and lateral dose profiles during monthly QAs at lower doses of irradiation (small monitor units  MUs).A Novel Scoring Metrics for Quality Assurance of Ocean Color ObservationsNASA Astrophysics Data System (ADS)Wei  J.; Lee  Z.2016-02-01Interpretation of the ocean bio-optical properties from ocean color observations depends on the quality of the ocean color data  specifically the spectrum of remote sensing reflectance (Rrs). The in situ and remotely measured Rrs spectra are inevitably subject to errors induced by instrument calibration  sea-surface correction and atmospheric correction  and other environmental factors. Great efforts have been devoted to the ocean color calibration and validation. Yet  there exist no objective and consensus criteria for assessment of the ocean color data quality. In this study  the gap is filled by developing a novel metrics for such data quality assurance and quality control (QA/QC). This new QA metrics is not intended to discard ""suspicious"" Rrs spectra from available datasets. Rather  it takes into account the Rrs spectral shapes and amplitudes as a whole and grades each Rrs spectrum. This scoring system is developed based on a large ensemble of in situ hyperspectral remote sensing reflectance data measured from various aquatic environments and processed with robust procedures. This system is further tested with the NASA bio-Optical Marine Algorithm Data set (NOMAD)  with results indicating significant improvements in the estimation of bio-optical properties when Rrs spectra marked with higher quality assurance are used. This scoring system is further verified with simulated data and satellite ocean color data in various regions  and we envision higher quality ocean color products with the implementation of such a quality screening system.A method of setting limits for the purpose of quality assuranceNASA Astrophysics Data System (ADS)Sanghangthum  Taweap; Suriyapee  Sivalee; Kim  Gwe-Ya; Pawlicki  Todd2013-10-01The result from any assurance measurement needs to be checked against some limits for acceptability. There are two types of limits; those that define clinical acceptability (action limits) and those that are meant to serve as a warning that the measurement is close to the action limits (tolerance limits). Currently  there is no standard procedure to set these limits. In this work  we propose an operational procedure to set tolerance limits and action limits. The approach to establish the limits is based on techniques of quality engineering using control charts and a process capability index. The method is different for tolerance limits and action limits with action limits being categorized into those that are specified and unspecified. The procedure is to first ensure process control using the I-MR control charts. Then  the tolerance limits are set equal to the control chart limits on the I chart. Action limits are determined using the Cpm process capability index with the requirements that the process must be in-control. The limits from the proposed procedure are compared to an existing or conventional method. Four examples are investigated: two of volumetric modulated arc therapy (VMAT) point dose quality assurance (QA) and two of routine linear accelerator output QA. The tolerance limits range from about 6% larger to 9% smaller than conventional action limits for VMAT QA cases. For the linac output QA  tolerance limits are about 60% smaller than conventional action limits. The operational procedure describe in this work is based on established quality management tools and will provide a systematic guide to set up tolerance and action limits for different equipment and processes.Informatics Futures in Dental Education and Research: Quality Assurance.ERIC Educational Resources Information CenterCrall  James J.1991-01-01The paper addresses the potential of informatics to patient care quality assurance curricula  focusing on (1) terminology and developments related to quality of care evaluations; (2) criticisms of traditional approaches; (3) limitations of existing data sources for quality assurance in dentistry; and (4) quality assurance considerations inâ€¦10 CFR 830.121 - Quality Assurance Program (QAP).Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 4 2010-01-01 2010-01-01 false Quality Assurance Program (QAP). 830.121 Section 830.121 Energy DEPARTMENT OF ENERGY NUCLEAR SAFETY MANAGEMENT Quality Assurance Requirements Â§ 830.121 Quality... the Quality Assurance criteria in Â§ 830.122. (b) The contractor responsible for a DOE nuclear facility...Quality Assurance and School Monitoring in Hong KongERIC Educational Resources Information CenterMok  Magdalena Mo Ching2007-01-01This study reports on the Hong Kong education quality assurance and school monitoring system. Three research questions were addressed: (1) Who controls the quality of school education in Hong Kong? (2) What strategies are used in the Hong Kong school education quality assurance process? (3) Agenda for Future Research on quality assurance andâ€¦10 CFR 830.121 - Quality Assurance Program (QAP).Code of Federal Regulations  2013 CFR2013-01-01... changes continue to satisfy the quality assurance requirements. (4) Conduct work in accordance with the... 10 Energy 4 2013-01-01 2013-01-01 false Quality Assurance Program (QAP). 830.121 Section 830.121 Energy DEPARTMENT OF ENERGY NUCLEAR SAFETY MANAGEMENT Quality Assurance Requirements Â§ 830.121 Quality...10 CFR 830.121 - Quality Assurance Program (QAP).Code of Federal Regulations  2012 CFR2012-01-01... changes continue to satisfy the quality assurance requirements. (4) Conduct work in accordance with the... 10 Energy 4 2012-01-01 2012-01-01 false Quality Assurance Program (QAP). 830.121 Section 830.121 Energy DEPARTMENT OF ENERGY NUCLEAR SAFETY MANAGEMENT Quality Assurance Requirements Â§ 830.121 Quality...10 CFR 830.121 - Quality Assurance Program (QAP).Code of Federal Regulations  2011 CFR2011-01-01... changes continue to satisfy the quality assurance requirements. (4) Conduct work in accordance with the... 10 Energy 4 2011-01-01 2011-01-01 false Quality Assurance Program (QAP). 830.121 Section 830.121 Energy DEPARTMENT OF ENERGY NUCLEAR SAFETY MANAGEMENT Quality Assurance Requirements Â§ 830.121 Quality...10 CFR 830.121 - Quality Assurance Program (QAP).Code of Federal Regulations  2014 CFR2014-01-01... changes continue to satisfy the quality assurance requirements. (4) Conduct work in accordance with the... 10 Energy 4 2014-01-01 2014-01-01 false Quality Assurance Program (QAP). 830.121 Section 830.121 Energy DEPARTMENT OF ENERGY NUCLEAR SAFETY MANAGEMENT Quality Assurance Requirements Â§ 830.121 Quality...[Quality assurance in occupational health services].PubMedMichalak  J1996-01-01The general conditions influencing the quality assurance and audit in Polish occupational health services are presented. The factors promoting or hampering the implementation of quality assurance and audits are also discussed. The major influence on the transformation of Polish occupational health services in exorted by employers who are committed to cover the costs of the obligatory prophylactic examination of their employees. This is the factor which also contributes to the improvement of quality if services. The definitions of the most important terms are reviewed to highlight their accordance with the needs of occupational health services in Poland. The examples of audit are presented and the elements of selected methods of auditing are suggested to be adopted in Poland.Quality assured measurements of animal building emissions: gas concentrations.PubMedHeber  Albert J; Ni  Ji-Qin; Lim  Teng T; Tao  Pei-Chun; Schmidt  Amy M; Koziel  Jacek A; Beasley  David B; Hoff  Steven J; Nicolai  Richard E; Jacobson  Larry D; Zhang  Yuanhui2006-10-01Comprehensive field studies were initiated in 2002 to measure emissions of ammonia (NH3)  hydrogen sulfide (H2S)  carbon dioxide (CO2)  methane (CH4)  nonmethane hydrocarbons (NMHC)  particulate matter <10 microm in diameter  and total suspended particulate from swine and poultry production buildings in the United States. This paper focuses on the quasicontinuous gas concentration measurement at multiple locations among paired barns in seven states. Documented principles  used in air pollution monitoring at industrial sources  were applied in developing quality assurance (QA) project plans for these studies. Air was sampled from multiple locations with each gas analyzed with one high quality commercial gas analyzer that was located in an environmentally controlled on-farm instrument shelter. A nominal 4 L/min gas sampling system was designed and constructed with Teflon wetted surfaces  bypass pumping  and sample line flow and pressure sensors. Three-way solenoids were used to automatically switch between multiple gas sampling lines with > or =10 min sampling intervals. Inside and outside gas sampling probes were between 10 and 115 m away from the analyzers. Analyzers used chemiluminescence  fluorescence  photoacoustic infrared  and photoionization detectors for NH3  H2S  CO2  CH4  and NMHC  respectively. Data were collected using personal computer-based data acquisition hardware and software. This paper discusses the methodology of gas concentration measurements and the unique challenges that livestock barns pose for achieving desired accuracy and precision  data representativeness  comparability and completeness  and instrument calibration and maintenance.DICOM index tracker enterprise: advanced system for enterprise-wide quality assurance and patient safety monitoringNASA Astrophysics Data System (ADS)Zhang  Min; Pavlicek  William; Panda  Anshuman; Langer  Steve G.; Morin  Richard; Fetterly  Kenneth A.; Paden  Robert; Hanson  James; Wu  Lin-Wei; Wu  Teresa2015-03-01DICOM Index Tracker (DIT) is an integrated platform to harvest rich information available from Digital Imaging and Communications in Medicine (DICOM) to improve quality assurance in radiology practices. It is designed to capture and maintain longitudinal patient-specific exam indices of interests for all diagnostic and procedural uses of imaging modalities. Thus  it effectively serves as a quality assurance and patient safety monitoring tool. The foundation of DIT is an intelligent database system which stores the information accepted and parsed via a DICOM receiver and parser. The database system enables the basic dosimetry analysis. The success of DIT implementation at Mayo Clinic Arizona calls for the DIT deployment at the enterprise level which requires significant improvements. First  for geographically distributed multi-site implementation  the first bottleneck is the communication (network) delay; the second is the scalability of the DICOM parser to handle the large volume of exams from different sites. To address this issue  DICOM receiver and parser are separated and decentralized by site. To facilitate the enterprise wide Quality Assurance (QA)  a notable challenge is the great diversities of manufacturers  modalities and software versions  as the solution DIT Enterprise provides the standardization tool for device naming  protocol naming  physician naming across sites. Thirdly  advanced analytic engines are implemented online which support the proactive QA in DIT Enterprise.The use of photostimulable phosphor systems for periodic quality assurance in radiotherapy.PubMedConte  L; Bianchi  C; Cassani  E; Monciardini  M; Mordacchini  C; Novario  R; Strocchi  S; Stucchi  P; Tanzi  F2008-03-01The fusion of radiological and optical images can be achieved through charging a photostimulable phosphor plate (PSP) with an exposure to a field of X- or gamma-rays  followed by exposure to an optical image which discharges the plate in relation to the amount of incident light. According to this PSP characteristic  we developed a simple method for periodic quality assurance (QA) of light/radiation field coincidence  distance indicator  field size indicators  crosshair centering  coincidence of radiation and mechanical isocenter for linear accelerators. The geometrical accuracy of radiological units can be subjected to the same QA method. Further  the source position accuracy for an HDR remote afterloader can be checked by taking an autoradiography of the radioactive source and simultaneously an optical image of a reference geometrical system.Quality Assurance of Quality Assurance Agencies from an Asian Perspective: Regulation  Autonomy and AccountabilityERIC Educational Resources Information CenterHou  Angela Yung-Chi; Ince  Martin; Tsai  Sandy; Chiang  Chung Lin2015-01-01As quality guardians of higher education  quality assurance agencies are required to guarantee the credibility of the review process and to ensure the objectivity and transparency of their decisions and recommendations. These agencies are therefore expected to use a range of internal and external approaches to prove the quality of their reviewâ€¦Now & Then: Ingrid Proctor-Fridia: Quality Assurance Representative.ERIC Educational Resources Information CenterBarnes  Sue; Michalowicz  Karen Dee1995-01-01Describes the use of geometry now by a U.S. Department of Defense quality assurance representative and in ancient times by the Egyptians and Babylonians. Includes reproducible student worksheets on quality assurance. (MKR)Position paper: recommendations for a digital mammography quality assurance programÂ V4.0.PubMedHeggie  J C P; Barnes  P; Cartwright  L; Diffey  J; Tse  J; Herley  J; McLean  I D; Thomson  F J; Grewal  R K; Collins  L T2017-09-01In 2001 the ACPSEM published a position paper on quality assurance in screen film mammography which was subsequently adopted as a basis for the quality assurance programs of both the Royal Australian and New Zealand College of Radiologists (RANZCR) and of BreastScreen Australia. Since then the clinical implementation of digital mammography has been realised and it has become evident that existing screen-film protocols were not appropriate to assure the required image quality needed for reliable diagnosis or to address the new dose implications resulting from digital technology. In addition  the advantages and responsibilities inherent in teleradiology are most critical in mammography and also need to be addressed. The current document is the result of a review of current overseas practice and local experience in these areas. At this time the technology of digital imaging is undergoing significant development and there is still a lack of full international consensus about some of the detailed quality control (QC) tests that should be included in quality assurance (QA) programs. This document describes the current status in digital mammography QA and recommends test procedures that may be suitable in the Australasian environment. For completeness  this document also includes a review of the QA programs required for the various types of digital biopsy units used in mammography. In the future  international harmonisation of digital quality assurance in mammography and changes in the technology may require a review of this document. Version 2.0 represented the first of these updates and key changes related to image quality evaluation  ghost image evaluation and interpretation of signal to noise ratio measurements. In Version 3.0 some significant changes  made in light of further experience gained in testing digital mammography equipment were introduced. In Version 4.0  further changes have been made  most notably digital breast tomosynthesis (DBT) testing and QC haveQuality Assurance and Quality Enhancement in Higher Education: Contested Territories?ERIC Educational Resources Information CenterFilippakou  Ourania; Tapper  Ted2008-01-01This paper analyses the unfolding of the quality agenda in England from 1992 to the present. By using two disciplinary approaches  ""political science"" and ""social philosophy""  the article traces the recent transition from quality assurance to quality enhancement. How is this development to be explained and how significant isâ€¦Design and performance of daily quality assurance system for carbon ion therapy at NIRSNASA Astrophysics Data System (ADS)Saotome  N.; Furukawa  T.; Hara  Y.; Mizushima  K.; Tansho  R.; Saraya  Y.; Shirai  T.; Noda  K.2017-09-01At National Institute of Radiological Sciences (NIRS)  we have been commissioning a rotating-gantry system for carbon-ion radiotherapy. This rotating gantry can transport heavy ions at 430 MeV/u to an isocenter with irradiation angles of Â±180Â° that can rotate around the patient so that the tumor can be irradiated from any direction. A three-dimensional pencil-beam scanning irradiation system equipped with the rotating gantry enables the optimal use of physical characteristics of carbon ions to provide accurate treatment. To ensure the treatment quality using such a complex system  the calibration of the primary dose monitor  output check  range check  dose rate check  machine safety check  and some mechanical tests should be performed efficiently. For this purpose  we have developed a measurement system dedicated for quality assurance (QA) of this gantry system: the Daily QA system. The system consists of an ionization chamber system and a scintillator system. The ionization chamber system is used for the calibration of the primary dose monitor  output check  and dose rate check  and the scintillator system is used for the range check  isocenter  and gantry angle. The performance of the Daily QA system was verified by a beam test. The stability of the output was within 0.5%  and the range was within 0.5 mm. The coincidence of the coordinates between the patient-positioning system and the irradiation system was verified using the Daily QA system. Our present findings verified that the new Daily QA system for a rotating gantry is capable of verifying the irradiation system with sufficient accuracy.TU-FG-201-04: Computer Vision in Autonomous Quality Assurance of Linear AcceleratorsSciTech ConnectYu  H; Jenkins  C; Yu  SPurpose: Routine quality assurance (QA) of linear accelerators represents a critical and costly element of a radiation oncology center. Recently  a system was developed to autonomously perform routine quality assurance on linear accelerators. The purpose of this work is to extend this system and contribute computer vision techniques for obtaining quantitative measurements for a monthly multi-leaf collimator (MLC) QA test specified by TG-142  namely leaf position accuracy  and demonstrate extensibility for additional routines. Methods: Grayscale images of a picket fence delivery on a radioluminescent phosphor coated phantom are captured using a CMOS camera. Collected images are processed to correct formoreÂ Â» camera distortions  rotation and alignment  reduce noise  and enhance contrast. The location of each MLC leaf is determined through logistic fitting and a priori modeling based on knowledge of the delivered beams. Using the data collected and the criteria from TG-142  a decision is made on whether or not the leaf position accuracy of the MLC passes or fails. Results: The locations of all MLC leaf edges are found for three different picket fence images in a picket fence routine to 0.1mm/1pixel precision. The program to correct for image alignment and determination of leaf positions requires a runtime of 21â€“ 25 seconds for a single picket  and 44 â€“ 46 seconds for a group of three pickets on a standard workstation CPU  2.2 GHz Intel Core i7. Conclusion: MLC leaf edges were successfully found using techniques in computer vision. With the addition of computer vision techniques to the previously described autonomous QA system  the system is able to quickly perform complete QA routines with minimal human contribution.Â«Â lessInvestigations of a flat-panel detector for quality assurance measurements in ion beam therapy.PubMedHartmann  Bernadette; Telsemeyer  Julia; Huber  Lucas; Ackermann  Benjamin; JÃ¤kel  Oliver; MartiÅ¡Ã­kovÃ¡  MÃ¡ria2012-01-07Increased accuracy in radiation delivery to a patient provided by scanning particle beams leads to high demands on quality assurance (QA). To meet the requirements  an extensive quality assurance programme has been implemented at the Heidelberg Ion Beam Therapy Center. Currently  high-resolution radiographic films are used for beam spot position measurements and homogeneity measurements for scanned fields. However  given that using this film type is time and equipment demanding  considerations have been made to replace the radiographic films in QA by another appropriate device. In this study  the suitability of the flat-panel detector RID 256 L based on amorphous silicon was investigated as an alternative method. The currently used radiographic films were taken as a reference. Investigations were carried out for proton and carbon ion beams. The detectors were irradiated simultaneously to allow for a direct comparison. The beam parameters (e.g. energy  focus  position) currently used in the daily QA procedures were applied. Evaluation of the measurements was performed using newly implemented automatic routines. The results for the flat-panel detector were compared to the standard radiographic films. Additionally  a field with intentionally decreased homogeneity was applied to test the detector's sensitivities toward possible incorrect scan parameters. For the beam position analyses  the flat-panel detector results showed good agreement with radiographic films. For both detector types  deviations between measured and planned spot distances were found to be below 1% (1 mm). In homogeneously irradiated fields  the flat-panel detector showed a better dose response homogeneity than the currently used radiographic film. Furthermore  the flat-panel detector is sensitive to field irregularities. The flat-panel detector was found to be an adequate replacement for the radiographic film in QA measurements. In addition  it saves time and equipment because no post[Quality assurance of the renal applications software].PubMeddel Real NÃºÃ±ez  R; Contreras Puertas  P I; Moreno Ortega  E; Mena Bares  L M; Maza Muret  F R; Latre Romero  J M2007-01-01The need for quality assurance of all technical aspects of nuclear medicine studies is widely recognised. However  little attention has been paid to the quality assurance of the applications software. Our work reported here aims at verifying the analysis software for processing of renal nuclear medicine studies (renograms). The software tools were used to build a synthetic dynamic model of renal system. The model consists of two phases: perfusion and function. The organs of interest (kidneys  bladder and aortic artery) were simple geometric forms. The uptake of the renal structures was described by mathematic functions. Curves corresponding to normal or pathological conditions were simulated for kidneys  bladder and aortic artery by appropriate selection of parameters. There was no difference between the parameters of the mathematic curves and the quantitative data produced by the renal analysis program. Our test procedure is simple to apply  reliable  reproducible and rapid to verify the renal applications software.DOE-OES-EML quality assurance programSciTech ConnectSanderson  C.G.1980-01-01Contractor laboratories handling radioactive materials for the US Department of Energy (DOE) are required to monitor the environmental exposure and publish annual reports for the Division of Operational and Environmental Safety (OES). In order to determine the validity of the data contained in these reports the Environmental Measurements Laboratory (EML) was requested to develop  coordinate  and conduct an Environmental Quality Assurance Program (QAP). There are four major phases to the DOE-OES-EML Quality Assurance Program: sample collection and preparation  sample analyses at EML  quarterly sample distribution  and reporting the data returned by the participants. The various phases of the QAP andmoreÂ Â» the data reported during the first year of the program are discussed.Â«Â lessQuality assurance for health and environmental chemistry: 1990SciTech ConnectGautier  M.A.; Gladney  E.S.; Koski  N.L.1991-10-01This report documents the continuing quality assurance efforts of the Health and Environmental Chemistry Group (HSE-9) at the Los Alamos National Laboratory. The philosophy  methodology  computing resources  and laboratory information management system used by the quality assurance program to encompass the diversity of analytical chemistry practiced in the group are described. Included in the report are all quality assurance reference materials used  along with their certified or consensus concentrations  and all analytical chemistry quality assurance measurements made by HSE-9 during 1990.Quality Assurance/Quality Control JobsNASA Astrophysics Data System (ADS)Fanslau  Melody; Young  JanelleThe production of a quality and safe food product is essential to the success of any food manufacturing facility. Because of this great importance  a career in quality can be extremely rewarding. Without happy customers willing to buy a product  a company would not be able to survive. Quality issues such as foreign objects  spoiled or mislabeled product  failure to meet net weight requirements  or a recall can all turn customers away from buying a product. The food industry is a customer-driven market in which some consumers are brand loyal based on a history of high quality or in which a single bad experience with a product will turn them away for a lifetime. With this said  the main role of a quality department is to help ensure that quality issues such as these are eliminated or kept to a minimum to maintain or increase the number of customers purchasing their product.Underground Test Area Fiscal Year 2013 Annual Quality Assurance Report Nevada National Security Site  Nevada  Revision 0SciTech ConnectKrenzien  Susan; Marutzky  SamThis report is required by the Underground Test Area (UGTA) Quality Assurance Plan (QAP) and identifies the UGTA quality assurance (QA) activities for fiscal year (FY) 2013. All UGTA organizationsâ€”U.S. Department of Energy (DOE)  National Nuclear Security Administration Nevada Field Office (NNSA/NFO); Desert Research Institute (DRI); Lawrence Livermore National Laboratory (LLNL); Los Alamos National Laboratory (LANL); Navarro-Intera  LLC (N-I); National Security Technologies  LLC (NSTec); and the U.S. Geological Survey (USGS)â€”conducted QA activities in FY 2013. The activities included conducting assessments  identifying findings and completing corrective actions  evaluating laboratory performance  and publishing documents. In addition  integrated UGTA required reading and correctivemoreÂ Â» action tracking was instituted.Â«Â lessHPV testing for primary cervical screening: Laboratory issues and evolving requirements for robust quality assurance.PubMedCarozzi  Francesca Maria; Del Mistro  Annarosa; Cuschieri  Kate; Frayle  Helena; Sani  Cristina; Burroni  Elena2016-03-01This review aims to highlight the importance of Quality Assurance for Laboratories performing HPV test for Cervical Cancer Screening. An HPV test  to be used as primary screening test  must be validated according to international criteria  based on comparison of its clinical accuracy to HC2 or GP5+/6+ PCR-EIA tests. The number of validated platforms is increasing and appropriate Quality Assurance Programs (QAPs) which can interrogate longitudinal robustness and quality are paramount. This document describes the following topics: (1) the characteristics of an HPV laboratory and the personnel training needs  to ensure an elevated quality of the entire process and the optimal use of the resources; (2) the Quality Assurance  as both internal (IQA) and external quality assessment (EQA) systems  to be implemented and performed  and the description of the existing EQAs  including limitations; (3) general considerations for an optimal EQA program for hrHPV primary screening Due to the importance of Quality Assurance for this field  international efforts are necessary to improve QA International Collaboration. Copyright Â© 2015 Elsevier B.V. All rights reserved.10 CFR 71.103 - Quality assurance organization.Code of Federal Regulations  2011 CFR2011-01-01... 10 Energy 2 2011-01-01 2011-01-01 false Quality assurance organization. 71.103 Section 71.103... Quality Assurance Â§ 71.103 Quality assurance organization. (a) The licensee  2 certificate holder  and... that are important to safety have been correctly performed. (c) The persons and organizations...10 CFR 71.103 - Quality assurance organization.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance organization. 71.103 Section 71.103... Quality Assurance Â§ 71.103 Quality assurance organization. (a) The licensee  2 certificate holder  and... that are important to safety have been correctly performed. (c) The persons and organizations...Operational excellence (six sigma) philosophy: Application to software quality assuranceSciTech ConnectLackner  M.1997-11-01This report contains viewgraphs on operational excellence philosophy of six sigma applied to software quality assurance. This report outlines the following: goal of six sigma; six sigma tools; manufacturing vs administrative processes; Software quality assurance document inspections; map software quality assurance requirements document; failure mode effects analysis for requirements document; measuring the right response variables; and questions.10 CFR 63.144 - Quality assurance program change.Code of Federal Regulations  2011 CFR2011-01-01... 10 Energy 2 2011-01-01 2011-01-01 false Quality assurance program change. 63.144 Section 63.144 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) DISPOSAL OF HIGH-LEVEL RADIOACTIVE WASTES IN A GEOLOGIC... assurance program information that duplicates language in quality assurance regulatory guides and quality...2015 International PV Quality Assurance Task Force (PVQAT) Workshop |Science.gov WebsitesPhotovoltaic Research | NREL International PV Quality Assurance Task Force (PVQAT) Workshop 2015 International PV Quality Assurance Task Force (PVQAT) Workshop Wednesday  February 25  2015 Chairs : Tony Sample and Masaaki Yamamichi The 2015 International PV Quality Assurance Task Force (PVQATPerspectives on Quality Assurance in Higher Education in NorwayERIC Educational Resources Information CenterLycke  Kirsten Hofgaard2004-01-01Quality assurance is well known internationally but the notion is relatively new in Norway. To understand some of the issues and dilemmas that emerge in the Norwegian reception of quality assurance in higher education  this article traces how quality assurance is gaining its form and how international trends are understood  transposed and adoptedâ€¦Quality Assurance in Higher Education: Proposals for Consultation.ERIC Educational Resources Information CenterHigher Education Funding Council for England  Bristol.This document sets out for consultation proposals for a revised method for quality assurance of teaching and learning in higher education. The proposals cover: (1) the objectives and principles of quality assurance; (2) an approach to quality assurance based on external audit principles; (3) the collection and publication of information; (4)â€¦Single-Subject Evaluation: A Tool for Quality Assurance.ERIC Educational Resources Information CenterNuehring  Elane M.; Pascone  Anne B.1986-01-01The use of single-subject designs in peer review  in utilization review  and in other quality-assurance audits is encouraged. Presents an overview of the methodologies of single-subject designs and quality assurance  and provides examples of cases in which single-subject techniques furnished relevant quality assurance documentation. (Author/ABB)Development of an Instructional Quality Assurance Model in Nursing ScienceERIC Educational Resources Information CenterAjpru  Haruthai; Pasiphol  Shotiga; Wongwanich  Suwimon2011-01-01The purpose of this study was to develop an instructional quality assurance model in nursing science. The study was divided into 3 phases; (1) to study the information for instructional quality assurance model development (2) to develop an instructional quality assurance model in nursing science and (3) to audit and the assessment of the developedâ€¦Quality assurance program plan for radionuclide airborne emissions monitoringSciTech ConnectBoom  R.J.1995-12-01This Quality Assurance Program Plan identifies quality assurance program requirements and addresses the various Westinghouse Hanford Company organizations and their particular responsibilities in regards to sample and data handling of radiological airborne emissions. This Quality Assurance Program Plan is prepared in accordance with and to written requirements.Quality Assurance of Assessment and Moderation Discourses Involving Sessional StaffERIC Educational Resources Information CenterGrainger  Peter; Adie  Lenore; Weir  Katie2016-01-01Quality assurance is a major agenda in tertiary education. The casualisation of academic work  especially in teaching  is also a quality assurance issue. Casual or sessional staff members teach and assess more than 50% of all university courses in Australia  and yet the research in relation to the role sessional staff play in quality assurance ofâ€¦42 CFR 441.585 - Quality assurance system.Code of Federal Regulations  2012 CFR2012-10-01... provides information about the provisions of quality improvement and assurance to each individual receiving... 42 Public Health 4 2012-10-01 2012-10-01 false Quality assurance system. 441.585 Section 441.585...) Â§ 441.585 Quality assurance system. (a) States must establish and maintain a comprehensive  continuous...10 CFR 71.105 - Quality assurance program.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance program. 71.105 Section 71.105 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) PACKAGING AND TRANSPORTATION OF RADIOACTIVE MATERIAL Quality Assurance Â§ 71.105 Quality assurance program. (a) The licensee  certificate holder  and applicant for a CoC...Managerialism and the Risky Business of Quality Assurance in UniversitiesERIC Educational Resources Information CenterDavis  Annemarie2017-01-01Purpose: This paper aims to identify what is needed to enhance academic quality assurance in a university  with specific efforts to reduce the risks associated with ritualised quality assurance practices. Design/methodology/approach: The aspects to enhance academic quality assurance efforts in managerial universities are identified through aâ€¦21 CFR 892.1940 - Radiologic quality assurance instrument.Code of Federal Regulations  2010 CFR2010-04-01... 21 Food and Drugs 8 2010-04-01 2010-04-01 false Radiologic quality assurance instrument. 892.1940... (CONTINUED) MEDICAL DEVICES RADIOLOGY DEVICES Diagnostic Devices Â§ 892.1940 Radiologic quality assurance instrument. (a) Identification. A radiologic quality assurance instrument is a device intended for medical...10 CFR 71.135 - Quality assurance records.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance records. 71.135 Section 71.135 Energy NUCLEAR REGULATORY COMMISSION (CONTINUED) PACKAGING AND TRANSPORTATION OF RADIOACTIVE MATERIAL Quality Assurance Â§ 71.135 Quality assurance records. The licensee  certificate holder  and applicant for a CoC...10 CFR 72.174 - Quality assurance records.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance records. 72.174 Section 72.174 Energy... NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.174 Quality assurance records. The licensee  applicant for a license  certificate holder  and...49 CFR 180.505 - Quality assurance program.Code of Federal Regulations  2010 CFR2010-10-01... 49 Transportation 2 2010-10-01 2010-10-01 false Quality assurance program. 180.505 Section 180.505... MAINTENANCE OF PACKAGINGS Qualification and Maintenance of Tank Cars Â§ 180.505 Quality assurance program. The quality assurance program requirements of Â§ 179.7 of this subchapter apply. ...10 CFR 72.144 - Quality assurance program.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance program. 72.144 Section 72.144 Energy... NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.144 Quality assurance program. (a) The licensee  applicant for a license  certificate holder...Quality Assurance in Postgraduate Education. ENQA Workshop Report 12ERIC Educational Resources Information CenterBitusikova  Alexandra; Bohrer  Janet; Borosic  Ivana; Costes  Nathalie; Edinsel  Kerim; Hollander  Karoline; Jacobsson  Gunilla; Jakopovic  Ivan Filip; Kearney  Mary-Louise; Mulder  Fred; Negyesi  Judith; Pietzonka  Manuel2010-01-01The present report follows an ENQA (European Association for Quality Assurance in Higher Education) Workshop on Quality Assurance and Postgraduate Education  hosted by the Romanian Agency for Quality Assurance in Higher Education (ARACIS) in Brasov  Romania on 12-13 March 2009. The workshop was an excellent opportunity for ENQA members to exchangeâ€¦42 CFR 441.474 - Quality assurance and improvement plan.Code of Federal Regulations  2010 CFR2010-10-01... 42 Public Health 4 2010-10-01 2010-10-01 false Quality assurance and improvement plan. 441.474... SERVICES Optional Self-Directed Personal Assistance Services Program Â§ 441.474 Quality assurance and improvement plan. (a) The State must provide a quality assurance and improvement plan that describes the State...42 CFR 441.474 - Quality assurance and improvement plan.Code of Federal Regulations  2011 CFR2011-10-01... 42 Public Health 4 2011-10-01 2011-10-01 false Quality assurance and improvement plan. 441.474... SERVICES Optional Self-Directed Personal Assistance Services Program Â§ 441.474 Quality assurance and improvement plan. (a) The State must provide a quality assurance and improvement plan that describes the State...42 CFR 441.474 - Quality assurance and improvement plan.Code of Federal Regulations  2013 CFR2013-10-01... 42 Public Health 4 2013-10-01 2013-10-01 false Quality assurance and improvement plan. 441.474... SERVICES Optional Self-Directed Personal Assistance Services Program Â§ 441.474 Quality assurance and improvement plan. (a) The State must provide a quality assurance and improvement plan that describes the State...42 CFR 441.474 - Quality assurance and improvement plan.Code of Federal Regulations  2012 CFR2012-10-01... 42 Public Health 4 2012-10-01 2012-10-01 false Quality assurance and improvement plan. 441.474... SERVICES Optional Self-Directed Personal Assistance Services Program Â§ 441.474 Quality assurance and improvement plan. (a) The State must provide a quality assurance and improvement plan that describes the State...42 CFR 441.474 - Quality assurance and improvement plan.Code of Federal Regulations  2014 CFR2014-10-01... 42 Public Health 4 2014-10-01 2014-10-01 false Quality assurance and improvement plan. 441.474... SERVICES Optional Self-Directed Personal Assistance Services Program Â§ 441.474 Quality assurance and improvement plan. (a) The State must provide a quality assurance and improvement plan that describes the State...10 CFR 72.174 - Quality assurance records.Code of Federal Regulations  2011 CFR2011-01-01... 10 Energy 2 2011-01-01 2011-01-01 false Quality assurance records. 72.174 Section 72.174 Energy... NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.174 Quality assurance records. The licensee  applicant for a license  certificate holder  and...10 CFR 72.174 - Quality assurance records.Code of Federal Regulations  2012 CFR2012-01-01... 10 Energy 2 2012-01-01 2012-01-01 false Quality assurance records. 72.174 Section 72.174 Energy... NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.174 Quality assurance records. The licensee  applicant for a license  certificate holder  and...10 CFR 72.174 - Quality assurance records.Code of Federal Regulations  2014 CFR2014-01-01... 10 Energy 2 2014-01-01 2014-01-01 false Quality assurance records. 72.174 Section 72.174 Energy... NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality Assurance Â§ 72.174 Quality assurance records. The licensee  applicant for a license  certificate holder  and...A pilot quality assurance scheme for diabetic retinopathy risk reduction programmes.PubMedGarvican  L; Scanlon  P H2004-10-01We describe a pilot study of measurement of quality assurance targets for diabetic retinopathy screening and performance comparison between 10 existing services  in preparation for the roll-out of the national programme. In 1999 the UK National Screening Committee approved proposals for a national diabetic retinopathy risk reduction programme  including recommendations for quality assurance  but implementation was held pending publication of the National Service Framework for Diabetes. Existing services requested the authors to perform a pilot study of a QA scheme  indicating willingness to contribute data for comparison. Objectives and quality standards were developed  following consultation with diabetologists  ophthalmologists and retinal screeners. Services submitted 2001/2 performance data  in response to a questionnaire  for anonymization  central analysis and comparison. The 17 quality standards encompass all aspects of the programme from identification of patients to timeliness of treatment. Ten programmes took part  submitting all the data available. All returns were incomplete  but especially so from the optometry-based schemes. Eight or more services demonstrated they could reach the minimum level in only five of the 17 standards. Thirty per cent could not provide coverage data. All were running behind. Reasons for difficulties in obtaining data and/or failing to achieve standards included severe under-funding and little previous experience of QA. Information systems were limited and incompatible between diabetes and eye units  and there was a lack of co-ordinated management of the whole programme. Quality assurance is time-consuming  expensive and inadequately resourced. The pilot study identified priorities for local action. National programme implementation must involve integral quality assurance mechanisms from the outset.Quality assessment program for EuroFlow protocols: summary results of four-year (2010-2013) quality assurance rounds.PubMedKalina  Tomas; Flores-Montero  Juan; Lecrevisse  Quentin; Pedreira  Carlos E; van der Velden  Vincent H J; Novakova  Michaela; Mejstrikova  Ester; Hrusak  Ondrej; BÃ¶ttcher  Sebastian; Karsch  Dennis; SÄ™dek  Åukasz; Trinquand  Amelie; Boeckx  Nancy; Caetano  Joana; Asnafi  Vahid; Lucio  Paulo; Lima  Margarida; Helena Santos  Ana; Bonaccorso  Paola; van der Sluijs-Gelling  Alita J; Langerak  Anton W; Martin-Ayuso  Marta; SzczepaÅ„ski  Tomasz; van Dongen  Jacques J M; Orfao  Alberto2015-02-01Flow cytometric immunophenotyping has become essential for accurate diagnosis  classification  and disease monitoring in hemato-oncology. The EuroFlow Consortium has established a fully standardized ""all-in-one"" pipeline consisting of standardized instrument settings  reagent panels  and sample preparation protocols and software for data analysis and disease classification. For its reproducible implementation  parallel development of a quality assurance (QA) program was required. Here  we report on the results of four consecutive annual rounds of the novel external QA EuroFlow program. The novel QA scheme aimed at monitoring the whole flow cytometric analysis process (cytometer setting  sample preparation  acquisition and analysis) by reading the median fluorescence intensities (MedFI) of defined lymphocytes' subsets. Each QA participant applied the predefined reagents' panel on blood cells of local healthy donors. A uniform gating strategy was applied to define lymphocyte subsets and to read MedFI values per marker. The MedFI values were compared with reference data and deviations from reference values were quantified using performance score metrics. In four annual QA rounds  we analyzed 123 blood samples from local healthy donors on 14 different instruments in 11 laboratories from nine European countries. The immunophenotype of defined cellular subsets appeared sufficiently standardized to permit unified (software) data analysis. The coefficient of variation of MedFI for 7 of 11 markers performed repeatedly below 30%  average MedFI in each QA round ranged from 86 to 125% from overall median. Calculation of performance scores was instrumental to pinpoint standardization failures and their causes. Overall  the new EuroFlow QA system for the first time allowed to quantify the technical variation that is introduced in the measurement of fluorescence intensities in a multicentric setting over an extended period of time. EuroFlow QA is a proficiency test specific forImplementing the European Quality Assurance in Vocational Education and Training (EQAVET) at National Level: Some Insights from the PEN Leonardo ProjectERIC Educational Resources Information CenterGatt  Suzanne; Faurschou  Kim2016-01-01EQAVET  the quality assurance tool in vocational and educational training  was developed in response to the need for a supply of a trained workforce for labour market needs. Implementation of EQAVET at national level  however  remains a challenge. The research reported here focused on the implementation of QA processes by VET providers in 4â€¦QUALITY ASSURANCE STUDY OF MARINE LIPID CLASS DETERMINATION USING CHROMAROD/IATROSCAN( REG. TRADEMARK) THIN-LAYER CHROMATOGRAPHY-FLAME IONIZATION DETECTOREPA Science InventoryAn Iatroscan thin-layer chromatorgraphy-flame ionization detector has been utilized to quantify lipid classes in marine samples. This method was evaluated relative to established quality assurance (QA) procedures used for the gas chromatographic analysis of PCBs. A method for ext...Software Quality Assurance and Controls StandardDTIC Science & Technology2010-04-27Software Quality Assurance d C t l St d dan on ro s an ar Sue Carroll Principal Software Quality Analyst  SAS John Wal z VP Technology and...for Information Operations and Reports  1215 Jefferson Davis Highway  Suite 1204  Arlington VA 22202-4302. Respondents should be aware that...Cycle (SLC) process? â€¢ What is in a SQA Process? â€¢ Where are SQA Controls? â€¢ What is the SQA standards history? Wh t i h i i SQA?â€¢ a s c ang ng nQuality Assurance Framework for Mini-GridsSciTech ConnectEsterly  Sean; Baring-Gould  Ian; Booth  SamuelTo address the root challenges of providing quality power to remote consumers through financially viable mini-grids  the Global Lighting and Energy Access Partnership (Global LEAP) initiative of the Clean Energy Ministerial and the U.S. Department of Energy teamed with the National Renewable Energy Laboratory (NREL) and Power Africa to develop a Quality Assurance Framework (QAF) for isolated mini-grids. The framework addresses both alternating current (AC) and direct current (DC) mini-grids  and is applicable to renewable  fossil-fuel  and hybrid systems.Apollo experience report: Reliability and quality assuranceNASA Technical Reports Server (NTRS)Sperber  K. P.1973-01-01The reliability of the Apollo spacecraft resulted from the application of proven reliability and quality techniques and from sound management  engineering  and manufacturing practices. Continual assessment of these techniques and practices was made during the program  and  when deficiencies were detected  adjustments were made and the deficiencies were effectively corrected. The most significant practices  deficiencies  adjustments  and experiences during the Apollo Program are described in this report. These experiences can be helpful in establishing an effective base on which to structure an efficient reliability and quality assurance effort for future space-flight programs.Underground Test Area Activity Quality Assurance Plan Nevada National Security Site  Nevada. Revision 1SciTech ConnectFarnham  Irene; Krenzien  SusanThis Quality Assurance Plan (QAP) provides the overall quality assurance (QA) requirements and general quality practices to be applied to the U.S. Department of Energy (DOE)  National Nuclear Security Administration Nevada Site Office (NNSA/NSO) Underground Test Area (UGTA) activities. The requirements in this QAP are consistent with DOE Order 414.1C  Quality Assurance (DOE  2005); U.S. Environmental Protection Agency (EPA) Guidance for Quality Assurance Project Plans for Modeling (EPA  2002); and EPA Guidance on the Development  Evaluation  and Application of Environmental Models (EPA  2009). NNSA/NSO  or designee  must review this QAP every two years. Changes that do not affect the overallmoreÂ Â» scope or requirements will not require an immediate QAP revision but will be incorporated into the next revision cycle after identification. Section 1.0 describes UGTA objectives  participant responsibilities  and administrative and management quality requirements (i.e.  training  records  procurement). Section 1.0 also details data management and computer software requirements. Section 2.0 establishes the requirements to ensure newly collected data are valid  existing data uses are appropriate  and environmental-modeling methods are reliable. Section 3.0 provides feedback loops through assessments and reports to management. Section 4.0 provides the framework for corrective actions. Section 5.0 provides references for this document.Â«Â lessUnderground Test Area Activity Quality Assurance Plan Nevada National Security Site  Nevada. Revision 2SciTech ConnectKrenzien  Susan; Farnham  IreneThis Quality Assurance Plan (QAP) provides the overall quality assurance (QA) requirements and general quality practices to be applied to the U.S. Department of Energy (DOE)  National Nuclear Security Administration Nevada Field Office (NNSA/NFO) Underground Test Area (UGTA) activities. The requirements in this QAP are consistent with DOE Order 414.1D  Change 1  Quality Assurance (DOE  2013a); U.S. Environmental Protection Agency (EPA) Guidance for Quality Assurance Project Plans for Modeling (EPA  2002); and EPA Guidance on the Development  Evaluation  and Application of Environmental Models (EPA  2009). If a participantâ€™s requirement document differs from this QAP  the stricter requirement will take precedence.moreÂ Â» NNSA/NFO  or designee  must review this QAP every two years. Changes that do not affect the overall scope or requirements will not require an immediate QAP revision but will be incorporated into the next revision cycle after identification. Section 1.0 describes UGTA objectives  participant responsibilities  and administrative and management quality requirements (i.e.  training  records  procurement). Section 1.0 also details data management and computer software requirements. Section 2.0 establishes the requirements to ensure newly collected data are valid  existing data uses are appropriate  and environmental-modeling methods are reliable. Section 3.0 provides feedback loops through assessments and reports to management. Section 4.0 provides the framework for corrective actions. Section 5.0 provides references for this document.Â«Â lessItalian quality assurance in mental health.PubMedRossi  Giovanni; Agnetti  Germana; Bosio  Roberto; De Luca  Pasquale; Erlicher  Arcadio; Morganti  Carla; Neri  Giovanni; Re  Edoardo; Semisa  Domenico; Fioritti  Angelo2014-06-01Since the radical changes in Italian mental health law in the 1970s  quality assurance models have gained consensus as the most suitable service assessment tool. In the 1990s  the whole Italian National Health System changed into a corporate model  and an accreditation system was implemented.The Italian Association for Quality and Accreditation in Mental Health (Associazione Italiana per la QualitÃ  e l'Accreditamento in Salute Mentale [QUASM]) was founded in 1984  and since then  it offers consultation and support for Mental Health Departments and Regional Governments to help them to develop psychiatric programs  self-evaluation  educational programs  and professional peer-model accreditation. The QUASM accreditation manual has now gone through several revisions  the last in 2008. Until 2008  QUASM was successful in promoting quality and facilitating both institutional and professional accreditation. However  radical changes triggered by financial crisis have jeopardized quality assurance implementation. Nowadays  the challenge for QUASM is to maintain quality and accreditation geared to excellence against prevailing leveling trends.Quality assurance and training procedures for computer-aided detection and diagnosis systems in clinical usea)PubMed CentralHuo  Zhimin; Summers  Ronald M.; Paquerault  Sophie; Lo  Joseph; Hoffmeister  Jeffrey; Armato  Samuel G.; Freedman  Matthew T.; Lin  Jesse; Ben Lo  Shih-Chung; Petrick  Nicholas; Sahiner  Berkman; Fryd  David; Yoshida  Hiroyuki; Chan  Heang-Ping2013-01-01Computer-aided detection/diagnosis (CAD) is increasingly used for decision support by clinicians for detection and interpretation of diseases. However  there are no quality assurance (QA) requirements for CAD in clinical use at present. QA of CAD is important so that end users can be made aware of changes in CAD performance both due to intentional or unintentional causes. In addition  end-user training is critical to prevent improper use of CAD  which could potentially result in lower overall clinical performance. Research on QA of CAD and user training are limited to date. The purpose of this paper is to bring attention to these issues  inform the readers of the opinions of the members of the American Association of Physicists in Medicine (AAPM) CAD subcommittee  and thus stimulate further discussion in the CAD community on these topics. The recommendations in this paper are intended to be work items for AAPM task groups that will be formed to address QA and user training issues on CAD in the future. The work items may serve as a framework for the discussion and eventual design of detailed QA and training procedures for physicists and users of CAD. Some of the recommendations are considered by the subcommittee to be reasonably easy and practical and can be implemented immediately by the end users; others are considered to be â€œbest practiceâ€ approaches  which may require significant effort  additional tools  and proper training to implement. The eventual standardization of the requirements of QA procedures for CAD will have to be determined through consensus from members of the CAD community  and user training may require support of professional societies. It is expected that high-quality CAD and proper use of CAD could allow these systems to achieve their true potential  thus benefiting both the patients and the clinicians  and may bring about more widespread clinical use of CAD for many other diseases and applications. It is hoped that the awareness of theA Strategy to Establish a Quality Assurance/Quality Control Plan for the Application of Biosensors for the Detection of E. coli in Water.PubMedHesari  Nikou; KÄ±ratlÄ± YÄ±lmazÃ§oban  Nursel; Elzein  Mohamad; Alum  Absar; Abbaszadegan  Morteza2017-01-03Rapid bacterial detection using biosensors is a novel approach for microbiological testing applications. Validation of such methods is an obstacle in the adoption of new bio-sensing technologies for water testing. Therefore  establishing a quality assurance and quality control (QA/QC) plan is essential to demonstrate accuracy and reliability of the biosensor method for the detection of E. coli in drinking water samples. In this study  different reagents and assay conditions including temperatures  holding time  E. coli strains and concentrations  dissolving agents  salinity and pH effects  quality of substrates of various suppliers of 4-methylumbelliferyl glucuronide (MUG)  and environmental water samples were included in the QA/QC plan and used in the assay optimization and documentation. Furthermore  the procedural QA/QC for the monitoring of drinking water samples was established to validate the performance of the biosensor platform for the detection of E. coli using a culture-based standard technique. Implementing the developed QA/QC plan  the same level of precision and accuracy was achieved using both the standard and the biosensor methods. The established procedural QA/QC for the biosensor will provide a reliable tool for a near real-time monitoring of E. coli in drinking water samples to both industry and regulatory authorities.A Strategy to Establish a Quality Assurance/Quality Control Plan for the Application of Biosensors for the Detection of E. coli in WaterPubMed CentralHesari  Nikou; KÄ±ratlÄ± YÄ±lmazÃ§oban  Nursel; Elzein  Mohamad; Alum  Absar; Abbaszadegan  Morteza2017-01-01Rapid bacterial detection using biosensors is a novel approach for microbiological testing applications. Validation of such methods is an obstacle in the adoption of new bio-sensing technologies for water testing. Therefore  establishing a quality assurance and quality control (QA/QC) plan is essential to demonstrate accuracy and reliability of the biosensor method for the detection of E. coli in drinking water samples. In this study  different reagents and assay conditions including temperatures  holding time  E. coli strains and concentrations  dissolving agents  salinity and pH effects  quality of substrates of various suppliers of 4-methylumbelliferyl glucuronide (MUG)  and environmental water samples were included in the QA/QC plan and used in the assay optimization and documentation. Furthermore  the procedural QA/QC for the monitoring of drinking water samples was established to validate the performance of the biosensor platform for the detection of E. coli using a culture-based standard technique. Implementing the developed QA/QC plan  the same level of precision and accuracy was achieved using both the standard and the biosensor methods. The established procedural QA/QC for the biosensor will provide a reliable tool for a near real-time monitoring of E. coli in drinking water samples to both industry and regulatory authorities. PMID:28054956Summary of development and recommendations for a quality assurance program for the procurement and manufacture of urban mass transit operating equipment and systemsNASA Technical Reports Server (NTRS)Witkin  S. A.1976-01-01A viable quality program for the urban mass transit industry  and a management approach to ensure compliance with the program are outlined. Included are: (1) a set of guidelines for quality assurance to be imposed on transit authorities  and a management approach to ensure compliance with them; (2) a management approach to be used by the transit authorities (properties) for assuring compliance with the QA guidelines; and (3) quality assurance guidelines to be imposed by properties and umta for procurement of hardware and systems.TH-A-BRC-02: AAPM TG-178 Gamma Stereotactic Radiosurgery Dosimetry and Quality AssuranceSciTech ConnectGoetsch  S.AAPM TG-135U1 QA for Robotic Radiosurgery - Sonja Dieterich Since the publication of AAPM TG-135 in 2011  the technology of robotic radiosurgery has rapidly developed. AAPM TG-135U1 will provide recommendations on the clinical practice for using the IRIS collimator  fiducial-less real-time motion tracking  and Monte Carlo based treatment planning. In addition  it will summarize currently available literature about uncertainties. Learning Objectives: Understand the progression of technology since the first TG publication Learn which new QA procedures should be implemented for new technologies Be familiar with updates to clinical practice guidelines AAPM TG-178 Gamma Stereotactic Radiosurgery Dosimetry and Quality Assurance -moreÂ Â» Steven Goetsch Purpose: AAPM Task Group 178 Gamma Stereotactic Radiosurgery Dosimetry and Quality Assurance was formed in August  2008. The Task Group has 12 medical physicists  two physicians and two consultants. Methods: A round robin dosimetry intercomparison of proposed ionization chambers  electrometer and dosimetry phantoms was conducted over a 15 month period in 2011 and 2012 (Med Phys 42  11  Nov  2015). The data obtained at 9 institutions (with ten different Elekta Gamma Knife units) was analyzed by the lead author using several protocols. Results: The most consistent results were obtained using the Elekta ABS 16cm diameter phantom  with the TG-51 protocol modified as recommended by Alfonso et al (Med Phys 35  11  Nov 2008). A key white paper (Med Phys  in press) sponsored by Elekta Corporation  was used to obtain correction factors for the ionization chambers and phantoms used in this intercomparison. Consistent results were obtained for both Elekta Gamma Knife Model 4C and Gamma Knife Perfexion units as measured with each of two miniature ionization chambers. Conclusion: The full report gives clinical history and background of gamma stereotactic radiosurgery  clinical examples and history  quality assurance recommendations andBritish standard (BS) 5750--quality assurance?PubMedPratt  D J1995-04-01BS5750 is the British Standard on ""Quality Systems"". Its equivalent in European Standards is EN29000 and in the International Standards Organisation ISO9000. This paper points out that these standards lay down formalised procedures and require documentation but do not ipso facto lead to quality assurance. The author points to the Japanese post-war industrial success as being an example of Total Quality Management within the framework provided by the philosophy of Dr. W. Edwards Deming (1988 and 1993). This philosophy on the management of ""systems"" to provide high quality products and services is briefly outlined. The author argues that improvement in prosthetic and orthotic services will not be reached through implementation of BS5750 but rather through radical rethinking and the adoption and application of the Deming philosophy.[Quality assurance and quality management in intensive care].PubMedNotz  K; Dubb  R; Kaltwasser  A; Hermes  C; Pfeffer  S2015-11-01Treatment success in hospitals  particularly in intensive care units  is directly tied to quality of structure  process  and outcomes. Technological and medical advancements lead to ever more complex treatment situations with highly specialized tasks in intensive care nursing. Quality criteria that can be used to describe and correctly measure those highly complex multiprofessional situations have only been recently developed and put into practice.In this article  it will be shown how quality in multiprofessional teams can be definded and assessed in daily clinical practice. Core aspects are the choice of a nursing theory  quality assurance measures  and quality management. One possible option of quality assurance is the use of standard operating procedures (SOPs). Quality can ultimately only be achieved if professional groups think beyond their boundaries  minimize errors  and establish and live out instructions and SOPs.INTRODUCING CHANGES TO QUALITY SYSTEMS IN LARGE  ESTABLISHED ORGANIZATIONSEPA Science InventoryTo achieve the agency's mission of having defensible and reliable scientific data with which to make informed decisions  the EPA Quality Assurance (QA) community must continue its successful efforts in increasing support for QA activities through personal communication and carefu...Analysis of the sources of uncertainty for EDR2 filmâ€based IMRT quality assurancePubMed CentralShi  Chengyu; Papanikolaou  Nikos; Yan  Yulong; Weng  Xuejun; Jiang  gyu2006-01-01In our institution  patientâ€specific quality assurance (QA) for intensityâ€modulated radiation therapy (IMRT) is usually performed by measuring the dose to a point using an ion chamber and by measuring the dose to a plane using film. In order to perform absolute dose comparison measurements using film  an accurate calibration curve should be used. In this paper  we investigate the film response curve uncertainty factors  including film batch differences  film processor temperature effect  film digitization  and treatment unit. In addition  we reviewed 50 patientâ€specific IMRT QA procedures performed in our institution in order to quantify the sources of error in filmâ€based dosimetry. Our study showed that the EDR2 film dosimetry can be done with less than 3% uncertainty. The EDR2 film response was not affected by the choice of treatment unit provided the nominal energy was the same. This investigation of the different sources of uncertainties in the film calibration procedure can provide a better understanding of the filmâ€based dosimetry and can improve quality control for IMRT QA. PACS numbers: 87.86.Cd  87.53.Xd  87.57.Nk PMID:17533329Hanford meteorological station computer codes: Volume 9  The quality assurance computer codesSciTech ConnectBurk  K.W.; Andrews  G.L.1989-02-01The Hanford Meteorological Station (HMS) was established in 1944 on the Hanford Site to collect and archive meteorological data and provide weather forecasts and related services for Hanford Site approximately 1/2 mile east of the 200 West Area and is operated by PNL for the US Department of Energy. Meteorological data are collected from various sensors and equipment located on and off the Hanford Site. These data are stored in data bases on the Digital Equipment Corporation (DEC) VAX 11/750 at the HMS (hereafter referred to as the HMS computer). Files from those data bases are routinely transferred to themoreÂ Â» Emergency Management System (EMS) computer at the Unified Dose Assessment Center (UDAC). To ensure the quality and integrity of the HMS data  a set of Quality Assurance (QA) computer codes has been written. The codes will be routinely used by the HMS system manager or the data base custodian. The QA codes provide detailed output files that will be used in correcting erroneous data. The following sections in this volume describe the implementation and operation of QA computer codes. The appendices contain detailed descriptions  flow charts  and source code listings of each computer code. 2 refs.Â«Â less10 CFR 72.142 - Quality assurance organization.Code of Federal Regulations  2011 CFR2011-01-01... 10 Energy 2 2011-01-01 2011-01-01 false Quality assurance organization. 72.142 Section 72.142... Assurance Â§ 72.142 Quality assurance organization. (a) The licensee  applicant for a license  certificate... writing the authority and duties of persons and organizations performing activities affecting the...10 CFR 72.142 - Quality assurance organization.Code of Federal Regulations  2010 CFR2010-01-01... 10 Energy 2 2010-01-01 2010-01-01 false Quality assurance organization. 72.142 Section 72.142... Assurance Â§ 72.142 Quality assurance organization. (a) The licensee  applicant for a license  certificate... writing the authority and duties of persons and organizations performing activities affecting the...[Quality assurance: concepts  actions and reflexions].PubMedRuelas Barajas  E1994-01-01Importance that the topic of quality of medical care has acquired in recent years  a number of concepts have been utilized to mean many strategies to improve the quality of care. This situation has frequently created confusion between terms such as: quality assessment  quality assurance  total quality management  quality guarantee  etc. The purpose of this paper is to propose a conceptual framework that allows not only to clarify the concepts but also the actions towards the improvement of the quality of care. Therefore  a multidimensional matrix is also proposed in order to classify the multiple actions referred about in the literature and to organize them. The conclusions are: 1) The term ""Quality guarantee""  at least in spanish  is absolutely pertinent when referred to the quality of medical care; 2) This concept becomes a solid starting point to implement concret actions by integrating different concepts and avoiding confusions; 3) The multidimensional matrix allows to systematize multiple actions; 4) Since there was not a similar conceptual framework it is expected that this paper allows to close the gap between thinking and doing on behalf of every body.48 CFR 846.408 - Single-agency assignments of Government contract quality assurance.Code of Federal Regulations  2010 CFR2010-10-01... of Government contract quality assurance. 846.408 Section 846.408 Federal Acquisition Regulations System DEPARTMENT OF VETERANS AFFAIRS CONTRACT MANAGEMENT QUALITY ASSURANCE Government Contract Quality Assurance 846.408 Single-agency assignments of Government contract quality assurance. ...[Quality assurance and total quality management in residential home care].PubMedNÃ¼bling  R; Schrempp  C; Kress  G; LÃ¶schmann  C; Neubart  R; Kuhlmey  A2004-02-01Quality  quality assurance  and quality management have been important topics in residential care homes for several years. However  only as a result of reform processes in the German legislation (long-term care insurance  care quality assurance) is a systematic discussion taking place. Furthermore  initiatives and holistic model projects  which deal with the assessment and improvement of service quality  were developed in the field of care for the elderly. The present article gives a critical overview of essential developments. Different comprehensive approaches such as the implementation of quality management systems  nationwide expert-based initiatives  and developments towards professionalizing care are discussed. Empirically based approaches  especially those emphasizing the assessment of outcome quality  are focused on in this work. Overall  the authors conclude that in the past few years comprehensive efforts have been made to improve the quality of care. However  the current situation still requires much work to establish a nationwide launch and implementation of evidence-based quality assurance and quality management.GEOSPATIAL QAEPA Science InventoryGeospatial Science is increasingly becoming an important tool in making Agency decisions. Quality Control and Quality Assurance are required to be integrated during the planning  implementation and assessment of geospatial databases  processes and products. In order to ensure Age...Current external beam radiation therapy quality assurance guidance: does it meet the challenges of emerging image-guided technologies?PubMedPalta  Jatinder R; Liu  Chihray; Li  Jonathan G2008-01-01The traditional prescriptive quality assurance (QA) programs that attempt to ensure the safety and reliability of traditional external beam radiation therapy are limited in their applicability to such advanced radiation therapy techniques as three-dimensional conformal radiation therapy  intensity-modulated radiation therapy  inverse treatment planning  stereotactic radiosurgery/radiotherapy  and image-guided radiation therapy. The conventional QA paradigm  illustrated by the American Association of Physicists in Medicine Radiation Therapy Committee Task Group 40 (TG-40) report  consists of developing a consensus menu of tests and device performance specifications from a generic process model that is assumed to apply to all clinical applications of the device. The complexity  variation in practice patterns  and level of automation of high-technology radiotherapy renders this ""one-size-fits-all"" prescriptive QA paradigm ineffective or cost prohibitive if the high-probability error pathways of all possible clinical applications of the device are to be covered. The current approaches to developing comprehensive prescriptive QA protocols can be prohibitively time consuming and cost ineffective and may sometimes fail to adequately safeguard patients. It therefore is important to evaluate more formal error mitigation and process analysis methods of industrial engineering to more optimally focus available QA resources on process components that have a significant likelihood of compromising patient safety or treatment outcomes.A noble technique a using force-sensing resistor for immobilization-device quality assurance: A feasibility studyNASA Astrophysics Data System (ADS)Cho  Min-Seok; Kim  Tae-Ho; Kang  Seong-Hee; Kim  Dong-Su; Kim  Kyeong-Hyeon; Shin  Dong-Seok; Noh  Yu-Yun; Koo  Hyun-Jae; Cheon  Geum Seong; Suh  Tae Suk; Kim  Siyong2016-03-01Many studies have reported that a patient can move even when an immobilization device is used. Researchers have developed an immobilization-device quality-assurance (QA) system that evaluates the validity of immobilization devices. The QA system consists of force-sensing-resistor (FSR) sensor units  an electric circuit  a signal conditioning device  and a control personal computer (PC) with in-house software. The QA system is designed to measure the force between an immobilization device and a patient's skin by using the FSR sensor unit. This preliminary study aimed to evaluate the feasibility of using the QA system in radiation-exposure situations. When the FSR sensor unit was irradiated with a computed tomography (CT) beam and a treatment beam from a linear accelerator (LINAC)  the stability of the output signal  the image artifact on the CT image  and changing the variation on the patient's dose were tested. The results of this study demonstrate that this system is promising in that it performed within the error range (signal variation on CT beam < 0.30 kPa  root-mean-square error (RMSE) of the two CT images according to presence or absence of the FSR sensor unit < 15 HU  signal variation on the treatment beam < 0.15 kPa  and dose difference between the presence and the absence of the FSR sensor unit < 0.02%). Based on the obtained results  we will volunteer tests to investigate the clinical feasibility of the QA system.Concrete Quality Assurance Using Accelerated Strength Testing.DTIC Science & Technology1984-03-01n   Office  Chief of Engineers  U. S. Army WAVA Washington. D. C. 20314 -. ABORATORY Jnde CWIS Work Unit 31138 84 07 10 075 â€¢ ! Destoy hisreprt when...RECIPIENT’S CATALOG NUMBER 11iscellaneous Paper SL-84-4 9 i0LV"". L- 4. TITLE (awd Subtitle) 5 . TYPE OF REPORT & PERIOD COVERED CONCRETE QUALITY ASSURANCE USING...Laboratory P_ 0. Rox 63l Vicksburg  Miss- 39g CWIS Work Unit No. 31138 I1. CONTROLLING OFFICE NAME AND ADDRESS 12. REPORT DATE Office  Chief ofSpinal cord testing: auditing for quality assurance.PubMedMarr  J A; Reid  B1991-04-01A quality assurance audit of spinal cord testing as documented by staff nurses was carried out. Twenty-five patient records were examined for accuracy of documented testing and compared to assessments performed by three investigators. A pilot study established interrater reliability of a tool that was designed especially for this study. Results indicated staff nurses failed to meet pre-established 100% standard in all categories of testing when compared with investigator's findings. Possible reasons for this disparity are discussed as well as indications for modifications in the spinal testing record  teaching program and preset standards.Statistical process control analysis for patient-specific IMRT and VMAT QA.PubMedSanghangthum  Taweap; Suriyapee  Sivalee; Srisatit  Somyot; Pawlicki  Todd2013-05-01This work applied statistical process control to establish the control limits of the % gamma pass of patient-specific intensity modulated radiotherapy (IMRT) and volumetric modulated arc therapy (VMAT) quality assurance (QA)  and to evaluate the efficiency of the QA process by using the process capability index (Cpml). A total of 278 IMRT QA plans in nasopharyngeal carcinoma were measured with MapCHECK  while 159 VMAT QA plans were undertaken with ArcCHECK. Six megavolts with nine fields were used for the IMRT plan and 2.5 arcs were used to generate the VMAT plans. The gamma (3%/3 mm) criteria were used to evaluate the QA plans. The % gamma passes were plotted on a control chart. The first 50 data points were employed to calculate the control limits. The Cpml was calculated to evaluate the capability of the IMRT/VMAT QA process. The results showed higher systematic errors in IMRT QA than VMAT QA due to the more complicated setup used in IMRT QA. The variation of random errors was also larger in IMRT QA than VMAT QA because the VMAT plan has more continuity of dose distribution. The average % gamma pass was 93.7% Â± 3.7% for IMRT and 96.7% Â± 2.2% for VMAT. The Cpml value of IMRT QA was 1.60 and VMAT QA was 1.99  which implied that the VMAT QA process was more accurate than the IMRT QA process. Our lower control limit for % gamma pass of IMRT is 85.0%  while the limit for VMAT is 90%. Both the IMRT and VMAT QA processes are good quality because Cpml values are higher than 1.0.Quality assurance: Importance of systems and standard operating proceduresPubMed CentralManghani  Kishu2011-01-01It is mandatory for sponsors of clinical trials and contract research organizations alike to establish  manage and monitor their quality control and quality assurance systems and their integral standard operating procedures and other quality documents to provide high-quality products and services to fully satisfy customer needs and expectations. Quality control and quality assurance systems together constitute the key quality systems. Quality control and quality assurance are parts of quality management. Quality control is focused on fulfilling quality requirements  whereas quality assurance is focused on providing confidence that quality requirements are fulfilled. The quality systems must be commensurate with the Company business objectives and business model. Top management commitment and its active involvement are critical in order to ensure at all times the adequacy  suitability  effectiveness and efficiency of the quality systems. Effective and efficient quality systems can promote timely registration of drugs by eliminating waste and the need for rework with overall financial and social benefits to the Company. PMID:21584180Quality assurance: Importance of systems and standard operating procedures.PubMedManghani  Kishu2011-01-01It is mandatory for sponsors of clinical trials and contract research organizations alike to establish  manage and monitor their quality control and quality assurance systems and their integral standard operating procedures and other quality documents to provide high-quality products and services to fully satisfy customer needs and expectations. Quality control and quality assurance systems together constitute the key quality systems. Quality control and quality assurance are parts of quality management. Quality control is focused on fulfilling quality requirements  whereas quality assurance is focused on providing confidence that quality requirements are fulfilled. The quality systems must be commensurate with the Company business objectives and business model. Top management commitment and its active involvement are critical in order to ensure at all times the adequacy  suitability  effectiveness and efficiency of the quality systems. Effective and efficient quality systems can promote timely registration of drugs by eliminating waste and the need for rework with overall financial and social benefits to the Company.Quality assurance and quality control for thermal/optical analysis of aerosol samples for organic and elemental carbon.PubMedChow  Judith C; Watson  John G; Robles  Jerome; Wang  Xiaoliang; Chen  L-W Antony; Trimble  Dana L; Kohl  Steven D; Tropp  Richard J; Fung  Kochy K2011-12-01Accurate  precise  and valid organic and elemental carbon (OC and EC  respectively) measurements require more effort than the routine analysis of ambient aerosol and source samples. This paper documents the quality assurance (QA) and quality control (QC) procedures that should be implemented to ensure consistency of OC and EC measurements. Prior to field sampling  the appropriate filter substrate must be selected and tested for sampling effectiveness. Unexposed filters are pre-fired to remove contaminants and acceptance tested. After sampling  filters must be stored in the laboratory in clean  labeled containers under refrigeration (<4 Â°C) to minimize loss of semi-volatile OC. QA activities include participation in laboratory accreditation programs  external system audits  and interlaboratory comparisons. For thermal/optical carbon analyses  periodic QC tests include calibration of the flame ionization detector with different types of carbon standards  thermogram inspection  replicate analyses  quantification of trace oxygen concentrations (<100 ppmv) in the helium atmosphere  and calibration of the sample temperature sensor. These established QA/QC procedures are applicable to aerosol sampling and analysis for carbon and other chemical components.Physical and biological pretreatment quality assurance of the head and neck cancer plan with the volumetric modulated arc therapyNASA Astrophysics Data System (ADS)Park  So-Hyun; Lee  Dong-Soo; Lee  Yun-Hee; Lee  Seu-Ran; Kim  Min-Ju; Suh  Tae-Suk2015-09-01The aim of this work is to demonstrate both the physical and the biological quality assurance (QA) aspects as pretreatment QA of the head and neck (H&N) cancer plan for the volumetric modulated arc therapy (VMAT). Ten H&N plans were studied. The COMPASSÂ® dosimetry analysis system and the tumor control probability (TCP) and the normal tissue complication probability (NTCP) calculation free program were used as the respective measurement and calculation tools. The reliability of these tools was verified by a benchmark study in accordance with the TG-166 report. For the physical component of QA  the gamma passing rates and the false negative cases between the calculated and the measured data were evaluated. The biological component of QA was performed based on the equivalent uniform dose (EUD)  TCP and NTCP values. The evaluation was performed for the planning target volumes (PTVs) and the organs at risks (OARs)  including the eyes  the lens  the parotid glands  the esophagus  the spinal cord  and the brainstem. All cases had gamma passing rates above 95% at an acceptance tolerance level with the 3%/3 mm criteria. In addition  the false negative instances were presented for the PTVs and OARs. The gamma passing rates exhibited a weak correlation with false negative cases. For the biological QA  the physical dose errors affect the EUD and the TCP for the PTVs  but no linear correlation existed between them. The EUD and NTCP for the OARs were shown the random differences that could not be attributed to the dose errors from the physical QA. The differences in the EUD and NTCP between the calculated and the measured results were mainly demonstrated for the parotid glands. This study describes the importance and the necessity of improved QA to accompany both the physical and the biological aspects for accurate radiation treatment.Utilizing a structural meta-ontology for family-based quality assurance of the BioPortal ontologies.PubMedOchs  Christopher; He  Zhe; Zheng  Ling; Geller  James; Perl  Yehoshua; Hripcsak  George; Musen  Mark A2016-06-01An Abstraction Network is a compact summary of an ontology's structure and content. In previous research  we showed that Abstraction Networks support quality assurance (QA) of biomedical ontologies. The development of an Abstraction Network and its associated QA methodologies  however  is a labor-intensive process that previously was applicable only to one ontology at a time. To improve the efficiency of the Abstraction-Network-based QA methodology  we introduced a QA framework that uses uniform Abstraction Network derivation techniques and QA methodologies that are applicable to whole families of structurally similar ontologies. For the family-based framework to be successful  it is necessary to develop a method for classifying ontologies into structurally similar families. We now describe a structural meta-ontology that classifies ontologies according to certain structural features that are commonly used in the modeling of ontologies (e.g.  object properties) and that are important for Abstraction Network derivation. Each class of the structural meta-ontology represents a family of ontologies with identical structural features  indicating which types of Abstraction Networks and QA methodologies are potentially applicable to all of the ontologies in the family. We derive a collection of 81 families  corresponding to classes of the structural meta-ontology  that enable a flexible  streamlined family-based QA methodology  offering multiple choices for classifying an ontology. The structure of 373 ontologies from the NCBO BioPortal is analyzed and each ontology is classified into multiple families modeled by the structural meta-ontology. Copyright Â© 2016 Elsevier Inc. All rights reserved.The role of food quality assurance and product certification systems on marketing aspectsNASA Astrophysics Data System (ADS)PetroviÄ‡  Z.; MiliÄ‡eviÄ‡  D.; NastasijeviÄ‡  I.; ÄorÄ‘eviÄ‡  V.; TrboviÄ‡  D.; Velebit  B.2017-09-01The level of quality that a product offers to consumers is a fundamental aspect of competition in many markets. Consumersâ€™ confidence in the safety and quality of foods they buy and consume is a significant support to the economic development of production organizations of this type  and therefore the overall economic development. Consumer concerns about food safety as well as the globalization of food production have also led to the existence of a global internationally linked food production and distribution system. The necessity demanded by the consumer population to provide safe food with consistent quality at an attractive price imposes a choice of an appropriate quality assurance model in accordance with the specific properties of the product and the production processes. Modern trends  especially for the last ten years in quality assurance within specific production  such as the food industry  have marked the trend of hyperproduction and a number of production and safety standards  as well as a change of approach in the certification process of organizations according to one or more standards. This can be an additional source of costs for organizations  and can burden the food business operator`s budget in order to ensure their consistent application and maintenance. Quality assurance (QA) standards are considered to be a proven mechanism for delivering quality of product.The role of field auditing in environmental quality assurance management.PubMedClaycomb  D R2000-01-01Environmental data quality improvement continues to focus on analytical laboratoryperformance with little  if any  attention given to improving the performance of field consultants responsible for sample collection. Many environmental professionals often assume that the primary opportunity for data error lies within the activities conducted by the laboratory. Experience in the evaluation of environmental data and project-wide quality assurance programs indicates that an often-ignored factor affecting environmental data quality is the manner in which a sample is acquired and handled in the field. If a sample is not properly collected  preserved  stored  and transported in the field  even the best laboratory practices and analytical methods cannot deliver accurate and reliable data (i.e.  bad data in equals bad data out). Poor quality environmental data may result in inappropriate decisions regarding site characterization and remedial action. Field auditing is becoming an often-employed technique for examining the performance of the environmental sampling field team and how their performance may affect data quality. The field audits typically focus on: (1) verifying that field consultants adhere to project control documents (e.g.  Work Plans and Standard Operating Procedures [SOPs]) during field operations; (2) providing third-party independent assurance that field procedures  quality assurance/ quality control (QA/QC)protocol  and field documentation are sufficient to produce data of satisfactory quality; (3) providing a defense in the event that field procedures are called into question; and (4) identifying ways to reduce sampling costs. Field audits are typically most effective when performed on a surprise basis; that is  the sampling contractor may be aware that a field audit will be conducted during some phase of sampling activities but is not informed of the specific day(s) that the audit will be conducted. The audit also should be conducted early on in theTechnology Transfer Program (TTP). Quality Assurance System. Volume 2. AppendicesDTIC Science & Technology1980-03-03LSCo Report No. - 2X23-5.1-4-I TECHNOLOGY TRANSFER PROGRAM (TTP) FINAL REPORT QUALITY ASSURANCE SYSTEM Appendix A Accuracy Control System QUALITY...4-1 TECHNOLOGY TRANSFER PROGRAM (TTP) FINAL REPORT QUALITY ASSURANCE SYSTEM Appendix A Accuracy Control System QUALITY ASSURANCE VOLUME 2 APPENDICES...prepared by: Livingston Shipbuilding Company Orange  Texas March 3  1980 APPENDIX A ACCURACY CONTROL SYSTEM . IIII MARINE TECHNOLOGY. INC. HP-12148 CFR 2146.270 - FEGLI Program quality assurance requirements.Code of Federal Regulations  2013 CFR2013-10-01... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CONTRACT MANAGEMENT QUALITY ASSURANCE Contract Quality Requirements 2146.270 FEGLI Program quality assurance requirements. (a) The... 48 Federal Acquisition Regulations System 6 2013-10-01 2013-10-01 false FEGLI Program quality...48 CFR 2146.270 - FEGLI Program quality assurance requirements.Code of Federal Regulations  2014 CFR2014-10-01... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CONTRACT MANAGEMENT QUALITY ASSURANCE Contract Quality Requirements 2146.270 FEGLI Program quality assurance requirements. (a) The... 48 Federal Acquisition Regulations System 6 2014-10-01 2014-10-01 false FEGLI Program quality...48 CFR 2146.270 - FEGLI Program quality assurance requirements.Code of Federal Regulations  2012 CFR2012-10-01... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CONTRACT MANAGEMENT QUALITY ASSURANCE Contract Quality Requirements 2146.270 FEGLI Program quality assurance requirements. (a) The... 48 Federal Acquisition Regulations System 6 2012-10-01 2012-10-01 false FEGLI Program quality...48 CFR 2146.270 - FEGLI Program quality assurance requirements.Code of Federal Regulations  2011 CFR2011-10-01... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CONTRACT MANAGEMENT QUALITY ASSURANCE Contract Quality Requirements 2146.270 FEGLI Program quality assurance requirements. (a) The... 48 Federal Acquisition Regulations System 6 2011-10-01 2011-10-01 false FEGLI Program quality...48 CFR 2146.270 - FEGLI Program quality assurance requirements.Code of Federal Regulations  2010 CFR2010-10-01... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CONTRACT MANAGEMENT QUALITY ASSURANCE Contract Quality Requirements 2146.270 FEGLI Program quality assurance requirements. (a) The... 48 Federal Acquisition Regulations System 6 2010-10-01 2010-10-01 true FEGLI Program quality...Quality assurance in mammography: artifact analysis.PubMedHogge  J P; Palmer  C H; Muller  C C; Little  S T; Smith  D C; Fatouros  P P; de Paredes  E S1999-01-01Evaluation of mammograms for artifacts is essential for mammographic quality assurance. A variety of mammographic artifacts (i.e.  variations in mammographic density not caused by true attenuation differences) can occur and can create pseudolesions or mask true abnormalities. Many artifacts are readily identified  whereas others present a true diagnostic challenge. Factors that create artifacts may be related to the processor (eg  static  dirt or excessive developer buildup on the rollers  excessive roller pressure  damp film  scrapes and scratches  incomplete fixing  power failure  contaminated developer)  the technologist (eg  improper film handling and loading  improper use of the mammography unit and related equipment  positioning and darkroom errors)  the mammography unit (eg  failure of the collimation mirror to rotate  grid inhomogeneity  failure of the reciprocating grid to move  material in the tube housing  compression failure  improper alignment of the compression paddle with the Bucky tray  defective compression paddle)  or the patient (e.g.  motion  superimposed objects or substances [jewelry  body parts  clothing  hair  implanted medical devices  foreign bodies  substances on the skin]). Familiarity with the broad range of artifacts and the measures required to eliminate them is vital. Careful attention to darkroom cleanliness  care in film handling  regularly scheduled processor maintenance and chemical replenishment  daily quality assurance activities  and careful attention to detail during patient positioning and mammography can reduce or eliminate most mammographic artifacts.Quality assurance past and present in CanadaSciTech ConnectBush  R.S.Quality assurance in any clinical field must involve the three components of clinical care: (a) diagnosis and evaluation of patients; (b) medical decision making and treatment; and (c) outcome analysis. Nationally  there have been five annual reviews of outcome from all cancer centers following radiation therapy for cancer at various sites. These reviews are voluntary and organized through the Canadian Association of Radiologists. The objective is to determine if there are any major differences in outcome across the country  and if so  can such differences be related to the population treated or technique used. So far no major differences havemoreÂ Â» been noted. There is a National Tumour Reference Center funded by the National Cancer Institute of Canada (NCIC) to provide assistancein establishing diagnostic criteria in pathology. Ontario has been active through the staging and reporting  together with an evaluative program for this staging system. All other quality assurance programs take place at the level of local centers.Â«Â lessRadiographic Film Processing Quality Assurance: A Self-Teaching Workbook. Quality Assurance Series.ERIC Educational Resources Information CenterGoldman  Lee W.This workbook has been designed for use in conjunction with the manual  ""Photographic Quality Assurance in Diagnostic Radiology  Nuclear Medicine and Radiation Therapy."" Presented are several typical problems arising from the existence of variability and fluctuations in the automatic processing of radiographs  which unless corrected  canâ€¦Nuclear Technology. Course 31: Quality Assurance Practices. Module 31-7  Auditing for Quality Assurance.ERIC Educational Resources Information CenterPritchard  Jim; Espy  JohnThis seventh in a series of eight modules for a course titled Quality Assurance Practices describes the key features of an audit system and offers practice in carrying out tasks of the technicians. The module follows a typical format that includes the following sections: (1) introduction  (2) module prerequisites  (3) objectives  (4) notes toâ€¦Flight Dynamics Mission Support and Quality Assurance ProcessNASA Technical Reports Server (NTRS)Oh  InHwan1996-01-01This paper summarizes the method of the Computer Sciences Corporation Flight Dynamics Operation (FDO) quality assurance approach to support the National Aeronautics and Space Administration Goddard Space Flight Center Flight Dynamics Support Branch. Historically  a strong need has existed for developing systematic quality assurance using methods that account for the unique nature and environment of satellite Flight Dynamics mission support. Over the past few years FDO has developed and implemented proactive quality assurance processes applied to each of the six phases of the Flight Dynamics mission support life cycle: systems and operations concept  system requirements and specifications  software development support  operations planing and training  launch support  and on-orbit mission operations. Rather than performing quality assurance as a final step after work is completed  quality assurance has been built in as work progresses in the form of process assurance. Process assurance activities occur throughout the Flight Dynamics mission support life cycle. The FDO Product Assurance Office developed process checklists for prephase process reviews  mission team orientations  in-progress reviews  and end-of-phase audits. This paper will outline the evolving history of FDO quality assurance approaches  discuss the tailoring of Computer Science Corporations's process assurance cycle procedures  describe some of the quality assurance approaches that have been or are being developed  and present some of the successful results.Quantitative quality assurance in a multicenter HARDI clinical trial at 3T.PubMedZhou  Xiaopeng; Sakaie  Ken E; Debbins  Josef P; Kirsch  John E; Tatsuoka  Curtis; Fox  Robert J; Lowe  Mark J2017-01-01A phantom-based quality assurance (QA) protocol was developed for a multicenter clinical trial including high angular resolution diffusion imaging (HARDI). A total of 27 3T MR scanners from 2 major manufacturers  GE (Discovery and Signa scanners) and Siemens (Trio and Skyra scanners)  were included in this trial. With this protocol  agar phantoms doped to mimic relaxation properties of brain tissue are scanned on a monthly basis  and quantitative procedures are used to detect spiking and to evaluate eddy current and Nyquist ghosting artifacts. In this study  simulations were used to determine alarm thresholds for minimal acceptable signal-to-noise ratio (SNR). Our results showed that spiking artifact was the most frequently observed type of artifact. Overall  Trio scanners exhibited less eddy current distortion than GE scanners  which in turn showed less distortion than Skyra scanners. This difference was mainly caused by the different sequences used on these scanners. The SNR for phantom scans was closely correlated with the SNR from volunteers. Nearly all of the phantom measurements with artifact-free images were above the alarm threshold  suggesting that the scanners are stable longitudinally. Software upgrades and hardware replacement sometimes affected SNR substantially but sometimes did not. In light of these results  it is important to monitor longitudinal SNR with phantom QA to help interpret potential effects on in vivo measurements. Our phantom QA procedure for HARDI scans was successful in tracking scanner performance and detecting unwanted artifacts. Copyright Ã‚Â© 2016 Elsevier Inc. All rights reserved.Quality assurance in gerontological and geriatric training programs: the European case.PubMedPolitynska  Barbara; van Rijsselt  RenÃ© J T; Lewko  Jolanta; Philp  Ian; Figueiredo  Daniella; De Sousa  Lilliana2012-01-01Quality assurance (QA) in gerontological and geriatric education programs is regarded as essential to maintain standards  strengthen accountability  improve readability of qualifications  and facilitate professional mobility. In this article the authors present a summary of international developments in QA and elaborate four international trends  including the pros and cons of QA. Furthermore  the authors focus on accreditation and credit transfer opportunities in vocational and academic education programs for primary care practitioners  including nurses  home care workers  social workers  physiotherapists  and family doctors involved in the care of older people in nine European countries and highlight changes that have occurred over the last decade. Vocational education and professional training in elderly care at the basic and postgraduate specialization level remains extremely diversified  reflecting the lack of standardization for programs outside the higher education sector. The situation is ripe for the implementation of the European Qualifications Framework  which is intended to promote transparency  comparability and portability of qualifications at different levels and the introduction of a credit transfer system for vocational education to be established in 2012.Quality Assurance of Cancer Study Common Data Elements Using A Post-Coordination ApproachPubMed CentralJiang  Guoqian; Solbrig  Harold R.; Prudâ€™hommeaux  Eric; Tao  Cui; Weng  Chunhua; Chute  Christopher G.2015-01-01Domain-specific common data elements (CDEs) are emerging as an effective approach to standards-based clinical research data storage and retrieval. A limiting factor  however  is the lack of robust automated quality assurance (QA) tools for the CDEs in clinical study domains. The objectives of the present study are to prototype and evaluate a QA tool for the study of cancer CDEs using a post-coordination approach. The study starts by integrating the NCI caDSR CDEs and The Cancer Genome Atlas (TCGA) data dictionaries in a single Resource Description Framework (RDF) data store. We designed a compositional expression pattern based on the Data Element Concept model structure informed by ISO/IEC 11179  and developed a transformation tool that converts the pattern-based compositional expressions into the Web Ontology Language (OWL) syntax. Invoking reasoning and explanation services  we tested the system utilizing the CDEs extracted from two TCGA clinical cancer study domains. The system could automatically identify duplicate CDEs  and detect CDE modeling errors. In conclusion  compositional expressions not only enable reuse of existing ontology codes to define new domain concepts  but also provide an automated mechanism for QA of terminological annotations for CDEs. PMID:26958201Quantitative Quality Assurance in a Multicenter HARDI Clinical Trial at 3TPubMed CentralZhou  Xiaopeng; Sakaie  Ken E.; Debbins  Josef P.; Kirsch  John E.; Tatsuoka  Curtis; Fox  Robert J.; Lowe  Mark J.2016-01-01A phantom-based quality assurance (QA) protocol was developed for a multicenter clinical trial including high angular resolution diffusion imaging (HARDI). A total of 27 3T MR scanners from 2 major manufacturers  GE (Discovery and Signa scanners) and Siemens (Trio and Skyra scanners)  were included in this trial. With this protocol  agar phantoms doped to mimic relaxation properties of brain tissue are scanned on a monthly basis  and quantitative procedures are used to detect spiking and to evaluate eddy current and Nyquist ghosting artifacts. In this study  simulations were used to determine alarm thresholds for minimal acceptable signal-to-noise ratio (SNR). Our results showed that spiking artifact was the most frequently observed type of artifact. Overall  Trio scanners exhibited less eddy current distortion than GE scanners  which in turn showed less distortion than Skyra scanners. This difference was mainly caused by the different sequences used on these scanners. The SNR for phantom scans was closely correlated with the SNR from volunteers. Nearly all of the phantom measurements with artifact-free images were above the alarm threshold  suggesting that the scanners are stable longitudinally. Software upgrades and hardware replacement sometimes affected SNR substantially but sometimes did not. In light of these results  it is important to monitor longitudinal SNR with phantom QA to help interpret potential effects on in vivo measurements. Our phantom QA procedure for HARDI scans was successful in tracking scanner performance and detecting unwanted artifacts. PMID:27587227Commissioning and validation of COMPASS system for VMAT patient specific quality assuranceNASA Astrophysics Data System (ADS)Pimthong  J.; Kakanaporn  C.; Tuntipumiamorn  L.; Laojunun  P.; Iampongpaiboon  P.2016-03-01Pre-treatment patient specific quality assurance (QA) of advanced treatment techniques such as volumetric modulated arc therapy (VMAT) is one of important QA in radiotherapy. The fast and reliable dosimetric device is required. The objective of this study is to commission and validate the performance of COMPASS system for dose verification of VMAT technique. The COMPASS system is composed of an array of ionization detectors (MatriXX) mounted to the gantry using a custom holder and software for the analysis and visualization of QA results. We validated the COMPASS software for basic and advanced clinical application. For the basic clinical study  the simple open field in various field sizes were validated in homogeneous phantom. And the advanced clinical application  the fifteen prostate and fifteen nasopharyngeal cancers VMAT plans were chosen to study. The treatment plans were measured by the MatriXX. The doses and dose-volume histograms (DVHs) reconstructed from the fluence measurements were compared to the TPS calculated plans. And also  the doses and DVHs computed using collapsed cone convolution (CCC) Algorithm were compared with Eclipse TPS calculated plans using Analytical Anisotropic Algorithm (AAA) that according to dose specified in ICRU 83 for PTV.SU-E-J-199: A Software Tool for Quality Assurance of Online Replanning with MR-LinacSciTech ConnectChen  G; Ahunbay  E; Li  X2015-06-15Purpose: To develop a quality assurance software tool  ArtQA  capable of automatically checking radiation treatment plan parameters  verifying plan data transfer from treatment planning system (TPS) to record and verify (R&V) system  performing a secondary MU calculation considering the effect of magnetic field from MR-Linac  and verifying the delivery and plan consistency  for online replanning. Methods: ArtQA was developed by creating interfaces to TPS (e.g.  Monaco  Elekta)  R&V system (Mosaiq  Elekta)  and secondary MU calculation system. The tool obtains plan parameters from the TPS via direct file reading  and retrieves plan data both transferred from TPS and recorded during themoreÂ Â» actual delivery in the R&V system database via open database connectivity and structured query language. By comparing beam/plan datasets in different systems  ArtQA detects and outputs discrepancies between TPS  R&V system and secondary MU calculation system  and delivery. To consider the effect of 1.5T transverse magnetic field from MR-Linac in the secondary MU calculation  a method based on modified Clarkson integration algorithm was developed and tested for a series of clinical situations. Results: ArtQA is capable of automatically checking plan integrity and logic consistency  detecting plan data transfer errors  performing secondary MU calculations with or without a transverse magnetic field  and verifying treatment delivery. The tool is efficient and effective for pre- and post-treatment QA checks of all available treatment parameters that may be impractical with the commonly-used visual inspection. Conclusion: The software tool ArtQA can be used for quick and automatic pre- and post-treatment QA check  eliminating human error associated with visual inspection. While this tool is developed for online replanning to be used on MR-Linac  where the QA needs to be performed rapidly as the patient is lying on the table waiting for the treatment  ArtQA can be used as a generalUsefulness of a new online patient-specific quality assurance system for respiratory-gated radiotherapy.PubMedKurosawa  Tomoyuki; Tachibana  Hidenobu; Moriya  Shunsuke; Miyakawa  Shin; Nishio  Teiji; Sato  Masanori2017-11-01The accuracy of gated irradiation may decrease when treatment is performed with short ""beam-on"" times. Also  the dose is subject to variation between treatment sessions if the respiratory rate is irregular. We therefore evaluated the impact of the differences between gated and non-gated treatment on doses using a new online quality assurance (QA) system for respiratory-gated radiotherapy. We generated dose estimation models to associate dose and pulse information using a 0.6 cc Farmer chamber and our QA system. During gated irradiation with each of seven regular and irregular respiratory patterns  with the Farmer chamber readings as references  we evaluated our QA system's accuracy. We then used the QA system to assess the impact of respiratory patterns on dose distribution for three lung and three liver radiotherapy plans. Gated and non-gated plans were generated and compared. There was agreement within 1.7% between the ionization chamber and our system for several regular and irregular motion patterns. For dose distributions with measured errors  there were larger differences between gated and non-gated treatment for high-dose regions within the planned treatment volume (PTV). Compared with a non-gated plan  PTV D 95% for a gated plan decreased by -1.5% to -2.6%. Doses to organs at risk were similar with both plans. Our simple system estimated the radiation dose to the patient using only pulse information from the linac  even during irregular respiration. The quality of gated irradiation for each patient can be verified fraction by fraction. Copyright Â© 2017 Associazione Italiana di Fisica Medica. Published by Elsevier Ltd. All rights reserved.Development of a dynamic quality assurance testing protocol for multisite clinical trial DCE-CT accreditationSciTech ConnectDriscoll  B.; Keller  H.; Jaffray  D.2013-08-15Purpose: Credentialing can have an impact on whether or not a clinical trial produces useful quality data that is comparable between various institutions and scanners. With the recent increase of dynamic contrast enhanced-computed tomography (DCE-CT) usage as a companion biomarker in clinical trials  effective quality assurance  and control methods are required to ensure there is minimal deviation in the results between different scanners and protocols at various institutions. This paper attempts to address this problem by utilizing a dynamic flow imaging phantom to develop and evaluate a DCE-CT quality assurance (QA) protocol.Methods: A previously designed flow phantom  capable of producingmoreÂ Â» predictable and reproducible time concentration curves from contrast injection was fully validated and then utilized to design a DCE-CT QA protocol. The QA protocol involved a set of quantitative metrics including injected and total mass error  as well as goodness of fit comparison to the known truth concentration curves. An additional region of interest (ROI) sensitivity analysis was also developed to provide additional details on intrascanner variability and determine appropriate ROI sizes for quantitative analysis. Both the QA protocol and ROI sensitivity analysis were utilized to test variations in DCE-CT results using different imaging parameters (tube voltage and current) as well as alternate reconstruction methods and imaging techniques. The developed QA protocol and ROI sensitivity analysis was then applied at three institutions that were part of clinical trial involving DCE-CT and results were compared.Results: The inherent specificity of robustness of the phantom was determined through calculation of the total intraday variability and determined to be less than 2.2 Â± 1.1% (total calculated output contrast mass error) with a goodness of fit (R{sup 2}) of greater than 0.99 Â± 0.0035 (n= 10). The DCE-CT QA protocol was capable of detecting significant deviationsA quality assurance framework for the fully automated and objective evaluation of image quality in cone-beam computed tomography.PubMedSteiding  Christian; Kolditz  Daniel; Kalender  Willi A2014-03-01Thousands of cone-beam computed tomography (CBCT) scanners for vascular  maxillofacial  neurological  and body imaging are in clinical use today  but there is no consensus on uniform acceptance and constancy testing for image quality (IQ) and dose yet. The authors developed a quality assurance (QA) framework for fully automated and time-efficient performance evaluation of these systems. In addition  the dependence of objective Fourier-based IQ metrics on direction and position in 3D volumes was investigated for CBCT. The authors designed a dedicated QA phantom 10 cm in length consisting of five compartments  each with a diameter of 10 cm  and an optional extension ring 16 cm in diameter. A homogeneous section of water-equivalent material allows measuring CT value accuracy  image noise and uniformity  and multidimensional global and local noise power spectra (NPS). For the quantitative determination of 3D high-contrast spatial resolution  the modulation transfer function (MTF) of centrally and peripherally positioned aluminum spheres was computed from edge profiles. Additional in-plane and axial resolution patterns were used to assess resolution qualitatively. The characterization of low-contrast detectability as well as CT value linearity and artifact behavior was tested by utilizing sections with soft-tissue-equivalent and metallic inserts. For an automated QA procedure  a phantom detection algorithm was implemented. All tests used in the dedicated QA program were initially verified in simulation studies and experimentally confirmed on a clinical dental CBCT system. The automated IQ evaluation of volume data sets of the dental CBCT system was achieved with the proposed phantom requiring only one scan for the determination of all desired parameters. Typically  less than 5 min were needed for phantom set-up  scanning  and data analysis. Quantitative evaluation of system performance over time by comparison to previous examinations was also verified. The maximumAgar-Silica-Gel Heating Phantom May Be Suitable for Long-Term Quality Assurance of MRgHIFUNASA Astrophysics Data System (ADS)Partanen  Ari2009-04-01In MRgHIFU  the purpose of frequent quality assurance is to detect changes in system performance to prevent adverse effects during treatments. Due to high ultrasound intensities in MRgHIFU  it is essential to assure that the procedure is safe and efficacious and that image-based guidance of the treatment is reliable. We aimed to develop a guideline for MRgHIFU QA by acquiring MR temperature maps during ultrasonic heating of an agar-silica-gel phantom over a four month-period using three separate MRgHIFU uterine leiomyoma treatment systems. From this data  the stability of the maximum temperature elevation  the targeting accuracy  and the dimensions of the heated volume were analyzed. Additionally  we studied the sensitivity of these parameters to reveal hypothetical decrease in HIFU performance. After calibration  the mean targeting offsets of the heated volume were observed to be less than 2 mm in the three orthogonal directions. The measured maximum temperature elevation and the length and the width of the heated volume remained consistent throughout the four-month period. Furthermore  it was found that the parameters under investigation were sensitive to reveal the decreased HIFU performance. We conclude that an agar-silica -based phantom is suitable for targeting accuracy and heating properties QA of MRgHIFU system even in long-term use. Moreover  this simple QA method may be used to reveal small changes in HIFU performance assuring consistent functionality and safety of the MRgHIFU system.Quantity is nothing without quality: automated QA/QC for streaming sensor networksTreesearchJohn L. Campbell; Lindsey E. Rustad; John H. Porter; Jeffrey R. Taylor; Ethan W. Dereszynski; James B. Shanley; Corinna Gries; Donald L. Henshaw; Mary E. Martin; Wade. M. Sheldon; Emery R. Boose2013-01-01Sensor networks are revolutionizing environmental monitoring by producing massive quantities of data that are being made publically available in near real time. These data streams pose a challenge for ecologists because traditional approaches to quality assurance and quality control are no longer practical when confronted with the size of these data sets and the...Quality assurance paradigms for artificial intelligence in modelling and simulationSciTech ConnectOren  T.I.1987-04-01New classes of quality assurance concepts and techniques are required for the advanced knowledge-processing paradigms (such as artificial intelligence  expert systems  or knowledge-based systems) and the complex problems that only simulative systems can cope with. A systematization of quality assurance problems as well as examples are given to traditional and cognizant quality assurance techniques in traditional and cognizant modelling and simulation.Institutional Response to the Swedish Model of Quality Assurance.ERIC Educational Resources Information CenterNilsson  Karl-Axel; Wahlen  Staffan2000-01-01Evaluates the Swedish model of quality assurance of higher education by examining the response of institutions to 27 quality audits and 19 follow-up interviews. Discusses the relationship between top-down and bottom-up approaches to internal quality assurance and suggests that  with growing professionalization  more limited result-oriented auditsâ€¦Quality Assurance in Continuing Professional Education. An Analysis.ERIC Educational Resources Information CenterTovey  PhilipBased on research conducted in and around universities in the United Kingdom  this book analyzes quality assurance in continuing professional education (CPE). An introduction provides a close look at the terms ""quality """"quality assurance "" and ""CPE."" Part I deals with context. Chapter 1 looks at theoreticalâ€¦10 CFR 72.142 - Quality assurance organization.Code of Federal Regulations  2014 CFR2014-01-01...  or consultants  the work of establishing and executing the quality assurance program  but the... 10 Energy 2 2014-01-01 2014-01-01 false Quality assurance organization. 72.142 Section 72.142... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality...10 CFR 72.142 - Quality assurance organization.Code of Federal Regulations  2012 CFR2012-01-01...  or consultants  the work of establishing and executing the quality assurance program  but the... 10 Energy 2 2012-01-01 2012-01-01 false Quality assurance organization. 72.142 Section 72.142... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality...10 CFR 72.142 - Quality assurance organization.Code of Federal Regulations  2013 CFR2013-01-01...  or consultants  the work of establishing and executing the quality assurance program  but the... 10 Energy 2 2013-01-01 2013-01-01 false Quality assurance organization. 72.142 Section 72.142... SPENT NUCLEAR FUEL  HIGH-LEVEL RADIOACTIVE WASTE  AND REACTOR-RELATED GREATER THAN CLASS C WASTE Quality...Compliance with Aerospace Quality Assurance Standard AS9100NASA Technical Reports Server (NTRS)Hughitt  Brian2009-01-01The contents include: 1) United States Federal Acquisition Regulations (FAR) Part 46  Quality Assurance; 2) NASA Quality Roadmap; 3) AS9003 Inspection and Test Quality Management System; 4) Government Oversight Responsibilities; and 5) Third Party vs Second Party Oversight.A retrospective analysis for patient-specific quality assurance of volumetric-modulated arc therapy plansSciTech ConnectLi  Guangjun; Wu  Kui; Peng  Guang2014-01-01Volumetric-modulated arc therapy (VMAT) is now widely used clinically  as it is capable of delivering a highly conformal dose distribution in a short time interval. We retrospectively analyzed patient-specific quality assurance (QA) of VMAT and examined the relationships between the planning parameters and the QA results. A total of 118 clinical VMAT cases underwent pretreatment QA. All plans had 3-dimensional diode array measurements  and 69 also had ion chamber measurements. Dose distribution and isocenter point dose were evaluated by comparing the measurements and the treatment planning system (TPS) calculations. In addition  the relationship between QA results and several planning parameters moreÂ Â» such as dose level  control points (CPs)  monitor units (MUs)  average field width  and average leaf travel  were also analyzed. For delivered dose distribution  a gamma analysis passing rate greater than 90% was obtained for all plans and greater than 95% for 100 of 118 plans with the 3%/3-mm criteria. The difference (mean Â± standard deviation) between the point doses measured by the ion chamber and those calculated by TPS was 0.9% Â± 2.0% for all plans. For all cancer sites  nasopharyngeal carcinoma and gastric cancer have the lowest and highest average passing rates  respectively. From multivariate linear regression analysis  the dose level (p = 0.001) and the average leaf travel (p < 0.001) showed negative correlations with the passing rate  and the average field width (p = 0.003) showed a positive correlation with the passing rate  all indicating a correlation between the passing rate and the plan complexity. No statistically significant correlation was found between MU or CP and the passing rate. Analysis of the results of dosimetric pretreatment measurements as a function of VMAT plan parameters can provide important information to guide the plan parameter setting and optimization in TPS.Â«Â lessA retrospective analysis for patient-specific quality assurance of volumetric-modulated arc therapy plans.PubMedLi  Guangjun; Wu  Kui; Peng  Guang; Zhang  Yingjie; Bai  Sen2014-01-01Volumetric-modulated arc therapy (VMAT) is now widely used clinically  as it is capable of delivering a highly conformal dose distribution in a short time interval. We retrospectively analyzed patient-specific quality assurance (QA) of VMAT and examined the relationships between the planning parameters and the QA results. A total of 118 clinical VMAT cases underwent pretreatment QA. All plans had 3-dimensional diode array measurements  and 69 also had ion chamber measurements. Dose distribution and isocenter point dose were evaluated by comparing the measurements and the treatment planning system (TPS) calculations. In addition  the relationship between QA results and several planning parameters  such as dose level  control points (CPs)  monitor units (MUs)  average field width  and average leaf travel  were also analyzed. For delivered dose distribution  a gamma analysis passing rate greater than 90% was obtained for all plans and greater than 95% for 100 of 118 plans with the 3%/3-mm criteria. The difference (mean Â± standard deviation) between the point doses measured by the ion chamber and those calculated by TPS was 0.9% Â± 2.0% for all plans. For all cancer sites  nasopharyngeal carcinoma and gastric cancer have the lowest and highest average passing rates  respectively. From multivariate linear regression analysis  the dose level (p = 0.001) and the average leaf travel (p < 0.001) showed negative correlations with the passing rate  and the average field width (p = 0.003) showed a positive correlation with the passing rate  all indicating a correlation between the passing rate and the plan complexity. No statistically significant correlation was found between MU or CP and the passing rate. Analysis of the results of dosimetric pretreatment measurements as a function of VMAT plan parameters can provide important information to guide the plan parameter setting and optimization in TPS. Copyright Â© 2014 American Association of Medical Dosimetrists. Published byOpinion of gastroenterologists towards quality assurance in endoscopy.PubMedde Jonge  Vincent; Kuipers  Ernst J; van Leerdam  Monique E2011-03-01Quality assurance has become an important issue. Many societies are adopting quality assurance programs in order to monitor and improve quality of care. To assess the opinion of gastroenterologists towards quality assurance on the endoscopy department. A survey was sent to all gastroenterologists (n=319) in the Netherlands. It assessed their opinion on a quality assurance program for endoscopy units  including its design  logistics  and content. 200 gastroenterologists (63%) completed the questionnaire. 95% had a positive opinion towards quality assurance and 67% supposed an increase in quality. 28% assumed a negative impact on the time available for patient contact by introducing a quality assurance program and 35% that the capacity would decrease. A negative attitude towards disclosure of results to insurance companies (23%) and media (53%) was reported. Female gastroenterologists were less positive to share the results with other stakeholders (p<0.05). Most important quality measurements were assessment of complications (97%)  standardised reporting (96%)  and adequate patient information (95%). Gastroenterologists have a positive attitude towards quality assurance. However  concerns do exist about time investment and disclosure of results to others. Information provision and procedure characteristics were considered the most important aspects of quality assurance. Copyright Â© 2010 Editrice Gastroenterologica Italiana S.r.l. Published by Elsevier Ltd. All rights reserved.Historical evolution of medical quality assurance in the Department of Defense.PubMedGranger  Elder; Boyer  John; Weiss  Richard; Linton  Andrea; Williams  Thomas V2010-08-01The Department of Defense (DoD) Military Health System (MHS) embodies decades of health care practice that has evolved in scope and complexity to meet the demands for quality care to which its beneficiaries are entitled. War  Base Realignment and Closure (BRAC)  and other dynamic forces require the ongoing review and revision of health care policy and practice in military hospitals as well as the expanded network of civilian providers who care for our nation's soldiers  sailors  airmen  and marines and their families. The result has been an incrementally constructed quality assurance (QA) program with emphasis on organizational structures  programs  and systems  and the use of robust data sources and standard measures to analyze and improve processes  manage disease  assess patient perceptions of care  and ensure that a uniform health care benefit and high quality health care is accessible to all MHS beneficiaries.Development of the Quality Assurance/Quality Control Procedures for a Neutron Interrogation SystemNASA Astrophysics Data System (ADS)ObhoÄ‘aÅ¡  Jasmina; Sudac  Davorin; ValkoviÄ‡  Vladivoj2016-06-01In order to perform Quality Assurance/Quality Control (QA/QC) procedures for a system dedicated to the neutron interrogation of objects for the presence of threat materials one needs to perform measurements of reference materials (RM) i.e. simulants having the same (or similar) atomic ratios as real materials. It is well known that explosives  drugs  and various other benign materials  contain chemical elements such as hydrogen  oxygen  carbon and nitrogen in distinctly different quantities. For example  a high carbon-to-oxygen ratio (C/O) is characteristic of drugs. Explosives can be differentiated by measurement of both (C/O) and nitrogen-to-oxygen (N/O) ratios. The C/N ratio of the chemical warfare agents  coupled with the measurement of elements such as fluorine and phosphorus  clearly differentiate them from the conventional explosives. Here we present the RM preparation  calibration procedure and correlations attained between theoretical values and experimentally obtained results in laboratory conditions for C/O and N/C ratios of prepared hexogen (RDX)  TNT  DLM2  TATP  cocaine  heroin  yperite  tetranitromethane  peroxide methylethylketone  nitromethane and ethyleneglycol dinitrate simulants. We have shown that analyses of the gamma ray spectra by using simple unfolding model developed for this purpose gave a nice agreement with the chemical formula of created simulants  thus the calibration quality was successfully tested.Quality assurance in mammography: College of Radiology Survey in Malaysia.PubMedHo  E L M; Ng  K H; Wong  J H D; Wang  H B2006-06-01Malaysia's mammography QA practice was surveyed based on the Malaysian Ministry of Health and the American College of Radiology (ACR) requirements. Data on mammography unit  processor  image receptor  exposure factors  mean glandular dose (MGD)  sensitometry  image quality and viewbox luminance were obtained. Mean developer temperature and cycle time were 34.1 +/- 1.8degreesC and 107.7 +/- 33.2 seconds. Mean base+fog level  speed index and contrast index were 0.20+/-0.01  1.20+/-0.01 and 1.33+/-0.26 respectively. Eighty-six percent of the fifty centres passed the image quality test while 12.5% complied with ACR recommended viewbox luminance. Average MGD was 1.0+/-0.4 mGy. Malaysia is on the right track for QA but with room for total quality improvement.Examination of the properties of IMRT and VMAT beams and evaluation against pre-treatment quality assurance resultsNASA Astrophysics Data System (ADS)Crowe  S. B.; Kairn  T.; Middlebrook  N.; Sutherland  B.; Hill  B.; Kenny  J.; Langton  C. M.; Trapp  J. V.2015-03-01This study aimed to provide a detailed evaluation and comparison of a range of modulated beam evaluation metrics  in terms of their correlation with QA testing results and their variation between treatment sites  for a large number of treatments. Ten metrics including the modulation index (MI)  fluence map complexity  modulation complexity score (MCS)  mean aperture displacement (MAD) and small aperture score (SAS) were evaluated for 546 beams from 122 intensity modulated radiotherapy (IMRT) and volumetric modulated arc therapy (VMAT) treatment plans targeting the anus  rectum  endometrium  brain  head and neck and prostate. The calculated sets of metrics were evaluated in terms of their relationships to each other and their correlation with the results of electronic portal imaging based quality assurance (QA) evaluations of the treatment beams. Evaluation of the MI  MAD and SAS suggested that beams used in treatments of the anus  rectum  head and neck were more complex than the prostate and brain treatment beams. Seven of the ten beam complexity metrics were found to be strongly correlated with the results from QA testing of the IMRT beams (p < 0.00008). For example  values of SAS (with multileaf collimator apertures narrower than 10 mm defined as â€˜smallâ€™) less than 0.2 also identified QA passing IMRT beams with 100% specificity. However  few of the metrics are correlated with the results from QA testing of the VMAT beams  whether they were evaluated as whole 360Â° arcs or as 60Â° sub-arcs. Select evaluation of beam complexity metrics (at least MI  MCS and SAS) is therefore recommended  as an intermediate step in the IMRT QA chain. Such evaluation may also be useful as a means of periodically reviewing VMAT planning or optimiser performance.A Comprehensive Quality Assurance Program for Personnel and Procedures in Radiation Oncology: Value of Voluntary Error Reporting and ChecklistsSciTech ConnectKalapurakal  John A.  E-mail: j-kalapurakal@northwestern.edu; Zafirovski  Aleksandar; Smith  JefferyPurpose: This report describes the value of a voluntary error reporting system and the impact of a series of quality assurance (QA) measures including checklists and timeouts on reported error rates in patients receiving radiation therapy. Methods and Materials: A voluntary error reporting system was instituted with the goal of recording errors  analyzing their clinical impact  and guiding the implementation of targeted QA measures. In response to errors committed in relation to treatment of the wrong patient  wrong treatment site  and wrong dose  a novel initiative involving the use of checklists and timeouts for all staff was implemented. The impactmoreÂ Â» of these and other QA initiatives was analyzed. Results: From 2001 to 2011  a total of 256 errors in 139 patients after 284 810 external radiation treatments (0.09% per treatment) were recorded in our voluntary error database. The incidence of errors related to patient/tumor site  treatment planning/data transfer  and patient setup/treatment delivery was 9%  40.2%  and 50.8%  respectively. The compliance rate for the checklists and timeouts initiative was 97% (P<.001). These and other QA measures resulted in a significant reduction in many categories of errors. The introduction of checklists and timeouts has been successful in eliminating errors related to wrong patient  wrong site  and wrong dose. Conclusions: A comprehensive QA program that regularly monitors staff compliance together with a robust voluntary error reporting system can reduce or eliminate errors that could result in serious patient injury. We recommend the adoption of these relatively simple QA initiatives including the use of checklists and timeouts for all staff to improve the safety of patients undergoing radiation therapy in the modern era.Â«Â lessExperience with Quality Assurance in Two Store-and-Forward Telemedicine Networks.PubMedWootton  Richard; Liu  Joanne; Bonnardot  Laurent; Venugopal  Raghu; Oakley  Amanda2015-01-01Despite the increasing use of telemedicine around the world  little has been done to incorporate quality assurance (QA) into these operations. The purpose of the present study was to examine the feasibility of QA in store-and-forward teleconsulting using a previously published framework. During a 2-year study period  we examined the feasibility of using QA tools in two mature telemedicine networks [MÃ©decins Sans FrontiÃ¨res (MSF) and New Zealand Teledermatology (NZT)]. The tools included performance reporting to assess trends  automated follow-up of patients to obtain outcomes data  automated surveying of referrers to obtain user feedback  and retrospective assessment of randomly selected cases to assess quality. In addition  the senior case coordinators in each network were responsible for identifying potential adverse events from email reports received from users. During the study period  there were 149 responses to the patient follow-up questions relating to the 1241 MSF cases (i.e.  12% of cases)  and there were 271 responses to the follow-up questions relating to the 639 NZT cases (i.e.  42% of cases). The collection of user feedback reports was combined with the collection of patient follow-up data  thus producing the same response rates. The outcomes data suggested that the telemedicine advice proved useful for the referring doctor in the majority of cases and was likely to benefit the patient. The user feedback was overwhelmingly positive  over 90% of referrers in the two networks finding the advice received to be of educational benefit. The feedback also suggested that the teleconsultation had provided cost savings in about 20% of cases  either to the patient/family  or to the hospital/clinic treating the patient. Various problems were detected by regular monitoring  and certain adverse events were identified from email reports by the users. A single aberrant quality reading was detected by using a process control chart. The present study demonstratesChiropractic quality assurance: standards and guidelinesPubMed CentralGatterman  Meridel I; Dobson  Thomas P; LeFevbre  Ron2001-01-01Chiropractic quality assurance involves development of both clinical guidelines and standards. Confusion generated by poor differentiation of guidelines from standards contributes to mistrust of the guideline development process. Guidelines are considered to be recommendations that allow for flexibility and individual patient differences. Standards are more binding and require a high level of supporting evidence. While guidelines serve as educational tools to improve the quality of practice  standards that outline minimum competency are used more as administrative tools on which to base policy. Barriers to development of clinical guidelines and standards include fear that they will create prescriptive â€œcookbookâ€ practice  and the distrust that guidelines are developed primarily for cost containment. Clinicians also criticize guidelines developed by academics that don't relate to practice  and those based on evidence that lacks clinical relevance. Conflicting guidelines perceived to be based on strong bias or conflict of interest are also suspect. To reduce barriers to acceptance and implementation  guidelines should be inclusive  patient-centered  and based on a variety of evidence and clinical experience.Quality assurance in surgical practice through auditing.PubMedWong  W T1980-05-01An efficient auditing method is presented which involves objective criteria-based numerical screening of medical process and treatment outcome by paramedical staff and detailed analysis of deviated cases by surgeons. If properly performed it requires the study of no more than 50 cases in a diagnostic category to provide sufficient information about the quality of care. Encouraging points as well as problems are communicated to the surgeons to induce the maintenance or improvement of the standard of care. Graphic documentation of case performance is possible  allowing surgeons to compare results with their colleagues. The general performance level of several consecutive studies can be compared at a glance. In addition  logical education programs to improve the medical process can be designed on the basis of the problems identified. As all the cases with an unacceptable outcome are traceable to inadequate medical process  improvement in this area will decrease outcome defects. With the use of auditing and the follow-up technique described  the quality of care in surgery may be assured.Quality Assurance Program for Molecular Medicine LaboratoriesPubMed CentralHajia  M; Safadel  N; Samiee  S Mirab; Dahim  P; Anjarani  S; Nafisi  N; Sohrabi  A; Rafiee  M; Sabzavi  F; Entekhabi  B2013-01-01Background: Molecular diagnostic methods have played and continuing to have a critical role in clinical laboratories in recent years. Therefore  standardization is an evolutionary process that needs to be upgrade with increasing scientific knowledge  improvement of the instruments and techniques. The aim of this study was to design a quality assurance program in order to have similar conditions for all medical laboratories engaging with molecular tests. Methods: We had to design a plan for all four elements; required space conditions  equipments  training  and basic guidelines. Necessary guidelines was prepared and confirmed by the launched specific committee at the Health Reference Laboratory. Results: Several workshops were also held for medical laboratories directors and staffs  quality control manager of molecular companies  directors and nominees from universities. Accreditation of equipments and molecular material was followed parallel with rest of program. Now we are going to accredit medical laboratories and to evaluate the success of the program. Conclusion: Accreditation of medical laboratory will be succeeding if its basic elements are provided in advance. Professional practice guidelines  holding training and performing accreditation the molecular materials and equipments ensured us that laboratories are aware of best practices  proper interpretation  limitations of techniques  and technical issues. Now  active external auditing can improve the applied laboratory conditions toward the defined standard level. PMID:23865028Quality assurance program for molecular medicine laboratories.PubMedHajia  M; Safadel  N; Samiee  S Mirab; Dahim  P; Anjarani  S; Nafisi  N; Sohrabi  A; Rafiee  M; Sabzavi  F; Entekhabi  B2013-01-01Molecular diagnostic methods have played and continuing to have a critical role in clinical laboratories in recent years. Therefore  standardization is an evolutionary process that needs to be upgrade with increasing scientific knowledge  improvement of the instruments and techniques. The aim of this study was to design a quality assurance program in order to have similar conditions for all medical laboratories engaging with molecular tests. We had to design a plan for all four elements; required space conditions  equipments  training  and basic guidelines. Necessary guidelines was prepared and confirmed by the launched specific committee at the Health Reference Laboratory. Several workshops were also held for medical laboratories directors and staffs  quality control manager of molecular companies  directors and nominees from universities. Accreditation of equipments and molecular material was followed parallel with rest of program. Now we are going to accredit medical laboratories and to evaluate the success of the program. Accreditation of medical laboratory will be succeeding if its basic elements are provided in advance. Professional practice guidelines  holding training and performing accreditation the molecular materials and equipments ensured us that laboratories are aware of best practices  proper interpretation  limitations of techniques  and technical issues. Now  active external auditing can improve the applied laboratory conditions toward the defined standard level.48 CFR 2152.246-70 - Quality assurance requirements.Code of Federal Regulations  2013 CFR2013-10-01... 48 Federal Acquisition Regulations System 6 2013-10-01 2013-10-01 false Quality assurance... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CLAUSES AND FORMS PRECONTRACT PROVISIONS AND CONTRACT CLAUSES Text of Provisions and Clauses 2152.246-70 Quality assurance...48 CFR 2152.246-70 - Quality assurance requirements.Code of Federal Regulations  2010 CFR2010-10-01... 48 Federal Acquisition Regulations System 6 2010-10-01 2010-10-01 true Quality assurance... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CLAUSES AND FORMS PRECONTRACT PROVISIONS AND CONTRACT CLAUSES Text of Provisions and Clauses 2152.246-70 Quality assurance...48 CFR 2152.246-70 - Quality assurance requirements.Code of Federal Regulations  2012 CFR2012-10-01... 48 Federal Acquisition Regulations System 6 2012-10-01 2012-10-01 false Quality assurance... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CLAUSES AND FORMS PRECONTRACT PROVISIONS AND CONTRACT CLAUSES Text of Provisions and Clauses 2152.246-70 Quality assurance...48 CFR 2152.246-70 - Quality assurance requirements.Code of Federal Regulations  2014 CFR2014-10-01... 48 Federal Acquisition Regulations System 6 2014-10-01 2014-10-01 false Quality assurance... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CLAUSES AND FORMS PRECONTRACT PROVISIONS AND CONTRACT CLAUSES Text of Provisions and Clauses 2152.246-70 Quality assurance...48 CFR 2152.246-70 - Quality assurance requirements.Code of Federal Regulations  2011 CFR2011-10-01... 48 Federal Acquisition Regulations System 6 2011-10-01 2011-10-01 false Quality assurance... MANAGEMENT  FEDERAL EMPLOYEES GROUP LIFE INSURANCE FEDERAL ACQUISITION REGULATION CLAUSES AND FORMS PRECONTRACT PROVISIONS AND CONTRACT CLAUSES Text of Provisions and Clauses 2152.246-70 Quality assurance...Quality Assurance in Online Content Literacy Methods CoursesERIC Educational Resources Information CenterMarsh  Josephine P.; Lammers  Jayne C.; Alvermann  Donna E.2012-01-01As institutions offer more online courses in their teacher certification and literacy master's programs  research is needed to address issues of quality assurance in online instruction. This multicase study analyzes qualitatively elements for addressing quality assurance of the implementation of an online content literacy teacher education courseâ€¦Illinois' Forests  2005: Statistics  Methods  and Quality AssuranceTreesearchSusan J. Crocker; Charles J. Barnett; Mark A. Hatfield2013-01-01The first full annual inventory of Illinois' forests was completed in 2005. This report contains 1) descriptive information on methods  statistics  and quality assurance of data collection  2) a glossary of terms  3) tables that summarize quality assurance  and 4) a core set of tabular estimates for a variety of forest resources. A detailed analysis of inventory...10 CFR 71.101 - Quality assurance requirements.Code of Federal Regulations  2010 CFR2010-01-01... quality assurance actions related to control of the physical characteristics and quality of the material... through 71.137 and satisfying any specific provisions that are applicable to the licensee's activities... assurance requirement's importance to safety. (c) Approval of program. (1) Before the use of any package for...Current Trends in European Quality Assurance. ENQA Workshop Report 8ERIC Educational Resources Information CenterBozo  Dhurata; Damian  Radu; Gonzalez  Cecilia de la Rosa; Helle  Emmi; Imoda  Franco; Kohler  Alexander; Papazoglou  Vassilios J.; Dalmau  Gemma Rauret; Shopov  Todor2009-01-01The present report is a product of two ENQA (European Association for Quality Assurance in Higher Education) seminars  held in 2007  on current trends in European Quality Assurance. The first seminar  hosted by the Bulgarian National Evaluation and Accreditation Agency (NEAA)  examined the situation in South-Eastern Europe. The second seminarâ€¦7 CFR 90.102 - Quality assurance review.Code of Federal Regulations  2010 CFR2010-01-01... 7 Agriculture 3 2010-01-01 2010-01-01 false Quality assurance review. 90.102 Section 90.102 Agriculture Regulations of the Department of Agriculture (Continued) AGRICULTURAL MARKETING SERVICE (Standards  Inspections  Marketing Practices)  DEPARTMENT OF AGRICULTURE (CONTINUED) COMMODITY LABORATORY TESTING PROGRAMS INTRODUCTION Quality Assurance Â§...Policy of Quality Assurance in Hong Kong PreschoolsERIC Educational Resources Information CenterDora  Ho Choi-wa2007-01-01This article discusses the sources  processes and impact of the quality assurance policy implemented in Hong Kong preschools. Regarded as a sort of policy alignment between the subsystems of pre-primary  primary and secondary education  the introduction of a quality assurance policy has been directly and indirectly transforming the settlements inâ€¦Understanding Quality Assurance: A Cross Country Case StudyERIC Educational Resources Information CenterChoon Boey Lim  Fion2008-01-01Purpose: The purpose of this paper is to examine the level of understanding between an Australian university and its offshore partner institution  on quality assurance. It attempts to highlight the dynamics of quality assurance policy implementation within and across institutions for an offshore degree. Design/methodology/approach: The study usedâ€¦Quality Assurance in South Africa: A Reply to John MammenERIC Educational Resources Information Centerle Grange  L.2006-01-01In this article I point out that prominence given to higher education quality assurance by contemporary states might be viewed in the context of the ascendance of neoliberalism over the past few decades and a concomitant culture of performativity. However  I argue for a shift in the angle of vision on performativity and quality assurance through aâ€¦Quality Assurance in a School of Dentistry: Getting Started.ERIC Educational Resources Information CenterGuba  Christianne J.1990-01-01Steps in establishment of Indiana University School of Dentistry's quality assurance program included gathering existing information on quality assurance; ascertaining administrative support; appointing a committee; defining terms and setting goals; raising awareness and commitment; designing a patient satisfaction survey; undertaking a chartâ€¦42 CFR 441.585 - Quality assurance system.Code of Federal Regulations  2013 CFR2013-10-01... 42 Public Health 4 2013-10-01 2013-10-01 false Quality assurance system. 441.585 Section 441.585 Public Health CENTERS FOR MEDICARE & MEDICAID SERVICES  DEPARTMENT OF HEALTH AND HUMAN SERVICES... provides information about the provisions of quality improvement and assurance to each individual receiving...42 CFR 441.585 - Quality assurance system.Code of Federal Regulations  2014 CFR2014-10-01... 42 Public Health 4 2014-10-01 2014-10-01 false Quality assurance system. 441.585 Section 441.585 Public Health CENTERS FOR MEDICARE & MEDICAID SERVICES  DEPARTMENT OF HEALTH AND HUMAN SERVICES... provides information about the provisions of quality improvement and assurance to each individual receiving...Quality Assurance Toolkit for Distance Higher Education Institutions and ProgrammesERIC Educational Resources Information CenterRama  Kondapalli  Ed.; Hope  Andrea  Ed.2009-01-01The Commonwealth of Learning is proud to partner with the Sri Lankan Ministry of Higher Education and UNESCO to produce this ""Quality Assurance Toolkit for Distance Higher Education Institutions and Programmes"". The Toolkit has been prepared with three features. First  it is a generic document on quality assurance  complete with aâ€¦40 CFR Appendix C to Part 61 - Quality Assurance ProceduresCode of Federal Regulations  2010 CFR2010-07-01... 40 Protection of Environment 8 2010-07-01 2010-07-01 false Quality Assurance Procedures C Appendix C to Part 61 Protection of Environment ENVIRONMENTAL PROTECTION AGENCY (CONTINUED) AIR PROGRAMS...â€”Quality Assurance Procedures Procedure 1â€”Determination of Adequate Chromatographic Peak Resolution In this...Quality Assurance and Accreditation of Engineering Education in JordanERIC Educational Resources Information CenterAqlan  Faisal; Al-Araidah  Omar; Al-Hawari  Tarek2010-01-01This paper provides a study of the quality assurance and accreditation in the Jordanian higher education sector and focuses mainly on engineering education. It presents engineering education  accreditation and quality assurance in Jordan and considers the Jordan University of Science and Technology (JUST) for a case study. The study highlights theâ€¦Internal Quality Assurance Benchmarking. ENQA Workshop Report 20ERIC Educational Resources Information CenterBlackstock  Douglas; Burquel  Nadine; Comet  Nuria; Kajaste  Matti; dos Santos  Sergio Machado; Marcos  Sandra; Moser  Marion; Ponds  Henri; Scheuthle  Harald; Sixto  Luis Carlos Velon2012-01-01The Internal Quality Assurance group of ENQA (IQA Group) has been organising a yearly seminar for its members since 2007. The main objective is to share experiences concerning the internal quality assurance of work processes in the participating agencies. The overarching theme of the 2011 seminar was how to use benchmarking as a tool forâ€¦QUALITY ASSURANCE IN RESEARCH LABORATORIES: RULES AND REASONEPA Science InventoryQuality Assurance in Research Laboratories: Rules and ReasonRon Rogers  Quality Assurance and Records Manager  Environmental Carcinogenesis Division  NHEERL/ORD/US EPA  Research Triangle Park  NC  27709To anyone who has actively participated in research  as I have...Quality assurance in Australian hospitals: who does it and how?PubMedRenwick  M; Harvey  R1990-01-01To seek information on the type  method and extent of quality assurance being undertaken in all public and private hospitals within Australia. Mailed questionnaire. There was a predominance of two types of review being undertaken. Some important deficiencies in the quality assurance process were identified. Far more private than public hospitals reviewed medical records and surveyed patient satisfaction.Monitoring and Assuring the Quality of Digital Aerial DataNASA Technical Reports Server (NTRS)Christopherson  Jon2007-01-01This viewgraph presentation explains the USGS plan for monitoring and assuring the quality of digital aerial data. The contents include: 1) History of USGS Aerial Imaging Involvement; 2) USGS Research and Results; 3) Outline of USGS Quality Assurance Plan; 4) Other areas of Interest; and 5) Summary",quality assurance ( sqa ), 'Personal computer',https://www.science.gov/topicpages/q/quality%2Bassurance%2Bqa,'hendrie computer'
       Slideshare uses cookies to improve functionality and performance  and to provide you with relevant advertising. If you continue browsing the site  you agree to the use of cookies on this website. See our User Agreement and Privacy Policy.            Slideshare uses cookies to improve functionality and performance  and to provide you with relevant advertising. If you continue browsing the site  you agree to the use of cookies on this website. See our Privacy Policy and User Agreement for details.                     Published on Sep 4  2007                       This is a very good presentation on SEI CMM. (Althopugh the model has been retired but it still forms the basis for many IT organisations)                    Be the first to comment LinkedIn Corporation © 2019Looks like you’ve clipped this slide to  already.,capability maturity model ( cmm ), 'Personal computer',https://www.slideshare.net/guest035e0d/c-m-m-tutorial,'institute technology'
Unlock full access with a free trial.Unlock full access with a free trial.Unlock full access with a free trial.,capture / playback and test harness tools, 'Personal computer',https://www.scribd.com/presentation/182262661/testing-automation-and-tools-ppt,'institute technology'
top linksfilter your search allcollegesexamnewswe'reon mobile tooget collegedunia app for 10x faster experienceget app link on your mobileTeachingBankingPSU RecruitmentSSCLatest News:एसबीआई पीओ 2019 आवेदन फॉर्म .. Read Now रिक्तियां .. Read Now तिथियां.. Read NowFor undergraduate AdmissionFor law Courses AdmissionFor Postgraduate Management CoursesFor MS programsEnglish Proficiency TestLatest News:English language test for migration 101 – Everythi.. Read NowTOEFL 2018 Inscripción.. Read Now fechas de exámenes.. Read Now B.COM EXAMINATION   M.COM EXAMINATION  See all exams B.COM AdmissionCalicut   KeralaKrishnankovil   Tamil NaduCoimbatore   Tamil NaduSonepat   HaryanaM.COM AdmissionCoimbatore   Tamil NaduCoimbatore   Tamil NaduVijayapuram   KarnatakaChennai   Tamil NaduM.PHIL/PH.D IN COMMERCE AdmissionDharwad   KarnatakaBangalore   KarnatakaBangalore   KarnatakaVijayapuram   Karnataka B.COM COLLEGES See all colleges M.COM COLLEGES See all collegesPOPULAR COLLEGES IN INDIAAndhra University - [AU]TSR and TBK Degree and PG CollegePandu CollegeCKB Commerce College BE/B.TECH EXAMINATION   ME/M.TECH EXAMINATION  BE/B.TECH AdmissionVellore   Tamil NaduKochi   KeralaKochi   KeralaChennai   Tamil NaduM.PHIL/PH.D IN ENGINEERING AdmissionChennai   Tamil NaduBangalore   KarnatakaBangalore   KarnatakaThrissur   KeralaME/M.TECH AdmissionKochi   KeralaKochi   KeralaVellore   Tamil NaduThiruvananthapuram   Kerala BE/B.TECH COLLEGES See all colleges ME/M.TECH COLLEGES See all collegesPOPULAR COLLEGES IN INDIAPriyadarshini College of Engineering and Technology - [PCET]MIT WORLD PEACE UNIVERSITY - [MITWPU]RISE Gandhi Group of InstitutionsLingayas Institute of Management and Technology - [LIMAT] MBBS EXAMINATION   MS EXAMINATION  See all exams B.SC (MEDICINE) AdmissionThrissur   KeralaChennai   Tamil NaduChennai   Tamil NaduKochi   KeralaBAMS AdmissionThrissur   KeralaKanchipuram   Tamil NaduBelgaum   KarnatakaVijayawada   Andhra PradeshM.CH AdmissionThrissur   KeralaChennai   Tamil NaduKochi   KeralaChennai   Tamil Nadu MBBS COLLEGES See all colleges MS COLLEGES See all collegesPOPULAR COLLEGES IN INDIAGreat Eastern Medical School and HospitalAlluri Sitharama Raju Academy of Medical Sciences - [ASRAM]Guntur Medical CollegeGSL Medial College and General Hospital BBA/BBM EXAMINATION   MBA/PGDM EXAMINATION  BBA/BBM AdmissionDindigul   Tamil NaduCoimbatore   Tamil NaduChennai   Tamil NaduUdaipur   RajasthanEXECUTIVE MBA AdmissionBangalore   KarnatakaTirupati   Andhra PradeshVisakhapatnam   Andhra PradeshGRADUATE DIPLOMA IN MANAGEMENT AdmissionChennai   Tamil Nadu BBA/BBM COLLEGES See all colleges MBA/PGDM COLLEGES See all collegesPOPULAR COLLEGES IN INDIANoble Institute of Science and Technology - [NIST]MIT WORLD PEACE UNIVERSITY - [MITWPU]Sri Krishnadevaraya Institute of Management - [SKIM]Indian Academy Degree College - [IADC-A]B.SC EXAMINATION  M.SC EXAMINATION  B.SC AdmissionSiruseri   Tamil NaduThrissur   KeralaChennai   Tamil NaduCalicut   KeralaCERTIFICATE IN SCIENCE AdmissionChennai   Tamil NaduDIPLOMA IN SCIENCE AdmissionKochi   KeralaWayanad   KeralaChennai   Tamil Nadu B.SC COLLEGES See all colleges M.SC COLLEGES See all collegesPOPULAR COLLEGES IN INDIAPatna Science CollegeRam Lakhan Singh Yadav College - [RLSY]Sri Guru Tegh Bahadur Khalsa College - [SGTB]Deen Dayal Upadhyaya CollegeB.SC (AGRICULTURE) EXAMINATION  See all exams M.SC (AGRICULTURE) EXAMINATION  B.SC (AGRICULTURE) AdmissionThrissur   KeralaCoimbatore   Tamil NaduBangalore   KarnatakaBangalore   KarnatakaM.PHIL/PH.D IN AGRICULTURE AdmissionThrissur   KeralaChennai   Tamil NaduCoimbatore   Tamil NaduWayanad   KeralaM.SC (AGRICULTURE) AdmissionThrissur   KeralaWayanad   KeralaChidambaram   Tamil NaduKaraikudi   Tamil Nadu B.SC (AGRICULTURE) COLLEGES See all colleges M.SC (AGRICULTURE) COLLEGES See all collegesPOPULAR COLLEGES IN INDIAS. V. Agricultural College - [SVAC]Dr.YSR Horticultural UniversitySri Venkateswara Veterinary University - [SVVU]National Research Centre on Yak - [NRCY]B.ARCH EXAMINATION  M.ARCH EXAMINATION  See all exams B.ARCH AdmissionKrishnankovil   Tamil NaduThiruvananthapuram   KeralaChennai   Tamil NaduCoimbatore   Tamil NaduM.ARCH AdmissionKrishnankovil   Tamil NaduChennai   Tamil NaduBangalore   KarnatakaChennai   Tamil NaduM.PHIL/PH.D IN ARCHITECTURE AdmissionThanjavur   Tamil NaduRanchi   JharkhandNew Delhi   Delhi NCRHyderabad   Telangana B.ARCH COLLEGES See all colleges M.ARCH COLLEGES See all collegesPOPULAR COLLEGES IN INDIASAR College of Architecture - [SARCA]GITAM School of Architecture - [GSA]Royal School of ArchitectureGuwahati College of ArchitectureBA EXAMINATION  MA EXAMINATION  See all exams BA AdmissionKasaragod   KeralaCalicut   KeralaKrishnankovil   Tamil NaduChennai   Tamil NaduCERTIFICATE IN ARTS AdmissionChennai   Tamil NaduDIPLOMA IN ARTS AdmissionChennai   Tamil NaduChennai   Tamil Nadu BA COLLEGES See all colleges MA COLLEGES See all collegesPOPULAR COLLEGES IN INDIAPVKN Govt Degree College - [PVKNGDC]Dr. Lankapalli Bullayya CollegeSilver Jubilee Government Degree CollegeDera Natung Government College - [DNGC]B.SC (AVIATION) AdmissionChennai   Tamil NaduChennai   Tamil NaduJaipur   Rajasthan B.SC (AVIATION) COLLEGES See all colleges M.SC (AVIATION) COLLEGES See all collegesBCA EXAMINATION  MCA EXAMINATION  BCA AdmissionCalicut   KeralaKrishnankovil   Tamil NaduCoimbatore   Tamil NaduChennai   Tamil NaduM.PHIL/PH.D IN COMPUTER APPLICATIONS AdmissionBangalore   KarnatakaBangalore   KarnatakaCoimbatore   Tamil NaduThiruvananthapuram   KeralaMCA AdmissionKochi   KeralaCoimbatore   Tamil NaduKrishnankovil   Tamil NaduChennai   Tamil Nadu BCA COLLEGES See all colleges MCA COLLEGES See all collegesPOPULAR COLLEGES IN INDIASri Venkateswara University - [SVU]GITAMAssam Engineering College - [AEC]Lalit Narayan Mishra Institute of Economic Development and Social Change - [LNMI]BDS EXAMINATION  MDS EXAMINATION  BDS AdmissionThrissur   KeralaChennai   Tamil NaduChennai   Tamil NaduChidambaram   Tamil NaduM.PHIL/PH.D IN DENTAL AdmissionThanjavur   Tamil NaduMangalore   KarnatakaBelgaum   KarnatakaMangalore   KarnatakaMDS AdmissionChennai   Tamil NaduThrissur   KeralaKochi   KeralaChennai   Tamil Nadu BDS COLLEGES See all colleges MDS COLLEGES See all collegesPOPULAR COLLEGES IN INDIADr. NTR University of Health Sciences - [NTRUHS]Narayana Dental College and Hospital - [NDCH]GITAM Dental CollegeVishnu Dental CollegeB.DES EXAMINATION  See all exams M.DES EXAMINATION  See all exams B.DES AdmissionJaipur   RajasthanBangalore   KarnatakaHyderabad   TelanganaBangalore   KarnatakaM.DES AdmissionDehradun   UttarakhandBangalore   KarnatakaBangalore   KarnatakaBangalore   KarnatakaM.PHIL/PH.D IN DESIGN AdmissionCoimbatore   Tamil NaduCoimbatore   Tamil NaduThanjavur   Tamil NaduBangalore   Karnataka B.DES COLLEGES See all colleges M.DES COLLEGES See all collegesPOPULAR COLLEGES IN INDIANational Institute of Design - [NID]Dibrugarh Hanumanbux Surajmal Kanoi College - [DHSK]North East Institute of Fashion Technology - [NEIFT]National Institute of Fashion Technology - [NIFT]B.ED EXAMINATION  See all exams M.ED EXAMINATION  See all exams B.ED AdmissionChennai   Tamil NaduCalicut   KeralaKrishnankovil   Tamil NaduChennai   Tamil NaduM.ED AdmissionKasaragod   KeralaKaraikudi   Tamil NaduCoimbatore   Tamil NaduThiruvananthapuram   KeralaM.PHIL/PH.D IN EDUCATION AdmissionDharwad   KarnatakaBangalore   KarnatakaCalicut   KeralaBangalore   Karnataka B.ED COLLEGES See all colleges M.ED COLLEGES See all collegesPOPULAR COLLEGES IN INDIAGauhati University - [GU]Dakshin Guwahati BEd CollegeSt Xavier's College of EducationDr. SP Singh College of Teacher EducationBHM EXAMINATION  See all exams MHM EXAMINATION  BHM AdmissionUdaipur   RajasthanBellary   KarnatakaBangalore   KarnatakaBangalore   KarnatakaM.PHIL/PH.D IN HOTEL MANAGEMENT AdmissionThanjavur   Tamil NaduBangalore   KarnatakaBhopal   Madhya PradeshNoida   Uttar PradeshM.SC (HOTEL MANAGEMENT) AdmissionBhopal   Madhya Pradesh BHM COLLEGES See all colleges MHM COLLEGES See all collegesPOPULAR COLLEGES IN INDIAAssam Down Town University - [ADTU]Institute of Hotel Management Catering Technology and Applied Nutrition - [IHM]Banarsidas Chandiwala Institute of Hotel Management & Catering TechnologyInternational Institute of Hotel Management - [IIHM]LLB EXAMINATION  See all exams LLM EXAMINATION  See all exams LLB AdmissionKochi   KeralaChennai   Tamil NaduSonepat   HaryanaBangalore   KarnatakaLLD AdmissionBangalore   KarnatakaKolkata   West BengalLLM AdmissionKochi   KeralaKasaragod   KeralaKochi   KeralaChennai   Tamil Nadu LLB COLLEGES See all colleges LLM COLLEGES See all collegesPOPULAR COLLEGES IN INDIAKKC College of LawMRVRGR Law CollegeVeeravalli College of LawIndira Priyadarshini Law College - [IPLC]BMM EXAMINATION  MMC EXAMINATION  BMM AdmissionCalicut   KeralaBangalore   KarnatakaBhubaneswar   OrissaGorakhpur   Uttar PradeshM.PHIL/PH.D IN MASS COMMUNICATION AdmissionVijayapuram   KarnatakaThanjavur   Tamil NaduMangalore   KarnatakaMadurai   Tamil NaduMMC AdmissionNagpur   MaharashtraTirunelveli   Tamil NaduBhubaneswar   Orissa BMM COLLEGES See all colleges MMC COLLEGES See all collegesPOPULAR COLLEGES IN INDIAAssam Don Bosco University - [ADBU]Bongaigaon CollegeKushabhau Thakre Patrakarita Avam Jansanchar VishwavidyalayaMahant Laxminarayan Das CollegeB.SC (NURSING) EXAMINATION  See all exams M.SC (NURSING) EXAMINATION  B.SC (NURSING) AdmissionThrissur   KeralaChennai   Tamil NaduChennai   Tamil NaduChidambaram   Tamil NaduM.PHIL/PH.D IN PARAMEDICAL AdmissionThanjavur   Tamil NaduMangalore   KarnatakaManipal   KarnatakaBijapur   KarnatakaM.SC (NURSING) AdmissionThrissur   KeralaChennai   Tamil NaduKochi   KeralaChennai   Tamil Nadu B.SC (NURSING) COLLEGES See all colleges M.SC (NURSING) COLLEGES See all collegesB.PHARM EXAMINATION  M.PHARM EXAMINATION  See all exams B.PHARM AdmissionThrissur   KeralaChennai   Tamil NaduChennai   Tamil NaduChidambaram   Tamil NaduGRADUATE DIPLOMA IN PHARMACY AdmissionChidambaram   Tamil NaduM.PHARM AdmissionThrissur   KeralaChennai   Tamil NaduChennai   Tamil NaduMysore   Karnataka B.PHARM COLLEGES See all colleges M.PHARM COLLEGES See all collegesPOPULAR COLLEGES IN INDIAShri Vishnu College of Pharmacy - [SVCP]Bapatla College of Pharmacy - [BCOP]KVSR Siddhartha College of Pharmaceutical Sciences - [KVSR SCOPS]GITAM Institute of Pharmacy - [GIP]BVSC EXAMINATION  See all exams MVSC EXAMINATION  BVSC AdmissionChennai   Tamil NaduWayanad   KeralaBidar   KarnatakaTirupati   Andhra PradeshMVSC AdmissionChennai   Tamil NaduWayanad   KeralaBidar   KarnatakaNagpur   MaharashtraPH.D IN VETERINARY SCIENCE AdmissionChennai   Tamil NaduWayanad   KeralaBidar   KarnatakaThanjavur   Tamil Nadu BVSC COLLEGES See all colleges MVSC COLLEGES See all collegesBACHELORS EXAMINATION  MASTERS EXAMINATION  BACHELORS IN VOCATIONAL COURSES AdmissionChidambaram   Tamil NaduAurangabad   MaharashtraGaya   Bihar BACHELORS COLLEGES See all colleges MASTERS COLLEGES See all collegesM.Tech (Digital Electronics & Communication Systems) is a 2-year full-time Postgraduate course  the minimum eligibility for which is Bachelor’s Degree in Electronics & Communication/ Instrumentation Technology/ Electronics & Telecommunication /Telecommunication with a minimum aggregate score of 50%. The program is spread over 4 semesters  with the final semester based on the candidate’s chosen stream of study.INDIA'S BEST LARGEST PRIVATE UNIVERSITYDREAM PLACEMENTS AT TOP COMPANIESCOLLABORATIONS WITH WORLD'S BEST UNIVERSITIESDREAM PLACEMENTS AT TOP COMPANIESTop institutes for M.Tech (Digital Electronics & Communication Systems) are:Admission to the course is based on the candidate’s performance in a relevant entrance test  and subsequent round of counselling.There are certain entrance exam that are conducted by these colleges:Such postgraduates are hired in capacities such as Service Engineer  Technical Director  Field Test Engineer  Senior Sales Manager  Network Planning Engineer  Software Analyst  Customer Support Engineer  Electronics and Communications Consultant  Research & Development Software Engineer  and such.The average tuition fee charged for the course in India ranges between INR 50 000 and 2 50 000 for a span of 2 years  and the average annual salary offered to such professionals ranges between INR 2.5 and 7 Lacs  increasing with experience and expertise.Listed below are some of the major highlights of the course.The program has been designed to offer to eligible candidates  specialization in digital communication techniques used in the present scenario & the hardware languages used in design and implementation  while at the same time building competence in a particular area of technology.Successful Postgraduates of the course interested in pursuing further studies in the discipline may go for pursuing Ph.D in Digital Electronics.The program aims to build in students competent business acumen through advanced study of general subjects such as Advanced Digital Communication  Modern DSP  Advanced Embedded System  Antenna Theory and Design  Digital Electronics  Error control and coding  Advanced Computer Architecture  later allowing them to specialize in a chosen area. The curriculum involves intensive study  culminating with the completion of a research-based dissertation.DREAM PLACEMENTS AT TOP COMPANIESCOLLABORATIONS WITH WORLD'S BEST UNIVERSITIESTIMES OF INDIA GROUP | SCHOLARSHIP UPTO 100%*DREAM PLACEMENTS AT TOP COMPANIESOne of the principle objectives of the course is to train students with good scientific and engineering breadth  including proficiency in software language and use of latest software tools so as to comprehend  analyze  design and create novel products and solutions for the real life problems  as also for pursuing advanced research in the discipline. The course’s curriculum integrates theoretical and practical components of study.Listed below are some of the top institutes in India that offer the course.Candidates wishing to apply for the course need to have completed the Bachelor’s Degree in Electronics & Communication/ Instrumentation Technology/ Electronics & Telecommunication /Telecommunication with a minimum aggregate score of 50%.Most institutes offering the M.Tech (Digital Electronics & Communication Systems) course admit students based on their performance in a relevant entrance test  followed by a round of Personal Interview. Some institutes conduct their own entrance tests for offering admission. Admission process generally varies across colleges. A few institutes also provide direct admission based on the candidate’s score at the Graduate level. Following are the entrance exam that are conducted by some of the M.Tech (Digital Electronics & Communication Systems) colleges in India: A semester-wise breakup of the course’s syllabus is tabulated here.As Service engineers  successful postgraduates of the course keep track of the machinery and equipment present in a company's manufacturing unit. They have to plan the servicing work in advance so the output of the factory is not affected by the service work.They may also work as Technical Director  Field Test Engineer  Senior Sales Manager  Network Planning Engineer  Software Analyst  Customer Support Engineer  Electronics and Communications Consultant  Research & Development Software Engineer  etc.Such Postgraduates may later pursue advanced courses in the subject such as Doctor of Philosophy (Ph.D.) in Digital Electronics.Some of the popular professional avenues open to successful Postgraduates of the course are listed below with the corresponding salaries offered for the respective positions:No Comments To ShowCOPYRIGHT © 2019 COLLEGEDUNIA WEB PVT. LTD. ALL RIGHTS RESERVED××Thanks for subscribing  You will be the first to recieve College related newsPlease check for mails in the SPAM folder of your mailbox.Keep up to date with our progress by following usPlease register to get more informationYOUR FULL NAMEYOUR EMAIL IDYOUR MOBILE NUMBERSELECT A COURSESELECT YOUR CITYENTER MESSAGE HERE...Interested in Distance Education Already registered? Click Here to loginSign In,communication systems, 'Personal computer',https://collegedunia.com/courses/master-of-technology-mtech-digital-electronics-and-communication-systems,'institute technology'
"                                                                     Error:  1 Chapter 3 Technology adapted 3.1 Introduction In developing a web enabled solution for laboratory data and document management  there are several options available for system analysis and designing  documentation and the software development. 3.2 System Analysis and design System Analysis and designing can be done either with Structured Systems Analysis & Design Method (SSADM) or Unified Modeling Language (UML) modeling [3  26]. Table 2: Comparison of SSADM and UML SSADM Data: Logical Data Model Class diagrams UML Events : Entity Life History Process: Data flow diagram Interfaces: Dialog design Quality: Requirement catalog Acceptability: Prototyping  study of system impact on the staff Organizational structure and policies: Project Initial Document Job satisfaction: Business system option User Involvement: Information gathering  testing Business Issues: Data Flow Diagrams  Entity Life History Interaction diagrams Activity diagrams Class and component diagrams Experimental/explorative prototype Prototyping Activity Diagram None Information gathering  testing Activity Diagram According to the above comparison  it is evident that the SSADM and UML are both effective in analysis and designing a system. However due to the academic interest  UML methodology was selected [27  32]. 282 3.3 Rational Unified Processes Rational Unified Process (RUP) is an object-oriented program development methodology [48]. It provides comprehensive software engineering tools that combine the procedural aspects of development (such as defined stages  techniques  and practices) with other components of development (such as documents  models  manuals  code  and so on) within a unifying framework. RUP establishes four phases of development  each of which is organized into a number of separate iterations that must satisfy defined criteria before the next phase is undertaken: in the inception phase  developers define the scope of the project and its business case; in the elaboration phase  developers analyze the project's needs in greater detail and define its architectural foundation; in the construction phase  developers create the application design and source code; and in the transition phase  developers deliver the system to users. RUP provides a prototype at the completion of each iteration. Rational Unified documentation was used in the project in appropriate circumstances. 3.4 Software development methodologies Following software development methodologies were reviewed during the development process [40]. Waterfall model: This waterfall model is an approach to development that emphasizes completing a phase of the development before proceeding to the next phase. In conjunction with certain phase completions  a baseline is established that freezes the products of the development at that point. If a need is identified to change these products  a formal change process is followed to make the change. The major weakness of the Waterfall Model is that after project requirements are gathered in the first phase  there is no formal way to make changes to the project as requirements change or more information becomes available to the project team. Because requirements almost always change during long development cycles  often the product that is implemented at the end of the process is obsolete as it goes into production. 293 Spiral Model: In the Spiral SDLC Model  the development team starts with a small set of requirements and goes through each development phase (except Installation and Maintenance) for those set of requirements. Based on lesson learned from the initial iteration (via a risk analysis process)  the development team adds functionality for additional requirements in ever-increasing ""spirals"" until the application is ready for the Installation and Maintenance phase (production). Each of the iterations prior to the production version is a prototype of the application. The advantage of the Spiral Model over the Waterfall Model is that the iterative approach allows development to begin even when all the system requirements are not known or understood by the development team. As each prototype is tested  user feedback is used to make sure the project is on track. The risk analysis step provides a formal method to ensure the project stays on track even if requirements do change. If new techniques or business requirements make the project unnecessary  it can be canceled before too many resources are wasted. Rapid Prototyping: Rapid Application Development (RAD) was introduced as a better way to add functionality to an application. The main new tenant of RAD compared to older models is the use of prototypes. After a quick requirements gathering phase  a prototype application is built and presented to the application users. Feedback from the user provides a loop to improve or add functionality to the application. Early RAD models did not involve the use of real data in the prototype  but new RAD implementations do use real data. The advantage of Rapid Prototyping Models is that time-to-market is greatly reduced. Rapid Prototyping skips many of the steps in traditional models in favor of fast and low-cost software development. The idea is that application software is a ""throw-away."" If a new version of the software is needed  it is developed from scratch using the newest RAD techniques and tools [29]. According to the user requirement of having several prototypes and few unclear user 304 requirements  spiral (iterative) development model was followed with the help of prototypes. 3.5 Web and Database technologies Since the system is designed to develop as a web enabled system  there are two web server technologies which can be used for the proposed system. Those are Apache HTTP web server and Apache Tomcat web server [8]. Both of these server solutions are of free and open source. So it may not hinder the open source distribution of the proposed software. Similarly both of these servers will function equally with MySQL open source database engine [35]. Since web development language selected was PHP (see below)  accordingly the web severer selected was Apache HTTP server Web development languages Web development options considered are PHP and Java (JSP and Servlets). ASP was not considered since it is a proprietary development solution [49  33]. Table 3: Comparison of web development languages Feature JSP PHP Programming Approach Completely object oriented Scripting with object oriented support String and data manipulation Rich library  too much descriptive and object oriented code Web Oriented features 1. Includes 2. Mails 3. File Uploads 4. Form Handling 5. Sessions Almost everything is built in or supported by libraries. Complicated and too much of code. Rich functionality. Functional and easy coding. Inbuilt functionality. Easy to use functions  written for the specific tasks 315 Database Access features Extensibility Standard JDBC structure/ Use EJB/ Struts framework built over JDBC. Descriptive and too much overhead or boiler plate code involved. Uses the same API for all databases using JDBC driver Java Classes and Libraries. Runs in sandbox and hard JNI approach needed to integrate with server programs Dynamic Graphics/PDF Almost everything has a ready made library Web Services/SOAP Add-on Libraries like Axis  JAX-WS  etc. Dedicated inbuilt libraries for most of the commonly used databases. Very tight integration with MySQL and PostGRESQL. The libraries and results are straight forward and easy to use. PHP can very easily interact with programs on the server. Very good support for native code. Supported internally or though libraries. In Built(or NuSOAP) Since the both solutions are open source  PHP was selected as it is more flexible and time saving solution [44  45]. 3.6 Client side form processing and data validation Client side data validation and form processing can minimize the workload on the server machine. This can improve the response time and save the band width of the LAN or internet. Java Script will be the suitable method for the client side data validation process. Summary For the purpose of system development  many software development process models  web server technologies and languages were considered. According to the requirements of the domain specialist and the time available for the development task  set of suitable models  technologies and languages were selected. Chapter 4 will show the how the decision was made among these choices. 32          Managing IT Projects Chapter 3 Software Project Life cycle The Systems Development Life Cycle (SDLC) The SDLC is composed of four fundamental phases: -Planning Analysis Design Implementation The Systems              Software Development Process and Activities CS 490MT/5555  Fall 2015  Yongjie Zheng Software Process } A set of activities that leads to the production of a software product } What product we should work              CHAPTER_3 SOFTWARE ENGINEERING (PROCESS MODELS) Prescriptive Process Model Defines a distinct set of activities  actions  tasks  milestones  and work products that are required to engineer high quality              Modeling Web Applications Using Java And XML Related Technologies Sam Chung Computing & Stware Systems Institute Technology University Washington Tacoma Tacoma  WA 98402. USA chungsa@u.washington.edu Yun-Sik              Apache Jakarta Tomcat 20041058 Suh  Junho Road Map 1 Tomcat Overview What we need to make more dynamic web documents? Server that supports JSP  ASP  database etc We concentrates on Something that support              Table of Contents 1. Introduction 1.1 Methodology 3 1.2 Purpose 4 1.3 Scope 4 1.4 Definitions  Acronyms and Abbreviations 5 1.5 Tools Used 6 1.6 References 7 1.7 Technologies to be used 7 1.8 Overview              Session # 3 Contents Systems Analysis and Design 2 1 Tiers of Software Development 10/4/2013 Information system development project Realistic behavior 3 Information system development project System Development              Agenda Software Process Models Plan-driven Process Models Software Process and Models A software process model simplified  abstracted description of a software development process. A model is good for              Analysis and Comparative Study of Traditional and Web Information Systems Development Methodology (WISDM) Towards Web Development Applications Abubucker Samsudeen Shaffi 1  Mohaned Al-Obaidy 2 1 Faculty              Connecting with Computer Science  2e Chapter 13 Software Engineering Objectives In this chapter you will: Learn how software engineering is used to create applications Learn some software engineering process              September Case Studies of Running the Platform NetBeans UML Servlet JSP GlassFish EJB In this project we display in the browser the Hello World  Everyone! message created in the session bean with servlets              Your Objects of SA&D Study Chapter 1 The Systems Development Environment 2011 by Prentice Hall: J.A.Hoffer et.al.  Modern Systems Analysis & Design  6 th Edition 1/55 2/55 Course Content Fundamental of              SOFTWARE ENGINEERING TRACK JAVA Technologies QUARTER 1 DESKTOP APPLICATIONS - ESSENTIALS Module 1 - Office Applications This subject enables users to acquire the necessary knowledge and skills to use Office              Fundamentals: Software Engineering Dr. Rami Bahsoon School of Computer Science The University Of Birmingham r.bahsoon@cs.bham.ac.uk www.cs.bham.ac.uk/~rzb Office 112 Y9- Computer Science Unit 1. Introduction              Technology review Chapter 3 3.1. Introduction Previous chapter covers detail description about problem domain. In this chapter I will discuss the technologies currently available to solve a problem in              3.0 Methodology 3.1 Introduction In this chapter  five software development life cycle models are compared and discussed briefly. The most suitable system methodology for the proposed system is drawn out.              Year 2014  Vol. 1  issue 1  pp. 49-56 Available online at: http://journal.iecuniversity.com TRADITIONAL VS MODERN SOFTWARE ENGINEERING MODELS: A REVIEW Singh RANDEEP a*  Rathee AMIT b a* Department of              Systems Analysis and Design Slides adapted from Jeffrey A. Hoffer  University of Dayton Joey F. George  Florida State University Joseph S. Valacich  Washington State University Modern Systems Analysis              CSI 2132 Lab 8 Web Programming JSP 1 Outline Web Applications Model View Controller Architectures for Web Applications Creation of a JSP application using JEE as JDK  Apache Tomcat as Server and Netbeans              Information Management Software Information Management Software How to make a good Software Requirement Specification(SRS) Click to add text TGMC 2011 Phases Registration SRS Submission Project Submission              Processing Models Of SDLC Mrs. Nalkar Sanjivani Baban Asst. Professor  IT/CS Dept  JVM s Mehta College Sector 19  Airoli  Navi Mumbai-400708 Nalkar_sanjivani@yahoo.co.in Abstract This paper presents an              Information system for production and mounting of plastic windows MARCEL  MELIŠ Slovak University of Technology - Faculty of Material Sciences and Technology in Trnava  Paulínska 16 street  Trnava  917              Logicify Fact Sheet Contacts Please feel free to contact us for any enquiry or question. Alexander Cherednichenko  CEO alexander.cherednichenko@logicify.com +380 50 8692570 (direct cell) Andrew Mazur               MDA Case Study: State of Wisconsin Unemployment Insurance Division MDA Implementers Workshop 2003 ATC Enterprises  Inc. 7402 Borman Avenue St. Paul  MN 55076 651.554.1771 www.atcenterprises.com Objectives              !!"" ""!! # $% "" & '$%(!%)* + $()' ""- Table of Contents Abstract...3 1.0 Introduction...4 2.0 Approach...5 2.1 Iteration I - Inception... 7 2.2 Iteration II Elaboration... 8 2.3 Iteration III - Construction              CS 487 Week 8 Reading: 1. Ian Sommerville  Chapter 3. Objective: 1. To check the understandibility of the students in life cycle and process model for development of a software product. 2. To check if              Name : Z A B Phone : 1-847-530-7013 Email : consultants@webspherehatsguru.com SUMMARY One & half year experience of technical experience in complete software development life cycle process which includes              S-Power GmbH S-Power Software Solutions Enterprise Class Software Solutions for Small- and Medium- Sized Business Environments at Breathtaking Price 17 th February 2006 Page 1 Offshore Software Development              Course Number: IAC-SOFT-WDAD Web Design and Application Development Session 1 (10 Hours) Client Side Scripting Session 2 (10 Hours) Server Side Scripting - I Session 3 (10 hours) Database Session 4 (10              NetBeans IDE Field Guide Copyright 2005 Sun Microsystems  Inc. All rights reserved. Table of Contents Introduction to J2EE Development in NetBeans IDE...1 Configuring the IDE for J2EE Development...2 Getting              In this Lecture you will Learn: Development Chapter 5C About the Unified Software Development How phases relate to workflows in an iterative life cycle An approach to system development Major activities              What is a life cycle model? Framework under which a software product is going to be developed. Defines the phases that the product under development will go through. Identifies activities involved in each              Department of Computer Science Institute for System Architecture  Chair for Computer Network Application Development for Mobile and Ubiquitous Computing igrocshop Seminar Task - Second Presentation Group              Slide 3.1 Development Methodologies Prof. Dr. Josef M. Joller jjoller@hsr.ch Development Methodologies Prof. Dr. Josef M. Joller 1 Session 3 Slide 3.2 SOFTWARE LIFE-CYCLE MODELS Development Methodologies              Specialized Programme on Web Application Development using Open Source Tools A. NAME OF INSTITUTE Centre For Development of Advanced Computing B. NAME/TITLE OF THE COURSE C. COURSE DATES WITH DURATION              Specialized Programme on Web Application Development using Open Source Tools Objective: At the end of the course  Students will be able to: Understand various open source tools(programming tools and databases)              Eclectic Computing Time Tracking Tool Version  Revision History Date Version Description Author 7/Mar/05 1.0 Documentation of high-level architecture. David Janzen 7/Apr/05 1.1 Architecture at end              The Rap on RUP : An Introduction to the Rational Unified Process Jeff Jacobs Jeffrey Jacobs & Associates phone: 650.571.7092 email: jeff@jeffreyjacobs.com http://www.jeffreyjacobs.com Survey Does your              Evolving Ideas Computing  Communication and Networking Publish by Global Vision Publishing House Edited by Jeetendra Pande Nihar Ranjan Pande Deep Chandra Joshi Requirements Analysis (RA): An Analytical              Architectural Overview CatDV Pro Workgroup Server Square Box Systems Ltd May 2003 The CatDV Pro client application is a standalone desktop application  providing video logging and media cataloging capability              Chap 1. Introduction to Software Architecture 1. Introduction 2. IEEE Recommended Practice for Architecture Modeling 3. Architecture Description Language: the UML 4. The Rational Unified Process (RUP)              In This Presentation: What are DAMS? Terms Why use DAMS? DAMS vs. CMS How do DAMS work? Key functions of DAMS DAMS and records management DAMS and DIRKS Examples of DAMS Questions Resources What are DAMS?              Put a Firewall in Your JVM Securing Java Applications! Prateep Bandharangshi"" Waratek Director of Client Security Solutions"" @prateep"" Hussein Badakhchani"" Deutsche Bank Ag London Vice President"" @husseinb""              UNIT I J2EE Platform 9 Introduction - Enterprise Architecture Styles - J2EE Architecture - Containers - J2EE Technologies - Developing J2EE Applications - Naming and directory services - Using JNDI - JNDI              Productivity Comparison for Building Applications and Web Services Between The Virtual Enterprise  BEA WebLogic Workshop and IBM WebSphere Application Developer Prepared by Intelliun Corporation CONTENTS              2014 COURSE CATALOG SECURITY COURSES Advanced Ethical Hacking Secure Android Development Secure ios Development C/C++ Programming Security Complete Windows Security Cryptography Overview Designing Secure              Project estimation with Use Case Points using Enterprise Architect (EA) Step by Step Guide: How to use Enterprise Architect (EA) as a CASE tool to facilitate calculating Use Case Points for software projects              Unit I Introduction Product Life Cycles Products also have life cycles The Systems Development Life Cycle (SDLC) is a framework for describing the phases involved in developing and maintaining information              Software Processes Objectives To introduce software process models To describe three generic process models and when they may be used To describe outline process models for requirements engineering  software              White Paper IT Methodology Overview & Context IT Methodologies - Delivery Models From the inception of Information Technology (IT)  organizations and people have been on a constant quest to optimize the              A Cost Effective Approach to Develop Mid-size Enterprise Software Adopted the Waterfall Model 17th International Conference on Computer Science and Information Engineering (ICCSIE 2015) Mohammad Nehal              Ob j ect-oriented Project Management with UML Murray Cantor WILEY COMPUTER PUBLISHING John Wiley & Sons  Inc. New York Chichester Weinheim Brisbane Singapore Toronto CONTENTS Acknowledgments Introduction              Software Engineering Software Processes Based on Software Engineering  7 th Edition by Ian Sommerville Objectives To introduce software process models To describe three generic process models and when              Fundamentals of Information Systems  Fifth Edition Chapter 8 Systems Development Principles and Learning Objectives Effective systems development requires a team effort of stakeholders  users  managers               Equipment Room Database and Web-Based Inventory Management System Block Diagram Sean M. DonCarlos Ryan Learned Advisors: Dr. James H. Irwin Dr. Aleksander Malinowski November 4  2002 System Overview The              Lifecycle Planning Rapid Development & Software Project Survival Guide Steve McConnell Dave Root (Developed with Mel Rosso-Llopart) Version 1.4 David Root  2005  all rights reserved 1 Topics Who am I to              Ingegneria del Software Corso di Laurea in Informatica per il Management Software process model Davide Rossi Dipartimento di Informatica Università di Bologna The task of the software development team              Chapter 1 System Development Environment Definition Information systems analysis and design: The organizational process to develop computer-based information systems. History In the early years of computing               Software Engineering Prof. N. L. Sarda Computer Science & Engineering Indian Institute of Technology  Bombay Lecture - 2 Introduction to Software Engineering Challenges  Process Models etc (Part 2) This              Ruby on Rails a high-productivity web application framework http://blog blog.curthibbs.us/ Curt Hibbs  Agenda What is Ruby? What is Rails? Live Demonstration (sort of ) Metrics for Production              Internship Report Master of Software Engineering (2012-2014) Integrating Online Banking and Top-up Card into Payment Gateway Author: DAO Nguyen Vu Supervisor: HO Hoang Thuong January 11  2015 Acknowledgment              A Comparison of Software Architectures for E-Business Applications Emmanuel Cecchet  Anupam Chanda  Sameh Elnikety  Juli Marguerite and Willy Zwaenepoel Rice University Department of Computer Science Dynamic              CS 389 Software Engineering Lecture 2 Chapter 2 Software Processes Adapted from: Chap 1. Sommerville 9 th ed. Chap 1. Pressman 6 th ed. Topics covered Software process models Process activities Coping              Database Application Design and Development Virtually all real-world user interaction with databases is indirect it is mediated through an application A database application effectively adds additional              Introduction to Systems Analysis and Design What is a System? A system is a set of interrelated components that function together to achieve a common goal. The components of a system are called subsystems.              Jonathan ROUSSEAU 27 years old (3 rd of February 1983) Bruyères  15/A 4950 Waimes +32 (473) 69 82 42 Jrousseau.webco@gmail.com http://www.jrousseau.be Java/J2EE or Web Developer Formal Education 2000:              Software Development Life Cycle (SDLC) Supriyo Bhattacharjee MOF  Capability Maturity Model (CMM) A bench-mark for measuring the maturity of an organization s software process CMM defines 5 levels of process              CS4507 Advanced Software Engineering Lectures 2 & 3: Software Development Lifecycle Models A O Riordan  2015 Some diagrams from Sommerville  some notes from Maciaszek/Liong Lifecycle Model Software development                pp. 213-220 http://dx.doi.org/10.14257/ijseia.2014.8.10.19 A Review of an MVC Framework based Software Development Ronnie D. Caytiles and Sunguk Lee * Department of Multimedia Engineering  Hannam University              SERBIAN JOURNAL OF ELECTRICAL ENGINEERING Vol. 1  No. 1  November 2003  81-87 Principles and Software Realization of a Multimedia Course on Theoretical Electrical Engineering Based on Enterprise Technology              Information Technology Services ""improve your business performance with custom software solutions"" ISO 90001:2008 Quality Management System Certified Company About Providence Providence is a well-established              Java Application Developer Certificate Program Competencies After completing the following units  you will be able to: Basic Programming Logic Explain the steps involved in the program development cycle              Exam Name MULTIPLE CHOICE. Choose the one alternative that best completes the statement or answers the question. 1) Which of the following requires a systems development method that uses a data orientation              Systems Analysis and Design (Compulsory) BIT 1 st YEAR SEMESTER 2 INTRODUCTION This is one of the 4 courses designed for Semester 1 of Bachelor of Information Technology Degree program. CREDITS: 04 LEARNING              Software Life Cycle Main issues: Discussion of different life cycle models Maintenance or evolution Not this life cycle SE  Software Lifecycle  Hans van Vliet  2008 2 Introduction software development              Internet Engineering Tomasz Babczyński  Zofia Kruczkiewicz Tomasz Kubik Information systems modelling UML and service description languages Student Contact Hours: 25.02.2015- Location: 325 C3 room 25.03.2015:              Modern Software Development Tools on OpenVMS Meg Watson Principal Software Engineer 2006 Hewlett-Packard Development Company  L.P. The information contained herein is subject to change without notice Topics              UNIVERSITY OF ILLINOIS AT CHICAGO University of Illinois Ready Kuali Ready & University of Illinois Ready Web-Based System adopted by all three campuses of the University of Illinois system Step by step              Basic Unified Process: A Process for Small and Agile Projects Ricardo Balduino - Rational Unified Process Content Developer  IBM Introduction Small projects have different process needs than larger projects.              Available Online at www.ijcsmc.com International Journal of Computer Science and Mobile Computing A Monthly Journal of Computer Science and Information Technology IJCSMC  Vol. 4  Issue. 2  February 2015               Zeus Networks Company Portfolio Software Development Portfolio C3 Locale Led a team of developers that developed a campaign management solution for managing election campaigns. This software uses Geographical              Software Development Process Models and their Impacts on Requirements Engineering Organizational Requirements Engineering Prof. Dr. Armin B. Cremers Sascha Alda Overview Phases during Software Development              Summary 165620 Male  July 16th 1975 Professional Profile Studies Senior Engineer October 1993 - September 1998 Computer Engineering University of Deusto - Bizkaia (Spain) EHEA Postgraduate (Master) Software              Application Development Services for Cloud 1. Document Purpose This document describes the G-Cloud J2EE and Application Development Services for Cloud provisioning offering by Vouchcom. 2. J2EE and Java              Using Simulation to teach project management skills Dr. Alain April  ÉTS Montréal alain.april@etsmtl.ca Agenda of the workshop 1 The software project management theory overview (40 minutes) 2 Why use SDLC              A complete software development process of a general report publication service implemented using Web Services Anders Nilsson & Klas Fahlberg February 1  2008 Master s Thesis in Computing Science  2*30              A Monitored Student Testing Application Using Cloud Computing R. Mullapudi and G. Hsieh Department of Computer Science  Norfolk State University  Norfolk  Virginia  USA r.mullapudi@spartans.nsu.edu  ghsieh@nsu.edu              Migrating Applications From IBM WebSphere to Apache Tomcat MuleSource and the MuleSource logo are trademarks of MuleSource Inc. in the United States and/or other countries. All other product and company              Sports Management Information Systems Camilo Rostoker November 22  2002 Introduction We are in the information age The availability of technology has brought forth a new problem domain how do we manage              Syllabus INFO-UB-3322 Design and Development of Web and Mobile Applications (Especially for Start Ups) Fall 2014 Stern School of Business Norman White  KMEC 8-88 Email: nwhite@stern.nyu.edu Phone: 212-998              The ITB Journal Volume 3 Issue 2 Article 2 2002 Virtual Credit Card Processing System Geraldine Gray Karen Church Tony Ayres Follow this and additional works at: http://arrow.dit.ie/itbj Part of the E-Commerce              Net Developer We are seeking a skilled ASP.NET/VB.NET developer with a background in building scalable  predictable  high-quality and high-performance web applications on the Microsoft technology stack.              6. Software Lifecycle Models A software lifecycle model is a standardised format for planning organising  and running a new development project. Hundreds of different kinds of models are known and used.              General Problem Solving Model Software Development Methodology These focus on understanding what the problem is about Chapter 2A Concerned with understanding more about the nature of the problem and possible              Page 1 A. Title Client/Server Technology B. Introduction Client/server is a network architecture that divides functions into client and server subsystems  with standard communication methods to facilitate              Software Development Methodologies Lecturer: Raman Ramsin Lecture 15 Agile Methodologies: AUP 1 Agile Unified Process (AUP) Proposed by Ambler as a simplified version of the Rational Unified Process (RUP).              ISSUES OF STRUCTURED VS. OBJECT-ORIENTED METHODOLOGY OF SYSTEMS ANALYSIS AND DESIGN Mohammad A. Rob  University of Houston-Clear Lake  rob@cl.uh.edu ABSTRACT In recent years  there has been a surge of              A review and analysis of technologies for developing web applications Asha Mandava and Solomon Antony Murray state University Murray  Kentucky Abstract In this paper we review technologies useful for design              Software Design Models  Tools & Processes * Lecture 1: Software Design and Software Development Process Cecilia Mascolo * Thanks to Alan Blackwell and Jim Arlow for le7ng me use some of their slides. About              www.ijcsi.org 106 A Comparison Between Three SDLC Models Waterfall Model  Spiral Model  and Incremental/Iterative Model Adel Alshamrani 1 and Abdullah Bahattab 2 1 Ira A. Fulton Schools of Engineering    ",development life cycle ( sdlc ), 'Personal computer',https://docplayer.net/14181592-Chapter-3-technology-adapted.html,'institute technology'
Loading PreviewSorry  preview is currently unavailable. You can download the paper by clicking the button above.Enter the email address you signed up with and we'll email you a reset link.,earliest start time, 'Personal computer',http://www.academia.edu/35075757/Novel_Approaches_for_Scheduling_Task_Graphs_in_Heterogeneous_Distributed_Computing_Environment,'institute technology'
"Download presentationWe think you have liked this presentation. If you wish to download it  please recommend it to your friends in any social system. Share buttons are a little bit lower. Thank you!Buttons: Presentation is loading. Please wait.                                                 To view this video please enable JavaScript  and consider upgrading to a web browser that                                                 supports HTML5 video This is a modal window.Beginning of dialog window. Escape will cancel and close the window.End of dialog window.Published byDennis Todd Modified over 3 years ago FPA – IFPUG CPM 4.1 Rules.SOFTWARE TESTING. INTRODUCTION  Software Testing is the process of executing a program or system with the intent of finding errors.  It involves any.                       1                  Software Metrics Software Engineering  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/1/Software+Metrics+Software+Engineering.jpg""      ""name"": ""Software Metrics Software Engineering""      ""description"": ""Software Metrics Software Engineering""      ""width"": ""800"" }                         2                  Definitions Measure – the process of assigning numbers to attributes of entities according to some defined rules. E.g.  Number of errors Metric – The continuous application of the measurement based techniques to the software development processes and products to supply meaningful information together with use of those techniques to improve software development process and its products E.g.  Number of errors found per person  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/2/Definitions+Measure+%E2%80%93+the+process+of+assigning+numbers+to+attributes+of+entities+according+to+some+defined+rules..jpg""      ""name"": ""Definitions Measure – the process of assigning numbers to attributes of entities according to some defined rules.""      ""description"": ""E.g.  Number of errors. Metric – The continuous application of the measurement based techniques to the software development processes and products to supply meaningful information together with use of those techniques to improve software development process and its products. E.g.  Number of errors found per person.""      ""width"": ""800"" }                         3                  Software Metrics Measurement Based Techniques Applied to To SupplyProcesses  Products and Services Engineering and Management Information To Improve  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/3/Software+Metrics+Measurement+Based+Techniques+Applied+to+To+Supply.jpg""      ""name"": ""Software Metrics Measurement Based Techniques Applied to To Supply""      ""description"": ""Processes  Products and Services. Engineering and Management Information. To Improve.""      ""width"": ""800"" }                         4                  Why Measure Software? Determine the quality of the current product or process Predict qualities of a product/process Improve quality of a product/process  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/4/Why+Measure+Software+Determine+the+quality+of+the+current+product+or+process.+Predict+qualities+of+a+product%2Fprocess..jpg""      ""name"": ""Why Measure Software Determine the quality of the current product or process. Predict qualities of a product/process.""      ""description"": ""Improve quality of a product/process.""      ""width"": ""800"" }                         5                  Types of Measures Direct Measures (internal attributes)Cost  effort  LOC (lines of code)  speed  memory size and defects reported over set period of time. Indirect Measures (external attributes) Functionality  quality  complexity  efficiency  reliability  maintainability More difficult to assess  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/5/Types+of+Measures+Direct+Measures+%28internal+attributes%29.jpg""      ""name"": ""Types of Measures Direct Measures (internal attributes)""      ""description"": ""Cost  effort  LOC (lines of code)  speed  memory size and defects reported over set period of time. Indirect Measures (external attributes) Functionality  quality  complexity  efficiency  reliability  maintainability. More difficult to assess.""      ""width"": ""800"" }                         6                  Motivation for MetricsEstimate the cost & schedule of future projects Evaluate the productivity impacts of new tools and techniques Establish productivity trends over time Improve software quality Forecast future staffing needs Anticipate and reduce future maintenance needs  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/6/Motivation+for+Metrics.jpg""      ""name"": ""Motivation for Metrics""      ""description"": ""Estimate the cost &amp;amp; schedule of future projects. Evaluate the productivity impacts of new tools and techniques. Establish productivity trends over time. Improve software quality. Forecast future staffing needs. Anticipate and reduce future maintenance needs.""      ""width"": ""800"" }                         7                  Metric ClassificationProduct Metrics Describe the characteristics of the product  such as size  complexity  design features  performance  efficiency  reliability  portability etc. Process Metrics Activities related to production of software like effort required in the process  time to produce the product  number of defects found during testing  effectiveness of defect removal during development  maturity of the process Project Metrics Describe the project characteristics and execution like number of software developers  cost and schedule  productivity  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/7/Metric+Classification.jpg""      ""name"": ""Metric Classification""      ""description"": ""Product Metrics. Describe the characteristics of the product  such as size  complexity  design features  performance  efficiency  reliability  portability etc. Process Metrics. Activities related to production of software like effort required in the process  time to produce the product  number of defects found during testing  effectiveness of defect removal during development  maturity of the process. Project Metrics. Describe the project characteristics and execution like number of software developers  cost and schedule  productivity.""      ""width"": ""800"" }                         8                  Attributes of Effective Software MetricsSimple and Computable Consistent and objective Consistent in the use of units and dimensions Programming language independent An effective mechanism for high – quality feedback  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/8/Attributes+of+Effective+Software+Metrics.jpg""      ""name"": ""Attributes of Effective Software Metrics""      ""description"": ""Simple and Computable. Consistent and objective. Consistent in the use of units and dimensions. Programming language independent. An effective mechanism for high – quality feedback.""      ""width"": ""800"" }                         9                  Halstead's Software Science MetricsIt is an analytical technique to measure size  development effort and development cost of software products. Halstead used a few primitive program parameters to develop the expressions for overall program length  potential minimum value  actual volume  effort and development time.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/9/Halstead+s+Software+Science+Metrics.jpg""      ""name"": ""Halstead s Software Science Metrics""      ""description"": ""It is an analytical technique to measure size  development effort and development cost of software products. Halstead used a few primitive program parameters to develop the expressions for overall program length  potential minimum value  actual volume  effort and development time.""      ""width"": ""800"" }                         10                  Halstead's Software Science MetricsHalstead (researcher) proposed that program may be considered as a collection of lexical tokens  each of which can be classified as operator or operand. Operands are the tokens which have value. Data variables and constants therefore constitute the operands. Operators are commas  parenthesis  keywords  arithmetic operators  functions and so on. Tokens that appear in pairs are counted as one token eg. ""begin...end""  ""repeat...until“ etc  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/10/Halstead+s+Software+Science+Metrics.jpg""      ""name"": ""Halstead s Software Science Metrics""      ""description"": ""Halstead (researcher) proposed that program may be considered as a collection of lexical tokens  each of which can be classified as operator or operand. Operands are the tokens which have value. Data variables and constants therefore constitute the operands. Operators are commas  parenthesis  keywords  arithmetic operators  functions and so on. Tokens that appear in pairs are counted as one token eg. begin...end   repeat...until etc.""      ""width"": ""800"" }                         11                  Halstead's Software Science MetricsPrimitive Measures proposed by Halstead are: the number of unique operators in program the number of unique operands in program N1 = total count of all operators in program. N2 = total count of all operands in program.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/11/Halstead+s+Software+Science+Metrics.jpg""      ""name"": ""Halstead s Software Science Metrics""      ""description"": ""Primitive Measures proposed by Halstead are: the number of unique operators in program. the number of unique operands in program. N1 = total count of all operators in program. N2 = total count of all operands in program.""      ""width"": ""800"" }                         12                  Halstead's Software Science Metrics - MeasuresHalstead length : Total number of operators and operands in a program Vocabulary :  Defined as the sum of the number of unique operands and operators used in the program Estimated Program Length : This value can be estimated before the program is written. Program Volume : is the minimum number of bits needed to encode the program  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/12/Halstead+s+Software+Science+Metrics+-+Measures.jpg""      ""name"": ""Halstead s Software Science Metrics - Measures""      ""description"": ""Halstead length : Total number of operators and operands in a program. Vocabulary : Defined as the sum of the number of unique operands and operators used in the program. Estimated Program Length : This value can be estimated before the program is written. Program Volume : is the minimum number of bits needed to encode the program.""      ""width"": ""800"" }                         13                  Halstead's Software Science Metrics - MeasuresEffort Equation : The effort  E required to implement the program P is Effort = (n1N2/2n2) (Nlog2n) It correlates with the effort needed for maintenance for small programs. Unit for effort is elementary mental discriminators (emd). Time Equation: Halstead also estimated the time T required to implement the program as T = (E/18) seconds  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/13/Halstead+s+Software+Science+Metrics+-+Measures.jpg""      ""name"": ""Halstead s Software Science Metrics - Measures""      ""description"": ""Effort Equation : The effort E required to implement the program P is. Effort = (n1N2/2n2) (Nlog2n) It correlates with the effort needed for maintenance for small programs. Unit for effort is elementary mental discriminators (emd). Time Equation: Halstead also estimated the time T required to implement the program as. T = (E/18) seconds.""      ""width"": ""800"" }                         14                  Halstead's Software Science Metrics - AdvantagesSimple to calculate Do not require in depth analysis of programming structure Measure overall quality of programs Predicts maintenance effort Useful in scheduling the projects  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/14/Halstead+s+Software+Science+Metrics+-+Advantages.jpg""      ""name"": ""Halstead s Software Science Metrics - Advantages""      ""description"": ""Simple to calculate. Do not require in depth analysis of programming structure. Measure overall quality of programs. Predicts maintenance effort. Useful in scheduling the projects.""      ""width"": ""800"" }                         15                  Q. Consider the program code given belowint sum  i; sum = 0; for (i=1; i<=20; i++) sum = sum  + i; printf(sum); For this program compute Halstead software science metrics n1  n2 N1  N2 n V E and T.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/15/Q.+Consider+the+program+code+given+below.jpg""      ""name"": ""Q. Consider the program code given below""      ""description"": ""int sum  i; sum = 0; for (i=1; i&amp;lt;=20; i++) sum = sum + i; printf(sum); For this program compute Halstead software science metrics n1 n2 N1 N2 n V E and T.""      ""width"": ""800"" }                         16                  Halstead's Software Science Metrics - ExampleList of Operators : List of Operands : PROGRAM Int sum i; Sum = 0; For (i=1; i<=20; i++) sum = sum  + i; Printf(sum); Operator frequency Int 1   ; 6 = 3 () 2 <= ++ For + Printf Operands frequency Sum 5 i 1 20  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/16/Halstead+s+Software+Science+Metrics+-+Example.jpg""      ""name"": ""Halstead s Software Science Metrics - Example""      ""description"": ""List of Operators : List of Operands : PROGRAM. Int sum i; Sum = 0; For (i=1; i&amp;lt;=20; i++) sum = sum + i; Printf(sum); Operator. frequency. Int. 1.   ; 6. = 3. () 2. &amp;lt;= ++ For. + Printf. Operands. frequency. Sum. 5. i""      ""width"": ""800"" }                         17                  Halstead's Software Science Metrics - Examplen1 = number of distinct operators = 10 n2 = number of distinct operands = 5 N1 = total number of operator  occurrences = 18 N2 = total number of operand  occurrences = 13 Vocabulary (n) of program = n1 + n2 = 15 Length of the program  = N1 + N2 = 31 Estimated Program Length : n1log2n1 + n2log2n2 = 10log log25 = 10* *2.32 = 44.8 4. Volume (V) = Nlog2n = 31 log215 = 31*3.91 = bits  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/17/Halstead+s+Software+Science+Metrics+-+Example.jpg""      ""name"": ""Halstead s Software Science Metrics - Example""      ""description"": ""n1 = number of distinct operators = 10. n2 = number of distinct operands = 5. N1 = total number of operator occurrences = 18. N2 = total number of operand occurrences = 13. Vocabulary (n) of program = n1 + n2 = 15. Length of the program = N1 + N2 = 31. Estimated Program Length : n1log2n1 + n2log2n2. = 10log log25 = 10* *2.32 = Volume (V) = Nlog2n = 31 log215 = 31*3.91 = bits.""      ""width"": ""800"" }                         18                  Halstead's Software Science Metrics - Examplen1 = number of distinct operators = 10 n2 = number of distinct operands = 5 N1 = total number of operator  occurrences = 18 N2 = total number of operand  occurrences = 13 5. Effort = (n1N2/2n2) (Nlog2n) = ((10*13)/(2*5))(31log215) = emd 6. Time = E/18 = /18 = seconds  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/18/Halstead+s+Software+Science+Metrics+-+Example.jpg""      ""name"": ""Halstead s Software Science Metrics - Example""      ""description"": ""n1 = number of distinct operators = 10. n2 = number of distinct operands = 5. N1 = total number of operator occurrences = 18. N2 = total number of operand occurrences = Effort = (n1N2/2n2) (Nlog2n) = ((10*13)/(2*5))(31log215) = emd. 6. Time = E/18 = /18 = seconds.""      ""width"": ""800"" }                         19                  Size-Oriented Metrics - LOCLOC - Lines Of Code is the simplest among all metrics available to estimate project size. KLOC Lines Of Code SLOC – Statement Lines of Code  (ignore whitespace) Project size is estimated by counting the number of source instructions in the developed program. Typical Measures: Errors/KLOC  Defects/KLOC  Cost/LOC  Documentation Pages/KLOC  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/19/Size-Oriented+Metrics+-+LOC.jpg""      ""name"": ""Size-Oriented Metrics - LOC""      ""description"": ""LOC - Lines Of Code is the simplest among all metrics available to estimate project size. KLOC Lines Of Code. SLOC – Statement Lines of Code (ignore whitespace) Project size is estimated by counting the number of source instructions in the developed program. Typical Measures: Errors/KLOC  Defects/KLOC  Cost/LOC  Documentation Pages/KLOC.""      ""width"": ""800"" }                         20                  Size Metric- Lines of Code(LOC)The basic and simplest metric for the size is Lines of code(LOC) often quoted in 1000’s (KLOC). In a real sense this metric measures the length of a program which is a logical characteristic but not size which is physical characteristic of the program. While number of lines  normally researchers are of the view that comments and blank lines should not be counted. Comments used in the program make the program understandable and easier to maintain but effort required for writing the comments is not as much as writing the code. According to some researchers LOC mat be computed by counting the new-line characters in the program. This metric can also be used in other indirect measures as well  such as Productivity = LOC/Effort  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/20/Size+Metric-+Lines+of+Code%28LOC%29.jpg""      ""name"": ""Size Metric- Lines of Code(LOC)""      ""description"": ""The basic and simplest metric for the size is Lines of code(LOC) often quoted in 1000’s (KLOC). In a real sense this metric measures the length of a program which is a logical characteristic but not size which is physical characteristic of the program. While number of lines  normally researchers are of the view that comments and blank lines should not be counted. Comments used in the program make the program understandable and easier to maintain but effort required for writing the comments is not as much as writing the code. According to some researchers LOC mat be computed by counting the new-line characters in the program. This metric can also be used in other indirect measures as well  such as Productivity = LOC/Effort""      ""width"": ""800"" }                         21                  LOC Metrics Advantages Disadvantages Easy to use Easy to computeLanguage & programmer dependent Bad software design may cause excessive line of code Defined on code User cannot easily understand it  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/21/LOC+Metrics+Advantages+Disadvantages+Easy+to+use+Easy+to+compute.jpg""      ""name"": ""LOC Metrics Advantages Disadvantages Easy to use Easy to compute""      ""description"": ""Language &amp;amp; programmer dependent. Bad software design may cause excessive line of code. Defined on code. User cannot easily understand it.""      ""width"": ""800"" }                         22                  Measuring Functionality – Function Point Analysis (FPA)FPA is a popular method which uses complexity and the number of functions supported by the software to compute the size of the software in terms of Function Point Count (FPC). Concept : the size of the software being developed is directly proportional to the number of functions it will support. Each of these functions are characterized by the inputs taken  outputs given  interfaces and the number of files used. All these factors contribute in calculating total function points.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/22/Measuring+Functionality+%E2%80%93+Function+Point+Analysis+%28FPA%29.jpg""      ""name"": ""Measuring Functionality – Function Point Analysis (FPA)""      ""description"": ""FPA is a popular method which uses complexity and the number of functions supported by the software to compute the size of the software in terms of Function Point Count (FPC). Concept : the size of the software being developed is directly proportional to the number of functions it will support. Each of these functions are characterized by the inputs taken  outputs given  interfaces and the number of files used. All these factors contribute in calculating total function points.""      ""width"": ""800"" }                         23                  Flowchart for computing Function PointsStart Specify the Functional Requirement Project Count Data Function Type and Transaction Function Type Compute Unadjusted Function Point (UFP) Apply General Characteristics Compute Value Adjustment Factor (VAF) Adjusted Compute Function Point from UFP and VAF End  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/23/Flowchart+for+computing+Function+Points.jpg""      ""name"": ""Flowchart for computing Function Points""      ""description"": ""Start. Specify the Functional Requirement Project. Count Data Function Type and Transaction Function Type. Compute Unadjusted Function Point (UFP) Apply General Characteristics. Compute Value Adjustment Factor (VAF) Adjusted Compute Function Point from UFP and VAF. End.""      ""width"": ""800"" }                         24                  Steps for Computing Function PointsIdentify and Count following functions : External Inputs (EI) : user or control data entering the system. External Outputs (EO) : user or control data coming out of the system. External Inquiries (EIQ) : they do not change the system data. They represent input – output combination. Internal Files (IF) : maintained and understood by customers External Interface (EIF) : files which are shared by the system and other programs. They are not maintained by the software.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/24/Steps+for+Computing+Function+Points.jpg""      ""name"": ""Steps for Computing Function Points""      ""description"": ""Identify and Count following functions : External Inputs (EI) : user or control data entering the system. External Outputs (EO) : user or control data coming out of the system. External Inquiries (EIQ) : they do not change the system data. They represent input – output combination. Internal Files (IF) : maintained and understood by customers. External Interface (EIF) : files which are shared by the system and other programs. They are not maintained by the software.""      ""width"": ""800"" }                         25                  Steps for Computing Function PointsCalculate Unadjusted Function Points : Identify the complexity level of data function type and transaction function type Their complexity depends on the number of data element types and file types referenced. Once the unadjusted function points are computed   then based on their complexity level they are multiplied by the weighing factors as follows: Simple Average Complex EI 3 4 6 EO 5 7 EIQ IF 10 15 EIF  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/25/Steps+for+Computing+Function+Points.jpg""      ""name"": ""Steps for Computing Function Points""      ""description"": ""Calculate Unadjusted Function Points : Identify the complexity level of data function type and transaction function type. Their complexity depends on the number of data element types and file types referenced. Once the unadjusted function points are computed  then based on their complexity level they are multiplied by the weighing factors as follows: Simple. Average. Complex. EI EO EIQ. IF EIF.""      ""width"": ""800"" }                         26                  Steps for Computing Function PointsApply 14 general characteristics : The 14 characteristics are : data communications  performance  transaction rate  processing  reusability  end user efficiency  online update  configuration  multiple sites  operations  change requirements  distributed processing  online data entry and installation. These characteristics have rating 0 – 5 which influence Function Point Count (FPC) Sum of these 14 general characteristics rating can be between 0 – 70 and is called Total Degree of Influence (TDI)  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/26/Steps+for+Computing+Function+Points.jpg""      ""name"": ""Steps for Computing Function Points""      ""description"": ""Apply 14 general characteristics : The 14 characteristics are : data communications  performance  transaction rate  processing  reusability  end user efficiency  online update  configuration  multiple sites  operations  change requirements  distributed processing  online data entry and installation. These characteristics have rating 0 – 5 which influence Function Point Count (FPC) Sum of these 14 general characteristics rating can be between 0 – 70 and is called Total Degree of Influence (TDI)""      ""width"": ""800"" }                         27                  Steps for Computing Function PointsCompute the Value Adjustment Factor (VAF) VAF = (TDI * 0.01) Calculate Function Point count (FPC) FPC = UFP * VAF FP are not suitable for algorithmically intensive systems such as embedded systems and real time systems. In such type of systems function points called feature points are used for estimating the size.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/27/Steps+for+Computing+Function+Points.jpg""      ""name"": ""Steps for Computing Function Points""      ""description"": ""Compute the Value Adjustment Factor (VAF) VAF = (TDI * 0.01) Calculate Function Point count (FPC) FPC = UFP * VAF. FP are not suitable for algorithmically intensive systems such as embedded systems and real time systems. In such type of systems function points called feature points are used for estimating the size.""      ""width"": ""800"" }                         28                  Advantages of Function Point TechniqueFunction Points(FP) can be computed early in the project and are directly derived from SRS. FP are independent of the technology (ie. Programming languages  database etc. ) used to develop the software. It can be used as a technique to measure the productivity of the projects written in different languages.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/28/Advantages+of+Function+Point+Technique.jpg""      ""name"": ""Advantages of Function Point Technique""      ""description"": ""Function Points(FP) can be computed early in the project and are directly derived from SRS. FP are independent of the technology (ie. Programming languages  database etc. ) used to develop the software. It can be used as a technique to measure the productivity of the projects written in different languages.""      ""width"": ""800"" }                         29                  Function Point Technique - ExampleConsider a project with following data: Number of external inputs with low complexity = 10 Number of external inputs with high complexity = 10 Number of external outputs with average complexity = 15 Number of external inquiries with average complexity = 13 Number of internal logical files with high complexity = 2 Number of internal logical files with low complexity = 2 Number of external interface files with average complexity = 7 The system has a very high transaction rate and supports several multiple communication protocols. Calculate the unadjusted as well as adjusted function points.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/29/Function+Point+Technique+-+Example.jpg""      ""name"": ""Function Point Technique - Example""      ""description"": ""Consider a project with following data: Number of external inputs with low complexity = 10 Number of external inputs with high complexity = 10 Number of external outputs with average complexity = 15 Number of external inquiries with average complexity = 13 Number of internal logical files with high complexity = 2 Number of internal logical files with low complexity = 2 Number of external interface files with average complexity = 7 The system has a very high transaction rate and supports several multiple communication protocols. Calculate the unadjusted as well as adjusted function points.""      ""width"": ""800"" }                         30                  Function Point Technique - ExampleSolution: Total unadjusted function points (UFP) after considering the weighting factors are given by : UFP = 3 * * * * * * * 7 = = 310 The software also supports high transaction rate and multiple communication protocols. Hence these two system characteristics can be assigned a rating of 5. TDI = =10 VAF = (TDI * 0.01) = (10 * 0.01) = 0.75 Adjusted function points FPC = UFP * VAF = 310 * 0.75 = 232.5  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/30/Function+Point+Technique+-+Example.jpg""      ""name"": ""Function Point Technique - Example""      ""description"": ""Solution: Total unadjusted function points (UFP) after considering the weighting factors are given by : UFP = 3 * * * * * * * 7 = = 310 The software also supports high transaction rate and multiple communication protocols. Hence these two system characteristics can be assigned a rating of 5. TDI = =10 VAF = (TDI * 0.01) = (10 * 0.01) = 0.75 Adjusted function points FPC = UFP * VAF = 310 * 0.75 =""      ""width"": ""800"" }                         31                  McCabe’s Cyclomatic Complexity MetricIt is a metric to measure logical complexity of the program. McCabe’s metrics are based on a control flow representation of the program. It defines the number of independent paths in the program to be executed in order to ensure that all statements in the program are executed at least once. In  other words it gives us the value for maximum number of est cases to be designed. A program graph is used to depict control flow. Nodes represent processing tasks (one or more code statements) Edges represent control flow between nodes  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/31/McCabe%E2%80%99s+Cyclomatic+Complexity+Metric.jpg""      ""name"": ""McCabe’s Cyclomatic Complexity Metric""      ""description"": ""It is a metric to measure logical complexity of the program. McCabe’s metrics are based on a control flow representation of the program. It defines the number of independent paths in the program to be executed in order to ensure that all statements in the program are executed at least once. In other words it gives us the value for maximum number of est cases to be designed. A program graph is used to depict control flow. Nodes represent processing tasks (one or more code statements) Edges represent control flow between nodes.""      ""width"": ""800"" }                         32                  Flow Graph Notation While Sequence If-then-else Until Case  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/32/Flow+Graph+Notation+While+Sequence+If-then-else+Until+Case.jpg""      ""name"": ""Flow Graph Notation While Sequence If-then-else Until Case""      ""description"": ""Flow Graph Notation While Sequence If-then-else Until Case""      ""width"": ""800"" }                         33                  Ways to compute Cyclomatic ComplexityThe cyclomatic complexity C(G) of a graph G can be computed using one of the following ways: C(G) = E – N + 2 E is the number of flow graph edges N is the number of nodes C(G) = number of regions in the flow graph. Regions are the areas bounded by nodes and edges in a flow graph. While counting regions  area outside the graph is also counted as one region. C(G) = P + 1 P is the number of predicate nodes  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/33/Ways+to+compute+Cyclomatic+Complexity.jpg""      ""name"": ""Ways to compute Cyclomatic Complexity""      ""description"": ""The cyclomatic complexity C(G) of a graph G can be computed using one of the following ways: C(G) = E – N + 2. E is the number of flow graph edges. N is the number of nodes. C(G) = number of regions in the flow graph. Regions are the areas bounded by nodes and edges in a flow graph. While counting regions  area outside the graph is also counted as one region. C(G) = P + 1. P is the number of predicate nodes.""      ""width"": ""800"" }                         34                  Example main() { int num_student  marks  subject  total;float average; num_student = 1; while(num_student <=25) { total = 0; subject = 1; while(subject<=5){ scanf(“Enter marks:%d”  &marks); total = total + marks subject ++; } average = total/5; If(average>=50) printf(“Pass...Average is %f”  average); else printf(“Fail...Average is %f”  average); num_student++; 20. printf({“End of Program”); 21. } Nodes State ment Numbers a 2-4 b 5 e 6-7 f 8 z 9-12 g 13-14 h 15 i 17 j 18 c 19 d 20  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/34/Example+main%28%29+%7B+int+num_student%2C+marks%2C+subject%2C+total%3B.jpg""      ""name"": ""Example main() { int num_student  marks  subject  total;""      ""description"": ""float average; num_student = 1; while(num_student &amp;lt;=25) { total = 0; subject = 1; while(subject&amp;lt;=5){ scanf( Enter marks:%d   &amp;amp;marks); total = total + marks. subject ++; } average = total/5; If(average&amp;gt;=50) printf( Pass...Average is %f   average); else. printf( Fail...Average is %f   average); num_student++; 20. printf({ End of Program ); 21. } Nodes. State. ment Numbers. a b. 5. e f. 8. z g h. 15. i. 17. j. 18. c. 19. d. 20.""      ""width"": ""800"" }                         35                  Flow Graph a b e f z g h i j c d  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/35/Flow+Graph+a+b+e+f+z+g+h+i+j+c+d.jpg""      ""name"": ""Flow Graph a b e f z g h i j c d""      ""description"": ""Flow Graph a b e f z g h i j c d""      ""width"": ""800"" }                         36                  Ways to compute Cyclomatic ComplexityThe cyclomatic complexity C(G) of a graph G can be computed using one of the following ways: C(G) = E – N + 2 E =13  N=11 C(G)= =4 C(G) = number of regions in the flow graph= 4 C(G) = P + 1 =3+1 =4  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/7769031/25/images/36/Ways+to+compute+Cyclomatic+Complexity.jpg""      ""name"": ""Ways to compute Cyclomatic Complexity""      ""description"": ""The cyclomatic complexity C(G) of a graph G can be computed using one of the following ways: C(G) = E – N + 2. E =13  N=11. C(G)= =4. C(G) = number of regions in the flow graph= 4. C(G) = P + 1. =3+1. =4.""      ""width"": ""800"" }  Software Metrics Software Engineering.Metrics for Process and ProjectsSoftware Metrics.Software Engineering II - Topic: Software Process Metrics and Project Metrics Instructor: Dr. Jerry Gao San Jose State UniversitySoftware Metrics II Speaker: Jerry Gao Ph.D. San Jose State University   URL:  Sept.  2001.R&D SDM 1 Metrics How to measure and assess software engineering? 2009 Theo Schouten.Software metrics Selected key concepts. Introduction Motivation:  Management:  Appraisal  Assurance  Control  Improvement  Research:  Cause-effect.Project Management Metrics.CS 551 Estimation Fall December QSE Lambda Protocol Prospectus Measurable Operational Value Prototyping or Modeling sQFD Schedule  Staffing Chapter 18 Testing Conventional ApplicationsSoftware Process and Product MetricsSoftware Project Management1 Cost Estimation CIS 375 Bruce R. Maxim UM-Dearborn.Software Metric capture notions of size and complexity.Copyright © The David Consulting Group  Inc. 1 UNDERSTANDING and EFFECTIVELY USING FUNCTIONAL MEASUREMENT Presented By The David Consulting Group.University of Toronto Department of Computer Science © 2001  Steve Easterbrook CSC444 Lec22 1 Lecture 22: Software Measurement Basics of software measurement.Lecture 17 Software MetricsCmpe 589 Spring Software Quality Metrics Product  product attributes –Size  complexity  design features  performance  quality level Process  Used. Similar presentations                                    © 2019 SlidePlayer.com Inc. All rights reserved.",elementary mental discriminators ( emd ), 'Personal computer',https://slideplayer.com/slide/7769031/,'institute technology'
"                                                                     Error:  1 The Road in Software Engineering Education from Structured Programming to Object- Oriented Modelling Dr. József Tick Budapest Polytechnic  Hungary  Abstract: Higher level software engineering education has always followed the drastic paradigm changes that happened in the profession in the last twenty five years. As a result  software engineers have got to object oriented modelling  the use of CASE tools  the usage of client-server software architecture and component-based software development from the old structured programming. This paper examines how well software engineering education went after this progress. Higher level software engineering education has converged to the curve of the progress in the form of a broken line. This paper examines first and foremost the educational aspects  especially highlighting those educational methods that enforced a mentality change in the attitude of the students as young software engineers. Keywords:Software Engineering  Education  Structured Software Development  Objectoriented Modelling  CASE tools 1 Introduction The last twenty five years have resulted in a quite large and increasingly speeding technical development  in which informatics has done its own share. Furthermore  in the field of informatics the improvement in software development has been significant without any question. This paper  primarily  summarises the statements based on the features  relations and experiences of software engineering education in the John von Neumann Informatics Faculty of the Budapest Polytechnic  and earlier in the form of programming technologies in the ancestor institution  the informatics course of Kalman Kando Polytechnic. Modern higher education  within which  of course  the education of software engineering  has to follow the progress in the profession. This tracking can only happen in the form of a broken line  since:2 Higher education has a large time constant  in which the training term itself is of a 3-5- year period. A change in the education requires a big change in fixed assets especially in the labs  which means the demand of great financial resources (the purchase of software licences in large numbers  occasionally a change in the computer park) The knowledge and methodology background of a change must be set up (new learning materials  the elaboration of case studies). As a result of the above  great changes have been discrete and separate periods could be defined. Of course  some features of some periods can overlap. The beginnings and ends of the different periods cannot be easily determined  however  the events that can be linked to the introduction of a certain new paradigm can also be well distinguished. Describing it on a time axle  the life cycle of each new paradigm can be examined. These events are as follows: 1. The introduction of structured programming 2. The introduction of structured software development methodologies 3. The introduction of the usage of structured CASE tools 4. The introduction of object-oriented programming 5. The introduction of object-oriented software development methodologies 6. The introduction of the usage of object-oriented CASE tools 7. The introduction of integrated software development tools Taking the always existing overlaps into consideration  5-7 year long time periods can be determined in the development of software engineering. These periods on the time axle with their most significant features are: 1. The era of structured development 2. The era of object-oriented development 3. The era of integrated software development systems The knowledge components make up a hierarchy in which the components are built on each other. A change in each component  thus a change in the profession  can be followed in education only with a certain time shift. These components (theories  methodologies and tools) have their own characteristics like their own place in the education  the optimal methodology of their teaching  their life-cycle in the profession and the rate of immediate usable knowledge in the software production.3 Taking the elements of software development and the above mentioned components into account  the field of development can be basically split into four categories: 1. The category of development methodologies 2. The category of development tools 3. The category of programming languages 4. The category of project management When describing the eras these four factors must be considered. Figure 1. presents the component lifecycles in software engineering education at the Budapest Polytechnic. 2 The eras in software engineering higher education at the Budapest Polytechnic According to the above list  the eras distinguished by their features follow below: 2.1 The era of structured development The boom of structured programming  a so called structured euphoria  can be placed at the beginning of the eighties. Thanks to the work of Wirth [1] half the world used PASCAL and later thanks to the Borland firm software products were developed in Turbo Pascal. Naturally  education followed the trend and with the introduction of Turbo Pascal 3.0 students developed software in Pascal in the labs. By now Pascal is  of course  not used in software engineering  however  some new versions of Turbo Pascal are still in use in some other fields. A real world success  C language replaced programming in Pascal in the education  which lasted quite a long. First the methodology of Jackson  called JSP [2]  later the methodologies of DeMarco [3]  Stevens  Myers  Constantine [4] and Yourdon [5] have gained ground in the software engineering specialisation. In order to complete the list the methodologies of Gane  Sarson [6]  Warnier and Orr [7] as well as of Jackson s JSD [8] are also taught  although of minor importance. Considering CASE tools  firstly the product of Siemens  the Easy-Case and later the product of Cadre Technologies  the Teamwork  have been introduced. By the end of the era  in project management  teamwork has been accepted the usual way of solving different tasks  which has not been supported by CASE tools at all yet.4 5 2.2 The era of object-oriented development Similarly to the structured development the upside down triangle syndrome was valid in this phase as well  which means that this era also started with programming followed by design  and later by analyses. At the beginning of this era object-oriented programming started with the introduction of Turbo Pascal 5.5  which was followed by advanced versions. The OO concept was completed by the introduction of C++  which was the next step in the education as well. Tracking the development  the use of JAVA and thus the use of network-based client-server architecture were chosen from the applied languages. In software engineering education  the methodology named after Booch [9] came out first as an object-oriented methodology. This was followed by The Object- Oriented Analysis and Design noted by Coad-Yourdon  [10] [11] and it was completed by Jacobson [12]. Apart from these ones  the responsibility driven methodology by Rebeca Wirfs-Brock [13] was also introduced. The above methods were followed by two successful and widespread Object oriented modelling technique-based methods  namely  OMT  which is linked to Rumbaugh [14] and later  UML [15]  which was elaborated by Rumbaugh  Jacobson and Booch and has slowly become the exclusive leader in the profession From CASE tools  first Software through Pictures  which supports OMT  later Rational Rose  which also supports OMT  and then a version of Rational Rose  which supports UML were introduced in the education of software engineering. In this era projects carried out by the students during the semesters were done in groups of four  where team roles were well defined  the project was well documented and the project management was well supported by a CASE Tool. A presentation and evaluation of project happened at the end. 2.3 The era of integrated Software Development Systems The applied OO methodologies have crystallised and Unified Modelling Language (UML) was almost exclusively used in each more important development firm. The methodology linked to UML  the Rational Unified Process (RUP) was rapidly spreading among software developers. Thanks to this technology  the development of much larger and more complex applications became possible. By now  software development looks like a construction from Lego set by clicking onto or moving the (existing  large numbered) components. During software development  the application of CASE tools  out of which mostly the usage of tools supporting complex application-development  has stepped6 forward. In the industrial type software development the Rational XDE CASE system  the product of the Rational firm acquired by IBM  has much the biggest market share. This tool supports the development of OO type UML based standalone or rather client-server architectural and platform free software systems that apply software-reuse. During realisation  Rational XDE can be linked to all the three presently market leading  component based development environments that apply visual techniques  support team work and version management and build on network technology. These environments enable extremely effective  rapid and safe software development. They fulfill the demands set up by the present modern applications (running under windows  integration with database  web based distributed application) to the highest extent. These systems have been made for similar purposes  but were built on different phylosophies and offer different services. They are competitive products  however  each tool has its own widescale technological background: Visual Age for Java  by IBM  and the replacing WebSphere Studio is a component based visual development system  which is JAVA based  well cooperates with Oracle and well builds up with Rational XDE. Due to its JAVA background it enables the development of real multiplatformed applications. Microsoft Visual Studio NET is built on the new technology group (NET) of Microsoft and is also a component based visul development tool  which  however  has enabled the development of applications exclusively on MS Windows-based platform so far. JBuilder by Borland  which can be considered a follow-up of the PASCAL -> DELPHI line  is a JAVA based popular visual development system  that can be well integrated with database handling. The usage of the above mentioned tools and the development work with them are quite similar  however  the technological line they represent and the product line of the companies supporting them are quite different. In order to make the students participation in the development work at their work place easy  it is practical to give the opportunity to present all three systems to the students during their higher education studies. Naturally  the number of lessons does not give the opportunity to teach all the three trends to the students. Within the compulsory number of lessons the use of WebSphere Studio would be practical in the labs. This is justified by the fact  that this product is quite popular and widespread in Hungary  it enables platform free development and it applies all the techniques that are required by the different development environments. The other two trends have to be taught in optinal courses.7 Conclusions The above defined three eras are determined arbitrarily  however  they well describe the progress that software engineering education made in the last decades from structured programming to the application of integrated software development systems. This overview tried to present those components that meant the most important building bricks in the education of software engineering at the Budapest Polytechnic. With the help of the selected methodologies  languages and tools the students were trained to skill level in software development in each era. This has been proved by the good job rate among graduates and by the positive feedback from the profession for a long time. References [1] Jensen  K.  Wirth  N.: PASCAL User Manual and Report Springer Verlag  1974 [2] Jackson  M.: Principles of Program Design Academic Press  1975 [3] DeMarco  T.: Structured Analysis and System Specification Prentice-Hall  1979 [4] Stevens  W. P.  Myers  G. J.  Constantine  L. L.: Structured Design IBM Systems Journal  vol.13  no. 2  1974 [5] Yourdon  E. N.  Constantine  L. L.: Structured Design Yourdon Press  New York  1978 [6] Gane  T.  Sarson  C.: Stuctured Systems Analysis McDonnell Dougles  1982 [7] Orr  K. T.: Structured Systems Development Yourdon Press  New York  1977 [8] Jackson  M.: System Development Prentice-Hall International  1983 [9] Booch  G.: Object Oriented Design with Applications The Benjamin/Cummings Publishing Company  Redwood City 1991 [10] Coad  P.  Yourdon  E.: Object-Oriented Analysis Yourdon Press  New York  1991 [11] Coad  P.  Yourdon E.: Object-Oriented Design Yourdon Press  New York 19918 [12] Jacobson  I.  Christerson  M.  Jonsson  P.  Övergaard  G.: Object- Oriented Software Engineering A Use Case Driven Approach Addison Wesley  1992 [13] Wirfs-Brock  R.  Wilkerson  B.  Wiener  L.: Designing Object-Oriented Software Prentice Hall PTR  Englewood Cliffs  New Jersey  1990 [14] Rumbaugh  J.  Blaha  M.  Premerlani  W.  Eddy  F.  Lorensen  W.: Object-Oriented Modelling And Design Prentice Hall International Edition  1991 [15] Rumbaugh  J.  Jacobson  I.  Booch  G.: The Unified Modeling Language Reference Manual Addison Wesley  1998          Special Aspects of Component Based Software Development József Tick tick@bmf.hu Abstract: The Component Based Software Development (CBSD) is the new answer in the field of Software Engineering to the challenge              A Rapid Development Process with UML Giuliano Armano DIEE  Dipartimento di Ingegneria Elettrica ed Elettronica  University of Cagliari Piazza d Armi I-09123  Cagliari (Italy) Tel. +39-70-675.5878 armano@diee.unica.it              Model-Driven Software Engineering Foundations of Model-Driven Software Engineering Dr. Jochen Küster (jku@zurich.ibm.com) Contents Introduction to Models and Modeling Concepts of Model-Driven Software              Teaching an Object-Oriented Software Development Lifecycle in Undergraduate Software Engineering Education M. Brian Blake and Todd Cornett Department of Computer Science Georgetown University Washington               A Systematic Approach for Constructing Static Class Diagrams from Software Requirements Nabil Arman Department of Mathematics and Computer Science Palestine Polytechnic University Hebron  Palestine Khalid              Masters of Science in Software & Information Systems To be developed and delivered in conjunction with Regis University  School for Professional Studies Object Oriented Design Table of Contents January              A SIMPLIFIED CASE TOOL FOR OBJECT-ORIENTED ANALYSIS AND DESIGN Presented in Partial Fulfillment of the Requirements for the Degree Master of Science of Computer Science By Roger L. West University of Illinois              I219 Software Design Methodology JAIST Master s Program Fall 2014 Nguyen Van Vu nvu@fit.hcmus.edu.vn Topics Course Introduction Objectives and Scope Evaluation Policies Content and Schedule Basic Concepts              BOOSTER*Process A Software Development Process Model Integrating Business Object Technology and UML Axel Korthaus and Stefan Kuhlins University of Mannheim Department of Management Information Systems              DEVELOPING REQUIREMENTS FOR DATA WAREHOUSE SYSTEMS WITH USE CASES Robert M. Bruckner Vienna University of Technology bruckner@ifs.tuwien.ac.at Beate List Vienna University of Technology list@ifs.tuwien.ac.at              The Norwegian School of Information Technology Index About NITH...2 Curriculum...2 Bachelor Information Systems...3 1. year...3 2. year...3 3. year...4 Bachelor Information Technology...6 1. year...6 2.              3C05: Unified Software Development Process 1 Unit 5: Unified Software Development Process Objectives: Introduce the main concepts of iterative and incremental development Discuss the main USDP phases 2              Robust Object Oriented System Analysis Dr Jie Zhao  Dunstan Thomas Consulting Summary Uses cases are widely accepted as the best approach to capturing system requirements  in particular  functional requirements.              Linking Object-Oriented Conceptual Modeling with Object-Oriented Implementation in Java Oscar Pastor  Emilio Insfrán  Vicente Pelechano  Susana Ramírez Departament de Sistemes Informàtics i Computació              A Comprehensive Assessment of Object-Oriented Software Systems Using Metrics Approach Sanjay Kumar Dubey Department of Computer Science and Engineering Amity School of Engineering and Technology Amity              COM 401 Software Engineering Lecture Overview Object-Oriented Software Engineering: Using UML  Patterns  Java  and Software Development Processes Prof. Dr. Halûk Gümüşkaya haluk.gumuskaya@gediz.edu.tr              Class Diagrams and Use Cases - Experimental Examination of the Preferred Order of Modeling Peretz Shoval*  Avi Yampolsky and Mark Last Dept. of Information Systems Engineering Ben-Gurion University of              DATA VALIDATION Ramesh M. Choudhari  South Carolina State University  Orangeburg  SC 29117 Shobha R. Choudhari  South Carolina State University  Orangeburg  SC 29117 ABSTRACT Data validity is an important              MODERN OBJECT-ORIENTED SOFTWARE DEVELOPMENT A.N. Dunlop University of Southampton  SO17 1BJ  England Abstract Object-oriented (OO) programming has been around for a few years and there are many users of              Internet Engineering Tomasz Babczyński  Zofia Kruczkiewicz Tomasz Kubik Information systems modelling UML and service description languages Student Contact Hours: 25.02.2015- Location: 325 C3 room 25.03.2015:              ISSUES OF STRUCTURED VS. OBJECT-ORIENTED METHODOLOGY OF SYSTEMS ANALYSIS AND DESIGN Mohammad A. Rob  University of Houston-Clear Lake  rob@cl.uh.edu ABSTRACT In recent years  there has been a surge of              CHAPTER_3 SOFTWARE ENGINEERING (PROCESS MODELS) Prescriptive Process Model Defines a distinct set of activities  actions  tasks  milestones  and work products that are required to engineer high quality              Handling Spatial Objects in a GIS Database -Relational v Object Oriented Approaches Paul Crowther 1 and Jacky Hartnett 2 1 Sheffield Hallam University  School of Computing and Management Sciences  United              The Software Development Life Cycle: An Overview Presented by Maxwell Drew and Dan Kaiser Southwest State University Computer Science Program Last Time The design process and design methods Design strategies              The Online Grade Book A Case Study in Learning about Object-Oriented Database Technology Charles R. Moen  M.S. University of Houston - Clear Lake crmoen@juno.com Morris M. Liaw  Ph.D. University of Houston              Component Based Software Engineering: A Broad Based Model is Needed Allen Parrish (parrish@cs.ua.edu) Brandon Dixon (dixon@cs.ua.edu) David Hale (dhale@alston.cba.ua.edu) Department of Computer Science              UNIVERSITI PUTRA MALAYSIA THE USAGE OF OBJECT ORIENTED APPROACH IN SOFTWARE DEVELOPMENT COMPANIES ANNE VIKNESW ARY FSKTM 2003 15 THE USAGE OF OBJECT ORIENTED APPROACH IN SOFTWARE DEVELOPMENT COMPANIES              Coordinating unit: 270 - FIB - Barcelona School of Informatics Teaching unit: 747 - ESSI - Department of Service and Information System Engineering Academic year: Degree: 2015 BACHELOR'S DEGREE IN INFORMATICS              A Multi-Variant Approach to Software Process Modelling Keynotes: Wolfgang Hesse 1 and Jörg Noack 2 1 c/o FB Mathematik/Informatik  Philipps-Universität Marburg/Germany email: hesse@informatik.uni-marburg.de              Functional Modeling with Data Flow Diagrams Amasi Elbakush 5771668 Teaching Assistant : Daniel Alami Utrecht University 1 Introduction Data Flow Diagrams (DFDs) are a visual representation of the flow              DEVELOPMENT OF AN ACCOUNTING SYSTEM Applying the Incrementally Modular Abstraction Hierarchy to a Complex System Kenji Ohmori Computer and Information Sciences  Hosei Univeristy  3-7-2 Kajino-cho  Koganei-shi               GEO-OMT An Object-Oriented Method Supporting the Development of Facilities Management Systems Graça ABRANTES and Mário R. GOMES This paper presents the support that Geo-OMT  an extension of the Object              Extending the Sugiyama Algorithm for Drawing UML Class Diagrams: Towards Automatic Layout of Object-Oriented Software Diagrams Jochen Seemann Institut fur Informatik  Am Hubland  97074 Wurzburg  seemann@informatik.uni-wuerzburg.de              From Object Oriented Conceptual Modeling to Automated Programming in Java Oscar Pastor  Vicente Pelechano  Emilio Insfrán  Jaime Gómez Department of Information Systems and Computation Valencia University              Bridging the gap between Use Case Analysis and Class Structure Design by Formal Concept Analysis Stephan Düwel & Wolfgang Hesse Abstract The early stages of software development are increasingly supported              The Software Process Xiaojun Qi 1 The Unified Process Until recently  three of the most successful object-oriented methodologies were Booch smethod Jacobson s Objectory Rumbaugh s OMT (Object Modeling              Applying Agile Methods in Changing Environments 7/23/2002 1 Applying Agile Methods in Rapidly Changing Environments Peter Kutschera IBM Unternehmensberatung GmbH Am Fichtenberg 1  D-71803 Herrenberg Steffen              Softage Macintosh team PM KEYWORDS: Software architecture  design  project management  development and testing  JavaScript  XML  HTML  MS SQL  My SQL  ER-studio  Fortran  PL/1  Pascal  C/C++  Assembler               City University of Hong Kong Course Syllabus offered by Department of Computer Science with effect from Semester A 2015/16 Part I Course Overview Course Title: Problem Solving and Programming Course Code:              SOFTWARE PROCESS MODELS Slide 1 Software Process Models Process model (Life-cycle model) - steps through which the product progresses Requirements phase Specification phase Design phase Implementation              Generating Aspect Code from UML Models Iris Groher Siemens AG  CT SE 2 Otto-Hahn-Ring 6 81739 Munich  Germany Iris.Groher@fh-hagenberg.at Stefan Schulze Siemens AG  CT SE 2 Otto-Hahn-Ring 6 81739 Munich               Agile Modeling: A Brief Overview Scott W. Ambler President  Ronin International scott.ambler@ronin-intl.com Abstract: Agile Modeling (AM) is a practice-based methodology for effective modeling of software-based              Evaluating OO-CASE tools: OO research meets practice Danny Greefhorst  Matthijs Maat  Rob Maijers {greefhorst  maat  maijers}@serc.nl Software Engineering Research Centre - SERC PO Box 424 3500 AK Utrecht              Xtreme RUP by Ne t BJECTIVES Lightening Up the Rational Unified Process 2/9/2001 Copyright 2001 Net Objectives 1 RUP Overview Agenda Typical RUP Challenges Xtreme Programming Paradigm Document driven or              Object-Oriented Modeling and Design James Rumbaugh Michael Blaha William Premerlani Frederick Eddy William Lorensen General Electric Research and Development Center Schenectady  New York Tschnische Hochschule              PROJECT MANAGEMENT METHODOLOGY OF OBJECT- ORIENTED SOFTWARE DEVELOPMENT Ing. David BEDNÁŘ  Doctoral Degree Programme (2) Dept. of Information Systems  FIT  BUT E-mail: bednar@fit.vutbr.cz Supervised by:              Programming Language Constructs as Basis for Software Architectures 1 From individual parts to components In the 50s: Machine/Assembler programs: bound to specific hardware In the 60s-70s: Higher programming              HJSOFT Business Outsourcing Proposal Introduction... 2 Business Outsourcing Focus... 2 Standard and Unified Development Process... 3 Standardized Testing Procedures... 4 Price reference... 5 1 Introduction              Course Computer Science Academic year 2012/2013 Subject Software Engineering II ECTS 6 Type of course Compulsory Year 3rd Semester 1st semester Student Workload: Professor(s) Maria Clara Silveira Total              Association for Information Systems AIS Electronic Library (AISeL) AMCIS 2004 Proceedings Americas Conference on Information Systems (AMCIS) 12-31-2004 - Student Reactions Robert Nelson Penn State University              Modeling Web Applications Using Java And XML Related Technologies Sam Chung Computing & Stware Systems Institute Technology University Washington Tacoma Tacoma  WA 98402. USA chungsa@u.washington.edu Yun-Sik              SISY 2006 4 th Serbian-Hungarian Joint Symposium on Intelligent Systems Visual Studio Class Designer and Unified Modelling Language Krisztina Katona John von Neumann Faculty of Informatics Budapest Tech              OFTWARE QUALITY MODEL BAED ON OFTWARE DEVELOPMENT APPROACHE Kenyer Domínguez  María Pérez  Anna C. Grimán  Maryoly Ortega  Luis E. Mendoza Laboratorio de Investigación en istemas de Información (LII)               A Brief Analysis of Web Design Patterns Ginny Sharma M.Tech Student  Dept. of CSE  MRIU Faridabad  Haryana  India Abstract Design patterns document good design solutions to a recurring problem in a particular              Electronic Healthcare Design and Development Background The goal of this project is to design and develop a course on Electronic Healthcare Design and Development using Unified Modeling Language (UML)              Systematization of Requirements Definition for Software Development Processes with a Business Modeling Architecture Delmir de Azevedo Junior 1 and Renato de Campos 2 1 Petrobras University  Republican              The Rap on RUP : An Introduction to the Rational Unified Process Jeff Jacobs Jeffrey Jacobs & Associates phone: 650.571.7092 email: jeff@jeffreyjacobs.com http://www.jeffreyjacobs.com Survey Does your              SYLLABUS CIS 3660: OBJECT-ORIENTED SYSTEM ANALYSIS AND DESIGN SPRING 2010 Instructor: Dr. Silvana Faja Office: WDE 2400 Office Hours: 9:30 10:45 and 1:30 3:00  Tuesday and Thursday and by appointment Office              TR No. CIT/24/2003 Fifteenth International Conference on Software Engineering and Knowledge Engineering San Francisco Bay - 30 June - 3 of July 2003. Re Engineering Software Development Process for ebusiness              Software Engineering for Engineers Lecture 1: UML Class Diagrams Outline What is UML and why do we use it? UML Class Diagram Associations Inheritance UML to Java Where are we? UML Techniques  Methods and              ~""'HEWLETT.:~ PACKARD Criteria for Comparing Object-Oriented Development Methods Patrick Arnold  Stephanie Bodoff  Derek Coleman Helena Gilcrist  Fiona Hayes Information Management Laboratory HP Laboratories              Software Corporation Software Project Management using an Iterative Lifecycle Model 1 Objectives of this Presentation To understand what the Unified Process is To understand the iterative lifecycle approach              A SYSTEMATIC APPROACH FOR COMPONENT-BASED SOFTWARE DEVELOPMENT Cléver Ricardo Guareis de Farias  Marten van Sinderen and Luís Ferreira Pires Centre for Telematics and Information Technology (CTIT) PO Box              75 Electronic Commerce Studies Vol. 2  No.1  Spring 2004 Page 75-94 An Object-Oriented Analysis Method for Customer Relationship Management Information Systems Jyh-Jong Lin Chaoyang University of Technology              AARMS Vol. 8  No. 1 (2009) 173 178 INFORMATION SECURITY The security of Web applications VALÉRIA PÓSERNÉ OLÁH Budapest Tech  John Von Neumann Faculty of Informatics  Budapest  Hungary The network (LAN)              Eclipse BPMN Modeler Introducing Intalio Designer Arnaud Blandin Ismael Ghalimi Hugues Malphettes Intalio Inc  EMEA Manager Intalio Inc  CEO Intalio Inc  Lead Developer 6 rue du conseil general 1205 Geneva              Course Title: ITAP 4371: E-Commerce Semester Credit Hours: 3 (3 0) I. Course Overview The primary objective of this course is to expose students to the advanced use of information technology in the design              Unified Process Family: Iterative Enhancement Origin: Ivar Jacobson  James Rumbaugh  Grady Booch  1996 Defines process framework that is adaptable to various application domains different organizations              Your Objects of SA&D Study Chapter 1 The Systems Development Environment 2011 by Prentice Hall: J.A.Hoffer et.al.  Modern Systems Analysis & Design  6 th Edition 1/55 2/55 Course Content Fundamental of              Core Issues Affecting Software Architecture in Enterprise Projects Halûk Gümüşkaya Abstract In this paper we analyze the core issues affecting software architecture in enterprise projects where a large              Technology review Chapter 3 3.1. Introduction Previous chapter covers detail description about problem domain. In this chapter I will discuss the technologies currently available to solve a problem in              On the Concept of Method in Information Systems Development Stefan Cronholm a & Pär J. Ågerfalk b stecr@ida.liu.se a and pak@esa.oru.se b Dept. of computer and information science a Linköping University               Over-viewing Development Methodologies in the Context of e-government Shawren Singh 1 ABSTRACT e-government will most probably reshape the South African civil society  as is happening in the rest of the              Aspect Oriented Strategy to model the Examination Management Systems P.Durga 1  S.Jeevitha 2  A.Poomalai 3  Prof.M.Sowmiya 4 and Prof.S.Balamurugan 5 Department of IT  Kalaignar Karunanidhi Institute of              PROCESS-DRIVEN SOFTWARE DEVELOPMENT METHODOLOGY FOR ENTERPRISE INFORMATION SYSTEM Kwan Hee Han 1 and Yongsun Choi 2 1 Department of Industrial & Systems Engineering  Engineering Research Institute  Gyeongsang              Analyze and Design of Information Systems Using OODPM for Small Scale Businesses Pavel Petkun Offer Drori The Hebrew University of Jerusalem E-mail: pashka  offerd {@cs.huji.ac.il} Abstract In the modern              Case Study: SITINA - A Software Engineering Project Using Evolutionary Prototyping Nuno Jardim Nunes dnnunes@dragoeiro.uma.pt Phone/Fax: +351 (91) 705160 / +351 (91) 705199 Address: UMa - Madeira Tecnopolo               Business Modeling with UML Hans-Erik Eriksson and Magnus Penker  Open Training Hans-Erik In order to keep up and be competitive  all companies Ericsson is and enterprises must assess the quality of their              Architected RAD: Tackling the challenges of on demand business by Arun Gupta Chief Technologist  Enterprise Applications Rational Software IBM Software Group (186 K) It's an inescapable fact: Companies              INTRODUCING SOA AND WORKFLOW MODELING TO NON- TECHNICAL STUDENTS * Bruce J. Neubauer Public Administration Program  Government & International Affairs Department University of South Florida Tampa  Florida              Key words: user interface design 12 archetypes  Star analysis COOAD Maciej PIASECKI 1 Katarzyna PIESZKA 1 Conceptual Methodology of Developing the User Interface This paper presents a proposal of a new              Component Based Development in Software Engineering Amandeep Bakshi  Rupinder Singh Abstract--In today s world  Component Based development is an active research area for more than a decade in software              MindTelligent  Inc. Software Solutions with Mind  Diligence and Intelligence Tel: 1-877-ASK-MIND mailto:training@mindtelligent.com Configure CVS repository with IBM Rational Application Developer For WebSphere              : Object models and Databases by Robin Beaumont e-mail: robin@robinbt2.free-online.co.uk Contents 2. LEARNING OUTCOMES CHECK LIST FOR THE SESSION... 2-2 3. INTRODUCTION... 3-3 4. A STRATEGY FOR SPECIFYING              CS4507 Advanced Software Engineering Lectures 2 & 3: Software Development Lifecycle Models A O Riordan  2015 Some diagrams from Sommerville  some notes from Maciaszek/Liong Lifecycle Model Software development              In this Lecture you will Learn: Systems Development Methodologies What a systems development methodology is Why methodologies are used The need for different methodologies The main features of one methodology              Karlstad University Department of Information Systems Adapted for a textbook by Blaha M. and Rumbaugh J. Object Oriented Modeling and Design Pearson Prentice Hall  2005 Modeling Concepts Remigijus GUSTAS              The Journal of Systems and Software 43 (1998) 85±91 A case study of evolution in object oriented and heterogeneous architectures Vaclav Rajlich *  Shivkumar Ragunathan Department of Computer Science  Wayne              CHALLENGES AND WEAKNESSES OF AGILE METHOD IN ENTERPRISE ARCHITECTURE Zahra Askarinejad Amiri 1 1 Department of Computer Engineering  Staffordshire University ABSTRACT zahra.askarinejad@gmail.com As Information              Promoting Open Source Technology in Education UML Modeling Tools 1 Sonymol Koshy  2 Dr. Sunil Kumar  3 Dr. U. V. S Teotia 1 2 Dept. of CS  Shri Venkateshwara University Gajraula  UP  India 3 Director of              Acta Informatica Pragensia 2(2)  2013  68 76  DOI: 10.18267/j.aip.25 Section: Online: aip.vse.cz Peer-reviewed papers TOGAF usage in outsourcing of software development Aziz Ahmad Rais 1  Rudolf Pecinovsky              Integration of Usability Techniques into the Software Development Process Xavier Ferre Universidad Politecnica de Madrid xavier@fi.upm.es Abstract Software development organisations are paying more and              UML SUPPORTED SOFTWARE DESIGN Darko Gvozdanović  Saša Dešić  Darko Huljenić Ericsson Nikola Tesla d.d.  Krapinska 45  HR-0000 Zagreb  Croatia  tel.: +385 365 3889  faks: +385 365 3548  e-mail: darko.gvozdanovic@etk.ericsson.se              Towards an Integration of Business Process Modeling and Object-Oriented Software Development Peter Loos  Peter Fettke Chemnitz Univeristy of Technology  Chemnitz  Germany {loos peter.fettke}@isym.tu-chemnitz.de              The Role of Engineering in Software Development Life Cycle 1 Abhijit Chakraborty  2 Mrinal Kanti Baowaly  3 Ashraful Arefin  4 Ali Newaz Bahar 1  2 Department of Computer Science and Telecommunication              Andreas Spillner Dr. Spillner is working as Professor at the Hochschule Bremen (University of Applied Sciences) where he is responsible for software engineering and real time systems. Dr. Spillner has              International Journal of Information Processing Systems  Vol.2  No.3  December 2006 163 A Quality Assurance Process Model on Fault Management Hyo-Soo Kim*  and Cheong Ho Baek** Abstract: So far  little              Principles of integrated software development environments Wolfgang Emmerich Professor of Distributed Computing University College London http://sse.cs.ucl.ac.uk Learning Objectives Be able to define the              Software Development Methodologies Lecturer: Raman Ramsin Lecture 5 Integrated Object-Oriented Methodologies: OPM and Catalysis 1 Object Process Methodology (OPM) Introduced by Dori in 1995 Primarily intended    ",evolutionary prototyping, 'Personal computer',https://docplayer.net/9070098-The-road-in-software-engineering-education-from-structured-programming-to-object-oriented-modelling.html,'institute technology'
AdvertisementICFEM 2003: Formal Methods and Software Engineering                 pp 641-664 |                 Cite asThis paper is towards the development of a methodology for object-oriented software development. The intention is to support effective use of a formal model for specifying and reasoning during the requirements analysis and design of a software development process. The overall purpose is to enhance the application of the Unified Modelling Language (UML) with a formal semantics in the Rational Unified Software Development Process (RUP). The semantic framework defines the meaning of some UML submodels. It identifies both the static and dynamic relationships among these submodels. Thus  the focus of this paper is the development of a semantic model to consistently combine a use-case model and a conceptual class diagram to form a system specification.Unable to display preview. Download preview PDF.Unable to display preview. Download preview PDF.AdvertisementOver 10 million scientific documents at your fingertips© 2018 Springer Nature Switzerland AG. Part of Springer Nature. Not logged in Not affiliated 103.46.201.228 Your PrivacyStrictly Necessary CookiesPerformance CookiesFunctional CookiesTargeting CookiesMore InformationActiveAlways ActiveWe use cookies to personalise content and ads  to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media  advertising and analytics partners in accordance with our Privacy Statement. You can manage your preferences in Manage Cookies.,object oriented requirement analysis, 'Personal computer',https://link.springer.com/chapter/10.1007/978-3-540-39893-6_36,'institute technology'
       Slideshare uses cookies to improve functionality and performance  and to provide you with relevant advertising. If you continue browsing the site  you agree to the use of cookies on this website. See our User Agreement and Privacy Policy.            Slideshare uses cookies to improve functionality and performance  and to provide you with relevant advertising. If you continue browsing the site  you agree to the use of cookies on this website. See our Privacy Policy and User Agreement for details.                     Published on Oct 14  2013   Be the first to comment LinkedIn Corporation © 2019Looks like you’ve clipped this slide to  already.,operational feasibility, 'Personal computer',https://www.slideshare.net/saicharan02/software-project-management-tool-27159513,'institute technology'
Skip to Main ContentGetting results... 							A not-for-profit organization  IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.© Copyright 2019 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions. 						,public domain software, 'Personal computer',https://ieeexplore.ieee.org/author/37085591667,'institute technology'
Don't have an account? Sign upBy clicking Join now  you agree to the LinkedIn User Agreement  Privacy Policy  and Cookie Policy.Already have an account? Sign in,quality assurance ( sqa ), 'Personal computer',https://in.linkedin.com/in/raghvendra-pratap-ojha-8195b430,'institute technology'
       Slideshare uses cookies to improve functionality and performance  and to provide you with relevant advertising. If you continue browsing the site  you agree to the use of cookies on this website. See our User Agreement and Privacy Policy.            Slideshare uses cookies to improve functionality and performance  and to provide you with relevant advertising. If you continue browsing the site  you agree to the use of cookies on this website. See our Privacy Policy and User Agreement for details.                     Published on Nov 27  2018                       05                    Be the first to comment LinkedIn Corporation © 2019Looks like you’ve clipped this slide to  already.,capture / playback and test harness tools, 'Personal computer',https://www.slideshare.net/Sangeethadisha/unit-5-software-testing,'parallel system'
Loading PreviewSorry  preview is currently unavailable. You can download the paper by clicking the button above.Enter the email address you signed up with and we'll email you a reset link.,communication systems, 'Personal computer',https://www.academia.edu/20988501/Software_Engineering_for_Parallel_and_Distributed_Systems,'parallel system'
Loading PreviewSorry  preview is currently unavailable. You can download the paper by clicking the button above.Enter the email address you signed up with and we'll email you a reset link.,development life cycle ( sdlc ), 'Personal computer',https://www.academia.edu/15563392/The_Systems_Development_Life_Cycle_LECTURE_NOTES_DEVELOPING_INFORMATION_SYSTEMS_SOLUTIONS,'parallel system'
type Status reportmessage description The requested resource is not available.,earliest start time, 'Personal computer',http://citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.543.7194%26rep%3Drep1%26type%3Dpdf,'parallel system'
 							Reference Number: 18.a3e83217.1554522779.205dea1c 						,execution time, 'Personal computer',https://www.sciencedirect.com/topics/computer-science/execution-platform,'parallel system'
"Published on                                     08-Oct-2015                                 View                                     105                                 Download                                     1                                 DESCRIPTIONSyllabus bTranscriptB Level Syllabus R4    1  Contents  S No     TITLE     Page Number 1.   About the Revised Syllabus     1 2.   DOEACC Scheme       1 3.   DOEACC B Level Course     2 4.   Practicals        3-4 5.   Projects        4-8 6.   Credit Scheme       8-10 7.   Examination Pattern      10 8.   Hardware requirement for B Level course  13 9.   Software requirement for B Level course  13 10. Parity Table between Revision II (w.e.f July 1999)  and Revision III (w.e.f July 2003) and Rev IV  (w.e.f January 2011) of DOEACC B Level Syllabus 14-15 Detailed Syllabus  Semester-I B0-R4 Basic Mathematics     16 B1.1-R4 IT Tools and Business System    21 B1.2-R4 Internet Technology and Web         Design       38 B1.3-R4 Programming and Problem Solving         Through C Language      54 B1.4-R4 Computer System Architecture   68 B1.5-R4 Structured System Analysis and  Design       78  Semester II B2.1-R4   Data Structures through C++    95 B2.2-R4  Introduction to Database  Management System     110 B Level Syllabus R4    2   B2.3-R4 Basics of Os  Unix and Shell    Programming      125  B2.4-R4 Data Communication and     Network Technologies     136 B2.5.1-R4 Introduction to Object-Oriented   Programming through Java    147 B2.5.2-R4  Software Testing and Quality  Management      163  Semester-III B3.1-R4 Management Fundamentals &  Information Systems     174  B3.2-R4 Discrete Structures     180  B3.3-R4 Software Engineering and  CASE Tools       186  B3.4-R4 Operating Systems     194  B3.5-R4 Visual Programming     203  Semester-IV  B4.1-R4 Computer based Statistical &    Numerical Methods     208  B4.2-R4 Professional & Business  Communication      214  B4.3-R4 Object Oriented Database    Management Systems     218  B4.4-R4 Computer Graphics &     Multimedia       223  B4.5-R4 Internet Technology and Web Services      227  Semester-V  B5.1-R4 Software Project Management   232  B5.2-R4  Automata Theory & Compiler Design      238  B5.3-R4 Network Management &      Information Security     244  B5.4-R4 Elective II (Two out of the following  B5.5-R4 Elective - III  Twelve subjects to be chosen) B Level Syllabus R4    3   List of Elective Subjects:  BE1-R4 Embedded Systems     251  BE2-R4 Artificial Intelligence &    Neural Networks      259  BE3-R4 E-Business       268  BE4-R4 System Modeling & Computer Simulation       272  BE5-R4 Parallel Computing     278  BE6-R4 Data Warehouse and Data Mining   284  BE7-R4 Software Testing and Quality Management      290  BE8-R4 Digital Image Processing    300  BE9-R4 Accounting & Financial Management System    305  BE10-R4 Applied Operations Research    321  BE11-R4 Wireless & Mobile Communication      330  BE12-R4 Information Storage &    Management      337 B Level Syllabus R4    1  1.         ABOUT THE REVISED SYLLABUS   The third revised version of DOEACC syllabus came into effect in July 2003 examinations.  Since then many advancements have taken place in the field of Information Technology.  Consequently it has become necessary to revise the syllabus.   This document presents the fourth revised version of DOEACC B level syllabus which becomes effective for teaching w.e.f. January 2011.  This B Level syllabus is designed to facilitate students in the development of concept based approach for problem solving using IT as a tool.  The self learning approach is built into the syllabus  thereby training the candidates to update themselves on the changing technologies in their area of work. The B Level syllabus has been designed to produce Programmers  Web Administrators  faculty/ Trainer  Web Content Developers and trouble shooters etc.  equipped with latest knowledge and skills. 2. DOEACC SOCIETY   DOEACC Society is an Autonomous Scientific Society of the Department of Information Technology  Ministry of Communications & Information technology  Govt. of India.  The Society is registered under the Societies Registration Act  1860.  DOEACC Society is the only professional examination body in India  which accredits institutes / organizations for conducting particular course  specializing in the non-formal sector of IT education.  The office of the Society is situated at Electronics Niketan  6  CGO Complex  New Delhi  110 003 and number of counseling centres are situated in important cities in the country.  DOEACC is envisioned to be a premier knowledge institution pursuing human resource development activities in areas of Information Technology  Electronics and Communication Technology (IECT). DOEACCs holistic quality policy entails offering its courses through painstakingly screened accredited institutes to ensure seriousness at both the institute and individual level.  The Society has its twelve Centers at 20 locations namely Agartala  Aizawl  Aurangabad  Calicut (with Southern Regional Office at Pudukkottai)  Gorakhpur(with Eastern Regional Office at Patna)  Imphal  Kohima/Chuchuyimlang  Kolkata  Srinagar/Jammu  Shillong  Tezpur/Guwahati  Chandigarh (Branches  New Delhi  Shimla  Lucknow).  Three more DOEACC Centres are being set up at Gangtok  Itanagar and Chennai. These Centres provide quality education & training programmes in Information  Electronic Design and related technologies/areas on long term and short term basis.  3. DOEACC SCHEME   DOEACC is a joint Scheme of the Department of information Technology (erstwhile Department of Electronics)  Ministry of Communications & Information Technology  Govt. of India and All India Council for Technical Education (AICTE). Objective of the Scheme   The objective of the Scheme is to generate qualified manpower in the area of Information Technology (IT) at the national level  by utilizing the facilities and infrastructure available with the institutions/organizations in the non-formal sector.  The Society is managed and administered by a Governing Council which consists of eminent academicians and professionals from IT industry.  Minister of B Level Syllabus R4    2  Communications & Information Technology  Govt. of India  is the Chairman  Governing Council of the Society.  The Executive Director is the Chief Executive Officer of the Society and manages day to day affairs of the Society.  Manifold functions of the DOEACC Scheme are: a) Accreditation b) Registration and c) Examination 4. DOEACC B  LEVEL COURSE  Objective of the B  Level Course  The objective of B Level is to develop capability to analyse  develop and manage software project. The course has been designed to give the students sound background in computing  business functions and mathematics relevant to information technology. During the course  a student will learn Computer Programming Languages  Compilers  Software packages  database systems  Network Management & Information Security etc.  The career options available to DOEACC B  level qualifiers are:   System Analyst  Software Engineer  Training faculty  R & D Scientist  EDP Manager DOEACC B Level Course consists of 25 theory modules (22 compulsory modules and 3 elective module)  four Practicals and three Projects(out of which one will be a comprehensive project). The minimum duration of the course is three years. The structure of B Level syllabus is indicated below :  DOEACC B  LEVEL COURSE STRUCTURE  The structure of  the B  Level course is:  Module             Title Bridge Course  B0-R4                  Basic Mathematics (Required for students who have not studied Mathematics up to class 12)  Semester I  B1.1-R4                  IT Tools and Business Systems B1.2-R4                  Internet Technology and Web Design B1.3-R4                  Programming and Problem Solving through C B1.4-R4                  Computer System Architecture B1.5-R4                  Structured System Analysis & Design             Semester II  B2.1-R4                        Data Structure through C++ B2.2-R4 Introduction to DBMS B2.3-R4 Basics of OS  Unix & Shell Programming B2.4-R4 Data Communication and Network Technologies B2.5-R4                        Elective (Any one from the following to be chosen) B Level Syllabus R4    3  B2.5.1-R4 Introduction to Object Oriented Programming through JAVA B2.5.2-R4 Software Testing and Quality Management  PJ-1-R4    Semester III                        Project I                                B3.1-R4 Management Fundamentals & Information System B3.2-R4 Discrete Structure B3.3-R4 Software Engineering & CASE Tools B3.4-R4 Operating Systems B3.5-R4 Visual Programming  Semester IV  B4.1-R4 Computer-based Statistical & Numerical Methods B4.2-R4 Professional & Business Communication B4.3-R4 Object Oriented DBMS B4.4-R4 Computer Graphics & Multimedia B4.5-R4 Internet Technology and Web Services Semester V  B5.1-R4 Software Project Management B5.2-R4 Automata Theory & Compiler Design B5.3-R4 Network Management & Information Security  Elective                        (Any two from the following to be chosen) BE1-R4 Embedded Systems BE2-R4 Artificial Intelligence & Neural Networks BE3-R4 E-Business BE4-R4 System Modeling and Computer Simulation BE5-R4 Parallel Computing BE6-R4 Data Warehouse and Data Mining  BE7-R4** Software Testing and Quality Management BE8-R4 Digital Image Processing BE9-R4 Accounting & Financial Management System BE10-R4 Applied Operations Research BE11-R4 Wireless & Mobile Communication BE12-R4 Information Storage & Management  PJ-2-R4  Mini project / Seminar            Semester-VI            PJ-3-R4                                    PROJECT-III ** (Compulsory for students who have not done in Semester II of B Level / A Level)  5. PRACTICAL    All B Level Candidate under the revised syllabi (Revision 4) shall have to qualify the Practical Examination  in addition to qualifying the theory examinations as well as the Project Work.  B Level Syllabus R4    4  The students have to devote half of the total time allotted to each module for the practical session.  Practical assignments have been worked out for each theory paper. At B Level  there are four Practical Examinations.   The Practical-1 examination will be based on the syllabi of   B1.1-R4                  IT Tools and Business Systems B1.2-R4                  Internet Technology and Web Design B1.3-R4                  Programming and Problem Solving through C B1.4-R4                  Computer System Architecture Practical -2 examination will be based on the syllabi of  B1.5-R4                    Structured System Analysis & Design B2.1-R4                        Data Structure through C++ B2.2-R4 Introduction to DBMS B2.3-R4 Basics of OS  Unix & Shell Programming B2.4-R4 Data Communication and Network Technologies B2.5-R4                        Elective (Any one from the following to be chosen) B2.5.1-R4 Introduction to Object Oriented Programming through JAVA B2.5.2-R4 Software Testing and Quality Management Practical 3 examination will be based on the syllabi of  B3.3-R4 Software Engineering & CASE Tools B3.4-R4 Operating Systems B3.5-R4 Visual Programming Practical - 4 examination will be based on the syllabi of  B4.3-R4 Object Oriented DBMS B4.4-R4 Computer Graphics & Multimedia B4.5-R4 Internet Technology and Web Services 6. PROJECT  DOEACC curriculum has a project as an important component of B Level course.  There are three projects at B Level. The Project is carried out by the student under guidance and support of faculty and management of the respective institute.    It is felt that such a project provides an opportunity to the student to apply his/her knowledge and skills to real life problems (including oral and written communication skills)  and as such the project should be given utmost importance and priority both by the students as well as institution faculty / management in respect of its identification  planning and implementation.  Objective of the Project  The aim of the project is to give the students an integrated experience in solving a real life problem by applying knowledge and skills gained on completion of theory papers in a course at a given Level.  It provides an occasion for students to develop written and communication skills; Project also helps the students to realize the importance of resource and time management  ownership of task towards deliverables  innovation and efficiency in task management apart from presentation skills.  It also provides a good opportunity for students to build  enhance and sustain B Level Syllabus R4    5  high levels of professional conduct and performance and evolves a problem solver frame of mind in student.  It is also felt that taking up the project by a student prepares him for a job in industry and elsewhere.  6.1  B Level First project (PJ -1-R4)  Every candidate should do a project individually and no grouping is allowed. The project will be carried out under the guidance of the institute  if he/she is through the institute conducting an accredited course. The direct candidate will do the project in an organization where he/she is working. In that case  he/she will carry out the project under the guidance of experts/professionals from his organization.  Who could be a Supervisor / Guide  A guide for B Level should be a person with DOEACC B level / MCA / B.Tech / equivalent / higher qualification and adequate experience (minimum 3 years) in the area in which the student has chosen the Project.  In the case of a candidate from an accredited institute  the institute concerned will render all help including the nomination of the Supervisor.  Time of Submission of First B  Level Project  B Level student can submit the project only after clearing 5 papers from the first two semesters and appearing in remaining papers of these two semesters in the next examinations.   Credits The first Project would be approximately 350 man-hours and carries a total of 100 marks (80% for the project evaluation and 20% for the viva-voce).  Some important notes while preparing the project proposal  The following suggested guidelines may be followed in preparing the Final Project Report:  Good quality white executive bond paper A4 size should be used for typing and duplication.  Care should be taken to avoid smudging while duplicating the copies. Page Specification: (Written paper and source code) Left margin  3.0 cms Right margin  3.0 cms Top margin  2.7 cms Bottom margin  2.7 cms Page numbers  All text pages as well as Program source code listing should be numbered at the bottom center of the pages.  Submission of Project Report to DOEACC  The student will submit his/her project report in the prescribed format along with requisite fee.   The Project Report should include:  One hard copy of the Project Report.  Soft copy of Project on CD  The Project Report may be about 50 pages (excluding coding). B Level Syllabus R4    6  6.2       Mini Project /Seminar (PJ- 2-R4) Objective DOEACC curriculum has a mini project as an important component of B Level course.  With the rapid technological advances in the field of computer  all the researches and studies carried out on various subjects around the world may not be available in the course curriculum.  This is where the seminars or such mini projects are of great importance. Seminars are capable of keeping the students updated with the technologies. B level students are expected to take part in various seminars on latest topics. Through conducting or attending the seminars  they can make others understand what is their idea is all about. Seminars on the subject topics would always help them to understand the subject more effectively. This would give them a chance to collect more information about the topic they are provided with. The result is that they would learn the subject well.  Time of submission  The Project is carried out by the student under guidance and support of faculty and management of the respective Institute / Organization.  This project or seminar  will be based on the syllabi B5.1-R4  B5.2-R4  B5.3-R4  BE1-R4 to BE12-R4 modules of the B  Level course. The project completion certificate has to be submitted after appearing for all the modules of semester V of DOEACC B level examination.  Credits  This mini Project/ seminar would be approximately 350  man-hours and carries a total of 100 marks. The marks and a certificate of conducting mini project/ seminar should  be submitted  in the prescribed format by the head of the institute running the accredited course or the organization of which the candidate is an employee.    Proforma  of the mini Project Completion Certificate is given below;  Proforma  of the Mini Project Completion Certificate  This is to certify that the Project work done or seminar (-----------------------Title)  attended  at ___________________________ by Mr./Ms.__________________________ (DOEACC Registration No.___________) in partial fulfillment of DOEACC B Level Examination has been found satisfactory and the total marks obtained by the candidate is ___________.  This report has not been submitted for any other examination and does not form part of any other course undergone by the candidate.  It is further certifies that he / she has appeared in all the five modules of semester V of DOEACC B Level examination.  Signature       Name:       (By head of the institution with PROV       No. /FULL No.) or by       Head of the Organization / Division       Name of the Organization:       Address:   B Level Syllabus R4    7  6.3 B level Final Project (PJ-3-R4)  At this academic level  the project is of some great significance in the testing of a candidates virtuosity in Information Technology and judges his or her ability to independently take charge of Project/System development. The final Project may be started after the candidate has completed at least first 15 papers and has appeared in the remaining papers of the 4th semester of /B level course. All B level candidates are required to get the synopsis of the project and the brief bio-data of the supervisor/Guide approved from the Society. The synopsis should clearly mention the scope of the project. The project is to be taken up only after obtaining the approval of the Society.  Eligibility  The candidate could be from an institute conducting the accredited course or may be a direct candidate. The project is to be selected by the student reflecting knowledge gained by the him/her during the course of study. The subject will be chosen by the student duly approved by a supervisor/Guide.  Supervisor/Guide    A supervisor/Guide should be a person of eminence in the area in which the student has chosen the project. In the case of a candidate from an institute conducting the accredited course  all help including the nomination of the supervisor./guide will be rendered by the institute concerned. In the case of a direct candidate  the candidate should ensure that the facilities are available in the organization (where the project is taken up) and also the same are extended to them.  The guide of B level Final project would be a person having MCA / B.Tech / M.Sc (comp.Sc) / M.Tech (Comp.Sci) / C level with 5 years of experience in the field of Information Technology.  Topic of the Project  Should enable bringing out the topics learnt and should be related to applications in the Industry/field in real life.  Methodology  Candidate should undertake a project work involving use of software engineering methodologies  tools and techniques.  Format    Candidate should see the format in the Student project Guide at Doeacc website.  Credits  Project would be of approximately 450 man-hours and so credited by the Supervisor/Guide and will be presented in the form in conformance with the format given in the Student guide. The project will also include a viva-voce examination. Project carries a total of 300 marks. 80% of the marks are earmarked for the project evaluation and 20% for the viva-voce.   To qualify for a pass  a candidate must obtain at least 50% in each of project evaluation and viva-voice. Exact location of the viva-voce will be intimated by the examiner designated. B Level Syllabus R4    8  Time for submission   Project may be submitted by direct candidates when they have appeared for the last papers in the 5th semester and by students from institutes in 6th semester. The hard copy of the project is required to be submitted along with the following:  Soft copy of Project on  CD  Project fee as applicable at the time of submission vide demand draft in favour of DOEACC Society payable at any nationalized bank in New Delhi.  Authenticity   Should be an original work  of real life value and not copied from existing material from any source and a certificate to the effect will be provided with the Project duly countersigned by the supervisor/Guide. 7. CREDIT SCHEME FOR DOEACC B  LEVEL COURSE   Introduction   A credit system based on the AICTE norms has been introduced for indicating the efforts required to pass a specific level of course under the DOEACC Scheme.  Award of credit to a student will facilitate measurement/comparison of study hours including Theory Lectures  Tutorials and Practical Assignments put in a given mudule/paper/subject under the Scheme with similar course in IT in India and abroad.  This will also facilitate other Universities/Apex Accrediting bodies to consider academic and professional equivalence of DOEACC courses.  This will also help students/organizations to transfer credits from DOEACC to other academic bodies and vice-versa for ensuring continuing education.  Following table gives the no. of hours of Lectures/Tutorials and Practicals per week to be attended and the credits earned by the student:- Calculation of Credits  Code   Modules/ Subject Name      No. of Hrs. per week  No.       L* T/P**  No. of            Credits+  B0-R4  Basic Mathematics B1.1-R4 IT Tools and Business System 3 3   5 B1.2-R4 Internet Technology and Web         Design     3 3   5 B1.3-R4 Programming and Problem Solving         Through C Language    3 3   5 B1.4-R4 Computer System Architecture 3 3   5  B1.5-R4 Structured System Analysis and  Design     3 3   5 25 B2.1-R4   Data Structures through C++  3 3   5 B2.2-R4  Introduction to Database  Management System   3 3   5  B2.3-R4 Basics of Os  Unix and Shell    Programming    3 3   5  B2.4-R4 Data Communication and     Network Technologies   3 3   5   B2.5-R4 Elective-I (One out of the following two subjects to be chosen)  B Level Syllabus R4    9  B2.5.1-R4 Introduction to Object-Oriented   Programming through Java  3 3   5 B2.5.2-R4  Software Testing and Quality  Management    3 3   5 25 PJ1-R4 Project -I                 5      5 B3.1-R4 Management Fundamentals &  Information Systems   3 3   5  B3.2-R4 Discrete Structures   3 3   5  B3.3-R4 Software Engineering and  CASE Tools    3 3   5  B3.4-R4 Operating Systems   3 3   5  B3.5-R4 Visual Programming   3 3   5  25  B4.1-R4 Computer based Statistical &    Numerical Methods   3 3   5  B4.2-R4 Professional & Business  Communication   3 3   5  B4.3-R4 Object Oriented Database    Management Systems  3 3   5  B4.4-R4 Computer Graphics &     Multimedia    3 3   5  B4.5-R4 Internet Technology and Web Services    3 3   5 25  B5.1-R4 Software Project Management 3 3   5  B5.2-R4  Automata Theory & Compiler Design   3 3   5  B5.3-R4 Network Management &      Information Security   3 3   5    B5.4-R4 Elective II (Two out of the following  B5.5-R4 Elective - III  Twelve subjects to be chosen)    BE1-R4 Embedded Systems   3 3   5  BE2-R4 Artificial Intelligence &    Neural Networks   3 3   5  BE3-R4 E-Business    3 3   5  BE4-R4 System Modeling & Computer Simulation    3 3   5  BE5-R4 Parallel Computing   3 3   5  BE6-R4 Data Warehouse and Data Mining 3 3   5  BE7-R4 Software Testing and Quality Management    3 3   5  BE8-R4 Digital Image Processing  3 3   5  BE9-R4 Accounting & Financial Management System  3 3   5  BE10-R4 Applied Operations Research  3 3   5  BE11-R4 Wireless & Mobile Communication   3 3   5  BE12-R4 Information Storage &    Management    3 3   5 25   PJ-2  Mini Project/Seminar       5 5 B Level Syllabus R4    10  PJ-3  Project  II        34 34    Total Credit (for 25 papers)           169   *L : No. of Lecture hours per week  **T/P : No. of Tutorial/Practical hours per week   +Credits = L + (T+P)/2  Notes  1. One hour of lecture is equated to One credit and two hours  of tutorial / practicals are similarly equated to a credit  every week for a semester consisting of 20 weeks. 2. Total No. of credits earned in a module is calculated using AICTE FORMULA (as applicable to Under Graduate Courses in IT namely  C=L + (T+P)/2 where L  T and P indicate no. of hours per week for Lectures  Tutorials and Practical. 3. The credit scheme was implemented from July  2003 examinations. 4. Fractions in Credits have been rounded to nearest integer. 8. EXAMINATION PATTERN  The theory examination for each module under the fourth revised syllabus would be for duration of three hours and the total marks for each subject would be 100.  Four Practical examinations of three hours duration and 100 marks each have been introduced.  The first examination with the revised syllabus will be held in July 2011  for which teaching will commence in January  2011.  Dates for the various activities connected with examinations will be announced on DOEACC website  well in advance of the examinations.  Pass percentage  To qualify for a pass in a module  a candidate must have obtained at least 50% in each theory and practical examination each.  The marks will be translated into grades  while communicating results to the candidates.  The gradation structure is as below:-  Pass percentage   Grade  Failed (B Level Syllabus R4    11  Development  Govt. of Indias notification no. F.2/697TS.IIIa dated 26th September 2000.  9. Registration  Registration is a pre-requisite for appearing in DOEACC examinations. A candidate can register at only one Level at a time to appear for the examination. Registration is only for candidates and not for institutes. Registration forms are available from the DOEACC Society free of cost and also can be downloaded from the website. The eligibility criteria for registration at B Level is as follows:  Students from institutes conducting accredited courses:   Level 'A'/ Government recognised PPDCA / Government recognised PGDCA / Government recognised polytechnic engineering diploma/Graduate  followed in each case  by an accredited 'B' Level course (First two semesters are exempted for those who pass 'A' Level in full. Candidates having Government recognised PPDCA / Government recognised PGDCA will also be eligible for exemption of some subjects depending on the courses they had undergone  on a case-by-case basis).   Direct Applicants   Level A / Government  recognised  PPDCA /   Government recognised  PGDCA  followed in each case  by two years relevant experience. (First two semesters are exempted for those who    pass  A   level in full. Candidates having  Government recognised PPDCA / Government recognised   PGDCA will also be eligible for exemption of some subjects depending on the courses  they had undergone  on a case by case basis).  or Graduate/Government recognised polytechnic engineering diploma  followed in each case by three years relevant experience. Relevant experience connotes job experience in  IT  including teaching  in a recognised  institution  as  a  faculty member excludes coaching. Registration is open throughout the year  however cut off dates are  specified for submitting registration applications for each examinations for the convenience of processing and allotting Registration Numbers. Level Cut off Dates  January Exams July Exams B Level Preceding 31st July Preceding 31st January Accredited Institutes are allowed to submit the Registration Application Form of their candidates one month beyond the cut off dates.  9.1  Auto-upgradation:  The candidates successfully completing all papers (Theory as well as Practical) of a particular Level in a particular Examination and wish to appear in the next Examination for immediate higher Level are exempted from the above cut off dates.  Such candidates can fill up examinations Form and Registration Forms for higher Levels subject to following conditions:-  B Level Syllabus R4    12  a) Registration fee is not mixed / combined with Examination fee and is paid through a separate Demand Draft. b) The facility is available to the candidates appearing through Accredited Institutes and not for direct applicants.  However the facility is available to a candidate who might have completed lower level as a direct candidate and wishing to appear for immediate higher level through Accredited Institutes. c) The facility is also not available to the candidates those who might be appearing through Accredited examination but have cleared lower level prior to the preceding exam (e.g. if a candidate has passed A Level Exam in Jan  2011 he would be eligible for this facility in case he wishes to appear for B Level Examinations in July  2011 through Accredited Institute.  If  however  he had passed B Level prior to Jan.  2011 Exams  this facility would not be available to him). d) This facility would also not be available to the candidate opting for Level jumping (e.g. from O to B or A to C Levels). Once registered at a particular level  the registration is valid for twelve consecutive examinations for B Level  reckoned from the specific examination as indicated in the Registration allocation letter issued to the candidates.  Registration  by itself  does not entitle a candidate to appear for an examination at the Level concerned  unless all conditions  stipulated in the examination application form  and in any other notification  relevant to the examination are fulfilled by the candidate.  9.2 Re-registration:  Candidates who are not able to clear the level within the validity period of initial registration  are allowed to re-register for once  at the same level for another full term i.e. 6 years to clear the left over papers by submitting filled in Registration application and full Registration fee within one year of the expiry of the validity period of existing B level Registration.  10. PRACTICAL EXAMINATION SCHEME  No of Practical Examination : Four Duration of each Examination :Three hour duration including viva-voce Max. marks in each Examination : 100=80 (Practical) + 20 (Viva)  Grading : Students will be awarded grades in practical examinations based on the marks scored by them in the practical and viva voce.  Every candidate has  to pass in both Theory and Practical examinations. Date(s) :Date(s) will be announced  on  the   DOEACC website.  The examinations will be conducted by the Society in reputed institutions for all candidates.  The institutes are obliged to facilitate the conduct of Practical examinations and arrange infrastructure  faculty for the conduct of practical examination.  The institutes are not allowed to charge any fee from the candidates  for the practical examination.  B Level Syllabus R4    13  11. HARDWARE REQUIREMENT FOR B  LEVEL COURSE  11.1 Computer configuration recommended  Processor   : 1 GHz or higher RAM    : 128 MB or higher HDD    : 40 GB or higher Monitor   : SVGA Mouse    : Windows compatible Keyboard   : Standard NIC    : Standard Micro controllers  : Standard Micro processor  : Standard Optical Drive   : Standard Speaker  Mic  Webcam : Standard 11.2 Printer   Laser printer / Inkjet Printer : Standard  Dot matrix printer  : Standard  OHP /LCD Projector  : Standard  MODEM  DIAL UP/DSL : Standard  SCANNER   : Standard  Sufficient number of Computers / nodes in Client server configuration mode satisfying the criteria  of accreditation. 11.3 Networking   NIC     : Standard  RJ-45 Connector   : Standard Punching Tool   : Standard   Crimping Tools   : Standard  UTP/STP/Coaxial Fiber  Optic Cables and their connectors  : Standard 8/16 port Hub/Switch   : Standard Wi-H Router    : Standard 12. SOFTWARE REQUIREMENT FOR B  LEVEL COURSE   Operating system  : Linux / Windows / 2000/xp/vista  NOS    : Linux / Unix / Windows NT/Novell Netware SW Packages                        : Star Office / MS Office  Internet Explorer  Internet Explorer / Web Publishing Tool  JDK / Oracle J Developer2  AUTOCAD/CorelDraw / MS Visio  Microsoft Visual Studio .Net. Oracle / SQL Server. Standard Multimedia Tools CASE Tool Win Runner/Load Runner  RASMOL  BLAST Fasta WorkBench and NCBI Software Tools(Entrez) etc.Network Simulation Software Project Management tools/software  Firewall  Network Traffic Analysis Tools  RTOS  Software Testing Tools  MATLAB / Mathmatica (with relevant tool boxes ) Software  Antivirus Software                    : Standard  Compilers                              :           C & C++ Compiler  Java MPI PVM and OpenMP  B Level Syllabus R4    14  Parity Table between Revision II (w.e.f July 1999) and Revision III (w.e.f July 2003) and Rev IV (w.e.f January 2011) of DOEACC B Level Syllabus Code Revision II Code Revision III Code  Revision IV B1.1 Personal Computer Software B1.1-R3 IT Tools and Applications B1.1-R4 IT Tools and Business System B1.2.1 Business Systems B1.2-R3 Business Systems B1.1-R4 IT Tools and Business System B1.2.2  ERP Fundamentals  No Equivalence  No Equivalence B1.3 l Computer Organization and System Software B1.4-R3 Computer Organization B1.4-R4 Computer System Architecture B1.4 Programming and Problem Solving through C language B1.3-R3 Programming and Problem Solving through C Language B1.3-R4 Programming and Problem Solving through C Language B1.5 System Analysis  Design and MIS B1.5-R3 Structured System Analysis & Design B1.5-R4 Structured System Analysis & Design B2.1 Data Structure through C Language B2.1-R3 Data Structure through C Language B2.1-R4 Data Structure through C++ B2.2 Introduction to Database Management B2.2-R3 Introduction to Database Management B2.2-R4 Introduction to Database Management System B2.3 Computer Graphics B2.5.3-R3 Computer Graphics  No Equivalence B2.4 Data Communication and Network B2.4-R3 Data Communication and Network B2.4-R4 Data Communication and Network Technologies B2.5.1 Unix and Shell Programming B.2.3-R3 Basics of OS  Unix & Shell Programming B2.3-R4 Basics of OS  Unix & Shell Programming B2.5.2 Introduction to Object Oriented Programming and C++ / Visual C++ B2.51-R3 Introduction to Object Oriented Programming and C++  B2.5.1-R4 Introduction to Object Oriented Programming through Java  B2.5.3 Programming in Java B2.5.2-R3 Introduction to Object Oriented Programming through Java  B2.5.1-R4 Introduction to Object Oriented Programming through Java  B2.5.4 Introduction to Object Oriented programming and Visual Basic B2.5.2-R3 No Equivalence  No Equivalence B3.1 Principles of Management B3.1-R3 Management Fundamentals And Information System B3.1-R4 Management Fundamentals And Information System B3.2 Computer based Numerical and Statistical techniques B4.1-R3 Computer based Numerical and Statistical Techniques B4.1-R4 Computer based Statistical and Numerical Methods B3.3 Computer Graphics & Multimedia B4.4-R3 Computer Graphics & Multimedia B4.4-R4 Computer Graphics & Multimedia B3.4 Operating Systems B3.4-R3 Operating Systems B3.4-R4 Operating Systems B3.5 Discrete Structure B4.2-R3 Discrete Structures B3.2-R4 Discrete Structures B4.1 Accountancy & Financial management BE9-R3 Accountancy & Financial Management BE9-R4 Accounting & Financial Management System B4.2 Data & Computer Communication B3.5-R3 Networking & Mobile Communication BE11-R4 Wireless & Mobile Communication B4.3 Artificial Intelligence & Applications BE2-R3 Artificial Intelligence & Application BE2-R4 Artificial Intelligence and Neural Networks B4.4 Software Engineering & CASE Tools B3.3-R3 Software Engineering & CASE Tools B3.3-R4 Software Engineering & CASE Tools B4.5 Windows Programming  No equivalence  No Equivalence B5.1 Operations Research BE10-R3 Applied Operations Research BE10-R4 Applied Operations Research B Level Syllabus R4    15  B5.2 Advanced Database Management B5.2-R3 Object Oriented Database Management System B4.3-R4 Object Oriented Database Management System BE1 Advanced UNIX Programming  No Equivalence  No Equivalence BE2 Object Oriented Technology  No Equivalence  No Equivalence BE3 Compiler Design  No Equivalence   BE4 Modelling and Simulation BE4-R3 Principles of Modelling and Simulation BE4-R4 System Modeling and Computer Simulation BE5 Parallel Architecture and Parallel Computing BE5-R3 Parallel Architecture & Computing BE5-R4 Parallel Computing BE6 Software Project Management BE6-R4 Software Project Management B5.1-R4 Software Project Management  No Equivalence B3.2-R3 Basic Mathematics  No Equivalence  No Equivalence B4.3-R3 Software Testing & Quality Management BE7-R4 Software Testing & Quality Management  No Equivalence B4.5-R3 Internet Technologies and Tools B4.5-R4 Internet Technology and Web Services  No Equivalence B5.3-R3 Network Management & Information Security B5.3-R4 Network Management & Information Security  No Equivalence BE1-R3 Embedded Systems BE1-R4 Embedded Systems  No Equivalence BE3-R3 E-Business BE3-R4 E-Business  No Equivalence BE7-R3 Applied Bi-informatics  No equivalence  No Equivalence BE8-R3 Digital Image Processing BE8-R4 Digital Image Processing  No Equivalence B5.1-R3 Professional and Business Communication B4.2-R4 Professional and Business Communications  No Equivalence  No Equivalence B3.5-R4 Visual Programming  No Equivalence  No Equivalence B5.2-R4 Automata Theory & Compiler Design  No Equivalence  No Equivalence BE6-R4 Data Warehouse and Data Mining  No Equivalence  No Equivalence BE12-R4 Information Storage & Management  1. Candidates who have already cleared B3.2-R3 Basic Mathematics in Revision III do not need to pass the Bridge Course  B0-R4:Basic Mathematics. 2. The above table shows the equivalence between the modules of old syllabus (Revision II & III) and the new syllabus (Revision IV). 3. Candidates would not be allowed to appear in the equivalent papers of the Revision IV (new syllabi)  if they have already passed the relevant papers in earlier revision. 4. Candidates would have to pass a total of 25 papers and 4 practical and 3 projects in order to qualify B Level in Revision IV syllabus. 5. Candidates would not be allowed to appear for more than two elective papers as per the Revision IV from B3.1-R4 onwards  which means that if a candidate has already passed at least two electives as per the earlier revisions or Revision IV or both  He/she cannot opt for any  further elective paper as per Revision IV. 6. Candidates who have already cleared the Elective paper (B2.5.2 R4)-Software Testing & Quality Management  would not be allowed to obtain exemption against the Elective paper (BE7-R4)- Software Testing & Quality Management in B level. 7. Cases where unclear papers have either become elective or have no equivalence in Revision IV and the candidate has already cleared his/her quota of elective papers  the candidate must replace the papers with equal number of introduced compulsory papers in Revision IV  i.e. papers which have no equivalence in earlier Revisions.   B Level Syllabus R4    16  B0R4: BASIC MATHEMATICS  Objective of the Course  The aim of this course is to make students aware about mathematics skills which are necessary for understanding essential topics in computer science. The course is framed in such a way that the students get exposure to basic topics in mathematics that would prepare the students to learn the advance level courses in the domain of computer science such as discrete structure  computer graphics  computer and communication networks  simulation  operations research etc.  The courses provide introduction to complex analysis  differential & integral calculus  analytic geometry  vectors and matrices.  Outline of Course  S. No.   Topic Minimum number of hours 1. Complex numbers 04 2. Matrices & determinants                                08 3. Differential Calculus                                     12 4. Integral Calculus                                           10 5. Sequences & Series 08 6. Differential equation                                      04 7. Analytic geometry                                         09 8. Vectors                                                            05 Lectures = 60 Practical/Tutorials = 60 Total = 120 Detailed Syllabus   1. Complex Numbers           04 Hours. Representation of complex numbers in polar form  vector form  exponential form  properties of arguments & modulus. Graphical representatives of complex numbers  De  Moivers theorem  roots of complex numbers  solution of complex equations.  2. Matrices & Determinants         08 Hours. Notion of matrices  triangular  diagonal  identity matrices  transpose of a matrix  symmetric and skew - symmetric matrices  orthogonal matrices  Hermitian and skew Hermitian matrices consistent and inconsistent system of linear equations  Cramers rule  Gauss elimination method  rank of a matrix  inverse of a square matrix. Determinants  properties of determinants  Eigenvalues & eigenvectors of a matrix  characteristic roots and characteristic vectors of a matrix.  3. Differential Calculus          12 Hours. Functions and their graph. Domain & ranges of functions. Real numbers  exponential & logarithmic functions.   Limits & continuity of functions. Hospitals rule.  4. Differential  Calculus Derivative as slopes and rate of change  techniques of differentiation  chain rule  Mean Value theorem. Maxima & minima  asymptotes.  B Level Syllabus R4    17  5. Integral Calculus           10 Hours.  Integration by substitution  parts  partial fractions. Definite integral. Area between two curves  volume  lengths of plane curves  area of surface of revolution.  6. Sequences & Series          08 Hours. Limits of sequences & series. Sandwich theorem. Ratio test  comparison test  integral test. Alternating series  Taylor & Mclaurins series.  7. Differential Equations           04 Hours. First order differential equations and applications. Second order linear homogeneous differential equation.  8. Analytic Geometry           09 Hours. Polar coordinates  tangent lines and arc length for parametric and polar curves  conic sections  conic section in polar coordinates  rotation of axes: second degree equations.  9. Vectors             05 Hours. Vectors  dot & cross product of vectors  projections parametric equations of lines  planes in 3 -space.                                                                                                                   RECOMMENDED BOOKS  MAIN READING  1. H Anton  I. Bivens  S. Davis  Calculus  John Wiley and Sons. 2.   E. Kreysig  Advanced Engineering Mathematics  8th Edition. Wiley  2002     McGraw Hill        3. G.B. Thomas  Jr. R.L. Finney  Calculus and Analytic Geometry  Pearson Education Asia  Ninth Edition  2002  SUPPLEMENTARY READING  1. S.T.Tan  Applied Calculus   Kent Publishing Company.   B Level Syllabus R4    18  B0R4: BASIC MATHEMATICS  Model Question Paper Note: 1. Answer question 1 and any four questions from 2 to 6. 2. Parts of the same question shoul be answered together and in the same sequence.   Time allotted: 3 hours                                                                Total Marks :100  1.   (a) Express the complex numbers 2 + 3i in the form a + ib.                                      (2)                                                                      1 + i   (b) Let A = 1   2   and B = 2   1  .                        -1   3               0   1           Find whether the identity A2  B2 = (A + B) (A  B) is true or not. If not  then         give reasons.                                                                                                       (3)   (c) If A = 1  2  . Then find the eigenvalues and associated eigenvectors of A.       (4)                                      4  3    (d) Evaluate             lim         x2  3x - 10                           x 5    x2  10x + 25.                                                                                   (3)   (e) Evaluate                         d  x                                                                                                                 (2)                        1+ex   (f) Find the area under the curve x2 + 1 over the interval [0  3].                                (3)                                                       (g) Show that the series           k   diverges.          (3)                                                                                                    k=1    k+1                                                                         (h) Test the convergence of the series           k      .                                          (3)                                                                                 k=1    2k               (i) Solve the differential equation                                                                               (2)                   dy = 1 y(2  y)                   dx    4               (j) Find the entremum values of the function f(x) = logx .                                         (3)                                                                                                x 2.   (a) Find all the solutions of x3  1 = 0        (4)   (b) Express  (cos -i sin)3    in the form a+ib where a and b are real numbers                                (cos +isin)5                                                                                                                                                          (4)   (c) Find whether the following pair of vectors is orthogonal or not (i.)x = (2  -4)                    y = (4 2) (ii.) x = (0  2)  y = (-3  3)                                                                         (3)  B Level Syllabus R4    19   (d) Find the equation of a line which passes through the point (4  3) in the direction of        the vector (-2  6)                                                                                                  (3)   (f) Show that the matrix     1/3   2/3     2/4   is orthogonal.                                                 2/3    1/3   -2/3                                                                (4)                                                       -2/3    2-3   -1/3   3.   (a) Solve the following system  if possible using Cramers rule                              x  3y + 4z = 3                            2x  5y + 7z = 6                        (4)                            3x  8y + 11z = 11   (b.) Find the inverse of the matrix                           2    -1    3                               1     3   -1                 (4)                            3     2     1    (c) Prove that                a      b      c                    2bc - a2       c2             b2                                       (4)               b      c      a         =          c2            2ca  b2      a2                      c      a      b                   b2               a2          2ab  c2     (d) Draw the graph of y = 4 - |x  2|                                                                           (4)      (e) Find dy for the function x2/3 + y2/3 = a2/3                                                                                                 (2)                          dx  4.   (a) Show that the function (x + 1)2 has a maximum value   2   and a minimum value                                                      x + 3                                        27                      0.                                                                                                                          (3)                                                                                                                                                (9)             (b) Evaluate    (i)   x2 log x dx  (ii)           1          dx                            x + a  + x  (iii)       dx                             .                      x [(logx)5  5 logx + 6     (c) Find the area of the region bonded by the curvey = x2  the x  axis and the lines                     x = 2 and x = 3                                                                                                   (4)   3                           (2)             (d) Evaluate     |x| dx                       -3           . 5.   (a) test the convergence of the following series   (i)               1  1      .               k=1    5k   k(k + 1)                 (ii)        4k2  2k + 6                                 (6)                   k=1     8k7 + k  8   (b) Using Leibnitz test  show that the following alternating series in convergent B Level Syllabus R4    20                         (4)                    1  1/2 + 1/3  1/4 + 1/5+ .   (c) Find the Maclaurins series for ex.                                                                                                                  (4)              (d) Find the binomial series for       1                     (4)                                                               1+ x  6.   (a) Express the matrix A =   4    2    -1                                                           3    5     7                                                                                                                        1    -2    1                     as the sum of a symmetry and a skew symmetric matrix.                                   (4)   (b) Draw the graph of r2 = 4cos 2  in polar form .                                                     (4)              (c) Find the slope of the tangent line to the circle r = 4cos at the point where                     = pi / 4                                                                                                                                                 (4)             (d) Find the equation of the parabola that is symmetric about the y  axis  has its            vertex at the origin and passes through the point (5  2).                    (3)             (e) Draw the graph of the ellipse               x2 + y2 = 1    9    16 (3) 7.   (a) Solve the initial value problem                        xdy  y = x    y(1) = 2.                                 dx (4)  (b) Find the a curve in the xy  plane that passes through (0  3) and whose tangent        line at a point (x  y) has slope 2x / y2 (4)             (c) Find the general solution of d2y  dy  6y = 0 .                                                                dx2    dx (5)              (d) According to United Nations data  the world population in 1998 was       approximately 5.9 million and growing at a rate of about 1.33% per year. Assuming an exponential growth model  estimate the world population at the beginning of the year 2023. (5)                         B Level Syllabus R4    21  B1.1-R4: IT TOOLS AND BUSINESS SYSTEM  Objective of the Course  The goal of this course is to present overview of IT tools used in day to day use of computers and data base operations. The Course has been designed to provide knowledge on various hardware and software components of computer  operating system  various packages used for different applications  data base concepts & operations and various issues related to IT and application of IT.  At the end of the course the students will be able to:-   Acquire the foundation level knowledge required to understand computer and its operations.  Understand the hardware and software components of the computer.  Understand the basic concept of operating system and get knowledge about various different operating systems.  Understand to use the packages of word processing  spread sheet and presentation in detail.  Understand various data base concepts and operations.  Understand the issues related to IT and IT applications.  Outline of Course  S. No.   Topic Minimum number of hours 1. Computer Appreciation 04 2. Computer Organization  06 3. Operating System 13 4. Word Processing 06 5. Spreadsheet Package 09 6. Presentation Package 05 7. Data Base Operations 13 8. Information Technology and Society 04 Lectures = 60 Practical/Tutorials = 60 Total = 120 Detailed Syllabus  1. Computer Appreciation                 04Hrs. Characteristics of Computers  Input  Output  Storage units  CPU  Computer System  Binary number system  Binary to Decimal Conversion  Decimal to Binary Conversion  ASCII Code  Unicode.  2. Computer Organization                                                                     06 Hrs. Central Processing Unit - Processor Speed  Cache  Memory  RAM  ROM  Booting  Memory- Secondary Storage Devices: Floppy and Hard Disks  Optical Disks CD-ROM  DVD  Mass Storage Devices: USB thumb drive. Managing disk Partitions  File System B Level Syllabus R4    22  Input Devices -   Keyboard  Mouse  joystick  Scanner  web cam  Output Devices- Monitors  Printers  Dot matrix  inkjet  laser  Multimedia-  What is Multimedia  Text  Graphics  Animation  Audio  Images  Video; Multimedia Application in Education  Entertainment  Marketing. Names of common multimedia file formats  Computer Software-   Relationship between Hardware and Software; System Software  Application Software  Compiler  names of some high level languages  free domain software.  3. Operating System                                      13 Hrs. Microsoft Windows- An overview of different versions of Windows  Basic Windows elements  File management through Windows. Using essential accessories: System tools  Disk cleanup  Disk defragmenter  Entertainment  Games  Calculator  Imaging  Fax  Notepad  Paint  WordPad. Command Prompt- Directory navigation  path setting  creating and using batch files. Drives  files  directories  directory structure. Application Management: Installing  uninstalling  Running applications. Linux- An overview of Linux  Basic Linux elements: System Features  Software Features  File Structure  File handling in Linux: H/W  S/W requirements  Preliminary steps before installation  specifics on Hard drive repartitioning and booting a Linux system.  4. Word Processing                                                 06 Hrs. Word processing concepts: saving  closing  Opening an existing document  Selecting text  Editing text  Finding and replacing text  printing documents  Creating and Printing Merged Documents  Character and Paragraph Formatting  Page Design and Layout. Editing and Profiling Tools: Checking and correcting spellings. Handling Graphics  Creating Tables and Charts  Document Templates and Wizards.  5. Spreadsheet Package                                                                            09 Hrs. Spreadsheet Concepts  Creating  Saving and Editing a Workbook  Inserting  Deleting Work Sheets  entering data in a cell / formula Copying and Moving from selected cells  handling operators in Formulae  Functions: Mathematical  Logical  statistical  text  financial  Date and Time functions  Using Function Wizard. Formatting a Worksheet: Formatting Cells  changing data alignment  changing date  number  character or currency format  changing font  adding borders and colors  Printing worksheets  Charts and Graphs  Creating  Previewing  Modifying Charts. Integrating word processor  spread sheets  web pages.  6. Presentation Package                                                05 Hrs. Creating  Opening and Saving Presentations  Creating the Look of Your Presentation  Working in Different Views  Working with Slides  Adding and Formatting Text  Formatting Paragraphs  Checking Spelling and Correcting Typing Mistakes  Making Notes Pages and Handouts  Drawing and Working with Objects  Adding Clip Art and other pictures  Designing Slide Shows  Running and Controlling a Slide Show  Printing Presentations.  7. Data Base Operations                                      13 Hrs. Data Manipulation-Concept: Database  Relational Database  Integrity.  Operations: Creating  dropping  manipulating table structure. Manipulation of Data: Query  Data Entry Form  Reports.  8. Information Technology and Society                         04 Hrs. Indian IT Act  Intellectual Property Rights  issues. Application of information Technology in Railways  Airlines  Banking  Insurance  Inventory Control  Financial systems  Hotel management  Education  Video games  Telephone exchanges  Mobile phones  Information kiosks  special effects in Movies. B Level Syllabus R4    23  RECOMMENDED BOOKS  MAIN READING  2. P.K. Sinha and P. Sinha   Foundations of Computing   BPB Publication  2008. 3. Sagman S  MS Office for Windows XP  Pearson Education  2007. 4. ITL Educational Society  Introduction to IT  Pearson Education  2009. 5. Miller M  Absolute Beginners Guide to Computer Basics  Pearson Education  2009.  SUPPLEMENTARY READING  2. Turban  Mclean and Wetherbe  Information Technology and Management John Wiely & Sons. 3. Mansfield Ron  Working in Microsoft Office  2008  Tata McGraw-Hill 4. Balagurusamy E  Fundamentals of Computers  2009  Tata McGraw-Hill 5. Mavis Beacon  All-in-one MS Office CD based views for self learning  BPB Publication  2008 6. Perry G  MS Office 2007  Pearson Education  2008. 7. DSuoza & Dsouza  Learn Computer Step by Step  Pearson Education  2006. 8. Kulkarni  IT Strategy for Business  Oxford University Press Refer: Open Office/ MS Office Environment for practice.  B Level Syllabus R4    24  B1.1-R4 IT TOOLS AND BUSINESS SYSTEM  Model Question Paper NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS TOTAL MARKS:  100 (PART ONE - 40; PART TWO - 60) PART ONE (Answer ALL Questions; each question carries ONE mark) 1. Each question below gives a multiple choices of answers. Choose the most appropriate one. 1.1 Which type of software provides additional functionality to your operating system?  a) System software  b) Operating system software  c) Utility software  d) Application software  1.2 Which of the following detects the presence or absence of a mark in a predetermined place?  a) Pointing stick  b) Bar code reader  c) Optical mark reader  d) Trackball  1.3 To create a capital letter  you must use which special key simultaneously with the letter key? a) Enter b) Esc c) Tab d) Shift  1.4 What type of software would you need to create an invitation to your birthday party? a) Spreadsheet b) Database c) Word processing d) Desktop publishing  1.5 In a word processing program  word wrap refers to: B Level Syllabus R4    25  a) Typing that extends beyond the right margin then automatically continues onto the next line. b) Finishing a document. c) Words that are unacceptable. d) Words with too little space between them.  1.6 A space near the top of the spreadsheet where the formulas or other information in the active cell can be viewed is called the: a) address label b) title bar c) entry bar d) active cell  1.7 What is the binary number for the decimal number 217 ?  a) 11011001 b) 11101001 c) 10110101 d) 11000001  1.8  Which of the following translates a program written in a high-level language into machine code? a) an assembler b) a compiler  c) an operating system  d) an editor  1.9   Of the following components of a computer  which one performs computations? a) output device b) arithmetic/logic unit c) control unit d) memory unit  2. Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book. 2.1 The speed of a cpu is measured by the amount of time it takes to execute one machine cycle. 2.2 You can embed sounds  video clips  and animations into your word-processed document. 2.3 ROM doesn't lose data when you switch the computer off. 2.4 Operating systems are software systems that help make it more convenient to use computers and manage the transitions between multiple jobs. 2.5 In a computer  data is represented electronically by pulses of electricity. 2.6 The computer uses decimal number system for all computations 2.7 Hexadecimal number system is a compact representation of the binary number system. 2.8 The ASCII code for upper case and lower case alphabets is the same. 2.9 Microsoft Windows is a word processing system. 2.10 Computer memory is usually organized in bytes.   3. Match words and phrases in column X with the nearest in meaning in column  Y. X Y  3.1 software  a) transforming data into information   3.2 instructions b) data that has been organized or presented in a B Level Syllabus R4    26  meaningful fashion  3.3 operating system c)any part of the computer that you can physically touch  3.4 processing d)a set of computer programs that enables hardware to perform different tasks  3.5 information e)the most common type of system software  it controls the way in which the computer system functions  3.6 data f)the main circuit board in the system unit  3.7 Memory g) the representation of a fact or idea (unprocessed information)  3.8 system software h)holds instructions or data that the CPU processes  3.9 storage i)processed data or information  3.10 motherboard j)data or information that can be accessed again   k)the set of programs that enables computer hardware devices and application software to work together   l)steps and tasks necessary to process data into usable information 4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below:  (a) Read  (b) magneto-optical  (c) Attachment  (d) Thesaurus  (e) backup  (f) Operating   system  (g) Microprocessor  (h) Netiquette  (i) Assembler  (j) algorithm 4.1 A storage device that uses a combination of magnetic and optical (laser) technologies is a _____ storage device. 4.2 A(n) ________ is the CPU of a computer. 4.3 A(n) ___________ is a program that converts an assembly language program to a machine language program. 4.4 The operation that takes data out of a specific memory location is the _________ operation. 4.5 _____________ is an electronic document such as a Word file that is sent along with an email message 4.6 ___________is a part of your Word Processor that will give you a list of antonyms or synonyms for chosen words  4.7 A _________ is a copy of one or more files created as an alternate in case the original data is lost or becomes unusable. 4.8 _______________ involves respecting others' privacy and not doing anything online that will annoy or frustrate other people. 4.9 __________is the software that communicates with computer hardware on the most basic level. 4.10 An __________ is a set of instructions  sometimes called a procedure or a function  that is used to perform a certain task on a computer.  PART  TWO (Answer ANY FOUR questions) 5.  a. Differentiate between (i) Control Unit and Arithmetic Logic Unit (ALU) (ii) Volatile Storage and Non volatile Storage (iii) System Software and Application Software   (iv) Impact and non impact printer B Level Syllabus R4    27   b. What are the components of Central Processing Unit? What are their functions? (8+7) 6. a. What are the principal functions of an Operating System? What is a multitasking operating system b. Give the differences between compiler and interpreter? c. As working with Linux OS all files and directories have security permissions; what are those and how chmod command helps in operating all those permissions? (5+5+5) 7. a. What is a template and what are the advantages and disadvantages of using one? b. What is mail merge?  Explain the steps to mail merge two documents using MS-WORD? c. What is the role of Control Panel in Windows? (5+5+5) 8. a. What are the main functions of Database Management System (DBMS)?  How will  you differentiate it from File Management System? b. Why is data validation necessary? What are the different types of data validation checks that are kept in a programme? c. Define the meaning of Data Structures. (5+5+5) 9. a. Explain about Animating Text and Objects on the Slides of your Presentation. b. What is the difference between relative and absolute references? c. What is the purpose of Presentation Software in edutainment? Explain the features provided by Power Point softwares of embedding video and animations.  (5+5+5) B Level Syllabus R4    28  B1.1-R4: IT TOOLS AND BUSINESS SYSTEM  Assignment 1.    In a library  librarian has to maintain various books. He has made various categories according to the subject. The tree structure for the various directories are shown below                 Subjects          Arts                   Science         Social Sc             Hindi                   Others    Social    Psycho  Physics  Chem   Math     Language    Grammar                                           Solution.txt                       Mphysics     Optics     Civics            History                                                        Law.txt            Egypt.txt                                                        Oldlaw.txt        h1.txt          Create the above structure using DOS Commands.       Using the above tree structure do the following (a) Imagine you are in psycho directory and from this location copy all                     files of Civics directory to the Others directory. (b) List all the files of civics directory using the same location. (c) Copy all the directories and subdirectories of  SocialSc to others.     Assignment 2.    Imagine you are in the others directory. From this location give the DOS commands for the following  B Level Syllabus R4    29  (a) Display all the files of civics directory (b) Delete the files from the mphysics physics (c) Display all the files  which have extension of txt under the math directory. (d) Copy the directory optics under the mphysics directory.  Assignment 3.   Create the following folders under the specified locations using windows. a) D1 on desktop b) R1 on the c: i.e. root c) D2 on desktop d) R2 on the c:  Do the following:  (i) Create a folder D1-1 under the D1 folder (ii) Create a folder D2-1 under the D2 folder (iii) Copy this D2-1 folder and paste it under R1 folder. (iv) Delete the folder D2-1 from R1 folder (v) Create the folder R1-1 under R1 folder (vi) Copy R1-1 folder under the R2 folder (vii) Rename folder R1-1 under R2 folder as subfolder of R2 (viii) From the c: copy all files to folder R2 (ix) Delete all the files from the folder R2 (x) Recover all the deleted files  Assignment 4.    Do the following (i)  Interchange the functions of left and right mouse buttons. (ii)  Change the wallpaper of your computer and set it to a paint brush file         made by you. (iii) Change the screen saver of your computer and change it to marquee                set your name as the text and wait time should be 2 minutes.  Assignment 5.   Do the following settings a) Display pointer trails b) Change the normal pointer of a mouse to another pointer c) Set the date advanced by 2 months d) Reset the system date & time e) Set the system time late by 2 hrs: 40 minutes. Assignment 6.   Create a document in Word on a topic of your choice. Format the document with various fonts (minimum 12  maximum 15) and margins (minimum 2  maximum 4). The document should include a) A bulleted or numbered list B Level Syllabus R4    30  b) A table containing name  address  basic pay  department as column heading c) A picture of lion using clip art gallery d) An example of word art e) A header with student name & date f) A footer with pagination Assignment 7.    Create a document with the text given below and save it as First.Doc  A Read only Memory is a memory unit that performs the read operation only  it does not have a write capability. This implies that binary information stored in a ROM is made permanent during the hardware production of the unit and cannot be altered by writing different words into it. Whereas a RAM is a general-purpose device whose contents can be altered during the computational process  a ROM is restricted to reading words that are permanently stored with in the unit. The binary information to be stored  specified by the designer  is then embedded in the unit to form the required interconnection pattern. Do the following a) Count the occurrences of the word ROM in the above document. b) Replace ROM with Read Only Memory in the entire document c) Underline the text Read Only Memory d) Make an auto correct entry for ROM and it should be replaced by Read Only Memory  Assignment 8.   Use first.doc to perform the following operations a) Make the first line of document bold b) Make the second line italic c) Underline the third line d) Align the fourth line to center e) Make the font color of first line as red f) Change the font style of fifth line to Arial g) Change the second line to 18 points h) Insert the date & time at the start of document Assignment 9.   Use the document earlier saved and perform the page setting as follows Top Margin     1.3 Bottom margin                1.4 Left margin     1.30 Right margin     1.30 Gutter margin     1.2 B Level Syllabus R4    31  Header                  0.7 Footer                  0.7 Paper size     executive Orientation     landscape Assignment 10.   Insert a table. The table should have 5 columns. The auto behavior should be Fixed column width. The following report has to be created in the table. Sr. No. Name Basic Pay Designation Department  Rahul Roy 10000/- MD Marketing  Ritu Garg 12000/- AD Sales  Mohit 8000/- Manager Sales  Rakesh 9000/- Senior Manager HR (a) Heading should have a font size of 18  color should be blue and font should be bold. (b) The data should have a font size of 12  color should be Red and font should be italic (c) Insert a new row between 3 & 4 and type the data and reorder the sr. no column.  Assignment 11.    Create a table in word as shown below Roll No Name Marks in Physics Marks in Chemistry Total Marks  Ritu 80 70  Rohit 70 80  Amit 60 50  Rakesh 40 60  Niti 30 70  Garima 80 80        Do the following (a) In the total marks column  entries should be calculated using formulas and it is the sum of marks in physics and marks in chemistry. (b) Insert a new row at the end of the table and also find grand total using formula. (c) Sort the table based on total marks (d) The date and heading should be center aligned (e) Heading should be in bold and underlined Assignment 12.   B Level Syllabus R4    32  Below is given a letter and some addresses  this letter is to be sent to all these addresses  so use mail merge option to do so Addresses are: 1)   Amit       H No 424 sector 8D       Chandigarh   2)   Rohit        H No 444  Sector 125C      Chandigarh  3)    Jyoti        H NO 550  Sector 16A        Chandigarh  The Letter is  To       Dear   You are called for an interview on the at 9:00 A.M with your original documents         Yours Sincerely         ABC Limited         Phase 7         Mohali  Assignment 13.   Make a template for the bio-data with the following format Bio-Data Name   : Fathers Name  : Date of Birth  : B Level Syllabus R4    33  Age   : Address   : Educational Qualification  Sr No Qualification Board Percentage Work Experience:  Assignment 14.   Make a document with the following 1. It should have 3 pages 2. It should have bookmarks named book1  book2  and book3 for the respective pages. 3. Using go to command go to the  i) Page no 2 j) Bookmark named book3 4. Insert one page break on page 2 to make total no. of pages 4. 5. Insert page number at each page Assignment 15.   (i) Make an auto correct entry so that a) Teh is replaced by The b) Nmae is replaced by Name c) Abouta is replaced by About a (ii) Define a Macro Decorate which makes the text bold  Red in color and italic  font size 14. Assign a shortcut key Alt + Z to this macro. Assignment 16.   Type the following data in excel worksheet and save it as first.xls  513 501 504 513 B Level Syllabus R4    34  511 516 532 504 432 501 510 517 479 494 498 Do the following  (a) Highlight column A and copy it to column C (b) Sort the data in column C in ascending order (c) What is the lowest number in the list (use a function) (d) Copy the data in column A to column E and sort it in descending order (e) What is the highest number in the list (use a function) (f) How many numbers in this list are bigger than 500 (use a database  function) (g) How many numbers in column A are between 520 and 540 inclusive        (use a database  function) Assignment 17.   Type the following data in excel worksheet and save it as second.xls.  A B C D People per physician Life Expectancy   X Y X * Y  370 70.5   6166 53.5   684 65   449 76.5   643 70   1551 71   616 60.5   403 51.5    Do the following B Level Syllabus R4    35  (a) Complete column C for finding product x * y (b) Find sum of x column at the end of data (c) Find sum of y column at the end of data (d) Find sum of x * y  column at the end of data (e) Find sum of x^2  (f) Find sum of y^2  Assignment 18.   Enter the following data and save it in grade .xls  Name Marks1 Marks2 Marks3 Total Percentage Grade Amit 80 70 80    Renu 70 60 90    Rajeev 60 50 80    Manish 50 30 90    Sanjeev 40 40 80    Anita 70 70 90           Do the following (a) Compute the total marks and percentage of each student by entering appropriate formula. (b) Compute the grades based on following criteria If percentage >= 90 then grade = A If percentage >=  80 and = 70 and = 60 and B Level Syllabus R4    36  4 2005 400 600 500 550  5 2006 456 450 550 450  6 Total       (a) Complete the report to calculate the course wise average in row 6 (b) Provide formula to calculate year wise average in column G (c) Generate a column chart to compare data  Assignment 21.   A person wants to start a business and he has four schemes to invest money according to profit and years. Find out which scheme is the most profitable.  Investment Amount Percentage for Profit No of years 20000 10% 6 years 40000 20% 5 years 14000 30% 4 years 12000 15% 5 years  Assignment 22.   A company records the details of total sales (in Rs. ) sector wise and month wise in the following format   Jan Feb March April Sector 30 12000 17000 14000 15000 Sector 22 14000 18000 15000 16000 Sector 23 15000 19000 16000 17000 Sector 15 16000 12000 17000 18000  (a) Enter the data in a worksheet and save it as sector.xls (b) Using appropriate formula  calculate total sale for each sector (c) Create a 3-D column chart to show sector wise data for all four months (d) Create a 3-D pie chart to show sales in Jan in all sectors  Assignment 23.   Type the following data and save it in employee.xls  Name Department Designation Salary Address Anju TRG MD 100000 CHD Amit TRG AD 200000 MOHALI Renu BILL MD 300000 CHD B Level Syllabus R4    37  Anita BILL AD 20000 MOHALI Shivani S/W MD 10000 CHD  Do the following (a) Count the total no. of employees department wise (b) List the name of employees whose designation is MD (c) List the name and department of employees whose address is Chandigarh (d) List the name of employees whose salary is greater than 5000 (e) List the Address of employees whose department is TRG  Assignment 24.   Using above sheet do the following (a) Count the total no. of employees who have salary greater than 10000 (b) Count the total no. of employees who are MD (c) Find the maximum salary department wise (d) Find the minimum salary designation wise  (e) Count the employees for each designation for each department  Assignment 25.   Create a table with the following field names in MS-Access     Name of field   Data type   Book_name Varchar   Purchase_date Date   Price Numeric   Author_name Varchar          Do the following a) Enter 5 records in the table using forms b) Display list of books in alphabetical order using reports c) Display list of books in ascending order of price B Level Syllabus R4    38  B1.2-R4: INTERNET TECHNOLOGY AND WEB DESIGN  Objective of the Course  The aim of this course is to provide you the conceptual and technological developments in the field of Internet and web designing with the emphasis on comprehensive knowledge of Internet  its applications and the TCP/IP protocols widely deployed to provide Internet connective worldwide. The World Wide Web with its widespread usefulness has become an integral part of the Internet. Therefore  this course also puts emphasis on basic concepts of web design.   At the end of the course the students will be able to: -    Review the current topics in Web & Internet technologies.  Describe the basic concepts for network implementation.  Learn the basic working scheme of the Internet and World Wide Web.  Understand fundamental tools and technologies for web design.  Comprehend the technologies for Hypertext Mark-up Language (HTML).  Specify design rules in constructing web pages and sites.  Effectively deal with programming issues relating to VB Script  JavaScript  Java  ASP  Front Page and Flash.  Figure out the various security hazards on the Internet and need of security measures.  Outline of Course  S. No.   Topic Minimum number of hours 1. Introduction to Internet 02 2. TCP/IP  Internet Technology and Protocol 03 3. Internet Connectivity 03 4. Internet Network 04 5. Services on Internet (Definition and Functions) 04 6. Electronic Mail 07 7. Current Trends on Internet 03 8. Web Publishing and Browsing 10 9. HTML Programming Basics 12 10. Interactivity Tools 08 11. Internet Security Management Concepts  Information Privacy and Copyright Issues 04 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. Introduction to Internet                 02 Hrs. Internet  Growth of Internet  Owners of the Internet  Anatomy of Internet  ARPANET and Internet history of the World Wide Web  basic Internet Terminology  Net etiquette. B Level Syllabus R4    39  Internet Applications  Commerce on the Internet  Governance on the Internet  Impact of Internet on Society  Crime on/through the Internet.   2. TCP/IP  Internet Technology and Protocol                                             03 Hrs. Packet switching technology  Internet Protocols: TCP/IP  Router  Internet Addressing Scheme: Machine Addressing (IP address)  E-mail Addresses  Resources Addresses  3. Internet Connectivity                                      03 Hrs. Connectivity types: level one  level two and level three connectivity  Setting up a connection: hardware requirement  selection of a modem  software requirement  modem configuration  Internet accounts by ISP: Telephone line options  Protocol options  Service options  Telephone line options  Dialup connections through the telephone system  dedicated connections through the telephone system  ISDN   Protocol options  Shell  SLIP  PPP  Service options  E-mail  WWW  News Firewall etc.   4. Internet Network                                       04 Hrs. Network definition  Common terminologies: LAN  WAN  Node  Host  Workstation  bandwidth  Interoperability  Network administrator  network security  Network Components: Severs  Clients  Communication Media  Types of network: Peer to Peer  Clients Server  Addressing in Internet: DNS  Domain Name and their organization  understanding the Internet Protocol Address.  Network topologies: Bust  star and ring  Ethernet  FDDI  ATM and Intranet.   5. Services on Internet (Definition and Functions)                                  04 Hrs. E-mail  WWW  Telnet  FTP  IRC and Search Engine   6. Electronic Mail                                                 07 Hrs. Email Networks and Servers  Email protocols SMTP  POP3  IMAp4  MIME6  Structure of an Email  Email Address  Email Header  Body and Attachments  Email Clients: Netscape mail Clients  Outlook Express  Web based E-mail. Email encryption- Address Book  Signature File.  7. Current Trends on Internet                          03 Hrs. Languages  Internet Phone  Internet Video  collaborative computing  e-commerce.  8. Web Publishing and Browsing                          10 Hrs. Overview  SGML  Web hosting  HTML. CGL  Documents Interchange Standards  Components of Web Publishing  Document management  Web Page Design Consideration and Principles  Search and Meta Search Engines  WWW  Browser  HTTP  Publishing Tools  9. HTML Programming Basics                          12 Hrs. HTML page structure  HTML Text  HTML links  HTML document tables  HTML Frames  HTML Images  multimedia   10. Interactivity Tools                                      08 Hrs. ASP  VB Script  JAVA Script  JAVA and Front Page  Flash  11. Internet Security Management Concepts  Information Privacy and Copyright Issues  04 Hrs. Overview of Internet Security  Firewalls  Internet Security  Management Concepts and Information Privacy and Copyright Issues  basics of asymmetric cryptosystems.   B Level Syllabus R4    40  RECOMMENDED BOOKS  MAIN READING  1. Greenlaw R and Hepp E Fundamentals of Internet and www 2nd EL  Tata McGrawHill 2007. 2. Ivan Bayross  HTML  DHTML  JavaScript  Perl CGI  3rd Edition  BPB Publications. 3. D. Comer  The Internet Book  Pearson Education  2009.   SUPPLEMENTARY READING  1. M. L. Young The Complete reference to Internet  Tata McGraw Hill  2007. 2. Godbole AS & Kahate A  Web Technologies  Tata McGrawHill 2008. 3. Jackson  Web Technologies  Pearson Education  2008. 4. B. Patel & Lal B. Barik   Internet & Web Technology   Acme Learning Publishers. 5. Leon and Leon  Internet for Everyone   Vikas Publishing House. B Level Syllabus R4    41  B1.2-R4: INTERNET TECHNOLOGY AND WEB DESIGN   Model Question Paper NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS                     TOTAL MARKS: 100        (PART ONE: 40; PART TWO: 60) PART ONE (Answer all the questions; each question carries ONE mark)  1. Each question below gives a multiple choices of answers. Choose the most appropriate one.                        1.1. Which type of network is most  likely confined to a building or a campus a) Local area  b) Metropolitan area c) Wide area d) Departmental  1.2. Which programming language always makes platforms-independent  application a) Java  b) Visual basic c) C++ d) C  1.3. Which best describes support over serial line communication under the TCP/IP Protocol . a) SLIP b) PPP c) Both A B  d) None  1.4. If a group of network computers connect to a central hub the network has what type of Physical Topology  a) Ring b) Star c) Bus d) None  1.5. If a group of computer connected to a central concentrator  the network has what type of logical topology? a) Ring. B Level Syllabus R4    42  b) Sart c) Bus d) INone  1.6. The transport layer protocol is a) ALP b) PPX c) TCP  d) None  1.7. The UDP is part of the which protocol suite a) TCP/IP  b) IPX/SPX c) Apple Talk d) NetBEUI  1.8. JDK  (Java Development Kit) include . a) Java b) Javac c) JDB d) All    1.9. Buffer over flow attacks means a) Collect and relay some data b) Get full system access  c) Play and display advertisement d) Slow down system  1.10. A firewall can be   a) A Hardware b) A  Software c) Both software and Hardware  d) Network Engine 2. Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book.  2.1. The Word Wide Web  is a very large set of interlinked hypertext documents accessed viahe Internet. 2.2. World Wide Web is  synonymous with Internet. 2.3. Packet switching is a network communications method that does not  groups all Transmitted data  irrespective of content  type  or structure into suitably-sized blocks  called packets  2.4. The ARPANET computer network made a large contribution to the development of the  e-mail.  2.5. SMTP is the push protocol that can not pull information from a remote server on demand. 2.6. Disaster recovery is the recovery of documents   in case of destruction from fires  floods earthquake etc.  2.7. Streams can not controlled the flow of data from one source to another 2.8. The TCP/IP is slower then NetBEUI 2.9. A user level access is less secure then share level access 2.10. The ability of the new object to implement the base functionality of the parent object in new way is called inheritance  B Level Syllabus R4    43  3. Match words and phrases in column X with the nearest in meaning in column Y. X Y 3.1    server would constantly send new data to the client through the initial connection  that remains open a) Spoofing      3.2    A kind of forgery  mail assume to be send from know person but actually they are not  b) SGML    3.3    It is an application-layer Internet standard protocol used by local e-mail clients to retrieve e-mail from a remote server over a TCP/IP connection  c) Drug trafficking    3.4   It is an ISO Standard metalanguage in which one can define markup languages for documents .. d) Web server push  3.5    The ability of a system or product to work with other system or product without much efforts  e) Web designing 3.6    Encoding data to make them unintelligible to unauthorized persons  f) Thread 3.7   use of  Internet to sell their illegal substances through encrypted e-mail and other Internet Technology g) Interoperability 3.8 Skill of designing hypertext presentation of   Content delivered to end user  h) Class Diagram 3.9 It can be divided into linear and non linear              technique categories  i) Scope  3.10  A single path of execution that is a sub process of the main process j) POP3  k) Encryption  l) Multimedia  m) nesting 4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below :  (a) Cache  (b) URL  (c)  Cyberterrorism (d) metadata   integration   (e) IMAP4  (f) enterprise data    modeling outer jain  oouter outer join (gHeader Body  (h) CASCADE   (i) Interleaved main    memory (j) Virtual memory  (k) bus  (l) website   (m) Applet  4.1. Viewing a Web page on the World Wide Web normally begins  by typing the _____ of the page into a Web browser. 4.2. Web page data may  need not to be re-obtained from the source Web server. Almost all Web browsers _______ the recently obtained data on the local hard disk  4.3. The internet e-mail message consist of  two major section that are __________ and _______  4.4.  _______ is one of the two most prevalent protocol for e-mail retrieval.  4.5. ______ is act of terrorism committed through the use of cyberspace or computer  4.6. _______ and  _________. are the part of the document management  4.7. _____ collection of information about a particular topic or subject  4.8. A class that has no direct instances  but whose descendants may have direct instances is called a _______  _______.  B Level Syllabus R4    44  4.9. Java communicate with the web page through a special tag called ________. 4.10.  In ______ topology all device connect to a common shared cable. PART TWO (Answer any FOUR questions) 5.  a. What  was the various firewall technique. (6) b. What is interoperability and how product or system achieve interoperability. c. Explain the advantages  of Peer to Peer (P2P)  network? (6+5+4) 6.  a. What is the difference between SLIP and PPP ? b. Explain the difference between router  repeater and bridge c. Explain FDDI.  (6+5+4) 7.  a. What are the various network topologies explain with example. b. What is Net etiquette?  (10+5) 8.  a. What do you understand with e-commerce explain with example (8) b. Define document management                                        (8+7) 9.      a. Explain Web template system  b. What is world wide web ? what is the contribution of java to the world wide web. c. What is token? List the various type of tokens supported by the java. (4+6+5)  B Level Syllabus R4    45  B1.2-R4  : INTERNET TECHNOLOGY AND WEB DESIGN  Assignment  1.   Internet Surfing  a) Open the website of Yahoo! with the help of Internet Explorer or Netscape Browser b) Check the properties of your browser. c) Change the Home Page of your browser. d) Check the History and clear the history. e) Create a Bookmark. Assignment  2   Email  a) Create your email account on any of the familiar email services like hotmail     yahoo  rediffmail etc. b) Compose and send an email to a friend. c) Get the email addresses of five of your classmates.  Add them to the address  book of your email program.  Send them each an email. d) Receive an email from a friend. e) Attach a document to the email. f) Retrieve an attachment from an email received.  Assignment  3    Search Engines  a) Open the search engines google and search for Doeacc b) Check the Advanced Search Options of Google. c) Open the search engines Yahoo and search for Indian Railway Assignment  4   Web Chart and Usenet  a) Start Netscape and select Communicator  Messenger from the menu.  Try various ways of driving Usenet News via Netscape Messenger.  Look at some serious news group and set-up chat session. b) Open Windows Messenger and create a chat session with your friend  Assignment  5   Web Page Development -HTML  Create a basic web page using Netscape Composer.  The topic of the web page is up to you (within acceptable use).   Create a web page containing information about you  your family and friends.  Enter a suitable title for your page.  Add some sub-titles for different sections of your text.  For example  you could have a subheading for where you live  your family  your interests etc.  B Level Syllabus R4    46   Format the text of your web page in different Font  Alignment styles.  Move the cursor to a sub-title and set it to Heading2. Experiment with the different heading styles to see what each one does .Which of these styles do you think is useful?  Which are less useful?  Why?  Experiment with the font size  color  style (bold  italic  underline  etc.) and alignment (left  center  right or indented.   See the HTML that is generated by Browser by selecting View Page source.   Add a picture to your web page.  You have scanned in  or one taken with a digital camera.  Alternatively  you can use a picture from another web page.  Remember that if you put pictures that you did not take on your web page  you must check for copyright permission first.  Experiment with different sizes of picture and different locations within your web page.  Also  experiment with different alignment and text wrappings.  One minor problem with Netscape Composer is that it does not give proper WYSIWYG for pictures with text wrap.  You will have to save your page and view it in the browser to see exactly what the layout will be.  Your HTML documents should have the following characteristics: -  a) Use of paragraphs. b) Use of 1 or more levels of section headers. c) Use of highlighting (bold  italics  etc.) d) Use of lists. e) Use of internal links (to other parts of your document) commonly used for a document table of contents. f) Use of links to graphic images and alternate text  in case the image could not be found or is not loaded (alternatively). By using the above items one should be able to create his/her own home page.  Assignment  6   Create a document with two links to an external document.  The first link should lead to the beginning of the external document.  The second link should lead to a particular section in the external document.  In the external document specify a link that will lead to a particular section within it.  Text Content:  Welcome to our homepage This page has links to the website of ABC Lever Inc.  For further information click on any of the following:   About ABC Lever Inc.  Contact Information  Content of Linked pages is  B Level Syllabus R4    47  Contact us  ABC Lever Inc. is a conglomerate that has interests ranging from bodycare products to toilet soaps.  A couple of years ago we entered the frozen Food industry through mergers and Acquisitions. Last year we started our plant to manufacture salt and this year it is wheat flour. Our current turnover is about Rs. 7500 cr and by the next decade we are looking at a target of 15000 cr.  Contact Us  You can contact us at the following address:-  ABC Lever Inc. 101 Maker Chambers III  Nariman Point  Mumbai-21 Tel. 2102011  You can also email us at customersservices@abclever.com  Assignment  7   Prepare a ""resume.html"" that might include such information as:  a) distinguishing marks  b) special interests  c) work history  d) education and training  e) job objective  f) relevant skills and experience  Assignment  8  Create the following HTML page B Level Syllabus R4    48  The keywords for the page are travel  recreation  and flight reservations. The description for the page is Island Quest Travel can help you make reservations for an exotic island vacation. The words Flight Reservations links to a file called reservations.html. The words Island Quest Travel are an email link to quest@travel.com  Assignment  9  Design the form using HTML tags.  Employment Exchange  First Name    :  Second Name   :  Father's Name :  Date of Birth :  Sex Code      :  M  F Qualification : High School                                 B Level Syllabus R4    49  Stream  Science  Percentage Marks :  Nationality   :  Religion      :  Category      : SC  Mailing Address   :  Permanent Address :   OK   CLEAR Assignment 10   Design the following web page using HTML Tags:  B Level Syllabus R4    50  Assignment 11 Design the above webpage in which the links for courses  should be in the same page with the following details:  Short term Courses. Doeacc Center offers following short-term courses   a) Use of Personal Computer  b) 'C' Language  c) 'C++"" Language  d) Visual Basic  e) Oracle/Dev. 2000  f) AutoCAD  g) Internet and Web Designing  Long term courses  Doeacc Center offers following long-term courses  a) O' Level  b) A' Level  c) B' Level  d) C' Level  Corporate courses  Doeacc Center offers following corporate courses  a) Use of Personal Computer  b) Courses according to their requirement  Assignment  12  a) Make a table with your friends details in it.  b) Column One  your friends names  c) Column Two  Address of your friends  d) Column Three  Mobile No of your friends  e) Column Four  Birth-Date of your friends  Assignment  13  B Level Syllabus R4    51  a) Create a 4x3 table  b) Within each table  place 12 images of Indian Tourist Spots  in each box  c) Each image link to the corresponding site of Tourist Spot  d) Each Image must be at least 100x100 in size Assignment  14   Create a page with two frames  The left frame of page contains the list of names & Images of the Indian National Heros..   On the left frame when you click on name or image  the details will be shown on the right frame.  Assignment  15  create a job application form  Create an area called section one and place text boxes that receives details - a) Name  b) Age  c) Gender  d) High School  e) Qualifications    Create an area called section two and place text boxes that receives details -  a) Previous Employment  b) References  c) Qualification    At the end place a submit button   Assignment  16   a) Take the picture of the motherboard  b) Place an image map on each item that is pointed out on the picture  c) Have them link to some information that you know about them.  d) There should be some sort of navigation or a back button on each page   Web Page Development  DHTML  Assignment   17   Create a style in the  section a) Change the lists size to h4  b) Change the links size to h2  c) Both should also have different colors   Assignment  18  Create a style in the  section a) Create a list of each persons first name in the class  b) Have each name have a different color and or size  c) your name must be the biggest  B Level Syllabus R4    52  Web Page Development - VbScript  Assignment  19  Write VbScript code for displaying an alert dialog box with OK button  welcoming a user with a message Welcome To my Web Site.  As soon as the OK button is clicked  an image is displayed in the web browser.  Assignment  20  Create a VbScript file that contains  a) a textbox to accept a string and a button. b) When user clicks the button the script checks whether that string is palindrome or not  Web Page Development  JavaScript  Assignment  21    Validate the form in assignment -9 . The following validation checks are required:  a) First name  second name should not be left empty b) Percentage marks should be numeric c) Mailing address must contain @ symbol in it.  Assignment  22  Create a an HTML document containing JavaScript code that   a) Has a button called check out  b) when this button is clicked on   it summons two windows  c) Window 1: Have a question that tells user to input value of the item  d) Window 2: Have a question that requests the user to input the amount of sales tax   Have a sentence that displays the cost of the item  the sales tax  and your final price.  Assignment  23   Create a document that reads and stores cookies containing a user name and number of times   he or she has visited your website . Whenever the user visits the site  the system displays the cookies in alert dialogue box  increments the counter cookie by 1 and then resets the counters expiration date to one year from the current date.  Assignment  24   Create an HTML document that calculates the square feet of carpet required to carpet a room . Include three text boxes ; Create one text box for width of room and another for length of the room in linear feet . Also create a text box for the cost per square feet of carpeting. When you calculate the cost  add 25% to the total number of square feet to account for the closets and other features of the room. Display the total cost in an alert dialogue box.  Assignment  25 B Level Syllabus R4    53  Create a an HTML document with JavaScript code that   a) Has three textboxes and a button b) The details to be accepted using textboxes are principal  rate of interest  and duration in years. c) When user clicks the Ok button a message box appears showing the simple interest of principal amount B Level Syllabus R4    54  B1.3-R4: PROGRAMMING AND PROBLEM SOLVING THROUGH C LANGUAGE   Objective of the Course The objectives of this course are to make the student understand programming language  programming  concepts of Loops  reading a set of Data  stepwise refinement  Functions  Control structure  Arrays. After completion of this course the student is expected to analyze the real life problem and write a program in C language to solve the problem. The main emphasis of the course will be on problem solving aspect i.e. developing proper algorithms.     After completion of the course the student will be able to  Develop efficient algorithms for solving a problem.  Use the various constructs of a programming language viz. conditional  iteration and recursion.  Implement the algorithms in C language.  Use simple data structures like arrays  stacks and linked list in solving  problems.  Handling File in C. Outline of Course  S. No.   Topic Minimum number of hours 1. Introduction to Programming 04 2. Algorithms for Problem Solving 10 3. Introduction to C Language   04 4. Conditional  Statements and Loops 07 5. Arrays 06 6. Functions 06 7. Storage Classes 03 8. Structures and Unions 06 9. Pointers 06 10. Self Referential Structures and Linked Lists 04 11. File Processing 04 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. Introduction to Programming                                                                                04 Hrs. The Basic Model of Computation  Algorithms  Flow-charts  Programming Languages  Compilation  Linking and Loading  Testing and Debugging  Documentation   2. Algorithms for Problem Solving                                                                             10 Hrs. Exchanging values of two variables  summation of a set of numbers  Decimal Base to Binary Base conversion  Reversing digits of an integer  GCD (Greatest Common Division) of two numbers  Test whether a number is prime  Organize numbers in ascending order  Find square root of a number  factorial computation  Fibonacci sequence  Evaluate  sin x as sum of a series  Reverse order of elements of an array  Find B Level Syllabus R4    55  largest number in an array  Print elements of upper triangular matrix  multiplication of two matrices  Evaluate a Polynomial   3. Introduction to C Language                                                                                      04 Hrs.  Character set  Variables and Identifiers  Built-in Data Types  Variable Definition  Arithmetic operators and Expressions  Constants and Literals  Simple assignment statement  Basic input/output statement  Simple C programs.  4. Conditional Statements and Loops                                                                       07 Hrs. Decision making within a program  Conditions  Relational Operators  Logical Connectives  if statement  if-else statement  Loops: while loop  do while  for loop  Nested loops  Infinite loops  Switch statement  structured Programming .  5. Arrays                                                                                                    06 Hrs. One dimensional arrays: Array manipulation; Searching  Insertion  Deletion of an element from an array; Finding the largest/smallest element in an array; Two dimensional arrays  Addition/Multiplication of two matrices  Transpose of a square matrix; Null terminated strings as array of characters  Standard library string functions  6. Functions                                                                                                     06 Hrs. Top-down approach of problem solving  Modular programming and functions  Standard Library of C functions  Prototype of a function: Formal parameter list  Return Type  Function call  Block structure  Passing arguments to a Function: call by reference  call by value  Recursive Functions  arrays as function arguments.   7. Storage Classes                                                                                                       03 Hrs. Scope and extent  Storage Classes in a single source file: auto  extern and static  register    Storage Classes in a multiple source files: extern and static  8. Structures and Unions                                                                                            06 Hrs. Structure variables  initialization  structure assignment  nested structure  structures and functions  structures and arrays: arrays of structures  structures containing arrays  unions   9. Pointers                                                                                                            06 Hrs. Address operators  pointer type declaration  pointer assignment  pointer initialization  pointer arithmetic  functions and pointers  Arrays and Pointers  pointer arrays  pointers and structures  dynamic memory allocation.  10. Self Referential Structures and Linked Lists                                                     04 Hrs. Creation of a singly connected linked list  Traversing a linked list  Insertion into a linked list  Deletion from a linked list   11. File Processing                                                                                                      04 Hrs. Concept of Files  File opening in various modes and closing of a file  Reading from a file  Writing onto a file   RECOMMENDED BOOKS  MAIN READING   1. Byron S Gottfried Programming with C Second edition  Tata McGrawhill  2007 (Paper back) B Level Syllabus R4    56  2. R.G. Dromey  How to solve it by Computer  Pearson Education  2008. 3. Kanetkar Y  Let us C  BPB Publications  2007. 4. Hanly J R & Koffman E.B  Problem Solving and Programm design in C  Pearson Education  2009.  SUPPLEMENTARY READING  1. E. Balagurusamy  Programming with ANSI-C  Fourth Edition 2008  Tata McGraw Hill. 2. Venugopal K. R and Prasad S. R  Mastering C  Third Edition  2008  Tata McGraw Hill. 3. B.W. Kernighan & D. M. Ritchie  The C Programming Language  Second Edition  2001  Pearson Education 4. ISRD Group  Programming and Problem Solving Using C  Tata McGraw Hill 2008. 5. Pradip Dey   Manas Ghosh  Programming in C  Oxford University Press  2007.  B Level Syllabus R4    57  B1.3-R4: PROGRAMMING AND PROBLEM SOLVING THROUGH C LANGUAGE  Model Question Paper NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS  TOTAL MARKS: 100 (PART ONE - 40; PART TWO - 60) PART ONE (Answer ALL Questions; each question carries ONE mark) 1. Each question below gives a multiple choices of answers. Choose the most appropriate one. 1.1 The programming Language C  happens to be   a) An Assembly Level Language. b) A High Level Language with some Assembly Level Language Features. c) A Programming Language used only to write System Software. d) A Programming Language used for developing Application Packages only. 1.2 The C declaration int I_a; implies        a) The variable I_a is a signed Binary Integer . b) The variable I_a is an Unsigned Decimal Integer. c) The variable I_a is an signed Hexadecimal  Integer. d) The variable I_a is a signed  Integer that can be expressed in any Base. 1.3     The C statement  printf (The Value =%x 62);  will print         a) The Value= 62  b) The Value = O62 c) The Value= OX 3C d) The Value= 3C 1.4 In the following C declaration                           float F_C = 12.5;                  void   VF_A (int);                int  main();    { /* begin main */                             float F_B;  F_C = 13.5;                                               return (0); }/* end main */ B Level Syllabus R4    58  a) The Variable  F_C is GLOBAL to both the functions main () as well as  VF_A. b) The Variable F_C is LOCAL to the function main(); c) The Variable F_C is LOCAL to the function VF_A. d) The Variable F_C is EXTERNAL.           1.5    Consider the following C Program .         # define  S 10+2    #include    int main()                          { /* begin main */                                 int  Result  = S + S ;                                printf (\n\n Result = %d\n\n  Result ); /* Output Line #2 */                                 return (0);                            } /* end main*/ The Output generated by the above  C Program will be    a) Result = 10 b) Result = 12 c) Result = 24 d) Result = 20    1.6   What will be the Output generated by the following C Program ?         #include   int main()                          { /* begin main */                                                                int I_C ; float F_D   F_E;                                                              I_C = 5/2 ; F_D = 5/2 ; F_E = 5/2.0;                                 printf (\n I_C = %d  F_D =%f  F_E = %f \n\n  I_C F_D F_E);                                  return (0);                             } /* end main*/  a) I_C= 1  F D = 2.0  F_E = 2.5 b) I_C= 2  F D = 2.0  F_E = 2.5 c) I_C= 2  F D = 2.5  F_E = 2.0 d) I_C= 2  F D = 2.5  F_E = 2.5 1.7 In C Functions the actual expressions / parameters are passed on to Formal parameters using the method of : a) Call by reference. b) Call by Value Result. c) Call by Value. d) Call by Name.  B Level Syllabus R4    59  1.8 Consider the following C program segment :  typedef  struct  Point                      {  float  F_x; float  F_y; }Point_T; typedef  struct  Circle {  float  F_Radius;    Point_T  R_Center; }  Circle_T; int  main(); {  //  begin  main Point_T  R_Point;  Circle_T  R_Circle; /*  Circle  Manipulation  Statements  */ return(0); }  //  end  main To manipulate  a circle which of  the following set of assignment statements will have to be used ? a) R_Circle.F_Radius = 10.2; R_Circle.R_Center.F_x = 2.0 ; R_Center.F_y=3.0; b) R_Circle.F_Radius = 10; R_Circle..F_x = 2.0 ; R_Circle.F_y=3.0; c) R_Circle.F_Radius = 10.2; R_Circle.R_Center.F_x = 2.0 ;  d) R_Circle.R_Center.F_y=3.0; e) R_Circle.F_Radius = 10.2; R_Circle.F_x = 2.0 ; R_Circle.F_y=3.0; 1.9 In the following C Declaration                      #define CUI_Size 10                       typedef int AI_1D_01_T [CUI_Size];                     int main()                         {/* begin main */                              AI_1D_01_T  AI_1D_A;        The variable AI_1D_A represents   a) An  array of Integers of any size. b) An array of Integers having minimum 10 integers. c) An array of Integers having Maximum 10 Integers. d) None of the above.  1.10  Consider the following C Code   #include   #include   int  main  ()          {/*begin  main */                    int  I_X=6; int  *PI_Y; PI_Y  =  (int*)  malloc  (sizeof (int));  *PI_Y  =  I_X; printf("" *PI_Y  =%d"" *PI_Y); *PI_Y  =  7; printf  ("" I_X  =  %d"" I_X); return(0); B Level Syllabus R4    60  }  //  end  main  Which  among the following  will it produce as output ?  a) *PI_Y = 7  I_X = 6 b) *PI_Y = 6  I_X = 7 c) *PI_Y = 7  I_X = 6 d) *PI_Y = 6  I_X = 6 2.  Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book 2.1 In C  %x format can be used for Inputting  signed Octal Integers  (FALSE). 2.2 A Pointer variable content will be the Address of the variable it points to. (TRUE). 2.3 In C   a SINGLE scanf () can be used to read in the values of any number of pre-declared variables (TRUE). 2.4 Arrays in C are always stored in Column Major fashion (FALSE). 2.5 ! operator is a BINARY Operator in C. (FALSE). 2.6 Recursive functions provide an elegant way of representing  recurrences (TRUE). 2.7 Array represents a homogeneous Data Structure (TRUE). 2.8 A structure cannot be a member of an Union in C (FALSE). 2.9 In C *p++ increments the content of the location pointed to by p (TRUE). 2.10 A C Function can return a whole structure as its value (TRUE).  3. Match words and phrases in column X with the nearest in meaning in column Y. X  Y 3.1 Premature exit from within a C Loop  a)  1 Byte. 3.2 Character variable will have a size of  b) Indentation is essential  3.3 A C Function that do not return a value will be having  c) Call by Reference. 3.4 A string in C is terminated by  d) To open a file for writing after discarding its previous content 3.5 To understand the Blocks of C  e) An Integer type 3.6 Multiway branching in C can be implemented  f) A void type 3.7 All variables declared inside a function g) Are Local to that function 3.8 A Pointer Parameter in a C Function simulates  h) Opening a file in Read mode   retaining the previous content 3.9 A Linked List represents  i) A white space character. 3.10 In C fopen w mode is used  j) 4 Bytes   k) A \0 Charcter   l) A dynamic Data Structure   m) Using switch  case statement   n) Can be achieved by break statement   6. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below:  (a) Dividing (b) One or ZERO   (c) CPU Register (d) extern  (e) Optional (f) Randomly (g) At least once (h At run time B Level Syllabus R4    61   (i) Linked List   (j) An Array (k) Fields   4.1 The Operator I_Value >> 2  is equivalent to ______ I_Value by 4 . 4.2 The Declaration reg int IReg_C will allocate a ____________ for the variable IReg_C.  4.3 On executing f = ! (K  >10 ) f will have a value _______  4.4 The individual Elements of any Array can be accessed ________  4.5 The else portion of an if else statement in c is  _____  4.6 In C the body of do-while loop will be executed ______  4.7 Any variable starting with _____ in the declaration will be treated as an External variable   4.8 In C a polynomial  of the form 100 M 34  20M + 10 can be efficiently represented by a _____________   4.9 The Components of a Records are termed as _________    4.10 In C any dynamic data structure is created  ___________ . PART  TWO (Answer ANY FOUR questions) 5.  Consider the following C program Outline that DOES NOT USE any Structured Data Type like ARRAY or STRUCTURE or POINTER whatsoever ANYWHERE : #include   #include    /*  NO  OTHER  LIBRARY  CAN  BE  USED*/  #define  CI_Max  9999 #define  CI_Min  -9999 /*  NO  OTHER  USER  DEFINED  CONSTANTS   DATA  TYPES  OR  GLOBALS  CAN  BE USED*/ /*  User  Defined  Function  Prototypes.  NO  OTHER  FUNCTIONS  are used  */ void  VF_Read_Int  (  int   int   int*);  /*  READS  and  Returns  an Integer  through  its  pointer  parameter  provided  it  lies  between  a specific  range  passed  as  the  other  two  parameters  .  If  the  value read  in  within  the    happens  to  be  OUTSIDE  this  range   it  will continue  to    loop  &  print  the  message    Input  OUT  of range       Give    Again   and  wait  for  a  proper  value  to  be  inputted by  the  user.  */  int  IF_Test_Prime  (int)  ;  /*  Used  to  Test  MOST  EFFICIENTLY  whether the    Integer  passed  as  its  only  parameter  happens  to  be  Prime  or Not.  It  Returns  1  if  the  passed  Integer  is  prime  returns  0  if  it is  Non  Prime.  In  each  case     it  prints  an  appropriate  message within  it  */ int  main  () {//begin  main int  I_Value; /*  You  May  Employ  other  Simple  Variables  */ VF_Read_Int  (CI_Max   CI_Min   &I_Value); /*  Reads  in  an  Integer  Value  within  a  Specified  Range  */ VF_Print_NON_Prime_Factors  (I_Value); /*  Displays  all  the  NON  Prime  Factors  of  the  value  I_Value*/ return(0); B Level Syllabus R4    62  }//end  main  a.   Frame the body of the function  VF_Read_Int  .  The Function heading is as illustrated below :  void  VF_Read_Int  (int  I_High   int  I_Low   int  *PI_X) /*    READS  and  Returns  an  Integer  through  its  pointer  parameter provided  it  lies  between  a  specific  range  passed  as  the  other  two parameters  .  If  the  value  read  in  within  the   happens  to  be OUTSIDE  this  range   it  will  continue  to    loop  print  the message  {\bf  Input  OUT  of  range     Give    Again    and  wait  for  a proper  value  to  be  inputted  by  the  user. NO  OTHER  PARAMETER  CAN  BE USED.  */    b.  Frame the body of the function IF_Test_Prime  .  The Function heading is as illustrated below : int  IF_Test_Prime  (  int  I_Num)  /*  Used  to  Test  MOST  EFFICIENTLY whether  the  Integer  passed  as  its  only  parameter  happens  to  be prime  or  Not.  It  Returns  1  if  the  passed  Integer  is  prime  returns 0  if  it  is  Non  Prime.  In  each  case     it  prints  an  appropriate message  within  it  */ (6+9) 6.      Consider two  integer data files F1 and F2 having  following features.    a.  Number of data values (key)  in each file is unknown and the files may be          of different sizes.     b.   The values / Integer Keys  in both  the files F1 & F2 are Sorted in          Descending Order.   c.   Same data ( key)  can appear more than once in F1 or F2. d.  F1  and F2 may share common data values i.e. same key item may appear  both the files . Write a C function to merge the two files F1 and F2 to form a third  file F3 having the following features. -Elements in F3 are sorted in ascending order. - Duplicate entries  are not permitted (i. e.  No element appears more than once).  (15) 7.  The following operations are defined on a sorted Doubly linked list of Integers L where elements are arranged in Descending order from left. INSERT (L X) : Insert the integer X in the list L if X is not present.  DELETE (L X) : Delete the integer X from the list L (if it exists).  SHOW-MID (L)  : Print the n/2 th element of the list from left where n is the                                     Number of elements in the current list and we use integer                                     Division where 5/2 = 2 B Level Syllabus R4    63  Frame C functions to implement each of the above functions INSERT (L X)   DELETE (L X) and SHOW_MID( L)                                                        (6+6+3)  8.  a. In 2 (two) dimensions  a point can be described by its two coordinates namely X & Y both of which can be real numbers. A line can be described in the following manner : (i) The co-ordinates of its two end points  (X1  Y1) & ( X2  Y2 )  (ii) Its gradient m & intersection c (in  the form Y = mx + c)   (iii) The length of the line is also stored along with.    Specify appropriate data types to store a point as well as a line in C.                            (1+2)  b. Write a C function Point_to_Line (P1  P2) that will accept as parameters the coordinates of two points P1 & P2 and return a line that has the aforesaid 2 points as its end points.                           (5)  c.  A quadrilateral can be described by a sequence of 4(four) lines such that one end point of one line happens to be the starting point of the next line. Specify a suitable data structure in C to represent a quadrilateral.                          (2)  d.  Write a C function that will accept a quadrilateral as a parameter and classify it whether it is a  [2+2+3=7] A Square. A Rhombus. A Rectangle.    in each case it computes the perimeter as well.                         (2+2+3) 9.  a.  Write a single Recursive C function to generate the n th Fibonacci number Fib(n) ( n being a +ve non zero integer ) . You cannot use any array  global variables and/or additional parameters/functions. Trace out the Call & Return sequences along with return values clearly by a schematic diagram when your function Fib(n) is invoked from main() with n = 6. Also mention the TOTAL no. of times any Fib(n) is called for each value of n for invoking Fib(6) from main()  e.g. Fib(2) is called a total of 4 times etc.                           (2+5+2)                         b.  What will be the value of A(1  3) if A(m  n) happens to be defined in the following manner? Specify each computation step in detail .                                    A(0  n) = n + 1 for n  0 A(m  0) = A(m  1  1) for m > 0 A(m  n) = A(m  1 A(m  n - 1)) for m  n > 0 (6)  B Level Syllabus R4    64  B1.3-R4: PROGRAMMING AND PROBLEM SOLVING THROUGH C LANGUAGE  Assignment 1.   Write a program to find sum of all prime numbers between 100 and 500.  Assignment 2.   Write a program to obtain sum of the first 10 terms of the following series for any positive integer value of X :   X +X3 /3! +X5/5! ! +X7/7! +   Assignment 3.   Write a program to reverse the digits of a given number. For example  the number 9876 should be returned as 6789.  Assignment 4.   Write a program to compute the wages of a daily laborer as per the following rules :-   Hours Worked  Rate Applicable    Upto first 8 hrs Rs 50/-  For next 4 hrs  Rs 10/- per hr extra  For next 4 hrs  Rs 20/- per hr extra  For next 4 hrs  Rs 25/- per hr extra  For rest  Rs 40/- per hr extra  Accept the name of the laborer and no. of hours worked. Calculate and display the wages. The program should run for N number of laborers as specified by the user.  Assignment 5.   Write a program to input 20 arbitrary numbers in one-dimensional array. Calculate Frequency of each number. Print the number and its frequency in a tabular form.   Assignment 6.   Define 2 dimensional array a (3 3)  b(3 3) sum(3 3) diff(3 3) mult(3 3). Store 9 arbitrary numbers in a(3 3) and 9 arbitrary numbers in b(3 3). Do the following:   a)  Calculate sum of a(3 3) and b(3 3) and store in sum(3 3) where        sum(i j)=a(i j)+b(i j)  b)  Calculate difference of a(3 3) and b(3 3) and store in diff(3 3) where diff(i j)=a(i j)-b(i j)  c)   Calculate product of two arrays a(3 3) and b(3 3) and store in mult(3 3) where mult(i j)= summation of a(i k)*b(k j) over k where k=1 to 3.  Print the result in a tabular form  Assignment 7.   B Level Syllabus R4    65  Write a function  str_search(char* s1 char* s2  int n)   that takes two strings and an integer  as arguments and returns a pointer to the nth  occurrence of 1st  string s1 in 2nd  string s2  or NULL if it is not present.  Assignment 8.   Write a C function to remove duplicates from an ordered array. For example  if input array contains 10 10 10 30 40 40 50 80 80 100 then output should be 10 30 40 50 80 100.  Assignment 9.   Apply recursive call to do the following:  (i)    Input n(1-200). Calculate sum of n numbers.  (ii)   Input n(1-20). Calculate product of n numbers.  (iii) Input n(2-20). Print n number of Fibonacci numbers.  In Fibonacci sequence the sum of two successive terms gives the third term. The following are few terms of Fibonacci sequence :-  1 1 2 3 5 8 13   Assignment 10.   Write a program which will arrange the positive and negative numbers in a one-dimensional array in such a way that all positive numbers should come first and then all the negative numbers will come without changing original sequence of the numbers.  Example:  Original array contains: 10 -15 1 3 -2 0 -2 -3 2 -9                     Modified array: 10 1 3 0 2 -15 -2 -2 -3 -9  Assignment 11.    Write a menu driven program to maintain a Telephone Directory having following file structure:  1. Name :     Character type : Length =20 characters.  2. Address :  Character type : Length =40 characters.  3. Phone:      Character type : Length =12 characters.   Menu  1. Add record(s)  2. Display record(s)  3. Search record(s)  4. Modify record(s)  5. Delete record(s)  6. Backup copy of File  7. Exit  Type your choice= 1 2 3 4 5 6 7 ->Assignment 12.   Write a program to extract words form any text file and store in another file. Sort the words in alphabetical order and store them in the same file. Read the sorted file and print the frequency of each word.   Assignment 13.  B Level Syllabus R4    66  Write a program to remove all occurrences of word the and The from an input string. For example     Input : The Dhillon Theatre is now the Fun Republic.  Output :  Dhillon  atre is now Fun Republic.  Assignment 14.   Write a program to display the Following pattern called Floyeds Triangle.  1  2 3  4 5   6  7   8   9 10                         11  12  13 14 15  Assignment 15.  Write a program that accepts an input integer n in the range 3-9 inclusive  and display the following pattern on a cleared screen.  Sample input for n=3     Sample input for n=4              Sample output           Sample output 3                                                                4                          3 2 3                                                             4 3 4                       3 2 1 2 3                                                        4 3 2 3 4                          3 2 3                                                        4 3 2 1 2 3 4 3 4 3 2 3 4                                                                     4 3 4                                                                        4 Assignment 16.   Write a program to count the vowels in free text given as standard input. Read text one character at a time until you encounter end-of-data. Then print out the number of occurrences of each of these vowels.  Assignment 17.   Write a program to copy one file to another such that every word is reversed before being written to the target file. Assume the maximum size of each word is 10 characters and each word is separated either by new line(s)  tab(s)  or space(s). For example  if source file contains I am an Indian  the target file should contain I ma na naidnI.  Assignment 18.   Define a structure for an Employee having EmployeeName  EmployeeCode  BasicPay  DearnessAllowance  HRA  PF  GrossPay  NetPay Take an array of 10 Employees. Write C functions to :-  B Level Syllabus R4    67  a) Accept data for EmployeeName  EmployeeCode  BasicPay for all the employees.  b) Compute :- a. DearnessAllowance = 50% of BasicPay b. HRA = 20% of BasicPay + DearnessAllowance c. PF = 12% of BasicPay + DearnessAllowance d. GrossPay = BasicPay + DearnessAllowance + HRA e.  NetPay = GrossPay  PF c) Display the name of employee who has highest GrossPay. d) Compute and display average net pay. e) Display list of all employees in the alphabetical order of employee name. Assignment 19.   Write a program to convert a given decimal number to its binary equivalent and vice versa.  Assignment 20.   Input any positive integer number (n FILETYPE   MYFILE.TXT   Assignment 25.   Write a program to input name  address and telephone number of n persons (nB Level Syllabus R4    68  B1.4-R4: COMPUTER SYSTEM ARCHITECTURE  Objective of the Course Objective of the course is to familiarize students about hardware design including logic design  basic structure and behavior of the various functional modules of the computer and how they interact to provide the processing needs of the user. This subject mainly focuses on the computer hardware and system software. It aims to describe the following aspects   Building blocks of the computer  Computer Design  Assembly Language Programming Outline of Course  S. No.   Topic Minimum number of hours 1. Digital Components 10 2. Data Representation 04 3. Register Transfer & Micro Operations 04 4. Basic Computer Organization 04 5. Central Processing Unit 08 6. Computer Arithmetic 06 7. Input-Output Organization 08 8. Memory Organization 08 9. Assembly Language Programming 08 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. Digital Components                                        10 Hrs.  Overview of computer organization: Logic gates  Adders  Flip-flops (as 1 bit memory  device)  Encoders  Decoders  Multiplexers  Registers  Shift Registers  Counters  RAM   ROM   2. Data Representation                                      04 Hrs. Number system  Hexadecimal numbers  ASCII code  Twos complement  addition  subtraction  overflow  Floating point representation   3. Register Transfer & Micro Operations               04 Hrs. Bus and memory transfers  Three state Bus Buffers  Binary ADDER  Binary Incrementer   Arithmetic circuit  Logic and Shift Micro-operations  ALU   4. Basic Computer Organization                04 Hrs. Instruction codes  Direct and indirect address  Timing and Control Signal generation  Instruction Cycle  Memory Reference Instructions  Input Output instructions. . B Level Syllabus R4    69  5. Central Processing Unit                                      08 Hrs. General Register Organization  Memory Stack  One address and two address Instructions  Data transfer  arithmetic  logical and shift instructions  Software and hardware interrupts (only brief introduction)  Arithmetic and Instruction Pipelines.   6. Computer Arithmetic                                             06 Hrs.  Addition and Subtraction with signed magnitude data  Multiplication Algorithms Hardware Algorithm and Booth Algorithm  Division Algorithm  7. Input-Output Organization                            08 Hrs. Asynchronous Data transfer - Handshaking  Asynchronous Serial Transfer  Interrupt Initiated I/O  DMA transfer  Interfacing Peripherals with CPU (Introduction)  Keyboard  Mouse  Printer  Scanner  Network card  Introduction to Pipelining and Linear Pipeline processor  8. Memory Organization                           08 Hrs. ROM  RAM  Hard Disk  CD-ROM  Cache Memory - Direct mapping scheme  Virtual Memory concept  Cache memory working principles  9. Assembly Language Programming                08 hrs. Assembly Language of Intel 8086  Simple examples based on arithmetic and character operations.  Note: For assembly language programming Turbo Assembler may be used.  RECOMMENDED BOOKS  MAIN READING  1. Carter Nicholas  Computer Architecture  Schaun outline Sevies   Tata McGraw-Hill  2008. 2. M. Morris  Mano  Computer System Architecture   Pearson Education  2008. 3. Peter Abel and N. Nizamuddin  IBM PC Assembly Language and Programming  Pearson Education  2009.  SUPPLEMENTARY READING  1. J.P. Hayes  Computer Architecture & Organization  Tata  McGraw Hill 2. Michael J. Flynn  Computer Architecture: Pipelined and Parallel Processor Design  Narosa Publishing House  2002.  B Level Syllabus R4    70  B1.4-R4 : COMPUTER SYSTEM ARCHITECTURE  Model Question Paper Note: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS                                                                       TOTAL MARKS:  100                                                                        (PART ONE  40; PART TWO  60)  PART ONE (Answer ALL Questions; each question carries ONE mark) 1. Each question below gives a multiple choices of answers. Choose the most appropriate one. 1.1 The Toggle flip-flop can be constructed using JK flip-flop by connecting a) Toggle input to J and inverted form of Toggle input to K b) The Toggle input to J c) Inverted form of Toggle input to K d) None of these  1.2 One bit Full adder can be designed using a) Two half adder and one OR gate b) Two Half adder c) One EX-OR and two NAND gates d) None of these  1.3 In most of the digital computers  arithmetic operation of multiply is implemented with a) Sequence of add micro-operations only b) Sequence of shift micro-operations only c) Sequence of add and shift micro-operations  d) None of these  1.4 The most common type flip-flop to synchronize the  state  change during clock pulse transition is a) JK flip-flop b) Edge triggered flip-flop c) SR flip-flop d) None of these  1.5  Two references to memory to fetch an operand are needed in a) Indirect address instructions B Level Syllabus R4    71  b) Direct address instructions c) Immediate instructions d) None of these  1.6 Implied Accumulator (AC) register for all data manipulation is used in a) Two-address instruction b) Zero-address instruction c) One-address instruction d) None of these  1.7 Program Counter register holds a) The instruction to be executed next b) The address of next instruction to be executed c) The count of the programs running in the system d) None of these  1.8 DMA controller transfers one data word at a time in a) Cycle stealing b) Burst transfer c) Synchronous transfer d) None of these  1.9 Cache memory is used to keep a) Very frequently used data in organization b) Keep image of main memory c) Compensate for the speed differential between main memory access time and processor logic d) None of these  1.10 Segment register CS contains 1F00h and IP contains 0300h  the absolute address of the instruction 1F00:0300 is a) 1F300h b) 2200h c) 1F30h d) None of these  2. Each statement below either TRUE or FALSE. Identify and mark them accordingly in the answer book 2.1 A 4 to 1 multiplexer can be designed with the help of four AND gates and one OR gate. 2.2 Hardware procedure for programming ROM or PROM is irreversible. 2.3 Addition of two opposite signed numbers may cause overflow. 2.4 Three-state gates do not  perform all conventional logic such as AND or NAND. 2.5 An n-bit binary adder requires (n-1) full adder. 2.6 Address in instruction may contain the address of the address of the operand. 2.7 The conversion from infix notation to reverse Polish notation must take into consideration the operational hierarchy adopted for infix notation. 2.8 In asynchronous data transfer between two independent units require that control signals be transmitted between communicating units to indicate the time at which data is being transmitted. 2.9 ROM is also random access memory. 2.10 An assembly program may have maximum size of 256KB.  B Level Syllabus R4    72  3.   Match words and phrases in column X with the nearest in meaning in column Y. 3.1 Using flip-flop with complementing capabilities a. Counter circuit 3.2 Single processor register b. Accumulator 3.3 Carry into sign bit and carry out of  sign bit c. Overflow 3.4 Data in operand d. Immediate addressing 3.5 Control signal accompanying each data item e. Handshaking 3.6 Mechanism for translating program generated addresses into correct main memory locations f. Virtual memory 3.7 Addition of three bits (two significant bits and a previous carry)  g. Full adder 3.8 Rules for interpreting or modifying the address field of instruction before operand is actually referenced h. Addressing modes 3.9 Rate at which serial information is transmitted i. Baud rate 3.10 Holding high 16 bits of the product in multiplication operation of assembly language j. DX   k. BX   l. Half adder   m. Strobe   n. Direct addressing   o. Undefined  4.   Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in list below (a) ROM (b) Multiplex (c) Normalized (d) Indirect (e) Micro-programmed (f) One (g) Hardwired (h) Multiply (i) Pipelining (j) CX (k) RAM (l) Counter (m) Immediate (n) Macro-programmed (o) Add (p) DX      4.1 ---------- does not need a read-control line. 4.2 ---------- is a combinatorial circuit  which receives binary information for one of 2n input data lines and directs it to a single output line. 4.3 A floating point number is said to be ---------- if the most significant digit of the mantissa is non-zero. 4.4 One bit of instruction code can be used to distinguish between direct addressing and ---------- addressing. 4.5 A control unit which utilizes a ROM to store binary control information is called a ---------- control unit. 4.6 The computer needs only ---------- common hardware circuit to handle addition of signed and unsigned number. 4.7 In ---------- organization the control logic is implemented with gates  flip-flop  decoders and other digital circuits. 4.8 Booth algorithm gives a procedure to ---------- binary integers in signed  2s complement representation. B Level Syllabus R4    73  4.9 ---------- is a technique of decomposing a sequential process into sub-operations  with each sub-process being executed in a special dedicated segment which operates concurrently with all other segments. 4.10 ---------- register acts as counter for repeating and looping the assembly instructions. PART TWO (Answer ALL questions) 5. a. Simplify the following Boolean functions by means sum-of-product form of a three variable map. Draw the logic diagram with i. AND  OR gates ii. NAND gates  F(A  B C ) =   (0  2  4  5  6 ) b. Explain how JK Flip-flop can be realized from RS flip-flap? c. How many 128 x 8 memory chips are needed to provide a memory capacity of 4096 x 16 ?  ( 9 + 3 + 3 ) 6. a. Draw and explain a 4 bit adder-subtractor circuit. b. Explain direct and indirect address instructions and immediate instructions with suitable examples. c. Explain the basic computer instruction format. When do you call the set of instructions to be complete? Why are set of instructions for basic computer  which is complete  is not efficient?  ( 4 + 6 + 5 ) 7. a.  What are differences between zero-address  one-address and two-address instructions? Explain these through examples. b. What is Booth algorithm? Explain it through flow chart along with an example. c. What is asynchronous data transfer? What are strobe pulse method and handshaking method of asynchronous data transfer? Explain them.  ( 6 + 5 + 5 ) 8. a. What is virtual memory? How is it implemented? b. An address space is specified by 24 bits and corresponding memory space by 16 bits. i. How many words are there in the address space? ii. How many words are there in the memory space? iii. If page consists of 2k words  how many pages and blocks are there in the system? c. For what purpose the segment registers are used and how many are there In Intel 8086? How are effective address is calculated in Intel 8086 assembly language? d. Write an assembly language program to find the least and greatest number among the given twenty numbers (consecutively stored as words) at location NUM and put the results at LEAST and GREATEST locations (defined as words).  ( 3 + 4 + 3 + 5 )   B Level Syllabus R4    74  B1.4-R4: COMPUTER SYSTEM ARCHITECTURE  Assignment 1.   Design an AND gate and an EX-OR gate using NAND gates.  Assignment 2.   Solve the following K-Map for the given equation:    F (a b c d)= (0 1 4 5 7 9 10 11 14 15) And draw the equivalent digital circuit diagram for the same.  Assignment 3.   Solve the following K-Map for the given equation:    F (p q r s)=  (0 1 3 5 7 9 11 13 15) And draw the equivalent digital circuit diagram for the same.  Assignment 4.    Prove the following Boolean algebra identities: a) (A+B).(A+C)=A+B.C b) A+A.B=A c) (A+B'+A.B)(A+B')(A'.B)=0 d) A+A'.B=A+B Assignment 5.   Given the Boolean function      F= p.q.r + p'.q' + q'.r + p.r  a) Simplify the Boolean expression using K-Maps. b) Draw the logic diagram using the given Boolean expression. c) List the truth table of the function. Assignment 6.   Given the Boolean function     F= a'.b' + a'.d.c' + b.c.d'   a) List the truth table of the function. b) Draw the logic diagram using the given Boolean expression. c) Simplify the Boolean expression using Boolean Algebra Identities. d) Draw the logic diagram using the simplified Boolean expression and compare with part 3. e) Check whether the truth table of part 2 and of part 3 is identical.  Assignment 7.   B Level Syllabus R4    75  Represent the decimal number 1849 in  a) BCD   b) Excess-3 code   c) 5421 code   d) as a binary number   e) equivalent Grey code of binary number. Assignment 8.   A majority function is generated in a combinational circuit the output is equal to 1 if the input variables have 2 or more consecutive 1s appearing together  the output is 0 otherwise. Design the equivalent combinational circuit.  Assignment 9.   Design a combinational circuit with three inputs P  Q  R and three outputs a  b  c.  When the input is 0 or 1 in decimal the binary output is one greater than the input. When the input is 6 or 7 in decimal  the binary output is one less than the input. Otherwise the binary output is zero.  Assignment 10.   A circuit has four inputs and two outputs. One of the outputs is high when the majority inputs are high. The second is high only when all inputs are of same type. Design the combinational circuit.  Assignment 11.    Draw the state diagram and tabulate the state table for a sequential circuit with two flip-flops and one external input x. When x=1  the state of the flip-flops does not change. When x=0 the state sequence is 00 11 10 01  00 and repeat.  Assignment 12.   For the given state diagram given in the figure                      0/0                    00                    1/0   1/1                     1/0  01            10             0/1                     0/0                 0/0                                      11                    1/0          Draw the clocked sequential circuit using 2 T-Flip flops.  Assignment 13.   B Level Syllabus R4    76  Construct a 6-to-64-line decoder with two 5-to-32-line decoders with enable and one 1-to-2-line decoder.  Assignment 14.   How many address line and data lines would be required for the memories of the following capacities: a) 16K8 b) 256K16 c) 128M16 d) 32G32 e) 128G8 Where K refers to Kilobyte  M refers to MegaByte and G refers to GigaByte.  Assignment 15.   How many 25616 memory chips are needed to provide a memory capacity of 819216?  Assignment 16.   A computer needs 2048 bytes of RAM and 2048 bytes of ROM. The RAM and ROM chips to be used are specified in the problem. The RAM chip size is 2568 and the ROM chip size is 20488. List the memory address map and indicate what size decoders are needed.  Assignment 17.   Perform the arithmetic operations arithmetic operations below with binary numbers using signed 2s complement representation wherever required. Use eight bits to accommodate each number together with its sign. a) (+12) + (+56) b) (-35) + (- 49) c) (-85)  (+71) d) (-109) + (-11) Assignment 18.   Let Q be a register of eight bits having an initial value of Q=11011101  determine the sequence of binary values in Q after a arithmetic logical shift-left  followed by a circular shift-right  followed by a arithmetic logical shift-right and circular shift-left.  Assignment 19.   Divide (448) 10 with (17) 10 using the division algorithm. Assignment 20.    Multiply (-5) 10 with (-19) 10 using the Booths multiplication algorithm. Assignment 21.   Write a program in assembly language that will reverse an array of N   words.  Assignment 22.   B Level Syllabus R4    77  Write a program in Assembly language that will accept hexadecimal input of numbers and display the equivalent hexadecimal number entered in the output.  Assignment 23.   Prompt the user to enter a line of text. On the next line  display the capital letter entered that comes first alphabetically and the one that comes last. If no capital letters are enterd display message  No Capital Letters. The result should look like this on the screen:  Write a program in Assembly language to perform the above-mentioned task.  Assignment 24.  Write a program in Assembly language that will read a character from the keyboard and display the character in the next line.  Assignment 25.  Write a program in assembly language that will count the number of vowels and consonants in the string that has been entered. Type a line of text: THE QUICK BROWN FOX JUMPED  First capital=B Last Capital=X  B Level Syllabus R4    78  B1.5-R4: STRUCTURED SYSTEM ANALYSIS AND DESIGN  Objective of the Course The Objective of the course is to provide the necessary skills  learning and exposure in developing an information system. The student should be able to develop an understanding of the general principles and purpose of systems analysis and design; apply key techniques from a standard methodology. He should have knowledge of information systems and be able to prepare the physical design of an information system. The course focuses on the following aspects of Information System Development:     Study  Analysis and Design of a System   Documenting and evaluating the system   Data Modeling   Developing Information Management System for an Organization   Implementing  Testing and Security Aspects Outline of Course  S. No.   Topic Minimum number of hours 1. Introduction 03 2. System Development Cycle 03 3. System Planning 06 4. Modular and Structured Design 02 5. System Design and Modeling 14 6. Input/Output and Interface Design 07 7. System Implementation and Maintenance 03 8. Computer System  Security 02 9. OO Analysis/Design 12 10. Introduction to Management Information System 08 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. Introduction                            03 Hrs. System Definition and concepts: General Theory systems  Manual and automated systems  Real-life Business Sub-Systems. System Environments and Boundaries  Real-time and distributed systems  Basic principles of successful systems  Approach to system development: Structured System Analysis and Design  Prototype  Joint Application Development  Role and Need of Systems Analyst. Qualifications and responsibilities  System Analysis as a Profession.  2. System Development Cycle                                                                   03 Hrs. Introduction to Systems  Development Life Cycle (SDLC). Various phases of SDLC: Study Analysis  Design  Development  Implementation  Maintenance; Documentation: B Level Syllabus R4    79  Principles of Systems Documentation  Types of documentation and their importance  Enforcing documentation discipline in an organization   3. System Planning                                                 06 Hrs. Data and fact gathering techniques: Interviews  Group Communication -Questionnaires; Assessing Project Feasibility: Technical  Operational  Economic  Cost Benefits Analysis  Schedule  Legal and contractual  Political. Modern Methods for determining system requirements: Joint Application  Development Program  Prototyping  Business Process Re-engineering. System Selection Plan and Proposal   4. Modular and Structured Design                                     02 Hrs. Module specifications  Top-down and bottom-up design. Module  coupling and cohesion. Structure Charts.   5. System Design and Modeling                                               14 Hrs. Process Modeling  Logical and physical design  Conceptual Data Modeling: Entity /Relationship Analysis  Entity-Relationship Modeling  ERDs and DFDs  Concepts of Normalization. Process Description: Structured English  Decision Tree  Table;  Documentation: Data Dictionary  Recording Data Descriptions.   6. Input/Output and Interface Design                                              07 Hrs. Classification of forms  Input/output forms design. User-interface design  Graphical interfaces. Standards and guidelines for GUI design  Designing Physical Files and Databases: Designing Fields  Designing Physical Records  Designing Physical Files  Designing Databases  Introduction to CASE Tools; Features  Advantages and Limitations of CASE Tools   Awareness about some commercial CASE Tools.   7. System Implementation and Maintenance              03 Hrs. Planning considerations  Conversion methods  procedures and controls  System acceptance criteria  System Evaluation and Performance  Testing and Validation. Preparing  User Manual  Maintenance Activities and Issues.   8. Computer System  Security                                     02 Hrs. Security aspects of a Computer System; Control Measures; Disaster Recovery and Contingency Planning  Prevention of Computer Virus & Malicious Applications.  9. OO Analysis / Design                                      12 Hrs. OO Development Life Cycle and Modeling. Static and dynamic modeling. Comparison of OO and Module-oriented Approach. Modeling using UML ; The UML diagrams; the process of Object modeling  10. Introduction to Management Information System (MIS)                                 08 Hrs. Meaning and role of MIS  Systems approach to MIS. Types of information systems : Transaction Processing System  Management Information System  Decision Support System  Expert System Case Studies (Illustrative) : MIS for Accounting and Finance Function    MIS for Marketing System.  RECOMMENDED BOOKS  MAIN READING 1.  Hoffer J. A  George J.F  Valacich J.S  and Panigrahi P.K Modern Systems Analysis and Design  Pearson Education  2007. B Level Syllabus R4    80  2. A. Dennis and B. H. Wixom  Systems Analysis and Design  John Wiley & Sons  Inc.  SUPPLEMENTARY READING  1. Whitten J. L  Bentley L. D  Systems Analysis and Design Methods   Tata McGraw-Hill  2008. 2. Kendall & Kendall  Systems Analysis and Design  Seventh Edition  Pearson Education. B Level Syllabus R4    81  B1.5-R4: STRUCTURED SYSTEM ANALYSIS AND DESIGN Model Question Paper NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS              TOTAL MARKS: 100 (PART ONE: 40; PART TWO: 60) PART ONE (Answer all the questions; each question carries ONE mark) 1. Each question below gives a multiple choices of answers. Choose the most appropriate one.         1.1 A starting point in the hardware design phase of a system design project is A. The determination of size and capacity requirements for the hardware B. Preparation of a purchase contract C. Calling quotations from hardware vendors D. Benchmarking 1.2 Software maintenance includes  A. Bug fixing B. Setting preventive maintenance policy for the servers and clients in the             computer network C. Simulation of proposed changes in organizational strategy D. Feasibility study 1.3 The role of an integrated CASE tool in a systems analysis and design project is A. To provide automatic help in case of legal cases when there is a dispute             between developer and user B. To serve as a less expensive substitute for spreadsheet during the             negotiation process C. To provide an environment that automates key tasks throughout the             entire development process D. To serve as a sophisticated text editor 1.4 In the processing of a data dictionary  cross reference checking means A. Linking of documents through hypertext  in case the system deals with             document imaging  B. Ensuring that there is no inconsistency between the way a reference                                        is quoted in a text file  and the reference is listed in a reference file B Level Syllabus R4    82  C. Determination of where data are used in the system  i.e.  which                                                      processes use a given data item  which data items are unused.  D. Verifying whether the latest updates are reflected in different components             of a system 1.5      Cost of error correction is least at A. Requirement Analysis stage B. Design stage C. Development stage D. Implementation stage 1.6      A sequential access file is not a file A. In which the last record is retrieved in the same time as the first record B. In which a record cannot be accessed unless its predecessor records are     accessed C. Usually stored on magnetic tape D. In which to insert a record  a new copy of the file is created 1.7      The difference between menu interface and question-answer dialogue is A. In the former  the user fills in a form  whereas in the latter  the user B. In the former  the user uses a light pen  whereas in the uses a  mouse C. The former is popular in restaurant computers whereas the latter is popular in a  police   department D. In the former  the user has to choose from a given list of options  and in      the latter the user has to answer questions put by the computer  1.8 The primary difference between program testing and system testing is A. Program testing is more comprehensive than system testing B. System testing focuses on testing the interfaces between programs   whereas program testing focuses on individual programs C. System testing is concerned with testing all aspects of a system including job designs and reward system designs D. Programmers have no involvement in system testing  whereas designers are involved in program testing  1.9 Which of the following is not a major design consideration for a system? A. Response time required B. Frequency of record updates C. Availability of technically qualified personnel to carry out design and development D. Data integrity constraints 1.10 The largest percentage of the total life cycle cost of software is A. Design costs B. Maintenance costs C. Coding costs D. Testing costs 2. Each statement below is either TRUE or FALSE. Identify and mark them accordingly in the answer book.                2.1  A data dictionary is a structured repository of data about data. 2.2  HIPO diagrams are used to develop packages. B Level Syllabus R4    83  2.3  Computer system security involves only virus protection. 2.4  Validation errors are detected by check digits. 2.5  VTOC shows a hierarchy of documents. 2.6  ERD reflects the business requirements of a proposed system. 2.7  Aliases are included in Data Dictionaries. 2.8  During the Design phase of the SDLC  input design is governed by the volume and    frequency of data. 2.9  A Database Administrator is the one who designs the database for an application. 2.10 A Gantt chart represents activity or job schedules in the form of bar graphs. 3. Match words and phrases in column X with the closest related    meaning/word(s)/phrase(S) in column Y.     X Y 3.1 Smart Card A. Record occurrences 3.2 Knowledge Base B. Hardware selection 3.3 Alpha Test C. Verification 3.4 Validation D. Certificate 3.5 CASE E. SASD tool 3.6 Action Statement F. Expert System 3.7 Sizing G. Updating prelude 3.8 Tuples H. Communications 3.9 Benchmark I. Programming 3.10 Topology J. Transaction Processing 4.     Each statement below has BLANK space to fit one of the word(s) or phrase(s) in    the list below. Enter your choice in the answer sheet  following instructions there in.              (a) Balancing (b) Outsourcing (c) Unit (d) Incremental Commitment (e) Recurring (f) Relationship (g) One-time (h) Level-1 Diagram (i) Database (j) Transposition Document (k) Context Diagram (l) System (m) Turn around Document (n) icon (o) Graph (p) Equality      4.1 A shared collection of logically related data designed to meet the information needs of  multiple users in an organization is a ___________. 4.2 ___________ is a strategy in Systems Analysis and Design in which the project is  reviewed after each phase and continuation of the project is rejustified in each of these  reviews. 4.3 A __________ cost results from the ongoing evolution and use of a system. 4.4 ____________ provides an overview of an organizational system. 4.5 The conservation of inputs and outputs to a DFD process when that process is  decomposed to a lower level is called ___________. 4.6 ___________ is an association between the instances of one or more entity types that  is of interest to the organization. 4.7 The practice of turning over responsibility of some to all of an organizations information  systems applications and operations to an outside firm is called ____________.  4.8  ____________ provides information that is delivered to an external customer as an B Level Syllabus R4    84  output that can be returned to provide new information as an input to an information system.  4.9 __________ is a graphical picture that represents specific functions within a system. 4.10 In ________ testing each module is tested alone in an attempt to discover any errors           in its code. PART TWO (Answer any FOUR questions) 5.    a. What are the differences between system analysis and system design? Justify your answer with examples. What is the role of system analyst in system analysis and design?  b. What is Software Development Life Cycle (SDLC)? Describe various phases of SDLC. Briefly Explain various types of documentation involved in each phase of SDLC. (7+8) 6.  a. What is UML? Why it is called unified modeling? List and explain various diagrams involved in modeling using UML  which shows behavioral aspects of the system.  b. Describe pros and cones of interview and questionnaires technique for requirement gathering.  c. What is a structure chart? How is it related with cohesion and coupling?   (7+4+4) 7.  a. Develop a decision tree that describes the decisions  a school attendance officer must make in fulfillment her responsibilities.  The officer spends a part of each day looking for truant students. If the officer comes upon a student who is truant  she transports the youth to the schools attendance office. The student is held at office while the attendance officer attempts to contact the parents or guardians. If the officer is able to reach the parents or guardians  the student is released into custody and a date is set for a formal review of the students attendance record. If the officer is unable to reach the parents or guardians  the student is detained in the attendance office until the end of the school day and then released.  The system is dependent upon having up-to-date attendance records  as well as the current telephone numbers (home and work) for parents or guardians. Whenever possible  the attendance officer will attempt to visit a truant students parent or guardians and inform them of the problem.  However  if the officer has a large number of truancies to investigate  she sends a formal letter to the parents or guardians whom she has been unable to reach by phone or in person. The letter informs them of their childs truancy and requests that they call or come to see the truant officer.  b. A recruitment procedure in an organization is as follows: An advertisement is issued giving essential qualifications for the specific post  the last date for receipt of application and the fee to be enclosed with the application. A clerk in the registrars office checks the received applications to the concerned department. The department checks the application in detail and decides the applicants to be admitted  those to be put in the waiting list and those to be rejected. Appropriate letters are sent to the registrars office  which intimates the applicant. Give physical and logical DFDs corresponding to the above problem. (8+7) B Level Syllabus R4    85  8.    a. What is a CASE tool?  Explain about any commercial CASE tool with its features and limitations.   b. What is the Conversion of system? Why is it required? How conversion takes place in an organization for system implementation?  c. Explain different types of threats that a computer system can have and explain various control measures for those threats. (5+5+5) 9.  a. What is the significance of Usecase diagram in UML? At which phase of System Development it is drawn? Explain steps for preparing Usecase diagram with example.  b. Describe Object Oriented Development Life Cycle.  c. What is Object Oriented Modeling? Differentiate between Static and Dynamic Modeling.  (7+4+4)  B Level Syllabus R4    86  B1.5-R4: STRUCTURED SYSTEMS ANALYSIS AND DESIGN  Assignment-1   The City College has a large library consisting of books of different categories. Few are listed below: A. Fiction B. Biography C. Economics D. Mathematics E. Sports F. Management     G. Computers and Communication  H. Taxation I. Law               J.  Travel  Students and teachers borrow the library books. The students can take at time two books on subjects related to studies and one book from general interest.  The teachers can take at time three books on subjects related to studies and two books from general interest. The college decides to provide an online facility to inquire on the availability of books in the library. Entering any of the following can search the books available in the library:  1. By Author index (Entering first two alphabets ) 2. By title index (Entering first two alphabets of the title of the book) 3. By Subject index (Entering the name of the subject)  The database of the above application will be on the DBMS. You are required to specify: (a) The various files required to be specified and the layout and contents of the files. (b)  Design screen layouts for the above query. What are the checks and controls that you   would like to incorporate in the system to ensure that erroneous input gets tapped as soon as it is typed.  Assignment 2.  Activities of a school Office during admission time are as follows Applications are received from students and they are checked for eligibility for admission.  Eligible candidates are called for an admission test. The teachers set the question  papers for the test. The candidates take up the test. The teachers evaluate the test  papers.   Based on the marks obtained by the candidate in the test and other criteria specified by the school  the teachers prepare a provisional admission list. The candidates in the admission list are called for an interview. Normally  this list contains about 10% more than the number of seats available in the school.   An interview panel is constituted to interview the candidates. Taking into account the performance of the candidates in the interview  the panel prepares a selection list. This selection list is sent to the principal for approval.  The candidates who figure in the approved selection list are intimated about their admission. Such candidates pay their admission and other school fees and get admitted. Proper receipts are issued for the payment of the fees. Such admitted candidates are assigned roll numbers and sections. Section wise attendance registers are prepared. The application forms of these admitted students are kept in a separate file. Prepare the DFD representing these activities. Also give the data dictionary entries.   Assignment 3.  A company stores all the purchase orders placed by it on its vendors in  a purchase order B Level Syllabus R4    87  file (POFILE). When it receives delivery of goods against a purchase order the details are entered in a file called RECDPOFILE (assume that partial deliveries  do not exist  and that a purchase order corresponds to only one product). When an invoice is received from a vendor it is stored in the INVCEFILE. At the end of each day  a program retrieves each invoice in the INVCEFILE  checks it for the following:   (a)    Whether the purchase order number mentioned in the invoice exists  in the POFILE   (b) Whether the purchase order mentioned in the invoice has a   corresponding entry in the RECDPOFILE.  In case a mistake is indicated in either of the above checks  a corresponding message is printed for the vendor  for later mailing; if the invoice is valid according to both the tests  then payment of invoice is authorized  and the invoice is entered in PAYFILE and a cheque is printed.  3.1 Draw a DFD for the above system 3.2 Explain the file design in detail for the above system  Assignment 4.   The office of Department of Computer Science organizes and handles seminars / workshops.   When a person wants to register for a seminar  he / she sends a request.  The office clerk notes the persons name  address  telephone number and organization name on a registration form. Copy of the form is placed in the master file  an acknowledgement letter prepared and sent to the registrant.  Another copy is sent to the billing clerk who creates an invoice record for the registrant in another central file and sends a copy of the invoice to the registrant.  One month before the seminar  the clerk prepares name tags and seminar material for each participant.  The registrants are expected to pay in advance of the seminar.  When a cheque comes in  the clerk verifies the registration against the registration record and enters the information that the payment has been received.  In case registrants do not sent the advance payments  their names are listed on a separate sheet. This defaulter sheet is given to the seminar coordinator who takes the appropriate action  which may be:  1. a person is allowed to attend the seminar  if he agrees to make the payment on the first day before the seminar starts   or 2. brings in a sanction letter from the head of the organization. All registration records are maintained in a master file and used as a mailing list on an ongoing basis.  DESIGN A DFD FOR THE ABOVE REGISTRATION PROCEDURE FOR THE SEMINAR.  Assignment 5.   Below are some statements about order processing in an organization? You are required to construct an ER diagram from these statements.  Assignment 6.  In many organizations  raw material inventory consumes a major portion  of the assets of the business. Management of inventory is therefore an important  computer application. An integrated inventory system includes an inventory subsystem   B Level Syllabus R4    88  a purchase subsystem  receiving subsystem. An inventory master file is usually  maintained which is updated by all the subsystems. This file is also used to create a  number of outputs for each of the subsystems.   (a) Identify some major data elements for the inventory master file. (b) Identify which data elements are being updated by which subsystems. (c) Identify some of the important o/p generated by each of the subsystems.   Assignment 7.    Design a system for the Warehouse Inventory System and illustrate the solution with a Structure Chart that will take in customer orders  select the item from inventory  and generate a packing slip and invoice.  INPUTS:  a) Customer Order from the Sales Department.  b) Shipments of Finished Goods to be put in Inventory.  OUTPUTS:  a) Plant Order for more Finished Goods.  b) Shipments of Finished Goods to the Customer. c) Invoice and Packing Slip for items shipped to Customer.  d) Notice to Sales that items are Back Ordered.        The warehouse maintains the MASTER FILE that contains the quantities of all items in inventory. The warehouse ships all items ordered and send out invoices. If the order quantity is greater than quantity in inventory  nothing is shipped. The whole quantity is ""back ordered."" A Back Order notice is sent to the Sales Department and the customer by way of the Sales Department. Also a Plant Order for that item at the requested quantity is sent to the plant. No other tracking of back orders is done. If the order quantity is less than or equal to the quantity in inventory  then the items are shipped and the quantity in inventory is reduced for the items shipped. A check is then made to see if the amount left in inventory is below the minimum on-hand quantity controlled by the Sales Department. If so  the automatic reorder quantity that is dictated by the Sales Department is used to generate a Plant Order for that item so that the inventory can be replenished. The Customer Order contains all necessary information: Items  Quantities  Customer -Information (Name  Billing-Address  and Shipping-Address).   Assignment 8.  Design a structured chart using following information:  Calling module :  Calculate student grade Called module:  Get students academic information Get valid grade Find out errors Check for probation Period Check for directors list Include the required input and output couples  showing the direction and meaning. In the same chart show check for probation as a calling module and factor a called module EVALUATE APPRAISAL. Show input and output couples. B Level Syllabus R4    89  Assignment 9.   Design a structured chart using following information:  Calling Module:   Calculate Word Counting  Called Module:   Get Sorted Word List   Count Number of Different Words Output Count Include the required input and output couples  showing the direction and meaning. Also factorise the Get Sorted Word List as calling module and get word list and sort as called modules which further can be factorised. Show also the input & output couples.  Assignment 10.   In a ABC Limited company  if the invoice paid is B Level Syllabus R4    90  a) Candidate is to be declared PASS if he gets 40 or more than 40 marks in all three subjects. b) Candidate is to be declared FAIL if he gets less than 40 marks in TWO OR MORE SUBJECTS. c) Result is to be declared REAPPEAR  if the candidate secures less than 40 marks in one subject and 40 or more than 40 marks in other two subjects.  Assignment 15.   Given a file whose record consists of following attributes: Roll No.       Name        Sex code   M for males     F for females Marks in English      Marks in Biology      Marks in Maths      The scheme for selection and allotment of departments is as follows: a) Reject the candidate  if aggregate marks are less than 180. b) Allot ENGINEERING  department if the candidate has maximum marks in maths and sex code is M. c) Allot MEDICAL department if candidate has maximum marks in biology and sex code is F. d) Allot ENGLISH department if candidate has maximum marks in English. e) Allot PSYCHOLOGY department to all other selected candidates. Use limited entry decision tree to do the final selection. Assignment 16.  In Accounts Receivable systems printing of the monthly account statement is the main feature. Because of the frequency of accounts receivable invoices  customers generally expect certain information to be included on the statement. Name  address and account number details are essential as are the previous and current account balances.  A common form lists the date  type  and amount of each transaction in the main part of the invoice. Depending on the particular account  there may be none  one  or many transactions. (Statements are always sent to customers who have a balance outstanding  even if there are no transactions for the current month).   Some systems also charge interest on the previous months unpaid balance. Interest charged for the current month is listed separately in a special place on the statement form.   At the end of the calendar year  a separate line is often added to inform the customer of the amount of interest paid during the year because Customers want  to see this information as a means of knowing how much they paid in interest  and this is also required for reporting their taxes to the Internal Revenue department. To capture a customers attention  merchants often include a special message on the bottom of the statement form. The message may be up to   120 characters  and  can be used to promote special sales  provide consumer service telephone numbers  etc. Its use is  however  optional.   a. Develop the data structure(s) needed to accommodate accounts receivable statement preparation as described above. b.     Indicate which data items are mandatory and which are optional. B Level Syllabus R4    91  Assignment 17.   The sales staff of a Jewellery shop is divided into commissioned salesman and salaried salesman. A commissioned sales man receives 10% commission on every sale greater than or equal to Rs.10  000.00; receives 5% commission on every sale greater than or equal to Rs.1  000.00 and less than Rs. 10  000.00 and receives 2% commission on every sale less than Rs.1  000.00. A salaried salesperson receives a Rs.700.00 bonus for cumulative sales greater than or equal to Rs.10  000.00; receives a Rs.50.00 bonus for cumulative sales greater than or equal to Rs.1  000.00 and less than Rs.1  000.00  and receives no bonus for sales less than Rs. 1  000.00   From the above description  develop a class diagram for the system.  Assignment 18.   Prepare a limited entry decision table for the following case: A wholesaler has three commodities to sell and has three types of customers. Discount is given as per the following procedure: a) For VIPS orders  10% discount is given irrespective of the value of the order. b) For orders more than Rs. 50 000/- agent gets a discount of 15% and the retailer gets a discount of 10%. c) For orders of Rs. 20 000/- or more up to Rs. 50 000/- agent gets a discount of 12% and the retailer gets a discount of 8%. d) For orders of the value less than Rs. 20 000 agent gets 8% and retailer gets 5% discount. The above rules do not apply to the furniture items where in a flat rate of 10% discount is admissible to all customers irrespective of the value of the order. Assignment 19.  Identify the possible actions to be taken for the decision or policy for constructing decision table: a) Pay no interest b) Pay 5.75% quarterly interest on entire amount c) Pay 6% quarterly interest on entire amount d) Pay 6% monthly interest on amount up to Rs.25000 e) Pay 6.55% monthly interest on amount between Rs.25000 and Rs.50000 f) Pay 7.0% monthly interest on amount over Rs.50000 B Level Syllabus R4    92  Assignment 20.  Simplify the following decision table:    Rules 1 2 3 4 5 6 7 8 9 10 11 12  C1 N Y N Y N Y N Y N Y N Y C2 N N Y Y N Y Y N N Y Y C3 A A A A B B B B C C C C A1 X    X    X A2  X    X    X A3  X    X A4    X    X  X  X Were you able to combine rules 3 and 7 in above problem? Why?  Assignment 21.  Prepare a decision tree that defines the following course grading scheme: A student may receive a final course grade of S A  B  C or F. In deriving the students final course grade  the instructor first determines an initial grade for the first test of student. The initial course grade is determined in the following manner. a) A student who has scored a total of not less than 90 percent on the first test   quiz  class performance and received a score not less than 75 percent in the final test will receive an initial grade of S for the course.  b) A student who has scored a total less than 90 percent but greater than 80 percent on first test quiz  class performance and received a score not less than 70 percent in final test will receive an initial grade of A for the course. c) A student who has scored a total less than 80 percent but greater than 70 percent in the first test  quiz  class performance and received a score not  less than 65 percent in the final test  will receive an initial grade of B for the course.  d) A student who has scored a total less than 70 percent but greater than 60 percent on the first test  quiz  class performance and received a score not less  than 55 percent in the final test  will receive an initial grade of C for the course.  e) A student who has scored a total less than 60 percent in the first test  quiz and class performance will receive an initial and final grade of F for the course.  Once the instructor has determined the initial course grade for the student  the final course grade will be evaluated. The students final course grade will be the same as his or her initial course grade if no more than four class periods during the semester were missed; otherwise  the students final course grade will be one letter grade lower than his or her initial course grade (for example  an A will become a B).   Are there any conditions for which there was no course of action specified for the instructor to take? If so  what would you do to rectify the problem? Can your decision tree be simplified? If so  simplify it Assignment 22.  B Level Syllabus R4    93  Given the following use case  develop a class diagram by first developing a scenario diagram and then reducing it to a class diagram.  a) A customer arrives at an investment consultant and makes an initial enquiry about their investment requirements.  b) The consultant records and files the requirements.  c) The consultant checks the product files.  d) The consultant proposes a number of financial products to the customer for selection.  e) The customer then either selects one of the products.  f) The consultant records the decision in the requirements file.  Alternatives  The customer or proposes a variation to one of the alternatives.  The consultant to amend one of the alternatives uses the variation  Assignment 23.  For the following problem of car hire system:  Draw a use case model showing any relationships between the use cases.   USE CASE 1 - DOING RESERVATIONS  a) A customer contacts a reservation officer about a car rental. b) The customer quotes the start and end dates needed  the preferred vehicle  and the pickup office.  c) The reservation officer looks up a prices file and quotes a price.  d) The customer agrees to the price.  e) The vehicle availability file is checked to see if an appropriate vehicle is available for the required time at the required office.  f) If the requested vehicle is available at the nominated pickup office  then it is reserved for the customer. An entry is made in the vehicle availability registering the reservation.  g) The reservation officer issues the customer with a rental number.  A rental agreement is then created on the rental file  including the rental number  the rental period  the vehicle type and the pickup office.  Exceptions  An appropriate vehicle is not available at the pickup office. The customer is offered an alternative vehicle.  The customer does not agree to a price and asks for an alternate vehicle and/or period.     USE CASE 2  AVAILABILITY SYSTEM  a) A vehicle availability file is checked to see if a vehicle of a given type is available at the requested pickup office for a requested rental period. There is a record for each vehicle  which includes the times  when a vehicle is available and when it is rented.  b) If it is  then the vehicle is reserved for the requested period.  Exception  If a reservation cannot be made because of lack of vehicles a problem report is issued to be used in planning vehicle levels.  USE CASE 3 - INITIATING RENTAL  B Level Syllabus R4    94  a) A customer arrives at a pickup office and quotes a rental number to the rental officer.  b) The rental file is checked to the customers rental number.  c) If so then the rental agreement is retrieved and discussed with customer.  d) If the customer accepts  then a set of rental agreement is printed.  e) The customer signs the agreement and lodges a credit card number.  f) The rental officer requests the customer to select one of a number of insurance options. Following the selection an insurance policy is filled out and attached to the signed agreement.  Exception  A customer does not have a prior reservation. In that case a vehicle availability check is made. If a vehicle is available  the customer is offered the vehicle and a price is quoted. If the customer accepts then a rental is initiated.  If the kind of reserved vehicle is not available to a customer with a prior reservation (because of a late return) then an alternate proposal is made to the customer.   Assignment 24.  Admission procedure in a University is as follows: An advertisement is issued giving essential qualifications for the course  the last date for receipt of application  and the fee to be enclosed with the application. A clerk in the Registrar's office checks the received applications to see if mark sheet and fee are enclosed and sends valid applications to the concerned academic department. The department checks the application in detail and decides the applicants to be admitted  those to be put in the waiting list  and those rejected. Appropriate letters are sent to the Registrar's office  which intimates the applicant. Give physical and logical DFDs corresponding to the above problem.  Assignment 25.   A magazine is published monthly and is sent by post to its subscribers. Two months before the expiry of subscription  a reminder is sent to the subscribers. If subscription is not received within a month  another reminder is sent. If renewal subscription is not received up to two weeks before the expiry of the subscription  the subscriber's name is removed from the mailing list and the subscriber informed. Obtain logical DFDs for this problem.  Assignment 26.   Obtain a physical DFD for a simple payroll system described below.  A list of employees with their basic pay is sent to a clerk. He calculates the gross pay using standard allowances  which are known for each pay slab. Deduction statements such as loan repayment  subscription to association  EPF  Library security etc. is also sent to another clerk who matches these slips with the slips of gross pay and calculates net pay. This slip is used by a third clerk to write out pay cheques for each employee and sent to respective employees. The total pay bills paid are also computed.  Assignment 27.  Draw the context diagram  level 1 and level 2 diagrams for modelling the processing of an ATM. B Level Syllabus R4    95  B2.1-R4:  DATA STRUCTURE THROUGH C++  Objective of the Course The objective of the course is to introduce the fundamentals of Data Structures  Abstract concepts and how these concepts are useful in problem solving.  After completion of this course student will be able to -   To Understand and the concepts of object oriented language such as c++  Analyze step by step and develop algorithms to solve real world problems.  Implementing various data structures viz. Stacks  Queues  Linked Lists  Trees and Graphs.  Understanding various searching & sorting techniques. Outline of Course  S. No.   Topic Minimum number of hours 1. Analysis of Algorithm 10 2. Basics of C++  Elementary Data  Structures : Arrays  linked lists 18 3. Abstract Data types Stacks and Queues   05 4. Trees 12 5. Searching  sorting and Complexity 10 6. Graphs 05 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. Analysis of Algorithm                           10 Hrs. Introduction to Algorithm Design and Data Structures: Design and analysis of algorithm: Algorithm definition  comparison of algorithms. Top down and bottom up approaches to Algorithm design. Analysis of Algorithm; Frequency count  Complexity measures in terms of time and space. Structured approach to programming.   2. Basics of C++  Elementary Data  Structures : Arrays  linked lists                     18 Hrs. Basics of C++:    Structure of a program Variables. Data Types. Constants Operators  Basic Input/Output  Control Structure   Functions  Compound Data Types: Arrays  Pointers  Dynamic Memory   Object Oriented Programming :Classes  Encapsulation  Abstraction  inheritance  Polymorphism  Representation of arrays: single and multidimensional arrays. Address calculation using column and row major ordering. Various operations on Arrays  Vectors. Application of arrays: Matrix multiplication  Sparse polynomial representation and addition  Stacks and Queues : Representation of stacks and queues using arrays and linked-list. Circular queues  Priority Queue and D-Queue. Applications of stacks: Conversion from infix to postfix and prefix expressions  Evaluation of postfix expression using stacks.  Pointers: Definition  Pointer Arithmetic  Array of pointers   Arrays in terms of pointers.  Linked list: Singly linked list; operations on list   Linked stacks and queues. Polynomial representation and manipulation using linked B Level Syllabus R4    96  lists. Circular linked lists  Doubly linked lists. Generalized list structure. Sparse Matrix representation using generalized list structure  stacks  queues.   3. Abstract Data types Stacks and Queues                               05 Hrs. Definition of ADT  Stack ADT (array implementation)  FIFO   queue ADT (array implementation)         4. Trees                                                                  12 Hrs. Binary tree traversal methods : Preorder  In-order  Post-ordered   traversal. Recursive Algorithms for above mentioned Traversal methods. Representation of trees and its applications : Binary tree representation  of a general  tree. Conversion of forest into tree. Threaded binary trees.  Binary search tree. :  Height balanced (AVL) tree  B-trees.   5. Searching  Sorting and Complexity             10 Hrs. Selection sort  Insertion sort  Bubble sort  Quick sort  merge sort   Heap sort  Radix sort and their complexity  Searching: Sequential search  Binary Search  Binary Search Tree  ASVL trees  B trees  Searching   sorting and complexity  Searching : Sequential and binary searches  Indexed search  Hashing Schemes. Sorting : Insertion  selection  bubble  Quick  merge  radix  Shell  Heap sort  comparison of time complexity.  6. Graphs                                                                  05 Hrs. Graph representation : Adjacency matrix  Adjacency lists   Traversal schemes : Depth first search  Breadth first search.  Spanning tree : Definition  Minimal spanning tree algorithms. Shortest Path algorithms (Primes  and    Kruskal s).   RECOMMENDED BOOKS   MAIN READING   1. Hubbard John. R  Schaums outline of Data Structures with C++  Tata McGraw-Hill  2007. 2. Langsam Y .Augenstein M.J and Tanenbaum A. M  Data Structures Using  C and C++         Second Edition  Pearson Education  2007. 3.  Kruse R  Tonodo C.L. and Leung B  Data Structures and Program Design in C  Pearson Education  2007.  SUPPLEMENTARY READING  1. Horowitz E  Sahni S and Mehta D  Fundamentals of Data Structures in C++  Galgotia Publiction  2009. 2. Weiss M A  Data Structures and Algorithm Analysis in C++  Pearson Education  2007. 3.  Litvin G  Programmking with C++ and Data Structures  Vikas Publishing House.  B Level Syllabus R4    97  B2.1-R4: DATA STRUCTURE THROUGH C++  NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS                     TOTAL MARKS: 100 (PART ONE  40; PART TWO  60) PART ONE (Answer ALL Questions; each question carries ONE mark) 1. Each question below gives a multiple choice of answers. Choose the most appropriate one and enter in the tear-off answer sheet attached to the question paper  following the instructions therein.    1.1 The equivalent prefix expression corresponding to (A + B)  (C + D * E) / F * G is  a) - + A B * / + C DE * F G   b) / - + AB * + C  * D E F G  c) - / + A B * + C D E * F G  d) - + A B * / + C * D E F G  1.2 The address of a[2][3][4] is              where a[3][4][5] is stored in row major order with base address 1050. Assume element size is 4 bytes and the index values start from 0.   a 1200  b) 1286  c 1100  d) 1186  1.3 The number of nodes in a strict binary tree with n leaves is   a) 2n - 1  b) 2n  c) 2n +1  d) 2n +2  1.4 The best case of insertion sort is   a when the data is randomly ordered.  b) when the data is sorted in reverse order of what is required  c) when the data is sorted in the same order as what is required  d) none of the above  1.5 Building new classes from existing classes is  a) encapsulation b)  polymorphism B Level Syllabus R4    98  c)  inheritance d)  data hiding  1.6 What is the following function doing? int mystery(int temp  int a[]  int i) {  if (i < 0)   return temp;  else {   if ( temp < a[i])     temp = a[i];   return mystery(temp  a  i - 1);  } }   a) finding the position of the minimum element in the array passed to it as an argument  b) finding the position of the maximum element in the array passed to it as an argument  c) finding the minimum value in the array passed to it as an argument  d) finding the maximum value in the array passed to it as an argument  1.7 A right in-threaded binary tree has  a) right links having NULL replaced by a special link to the predecessor of the node in inorder traversal b) right links having NULL replaced by a special link to the successor of the node in inorder traversal c) left links having NULL replaced by a special link to the predecessor of the node in inorder traversal d) left links having NULL replaced by a special link to the successor of the node in inorder traversal  1.8 In                  a mathematical function is used to determine the location of a record.   a) AVL tree  b) Stack   c) Hashing   d) Adjacency matrix  1.9 Which of the following is not an application of stacks?   a) matrix multiplication   b) implementing function calls  c) conversion of an expression from infix to postfix form  d) determining whether the parentheses in an expression are balanced or not  1.10 Postorder traversal of a tree consists of three steps: 1. Visit the root 2. Traverse left subtree in postorder 3. Traverse right subtree in postorder The correct sequence of steps is  a) 1 2 3  b) 1 3 2  c) 2 3 1  d) 3 2 1                                  2. Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book B Level Syllabus R4    99  2.1 Preorder traversal of a tree is the mirror image of its postorder traversal. 2.2 Strict FIFO order is followed in priority queue.  2.3 In selection sort  once the shortest element found in ith iteration is placed at a particular position  it does not change its position after that. 2.4 Given a function prototype as void fn(char **ptr  int n) and a variable char a[10]  a call to the function can be fn(&a[3]  10). 2.5 Linked list can be implemented using arrays also. 2.6 B-trees have all the leaves at the same level. 2.7 On subtracting two pointers  we get the number of bytes between the two addresses being pointed to by the pointers. 2.8 A graph without cycles is also known as a tree.  2.9 Linear search can be applied on sorted data. 2.10 Queues are used to evaluate prefix expressions.  3.       Match words and phrases in column X with the nearest in meaning in column Y.           X      Y 3.1 Inorder traversal of binary search tree A.  Bubble sort 3.2 Sparse matrix B.  Prims algorithm 3.3 new operator C.  O(n3) 3.4 Shortest path D.  Non-linear data structure 3.5 Compound data type E.  Ordered list 3.6 Matrix multiplication complexity F.  Mostly non zero entries 3.7 Recursion  G.  Dynamic memory allocation 3.8 Linked Lists H.  Hashing  3.9 Consecutive elements comparison I.  Integer 3.10 Open addressing J.  Dijkstras algorithm   K.  O(n2)   L.  Linear data structure   M.  Defining new data type   N.  Polymorphism   O.  Mostly zero entries   P.  Divide and conquer strategy   Q.  Heap sort   R.  Array  4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below: (a) Hash tables (b) int *p[10]; (c) Depth (d) Complete binary tree  (e) O(n2) (f) n + 1 (g) Binary search tree (h) Adjacency lists (i) Data (j) Stacks (k) n  1 (l) Objects (m) Radix (n) AVL tree (o) Index (p) Heap sort (q) Shell sort (r) O(n lgn) (s) Breadth (t) n (u) int (*p)[10]; (v) General tree (w) Bubble sort (x) Quicksort  4.1 Another name for height balanced tree is              .  4.2 Mergesort has               complexity.  4.3 Graphs can be represented using                . B Level Syllabus R4    100  4.4               represents an array of pointers. 4.5 Preorder traversal of a tree is a type of               first search. 4.6  A tree with n vertices has             edges. 4.7                are instances of classes. 4.8  Indexed sequential search requires               file to be in sorted order. 4.9                 uses the concept of increments to sort data. 4.10  A               is a tree with the maximum number of nodes for a given depth.  PART TWO (Answer any FOUR questions) 5. a. Create a class TwoDim which contains x and y coordinates as int. Define the default constructor  parameterized constructor and void print() to print the co-ordinates. Now reuse this class in ThreeDim adding a new dimension as z of type int. Define the constructors for the derived class and override the method void print() in the subclass. Write main() to show runtime polymorphism.  b. Apply binary search algorithm to search for 90  in the following list of numbers:        12  25  33  37  48  50  53  57  86  92         Show the outcome after each iteration.  (9+6) 6.  a. Convert the following tree into a binary tree b. Create a binary search tree for the following sequence:             Tina  Manik  Nupur  Utsav  Neha  Alka  Sehej  Monika  Geetu  Uday          c.  What do you understand by space and time complexity? Calculate the space and  time complexity of linear search method.  (3+5+7)  7. a.  Write a C++ program to create a doubly linked circular list L  with a header node. The data values of nodes are of character type. The nodes are to be inserted in the list in such a way that the nodes are in ascending order of their data values. In addition to this  it should be possible to delete a node with the given data value from the list.  b. Evaluate the following prefix expression:     **A+BC-+CBA      Assume A = 1  B = 2 and C = 3  (12+3)  8. a.  What is an ADT? Briefly explain the various components of an ADT. b.  Apply heapsort on the following unsorted list of keys    8  20  9  4  15  10  7    Show intermediate the steps.  (6+9)  5 1 9 3 2 4 6 7 8 B Level Syllabus R4    101  9. a.  Draw a B-tree for the following data: 23  65  37  60  48  91  15  75  86 and 58. Suppose that the search field values are inserted in the given order in a B-tree of order p = 3; show how the tree will expand and what will the final tree look like? b.   Consider the following graph:  Give the implementation of the graph as an adjacency matrix. Also write the depth-first and breadth-first traversals of the graph.  (9+6)  1 2 3 5 9 4 6 7 8 B Level Syllabus R4    102  B2.1-R4: DATA STRUCTURE THROUGH C++  Assignment 1.   Write a program that reads ten numbers from the user. These ten numbers represent the scores that a student has received in a class. Your program should create a nicely formatted report that displays all ten scores as well as the total score and average score that the student received.  Assignment 2.     Write a C++ program that reads ten numbers from the user. After reading all ten numbers  compute the sum of the odd-positioned numbers  multiply all of the even-positioned numbers together  and add these two numbers together. That is  you should add the first  third  fifth  seventh  and ninth numbers. You will then multiply the second  fourth  sixth  eighth  and tenth numbers. The sum of these two numbers is your final result. Assignment 3.    The  library  circulation  system will keep  track of  every book as well as  library cardholders. Each  time  a book  is  checked out  or  returned   the  system must keep  track of  it.  Books  can be added  to  the librarys collection and also removed. Due dates for books should be tracked  as well as notices sent out for materials that are more than a week overdue. Fines for overdue materials should be calculated  and a record kept of the amount owed by each cardholder.         Design appropriate classes that keep records of book(book no  book name  author name)  cardholders(member no  member name  age  address  city) and issue_return(book no  member no  date of issue   date of return  fine).  Write appropriate functions  a) for  keeping records of books videos and audios in the library. b) for checking  out or returning of book c) for adding or removing of books in the library d) for keeping track of fine due if the book is returned after due date Assignment 4.     a) Write a program that can be used as a database of students information for a department. The program should be able to dynamically allocate or deallocate storage for the students records using linked lists. The database should have the following fields: the first and last names  a course code  and a grade for a student.  The program should display the following menu:  Welcome to the database menu!  Press 1 to insert a new record   Press 2 to delete a record  Press 3 to search the database (by last name)  Press 4 to print a range in the database  Press 9 to quit      b) Write a program for merging two sorted linked lists to form a third sorted linked list.  Assignment 5.     B Level Syllabus R4    103  Implement a sparse matrix in which any or most of the entries are zero. Because allocating memory space for all entries of the matrix will be wasteful we intend to allocate memory space only for nonzero entries.   (a) Represent a sparse matrix as a doubly linked circular or any other data structure which you think is useful.  (b) Write a program to perform the following operations:  (i) Read in inputs for the entries of a sparse matrix and form a suitable data structure.  (ii) Addition of two sparse matrices  (iii) Subtraction of two sparse matrices  (iv) Multiplication of two sparse matrices  (v) Deletion of a sparse matrix  (vi) Print sparse matrix (in matrix form)  Hint : Each entry of a sparse matrix can be viewed as a structure of the form  Row-index   Column-index   Value Left pointer Up pointer  Row index points to the next row (i.e. down). Column-index points to the next column (i.e. right).Value points to the information of data type added. Left pointer points to the element towards the next left element. Right pointer points to the element towards the next up element. Assignment 6.    There are three circular disks having a hole in the center and placed on a peg and there are two empty pegs. The three disks are of different sizes. It is now required to transfer the three disks (named A  B  and C : C is smallest) from the source peg P1 to the target peg P2 using a standby peg P3 such that   (i) only one disk can be moved at a time and  (ii) no disk can be kept on top of a disk with smaller diameter.  Build a system that gives the solution for the above problem.  [ Hint: Assume that there are three stacks for three pegs SP1  SP2  and SP3. Transferring a disk  from one peg to other involves ADD and DELETE operations of stacks ] Assignment 7.    Given a linked list of integers sorted from smallest (at the head end) to largest  and a pointer to a single node containing an integer  make appropriate function that insert the node in the linked list so that it remains sorted.  Assignment 8.   Implement a data structure that supports the following operations: insert  findMin  findMax  deleteMin  deleteMax  isEmpty  makeEmpty. You must use the following algorithm: maintain a sorted array. Insert new items into the correct position in the array  sliding elements over one position to the right  as needed. findMin and findMax  and deleteMax are trivial. For deleteMin remove the item in position 0  and slide over all the other items one position to the left.  Assignment 9.    Companies and people often buy and sells stocks. Often they buy the same stock for different prices at different times. Say a person owns 1000 shares a certain stock (such B Level Syllabus R4    104  as Checkpoint)  she may have bought the stock in amounts of 100 shares over 10 different times with 10 different prices.  In this assignment  you will be using a stack for Lifo accounting. You should use an array based implementation for your stack based implementation or a linked list for implementing your stack. Your stack  should have records with the following fields: The name of the stock (a string or int) The number of shares of a stock (an int) The purchase price (can be a decimal)  You can assume that the first element of the structure is the security bought first  the second was bought second  etc.  Create a program that should have the user able to enter information about various stocks  the amount of shares  and the price. The user can then enter a query about a certain stock and the cost according to the Lifo accounting methods for a certain number of shares.  The following could be your menu:  Press 1 to enter a new stock. Press 2 to find the Lifo price for a stock.  If 1 is pressed  the user needs to enter the stock symbol  and the number of shares  and the price. If 2 is pressed  the user needs to enter the stock symbol being queried and the number of shares in question. Assignment 10.   Companies and people often buy and sells stocks.  Often they buy the same stock for different prices at different times. Say a person owns 1000 shares a certain stock (such as Checkpoint)  she may have bought the stock in amounts of 100 shares over 10 different times with 10 different prices.  In this assignment  you will be using a queue for storing data for Fifo accounting You should use an array based implementation for your queue based implementation or a linked list for implementing your queue. Your queue should have records with the following fields: The name of the stock (a string or int) The number of shares of a stock (an int) The purchase price (can be a decimal) You can assume that the first element of the structure is the security bought first  the second was bought second  etc. Create a program that should have the user able to enter information about various stocks  the amount of shares  and the price.  The user can then enter a query about a certain stock and the cost according to the Fifo accounting methods for a certain number of shares. The following could be your menu:  Press 1 to enter a new stock Press 2 to find the Lifo and Fifo price for a stock.  B Level Syllabus R4    105  If 1 is pressed  the user needs to enter the stock symbol  and the number of shares  and the price. If 2 is pressed  the user needs to enter the stock symbol being queried and the number of shares in question. Assignment 11.    A deque is a data structure consisting of a list of items  on which the following operations are possible: a) push x : Insert x on the front end of the deque. b) pop : Remove the front item from the deque and return it. c) inject x : Insert x on the rear end of the deque. d) eject : Remove the rear item from the deque and return it. Describe routines to support the deque that take constant number of steps for each operation. You may use array-based or pointer-based implementation. Assignment 12.   A Matrix is a rectangular arrangement of values  where each element is specified as   A={a[i j] }m*n   a[i j] is element at i-th row and j-th  column.   m is the number of rows  n is the number of columns.           Assume we have multiplication of two matrices as                      1     1 4   2      3      4          16    8    10          2     3 2      *   2      1      2  =      16   11   16          3     2 1   3      1      1          13   12   17 Write a program for Multiplication of two matrices using OOP concept?  Assignment 13.   A polynomial(quadratic) is as   ax^2 + bx + c where a b c are constants and x is a variable   Here's a table of names for polynomials and their sources:     degree    name         shape    dimension      ------    ---------    ------      ---------         1     linear       line        (1)         2     quadratic    square   (2)         3      cubic        cube      (3)         4      quartic       -             4         5      quintic       -             5  a) Write a program for implementing a polynomial of degree 2?  b) Write a program for adding and subtract two polynomials(Using Linked List)  Assignment 14.    Consider a database of students information for a department . The program should be able to dynamically allocate or deallocate storage for the students records. The database should have the following fields:  the first and last names  a course code  and a grade for a student Create a C++ function to search  a particular students information from the database using  a) linear search and  b) binary search  B Level Syllabus R4    106  Assignment 15.   Consider a database of patients information for a hospital. The program should be able to allocate and deallocate storage memory for the patients records. The database should have the following information field: the first and last names  patient id  address   related disease   date of  admission  Devise an appropriate C++ class and circular queue using arrays to implement the following functions  a) creation of circular queue  b) accessing the element from the circular queue  and  c) searching element from the circular queue. Assignment 16.    Create a Phone Book Data Store class. The requirements for this class are given below:  -Create 2 String arrays for storing names and numbers  respectively.  -Create class member variables for the capacity of the storage and the number of entries in use.  -Use the constructor to initialize the arrays to a size specified by a parameter.  -On this class  create and implement the following 4 methods:  o storeNumber( ) should take two parameters  the name and the phone number to  store; it will not return any value. It will iterate through the store  find the next open  space  and store the name and number.  o retrieveNumber( ) should take one parameter  the name  and return one   parameter   the number. It will iterate through the storeuntil it matches the name  and then return  the number.   o replaceNumber( ) should take two parameters  the name and the phone number to  store; it will not return any value. It will iterate through the store until it matches the  name  and then replace the number.  o getAllNamesAndNumbers( ) does not take any parameters. It will return a list of all      of the names and numbers stored in the store.   -Use the PhoneBookDataStore.main( ) method to test the data structure. Create an instance that stores 5 numbers.  Finally  create an instance of PhoneBookDataStore as a member of your PhoneBook class  and   implement the user interface (e.g. prompting) using circular linked list to  (a) collect names and phone numbers from the user and store them in the data store and  (b) print out a list of names and numbers.  Assignment 17.   a) Infix  Postfix and Prefix notations are three different but equivalent ways of writing expressions.  Infix notation: X + Y   Operators are written in-between their operands. This is the usual way we write expressions. An expression such as A * ( B + C ) / D is usually   taken to mean something like: ""First add B and C together  then multiply the result by A  then divide by D to give the final answer.""   Postfix notation (also known as ""Reverse Polish notation""): X Y +  B Level Syllabus R4    107   Operators are written after their operands. The infix expression given above is equivalent to A B C + * D /   Prefix notation (also known as ""Polish notation""): + X Y   Operators are written before their operands. The expressions given above are equivalent to / * A + B C D   Write a program in C++ to convert an expression into a) prefix and b) postfix expression?    b) Write a C++ program for the evaluation of postfix expression using Stack?  Assignment 18.    Implement a class of your own: a priority queue for a hospital emergency room  for example  where it needs to schedule patients according to priority. A patient with a more critical problem will pre-empt others even if they have been waiting longer. This is a priority queue  where elements are prioritized relative to each other and when asked to dequeue one  it is the highest priority element in the queue that is removed.   Write necessary functions on a priority queue as a) create a empty queue  b) whenever a more critical patient come  the system will preempt the queue and add patient in the queue depending on its priority  c) access all patients information from the queue?  Assignment 19.   Parsing  a file  is  when you read a file  to  collect information from  the file.  In this assignment  you will parse a file  and put all of the words in a BST. You will use the BST to collect data about the number of times a word was found in the file. You should make no assumptions about which letters are in the middle (like M). The first word you encounter will be the root. If the next word is greater  put it to the right. If it is less  put it to the left. It is possible that the tree you make will be very very sparse (think what happens when the first word is zylberstein). Assume all words in the file are lower case (you can covert them easily anyway). I would recommend using the string library (it makes comparisons much better).     Devise appropriate functions  for a) creating a BST  b) adding any word   c) deleting any word  d) modification of any word  and e) searching any word in a BST. Assignment 20.   Build a Binary Search tree by adding the following items into an empty Binary Search Tree  in order: a) J  T  E  G  F  B  A  R  O  P  U  M  N  K  L  H  D  S  C  Q  I Write the functions for the tree in each of the following orders: a) Pre-order first traversal b) In-order  first traversal c) In-order  first traversal Assignment 21.      There are different sorting techniques used for arranging the values present in the list. Suppose we have a list of names of persons as  B Level Syllabus R4    108               a)Rajan  Rohit  Aman  Jinny  Sanjay  Bhatachariya Write C++ programs arrange these names using:  a) Bubble Sort    b) Selection Sort   c) Insertion Sort   d) Quicksort   e) Heap Sort  f) Merge Sort  ii) Differentiate between sorting Arrays vs sorting Linked Lists?  Assignment 22.    A bank needs to maintain records of its customers. It is decided to create a database using B-Tree or any other data structure which you think is useful. The order is based on the key and the Social Security number of each Customer. Each record contains the following information.  Name  Social Security Number  Street Address  City  State  Pin code  Date of Birth  Marital Status  Account Number  Account Type (Fixed  Saving  etc.)  A DBMS needs to be designed to provide menu driven facility to its users. The facilities are : I. Insert the record for a new customer  F. Find and display the record for a customer specified by name or by social security number  U. Update the record  D. Delete the record of a customer from the database.  Assignment 23.   A balanced binary search tree where the height of the two subtrees(children) of a node   differs by at most one is known as AVL tree. Insert 2  9  4  1  7  10  3  6  5  8 one by one into an initially empty AVL tree. Show the AVL tree after each insertion.           Write a C++ program for creating AVL tree-with insertion  deletion of data values into it?  Assignment 24    Kruskals algorithm is an algorithm for computing a minimum spanning tree. It maintains a set of partial minimum spanning trees  and repeatedly adds the shortest edge in the graph whose vertices are in different partial minimum spanning trees.  Write a C++ program for implementing Kruskals algorithm for a graph shown in Figure 1? B Level Syllabus R4    109  .  Assignment 25.   In Prim's algorithm we compute a minimum spanning tree by beginning with any vertex as the current tree. At each step add a least edge between any vertex not in the tree and any vertex in the tree. Continue until all vertices have been added.  Write a C++ program for implementing Prims algorithm for a graph shown in Figure1? Assignment 26.   Depth First Search is any search algorithm that considers outgoing edges (children) of a vertex before any of the vertex's siblings  that is  outgoing edges of the vertex's predecessor in the search. Extremes are searched first. This is typically implemented with a stack. Also known as DFS. Write a program in C++ to  find the DFS of the graph shown in  Figure 2? Assignment 27.   Breadth First Search is any search algorithm that considers neighbours of a vertex  that is  outgoing edges of the vertex's predecessor in the search  before any outgoing edges of the vertex. Extremes are searched last. This is typically implemented with a queue. Also Known as BFS. Write a program in C++ to find the BFS of the graph shown in Figure 2?  B Level Syllabus R4    110  B2.2-R4: INTRODUCTION TO DATABASE MANAGEMENT SYSTEM  Objective of the Course This course will allow students to develop background knowledge as well as core expertise in Database Management Systems.  The students will learn Database concept  Data Structure  Data Models  various approaches to Database design  strengths of relational model  Normalization.   At the end of the course the student will be able to   Understand Database design and normalisation techniques.  Use Standard Query Language and its various versions.  Understand Importance of backup and recovery techniques.  Develop Database system to handle the real world problem. Outline of Course  S. No.   Topic Minimum number of hours 1. An Overview of Database Management System 04 2. An Architecture of the Database System 04 3. Relational Database Management System 08 4. Normalization 08 5. Relational Algebra and Relational Calculus 08 6. The SQL Language 12 7. Backup and Recovery 02 8. Security 02 9. Integrity   02 10. Design and Development of Database Applications 10 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. An Overview of the Database Management System                           04 Hrs. What is database?  Why database?  database system  database management system (DBMS)  advantages of DBMS.  2. An Architecture of the Database system                                                        04 Hrs. Three levels of architecture  mappings  role of database administrator(DBA)  E-R model  three approaches of DBMS- relational  hierarchical and network.  3. Relational Database Management System (RDBMS)                                    08 Hrs. Introduction  RDBMS terminology  relational model  base tables  keys.   4. Normalization                                                 08 Hrs. Normal forms  Boyce-Codd Normal form  higher normal forms. 5. Relational Algebra and Relational Calculus                                         08 Hrs. B Level Syllabus R4    111  Relational operators  tuple calculus  well formed formulae.  6. The SQL Language                                                      12 Hrs. Introduction   Characteristics of SQL  data definition  data manipulation  SQL commands  SQL operators  Queries  aggregate functions.  7. Backup and Recovery                                            02 Hrs. Transaction recovery  system recovery  SQL  support   8. Security                                                                  02 Hrs. General considerations  controls  audit trail  data encryption  SQL support.  9.  Integrity                                                        02 Hrs. General considerations  integrity rules  SQL support.  10. Design and Development of Database Applications                            10 Hrs. Database applications using some standard RDBMS.  RECOMMENDED BOOKS  MAIN READING  1. Silberschatz A  Korth H.F and Sudarshan S  Database System Concepts  Fifth Edition  Tata McGraw-Hill  2006.    2. C.J.Date   An introduction to Database Systems  Pearson Education  2007.  3. R. Elmasri  S. B Navathe   Fundamentals of Database System  Pearson Education  2007. 4. Desai C. Bipin  An Introduction to Database Systems  Galgotia Publication  2009.  SUPPLEMENTARY READING  1. Leon A and Leon M  Fundamentals of  DBMS  Vijay Nicole & Tata McGraw-Hill  2007. 2. Gill P.S  DBMS  I.K. International  2008. 3. Singh S.K  Database Systems: Concepts  Design & Applications  Pearson Education  2008. 4. Leon A and Leon M  Database Management Systems  Vikas Publishing House. B Level Syllabus R4    112  B2.2-R4: INTRODUCTION TO DATABASE MANAGEMENT SYSTEM   Model Question Paper NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS                         TOTAL MARKS: 100    (PART ONE: 40; PART TWO: 60) PART ONE (Answer all the questions; each question carries ONE mark) 1.      Each question below gives a multiple choices of answers. Choose the most appropriate one.                        1.1. One of the following is a valid record -based data models e) Object-oriented model f) Relational model g) Entity-relationship model h) None of the above  1.2. Which of the following is not a valid unary operation in the relational algebra? e) select f) min g) project h) rename  1.3. An abstraction concept for building composite objects from their component object is called e) Specialization f) Normalization g) Generalization h) Aggregation  1.4. The expression (RUS)-((R-S)U(S-R)) is equivalent to e) R S f) R S g) (condition) (RxS) h) (RxS)  1.5. To represent many to many relationship between two entity types A and B in a relational model e) put identifying attribute(s) of A in the relation representing B. f) put identifying attribute(s) of B in the relation representing A. B Level Syllabus R4    113  g) create a new relation to represent the relationship. h) It can not be represented.  1.6. If a relation A has m attributes and relation B has n attributes and A divide by B is possible then A divide by B has e) m*n attributes f) m-n attributes g) n-m attributes h) m / n attributes  1.7. Which of the following cannot enhance database system throughput? e) Database system throughput can be enhanced by locking the smallest sized objects possible f) Database system throughput can be enhanced by reducing the time that transaction that hold locks g) Database system throughput can be enhanced by reducing the hot spots (frequently accessed and modified database objects) h) Increasing the main memory capacity can enhance database system throughput.  1.8. Object based data models are used in describing the abstraction of the following level(5). e) Only physical f) Conceptual and view g) Physical and conceptual h) None of the above  1.9. Assume transaction A holds a shared lock R. If transaction B also requests for a shared lock on R. e) it will result in a deadlock situation f) it will immediately be granted g) it will immediately be rejected h) it will be granted as soon as it is release by A  1.10. In which of the following situations would one have to use an outer join in order to obtain the desired results? e) A report is desired that lists all customers who placed an order. f) A report is desired that lists all customers and the total of their orders. g) A report is desired that lists all customers  the total of their orders during the most recent month  and includes customers who did not place an order during the month (their total will be zero).  h) There is never a situation that requires only an outer join.  2. Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book.  a. In a hierarchical database  modeling of many to many relations in achieved by record replication. b. Twophase locking protocols ensures freedom from deadlock. c. A constraint is a rule in a database system that can be violated by users. d. Integrity constraint guard against accidental damage to the database. e. The recovery manager is responsible for implementing a particular strategy for concurring control. f. Specialization is the reverse of generalization. B Level Syllabus R4    114  g. Domain relational calculus restricted to safe domain expressions is equivalent in expressive power to the basic relational algebra. 2.8 The process of check pointing reduces the amount of work done by DBMS during the restarting process. 2.9 A view is a table whose rows are computed as needed. 2.10 If GROUP BY is omitted in a SELECT command; entire table is taken as a        group.  4. Match words and phrases in column X with the nearest in meaning in column Y. X Y 3.1    Operation that create a new instance of a class is     called a(n) n) Unary    3.2   Shows the static structure of an object-oriented model o) constructor operation    3.3   A set of values that may be assigned to an attribute. p) DDL    3.4   A system used in transaction-oriented applications that involve real-time processing of transactions. q) Online Transaction Processing  3.5    Relationship occurs between two instances of a single entity type r) DISTINCT 3.6    Encoding data to make them unintelligible to unauthorized persons. s) Domain 3.7    A logical representation of the data for an  organization t) Data recovery 3.8    Data Dictionary u) Class Diagram 3.9    Shadow paging v) entity-relationship model   3.10  Eliminate duplicate rows from the query result         set. w) DML  x) Encryption  y) Deadlock  z) Cardinality 5. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below :  (a) Encapsulation  (b) Class  (c)  Structured   Query Language (d) entity   (e) Candidate key  (f) enterprise data    modeling outer jain  oouter outer join (g) abstract class  (h) CASCADE   (i) Interleaved main    memory (j) Virtual memory  (k) conceptual schema  (l) client   (m) null  a. ___________ is a tool even non-programmers can use to access information from a database. b. The first step in database development  in which the scope and general contents of databases are specified  is called _____.  c. The _____________ tier concentrates on managing the user-system interface as well as localized data. d. When creating tables using the CREATE TABLE statement  NOT NULL constrains an attribute from being assigned a(n) _______ value. e. An attribute or combination of attributes that uniquely identifies a row in a relation is called a(n) _______  _________. f. _____ is the technique of hiding the internal implementation details of an object from B Level Syllabus R4    115  its external view.  g. A class that has no direct instances  but whose descendants may have direct instances is called a(n) _______  _______.  h. Using an ___________  ____________ produces this information: rows that do not have matching values in common columns are also included in the result table. i. The ON UPDATE ____________ option allows changes to a parent table to pass onto a child table or tables. j. Transforming data in blocks from the main memory to the cache memory enables an ________unit to operate at its maximum speed.  PART TWO (Answer any FOUR questions) 5. a. Construct an ER diagram (including important attributes) for a car insurance database that includes data about Customer (Car owner)  Cars  accident  drivers involved in accidents and injured drivers and/or passengers. Note that any customer can insure many cars  each car may have different drivers at different times and accidents typically involved one or more cars. b. Explain the advantages and disadvantages of Database Processing? (10+5) 6. a. Explain the purpose and scope of Database security and explain the following in terms of providing security for a database: authorization  views  backup and recovery  Integrity  encryption and RAID technology. b. Consistency and reliability aspects of transaction are due to the ACIDity properties of transaction. Discuss each of these properties and how they relate to the concurrency control and recovery mechanisms? Give examples to illustrate your answer.  (8+7) 7. a. Explain the difference between external  internal and conceptual schemas. How these different layers are related to the concepts of logical and physical and physical data independence. b. What is a time stamp? How do time stamp based protocols for concurrency control differ from locking based protocols?  (7+8) 8. a. Consider the following Relation Schema. An employee can work in more than one department: Emp (E-id  E_name  Salary) Dept (d_id  d_name  manager_id  floor_number) Write the following queries in SQL: I. Print the name of all employees  who work on the 10th floor and earn salary less than Rs.50 000. II. Print the names of the departments that employee Santa work in. III. Print the names of all managers who manage three or more departments on the same floor. IV. Print the names of all employees who work on floors where Jane Donald works. V. Give every employee who works in the toys dept. at 10% raise in the salary. b. Explain 3rd normal form with suitable example. c. In what way dynamic SQL is different from embedded SQL?  (5+5+5)  B Level Syllabus R4    116  9. a.  Explain the Codd rules regarding null values and database description. b.    Explain the three levels ANSI/SPARC database architecture with its significance. c. Explain with examples  how primary key and foreign key concepts is useful in relational data model? (6+6+3) B Level Syllabus R4    117  B2.2-R4: INTRODUCTION TO DATABASE MANAGEMENT SYSTEM  Assignment 1.   The following tables form part of a database held in a relational DBMS: Hotel (Hotel_No   Name  Address) Room (Room_No  Hotel_No  Type  Price) Booking (Hotel_No  Guest_No  Date_From  Date_To  Room_No) Guest (Guest_No  Name  Address) where Hotel contains hotel details and Hotel_No is the primary key.  Room contains room details for each hotel and (Hotel_No  Room_No) forms the primary key. Booking contains details of the bookings and the primary key comprises (Hotel_No  Guest_No  Date From) and Guest contains guest details and Guest_No is the primary key.  Write the SQL statements for the following: a) List full details of all hotels in Mumbai. b) List the names and addresses of all guests in New Delhi  alphabetically ordered by   name. c) List all double or family rooms with a price below Rs.800 per day  in ascending order  of  price. d) List the bookings for which no date to has been specified. e) What is the total daily revenue from all the double rooms? f) How many different guests have made bookings for August  2006? g) List the price and type of all rooms at the hotel Land Mark. h) What is the total income from bookings for the hotel Manor today  Assignment 2.  Create an E R diagram and relational schema to hold information about the situation in many institutions affiliated to some University  many teachers of different disciplines are teaching to many students enrolled in many courses offered by the university to the students through the institutions. Use concept of keys  aggregation  generalisation  cardinality etc. in a proper way.  Say the schema of respective entities is:    Teacher( T#  Tname  Tqual  Tsubject  Tcourse  Prog) Student(Roll#.  Sname  Sage  Saddress  Scourse.Prog   Smarks) Teaches(T#  Roll#   Scourse  Prog  University)  Assignment 3.   Performa following queries in SQL using the above schema: a) Find details of Teachers who taught DBMS.  b) Find details of students who did MCA from PB University.  c) Find courses taught by T# 5078.  d) Find address of students whose marks are less than 50.  Assignment 4.  Consider the following requirements for a construction company that uses database system to keep track of its projects  workers and material requirements of various projects.  The projects for the company are of two kinds: (i) Turn key projects and (ii) Others. B Level Syllabus R4    118  All the projects have a life cycle (Please note that the turn key projects have a maintenance phase in addition.) and workers are allotted as per the phase of the project. Each project has its own plan of completion that is drawn at the start of the project. The worker and material requirement of project is calculated at the start of the project. The store manages the materials. One of the major constraints for the store is that it requires 15 days to acquire a product. Thus  the inventory should fulfil the requirements of the next 15 days.  The store also keeps track of the issue of materials and return of defective materials to various projects.  The company keeps the information of all the clients including the information about the projects that are being maintained by the company (turn key projects).  Draw an ER diagram for the above company. Specify key attributes and constraints of each entity type and of each relationship type. Note any unspecified requirements and make appropriate assumptions to make the specification complete. Also  design the normalised tables with required integrity and security constraints.   Assignment 5.   Assume that a Consumer item lease Company which leases various household items to its clients for their use for a specific period of time  maintains the following tables:  Clients (clientID  name  address  contact Phone) Itemlist (itemID  itemName  itemCost  purchase Date ) Leaselist (clientID  transactionNO  itemID  startDate  returnDate  amountTObeCharged)  Note: A client may lease an item many times. Amount to be charged is calculated as per a fixed rate multiplied by number of days item is leased. All items have unique itemID. However  two or more items may have same name.  Create the tables having appropriate referential integrity constraints. Make and state assumptions  if any.  Write and run the following SQL queries on the tables:  a) Find all the client names that have not got any item leased during the last month and no leased item is pending with them. b) Find the list of all the items that were leased or returned last month. c) Find the names of all those clients who have given the business to the company in the decreasing order of total amount paid by a client. d) List the client's details and the items leased to them at present. e) Find the client who has been leased at least two items.  Assignment 6.   Produce an E-R diagram  which documents the entities and relationships involved in the staff management and pay-roll for the employees working in a super market. Create a B Level Syllabus R4    119  relational schema to hold information. Identify the tables  perform normalization to the tables and fully implement the code with necessary validations using MS-Access / FOXPRO / DBASE or any other similar package. Provide necessary documentation and coding for the project.  Note: Assumptions can be made wherever necessary  Assignment 7.   The NBA (NDHU Basketball Association) is in dire need of a database in order to keep track of the activities in their league.  The entities in the database are   People (with attributes id  name and age)   Teams (with attributes team name and manager)  and  Courts (with attributes court id  address and capacity).   Furthermore  people are specialised into Referees and Players.    Referees have the extra attribute level and  Players have the extra attribute height.   Players play in teams  and teams and referees participate in a game that takes place in a court on a certain date.  This league is quite violent and very often players are fouled out by referees.  This causes bad relationships between teams and referees and some teams disqualify some referees from refereeing their games.  Some way of recording each game is also required.  This will need to store the home and away teams scores.  No player plays for more than one team. Only one game is played on one court on any one day.  a) Produce a set of normalised entities to 1NF. Add attributes as you think they are required. b) Create an ER diagram that models the relationships in the system.  Assignment 8.  Normalization of the CAR_SALE Table. The purpose of this exercise is for you to demonstrate your ability to take a database schema and convert it up through the Third Normal Form. Upon completion of this exercise you will have:  a) Listed the functional dependencies for a database schema b) Explained why a specific schema is not in Second or Third Normal Form c) Normalized a given schema into the Third Normal Form  The below scenario has been created to help you determine the table structures required for each of the subsequent normalized tables.  Scenario You are given the database schema for a car sales database as follows:  Table Name: CAR_SALE B Level Syllabus R4    120  ColumnName   Car_num   Date_sold  Salesman Commission_percent Discount_amt  KeyType             Primary      Primary Assuming that a car can be sold by multiple salesmen and  therefore  the attributes of ar_num and Salesman {Car_num  Salesman} taken together are the primary key for the relation. In addition  you are told that the date the car sells determines the discount amount and that each salesman has a unique commission rate.  Directions To complete exercise one  you should do the following: a) Read and complete each of the three steps identified under exercise two b) Create a response for each step listed under exercise two c) Create your response using MS Word d) When appropriate  use the table feature within Word to create your tables. e) Save the document as identified in the Labs section of the roadmap and upload the file in the course communication space drop-box.  Step 1 List the functional dependencies in the relation CAR_SALE. Based on the given primary key  decide if the dependency is  a) completely dependent on the primary key (primary keydependency)    b) partially dependent on the primary key (partial key dependency)  or   c)dependent on a non-key column (transitive dependency) for each of the Functional Dependencies you list.  Step 2 Explain why the relation CAR_SALE is not in 2NF or 3NF Step 3 Normalize the relation CAR_SALE into 3NF. Show your results by providing the resulting table schemas.  Assignment 9.  Exam Administration  Consider the following relation that keeps track of the exams taken by students at a University department:  Exam(studID  studName  courseID  courseTitle  acadYear  examSession  mark  degreeCourse)  Suppose the following functional dependencies hold on the relation:  studID -> studName  degreeCourse courseID -> courseTitle studID  courseID  acadYear  examSession -> mark studID  courseID -> acadYear  examSession  a) Decompose the relation in smaller relations such that B Level Syllabus R4    121      each of the smaller relations is in BNCF with respect to the projection       of the original dependencies;    the decomposition is a loss less join decomposition.  b) Is your decomposition dependency preserving? If your answer is yes  argue why. If your answer is no  show which dependencies have been lost.  Assignment 10.  Wholesale Dealer Consider the following relation that keeps track of the sales of a wholesale dealer in trousers:  TrousersSold(customerID  customerName  model  size  day  numberSold  price) Suppose the following functional dependencies hold on the relation:  customerID -> customerName customerID  model  size  day -> numberSold model  size -> price model  price -> size  a) Decompose the relation in smaller relations such that    each of the smaller relations is in BNCF with respect to the projection of the original dependencies;  the decomposition is a lossles join decomposition.  b) Is your decomposition dependency preserving? If your answer is yes  argue why. If your answer is no  show which dependencies have been lost.  Assignment 11.  Manufacturing Consider the following relation that keeps track of the orders placed by a manufacturing company:  Orders(orderDate  deliveryDate  supplier  partID  material  price).  Suppose the following functional dependencies hold on the relation:  orderDate  supplier -> deliveryDate partID  supplier  orderDate -> price partID -> material material -> supplier.  a) Decompose the relation in smaller relations such that  each of the smaller relations is in BNCF with respect to the projection of the original dependencies;  the decomposition is a lossless join decomposition.  b) Is your decomposition dependency preserving? If your answer is yes  argue why. If your answer is no  show which dependencies have been lost.  Note Solve the assignments from 12 to 20  through Select as well as through relational B Level Syllabus R4    122  algebra.  Database Schema  for the exercise:  Professor ( ssn   profname  status  salary) Course( crscode  crsname credits) Taught(crscode semester ssn)  Assumptions:  a) Each course has only one instructor in each semester. b) All professors have different salaries. c) All professors have different names d) All courses have different names e) Status  can take value from full associate   and assistant. Assignment 12.  Return those professors who have taught csc6710 but never csc7710  Assignment 13.  Return those professors who have taught csc6710 and  csc7710  in same semester.  Assignment 14.  Return those professors who have taught csc6710  or csc7710   but not both.  Assignment 15.  Return that course  which have never been taught.  Assignment  16.  Return that courses  that have been taught atleast in two semester. Assignment 17.  Return the names of all professors who have ever taught csc7710.  Assignment 18. Change all credits to 4  for those courses that are taught in semester f2006:.  Assignment 19.  Return the professor  who earns second highest salary.  Assignment 20. B Level Syllabus R4    123  Delete those professors who have never taught.  Assignment 21.      a)Create a tables Employee  with following columns :  Employee      Emp _ no integer NOTNULL Emp_fname char(20) NOTNULL Emp_lname char(20) not null Dept_no char(4) null  b)Create  a table Department with following columns:  Department Table Dept_no char(4) not null Dept_name char(25) not null Location char(30) null c)Create a table project with following columns:  Project table: Project_no char(4) notnull Project_name char(15) not null Budget float null  d)Create a table works_on with the following columns:  Works_on table Emp_no integer notnull Project_no char(4) notnull Job char(15) null  Assignment 22.  a) Using INSERT statement enter the following data in the Employee table:  Emp_no Emp_fname Emp_lname Dept_no 25348 Mathew Smith D3 10102 Ann Jones D3 18316 John Barrimore D1 29356 James James D2 9031 Elke Hansel D2 2581 Elsa Bertoni D2 28559 Sybill Moser D1  b) Using INSERT statement enter the following data in the Department  table:  Dept_no Dept_name Location D1 Research Dallas D2 Accounting Seattle D3 Marketing Dallas  B Level Syllabus R4    124  c) Using INSERT statement enter the following data in the Project table:  Project_no Project_name Budget P1 Apollo 120000 P2 Gemini 95000 P3 Mercury 185600  d) Using INSERT statement enter the following data in the works_on  table  Emp_no Project_no Job  10102 P1 Analyst 10102 P3 Manager 25348 P2 Clerk 18316 P2 Null 29346 P2 Null 2581 P3 Analyst 9031 P1 Manager 28559 P1 Null 28599 P2 Clerk 9031 P3 Clerk 29346 P1 Clerk  Assignment 23.  a) See the records of all the tables with SELECT command. b) List the Employee number of all the clerks. c) Get the employee numbers for all employees who have a leading job ( Analyst or Manager) in project P1. d) Get the employee number and first name of all employees whose first name starts with A. e) Find the employee details having  Maximum salary. Assignment 24. a) Find the employee details having second highest salary. b) Insert  the data of a new employee called Jullia Long   whose employee number is 11111. Her department no is not known yet. c) Change the name of the department of the employee James .The new department name is Sales. d) Find the employee number for all employees who are clerks or works in Department  D3. e) Create a table Sample and get all the record from employee table with select statement.  Assignment 25. a) Alter table sample   add new column Telephone_no char(12) null. b) Drop the Column Telephone_no from Sample table. c) Get the list of all the employee except the employees having emp_no either 10102 or 9031. d) List the name of the project whose budget lies between 95000 to 12000. e) Get the names of all the employees whose first name contains the letter a as the second character. f) Get Full details of  all  the employees whose departments are located in Dallas. g) Get all jobs of the employees. h) List the project numbers for all the projects employing less than four persons. B Level Syllabus R4    125  B2.3-R4 : BASICS OF OS  UNIX AND SHELL PROGRAMMING   Objective of the Course The objective of the course is to make students aware of the functioning of a multi-user operating system. This course will serve as a foundation course for the higher level course in Unix.  The students are expected to learn the commands while doing practical and emphasis should be given to those switches/options and flags  which are most frequently used in real life.   After completion of the course students will be able to:    Understand Operating System concepts.  Use System calls and memory management.  Use Unix commands and editors.  Carry out Unix File management and shell programming in Unix.  Do Network configuration and security management in Unix. Outline of Course  S. No.   Topic Minimum number of hours 1. Operating System Concepts 04 2. Linux Ideas and History 01 3. Linux Usage Basics 02 4. Running Commands and Getting help 02 5. Browsing the File System 04 6. The X-Window System 04 7. Users  Groups and Permissions 03 8. Advanced Topics in Users  Groups and Permissions 03 9. The Linux file system in-depth 06 10. vim: An advanced text editor 03 11. Standard I/O and Pipes 02 12. Using the bash shell  03 13. Configuring the Bash Shell  04 14. Text Processing Tools 03 15. Shell Programming 06 16. Investigating and Managing Process 04 17. Finding and Processing Files 02 18. Basic System Configuration Tools 04 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus 1. Operating System Concepts                                                                                 04 Hrs. Overview of OS. System Calls  Process Management  Memory Management  Disk and filesystems  Networking  Security  Graphical User Interface  Device Drivers.  2. Linux Ideas and History                                                                                    01 Hrs. What is Open Source?   Linux Origins  Red Hat Distributions  Linux Principles  B Level Syllabus R4    126  3. Linux Usage and Basics                                                                                           02 Hrs. Logging in to a Linux System  Switching between virtual consoles and the graphical environment  Elements of the X Window System  Starting the X server  Changing your password  The root user  Changing identities  Editing text files.  4. Running Commands and Getting Help                                                               02 Hrs. Running Commands  Some Simple commands  Getting Help  The whatis command  The help Option  Reading Usage Summaries  The man command  Navigating man pages  The info command  Navigating info pages  Extended Documentation  Red Hat Documentation.  5. Browsing the File System                                                                                    04 Hrs. Linux File Hierarchy Concepts  Some Important Directories  Current Working Directory  File and Directory Names  Absolute and Relative Pathnames  Changing Directories  Listing Directory Contents   Copying Files and Directories  Copying Files and Directories: The Destination  Moving and Renaming Files and Directories  Creating and Removing Files  Creating and Removing Directories  Using Nautilus  Determining File Content.  6. The X-Window System                                                                                           04 Hrs. XOrg: The X11  Server  XOrg Server  Design  XOrg  Server Configuration  XOrg Modularity  Server and Client Relationship  XOrg in runlevel 3  XOrg in runlevel 5  Configuration Utilities  Remote X Sessions. 7. Users  Groups and Permissions                                                                          03 Hrs. Users  Groups  Linux File Security  Permission Precedence  Permission Types  Examining Permissions  Interpreting Permissions  Changing File Ownership  Changing Permissions  Symbolic Method  Changing Permissions  Numeric Method  Changing Permissions  Nautilus  8.  Advanced Topics in Users  Groups and Permissions                                    03 Hrs. User and Group ID Numbers  /etc/passwd  /etc/shadow and /etc/group files  User Management  tools  System Users and and Groups  Monitoring Logins  Default Permissions  Special Permissions for Executables  Special Permissions for Directories.  9. The Linux File System In-depth                                                                             06 Hrs. Partitions and Filesystems  Inodes  Directories  Inodes and Directories  cp and inodes  mv and inodes  rm and inodes  Hard Links  Symbolic ( or soft) Links  The Seven Fundamental Filetypes  Checking Free Space  Removable Media  Mounting CDs and DVDs  Mounting USB Media  Mounting Floppy Disks  Archiving Files and Compressing Archives  Creating  Listing and Extracting File Archives  Creating File Archives: Other Tools.  10. vim: An Advanced Text Editor                                                                            03 Hrs. Introducing vim  vim: A Modal Editor  vim basics  Opening a file in vim  Modifying a file  Saving a file and exiting vim  Using Command Mode  Moving around  Search and Replace  Manipulating Text  Undoing changes  Visual Mode  Using multiple windows  Configuring vi and vim  Learning more.  11. Standard I/O and Pipes                                                                                        02 Hrs. Standard Input and Output  Redirecting Output to a File  Redirecting STDOUT to a Program(Piping)  Combining Output and Errors  Redirecting to Multiple Targets (tee)  Redirecting STDIN from a file  Sending Multiple Lines to STDIN.  B Level Syllabus R4    127  12. Using the Bash Shell                                                                                            03 Hrs. Bash Introduction  Bash Heritage and Features  Command Line Shortcuts  History Tricks  Command Line Expansion  Command Editing Tricks  gnome-terminal  13. Configuring the Bash Shell                                                                                 04 Hrs. Bash Variables  Environment variables  The TERM Environment variable  The PATH Environment variable  Some common variables  Aliases  How bash expands a Command Line  Preventing Expansion  Login vs non-login shells  Bash startup tasks: profile  Bash startup tasks: bashrc  Bash exit tasks  14. Text Processing Tools                 03 Hrs. Tools for Extracting Text  Viewing File Contents  Viewing File Excerpts  Extracting Text by Keyword  Extracting Text by column  Tools for analyzing text  Gathering text statistics  Sorting Text  Eliminating Duplicate Lines  Comparing Files  Duplicating File Changes  Spell Checking with aspell  Tools for manipulating Text  sed  Special Characters for Complex Searches.  15. Shell Programming                 06 Hrs. Scripting Basics  Creating Shell Scripts  Generating Output  Handling Input  Exit Status  Control Structures  Conditional Execution  File Tests  String Tests  for and sequences  continue and break  Using positional parameters  handling parameters with Spaces  Scripting at the command line  Shell Script debugging.  16. Investigating and Managing Process              04 Hrs. What is a Process? Listing Processes  Finding Processes  Signals  Sending Signals to Processes  Scheduling Priority  Altering Scheduling Priority  Interactive Process management tools  Job Control  Scheduling a Process to execute later  Crontab File format.  17. Finding and Processing Files                02 Hrs. Locate  Locate Examples  find  Basic find Examples  find and Logical Operators  find and Permissions  find and Numeric Criteria  find and Access Times  Executing commands with find  find Execution Examples  The GNOME Search Tool.   18. Basic System Configuration Tools               04 Hrs. TCP/IP Network Configuration  Managing Ethernet Connections  Graphical Network Configuration  Network Configuration Files  Printing in Linux  Setting the System's Date and Time  Managing Services.  RECOMMENDED BOOKS   MAIN READING  1. Maurice J. Bach  Design of the Unix Operating System  Pearson Education 2008. 2. Sumitabha Das  Unix : Concepts and Applications  Tata McGraw-Hill   2008. 3. ISRD Group  Basics of OS  UNIX and SHELL Programming   Tata McGraw-Hill 2006. 4. Sarwar  Koretsky  and Sarwar  Unix   The Text Book  Pearson Education  2007. SUPPLEMENTARY READING 1. Stephen Prata Advanced Unix -A programmers Guide.  BPB Publication  2008. 2. Kochan S & Wood P  Unix Shell Programming  Pearson Education  2008. 3. Stevens W R  Rago S.A  Advanced Programming in Unix Environment  Pearson Education  2008. B Level Syllabus R4    128  B2.3-R4: BASICS OF OS  UNIX AND SHELL PROGRAMMING  Model Question Paper  NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS                                         TOTAL MARKS: 100                                (PART ONE-40; PART TWO-60)  PART ONE  (Answer ALL Questions; each question carries ONE mark) a) Each question below gives a multiple choices of answers. Choose the most appropriate one. 1.1 Which one of the following is used to start X server? a) startwindow b) startx c) startxserver d) startgui 1.2 Which one of the following lets you know short description of command? a) show b) descriptor c) whatis d) none of the above 1.3 Which one of following is used to redirect output to a file while still redirecting to another program? a) > b) >> c) 2> d) tee 1.4 What command gives space usage per file system? a) df b) du c) ls d) chkdisk  1.5 Linux allows the use of more than one command in one line by specifying the following symbol among the commands: a) ; b) : B Level Syllabus R4    129  c)   d) >1.6 To copy entire directory structure  we need to use a) cp  s  olddir   newdir b) cp  d  olddir   newdir c) cp  e  olddir   newdir d) cp  r  olddir   newdir 1.7 Which one of the following is used to send signal to process? a) sig b) kill c) switch d) None of the above 1.8  Vim is text editor in Linux. Which one is used to redo last undone change in file? a) r b) r c) r d) r 1.9 Which one of the following suspends a foreground process? a) s b) r c) z d) x 1.10 File tests are used to test variety of conditions that relate to files on the system. Which one of the following returns true if file is symbolic link? a) d     b) e     c) s     d) h     2. Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book. 2.1 Locate searches file in to current directory by traversing current directory. 2.2 Ctrl + F1 is used to switch from virtual console to graphical environment.  2.3 Nice alters process scheduling priority. 2.4 During opening a files using vim editor  multiple files can be supplied to vim in command line. 2.5 Users name and password are stored in /etc/passwd directory. 2.6 su command is used to change user. 2.7 PATH is an environment variable 2.8 In file system of Linux  .(dot) refers to parent Directory. 2.9 In vi text editor  5b takes the cursor 5 words backward to the beginning of the word in ex mode. 2.10 Unique command removes all duplicate lines from file.  3. Match words and phrases in column X with the nearest in meaning in column Y.  X  Y B Level Syllabus R4    130   3.1 Detail documentation of command a) path   3.2 Directory of all users are located b) PS1  3.3 Displays absolute path of current directory c) help  3.4 The process who doesnt have parent d) diff  3.5 Users password stored in encrypted form e) /etc/passwd  3.6 File executed when exiting a login shell f) /etc/.bash_logout  3.7 Used to compare two files for differences g) man  3.8 Displays process information. h) init  3.9 Used to compress files and directories i) Gzip  3.10 Local Variable j) /home   k) ~/.bash_logout   l) pwd   m) ps   n) /etc/shadow   4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below: 4.1 ______command is used to change password of root user. 4.2 ___________ can be used to change the default access permission of file. 4.3 The ________ command provides output from the beginning of the concerned file. 4.4 ________is used to combines files. 4.5 The command __________can change access time of a file 4.6 _________command is used to see file permissions in current directory. 4.7 Remote login to a machine can be done via __________ command.  4.8 The ________ command provides the facility to schedule a job at a specific time. 4.9 Path of the system wide startup script is ____________. 4.10 __________ gives groups you belong to.  PART TWO (Answer any FOUR questions) 5.  a. What is open source? What are the principles of Linux? b. List out command line expansion. Using suitable example  explain working of each command line expansion.   (6 + 9) 6.  a. Write a shell script which takes marks of five subjects as input  finds out the percentage and prints grade of exam. For example Input: Enter marks of subject: Subject1 70 Subject2 80 Subject3 80 Subject4 65 Subject5 75 Output: (a)  telnet (b) ls -l (c) time (d) groups (e) /etc/startup (f) join (g) passwd (h) login (i) touch (j) umask (k) In-core inode (l) changerootpwd (m) /etc/profile (n) Dir  -per (o) head (p) paste (q) PCB (r) at B Level Syllabus R4    131  Grade: Distinction b. What are the advantages of having distinct disk partition? c. What are various commands available in Linux for taking backups? Explain important options of each utility. (6 + 4 + 5) 7.   a. Linux provides prompt ($ or #) to execute commands. How does shell expand commands which are typed on prompt? b. How overwriting and appending can be performed in Linux? Using suitable example  explain how standard error can be redirected? c. List and explain fundamental file types in Linux. How file type can be obtained? (5 + 3 + 7)  8.   a. Write a shell script which finds out whether entered number is prime or not. Input: Enter Number:  5 Output:  Prime Number b. What do the following commands in vi specify? How are they used?  i) map  ii)? pat  iii) set  iv) ab c. How does the login:prompt appear? (5 + 5 + 5) 9.    a. Which command is used to change permission associated to File/Directories? List and explain methods to change permission of File/Directories. b. What is hard link and soft link? How it can be created? c. What are the special permissions for executables and directories? What are uses of special permission?  (5 + 5 + 5) B Level Syllabus R4    132  B2.3-R4 : BASICS OF OS  UNIX AND SHELL PROGRAMMING  Assignment 1.   Try the following command sequence and write its output:  cd ; pwd ;ls -al ; cd . ;pwd  (where did that get you?) ; cd .. ;pwd ; ls -al ; cd .. ; pwd;ls -al ;cd .. ;pwd     (what happens now) ;cd /etc ;ls -al | more ;cat passwd ;cd  ;pwd.  Assignment 2.   a) Explore the filesystem tree using cd  ls  pwd and cat. Look in /bin  /usr/bin  /sbin  /tmp and /boot. What do you see? b) Explore /dev. Can you identify what devices are available? Which are character-oriented and which are block-oriented? Can you identify your tty (terminal) device (typing who am i might help); who is the owner of your tty (use ls -l)?  c) Explore /proc. Display the contents of the files interrupts  devices  cpuinfo  meminfo and uptime using cat. Can you see why we say /proc is a pseudo-filesystem which allows access to kernel data structures?  Assignment 3.  a) Convert the decimal number 192 to octal and hexadecimal using bc command. b) Run ps   the script command and run ps again . What is its output. Explain. c) Write a command to create following directory structure in one command: DOEACCALEVELAL55 d) Create above  Directory Structure with permission 777.?  Assignment 4.  a) Run the following command and explain its output (i) cd ../.. (ii)mkdir ../bin  (iii)rmdir ..  (iv)ls .. b) Write a command to remove entire directory structure DOEACC/ALEVEL/AL55 in one command? c) Run the command tty and note the device name of your terminal. Now run cp /etc/passwd to device name of your terminal. Explain its output. Assignment 5.  a) How does the command mv bar1 bar2 behave   where both bar1 and bar2 are directories  when (i) bar2 exists and (ii)bar2 does not exist b) Write a command to display lines common to a.txt and b.txt? c) Write a command to display lines unique to a.txt? d) Run script command and then issue dir ls pwd commands and then run exit. What is its output?  Assignment 6.  a) Write a command to compare two text files. b) Write a command to copy a file with permission 444.Copy it again and explain your observation.  Assignment 7.  B Level Syllabus R4    133  a) Use chmod w . and then try to create and remove a file in the current directory. What is its output. b) Run the commands (i) ls ld .  and (ii) ls l .. Explain its output.  Assignment 8.   Using vi editor write commands to do the following a) Combine five lines into a single line. b) Search a pattern printf and then repeat the search in opposite direction. c) How will you insert /* at the beginning and */  at the end? Assignment 9.   Using vi editor  a) Write a command to copy line number 1 10 after line number 25. b) Write a command to move line number 1 10 after line number 25. c) Write a command to copy next 10 lines to a.txt.  Assignment 10.   Using vi editor  a) Write a command to undo last action. b) Write a command to create abbreviation  LU as Linux Unix. c) Write a command to map ctrl+K to display manual of vi editor.  Assignment 11.  a) Write a command to convert contents of a file a.txt to upper case  b) Write sequence of commands to convert 1st line of a file a.txt to upper case  c) Write a command to display name of a file in your current directory whose size is maximum.  Assignment 12.  a) Write a command to change modification time of a file without modifying the file. b) Write a command to display name of a file in your current directory whose size is maximum. Assignment 13.  a) We have a file emp.mast which consists of detail of employees in an organization   (Fields are  emp_id emp_name dept_name basic_salary designation dob).Write a command to display name of employee who is not director. b) Write a command to display name and basic of each employee.  Assignment 14. a) Using at command submit a job at 7 pm. b) Using batch command submit a job at 7 pm.. c) Delete a job from at queue. d) Display the listing of jobs in at queue. e) Write  a command to kill a job. B Level Syllabus R4    134  Assignment 15.  a) Write a command to display those lines in emp.mast in which Training is present. b) Write a command to display names of employees in Training Department. c) Write a command to display number of blank records in a file.  Assignment 16.  a) Write a command to display contents of a file emp.mast in sorted order on emp_id field. b) Write a command to display contents of a file emp.mast in sorted order on basic_salary  field. c) Write a command to display name of the youngest employee . d) Write a command to create backup of current directory. Assignment 17.  a) Write a Shell script to display factorial of a number. Number cannot be blank. b) Write a Shell script to send mail to all users on your System c) Write a Shell script to find sum of prime numbers between 2 and 200.  Assignment 18.  b) Write a Shell script to display sum of digits and number of digits in a number. Number cannot be blank. c) Write a Shell script /command to display contents of a file in reverse order. d) Write a Shell script to display sum of prime factors of a number. Assignment 19.  a) Write a shell script to create a data entry screen for the file emp.mast created in assignment no-13. b) Write a shell script to modify records on the basis of emp_id .Emp_id  should be entered by user or command line argument can be used. c) Write a shell script to insert and delete a record from emp.mast file.[Apply all validations] Assignment 20.  a) Write a shell script to generate salary slip of employees (emp_id wise) in file emp.mast by using following formula : Net Salary=Basic+DA+HRA+CCA-EPF. b) Write a shell script to check spelling in a file and replace misspelled word.  Assignment 21.  Write a script that compares two directories bar1 and bar2 and copies all files in bar1 to bar2  which are not present in bar2. Assignment 22.   Write a script that checks each minute and reports on who logs in and who logs out.  Assignment 23.   B Level Syllabus R4    135  Write a script which converts 1st character of each line in a file to uppercase.  Assignment 24.  a) Write a shell function size() which lists only the total size of the files supplied as arguments. b) Use the above function to display size of all files in a directory. Directory Name should be supplied at command line. Assignment 25.    Write a shell script to add   modify and delete users without using system administration command.  B Level Syllabus R4    136  B2.4-R4: DATA COMMUNICATION AND NETWORK TECHNOLOGIES  Objective of the Course This course will allow students to develop background knowledge as well as core expertise in data communication and networking (DCN) technologies  which is one of the fastest growing industries in todays world. It forms an integral part of the modern Information and Communications Technology (ICT) in any organizations. Starting from intranet/extranet in small offices to the World Wide Web  principles of DCN play an important role in designing any modern telecom infrastructure.  A major ramification of the fantastic growth of telecommunications and networking is a dramatic increase in the number of professions  where an understanding of DCN is essential for success. Today  students wanting to understand the concepts and mechanisms underlying DCN infrastructures come from a variety of academic and professional backgrounds. Hence  to be useful  a course on DCN infrastructures must be accessible to students without technical backgrounds while still providing technical material comprehensive enough to challenge more experienced readers. This course is designed with this new mix of students in mind.  The course  being the first one on telecommunication and networking in the DOEACC hierarchy  starts from the very basics of communication technology and goes up to the Internet  spanning all the five layers of TCP/IP model. The students will be exposed to communication principles  different types of media  modulation techniques  multiplexing  switched networks  the Internet  TCP/IP suite  network security  mobile wireless communication  fibre-optic communications and the state-of-art networking applications.   At the end of the course the students would know:   Evolution of data communication and networking paradigms  Principles of data communication  channel characteristics  signaling  modulation and encoding  and multiplexing (SONET/SDH)  Various transmission media  their comparative study  fibre optics and wireless media  Categories and topologies of networks (LAN and WAN)  Layered architecture (OSI and TCP/IP) and protocol suites  Channel error detection and correction  MAC protocols  Ethernet and WLAN  Details of IP operations in the INTERNET and associated routing principles  Operations of TCP/UDP  FTP  HTTP  SMTP  SNMP  etc.  Strategies for securing network applications in enterprises  Emerging technologies  such as WDM mesh  mobile telephony etc Outline of Course  S. No.   Topic Minimum number of hours 1. Data Communications 06 2. Communication Network Fundamentals 08 3. Media Access Control 06 4. Networking Components 06 5. Link Control and MAC Protocols 05 6. Local Area Networks (LAN) 05 7. Wide Area Networks (WAN) 08 B Level Syllabus R4    137  8. Application Protocols 08 9. Wireless Networks 03 10. Security and Management 05      Detailed Syllabus  1. Data Communications                  06 Hrs. Introduction  Communication Systems  Signal and data  Transmission modes  Synchronous and asynchronous transmission  Circuits  channels and multichanneling  Signaling  Encoding and decoding  Error detection and Recovery  Flow control  Sliding Window  Congestion Management  Multiplexing [FDM  TDM  CDM  WDM] and Spreading [DS. FH]  Concept of Modulation  Baseband versus Broadband; Pulse Code Modulation (PCM)  Shift Keying [ASK  FSK  PSK  QPSK  DPSK]; Encoding techniques and CODEC; Classification of Modems  Standards and Protocols  Protocols used by Modem to Transfer files  Establishing a Connection (Internet connectivity); Digital Subscriber Loop (DSL)  2. Communication Network Fundamentals            08 Hrs. Introduction  Switching techniques: Circuit Switching  Packet switching  Datagram  Virtual circuit and Permanent Virtual Circuit  Connectionless and connection oriented communication  Message switching  Cell switching (ATM); Telephone network signaling Network topologies  Layering the communication process  Open Systems Interconnection (OSI) model  Data encapsulation; Protocols  services and layering  PDU/SDU; TCP/IP suite  Hour-glass model  Internet Architecture and Protocol overview.  3. Media Access Control            06 Hrs. Introduction  Access Techniques (STDM  FDMA  TDMA  Spread Spectrum techniques and CDMA  DSSS  FHSS); Media Access Control: Aloha and Slotted Aloha  Media Access Control Address  Polling  CSMA  CSMA/CA  CSMA/CD and Reservation Aloha  Digital hierarchies [SONET/SDH]   4. Network Components            06 Hrs. Introduction  LAN Hardware  LAN Operating Systems  Transmission Media: Guided Media (Twisted pair  Co-axial cable  Optical fiber); Unguided Media (Radio  VHF  microwave  satellite  Infrared); Fiber Optics Communication Components (Source  Channel Detector. . 5. Link Control and MAC Protocols                05 Hrs. Framing  Error Detection and Correction; Window-based Flow Control; Logical Link Control  HDLC Protocol  Point-to-Point Protocol (PPP)  X.25 CCITT standard for packet data transmission; Media access control  Random Access Techniques  Scheduling Mechanisms.  6. Local Area Network (LAN)            05 Hrs. LAN topologies and protocols; IEEE 802 Standard; Ethernet (Standard  Fast  Gigabit)  Token Ring  FDDI  Wireless LANs (802.11x);  Connecting LANs: Repeaters  Bridges  Switches  Routers; Virtual LANs Lectures = 60 Practical/tutorials = 60 Total = 120 B Level Syllabus R4    138  7. Wide Area Network (WAN)                  08 Hrs. Network Layer Addressing and Routing concepts (Forwarding Function  Filtering Function); Routing Methods (Static and dynamic routing  Distributed routing  Hierarchical Routing); Distance Vector Protocol  Link State protocol  Open Shortest Path First (OSPF);  Internet Protocol (IP): Addressing & Routing; Internet Control Message Protocol  (ICMP)  Address Resolution Protocol (ARP)  Dynamic Host Control Protocol (DHCP)  Network Address Translation (NAT)  IPv6  Mobile IP  Process-to-Process delivery in Transport Layer: User Datagram Protocol (UDP)  Transmission Control Protocol (TCP)  congestion control  8. Application Protocols            08 Hrs. Client/Server Model  Network File System (NFS)  Remote Login: Telnet; File Transfer Protocol (FTP)  Trivial File Transfer Protocol (TFTP); E-mail system: Simple Mail Transfer Protocol (SMTP)  Post Office Protocol (POP); World Wide Web (WWW)  Domain Name System (DNS)  DNS servers; Hyper Text system: Hyper Text Transfer Protocol (HTTP)  Hyper Text markup Language (HTML)   9. Wireless Networks            03 Hrs. Radio Communications  Cellular Radio  Mobile Telephony (GSM & CDMA)  Satellite Networks (VSAT)  Mobile Adhoc Networks (MANET).   10. Security and Management            05 Hrs. Cryptography  IPsec  SSL/TLS  PGP  secure HTTP  proxy  firewall  VPN; Simple Network Management Protocol (SNMP)  Network policies. RECOMMENDED BOOKS  MAIN READING  1. Behrouz A  Forouzan  Data Communication and Networking   Tata McGraw-Hill  2008 2. William Stallings  Data and Computer Communications   Pearson Education  2008. 3. Rajneesh Agrawal and Bharat Bhushan Tiwari  Data Communication and Computer Networks  Vikas Publishing house Ltd.   2005. 4. Tomasi Wayne  Introduction to Data Communications and Networking  Pearson Education  2007. SUPPLEMENTARY READING  1. A. S. Tanenbaum  Computer Networks  Fourth Edition   Pearson Education. 2. A. Leon-Gracia and I. Widjaja  Communication Networks  Tata McGraw Hill  2004. 3. K. Pahlavan and P. Krishnamurthy  Principles of Wireless Networks  EEE/ Prentice Hall of India  2003.  B Level Syllabus R4    139  B2.4-R4: DATA COMMUNICATION AND NETWORK TECHNOLOGIES  Model Question Paper NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS TOTAL MARKS:  100 (PART ONE - 40; PART TWO - 60) PART ONE (Answer ALL Questions; each question carries ONE mark) 1. Each question below gives a multiple choices of answers. Choose the most appropriate one. 1.1 The physical layer most popularly used in wired LANs nowadays uses a) UTP cables b) STP cables c) Coaxial cables d) Radio Frequency 1.2 Seamless networking refers to a) A complete end-to-end digital network. b) Use of a single platform for end-to-end communication where geographical distance between communicating entities is hidden to the end user. c) Use of a single platform for end-to-end communication where geographical distance between communication entities is visible to the end user. d) Use of a single platform to transmit data  audio and video. 1.3 Router operates in a) Data Link Layer b) Network Layer c) Transport Layer d) All of the above 1.4 Flow control in OSI model is done by a) Data link layer b) Network layer c) Transport layer d) Both data link and transport layer  B Level Syllabus R4    140  1.5 Which of the following keeps track of the individual units of data (called packets) that a message is divided into for efficient routing through the Internet. a) Address Resolution Protocol (ARP) b) Internet Protocol (IP) c) Hypertext Transfer Protocol (HTTP) d) Transmission Control Protocol/Internet Protocol (TCP/IP) 1.6 A brute force attack against an encryption system: a) is known as RC4 b) is also known as 3DES c) tries to gain access by trying every possible key d) always uses the Rijndael algorithm 1.7 In FDDI  data normally travels on a) Primary ring b) Secondary ring c) Both rings d) Neither ring 1.8 In Cellular Mobile Communication handoff means a) to disturb the signal b) to disturb the antenna c) to switch to a new channel when call is in progress d) to switch off the MTSO 1.9 The _____ sublayer is responsible for the operation of the CSMA/CD access method and framing.  a) LLC  b) MII  c) MAC  d) None of the above 1.10 Light is confined within the core of a simple optical fiber by ________________. a) refraction b) total internal reflection at the outer edge of the cladding c) total internal reflection at the core cladding boundary d) reflection from the fiber's plastic coating 2. Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book 2.1. Executable files can be transmitted using SMTP. 2.2. RSA is a secret key encryption algorithm. 2.3. IPv6 uses 16 bit addresses. 2.4. The remote controls of TVs  VCRs and Stereo use Radio waves. 2.5. Ethernet uses variables sized packets to transmit data. 2.6. TCP/IP is the protocol suite for Internet. 2.7. Encryption and decryption are the functions of the presentation layer. 2.8. Coaxial cable provides data rates over 10 Mbps and frequencies upto 400 MHz. 2.9. Synchronous transmission is known as start/stop transmission. 2.10. UTP Category 3 can be used in Fast Ethernet networks. B Level Syllabus R4    141  3. Match words and phrases in column X with the nearest in meaning in column Y.  X Y  3.1  Release of message contents and traffic  analysis a) Attenuation   3.2  Provides a wireless link between a LAN hub  and a mobile data terminal equipped with an  antenna b) Active attacks  3.3 Gradual weakening of a signal over distance c) nomadic access  3.4 Go-back-N ARQ d) Trunks  3.5 Branches between exchanges e) Passive attacks:.  3.6 Connect dissimilar networks. f) SONET  3.7 Phase modulation g) TFTP  3.8  Fiber Optics technology for transmitting high- speed data h) sliding-window flow control  3.9 File transfer protocol i) angle modulation  3.10 Division of network into smaller networks j) router   k) SNMP   l) Spectrum   m) Subnetting  4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below:  (a) CDMA (b) PDU (c) FTP (d) Isotropic antenna  (e) Full-duplex       operation (f) Baud rate (g) Bandwidth (h) ICMP  (i) FTAM (j) Direct Sequence Spread Spectrum (k) Manchester (l) FIFO queueing  (m) Weighted fair queuing    4.1. __________________takes into account the amount of traffic through each queue and gives busier queues more capacity without completely shutting out less busy queues. 4.2. Standard Ethernet (10-Mbps) uses _______ encoding. 4.3. With_________________  a station can transmit and receive simultaneously 4.4. An______________________ is a point in space that radiates power in all directions equally. 4.5. With ______________________  each bit in the original signal is represented by multiple bits in the transmitted signal  using a spreading code. 4.6. ______________ allows multiple users to transmit over the same wireless channel using spread spectrum. 4.7. A ___________ is the combination of data from the next higher communications layer and control information. 4.8. _____________ is  the difference between highest and lowest frequencies of a composite signal. 4.9. _____________ is a reporting protocol for the IP addressing. 4.10. The ________________________ protocol is used to transfer   accessand manage files.  PART  TWO (Answer ANY FOUR questions) 5.  a. What is meant by simplex  half duplex and full duplex communication system? Give representative examples of each. B Level Syllabus R4    142  b. What is the purpose of cladding in an optical fiber? Discuss its density with respect to the core. c. Define forwarding function. Explain its significance with the help of suitable example. (5+5+5) 6.  a. Compare the IEEE standards 802.2  802.3  802.4  802.5 and 802.6 briefly. b. Explain the difference between pure ALOHA and slotted ALOHA and draw diagrams for them. c. What is high speed LANs? Describe briefly the various types of High-speed LANs used in computer communication networking. (5+5+5) 7.    a. What advantages does TCP have over UDP? What are the features  which make TCP a reliable protocol?   b.  What is static routing? How does it differ from dynamic routing? Discuss the   problem of count to infinity associated with distance vector routing technique. (7+8) 8.       a.  Compare and contrast three key long distance communication technologies       namely X.25  frame relay and ATM.            b.  Why is it important for protocols configured on the top of Ethernet to have a      length field in their header  indicating how long the message is? Discuss what kinds of problems arise when two computers on the same Ethernet share the same MAC (hardware) address.            c.   Routers  bridges and repeaters are used to connect differing networks.  Under  what circumstances would each of these technologies be used? (6+5+4) 9.        Write short notes on any three: a.   SNMP b.   VPN c.   SONET d.   Novell Netware (5+5+5) B Level Syllabus R4    143  B2.4-R4: DATA COMMUNICATION AND NETWORK TECHNOLOGIES  Assignment 1.   What is the load on simple ALOHA system in packet/sec  with a data rate of 9600 bps  packet size of 804 bits and G=0.75  {Where G is total rate of data presented to network for transmission or simply offered load}     Assignment 2.   Explain the steps involved in  computing the checksum for a given message frame: Data Polynomial D(x)  = 10011101010101100000 Generator polynomial G(x) =x4 + x3 + 1   Find the complete frame bit pattern for data  given above.  [Hint :  FCS will be 0101 ]    Assignment 3.  Explain the steps involved in computing the checksum for a given message frame Data Polynomial D(x)  = 11001010101 Generator polynomial G(x) =x4 + x3 + x + 1 Assignment 4.   A 1-km-long  10-Mbps CSMA/CD LAN (not 802.3) has a propagation speed of 200 m/sec. Repeaters are not allowed in this system. Data frames are 256 bits long  including 32 bits of header  checksum  and other overhead. The first bit slot after a successful transmission is reserved for the receiver to capture the channel in order to send a 32-bit acknowledgement frame. What is the effective data rate  excluding overhead  assuming that there are no collisions? Assignment 5.   Calculate the baud rate for given bit rate and type of modulation  a) 2000 bps  4-PSK b) 4000 bps  8-PSK c) 4000 bps  4-QAM Assignment 6.   Calculate the bit rate for given baud rate and type of modulation a) 2000 baud  ASK b) 1000 baud  8 PSK c) 1000 baud  16 QAM Assignment 7.  How many amplitude levels are there for each of the following methods  a) unipolar b) NRZ-L c) NRZ-I d) Manchester Assignment 8. B Level Syllabus R4    144  Show the signal diagram (time domain graph) using following methods  for the data stream  1 0 0 1 0 1 1 0  a) RZ b) NRZ-L c) NRZ-I d) Differential Manchester Assignment 9.  Show the signal diagram (time domain graph) using following methods  for the data stream  1 1 0 1 0 0 0 1 1 0  a) QAM b) 4-PSK c) PSK d) Bipolar AMI Assignment 10.   What is the maximum data rate  for a typical telephone line with a signal-to-noise ratio of 30dB and an audio bandwidth of 3kHz? Assignment 11.   A line has signal-to-noise ratio of 1000 and a bandwidth of 4000 kHz. What is the maximum data rate supported by this line? Assignment 12.   A digital signal has a bit rate of 2000 bps. What is duration of each bit (bit interval)?  Assignment 13.   What is the minimum interval that retransmit timer can be set at  given the channel transmission capability of 20kb/s and propagation delay of 2ms.  Assignment 14.   Explain why channel efficiency of message switching is greater than circuit switching?  Assignment 15.  Configure the PC with first useable class C private IP address and subnet mask.  Assignment 16.  Write a program to simulate slotted controlled ALOHA. Each station should monitor the channel load and increment its value of  by X percent whenever G < 1 and decrement it by the same amount if G > 1. Assume negligible propagation delay. Examine how value of X affects system performance.   Assignment 17.  B Level Syllabus R4    145  Write a program to simulate routing using flooding. Each packet should contain a counter that is decremented on each hop. When the counter gets to zero  the packet is discarded. Time is discrete  with each line handling one packet per time interval. Make three versions of the program:   a) all lines are flooded b) all lines except the input line are flooded  c) only (statically chosen) best k lines flooded. Compare flooding with deterministic routing (k=1) in terms of delay bandwidth used.  Assignment 18.  A channel has a bit rate of 4 kbps and a propagation delay of 40msec. For what range of frame sizes does stop-and-wait give an efficiency of at least 60%? Assignment 19.  Identify the OSI layer in which the following protocols work: NFS  ICMP  NAT  PPP  X.25  SMTP  SSL  SONET Assignment 20.   Give the port number on which the following protocols work. TFTP  FTP  SMTP  DNS  DHCP  ICMP. Assignment 21.   Decrypt the following message which was encrypted using shifted alphabet cipher   f(a) = (a + 4)  mod 26  X L M W T V S F P I Q K E Z I Q I E L I E H E G L I   Assignment 22.  Write a program to break monoalphabetic substitution ciphers consisting of English prose (uppercase letters only). The program should compute single letter  digram  trigram frequencies of ciphertext  make guesses about which letter is which  and see if they lead to reasonable plaintext digrams and trigrams. The program should output the plaintext.  Assignment 23.  Configure the topology (given below) to establish a peer-to-peer network. Assignment 24.   Configure the topology (given below) to establish a switch-based network. After configuring the IP address and suitable subnet mask  ping PC1 to PC0 B Level Syllabus R4    146  Assignment 25.   Configure the topology (given below) to establish a network. After configuring the IP address and suitable subnet mask  ping PC1 to PC3 B Level Syllabus R4    147  B25.1-R4: INTRODUCTION TO OBJECT ORIENTED PROGRAMMING THROUGH JAVA. Objective of the Course  The course is designed to impart knowledge and develop skills required to solve real world problems using object oriented approach  Java Language constructs and Unified Modelling Language. This course covers the subject in 3 sections  viz  Introductions to Object Oriented Programming  Introduction to Java Programming Language  Introduction to UML.  After the completion of the course the student is expected to understand:   Basics of Object Oriented Programming.   Various Object Oriented programming concepts - Abstraction  Objects and       Classes  Inheritance  Polymorphism.  Basic data structures in Java  Objects and Classes   Super Class  sub-class  Interfaces  Inner classes.  GUI programming using AWT/Swing.   Deploying Java Applications.   Accessing Databases in Java.  What is unified Modeling Language and Why is it used.   Using Class  Interface  Interaction  State and Activity  Physical diagrams in             modeling software.   Outline of Course  S. No.   Topic Minimum number of hours 1. Introduction to Object Oriented Programming 14 2. Introduction to Java programming Language. 32 3. Introduction to UML. 14      Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. Introduction to Object Oriented Programming                                       14 Hrs.   1) Thinking Object-Oriented (1 Hr.)                Why Is OOP Popular? A New Paradigm   A Way of Viewing the World.                Why Is OOP Popular? A New Paradigm   A Way of Viewing the World.  2) Abstraction (1 Hr.)   Layers of Abstraction  Other Forms of Abstraction.  3) Classes and Methods  (1 Hr.)   Encapsulation  Class Definitions  Methods.  B Level Syllabus R4    148  4) Messages  Instances  and Initialization (2 Hrs.)   Message-Passing Syntax  Statically and Dynamically Typed Languages  Accessing the Receiver from Within a Method  Object Creation  Pointers and Memory Allocation  Constructors{Constant Values}  Destructors and Finalizers.  5) Inheritance and Substitution (3 Hrs.)   An Intuitive Description of Inheritance  Inheritance in Various Languages  [Subclass  Subtype  and Substitution]  Overriding and Virtual Methods  Interfaces and Abstract Classes  Forms of Inheritance  The Benefits of Inheritance  The Costs of Inheritance. Examples (Language independent)  6) Static and Dynamic Behavior (1 Hr.)   Static versus Dynamic Typing  Static and Dynamic Classes  Static versus Dynamic Method Binding.   7) Multiple Inheritance  (1 Hr.)   Inheritance as Categorization  Problems Arising from Multiple Inheritance  Inner Classes.   8) Polymorphism and Software Reuse  (1 Hr.)   Polymorphism in Programming Languages  Mechanisms for Software Reuse  Efficiency and Polymorphism  Will Widespread Software Reuse Become Reality?  9) Overloading and Overriding (3 Hrs.)   Type Signatures and Scopes  Overloading Based on Scopes  Overloading Based on Type Signatures  Redefinition  Notating Overriding  Replacement versus Refinement  Deferred Methods  Overriding versus Shadowing  Covariance and Contra variance.  2) Introduction to Java Programming Language              32 Hrs.  1) An Introduction to Java (1 Hr.)   Java as a Programming Platform  The Java ""White Paper"" Buzzwords  Java and the Internet  A Short History of Java  Common Misconceptions About Java.  2) The Java Programming Environment (1 Hr.)   Installing the Java Development Kit  Choosing a Development Environment  Using the Command-Line Tools  Using an Integrated Development Environment  Compiling and Running Programs from a Text Editor  Running a Graphical Application  Building and Running Applets.  3) Fundamental Programming Structures in Java (2 Hrs.)   A Simple Java Program  Comments  Data Types  Variables  Operators  Strings  Input and Output  Control Flow  Big Numbers  Arrays.  4) Objects and Classes  (2 Hrs.)   Introduction to Object-Oriented Programming  Using Predefined Classes  Defining Your Own Classes  Static Fields and Methods  Method Parameters  Object Construction  Packages  Documentation Comments  Class Design Hints.  B Level Syllabus R4    149  5) Inheritance  (2 Hrs.)   Classes  Superclasses  and Subclasses  Object: The Cosmic Superclass  Generic ArrayLists  Object Wrappers and Autoboxing  Reflection  Enumeration Classes  Design Hints for Inheritance.  6) Interfaces and Inner Classes  (2 Hrs.)            Interfaces  Object Cloning  Interfaces and Callbacks  Inner Classes  Proxies.   7) Introduction to GUI  (2 Hrs.)   AWT Architecture  Light-Weight vs Heavy-Weight  AWT Event Model  AWT Event Hierarchy & Event Handling  Using Top-Levels  components and containers  Introduction to Layouts  Focus Architecture.  8) Graphics Programming (4 Hrs.)   Java2D Rendering Model  Strokes & Fills  Geometries  Fonts and Text Layout  Transformations  Display and manipulation of Images and offscreen buffers  Using Color  Printing through Java  Doing More with Images using Image IO  Hardware Acceleration and Active Rendering techniques.  9) User Interface Components with Swing (4 Hrs.)   The Model-View-Controller Design Pattern  Introduction to Layout Management  Text Input  Choice Components  Menus  Sophisticated Layout Management  Dialog Boxes.  10) Deploying Applets and Applications  (2 Hrs.)   Applet Basics  The Applet HTML Tags and Attributes  Multimedia  The Applet Context  JAR Files  Application Packaging  Java Web Start  Storage of Application Preferences.  11) Exceptions and Debugging (2 Hrs.)   Dealing with Errors  Catching Exceptions  Tips for Using Exceptions  Logging  Using Assertions  Debugging Techniques  Using a Debugger.  12) Streams and Files  (3 Hrs.)   The Complete Stream Zoo  ZIP File Streams  Use of Streams  Object Streams  File Management  New I/O  Regular Expressions.   13) Database Programming (5 Hrs.)   The Design of JDBC  The Structured Query Language  JDBC Installation  Basic JDBC Programming Concepts  Query Execution  Scrollable and Updatable Result Sets  Metadata  Row Sets  Transactions  Advanced Connection Management  Introduction to LDAP.  3) Introduction to UML                     14 Hrs.  1) Introduction  An outline Development Process and Use cases      (2 Hrs.)   What Is the UML?  How We Got Here  Notations and Meta-Models  Why Do Analysis and Design?   Overview of the Process  Inception  B Level Syllabus R4    150  Elaboration  Planning the Construction Phase  Construction  Transition  When to Use Iterative Development  Use Case Diagrams  Business and System Use Cases  When to Use Cases.  2) Class Diagrams and Advance Concepts  (4 Hrs.)   Perspectives  Associations  Attributes  Operations  Generalization  Constraint Rules  When to Use Class Diagrams  Stereotypes  Object Diagram  Class Scope Operations and Attributes  Multiple and Dynamic Classification  Aggregation and Composition  Derived Associations and Attributes  Interfaces and Abstract Classes  Reference Objects and Value Objects  Collections for Multivalued Association Ends  Frozen  Classification and Generalization  Qualified Associations  Association Class  Parameterized Class  Visibility.   3) Interaction Diagrams  Packages and Collaborations                (1 Hr.)   Sequence Diagrams  Collaboration Diagrams  Comparing Sequence and Collaboration Diagrams  When to Use Interaction Diagrams  Packages  Collaborations  When to Use Package Diagrams and Collaborations.  4) State and Activity Diagrams     (1 Hr.)   Concurrent State Diagrams  When to Use State Diagrams  Decomposing an Activity  Dynamic Concurrency  Swimlanes  When to Use Activity Diagrams.          5) Physical Diagrams          (1 Hr.)   Deployment Diagrams  Component Diagrams  Combining Component and Deployment Diagrams  When to Use Physical Diagrams.           6) Case Studies         (5 Hrs.)   RECOMMENDED BOOKS  MAIN READING  1. Timothy Budo  An Introduction to Object-Oriented Programming with Java  Pearson Education  2009.  2. Martin Fowler UML Distilled: A Brief Guide to the Standard Object Modeling       Language  3rd Edition  Pearson Education  2009. SUPPLEMENTARY READING  1. H. Schildt  The Complete Reference -Java2  Tata McGraw-Hill   2008. 2.  P. J Dietel and H. M Dietel  Java  How to Program  7th Edition  Pearson Education  2008.   3. Grady Booch  James Rumbaugh  Ivar Jacobson  Unified Modeling Language User      Guide  2nd Edition  Pearson Education  2009. 4. Wu C Thomas  Introduction to Object Oriented Programming with Java  4th Edition  Tata McGraw-Hill  2008. 5. Balaguruswamy E  Programming with Java  Tata McGraw-Hill  2007. 6. Muthu C  Essentials of Java Programming  2008  Tata McGraw-Hill  2007. 7. Bhave M.P  Patekar S.A  Programming with Java  Pearson Education   2009. 8. Khurana  Rohit   Object Oriented Programming with C++   Vikas Publishing House.   B Level Syllabus R4    151  B25.1-R4: INTRODUCTION TO OBJECT ORIENTED PROGRAMMING THROUGH JAVA Model Question Paper  NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 HOURS                                         TOTAL MARKS: 100                     (PART ONE-40; PART TWO-60)   PART ONE  (Answer ALL Questions; each question carries ONE mark) 1. Each question below gives a multiple choices of answers. Choose the most appropriate one. 1.1.  A type of use case relationship that adds new behavior or actions is a(n): e) generalized relationship  f) extend relationship g) recursive relationship h) abstract relationship 1.2. The technique of hiding internal implementation details of an object best describes:  a) incorporation b) polymorphism c) encapsulation d) generalization. 1.3. Activity diagrams can be used to show a) how objects are activated b) how all the users can interact c) multithread processing d) how use cases fit together to achieve business level process 1.4.  Which of the following show the static structure of data and operations those act on   the data? a) use cases   b) class diagram c) state diagram d) sequence diagram 1.5. class ExceptionTest{   public static void main( String sz[] ){ B Level Syllabus R4    152     try{     int iA = 0;     int iB = 50 / iA;     }    catch(Exception e){     System.out.print(I am always here);    }    catch(ArithmeticException e){     System.out.print(Am I on Output ever???...);    }   }  }    What will be the output for the code above? a) I am always here.Am I on Output ever???... b) Error c) I am always here. d) Am I on Output ever???... 1.6. Which Exception is thrown by the read( ) method of InputStream class?  a) Exception b) FileNotFoundException c) ReadException d) IOException 1.7. Which of the statement below does not correctly defines the difference between JDBC and ODBC ? a) ODBC can be directly used with Java because it uses a C interface b) ODBC makes uses of pointers which has been totally removed from JAVA c) ODBC is from Microsoft while JDBC is from java applications d) ODBC requires manual installation of the ODBC driver manager and driver on all client machines. While for JDBC drivers are written in Java and JDBC code is automatically installable  secure and portable on all platforms. 1.8. Given the following code  import java.awt.*; public class SetF extends Frame{ public static void main(String argv[]){  SetF s=new SetF();  s.setSize(300 200);  s.setVisible(true);  } } How could you set the frame surface color to pink?  a) s.setBackground(Color.pink); b) s.setColor(PINK); c) s.Background(pink);  d) s.color=Color.pink 1.9.  Which of the following applet tag is legal to embed an applet class named Test into a webpage?  a)  < /applet >  b)  < /applet > c) < /applet >  d)   code = Test.class  width = 200  height = 200 < /applet >B Level Syllabus R4    153  1.10. State diagrams are being drawn to a) show how objects move between classes  b) find missing use cases c) show how an object responds to messages d) show how classes change state over time 2. Each statement below is either TRUE or FALSE.   Identify and mark them accordingly in the answer book. 2.11 A concrete class or an abstract class can only be a parent class. 2.12 Extension is applied to subclass while restriction is applied to superclass.  2.13 Traversing an association is an operation that yields related objects. 2.14 Computing the derived object may change the state of the object. 2.15 The % (modulo) operator can be used with floating point operands. 2.16 A static method can be invoked by simply using the name of the method alone. 2.17 Objects are passed to a method by use of call-by-value. 2.18 Abstract class can be a final class. 2.19 Interface can Inherit one or more Interfaces. 2.20 Font[] getAllFonts( ) returns an array of Font objects for all selected fonts.  3. Match words and phrases in column X with the nearest in meaning in column Y.  X  Y 3.1 Abstraction a) Can be done using Object.Method(Information)prototype. 3.2 Encapsulation b) a-part-of relationship 3.3 Message Passing c) Action 3.4 Runtime Polymorphism  d) isa relationship 3.5 destructor e) This information provides us the direction of inheritance 3.6 Aggregation f) This information will guide us in designing classes 3.7 Actors g) Normal objects 3.8 Association h) Functions are automatically called when derived class object gets destroyed 3.9 Generalization i) Dynamic Binding 3.10 Event j) Is a way to provide transparent access to Essential Details    k) Explicit objects   l) Can be related to Data Hiding in programming.    4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below: (a) event (b) data store (c) object-Code (d) state (e) integer (f) deployment (g) default (h) polymorphism (i) boolean (j) public (k) link (l) finalize () (m) association (n) byte-Code (o) object class 4.11 In dynamic model ___________ represent interval of time. 4.12 A (n) __________ describe a group of links with common semantics and are inherently bidirectional. B Level Syllabus R4    154  4.13 UML ______ diagram shows where components of distributed system are located. 4.14 __________ is a passive object within a data flow diagram that stores data for later access. 4.15 ________ is the cosmic super class. 4.16 Java compiler produces an intermediate code which is known as ________. 4.17 _________method in java is same as destructor method in c++. 4.18 __________ means the ability that one thing can take several different forms. 4.19 ________ is the data type returned by all relational operators. 4.20 _________ is the default access specifier for class members in Java. PART TWO (Answer any FOUR questions) 5.  a. Mention in brief four aspects of Object Oriented Design and Programming. b. Encapsulation protects the abstractions. Justify the statement. c. How can encapsulation and polymorphism improve reusability? d. What are the challenges in designing with inheritance (single/multiple both)? e. What is UML? What it is not? What is the importance of UML?                            (4+4+4+3+3) 6.  a. A more flexible way to do it is to write a wrapper JDBC Driver that is an intermediary between the client application and database. Explain how to write a wrapper JDBC Driver class. b. Explain the significant language features of java. c. Which are the Similarities and Differences between java and C++?                                                                 (10+4+4) 7. a. Write a short note on java access specifiers with examples.  b. Packages and interfaces form a very important concept in Java. Which are the advantages and disadvantages of package and interface? c. The Java 2D API provides two-dimensional graphics  text  and imaging capabilities for Java programs through extensions to the Abstract Windowing Toolkit (AWT). List the capabilities of Java 2D API. d. The Pattern class defines an alternate compile method that accepts a set of flags affecting the way the pattern is matched. Explain any four flags of Pattern class.                                                                                                  (4+6+4+4) 8. a. The Java language supports special ""doc comments"". Explain Java Documentation Comment Syntax. b. Various commands are available in Java Development Kit those can be used to enhance java programming. How various options of javac command can be used in java programming? c. Differentiate between Frozen v/s Read only object  Fork and Join and give example of the same.  d. What are the uses of multiple classification and dynamic classification? How it differs from classification and generalization?                                                                                                                             (4+4+5+5) 9.  a. What does state chart diagram document? b. Explain Aggregation & Composition with suitable example. c. How to reduce interface of a package? d. What do you mean by node? How do you represent it? In which diagram this concept is there? e. What is the role of a template?                           (5+4+4+3+2) B Level Syllabus R4    155  B25.1-R4: INTRODUCTION TO OBJECT ORIENTED PROGRAMMING THROUGH JAVA  Assignment 1.   Write a program that can create a concordance ( A concordance lists every word that occurs in the document  and for each word it gives the line number of every line in the document where the word occurs ).The document should be read from an input file  and the concordance data should be written to an output file. The names of the input file and output file should be specified as command line arguments when the program is run. Assignment 2.   Open a text file so that you can read the file one line at a time. Read each line as a String and place that String object into a LinkedList. Print all of the lines in the LinkedList in reverse order.  Assignment 3.   Write a Java Program to create three new types of exceptions. Write a class with a method that throws all three. In main( )  call the method but only use a single catch clause that will catch all three types of exceptions.  Assignment 4.   Design a Calculator using Java Applet/Swing. The display should have all the digit buttons along with buttons for operations + - *  / and =. There is a designated panel to show the current results. If a digit button is clicked  the number is displayed on the panel. If an operator button is clicked the operation is to be performed. The calculator can operate in two modes. a.  When  the operator buttons are pressed the intermediate results should be displayed. b.  The operations can take in any number of arguments and the final result is displayed only when the = button is pressed.  Assignment 5.   Write an applet with a JTextArea where the user can enter some text. The applet should have a button. When the user clicks on the button  the applet should count the number of lines in the user's input  the number of words in the user's input  and the number of B Level Syllabus R4    156  characters in the user's input. This information should be displayed on three labels in the applet. Assignment 6.   Write a Java Program to create three interfaces  each with two methods. Inherit a new interface from the three  adding a new method. Create a class by implementing the new interface and also inheriting from a concrete class. Now write four methods  each of which takes one of the four interfaces as an argument. In main( )  create an object of your class and pass it to each of the methods.   Assignment 7.   Create an image from an Array of Color-Indexed Pixel Values in the byte buffer. A 16-color index color model is used to represent the pixel colors.   Assignment 8.   Write a Java Program to find all the strings that match a given Regular Expression in one or more files or other sources. Assignment 9.   Write a little applet that lets the user draw polygons. As the user clicks a sequence of points  count them and store their x- and y-coordinates in two arrays. These points will be the vertices of the polygon. Also  draw a line between each consecutive pair of points to give the user some visual feedback. When the user clicks near the starting point  draw the complete polygon. Draw it with a red interior and a black border. The user should then be able to start drawing a new polygon. When the user shift-clicks on the applet  clear it. Assignment 10.   Write a Java Program to read from or write to a particular location in a file  such as an indexed file. Assignment 11.   B Level Syllabus R4    157  Assume that a bank maintains two kinds of accounts for customers  one called as savings account and the other as current account. The savings account provides compound interest and withdrawal facilities but no cheque book facility. The current account provides cheque book facility but no interest. Current account holders should also maintain a minimum balance and if the balance falls below this level  a service charge is imposed. Create a class account that stores customer name  account number and type of account. From this derive the classes cur_acct and sav_acct to make them more specific to their requirements. Include necessary functions in order to achieve the following tasks: a) Accept deposit from a customer and update the balance. b) Display the balance. c) Compute and deposit interest. d) Permit withdrawal and update the balance. e)     Check for the minimum balance  impose penalty  necessary  and update       the balance.  Assignment 12.   A hospital wants to create a database regarding its indoor patients. The information to stores include a) Name of the patient b) Date pf admission c) Disease d) Date of discharge Create a base class to store the above information. The base class should include functions to enter information and display a list of all the patients in the database. Create a derived class to store the age of the patients. Write a code to list the information about all the pediatric patients (less than 12 years in age). Assignment 13.   B Level Syllabus R4    158  Create the following form using java applet/Swing and the text in textbox should be formatted as per the selections: Assignment 14.  Create table with the following structure:  Userid  Character 10 Password Character 10 Primary Key-Userid  Now design a login form(connected to database using jdbc) and show a welcome message if userid and password combination is correct  otherwise display an error message. Assignment 15.   The Indian Airlines has launched a fast transportation service  using their supersonic passenger airplanes. You are hired by the Indian Airlines for maintaining their database. It contains only a single table  called Route  which holds all pairs of cities with a directed     LOGIN     User ID   :   Password :     SUBMIT CANCEL B Level Syllabus R4    159  connection  the distance between them  and the type of aircraft used for that trip. An example table is given below: FromCity  ToCity  Distance (km)  Airplane  Chandigarh N.delhi 265 IA300  Mumbai  Goa 165  IA200  Mumbai Pune 153  IA100          Your program should assume that the table already exists in the database and contains data. The structure of the command line to run your program is as follows: Java IA Supersonic < queryType >< queryVariable > [toTable]   Your program should ask the user for login and password  and connect right after to the database  based on the given information.  < queryType > is one of the following:  a) toCity:output all services that go to the city specified in   b) fromCity:output all services that go from the city specified in   c) airplane: output all services that use airplane specified in   [toTable] is an optional parameter  the user may dump the query result to toTable by stating toTable as an argument  or not specify a 3rd argument at all. In the latter case  the output should be inserted to a table called IA Result. In case that it does not exist  IA Result should be created by the program  with the same columns as Route. Otherwise  the existing data should be deleted  and the query result should be inserted. Assignment 16.   Create an application that creates a ball which bounces with the help of thread in Graphics.  Assignment 17.   Create a layout prototype of Ms-Paint in Java swing using menus and layout management. You can also add functionality to some of the menu item/toolbar items. B Level Syllabus R4    160  Assignment 18.   Write a program using inheritance that should be able to draw a circle  Ellipse  square  rectangle  parallelogram and a rhombus when relevant dimensions are read in e.g. a circle can be drawn when the centre and the radius is read in  and ellipse can be drawn when the major and minor axis lengths along with the centre is given  a rectangle can be drawn with two sides given and so on.   Assignment 19.   Write a java program to draw a Mandelbrot  which is a collection of points in the plane whose boundary forms a fractal. Assignment 20.   Draw  use case diagram for the parking ticket payment system .The information for the system is given below:  a) Patrol Officer enters ticket information. (ticket status = unpaid)  b) Ticket Holder views her ticket by ticket number. (ticket  status = unpaid)  c) Ticket Holder pays for ticket by entering her credit card information. (ticket status = in process)  d) Office Staff views all tickets whose status is in process to retrieve payment credit card information for each ticket.  (ticket status = in process)  e) Office Staff does credit card payment transactions manually.  (ticket status = in process)  f) Office Staff change ticket status for each successful payment. (ticket status = paid) Assignment 21.   B Level Syllabus R4    161  The following is a partial taxonomy of rotating electrical machines.  Electrical machines may be categorized for analysis purposes into alternating current (ac) or direct current (dc).   Some machines run on ac  some on dc  and some will run on either.  An ac machine may be synchronous or induction.  A few examples of electrical machines include large synchronous motors  small induction motors  universal motors  and permanent magnet motors.  Most motors found in the homes are usually induction machines or universal motors.  Universal motors are typically used in where high speed is needed such as in blenders or vacuum cleaners.  They will run on either AC or DC.  Permanent magnet motors are frequently used in toys and will work only on dc.   Prepare an object diagram showing how the categories and the machines just described relate to one another.  Use multiple inheritance where it is appropriate to do so.  Assignment 22.   Prepare a class  diagram from the instance diagram in the following figure:       Mate       child     child  sibling   Assignment 23.   The direction control for some of the first toy electric trains was accomplished by interrupting the power to the train.  Prepare state diagrams for the headlight and wheels of the train  corresponding to the following scenario:  Power is off  train is not moving. Power is turned on  train moves forward and train headlight shines. Power in turned off  train stops and headlight goes out. Power is turned on  headlight shines and train does not move. Power is turned off  headlight goes out. Power is turned on  train runs backward with its headlight shining. Power is turned off  train stops and headlight goes out. Power is turned on  headlight shines and train does not move. Power is turned off  headlight goes out. Power is turned on  train runs forward with its headlight shining. (Person) a grandmother (Person) a grandfather (Person) An aunt (Person) a cousin (Person) Your father (Person) Your mother (Person) You child mate cousin child child B Level Syllabus R4    162  Assignment 24.   A simple digital watch has a display and two buttons to set it  the A button and the B button.  The watch has two modes of operation  display time and set time.  In the display time mode  hours and minutes are displayed  separated by a flashing colon.  The set time mode has two sub-modes  set hours and set minutes.  The A button is used to select modes.  Each time it is pressed  the mode advances in the sequence: display  set hours  set minutes  display  etc.  Within the sub-modes  the B button is used to advance the hours or minutes once each time it is pressed.  Buttons must be released before they can generate another event.  Prepare a state diagram of the watch.  Assignment 25.   Some combined bath-showers have two faucets and a lever for controlling the flow of the water.  The lever controls whether the water flows from the showerhead or directly into the tub.  When the water is first turned on  it flows directly into the tub.  When the lever is pulled  a valve closes and latches  diverting the flow of water to the showerhead.  To switch from shower to bath with the water running  one must push the lever.  Shutting off the water releases the lever so that the next time the water is turned on  it flows directly into the tub.  Write a scenario for a shower that is interrupted by a telephone call. B Level Syllabus R4    163  B25.2-R4: SOFTWARE TESTING AND QUALITY MANAGEMENT  Objective of the Course  This objective of the course is to make students aware about the importance of the software testing during software development. The course covered to be in line with the development tools and languages taught in this level. The course will prepare the student for software testing and debugging. It will further laid the foundation for advanced courses in Software quality assurances.  Outline of Course  S. No.   Topic Minimum number of hours 1. Introduction  02 2. Importance of Software Testing 04 3. Testing Techniques and Strategy 10 4. Verification and Validation 06 5. Building Test Cases and Plans 20 6. Quality Assurance and Standards 10 7. Debugging Technique and Tools 04 8. External Source of Errors 04 Lectures = 60 Practical/tutorials = 60 Total = 120 Detailed Syllabus  1. Introduction                  02 Hrs. Software program and its objective  Software development techniques  top-down verses bottom-up approach  modular and structures programming. A brief introduction about object oriented approach.  2. Importance of Software Testing                04 Hrs. Software testing and its importance  software development life cycle verses software testing life cycle  Deliverables  version and error control   3. Testing Techniques and Strategy               10 Hrs. Unit testing  Integration testing  System testing  Acceptance testing White-Box testing: Flow Graph notation  Cyclomatic Complexity  Graph matrices  control structure and loop testing.  Black-Box testing: Equivalence partitioning  Boundary Value Analysis  Orthogonal Array testing.  4. Verification and Validation                06 Hrs. Requirement verification  Coding standards  Walk through  Formal Inspection  Design validation and verification  Function test  Design metrics  correctness proof and its requirement.   5. Building Test Cases and Plans                20 Hrs. Format of test cases  Du  dc and other data paths  Test data selection  branch coverage  statement coverage  pre-condition and post-condition  Test schedule and check pointing  suitable exercises for creating test cases for each type of techniques mentioned in para 3.  B Level Syllabus R4    164  6. Quality Assurance and Standards                           10 Hrs. Basic software quality parameters and its metrics  Software Configuration Change and types of errors  Quality management models: ISO  SPICE  IEEE  CMM  7. Debugging Technique and Tools                04 Hrs. Integrated development environment  debugging  tracing  data inspection  exception errors  code and data redundancy  unreachable code.   8. External Source of Errors                 04 Hrs. Main memory  conflicting dll and unknown interface as source of error and their rectification. Note: Any open-source Software Tools may be utilized  such as winrunner.  RECOMMENDED BOOKS  MAIN READING  1. Desikan S  Ramesh G  Software Testing  Pearson Education  2008. 2. Tamres L  Introducing Software Testing  Pearson Education  2007. 3. Dustin E  Effective Software Testing  Pearson Education  2007. 4. Mathur A.P  Fundamentals of Software Testing  Pearson Education  2008. SUPPLEMENTARY READING  1. Brian Marick  The Craft of Software Testing  Pearson Education  2008. 2. Rajani & Oak  Software Testing : Methodology  Tools and Processes Tata McGraw-Hill  2007. 3. R. Pressman  Software Engineering  6th Edition  Tata McGraw-Hill. B Level Syllabus R4    165  B25.2-R4: SOFTWARE TESTING AND QUALITY MANAGEMENT  Model Question Paper NOTE: 1. There are TWO PARTS in this Module/Paper.  PART ONE contains FOUR questions and PART TWO contains FIVE questions.  2. PART ONE is to be answered in the TEAR-OFF ANSWER SHEET only  attached to the question paper  as per the instructions contained therein.  PART ONE is NOT to be answered in the answer book. 3. Maximum time allotted for PART ONE is ONE HOUR.  Answer book for PART TWO will be supplied at the table when the answer sheet for PART ONE is returned.  However  candidates  who complete PART ONE earlier than one hour  can collect the answer book for PART TWO immediately after handing over the answer sheet for PART ONE. TOTAL TIME: 3 Hours               TOTAL MARKS: 100               (PART ONE -40; PART TWO-60)   PART ONE (Answer ALL Questions; each question carries ONE mark) 1. Each question below gives a multiple choices of answers. Chose the most appropriate one. 1.1 Verification is:  a) Checking that we are building the right system b) Checking that we are building the system right c) Performed by an independent test team d) Making sure that it is what the user really wants 1.2 A regression test: a) Will always be automated b) Will help ensure unchanged areas of the software have not been affected c) Will help ensure changed areas of the software have not been affected d) Can only be run during user acceptance testing 1.3 Which of the following could be a reason for a failure 1) Testing fault 2) Software fault 3) Design fault 4) Environment Fault 5) Documentation Fault    a) 2 is a valid reason; 1 3 4 & 5 are not b) 1 2 3 4 are valid reasons; 5 is not c) 1 2 3 are valid reasons; 4 & 5 are not d) All of them are valid reasons for failure 1.4 Test is prioritized so that:  a) you shorten the time required for testing b) You do the best testing in the time available c) You do more effective testing d) You find more faults B Level Syllabus R4    166  1.5 Which of the following is not a static testing technique  a) Error guessing b) Walkthrough c) Data flow analysis d) Inspections 1.6 During which test activity could faults be found most cost effectively?  a) Execution b) Design c) Planning d) Check Exit criteria completion 1.7 The purpose of requirement phase is  a) To freeze requirements b) To understand user needs c) To define the scope of testing d) All of the above 1.8 The process starting with the terminal modules is called - a) Top-down integration b) Bottom-up integration c) None of the above d) Module integration 1.9 The inputs for developing a test plan are taken from  a) Project plan b) Business plan c) Support plan d) None of the above 1.10  Inspections can find all the following except  a) Variables not defined in the code b) Spelling and grammar faults in the documents c) Requirements that have been omitted from the design documents d) How much of the code has been covered 2. Each statement below is either TRUE or False. Identify and mark them accordingly in the answer book.                                                                                                                                  2.1 In information technology  we often build products requirements/specifications which although documented not true quality needs of our customers. 2.2 Our products must be corrected so that they will eventually meet our customers' true quality needs.  2.3 Can produce products at our convenience and at any cost 2.4 Quality is not an attribute of product 2.5 Quality is not a binary state 2.6 Quality need not be defined in quantitative terms in order to be measurable. 2.7 Quality can be controlled only if it is measured. 2.8 Non conformance must be detected as early as possible measured. 2.9 High defect prone products and processes are identified testing the product after all processes are over. 2.10   0% of all defects are attributable to incorrect ineffective processes.   3.      Match words and phrases in column X with the nearest in meaning in column Y   B Level Syllabus R4    167  X Y  3.1 A process of selecting test cases/data by identifying the boundaries that separate valid and invalid conditions a) Quality Assurance  3.2 It is based upon graphical representation of the program process b) Software Configuration  3.3 The input domain of the system is partitioned into classes of representative values  so that the no of test cases can be limited to one-per-class  which represents the minimum no. of test cases that must be executed. c) CMM-Managed  3.4 A planned and systematic set of activities necessary to provide adequate confidence that requirements are properly established and products or services conform to specified requirements d) Data flow modeling  3.5 Foundation for continuing improvement and optimization of process e) Boundary value    Analysis  3.6 The nodes represent the data objects. The links represent the transformations that occur to translate one data object to another. f) Equivalence testing  3.7 Computer programs (source code and executables)  documentation (technical and user)  data (internal and external to programs)   g) Unit Testing  3.8 Brainstorming meeting  whose goal is to identify the problem  propose elements of a solution  negotiate different approaches  and specify a preliminary set of solution requirements h) Black Box  3.9 Iis the process of testing each software component individually using stubs and/or drivers. i) Control Flow Analysis  3.10 A technique in which the input domain is divided into classes of equivalent data items j) Facilitated application specification technique (FAST). 4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below:           (a) Quality control (b) Design  (c) Management cycle (d14  (e) Customer (f)  Acceptable quality level (g) Test tools (h) implementation and test  (i) White box (j) optimising process    4.1 For quality to happen  there must be well-defined standards and procedures which are followed 4.2 Quality means fit for use. This is ________________view. 4.3 The no of principles in Dr. W. Edwards Deming's quality principles is ____________. 4.4 The other name PDCA referred to  is _________. 4.5 With the__________  the data is available to justify the application of technology to various critical tasks  and numerical evidence is available on the effectiveness with which the process has been applied to any given product 4.6 If changes are not controlled  then orderly _________________ is impossible and B Level Syllabus R4    168  no quality plan can be effective.  4.7 AQL stands for_________________. 4.8 Is a vehicle for performing a test process________________. 4.9 The process by which product quality is compared with applicable standards; and the action taken when nonconformance is detected is called _________________. 4.10 cyclomatic Complexity method  is one of the method  of __________________Testing.  PART TWO (Answer ANY FOUR questions) 5. a. How does software differ from the artifacts produced by other engineering disciplines? b.  How do software process metrics differ from software project metrics? c. What is meant by the term software reliability? (5+5+5)  6. a. What  are the  names of the five levels of  the SEI  Capability  Maturity Model?  In your own words  briefly describe each. b. Describe the change control process for a modern software development project.                                                                                                                                       (10+5) 7. a. System Testing b. What is equivalence partitioning as it applies to software testing? c. Boundary Value Analysis d. Black box vs. white box testing e. Acceptance Testing (3+3+3+3+3) 8.       a.  What are the key differences between validation testing goals and acceptance testing goals?      b.  A computer system is required that will support the following small garage business.      Customers bring their cars to the garage for servicing and repair. The attendant must check the car in  record details about the owner and the car  along with any specific customer requests. The workshop manager inspects each car and creates a job specification for it. He then schedules the job and assigns a mechanic to complete the specified tasks. During this process  if any new problems are discovered a new job specification is created by the workshop manager before carrying out the work. When the job is finished the mechanic completes a report detailing the time spent  work done and materials used. This information is used by the attendant to create an invoice for the customer when they come to collect their car. Represent the system described above as a use-case diagram         (5+10) 9.        a. What is the difference between testing Techniques and tools? Give examples. B Level Syllabus R4    169        Quality control activities are focused on identifying defects in the actual products produced; however your boss wants you to identify and define processes that would prevent defects. How would you explain to him to distinguish between QA and QC responsibilities? b.   Describe the process used in the UML (unified modeling language) approach to object-oriented design.  (10+5) B Level Syllabus R4    170  B25.2-R4: SOFTWARE TESTING AND QUALITY MANAGEMENT  Assignment 1.   A program reads three integer values  representing the lengths of the sides if the triangle.  The program prints whether the triangle is scalene  isosceles or equilateral. Develop a set of test cases that would test the program adequately. Assignment 2.   Derive a flow graph for the above program and apply basis path testing to develop test cases that will guarantee the execution of all the statements. Execute the cases and show the results.  Assignment 3.   Given the following procedure   PROCEDURE AVERAGE   Interface Returns avg  input  valid  Interface accepts value  min  max  int value [100]; int avg; input  valid  min  max  sum  i  i = 1; input = valid = 0;  sum = 0 Do WHILE value [i]   - 999 and input = min and value [I]  0 THEN avg = sum/valid B Level Syllabus R4    171  ELSE  Avg = -999 END IF END AVERAGE a) Draw a flow graph for the above given algorithm. b) Determine the cyclomatic complexity by applying  i) Number of regions ii) Edges and nodes iii) Predicate nodes c) Determine a basis set of linearly independent paths.  Assignment 4.   Prepare the test cases corresponding to each independent path identified in Q3.  Assignment 5.   Draw a Graph Matrix corresponding to algorithm given in Q3 & compute the cyclomatic complexity. Prepare the test cases of the given algorithm to test the conditions using CONDITION TESTING.  Assignment 6.   Write a program in any programming language to accept a number and generate a table. Draw a flow graph and design various test cases for testing all possible paths.  Assignment 7.   Write a program in a programming language  specified by the examiner  to accept a 10 numbers & sort them in the order accepted at run time. Make a flow graph and design test cases for the condition testing. Also mention the expected results.  Assignment 8.   You are to prepare a Test Plan.  What are the various test factors to be analyzed that correspond to Project Risks?  Assignment 9.   A universitys web site allows students to enroll online bio-data. The form contains following fields: i. Name of the student ii. Fathers name iii. Address iv. City v. State vi. Pin code vii. Sex viii. Date of Birth ix. Academic Qualifications B Level Syllabus R4    172  a. Exam Passed b. University/Board c. Marks obtained d. Division e. Max Marks Design the validation checks for the given fields. Assignment 10.  Assume there is functionality to log-in through the screen given below:   Write a set of black box test cases to test the functionality of the given screen. Assignment 11.   Prepare a checklist to review the Requirements and Design Assignment 12 .  Write a program to find the sum of the matrices.  Write all the test cases so as to verify the correctness of the logic.  Assignment 13.  Write the code for binary and linear search. Find the cyclomatic complexity of the two by drawing the flow graph.  Assignment 14.   Prepare a list of checks to test date  numeric and alpha fields in any data entry screen.  Assignment 15.   Create du and dc graph for the following program: scanf(x y);  if (y < 0)    pow = pow  y;  else     pow = y;   z = 1.0; while(pow != 0) Log in name: ___________ Password  ____________ SUBMIT B Level Syllabus R4    173  {  z = z * x;  pow = pow  1; } if (y < 0)  z = 1.0/z; printf(z); Assignment 16.   Create the flow graph of the above Q15 and compute the cyclomatic complexity.  Assignment 17.   Prepare the list of test cases for q16  Assignment 18.   Write a program to compute the factorial of a number and create du and dc graph for the same.  Assignment 19.   Create the graph matrix of the Q18 and compute the cyclomatic complexity.  Assignment 20.   Prepare the list of test cases for q19  Assignment 21.   Write a program to create fibonacci series and and create du and dc graph for the same.  Assignment 22.    Create the flow graph of Q21 and compute the cyclomatic complexity.  Assignment 23.   Prepare the list of test cases for q22  Assignment 24.   Prepare a checklist to test the Graphical User Interface of Windows based application.  Assignment 25.   Prepare a comprehensive checklist to test a WEB Site  B Level Syllabus R4    174  B3.1-R4 : MANAGEMENT   FUNDAMENTALS  AND INFORMATION SYSTEM  Objective of the course:  This paper is concerned with the strategic importance of Management concepts and its processes  in an business organization.  This course provides a broad review of the field of Information system development  integration and managing security of such information systems  in the modern business environment. It recognizes that  many organizations employ information Technology (IT) Professionals   they  have a key role to play in as the information provider that adds significant value to the ever-increasing volume of data processed for management decision making. At the end of the course  candidates should be able to:  Develop an understanding of general management and information system concepts and practices.   To understand the  technological environment of the contemporary organization and to apply a systematic approach to the use of information technology in organisations.  Appraise the technological environment in order to support the practical aspects of information development  integration  usage and understand security holes and its security controls to prevent information from  various frauds.  To gain application ability of necessary controls and standards in computerized Information system. Outline of course  S.No  Topic      Minimum No. of Hours 1. The  Process Of Management          10 2. Information System Concepts     05 3. Functional and Other Information Systems       10 4. Enterprise Systems                                         05         5. System Development Process                                               10  6. Information System Security                                                 05 7. Information Systems Control Techniques                             10                            8. Case studies                                                                           05 Lecture         60    Tutorials      60 Total        120 DETAILED SYLLABUS  1.  THE  PROCESS OF MANAGEMENT          (10) hrs  Functions Of  Management Business Organization  Levels of Management  the classical organizational theory  the Behavioral Approach  the Management Science Approach :  Planning- Mission  Vision and goal setting; and SWOT Analysis; Organizing -Types of Organizational Structures  Power  Authority  Delegation  Centralization and Decentralization   Formal and informal organizations   Functions and Design of an organization; Leading - Motivation  Theories of Motivation; Controlling: Control Process. Relevance of Computer applications in different functional areas of Management.  2. INFORMATION SYSTEM CONCEPTS        (5) hrs Definition of system  Types of systems: Physical and Abstract Systems  Deterministic and Probabilistic systems  Open and Closed systems.  Need of an efficient information system.  Major types of systems in organizations on the basis of organizational levels. B Level Syllabus R4    175  3. FUNCTIONAL AND OTHER INFORMATION SYSTEMS       (10 ) hrs   Finance and Accounting Information systems- order processing  Inventory control Accounts receivable system Accounts Payable System  Payroll System  General ledger  Billing System  Purchase system. Marketing and Sales  Manufacturing and Productions    and Human Resources Information Systems. OAS  TPS  MIS DSS  GDSS EIS  and ES.    4. ENTERPRISE SYSTEMS                                                       (5 ) hrs  Redesigning the organization with information  systems  BPR  Enterprise System Architecture : Integration of business functions. ERP: Meaning Characteristics  Benefits  Limitations  Risks in ERP implementations. Supply Chain Management(SCM) Customer Relationship Management (CRM). E-Business   5.   SYSTEM DEVELOPMENT PROCESS                                (10) hrs   Introduction to SDLC/Basics of SDLC; Requirements analysis and systems design techniques; Strategic considerations :-Acquisition decisions and approaches; Software evaluation and selection/development ;Alternate development methodologies- RAD  Prototype etc; Hardware evaluation and selection; Systems operations and organization of systems resources; Systems documentation and operation manuals; User procedures  training and end user computing; System testing  assessment  conversion and start-up; Hardware contracts and software licenses System implementation; Post-implementation review; System maintenance; System safeguards.  6. INFORMATION SYSTEM SECURITY          (5) hrs   System Vulnerability  Computer frauds   computer abuse   preventing computer  frauds   Ensuring System Quality   Information Security  Need  Contents of information security plan   Principles of information security  Best approach to implement information security  7. INFORMATION SYSTEMS CONTROL TECHNIQUES                                         (10) hrs  Introduction  General Controls-Operating System controls  Data Management Controls  Organizational Structure Controls  System Development Controls  System Maintenance Controls  Computer Centre Security Controls  Internet and Intranet Controls  PC controls. Application  Controls:  Input controls  Processing controls  Output controls  Storage Controls. Case studies                                   (5 ) hrs  RECOMMENDED BOOKS           MAIN READING  1. K. C. Laudon and J. P. Laudon  Management Information Systems:  Organization and Technology  11th Edition   Prentice Hall India  New Delhi. 2. Sushila Madan  Management Fundamentals and Information  Systems Taxman Publishing New Delhi. SUPPLEMENTARY READING  i. Harold Koontz and Heinz Weihrich  Essentials of Management   VIIIth Edition  Tata McGraw-Hill Publishing New Delhi ii. Management  Principles and Practice By Dr  C.B. Gupta Published by   Scholar Tech Press Edition 2009 New Delhi.  iii. W. S. Jawadekar  Management Information System  IV th edition Tata McGraw-Hill Publishing New Delhi. B Level Syllabus R4    176  B3.1-R4: MANAGEMENT FUNDAMENTALS AND INFORMATION SYSTEMS  Model Question Paper  NOTE: 1. Answer question number 1 and any four from 2 to 7. 2. Parts of the same question must be answered in sequence and together. Time Allotted: 3 Hours                                                         Total Marks:  100  Ques. 1  (a) What is the significance of motivation in an organization ?                 (5 marks) (b) Explain the various skills that managers at different levels of management should possess.                                                                                        (5 marks) (c) Explain the effects of applying computer technology to MIS.                    ( 5 marks) (d) What are the characteristics of information required for strategic planning?                                                                                                                             ( 5 marks) Ques. 2          (a)     What is the importance of planning in an organization?                           (5 marks) (b)     What are the differences between programmed and non- programmed                             decisions?                                                                                                          ( 5 marks) (c )     Define and distinguish between Line  Staff and Functional relationships.                                                                                                                            (5 marks) (d )    What are the various principles of delegation of authority?                     (5 marks) Ques 3.        (a)    Why information systems are required?                                                  (5 marks)          (b)    What are the inputs and outputs of MIS and what processing is performed in  MIS?                                                                                                                                           (5 marks)         (c)     Describe the comparison between MIS and DSS.                                 (5 marks)        (d)     What are the advantages of an expert system?                                      (5 marks)  Ques 4.         (a)   What is the purpose of preliminary investigation?                                 (5 marks)         (b)   Explain the various steps involved in system analysis.                         (5 marks)         (c)   The final step of system implementation is its evaluation. What  functions are   being served by system evaluation ?                 (5 marks)         (d)    Explain the advantages and disadvantages of using prototyping approach of  system development               (5 marks)  Ques. 5 (a) What are the major factors to be considered in designing user inputs? (5 marks) (b)  Write a short note on system manual.                                                    (5 marks)               (c)  Explain the advantages of pre-written application software package.   (5 marks) (d)  Compare and contrast between direct conversion and parallel conversion.                                                                                                                                                            (5 marks)   Ques. 6           (a)  What are the benefits of ERP systems?                                                 (5 marks)           (b)  Briefly describe the various financial decisions.                                     (5 marks)           (c)  What are the characteristics of computer frauds?                                 (5 marks)           (d)   Explain private key and public key encryption.                                     (5 marks)        B Level Syllabus R4    177  Ques. 7            (a) What is firewall? What are the objectives of firewall?                          (5 marks)            (b)  What are the various risks involved in ERP implementation?             (5 marks)            (c)  What is information security? What are the objectives and contents of  information                 system security plan?                                                                              (5marks)  (d)Explain the factors upon which  make or buy decision of an application software  depends.                                                                                                  (5 marks)    B Level Syllabus R4    178  B3.1-R4:  MANAGEMENT FUNDAMENTALS AND INFORMATION SYSTEMS  (Assignments) Assignment 1. Case study on the Process Of  Management and give the answer of following questions.     1. Describe the different levels of management and explain the information required at these different levels. 2. Describe the various types of Organisation Structure.  3. Describe the relationship between planning and controlling and the importance of controlling. 4. Describe the importance of motivation and the theories of motivation.                                                                                                      Assignment 2. Case study on Information System Concepts and give the answer of following questions.    1. Discuss why information systems are required.  Assignment 3. . Case study on Functional and Other Information Systems and give the answer of following questions. 1. What is the Decision Support System? How it helps to take decisions?  2. What are the factors on which information requirements depend? 3. What are the Expert Systems? Discuss the application areas of Expert Systems. Assignment 4. . Case study on Enterprise Systems and give the answer of following questions.  1. Describe the importance of ERP in current business system and list out the various risk involved in implementing ERP. 2. Describe Scope of  SCM. 3. Explain trends in CRM and challenges faced. Assignment 5. . Case study on System Development Process and give the answer of following questions.   1. Describe the different stages of System Development Life Cycle. 2. Describe the different conversion strategies during System Implementation. 3. Describe the criteria for software selection. Assignment 6. . Case study on Information System Security and give the answer of following questions. 1. What are the objectives of information security policy? 2. Why should business take computer frauds seriously?   Assignment 7.  Case study on Information System Control Techniques and give the answer of following questions.    1. Describe General Controls. How do they differ from Application Controls? 2. What are the objectives of Storage Controls? Explain any two Storage Controls.  Assignment 8.  Case study on system maintenance of a Project  and give the answer of following questions 1. What are the  Duties and responsibilities of the following people in a project  i. Data entry supervisor  ii. File librarian iii. Control group iv. Operations management B Level Syllabus R4    179  v. Role of Security administrator vi. Role of Quality Assurance group  vii. Role of System Analyst viii. Role of application Programmer ix. LAN administrator x. Help desk administration B Level Syllabus R4    180  B3.2  R4: Discrete Structure  Objective of the course  Discrete structure is a course which plays important role in the development of computer science and data networking. It teaches the students how to work with discrete structures  which are the abstract mathematical structures used to represent discrete objects and relationship between these objects. These structures include sets  permutations  relations  graphs  trees and finite state machines. Mathematics logic and Boolean algebra will help the students in  the understanding of Digital system designs.  Certain classes of problems are solved by the specification of an algorithm. After an algorithm has described  a computer program can be constructed implementing it. In the portion of Analysis of algorithm  verification of the functioning of an algorithm  time required to perform it  are all covered. The topics on number theory has application in cryptography combinatorics.Recurrence relation has utility  in Analysis of Computer algorithms. To understand LAN  WAN knowledge of graph theory is required. A depth and comprehensive study of discrete structure helps the students to understand the advancements of computer science. Outline of course  S. No.                        Topic                                   Minimum number of hours  1.                           Sets theory and functions                          6 2.                           Mathematical logic                                     8 3.                           Boolean Algebra                                        5 4.                           Number Theory                                          5 5.                          Algebraic Methods                                      6 6.                          Combination                                                9 7.                          Graph Theory                                              9 8.                          Analysis of Algorithms                                 5 9.                          First state machines & languages               7                                                                  Lectures =   60                                                                 Tutorials =   60                                                                     Total      =  120        DETAILED SYALLABUS  1. Set Theory & Functions        (6) hrs  Sets  Subsets  Relations and their properties. Representing relations  Equivalence relation  partial orderings  maximal & minimal elements of a poset  functions   inverse functions. Composition of functions and recursive functions.  2. Mathematical logic          (8) hrs Logic operators  proposition equivalence involving tautologies contradiction   predicate & quantifiers  computer representations of sets.  3. Boolean Algebra         (5) hrs         Partitions of a set lattices and algebraic systems  Boolean functions and Boolean expressions  propositional Calculus  gates and switching circuits  Karnaugh map.  4. Number Theory         (5) hrs  The Principal of induction  Euclidean algorithms the greatest common divisor  equivalence relation  Fibonacci numbers. B Level Syllabus R4    181  5. Algebraic Methods         (6) hrs  Groups  order of a group element  cosets    Lagranges theorem  permutations  representation of groups by permutation.  6. Combinations          (9) hrs  Basics of counting  the Pigeonhole principle  permutation and combination  Discrete   Probability generating functions  recurrence rotation  Divide and conquer relation  Inclusion and exclusion with applications.  7. Graph Theory          (9) hrs      Multigraph and weighted graphs  paths & circuits  Eulerian paths nd circuits  the traveling salesman problem  planer graphs  trees  spanning trees  cut sets  minimum spanning tree.  8. Analysis of Algorithms         (5) hrs     Algorithms and programs  efficiency of algorithms. Big O notation  comparison of algorithm  sorting algorithm.  9. Finite start machines and languages       (7) hrs          Languages and grammars  finite state of machines with output and without  Language          recognition  turting machines.  Recommended Books Main Reading  1. Kenneth N. Rosen  Discrete Mathematics and its applications  Tata McGraw Hill. 2. C.L. Liu  Elements of Discrete mathematics Tata McGraw Hill. 3. Norman L. Biggs  Discrete Mathematics Oxford University Press 4. Trembling  J.P. & Manohar P   Discrete mathematical structure with applications       Tata McGraw Hill. 5. Vinay Kumar  Discrete Mathematics  BPB  India  2002   Supplementary Readings  1. John Truss   Discrete mathematics for computer scientists  Addison  Wesley 2. M. Lipson and Lipshutz  Discrete Mathematics  Schaums Outline series. 3. M.O. Albertson and P. Hutchinson  Discrete Mathematics with Algorithm  John Wiley and sons.  B Level Syllabus R4    182  B3.2  R4: Discrete Structure Model Question paper Attempt question 1 and any four of the remaining six questions. Question 1 is of 28 marks and the rest are of 18 marks each. Q.1  (a) How many different words can be formed out of the letters of the word VARANASI?  (b) If R is a relation Less Than from A = {1 2 3 4} to B = {1 3 5} then find RoR-1.   (c) A graph G has 21 Edges  3 vertices of degree 4 and other vertices are of degree 3. Find the number of vertices in G. (d) What kind of strings does the following automaton reject? (e) Find the binomial generating function for the sequence 1  2  3  . (f) Define cyclic group and give an example of such group. (g) Show that (D30  |) is a lattice. D30 is set of all positive integers that divides 30 and | is relation of divides i.e. x | y implies that x divides y.  [4x7] Q.2 (a) Write the negation of each of the following in good English sentence. I. Jack did not eat fat  but he did eat broccoli. II. The weather is bad and I will not go to work. III. Mary lost her lamb or the wolf ate the lamb. IV. I will not win the game or I will not enter the contest. (b) Simplify the logical expression  W  ZY ZY ZXY X +++ .  [8 10] Q.3  (a) For the given graph  find the minimal spanning tree using Prims algorithm.   B Level Syllabus R4    183  (b) Show that is 1R  and 2R are equivalence relations on A  then 21 RR   is an equivalence relation. [9 9] Q.4  (a) 20 members of a bowling league wear shirts numbered consecutively from 1 to 20. When any three of these members are chosen to be a team  the league proposes to use the sum of their shirt numbers as the code number for the team. Show that if any eight of the 20 are selected  then from these eight one may form at least two different teams having the same code number.    (b) In a group of athletic teams in a certain institute  21 are in the basketball team  26 in the hockey team  29 in the foot ball team. If 14 play hockey and basketball  12 play foot ball and basket ball  15 play hockey and foot ball  8 play all the three games.   (i) How many players are there in all?   (ii) How many play only football?   [8 10] Q.5  (a) Prove that for every pair of elements x and y in A (using algebraic method).   (i) (x + y)' = x' * y'   (ii) (x * y)' = x' + y'          (b) Prove that   (p  q)  r = p  (q  r) (c) Prove that the Boolean expression BAABA ++ is independent of B.   [8 6 4] Q.6 (a) Let (G  *) be a group then for any two elements a and b of (G  *) prove that (a * b) 1= b 1 * a1. (b) Solve the recurrence equation 5;75 11 =+=  anaa nn  (c) Prove that V(G)  E(G)  Deg (G)  in an undirected graph G. [6 6 6] Q.7 (a) Draw a finite state machine for the language that contains string on {0 1} such that number of 0s is even and number of 1s is a multiple of 3.  (b) Define permutation group. Show that every cycle can be written as product of transposition.  [8 10]  B Level Syllabus R4    184   B3.2-R4 : Discrete Mathematical Structure Assignment 1. Define a multi set. What is a cardinality of a set? Illustrate your answer with an example. How many binary relation can be defined on A if |A| = n?  2. When a set is called well ordered set? Show that (P(S)  ) is a finite boolean algebra  where S = {1  2  3} and   is a relation defined on P(S) as set containment.    3. Define normal subgroup. is (I+  +)  a group ?        4. Let M = (S  I    s0  T) be a finite state machine. Let R be a relation defined on S such that for any two states: si  sj  S  siR sj iff si and sj are w-compatible. Show that R is an equivalence relation. 5. Determine the binomial generating function for the sequence a  where the general term of the sequence is given as 211 )(1 ==  nfornk knkka  6. Prove the following using mathematical induction       )2...444()...888()....666( 2 digitsnuptodigitsnuptodigitsnupto =+  7. Find the discrete numeric function for the generating function (1+x)5. 8. Solve the recurrence relation an = an1 + an2; for n  2; given that a1 = a2 =1.  9. Twenty cards numbered 1 through 20 are placed face down on a table. Cards are selected one at a time and turned over until 10 cards have been selected. If the two cards add up to 21  the player loses. Is it possible to win the game?    10. Find the number of ways of selecting three numbers x  y and z from 1 to 300 (both inclusive) such that x + y + z is divisible by 3. 11. Draw a finite state machine that can accept any string from {a  b}* that contains 2n as and 3m bs where both m and n are non-negative integers. 12. Construct a phrase structure grammar G for the language L = {ambn | m  n  1  m  n} 13. Simplify the following FSM.  a cbfged1 0111001001 010Figure 1 B Level Syllabus R4    185  14. A lattice is said to be modular if  for all a  b and c  a  c  a  (b  c) = (a  b)  c. Show that a distributive lattice is modular. Further show that the lattice shown in the following Hasse diagram is a non-distributive lattice and is modular. 15. Show that if L1 and L2 are two distributive lattices  then L = L1  L2 is also distributive  where partial order in L is the product of partial orders in L1 and L2. 14. Given a complete regular bipartite graph of 100 vertices  what will be its chromatic number? What is the cardinal number of the set E of this graph?  15. What is a planar Graph? Show that Kn (n < 5) is a planar graph. 16. Calculate all pairs shortest path in the following graph. 17. Reduce the following Boolean expressions  defined over the two-valued Boolean algebra  to Conjunctive Normal Form and Disjunctive Normal Form. f(w  x  y  z) = (w  x  y)  (w  x  z)  (x  y z) 18. Simplify the following boolean expression w (x + y ( z + x) + y) + wxyz  19. Let L is a distributive lattice. Show that if there exists an a with  a  x = a  y and a  x = a  y then x = y.  0 y z x I bcaed32 7362 145  B Level Syllabus R4    186  B3.3-R4: SOFTWARE ENGINEERING & CASE TOOLS   Objective of the Course  In this course  students will study the various topics relevant to development of modern quality software system. Analysis  Design and development of software is an extremely important course and every software developer is required to be well conversant with the principles  theory and practical aspects of writing efficient and high quality programs. This course is a graduate-level software engineering course. We will explore a basic knowledge of software engineering principles  advanced specification and design. This course covers various topics that every computer science student needs to know and practice to ensure quality software development.  Outline of Course                     S.No.           Topic                                  Minimum No. of Hours 1. Software Engineering Fundamentals 05 2. Software Requirements Analysis & Specification 10 3. Software Design 05 4. CASE Tools 04 5. Coding and Testing 06 6. User Interface Design 03  7. Configuration Management 04 8. Software Maintenance 06 9. Software Quality and Metrics 05 10. Object-Oriented Software Engineering 06 11. Advance Software Engineering Topics 06   Lectures = 60 Practicals/Tutorials = 60 Total =                 120 Detailed Syllabus  1. Software Engineering Fundamentals                                                                      5 Hrs.  Definition of software product and process  Software Characteristics  Components  Applications  Layered Technologies  Processes and Product  Methods and Tools  Generic View of Software Engineering  Software Crisis  Software development paradigms  Techniques of Process Modeling  Software Process and lifecycle models: Build & Fix Model  Waterfall Model  Prototyping Model  Iterative Enhancement Model  Evolutionary Development Model and Spiral Model  Incremental  and Concurrent Development Model.  2. Software Requirements Analysis & Specification                                                10 Hrs.  System specification  Software requirements specification (SRS) standards  Formal specification methods  Specification tools  Requirements validation and management. Problem Recognition  Evaluation and Synthesis  Modeling  Specifications and Review Techniques. Analysis Modeling: Difference between Data and Information  ER Diagram  Dataflow Model  Control Flow Model  Control and Process Specification  Data Dictionary. 3. Software Design                                                                                                       5 Hrs.  B Level Syllabus R4    187  Software architecture  Modular design - cohesion and coupling  Process-oriented design  Process and Optimization  Data-oriented design  User-interface design  Real-time software design  Architectural Designing  Interface Design  Procedural Design  Object Oriented Design.  4. CASE Tools                                                                                                                4 Hrs.  Computer-aided software engineering  Introduction to CASE  Building Blocks of CASE  Relevance of CASE tools  High-end and low-end CASE tools  automated support for data dictionaries  DFD  ER diagrams  Integrated Case Environment  CASE workbenches.  5. Coding and Testing                                                                                                 6 Hrs.  Choice of Programming languages  Coding standards  Introduction to Testing Process     Functional & Structural Testing  Testing Activities like Unit  Integration & System Testing  Testing tools and workbenches.   6.  User Interface Design                                                                                   3 Hrs.        Concepts of Ui  Interface Design Model  Internal and External Design  Evaluation  Interaction and Information Display.   7. Configuration Management                                                                                       4 Hrs.  Concepts in Configuration Management  The Configuration Management Process: Planning and Setting up Configuration Management  Perform Configuration Control  Status Monitoring and Audits.   8. Software Maintenance                                                                                                     6 Hrs.  What is software maintenance  Maintenance Process & Models  Reverse Engineering  Software re-engineering  Configuration Management issues and concept  Configuration planning & techniques  Software versions and change control process  Documentation.   9. Software Quality and Metrics                                                                                         5 Hrs.  SQA-Software Quality Assurance  Debugging and reliability analysis  Program complexity analysis  Software quality and metrics  Quality Control   Approaches to SQA  Reliability  ISO9000 and 9001  CMM Levels and SIX sigma.  10. Object-Oriented Software Engineering                                                                      6 Hrs. OO Concepts and Approach  OO Analysis  Domain Analysis  OOA Process and Object Models  OO Design  System Design process and Models  UML and diagrams    11. Advance Software Engineering Topics                                                                        6 Hrs. Clean room approach and strategy  Functional specification and design  Component-based software engineering process  Reusability and Metrics  Reengineering Essentials  Software Agents.  RECOMMENDED BOOKS:  MAIN READING   1. R. Pressman  Software Engineering  7th  Edition  2002  McGraw-Hill. 2. W.S. Jawadekar  Software Engineering  A Primer  TMH-2008  B Level Syllabus R4    188  SUPPLEMENTARY REDING 1. Shari Ptleeger  Software Engineering  2001  Pearson Education. 2. Stephen Schach  Software Engineering  TMH  2007 3.  Sommerville I.  Software Engineering  Addision-Wesley B Level Syllabus R4    189  B3.3-R4: SOFTWARE ENGINEERING & CASE TOOLS  Model Question Paper NOTE:   TOTAL TIME: 3 HOURS                        TOTAL MARKS: 100  1.    b) Why should a requirement engineer avoid making any design decision during requirement analysis?  c) Why the Spiral life cycle model is considered to be a meta model? Differentiate between throw away and evolutionary prototype process model. d) Differentiate between functional and non functional requirements of a software? What are non-functional requirements for software? d)         How structure partitioning can help to make software more maintainable? e) Explain in brief: Software Characteristics. Mention some of the myths exists in the various stake holders mind about the software. f) Why SRS document also known as black box specification of a system? g) Project requirements continually change  but change can be easily accommodated if software is flexible. Justify in brief.                       (7x4)  2.         a) What are the major phases of the entire life of the software? Specify the percentage of efforts required on each phase. Which phase requires the maximum efforts? b) How do you evaluate user interface? List the desirable characteristics that a good user interface should possess. e) Why is it so difficult to gear a clear understanding of  what the customer wants? Which document needs to be prepared for contracting between customer and developer? What it contains?     (7+5+6) 3. a) Identify the types of defects that you would able to detect during the following:  Code walk through and code Inspection. Give difference between code walk through and code inspection. b) Discuss the merits and demerits of ISO 9001 and SEI CMM Certification. c) What is the meaning of FTR (Formal Technical Review)? What are the guidelines to review software product? List and explain various activity involve in Software audit.     (6+4+8) 4. a) What do you mean by measure  measurement and metric? How they are related to each other? What is difference between Product and Process Quality metrics? b) Develop an E-R diagram and prepare data dictionary for the following system.              Library Management System. c) What are the different kinds of project resources? Explain in brief.                 (7+8+3) 5. a) Draw the DFD for the following system.             A simple invoicing system for a small business. 1. Answer question 1 and any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the same sequence.  B Level Syllabus R4    190  b) Suppose an organization assessed at level 3 of SEI CMM  what can you infer about the current quality practices at the organization? What does this organization has to do reach SEI CMM level 4?  c) What is the meaning of Data Collection? Which factors are important for Data collection?                 (7+7+4) 6. a) What is the method of estimating software quality?  What is to be done in subcontracting and quality auditing? b) What is the meaning of software maintenance? What are the different types of maintenance that are software product might need. Why is such maintenance required? c) Explain the integration testing process. Why is the mixed integration testing approach preferred by many testing engineers?                 (7+7+4) 7.    a) Discuss the relationship between the concept of information hiding as an attribute of effective modularity and the concept of module independence. Why is it good idea to keep the scope of effect of a module within its scope of control? b)         Differentiate between software reengineering and reverse engineering.  c) Describe technique for tracking and controlling of Software Quality. How we can do effective contract management?                                (7+7+4) B Level Syllabus R4    191  B3.3-R4: SOFTWARE ENGINEERING & CASE TOOLS  Assignment 1. Find out the appropriate model for the below applications.   A Well-understood data processing application.  A new software product that would connect computers through satellite communication. Assume that your team has no previous experience in developing satellite communication software.  A software product that would function as the controller of a telephone switching system.  New library automation software that would link various libraries in the city.  Extremely large software that would provide  monitors  and control cellular communication among its subscribers using a set of revolving satellites.  New text editor.  A compiler for a new language.  An object-oriented software development effort.  The graphical user interface part of a large software product. Assignment 2. Prepare Software project management planning (SPMP) document as per below format using Turbo Project for Library Automation System.  Introduction 1. Objectives 2. Major Functions 3. Performance Issues 4. Management and Technical Constraints  Project Estimates 1. Historical Data Used 2. Estimation Techniques Used 3. Effort  Resource  Cost  and Project Duration Estimates  Schedule 1. Work Breakdown Structure 2. Gantt Chart Representation  Project Resources 1. People 2. Hardware and Software 3. Special Resources  Staff Organization B Level Syllabus R4    192  1. Team Structure 2. Management Reporting  Risk Management Plan 1. Risk Analysis 2. Risk Identification 3. Risk Estimation 4. Risk Abatement Procedures  Project Tracking and Control Plan  Miscellaneous Plans 1. Quality Assurance Plan 2. Configuration Management Plan 3. System Testing Plan 4. Delivery  Installation and Maintenance Plan Assignment 3. CASE STUDY: Study of different Software Cost Estimation models.    Calculate the cost of Library Automation system by COCOMO Assignment 4. Design Software Requirement Specification (SRS) document for the Library                           Automation System. Assignment 5. Draw the following diagram for the library automation system  Structure chart  Physical DFD  User Interface (I/O) Designing  Component level Design. Assignment 6. Draw the Users View diagram for the library automation system using                             Object Oriented approach by Enterprise Architecture Tool.  Use case Diagram Assignment 7. Draw the Behavioral View diagram for the library automation system using                            Object Oriented approach by Enterprise Architecture Tool.  Sequence Diagram  Collaboration Diagram  State-chart Diagram  Activity Diagram Assignment 8. Draw the Structural View diagram for the library automation system using                           Object Oriented approach by Enterprise Architecture Tool.  Class Diagram  Object Diagram Assignment 9. Draw the Implementation View diagram for the library automation system                           using Object Oriented approach by Enterprise Architecture Tool.  Component Diagram Assignment 10. Draw the Environmental View diagram for the library automation system                             using Object Oriented approach by Enterprise Architecture Tool.  Deployment Diagram Assignment 11. CASE STUDY: Various Testing Tools. B Level Syllabus R4    193  Assignment 12. Design Test Cases for Library automation systems functionality Assignment 13. Prepare technical white paper on any one topic as given below.  ISO  CMM  Six-Sigma standards  Agile Process Model  Clean room Software Engineering   Cost Benefit Analysis Method (CBAM)  Re-engineering  Software security  Automated software testing  Web Engineering  Computer Aided Software Engineering B Level Syllabus R4    194  B3.4-R4: OPERATING SYSTEMS                                          Objective of the Course This course is covering all the fundamental operating systems concepts such as processes  interprocess communication  input/output  virtual memory  file systems  and security.  The students are expected to learn these principles through UNIX/Linux/Windows 2000/XP/NT/Vista like operating systems.   The course outline is about the concepts  structure and mechanism of operating systems.  Its purpose is to present  as clearly and completely as possible  the nature and characteristics of modern-day operating systems.  It examines the operating systems that run in multiprocessing environments and covers distributed computing in the context of open system interconnection (OSI) standards and protocols.   The intent of this course is to provide a thorough discussion of the fundamentals of operating system design and to relate these to contemporary design issues and to current directions in the development of operating systems.                                                             Outline of Course  S.No. Topic                                      Minimum No. of Hours  1. Overview 08 2. Process Management 10 3. Storage Management 10 4. I/O Systems 08 5. Distributed Systems 10 6. Protection & Security 08 7. Case Studies 06  Lectures = 60 Practicals/Tutorials/Assignments  = 60 Total = 120                                                                          Detailed Syllabus  1. Overview                                                                                                                 8 Hrs.  Introduction: Operating Systems  Multi programmed Batched system  Time storing systems  Parallel and Distributed Systems  Real Time Systems  Computer System Structures : I/O structure  Storage Structure   Storage Hierarchy  Hardware  Protection  General System Architecture.   Services: User Interface Services  Graphics and Multimedia Services  Messaging and Collaboration  Network basics  Web Services  Operating System Structures:  System components  Operating System Service  System Calls  System programs  System Structure  System Design and Implementation  System Generation  Virtual Machines and Hypervisor   B Level Syllabus R4    195  2. Process Management                                                                                              10 Hrs.  Processes :   Process Concept  Process Scheduling  Operation on Processes  Cooperating Proceses  Interprocess Communication  Symmetric vs. asymmetric multiprocessing  Background Process.  CPU Scheduling :     Scheduling Criteria  Scheduling Algorithms  Multiple Processor Scheduling  Real Time Scheduling  Algorithm Evaluation  Thread Scheduling  System Jobs. Process Synchronization :  The Critical  Section Problem  Synchronization Hardware  Semaphores  Classical Problems of Synchronization  Critical Regions  Monitors.  Deadlocks:  Deadlock Characterization  Methods for Handling Deadlocks  Deadlock Prevention  Deadlock Avoidance  Deadlock Deletion  Recovery from Deadlock  Combined Approach to Deadlock Handling.   3. Storage Management                                                                                          10 Hrs.  Memory Management:  Logical versus Physical Address Space  Swapping  Contiguous Allocation  paging  Segmentation  Segmentation with paging.   Virtual Memory: Demand Paging  Performance of Demand Paging  Page Replacement Algorithms  Thrashing  Demand Segmentation.   File System Interface: Access Methods  Directory Structure  Protection  Consistency Semantics  Partitions  Simple Volumes  Shadow Volumes  Virtual Disks  Bitlocker.  File System Implementation: File System Structure  Allocation Methods  Free Space Management  Directory Implementation  Efficiency and Performance  Recovery.   4. I/O Systems                                                                                                                9 Hrs.  I /O Systems : I/O Hardware  Application I/O Interface  Kernel I/O Subsystem  Transforming I/O Requests to Hardware Operations  Performance  Synchronous I/O and Asynchronous I/O  File Caching.  Secondary-Storage Structure : Disk Structure  Disk Scheduling  Disk Management  Swap-Space Management  Disk Reliability  Stable Storage Implementation.   Tertiary-Storage Structure : Tertiary-Storage Devices  Operating-System Jobs  Performance Issues   File System: File System Formats (CDFS  FAT  NTFS  exFAT etc)  Kernel Mode and User Mode Driver Framework 5. Distributed Systems                                                                                               9 Hrs.  Network Structures :  Topology  Network Types  Communication  Design Strategies.   Distributed System Structures : Network Operating Systems  Distributed Operating Systems  Remote Services  Robustness  Design Issues   B Level Syllabus R4    196  Distributed File Systems : Naming and Transparency  Remote File Access  Stateful versus Stateless Service  File Replication.   Distributed Coordination : Event Ordering  Mutual Exclusion  Atomicity  Concurrency Control  Deadlock Handling  Election Algorithms  Reaching Agreement   6. Protection & Security                                                                                               8 Hrs. Protection : Goals of Protection  Domain of Protection  Access Matrix  Implementation of Access Matrix  Revocation of Access Rights.   Security : The Security Problem  Authentication  One-Time Passwords  Program Threats  System Threats  Threat Monitoring  Encryption  Computer-Security Classifications  Common Criteria  VPN  Protocol security  Access Checks (ACL  DACLs)  Auditing  Policy Management  User Account Controls (UAC).   7. Case Studies                                                                                                              6 Hrs. The Unix System  The Linux System  Windows Server.  RECOMMENDED BOOKS  MAIN READING   1. Silberschatz Galvin  Operating System Concepts  1999  Addison-Wesley Longman. 2. Andrew S. Tanenbaum  Albert S.  Woodhull  Operating Systems : Design &          Implementation  2002  Pearson Education Asia. 3.   Mark E. Russinovich and David A. Solomon   Windows Internals 5th Edition  June 2009 :       Microsoft Press   SUPPLEMENTARY READING  1. D.M.Dhamdhere  Operating Systems : A Concept Based Approach   2002  Tata McGraw   Hill Publishing Company. 2.   A.S. Godbole   Operating Systems  Tata McGraw Hill  2002 3.  Stephen G. Kochan   Patrick Wood    UNIX Shell Programming SAMS Publishing 2007         Third Edition  Pearson Education 4.  Richard L.Petersen   LINUX:The Complete Reference  fifth edition  Tata McGraw Hill 2006 5.  Kate Wrightson   Joe Merlino   Introduction To UNIX  McGrawHill  Irwin  2003  Note : For All modules  explanation must  carry case study of either UNIX family or Windows family or both and the last module then can be covered with features of the case study studied throughout. B Level Syllabus R4    197  B3.4-R4 : OPERATING SYSTEMS  NOTE:  1. Answer question 1 and any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the same sequence.   Time: 3 Hours                                                                  Total Marks: 100  1.  (a) How can one distinguish between Processes  Threads and Jobs ? (b) What is a software interrupt? (c) What is a virtual memory space? How is it different from a physical memory space? (d) Distinguish between Partitions  Volumes and Multi-Partition Volumes.. (e) What  does Process Virtualization do? What  security threat does it address ? (f) Briefly discuss one of the ways of implementing memory protection using special hardware support.  (g) Differentiate between Symmetric and Asymmetric multiprocessing.      (7 x 4) 2.  (a)  Describe in brief  the different attributes associated with any file in a typical computer system along with the relevance/usefulness of each of these attributes.  (b) What is Hypervisor? Define the two types of Hypervisor. Give Examples of each type. (c )        How does Bitlocker ensure OS integrity and encrypt files in the hard drive. (6+8+4)  3.  Assume that a producer is producing non zero integers  1000 and putting them in a  circular buffer of size 100  while the consumer is consuming the non zero integers contained in that circular buffer at its own speed. Using counting and binary emaphores   write the outline of the producer process and the consumer process.                                                                                                                    (18)  4.  (a)  Explain the basic differences between a security/protection policy and protection mechanism as existing in any contemporary computer system.  (b)  Explain the Application level filtering feature of Windows firewall . (c) What is a password? Why is it used? Describe the various types of password validation techniques as used in any computer system.                                                                                                     (4+6+8) B Level Syllabus R4    198  5. Consider a hypothetical computer system having the following CPU scheduling features.  It has got 3 (three) priority levels 1  2 & 3 with 1 being the highest and 3 being the lowest. It supports a multilevel preemptive scheduling policy having the features mentioned below:                        Priority level    Allotted Time Quantum          % CPU time  allotted                                                       (in units)             1                     10 50% 2                     15 30% 3                      20 20%  Context switching time among jobs/processes having same priority = 2 units. Context switching time from one priority level to another = 5 units. Dispatcher execution time = 5 units (fixed). Time Quantum allotted/job excludes the time taken by the dispatcher as well as the context switching time. Jobs/Processes are serviced in a Round Robin fashion. Before servicing the very first job  one needs to execute the dispatcher and perform a context switch i.e.  no job can possess a zero waiting time. If any job finishes well within its allotted time quantum the remaining part of that  time quantum is not allotted to any other job rather a context switch takes place. For the previously mentioned computer system having the aforesaid scheduling policy the following job mix / processes is required to be serviced. Process/Job Service time Priority Arrival time (in units) (in units) P0 20 2 0 P1 15 1 5 P2 25 2 8 P3 30 3 10 P4 12 1 15 P5 40 3 20 P6 18 2 22 P7 24 1 30 (a) Specify the queue status at each priority level. (b) Specify the Gantt chart for the given job mix. (c) From the Gantt chart compute the turnaround time as well as waiting time for each process.                                (5+10+3) 6. Consider the following specifications about the physical and virtual spaces as existing in a computer system. B Level Syllabus R4    199   Physical space = 64 K words out of which 16K is occupied by the resident  operating system. Remaining portion is available to accommodate user       processes.  Physical space is divided into 2K word size frames.  Virtual space for user 1 = 256K words.  Virtual space for user 2 = 512K words.  Both the users share a common 8K word Library  which is required at all time      By both the users.  (a) Specify the address layout of the following  clearly highlighting each field: i. Virtual address of user 1. ii. Virtual address for user 2. iii. Address of library. iv. Physical Address. (b) How many Page Map Table (PMT) entries will be needed for user 1  user 2 & Library? Clearly justify your answer. (c) Specify in detail a typical PMT entry assuming the following features of each page.  Each page has got an associated modify bit which helps to             identify whether the corresponding frame has been written               into and hence needed to be written back to the virtual space              during any page replacement.  A use bit indicating whether the page has been accessed               recently.  Access permission bits signifying the following modes of              access.  i. READ ii. WRITE iii. EXECUTE (d) Assuming that the library needs to be present at all time in memory and the system has a TLB Cache that can contain maximum 16 entries  how many user pages can be referred from TLB? Justify your answer.     (8+2+5+3)  7.  (a) State the necessary conditions for a deadlock to occur with                examples. (b) Explain the Kernel Structure in UNIX. Discuss with examples the             Directory entry attributes and Inode table Attributes in detail.  (c) Consider the following process and resource map.  The system has got 4 (four) concurrently non-shareable and                reusable resources with following unit allocation/resource. Resource Units R0 8 R1 5 R2 9 R3 7 B Level Syllabus R4    200    There are 5 (five) processes in the system P0 P4 having the following maximum resource requirements. Process R0 R1 R2 R3 P0 3 2 1 4 P1 0 2 5 2 P2 5 1 0 5 P3 1 5 3 0 P4 3 0 3 3 Applying Bankers algorithm  show that  i) The following is a safe Allocation State  Process R0 R1 R2 R3 P0 2 0 1 1 P1 0 1 2 1 P2 4 0 0 3 P3 0 2 1 0 P4 1 0 3 0 ii) The following is an unsafe Allocation State    Process R0 R1 R2 R3 P0 2 0 1 1 P1 0 1 2 1 P2 4 0 0 1 P3 1 2 1 0 P4 1 0 3 0 (5+5+8)  B Level Syllabus R4    201  B3.4-R4: OPERATING SYSTEMS  Assignment 1. Try the following command sequence and write its output:    a) General Commands   :- man   logname  uname  who  who am i  tty   date cal  echo b) Directory Commands :- mkdir   cd   cd ..   pwd   rmdir  c) File Commands          :- touch   cat   rm  cp  mv   ln   ls   chmod   umask    wc d) Filter Commands        :- head   tail   cut  paste   sort  uniq   tr  cmp   comm   grep  e) Disk Commands          :- du   df f) Mathematical Commands :- bc   expr  factor Assignment 2.   a) why unix commands can be divided into internal and external commands? b) How to know a process is a zombie or orphan process? c) How can we obtain just day from date command. d) What is the significance of  tee  commands? e) How to find the version details of unix? Assignment 3.  d) Explore the filesystem tree using cd  ls  pwd and cat. Look in /bin  /usr/bin   /tmp  /etc. What do you see? e) Explore /dev. Can you identify what devices are available? Which are character-oriented and which are block-oriented? Can you identify your tty (terminal) device (typing who am i might help); who is the owner of your tty (use ls -l)?  f) Explore /proc. Display the contents of the files interrupts  devices  cpuinfo  meminfo and uptime using cat. Can you see why we say /proc is a pseudo-filesystem which allows access to kernel data structures?   Assignment 4. e) Convert the decimal number 192 to octal and hexadecimal using bc command. f) Run ps   the script command and run ps again . What is its output. Explain. g) Write a command to create following directory structure in one command:       DOEACCALEVELAL55 h) Create above  Directory Structure with permission 777.?  Assignment 5.               a) Write a command to delete a non-empty directory. b) What output will this command sequence produce ?         who | grep c ^$LOGNAME c) What is the difference between pipe ( | ) and tee command  explain with example.  Assignment 6. Using vi editor write commands to do the following d) Block Copy e) Block Move f) Block Delete  Assignment 7. Using vi editor  d) Two consecutive lines are combined into one .Which vi command is used to do so?  e) Write a command to move line number 1 10 after line number 25. f) In the middle of a file being typed you want to import the output of who command. How would you do so?  Assignment 8. Using vi editor  d) Write a command to undo last action. e) What is the purpose of  .exrc file? f) Write a command to create abbreviation  LU as Linux Unix. B Level Syllabus R4    202  Assignment 9. Write a shell script  a) To copy source file to destination file using CP Command b) To copy source file to destination file without using CP Command c) To append file f1 at the end of file f2. d)  To concate content of two files.  Assignment 10. Write a shell script that  a) Works as a calculator. b) Takes a number and Checks it is a prime or not. c) Finds factorial of the given number. d) Finds reverse of a given number. e) Finds the given No is Armstrong or Not. f) Generates Fibonacci series   Assignment 11. a) Write a shell script to wish good morning  good afternoon  and good night     as per the current system time.  b) Write a Shell script to send mail to all users on your System  c) Write a shell script to check validity of  the user  Assignment 12. a) Write a shell script that changes directory as specified by the user b) Write a shell script to find out no. of vowels from the file. c) Write a shell script to find out the biggest number from the given three numbers. Numbers are supplied as command line argument. Print error message if sufficient arguments are not supplied. d) Write a shell script for checking file have write(w) read(r) and execute permission or not. And also that file exists or not`  Assignment 13. c) We have a file emp.mast which consists of detail of employees in an organization   (Fields are emp_id emp_name dept_name basic_salary designation dob).Write a command to display name of employee who is not director. d) Write a command to display name and basic of each employee.  Assignment 14. f) Using at command submit a job at 7 pm. g) Using batch command submit a job at 7 pm.. h) Delete a job from at queue. i) Display the listing of jobs in at queue. j) Write  a command to kill a job.  Assignment 15. e) Write a command to display contents of a file emp.mast in sorted order on emp_id field. f) Write a command to display contents of a file emp.mast in sorted order on basic_salary  field. c )Write a command to display name of the youngest employee . d )   Write a command to create backup of current directory.  Assignment 16. a) Write a shell script to generate salary slip of employees (emp_id wise) in file emp.mast   by using following formula :           Net salary=Basic+DA+HRA+CCA-EPF.   b) Get student information of students and store them in a file. The students            information contains roll no.  name and marks of students. Write a shell           script to print name of top five students. B Level Syllabus R4    203  B3.5-R4: Visual Programming  Objective of the Course   To make the students to understand the  visual programming language concepts applied to a business environment including: form design  common form tool controls  input-process-output model  arithmetic operations and assignment statements  predefined object methods & functions  decision structures  looping structures  list controls  array and table processing  sub procedures and user-defined functions  and database programming. Implement application design specifications with a visual object-oriented  event-driven programming language.  Outline of the Course  S.No   Topic    Minimum No. of Hours   1. Introduction to .NET      04 2. VB .NET       05 3. Console Applications      05 4. Introduction to Windows Forms    05  5. Introduction to ADO.NET                05 6. Windows Forms and Controls in detail   04 7. Data Types and Base Class Libraries   05 8. Object Oriented Programming with VB.NET  08 9. Visual Inheritance      02 10. Mastering Windows Forms    02 11. ASP .NET       08 12. Themes and Master Pages    03 13. Managing State      04                        Lectures  =    60    Practicals  =     60   Total   =  120 Detailed Syllabus 1 Introduction to .NET  .NET framework  MSIL  CLR  CLS  Name spaces  Assemblies The Common Language Implementation | Assemblies | Metadata and Intermediate Language | Garbage Collection | Versioning and Side-by-Side Execution | The End to DLL Hell | Managed Execution | COM InterOp   2 VB .NET Language Features | Creating .NET Projects | NameSpaces | Data Structure and Language Highlights | Classes and Inheritance | Structured Error Handling | Exploring the Base Class Library | Compatibility with VB6 | The .NET Type System | Threads | C# 3 Console Applications When to use Console Applications | Generating Console Output | Processing Console Input 4 Introduction to Windows Forms Benefits of Windows Forms | Windows Forms compared to the classic VB 'Ruby' Forms mode | .NET Events | Visual Inheritance | Code-free re-sizing | Using ActiveX Controls B Level Syllabus R4    204  5 Introduction to ADO.NET Benefits of ADO.NET | ADO.NET compared to classic ADO | DataSets | Managed Providers | Data Binding  DataSets and XML | Typed DataSets 6 Windows Forms and Controls in detail The Windows Forms Model |Creating Windows Forms |Windows Forms Properties and Events |Windows Form Controls |Resizing | Menus | Dialogs | ToolTips 7 Data Types and Base Class Libraries Understanding .NET Data Types | Exploring Assemblies and Namespaces | String Manipulation | Files and I/O | Collections | The Microsoft.VisualBasic Namespace 8 Object Oriented Programming with VB.NET Creating Classes in VB.NET | Overloading | Constructors | Inheritance | Controlling scope and visibility | Dispose and Finalization | Debugging and Error Handling 9 Visual Inheritance Apply Inheritance techniques to Forms | Creating Base Forms | Programming Derived Forms 10 Mastering Windows Forms Printing | Handling Multiple Events | GDI+ | Creating Windows Forms Controls 11 ASP .NET Introduction to ASP.NET  Working with Controls  Using Rich Server Controls Accessing Data  Overview of ADO.NET | Connecting to Data | Executing Commands | Working with Data | Choosing an ADO.NET Provider | Configuration Overview | Using the Web Site Administration Tool | Programming Configuration Files | Encrypting Configuration Sections  12. Themes and Master Pages Creating a Consistent Web Site | ASP.NET 2.0 Themes | Master Pages Displaying Data  with the GridView Control 13. ManagingState Preserving State in Web Applications | Page-Level State | Using Cookies to Preserve State | ASP.NET Session State | Storing Objects in Session State | Configuring Session State | Setting Up an Out-of-Process State Server | Storing Session State in SQL Server | Using Cookieless Session IDs | Application State Using the DataList and Repeater Controls | Overview of List-Bound Controls |Creating a Repeater Control | Creating a DataList Control  Recommended Books:  1. Bradley  Julie C. and Anita C. Millspaugh. PROGRAMMING VISUAL BASIC 2008 Edition 7th Edition  Boston  MA: McGraw-Hill/Irwin   2. Professional VB. NET 3.0  Wrox publication by Bill  Billy  Tim  Kent and Bill Sheldon. 3. ASP .NET complete reference  publication Tata McHill. 4. Introducing Microsoft Visual Basic 2005 for Developers  Microsoft Publications 5. Professional ASP.NET 2.0   Wrox Publication Web Reference:    www.msdn.microsoft.com  B Level Syllabus R4    205  Model Question Paper B3.5-R4  VISUAL PROGRAMMING NOTE:  1. Answer question 1 and any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the same sequence.   Time: 3 Hours                                                                  Total Marks: 100   a) Explain the difference between Array and Array List. b) Explain the architecture of .NET and the Framework of .NET. c) Explain Operator Overloading by giving Proper Example. d) Explain Exception handling in VB.NET. e) Define Namespace. Give types of namespace with example. f) Give the difference between Out and Ref Parameter.  g) Define terms: CLR and CLS  (7x4) Q.2  a) Explain Visual Inheritance in VB.NET with example. b) How the below methods of sqlCommand class are differ from each other.  ExecuteNonQuery()  ExecuteReader()  ExecuteScalar() c) Explain events and delegates with example.  (6+6+6) Q.3  a) Explain Managed and Unmanaged Code in the .NET context with Example. b) Explain Split and Join String function in VB.NET with program code.  (9+9) Q.4  a) List out the steps to create a master page and the use of the master page. b) Explain the page execution of the ASP.Net and also explain which are the main events of page are occurred when page is requested.  (9+9) Q.5  a) Differentiate web server and HTML control in brief and list various navigation controls in asp.net. b) Write a menu driven program that behaves like calculator. Take three arguments from user Two numbers and one operator and display proper result. Use command line Arguments. Define exception called ExWrongInput to handle invalid input  also handle zero division exception c) Explain Function Overloading & Overriding.  (6+9+3) Q.6  a) What is the difference between a sealed  interface and abstract class? b) Differentiate cookies  Sessions and application objects of Asp.net. c) What is the use of the DataRelation class? Can I use DataRelation class with DataTable?  (7+6+5) Q.7  a) Explain Terms: .NET code Synchronization  Multithreading b) How Regular Expression is handled in .NET? Explain with code example. c) What is Virtual Function? Give syntax of declaring of virtual function in VB .Net. d) What is the significance of DataSet Class? Explain how to populate a DataSet using a DataAdapter.  (4+4+6+4) B Level Syllabus R4    206  Practical Assignment List Sr. no. Practical Week no. PART-1 .NET Framework 2.0 and Visual Studio 2005 1 Study of .NET framework with comparison of various framework versions. 1 2 Study of .NET Architecture with 1) Run time environment (CLR) 2) CSC 3) Garbage Collection 4) Common Type System (CTS) 1 3 Introduction to IDE Visual Studio 2005 and Explain about new features of 2005 compares to Visual Studio  2003 2 4 Study of language features and comparison of VB.NET and C#. 3 PART-2. Visual Studio 2005 C# 5 Write a program for Arithmetic Calculator using Console Application in C# & VB. 3 PART-3. Visual Studio 2005 Object Oriented Programming 6 Write a Program for explaining use of Overloading and Overriding  constructor and Destructor in Class with using methods and properties in VB. 4 7 Write a program for explaining events and Delegates in VB. 5 PART-4. Windows Forms VB.NET 2.0 8 Implement Windows Form based application using controls like menus  dialog and tool tip etc. 6 9 Implement Master Form with Windows application. 7 10 Implement concepts of Inheritance  visual inheritance and Interface in windows application. 8 11 Implement printing of GDI+ with windows application. 8 PART-5. ADO.NET 2.0 12 Study of comparison between ADO and ADO.NET. 9 13 Use Dataset  Data Reader  XML Reader & Data Sources (SQL  Object & XML) with Any Windows or Web Application. 9 14 Use Data Controls like Data List  Grid View  Detail View  Repeater and List Bound Control 10 PART-6. ASP.NET 2.0 15 Implement web application using ASP.NET with web control. 11 16 Write a code for web application to provide input validations using Input Valuators. 12 17 Create a Web application that illustrates the use of themes and master pages with Site-Map. 13 18 Create a Web Application in ASP.NET using various CSS. 13 19 Implement the concept of state management in a web application. 14 20 Implement code in ASP.NET that creates and consumes Web service. 15 21 Study of ASP.NET administration and configuration tool. 16 Guidelines for Practical List:  Here Considering all aims if we can use these as a features of any application  we can get implemented two projects or two small applications (Windows Application and Web Application) by incorporating all practical of respective stream. We would follow VB.NET as programming language. For ASP.NET use of VB script is preferable. Please go through the operating manner describe below in next page B Level Syllabus R4    207  Any Application Development is developed in three layers  1) User Interface    Windows Forms and Windows Form Controls  Master Forms   Web Controls with Skins  Master Pages  Themes  Skins etc. 2) Business Logic  Using Constructors  Events  Inheritance and required etc.  & for Web Application State Management  3) Database            ADO.NET with Data Controls and Reports Generation This can accomplish a 75% work for a Windows/Web Application.  Remaining work is testing and validating the Input  which is also included in the practical list. Polishing the application will remain only. Here we can ask them to work for past analyzed project also.   Example-1:  .Assume that a bank maintains two kinds of accounts for customers  one called as savings account and the other as current account. The savings account provides compound interest and withdraws as facilities but no chequebook facility .The current account provides chequebook facility but no interest. Current account holders should also maintain a minimum balance and if the balance falls below this level  a service charge is imposed. Create an abstract class Account that stores customers name  account number and type of account. From this derive classes cur_acct and sav_acct to make them more specific to their requirements. Include necessary member functions in order to achieve the following tasks.   a) Accept deposit from a customer and update the balance b) Display the balance c) Compute & deposit interest d) Permit withdrawal and update the balance e) Check for the minimum balance  impose penalty necessary and update the balance.   (Use Constructors  Properties  method overloading)  Generate various reports for the organization   there is a namespace bit.edu and under that namespace there are three namespace such as Admin  Account  and Computer. Under the admin namespace there is a class called CollegeReports and interface called Report and CollegeReports class implements the Report interface and Account class implements also Report interface in account name space and ComputerReports class also implements Report interface  Example-2  For Data Types  Expressions  Control Structures  Modifiers Exception Handling  We can give some application description as below.  A Program  it behaves like calculator. Take three arguments from user  two numbers and one operator and display proper result. Use command line Arguments. Define exception called ExWrongInput to handle invalid input  also handle DivideByZeroException and catch other necessary application exceptions.  B Level Syllabus R4    208  B4.1  R4: Computer Based Numerical and Statistical techniques  Objective of the courses   There is a vast amount of data being generated in all the fields of human activity. In order to use this data  one needs to organize and analyze it. The analysis of data is a scientific endeavor which needs knowledge of numerical techniques  probability and statistical methods. The numerical techniques offer computational frameworks to solve real-life problems. Probability theory provides a rational framework to deal with uncertainty which is ubiquitous. Further  probability theory also provides a foundational basis for statistical techniques.   This course attempts to familiarize students with much needed concepts from numerical analysis  probability and statistics.  A good grounding of these concepts is essential for better understanding of topics such as Mobile Communications  Performance Modeling of Computer Networks  Soft Computing  Pattern Recognition  Image Processing  Data Mining.                                                                                                  Outline of the course  S. No.                               Topic                                                  Minimum number of hours    I                NUMERICAL TECHNIQUES                                                      20  1.   Errors in Numerical Calculations                                                                   02 2.  Algebraic and Transcendental Equations                                                      04 3.  System of Linear Equations                                                                           05       4.  Interpolation                                                                                                   04 5.  Numerical Differentiation & Integration                                                          05  II      STATISTICAL TECHNIQUES                                                               40  1. Probability  Conditional Probability and independence                                 10 2    Random Variables (RVs) and Expectation           08 3.   Some Important Distributions                                                                        08 4.   Statistical Inference                                                                                       08 5.   Regression                                                                                                    06                                                                                            lectures          =         60                                                                                 Practical / tutorials    =          60                                                                                                       Total    =        120 Detailed Syllabus  NUMERICAL TECHNIQUES  1. Errors in Numerical Calculations  Errors and their Computation  A general error formula  Error in Series Approximation  2. Algebraic and Transcendental Equations  Bisection Method  Iteration Method  Newton  Raphson  Method  3. System of linear Equations   Solution of Linear Systems  Direct Method: Matrix Inversion Method  Gaussian Elimination Method  Method of Factorization  Iterative Method: Gauss-Siedal Method.  4. Interpolation    B Level Syllabus R4    209  Finite differences  Newton Interpolation Formula  Lagranges Interpolation Formula.   5. Numerical differentiation & Integration    Numerical differentiation: Maximum and Minimum values of tabulated function  Numerical Integration: Trapezoidal rule  Simpsons rule for numerical integration.    II     STATISTICAL TECHNIQUES  1. Probability  Conditional Probability and independence                            Motivation  Probability Models  Probability Axioms  Sample space having equally likely outcomes  Conditional Probability  Bayes formula  Independent events 2. Random Variables (RVs) and Expectation                 Introduction  Discrete RV  Distribution Function  Probability Mass function  Bernoulli     and Binomial RVs  Continuous RVs  Probability Density Function  Uniform RVs  Moments and Expectation  Jointly distributed RVs  Independent RVs  Covariance  and correlation  Expectation of Sum of  RVs  Markov and Chebyshev inequalities.  3. Some Important Distributions  Discrete Distributions: Binomial  Poisson  Geometric; Continuous Distributions: Uniform  Exponential  Normal and Gamma; Moments of these distributions  Central Limit Theorem and its applications.   4. Statistical Inference   Parameter Estimation: Random Sample  Statistic  Estimator  Unbiased  Method of moments  Maximum likelihood estimation;  Confidence Intervals: sampling from Normal Population  Distribution of the sample mean  Population variance is unknown; sampling from Bernoulli Distribution   Hypothesis Testing: Null Hypothesis  Alternative Hypothesis  tests on population mean  Hypothesis concerning two means  Goodness of Fit (Chi-Square test)    5. Regression  Introduction  Least squares regression curve  Square of mean prediction error  Least squares curve fitting  Coefficient of determination.  Note: Students should use any statistical Software like Excel  SPSS and MATLAB etc. while doing lab-work. They should develop programs using C/C++ for implementation of numerical and statistical procedures.  RECOMMENDED BOOKS: Main Readings  1. Sastry  S.S  Introductory Methods of Numerical Analysis  4th ed. PHI  2007. 2. Ross  S.M  A First Course in Probability  6th ed. Pearson  2006. 3. Trivedi  K.S.  Probability & Statistics with Reliability  Queuing  and Computer     Science Applications  PHI  2008. Supplementary Reading  1. Ross  S.M  Probabilty and Statistics for engineers and Scientists  4th ed.  Elsevier. 2. Pal  S  Numerical Methods- Principles  Analyses and Algorithms  Oxford University Press  2009. B Level Syllabus R4    210  B4.1  R4: Computer Based Numerical and Statistical techniques Model Question Paper NOTE:  1. Answer question 1 and any four questions from 2 to 7. 2. parts of the same question must be answered in sequence and together. TOTAL TIME: 3 Hours               TOTAL MARKS: 100  Q1. (a.) Find the relative error in q = x / y where x = 4.536 and y = 1.32  both x and y being correct to the digits given.         (b.) Of 300 business students  100 are currently enrolled in accounting and 80 are currently enrolled in business statistics. These enrollment figures include 30 students who are in fact enrolled in both courses. What is the probability that a randomly chosen student will be in either accounting or business statistics.       (c.) Find a real root of the equation   x3 + x2  1 = 0  on the interval [0 1] with an accuracy of 10-3. (d.) The probability density of the continuous random variable x is given by                                            1/5  for 2B Level Syllabus R4    211   3x +   y + 2z = 8  (b.) Given that f(0) = 1  f(1) = 3  f(3) = 55  find the unique polynomial of degree 2 or less which fits the given data? Find the bound on the error. (c.)  From the following table  find dy/dx at x = 0.1:      x   0.0  0.1  0.2  0.3  0.4     y 1.000  0.998  0.990  0.978  0.960.  Q3(a.) A box of fuses contains 20 fuses of which five are defective. If three of the fuses are selected at random and removed from the box in succession without replacement  what is the probability that all the three are defective?                                                                                                                                             (b.) Find the distribution function of the total number of heads obtained in four tosses of a balanced coin.                                                                                                                   (c.) State the central limit theorem. Also outline its importance.  4 (a.) The joint probability density function given by                    4xy  for  0 < x 0   x2>0                                                          0 Find the probability density of   Y=X1 + X2.     Q6. (a.) An oil company claims that less then 20% of all car owners have not tried its gasoline. Test the claim at the 0.01 level of significance if a random check reveals that 22 of 200 car owners have not tried the oil companys gasoline.                                              (b.) The mean life of a sample of 10 electric light bulbs was found to be 1 456 hours with standard deviation of 423 hours. A second sample of 17 bulbs chosen from a different batch showed a mean life of 1 280 hours with standard deviation of 398 hours. Is there a significant difference between the means of the two batches?                                          (c.) In partially destroyed laboratory record of an analysis of correlation data  the following results only are legible variance of X = 9 Regression equations     8 X -10Y + 66 = 0  40X-18Y = 214. What are (i.) the mean values of X and Y; (ii.) the correlation coefficient between X and Y and (iii.) the standard deviation of Y.                                                                              B Level Syllabus R4    212  Q7(a.) The variables X and Y are connected by the equation a X +bY + c = 0. Show that the correlation between them is -1 if the sign of a and b are all alike and +1if they are different.  (b.) Let X1  X2    Xn be a random sample from a distribution with mean  and variance 2. The sample variance is defined by   S2 =      Show that E[S2]  2. (c.) A programs average working set size was found to be 0  = 50 pages with a variance of 2 = 900 pages2. A reorganization of the programs address space was suspected to have improved its locality and hence decreased its average working set size. In order to judge the locality-improvement procedure  test the hypothesis:   H0:   =  0   versus   H1:    < 0.  B Level Syllabus R4    213  B4.1-R4 Computer Based Numerical and Statistical Techniques  Practical Assignments  Sr.No.  Write computer programs (Using C/C++) for  1 Cramers Rule   /    Quadratic Equation      2 Bisection Method 3 False Position Method & Secant Method 4 Newton-Raphson Method 5 Newtons Forward Difference  & Newtons Backward Difference Method 6 Lagranges Interpolation Method  7 Curve fitting   8 Gauss Elimination Method  9 Gauss Jacobi Method & Gauss Seidel Method 10 Trapezoidal  Simpsons 1/3 & 3/8 rule 11 Numerical differentiation using Newtons Interpolation 12 Eulers Method  4th Order Runge Kutta Method                                    13 Milnes Predictor-Corrector Method 14 Summarizing datasets ( Histogram  Sample mean  Mode  Median  Variance  Skewness and Kurtosis) 15 Recursive computation of sample mean and sample variance 16  Plot of pmf of sum of n i.i.d.  random variables to illustrate central limit theorem.    B Level Syllabus R4    214  B4.2-R4: PROFESSIONAL AND BUSINESS COMMUNICATION  Objective of the Course  This objective of this paper is to equip the student with Professional and Business Communication Skills so as to enable him to effectively communicate and present technical reports/presentations.  The course covers various forms of communications and processes  art of listening  building interpersonal networks  group and team communications  interview and presentation skills.  Outline of Course  S. No.   Topic Minimum number of hours 1. Introduction  02 2. Forms of Technical Communication 05 3. Communication Process 12 4. The Art of Listening 05 5. Interpersonal Network 05 6. Communication in Groups and Teams 08 7. Resumes and Interviews 02 8. Making Presentation  05 9. Technology in Communication                      08     10.     Internet Collaborative Tools            08  Lectures = 60 CaseStudy/seminars/ Presentations = 60 Total =  120 Detailed Syllabus  1. Introduction               02 Hrs. What is Communication?  Why Communication is Key to Success in todays Business?  Goals of Communication; Effective Communication;  Communication Competence  2. Forms of Technical Communication            05 Hrs. Technical Reports; Forms  Memos  Letters and emails; Graphics; Reports; White Papers;  3. Communication Processes                       12 Hrs. Oral Communication Techniques; Speaking in Public; Negotiating Skills; facilitator and Participant skills in meetings; Proper Business Writing; Email Etiquettes; Reading and Comprehension skills.  4. The Art of Listening                        05 Hrs. Benefits of Effective Listening; Hearing versus Listening; A Model of Listening; Gender Differences and Listening; Assessing Differences and Listening  Improving Your Listening Skills; How to talk so that Others will Listen; Body language. . 5. Interpersonal Work                                             05 Hrs. Defining Interpersonal Communication;  The Impact of Conversations on Relationships; Formal and Informal Communication; Vertical versus Horizontal Organizations; Communication Styles; Communication Climate; Job Productivity and Satisfaction at Work Place; Building Interpersonal Skills in the Workplace  Ettiquets  6. Communication in Groups and Teams                         08 Hrs. B Level Syllabus R4    215   The Elements of Successful Group Communication; Types of Small Groups Operating in an Organization; Demographic Variables that affect Group Life; The Group Decision Making Process; Tools for Effective Problem Solving;   Performing Effectively in Teams; managing Meeting mania;  How to Stand out at Someone elses Meeting  probing skills  Voice Characteristics in Articulate Speaking  Tone  Pitch  Rate of Speech and Volume  7. Resumes and Interviews                                      02 Hrs.  Introduction to Resumes; Cover Letters;  The Employment Interview; Surviving the Group Employment Interview; The Informational interview;  Mock Interviews  The Performance Appraisal Interview.  8. Making Presentations                                     05 Hrs. Facets of Professional Presentations; Understanding Your Audience and the Speaking Occasion; Managing Time; Establishing Your Presentation Goals;  Selecting the Best Format for your Presentation.     Brainstorming; Developing Logical Sequences for Your Messages; Supporting Ideas; Generating Appeals and gathering evidence; Setting and Achieving your Image Goals; Optimizing; your PERC-Quotient  Being spontaneous  Capturing and holding your audience's attention 09. Technology in Communication                08 Hrs. Communication Technology Today; Mobile Communication  Use of electronic gadgets (mobile phone  iphone  ipod  e-books etc) and etiquettes  Changing Role of Communication Technology in the Workplace; Communication Competence and Life-Long Learning; Human Technology and the Virtual Office;   10. Internet Collaborative Tools              08 Hrs Internet Tools of Networking  modern Software Tools for business communication; Web 2.0 Tools;; Innovation and Techno-Life in the next decade. Legal Issues & Electronic Business Communications RECOMMENDED BOOKS  MAIN READING  1 Kitty Locker and Stephan K.Kaczmarek  Business Communication  3rd Edition  Tata McGraw-Hill  2007. 2 Andrea Rutherford  Basic Communication Skills for Technology  Pearson Education. 3 Meenakshi  Raman and S.Sharma  Technical Communication (OUP)  2009.  SUPPLEMENTARY READING  1 J. Penrose et.  Advanced Business Communication  Thomson Asia Ltd.  2002.. 2 Internet Usage must be encouraged to learn the latest B Level Syllabus R4    216  B4.2-R4: PROFESSIONAL AND BUSINESS COMMUNICATION  Model Question Paper NOTE:  1. Answer question 1 and any four questions from 2 to 7. 2. parts of the same question must be answered in sequence and together. TOTAL TIME: 3 Hours               TOTAL MARKS: 100  1.                      (7 x 4) a) What are pre-interview preparations to be done? b) How to create effective resumes? c) Enumerate features of a good web site. d) Bring out the importance of ON-Line Help systems. e) Give salient etiquette of electronic communication  emailing and chatting f) Web 2.0 Tools and their relevance in social networking. g) How has PC become the most powerful tool of communication for the modern business?  2.                                                                                                                                  (8+5+5) a) Describe the various communication styles.  Illustrate by examples. b) What steps would you follow to improve your communication? c) How can you communicate clearly and effectively?  Highlight the use of body language.  3.                                                                                                                                  (8+5+5) a) What are the basic writing skills?  Give illustrations. b) Discuss the basic guidelines for writing effective business letters. c) How to write reports and structure memos? Write a sample of each. 4.                                                                                                                              (5+5+4+4) a) List the guidelines for improving the listening skills? b) Bring out reasons as to why it is important to practice effective listening techniques. c) What are the dos & donts of listening? d) How to make others to listen you? 5.                                                                                                                              (5+5+4+4) a) How to plan for a presentation?  Enumerate the features of a good presentation. b) How to organize a persuasive presentation? c) List the steps to analyze the audience before and during the presentation? d) How to handle questions effectively? 6.                                                                                                                                  (8+5+5) a) Discuss how one can be a good team player?  Assume you are a team leader  what strategies would you adopt to help your team work together more effectively and efficiently? b) How to conduct a negotiation?  How to establish your terms of agreement? c) Discuss the essence of communication technology in your workplace. 7.                                                                                                                              (5+5+4+4) a) What steps to follow to create first impressions and impact? b) How to understand the supervisor Styles? c) How to manage physical culture? d) How to avoid clashes during group discussion? 8.                                                                                                                                           18  Write an email to a customer apologizing for the delay in the shipment of a product and requesting an additional period of two weeks for delivery. B Level Syllabus R4    217  B4.2-R4: PROFESSIONAL AND BUSINESS COMMUNICATION  Assignments  1. (a)   What are the basic writing skills? Support your answer by   illustrations.  (b)   Bring out reasons as to why it is important to be good listener.  (c)   How can one an effcective team performer?  (d)   List some of the good negotiating skills.  (e)   What are the most common kinds of persuasive messages? 2. Enumerate the role of humour in oral communication. What kind of  humour is appropriate in business context. 3. State the differences between individual behavior and group behavior   and its implications for group related communication. 4. You have completed your doctorate in Computer Science. Prepare your            resume highlighting your academic achievements and suitability for a     teaching job.    5. Enumerate the features of a good power-point presentation. Give  reasons for the effectiveness of power-point slides.     6. Internet has transformed the entire business communication field.   How? 7. How has the modern communication technologies affected the job  productivity and satisfaction? Give examples in support of your  answer.   8. Explain the concept of virtual office. Is it a boon or curse? Justify. 9. Explain the common rules that should be kept in mind to achieve  success in job search. 10.  List the essential etiquettes which need be observed when corresponding via emails. 11. List the common Web 2.0 tools for social interaction. How has these tools contributed to make this world a flat world? 12. Discuss the role of ethics in electronic business communications and   dealings. 13. CASE STUDY  The Technical Writing Department of IIS Vision Pvt (Ltd.) needs new computer equipment. Currently  the department has outdated H/W and application S/W  with hardly any graphical capabilities. There is a great need of color printers and scanners. Video camera will also of great support for technical work. Due to these constraints  companys manuals  pamphlets and course material are not being liked/appreciated by the customers. Moreover  IIS  Vision has no web-site for product advertisement and/or company recognition on the internet. All this has led to a decline in profits.    As technical Writing Department Manager  you have consulted with your group members to set the situation right. As a team  you have decided the company needs to purchase the following H/W and S/W:   Five new PCs  Two laser prnters  MS-office  Graphics S/W  Scanner  Video camera             Draft a technical proposal to CEO of IIS Vision  giving justification for the purchase and installation of the equipment. Invent the required details.  B Level Syllabus R4    218  B4.3-R4 : OBJECT ORIENTED DATABSE MANAGEMENT SYSTEMS   Objective of the Course The Database Technology and Object Oriented Technology have joined together to form Object Oriented Database Technology.   The Object Oriented Database Management Systems  which have now become the order of the day  incorporate the Object Oriented features into Database Management.   This course initially dwells deep into Object Oriented Technology and subsequently surveys the database management features  which are to be integrated into Object Oriented Technology to evolve into Object Oriented Database Systems.  Also the practical exposure for OO support  provided by popular packages like Oracle  DB2  etc for OODB is included in this course.  Outline of Course  S No Topic Name Minimum no of Hours  1 Overview of object oriented concepts  05 2 Object oriented programming  05 3 Object oriented Data Model   05 4 Object orientation in Query Languages  12 5 Object oriented Database systems   15 6 Information Integration  15 7 Object database standards  03                   Lectures                                           60                  Practicals/tutorials                            60                 Total                                               120  Detailed Syllabus 1. Overview of Object Oriented Concepts                                                                               5 Hrs. Need for Object Oriented Programming : Procedural Languages  The Object Oriented Approach  Advantages of Object Oriented Programming. Characteristics of Object Oriented Languages : Objects  Classes  Inheritance  Reusability  New Data Types  Polymorphism and Over Loading.  2. Object Oriented Programming                                                                                               5 Hrs. An overview of C++ Programming/Smalltalk/Java  Loops and Decisions  Structures and Functions  Objects and Classes  Arrays and Pointers  Inheritance  Virtual Functions.    3.Object oriented Data Model:                                                                                                           5 Hrs.   OO Relationships  Relationship integrity  ER Diagramming models for OO Relationships  -  different notations  ( Coad/Yurdan notation  Shlaer/Meelor notation  OMT notation  UML notation  and Booch Notation)  Integrating Objects into a Relational Database.                      4.Object orientation in Query Languages:                                                                                 12 Hrs. Introduction to Object Definition Language (ODL)  Class declarations  attributes in ODL    Relationships in ODL  Inverse relationships  Multiplicity of relationships  methods and types in ODL.   Additional ODL concepts: Multi-way relationships in ODL  sub- classes in ODL  multiple Inheritance in ODL  extents  declaring keys in ODL. From ODL to Relational Designs   Object relational model  from relations to object relations  Nested relations  references  OO vs object relational  from ODL B Level Syllabus R4    219  design to OR designs.   Introduction to OQL  features of OQL  additional forms of OQL expressions  object Assignment and creation in OQL  user defined types in SQL  operations on objet-relational data  Ordering relationships on UDTs  5.Object Oriented Database Systems (including Object Relational Database Systems)           15  Hrs. Relational vs Object Oriented Database Systems :  Semantic Database Systems  Object Hierarchies - Generalization  Specialization  Aggregation  E-R model  RM/T  SDM  SAM  Daplex  IFO.  The architecture of Object Oriented Databases  Query Languages for OO Databases  Gemstone/O2/Orion/Objectstone  Object Relational Database Management System (ORDBMS) - Oracle 8i  9i  DB2.  Overview of object database systems: ORDBMS implementation and challenges  database design for an ORDBMS  OODBMS  ODMG data model and ODL  comparison of RDBMS  OODBMS and ORDBMS.   6.Information Integration :                                                                                            15 Hrs.           Semi- structured data:  Motivation for the semi-structured data model  semi-structured data representation  Information integration Vs semi-structured data. XML and its data model: semantic tags  well formed XML  document type definitions  using a DTD  attribute lists.  Modes of Information integration  wrappers in mediator based systems  capability based optimization in Mediators  Online analytical processing  data cubes  materialized views .   7.Object Database standards                                                                                        3 Hrs Basics of OODBMS terminology  understanding of types  inheritance  representing logical  Relationships  basic interface and class structure  declaring attributes  specifying relationships   Adding operator signatures and the complete schema.  RECOMMENDED BOOKS  MAIN READING   1. Jan L Harrington :  Object oriented Database Design clearly explained   Morgan Kaufman       publishers      academic press   2000. ( chapters  3  4  5   6 7 8 9 10) 2. Ramakrishnan and Gehrke: Database Management Systems  Third edition  International edition        Mc-graw Hill   2003.  (chapter 23 only)  3.  H Garcia Molina   J D Ullman and J Widom: Database Systems The complete book    Pearson         Education  2004.   ( chapter 4 and 9 only)   SUPPLEMENTARY READING 1. R. Cattel  Object Data management  (1993)  Addison-Wesely. 2. W. Kim  Modern Database Systems  (1995)  ACM Press  Addison-Wesely. 3. CSR Prabhu  Object Oriented Databases Systems : Approaches and Architectures  (1999) Prentice Hall of India.  Resource Website :  1. www.omg.org 2. http://www.service-architecture.com/object-oriented-database/index.html B Level Syllabus R4    220  B4.3-R4 : OBJECT ORIENTED DATABSE MANAGEMENT SYSTEMS          Model Question Paper NOTE :  1. Answer question 1 and any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the          same sequence. Time: 3 Hours                                                                      Total Marks: 100  1. Answer whether you agree with the following statements by marking  them either TRUE or FALSE.  Justify your answer in each case. a) Aggregation relationship between classes is transitive. b) Objects when passed as arguments to a method in C++ are             always passed by reference. c) C++ classes can be considered as abstract data types (ADTs). d) A class hierarchy described the has a  relationship among the              classes. e) Is it possible to use object embedding (i.e.  composite objects) to             realize the features of inheritance? f) Class diagrams developed using Boochs methodology can             serve as the functional specification of a system. g) Deep class hierarchies are signs of an object-oriented design             done well. (7 X 4)  2.  Consider the following Automobile Spare Parts Shop Automation Software (AAS)  which  is required by a retail automobile spare parts shop to automate various book keeping activities associated with its business.    The retail shop deals with a large variety of automobile spare parts procured  from various manufacturers.  The shop owner maintains different partsin wall mounted and numbered racks. At the end of each day  the shop owner would request the computer to generate indents for the items  which are out of stock.  The computer should print out the parts description  the quantity required and the address of the vendor supplying  the part.  The shop owner would have to simply put these printouts into envelops and courier them to the address printed.   Whenever new supplies arrive  the shop owner should be able to update the inventory.  Whenever any sale occurs  the shop owner would enter the code number of       the parts and the corresponding quantities sold.  AAS should print out the      cash receipt  maintain the cashbook and adjust the inventory.  The computer should also generate the revenue for any specified day and       Month when queried by the owner. Perform the following.  (You can make suitable assumptions regarding the details of various features of AAS software but you must clearly write down the assumptions you make). a) For implementing the AAS software identify the classes and their inter-relationships and               represent them using the notations of the Booch methodology. b) Write the class declarations and the method prototypes arrived part (a) of this question              in C++ syntax.  (10+8) B Level Syllabus R4    221  3.  a) What  is    the  difference  between  static  and  dynamic  service invocation             mechanisms in CORBA?  Comments on the advantages and disadvantages of each.  b)  What is the role of OMG (Object Management Group) in forming standards in  object-oriented technology?  What are some of its contributions in this direction?  c)  What is the role of IDL in CORBA-based application development?  Write an  IDL interface for a simple calendar  which can set the date and time of an  appointment  change the date and time of an appointment  delete an appointment   and query appointments for a given day.  (6 + 6 + 6)  4. a)         What is the difference b/w method overloading and method overriding ?  Give an             example to explain your answer. b) Write C++ code for the following description of the class/subclasses : Define an abstract base class GeomShape that has the following:  Data members for the (x y) co-ordinate position.  A constructor for initializing GeomShapes  A virtual method MoveShape()  A virtual method PrintShape() to output an object Derive subclasses GeomLine  GeomCricle and GeomTriangle  from GeomShape  and implement MoveShape() and PrintShape() methods for each of the subclasses. You may assume appropriate data-members for each of the subclasses.  You should use appropriate access controls in GeomShape.  c)  Make appropriate changes/additions to the above code to create several shapes of different types and to print them so that your code can be compiled and runusing a C++ compiler.  Identify abstraction  encapsulations and polymorphism from your code.           (6 + 8 + 4)  5. What are the limitations of the Relational Model ? What is the  motivation and advantages for semantic database models  and object oriented database models in comparison with  the relational model ? What are the object / entry type hierarchies  and explain their characteristics.                                                                                                              (18) 6.What are the main features of the various semantic database models and their relative  comparison of features ?                                                                                                          (18)  7.What are the comparative features of various prominent OODBMS products ?  Distinguish the capabilities  of OODBMS & ORDBMS products with examples.  (18)   B Level Syllabus R4    222  B4.3-R4   OODBMS  Practical Assignments  1. Prepare object diagram showing at least 10 relationships among the following object classes. Include association  aggregation and generalization. Object classes are School  playground  principal  school board  classroom  book  student  teacher  cafeteria  rest room  computer  desk  chair  ruler  door  swing  2. Prepare object diagram showing at least 10 relationships among the following object classes. Include association  aggregation and generalization. Object classes File System  File  Directory  File Name  and ASCII file  Executable File  Directory File  Disk  Drive  Track  and Sector  3. Draw the Class Diagram for Phone Call.  4. Draw the Scenario of Vending Machine.  5. Draw the State Diagram for Phone Call.  6. Draw the Event Trace for phone call.  7. Draw the State Diagram to withdraw cash from ATM Machine.  8. Draw the Data Flow Diagram for Cash withdrawn  Cash Deposit in Bank ATM.  9. Design and Create cube by identifying measures and dimensions for Star Schema             Snowflake schema. 10. Design and Create cube by identifying measures and dimensions for  Design storage             for cube using storage mode MOLAP  ROLAP and HOLAP. 11. Process cube and Browse Cube data a. By replacing a dimension in the grid  filtering and drilldown using cube browser. b. Browse dimension data and view dimension members  member properties  member property values. c. Create calculated member using arithmetic operators and member property of dimension member. Create and use Excel Pivot Table report based on data cube  B Level Syllabus R4    223  B4.4  R4 : COMPUTER GRAPHICS AND MULTIMEDIA SYSTEMS  Objective of the course This course aims to impart fundamental concepts of computer graphics and multimedia so that students are able to understand:   The basic concept of computer graphics  Algorithms to draw various graphics primitives  2D 3D transformations  Multimedia concepts and various I/O technologies and to enable the students to develop their creativity.  Outline of the Course S.No   Topic      Minimum No. of Hours   1.   Graphics Hardware  Primitives          5 2.  Basic Mathematical Concepts for Computer Graphics      7 3.  Graphics Operations Clipping  Filling     10 4.  Object Representation       10 5.  Transformation 2D  3D & Projections     14 6.   Multimedia Systems        14 Lectures  =    60 Practicals/Tutorials =     60 Total   =  120  Detailed Syllabus 1. Graphics Hardware  Primitives   Display devices  Refresh Cathode Ray Tube  Raster Scan Display  Plasma Display  Liquid Crystal Display  Plotters  Printers Input Devices  Keyboard  Trackball  Joystick  Mouse  Light Pen  Tablet and Digitizing Camera.  2. Basic Mathematical concepts for Computer Graphics  Matrices and Determinants. Operations related to Matrices and Determinants. Vectors : Definition    Vectors and Co-ordinate System Drawing algorithms  DDA algorithm  Breshenhams Line algorithm  Breshenhams Circle generation algorithm.  3. Graphics Operations   Clipping  Point Clipping  Line Clipping  Polygon Clipping. Sutherland-Cohen line clipping algorithm. Midpoint Sub-division algorithm.  Filling  Flood fill algorithm  Boundary fill algorithm and scan-line polygon fill algorithm.  4. Object Representation  B Level Syllabus R4    224  Polygon surfaces  quadric surfaces  spline representation  Hermite curve  Bezier curve and B-spline curve. Bezier and B-Spline surfaces. Basic illumination models  shading algorithms . 5. Transformation 2D  3D & Projections   2D Geometrical transformation -translation  scaling  rotation  reflection and shear transformation matrix representation and homogenous co-ordinates  composite transformations  transformation between co-ordinates.  3D Geometrical transformation  Representation of points  3D scaling  shearing  rotation  reflection  translation  multiple transformation  rotation about and axis parallel to a co-ordinate axis.  Projections : Parallel  Perspective and Isometric. Viewpoints  6. Multimedia Systems  Multimedia Terms  Hardware  Hardware peripherals  Basic tools in multimedia  Multimedia Building Blocks -Media Forms  elements  Sound  Image  Animation  Video  MPEG JPEG Graphic file formats  Multimedia Applications.  RECOMMENDED  BOOKS   MAIN READING   1. David F. Rogers and J. Alan Adams Mathematical Elements for Computer Graphics (Paperback) McGraw-Hill Science/Engineering/Math; 2nd edition (Pub Date: JUL-02) 2. Schaums Outline of  Theory and Problems of Computer Graphics (Paperback) by Zhigang Xiang & Roy A. Plastock  McGraw-Hill; 2nd edition (September 8  2000) 3.        Prabhat K Andleigh and Kiran Thakrar  Multimedia Systems and Design  PHI  2003 4.        Mark J. Bunzel and Sandra K. Morris Multimedia Application Development Mcgraw-             Hill  Osborne Media; 2nd edition (September 1993)  SUPPLEMENTARY BOOKS  1. Donald Hearn and M. Pauline Baker  Computer Graphics C Version  (Papaerback) 3rd Edition Prentice Hall (2002) 2. Rogers  Procedural Elements of Computer Graphics  McGraw Hill Pub  1997 3. Judith Jeffcoate  Multimedia in practice technology and Applications  Prentice Hall PTR; 1 edition (February 8  1995) 4. Bing J. Sheu and Mohammed Ismail Multimedia Technology for Applications Wiley-IEEE Press (June 22  1998) B Level Syllabus R4    225  B4.4  R4 : COMPUTER GRAPHICS AND MULTIMEDIA SYSTEMS  Model Question Paper NOTE : 1. Answer question 1 and any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the same sequence.  Time : 3 Hours       Total Marks: 100  1. a). Explain the two basic techniques for producing color displays with a CRT. b). What steps are required to fill a region using the boundary-fill algorithm method? c). Show that sum of the squares of the direction cosines of a line is equal to one. d). What are the transformation commands? e). What does scaling mean? Give an example f). What is a hidden surface? Why should it be removed? g). Write short notes on 3D- Graphics packages used in Animation. 7x4 2. a). Explain with diagram how video controllers in a raster scan devices perform  refresh operation. b). Find the inverse of the matrix A  =     1      2       3      4 c). Given the vectors A=I+2J and B=2I-3J  find (i) the length  (ii) the dot product and (iii) the angle  between the vectors. d). Find the equation of a circle passing through the three points P1(1 2)  P2(3 0) and P3(0 -4).          (8 3 4 3) 3.  a). Derive Bresenham circle algorithm with radius. b). Draw a flowchart illustrating the logic for the Sutherland-Hodgman polygon clipping algorithm.          (9 9) 4.  a). Clip the line with endpoints (0  60) and (60  120) against a window with  lower left corner and upper right corners (10  10) and (110  110) using  midpoint subdivision method.  b). Briefly describe clipping a polygon against a rectangular window c). Write a short note on Flood fill with illustration.    (9 5 4) 5. a). Explain the Bezier technique for generating curves with examples. b). Write short notes on matrix representation and homogenous coordinates c). Derive the transformation matrix  which reflects a point about an arbitrary line. Hence reflect (5 2) about the line y = x + 1. (9 4 5) 6. a). What is a Sound Card? Explain its working and principle. b). Describe any two multimedia file formats. c). What extra hardware or equipment is required to produce digital sound and video? (9 5 4) 7. Write short notes on the followings. a). Positioning feedback techniques b). Rotation in 3  Dimensional Transformation c). Back face removal (6 x 3) B Level Syllabus R4    226  B4.4  R4 : COMPUTER GRAPHICS AND MULTIMEDIA SYSTEMS  PRACTICAL LIST  Pre-requisite knowledge: Familiarity Graphics programming in C Computer Graphics: 1. Implement DDA Line drawing algorithm for line drawing. 2. Implement Bresenhams Line drawing algorithm for slope < 1 as well as slope >1. 3. Implement Bresenhams Circle drawing algorithm. 4. Implement Cohen-Sutherland Line clipping algorithm for 2D. 5. Implement Midpoint Sub-division clipping algorithm for 2D. 6. Implement Boundary fill algorithm for polygon filling. 7. Implement Flood fill algorithm for polygon filling. 8. Generate the Bezier curve. 9. In 2D  draw a Square (Edge: 100 pixels) on the left top corner of the screen. Move it to the centre of the screen. Convert it into rectangle such that Horizontal edge =2Vertical edge. 10. Implement 2D general pivot-point rotation and shear for a square.  B Level Syllabus R4    227  B 4.5-R4: Internet Technology and Web Services  Objective of the Course  The objective of this course is to provide insight into the technologies and applications used in Internet and web. This is an advanced course and the students are expected to be familiar with basics of computer communications  Internet and World Wide Web.  Contemporary technologies and protocols need to be studied in depth with a purpose to understand their purpose  specifications and implementation.  Exposure to students will also be provided through practical and tutorial exercises. Aim of this is to make students enable to become network system administrators.   The leading objectives of this course is to provide   Review of the Internet  its architecture and related Infrastructure including servers  network components and its applications  Comprehensive understanding about how internetworking is accomplished using major Internet protocols   An introduction to the World Wide Web services  Familiarization with scripting languages and their importance in development of web applications    Underline concepts relating to web service protocols  Learning of relevant concepts for development of multicast and multimedia networks  Key issues relating to information security   Need of Quality of service with regard to IP network and data protection Outline of Course SN Topic Minimum Hours 1. Review of Internet  Infrastructure and Architecture 04 2. Internetworking and major Internet protocols 09 3. World Wide Web 05 4. Scripting Languages  09 5. Open Source Initiative  Applications and Utilities 04 6. Web Service Protocols  08 7. Multicast and Multimedia  08 8. Security issues 08 9. IP Networks and Quality of Service  05  Theory Practical Total 60 60 120  Detailed Syllabus Hours  1. Review of Internet its architecture  TCP/IP architectural model: Evolution of Internet and its architecture; Internetworking; TCP/IP Protocol Stack; bridges  routers and gateways  Internet Protocol (IP)  IP Addressing  IP Datagram;  Introduction to IPv6  Methods of Delivery - Unicast  Broadcast  Multicast and Anycast. TCP/IP application protocols: Domain Name System (DNS)  File Transfer Protocol (FTP)  TELNET  Simple Mail Transfer Protocol (SMTP)  Multipurpose Internet Mail Extensions (MIME)  Simple Network Management Protocol (SNMP) and Hypertext Transfer Protocol (HTTP)  10 2. Web essentials Introduction to WWW  Client/Server architecture  3-Tier and n-Tier architecture  web browsers  web servers  4 3. Web technologies 10 B Level Syllabus R4    228  Common Gateway Interface (CGI)  Server-Specific APIs  Servlets  Java Server Pages (JSP)  SGML  Introduction to Hypertext Markup Language (HTML)  Extensible Markup Language (XML)  Active Server Pages (ASP)  4. Web programming: Java its components and overview  JavaScript  Java in the World Wide Web  Java Security  Distributed Objects; Client-side Scripts  Server-side Scripts; ActiveX; Visual Basic Script; Perl and PHP Script; Web Graphics - GIF Format  JPEG Format; Web Audio/Video - MP3  AVI and Quicktime  12 5.  Web Services Protocols       Protocols: Simple Object Access Protocol (SOAP)  Universal Description Discovery and Integration (UDDI) and Web Services Description Language (WSDL); UDDI Registry; Search for Web Services; Create Web Services 6 6. Multicast and Multimedia Multicasting  Internet Group Management Protocol (IGMP)  Multicast Routing Protocols  Real-Time Protocols RTP and RTCP  Voice over IP  ITU-T Recommendation H.323  Multimedia and its application constraints on Internet; Audio and Video on the Internet; Standardized data formats for multimedia; Multimedia Compression: JPEG  MPEG; Streamed Data Transfer; Virtual Reality; Animation 6 7. Open Source Initiative  Applications and Utilities Open Source Initiatives  its importance and philosophy  Linux  Apache  MySQL and PHP/Perl (LAMP). Apache Server  MySQL 4 8. Security issues         Proxy Servers; Firewalls; VPN; Data Handling and Forwarding; Data Storage; Errors in Identity; Web Services Security issues - Data Protection and Encryption  Authentication  Authorization  Non Repudiation and Signatures; types of security attacks and threats; Cookies; Passports and Web Tracking Work; Cryptography; Privacy and Digital Certificates 8 BOOKS RECOMMENDED  Main Reading  1. Data Communications and Networking    Behrouz A Forouzan  Tata McGraw Hill (11th Reprint 2008) 2. Web Technologies  A Computer Science Perspective  2nd Edition Jeffrey C Jackson  Pearson Education (Reprint 2009) 3. Web Technologies  TCP/IP Architecure and Java Programming  2nd Edition  Achyute S Godbole and Atul Kahate  Tata McGraw Hill 4. Eric Rosebrock & Others Setting up LAMP: Getting Linux  Apache  MySQL and PHP Working Together  Sybex  2004 Supplementary Reading 1. Sandeep Chatterjee  James Webber   Developing Enterprise Web Services: An Architects Guide  Prentice Hall  Nov 2003 2. Frank. P. Coyle  XML  Web Services And The Data Revolution  Pearson Education  2002. 3. Ramesh Nagappan   Robert Skoczylas and Rima Patel Sriganesh   Developing Java Web Services  Wiley Publishing Inc.  2004. 4. Derek Atkins et.al. Internet Security Professional Reference  Techmedia 5. Eric Newcomer  ""Understanding Web Services: XML  WSDL  SOAP  and    UDDI""  Addison-Wesley Professional  2002  B Level Syllabus R4    229  B 4.5-R4: Internet Technology and Web Services Practical List Assignment 1. Create your home page in HTML. In that home page provide links to         move toother pages like hobbies  educational info  personal info etc.  Assignment 2. Create html program to illustrate the use of frame and frameset tags of                          html.  Assignment 3. Using HTML controls create a student information form to collect      students information like name  address  phone  email  sex  birth  date  hobbies etc. Use appropriate controls. Assignment 4. Create page which demonstrates loops in java script.  Assignment 5. Create page which demonstrates the use of functions in java script  Assignment 6. Create page which demonstrates various events like mouse click  got focus   lost focus (blur)  change etc. Assignment 7. Using vbscript create various functions and sub routines to validate the data entered by user in form of program 2 (i.e. Student Information form). Assignment 8. Create an ASP page to display time on server  Assignment 9. Create an ASP page to illustrate the use of buffer property of Response object Assignment 10. Create an ASP page to illustrate the use of FORM collection of Request   object. Assignment 11. Create an ASP page to illustrate the use of QUERY STRING collection of   request object Assignment 12. Write an ASP page to print all Environment and Server variables.  Assignment 13. Create ASP/PHP pages to illustrate the use of cookies. ( Create cookie in one   page and read it in other page) Assignment 14. Create an ASP/PHP page to show your session id.  Assignment 15. Illustrate the use of session object to maintain users state                       information(ASP/PHP)  Assignment 16. Create a program to show the use of abandon and timeout methods of session   object.(ASP/PHP) Assignment 17. Create HIT counter for your ASP/PHP page using Application object  Assignment 18. Illustrate the concept of Global.asa file  Assignment 19. Illustrate the use of URLEncode and HTMLEncode methods of server object. B Level Syllabus R4    230  Consider following database for following program   Database: STUDENT.MDB  Table:  Login(username as text  password as text)       StudentMaster(id as number  name as text  age as number  phone as text  email as text)  Assignment 20. Create an HTML page for login and one asp page to validate the user.  Assignment 21. Create an HTML form to enter student information and one asp page to save    information in database table Assignment 22. Create an ASP/PHP  page to display information of all students in tabular   format. Assignment 23. Create an ASP/PHP page to search  delete or modify particular students                          information. B Level Syllabus R4    231  B4.5-R4: Internet Technology and Web Services  Model Questions  NOTE: The first question below is the compulsory.  Answer any four questions from 2 to 7.  PART - I 1.  Answer the following:        (7x4)  (a) How can a Router be used as a Firewall? (b) What is the purpose of the Time to Live field of the IP datagram? (c) What is VPN and why is it needed? (d) How essential is UDDI in the web services? (e) What is streaming video and audio? Briefly explain them.  (f) What are the features of Java that make it ideal for web programming? (g) What key components are required to run and develop PHP Web pages? Explain them briefly.  PART - II  2 (a) How does the three-way handshake work for creating a TCP connection?            6    (b) What is Internet? Describe the Architecture of Internet. Explain how a router works.                    6    (c) Discuss  how the files can be copied across the network with FTP. What is the primary difference between FTP and HTTP?               6  3 (a) Describe the steps involved when a Web browser requests for and obtains a Web page from a Web server.                 6  (b) What do you understand by Inter thread Communication?  Explain it.           6  (c) Swing is part of the Java Foundation Classes (JFC). Explain the features that Swing and the Java Foundation Classes provide.              6  4 (a) What is the transport protocol used to call a webservice? Explain briefly the key elements used for this protocol message along with the syntax rules applied.        9  (b) What are the Web Services Description Language (WSDL) document types? How do they assist with publishing and finding WSDL service descriptions in a UDDI Registry?                    9 5 (a) What is transport layer security? What are the threats from which it prevents an application to communicate across a network?             6  (b) What do you understand by the LAMP technology as Web development framework? What makes PHP more commonly used Server-side scripting language?           6  (c) How is the Internet Group Management Protocol (IGMP) used both by the client computer and the adjacent network switches to connect the client to a local multicast router? Explain the basic network architecture used to deliver a multicast service (like video) using IGMP.                 6 6  Describe briefly the purpose and functioning of the following Internet Servers        6x3 (i) Remote Access Server (ii) Domain Name Server (iii) Proxy Server 7 (a) How and what kinds of errors can creep into XML data? How can they be eliminated?                   6  (b) What is the output of the following JavaScript program? Explain why this output is produced?                     6  (c) How does HTML provide presenting data in tabular form? Explain with a suitable example by writing codes for 3x3 table with automatically adjusted table column width to contain the maximum width item in any column and border width of 5 pixels and rule width of 1 pixels.                       ( 6 ) B Level Syllabus R4    232  B5.1-R4: SOFTWARE PROJECT MANAGEMENT    Objective of the Course The course presents a new management framework uniquely suited to the complexities of modern software development.  The course provides a clear and provocative discussion of the economic  metrics and management strategies needed to plan and execute a software project successfully.  This comprehensive course also covers all the qualitative and quantitative aspects of project management with a practical treatment of many engineering and managerial issues.  At the end of the course  students will gain a practical framework for systematically improving the planning and execution of any software project.   Outline of Course  S. No.  Topic  1.  Review of software engineering concepts 2.  Software Process 3.  Introduction to Project Management 4.  Software Project Planning 5.  Project Economics 6.  Project Scheduling and Tracking Techniques 7.  Risk Analysis and Management 8.  Software Metrics and Project Management 9.  Project Control and Closure Minimum No. of Hours  04 04 04 08 10 06 06 08 04  10. Project Management Issues with regard to New Technologies       06                                                                          Lectures   60                                                                        Practical /Tutorials   60                                                                             Total 120  Detailed Syllabus 1. Review of software engineering concepts 4 Hrs.  Principles of software engineering  Features of good software  Quality Requirement in different Application Areas   2. Software Process 6 Hrs.  Software Process and Models  Tools and techniques of Process Modeling  Product and Process .B Level Syllabus R4    233  3. Introduction to Project Management 4 Hrs.  Definition of the project  Project specification and parameters  Principles of Project management  Project management life cycle   4. Software Project Planning 8 Hrs.  Project activities and Work Breakdown Structure (WBS)  Criteria for completeness in the WBS  Activity Resource Requirements and Cost  Joint Project Planning Session  Project Management Plan   5. Project Economics 10 Hrs.  Project Costing  Empirical Project Estimation Techniques  Decomposition Techniques  Algorithmic methods  Automated Estimation Tools   6. Project Scheduling and Tracking Techniques 6 Hrs.  Why are projects delayed? Effort Estimation Techniques  Task Network and  Scheduling Methods  Monitoring and Control Progress  Graphical Reporting  Tools   7. Risk Analysis and Management 6 Hrs.  Risk Concepts and Identification  Risk Assessment and Control  Risk Components and Drivers  Risk Tracking and Monitoring  Risk Mitigation and Management   8. Software Metrics and Project Management 8 Hrs.  Measures  Metrics and Indicators  Process and project metrics  Statistical Metrics and Process Monitoring  Function-point and project management   9. Project Control and Closure 4 Hrs.  Defect Collection and Audit  Causal and Pareto Analysis  Project Closure Analysis   10. Project Management Issues with regard to New Technologies 6 Hrs.  Object-oriented Methodology  Web-based Projects  Embedded Systems   RECOMMENDED BOOKS  MAIN READING   1. John J. Rakos  Software Project Management for Small to Medium Sized Projects  1998  Prentice Hall   ISBN: 0138261733. 2. Walker Royce  Software Project Management: A Unified Framework   2001  Addison-Wesley Professional  ISBN-10: 0201309580  ISBN-13:  9780201309584. 3. Pankaj Jalote  Software Project Management in Practice  2001  Addison-Wesley Professional  ISBN-10:0-201-73721-3  ISBN-13:  9780201737219.  B Level Syllabus R4    234  Note 1 : This course should be supported extensively by Web-based and CASE Studies.  Note 2 :This course will be supported by a project management software package  such as MS-Project.  SUPPLEMENTARY READING  1. Roger S. Pressman  Software Engineering: A Practitioner's Approach  7th Edition    McGraw Hill  ISBN: 0073375977. 2.  Ian Sommerville  Software Engineering  8th Edition  Pearson Education  2006. 3. A Guide  to  the  Project   Management  Body  of  Knowledge  (PMBOK Guide)    (4th Edition)  2008  Project  Management Institute  ISBN-13: 97819306994580.  B Level Syllabus R4    235  B5.1-R4 : SOFTWARE PROJECT MANAGEMENT  NOTE :  Time : 3 Hours                      Total Marks : 100  1  Do as directed:                      (7*4) [28] a)  State the meaning of a software quality and its quality attributes. b) Describe the meaning of Payback analysis in software projects? c) State the meaning of productivity  process and software process. d) Explain about defect density measures. e) What is the distinction between a WBS and a Process Model? f)  Justify  Non-critical project activities have time slacks g)  Explain the kind of team structure for small  medium and large software projects.   2  (a) Describe the software processes as per IEEE standard. [6]     (b) Explain the different stages of a project management life cycle. [6]     (c) Describe the role of project management plan. [6]  3  (a) How can we estimate the cost of a software? Explain COCOMO model. [8]     (b) Explain the role of Work Breakdown Structure (WBS) in managing the project activities. [6]     (c) Explain Pareto 80/20 rule. [4]   4  (a) Describe the challenges of automated regression testing in Agile Environment [9]     (b) Describe the factors behind the delay in a software project. [9]   5  (a) Draw a control flow graph and calculate McCabes Cyclomatic number for the following source code.  0. { 1.  a=1; 2.  while (aB Level Syllabus R4    236  (b) Consider the following activities for a certain software projects: [10]  Do the following:  Draw activity network representation of the project.  Find earliest start (ES) time  earliest finish (EF) time  latest start (LS) time  latest finish (LF) time and slack time (ST) for each activity.  Find the critical path. Activity no. Activity name Duration (days) Immediate predecessor 1. Requirement Specification 35 - 2. Database Design 25 1 3. GUI Design 30 1 4. Coding  30 1 5. Documentation 35 2 6. Integration 25 3 7. Testing 120 5 6 * * * B Level Syllabus R4    237  B5.1-R4 Software Project Management Practical Assignments 1. Study Software Project management basics concept. Define Case study project of any software system. With synopsis of it. 2. Study of Life cycle of a project using steps. Prepare rough project task list and plan for software project. 3. Case study for Roles played by the project Manager and various team members in Software project. Distribute the project work according to role of team members. 4. Software Time  Effort and Cost Estimation of given project using various methods. 5. Prepare Gantt chart (Task Entry) for project plan of software project with duration and create baseline and milestones. 6. Prepare PERT for project plan of software project with duration. 7. Prepare CPM for project plan of software project with duration. 8. Prepare list of resource in Software project task. Assigned resources to particular task. Enter respective entry in PERT  CPM and Gantt chart.  9. A Case Study on Risk management using given software project. 10. Track the project using recording actual duration or work done in each task of project. Enter data in Tracking Gantt chart wizard. 11. Generate various reports for all level of managers of Software Project for different milestone. 12. How Project fails: A Case Study on Common mistakes made during different phases of a project  13. Practical on Resource re-allocation & smoothing for resolving conflicts in Project schedule and resources. 14. Case study of various projects Management CASE tools and compare functionality with each other. B Level Syllabus R4    238  B5.2-R4: AUTOMATA THEORY AND COMPILER DESIGN  Objective of the course This course aims to impart fundamental concepts of theory of automata and compiler construction so that students are able to:   To study the basic concept of language and operation on it.  To study the regular language and finite automata to recognize it.  To study context free language and PDA to accept it.  To understand  design and implement a lexical analyzer.  To understand  design and implement a parser.  To understand  design code generation schemes.  To understand optimization of codes and runtime environment. And to enable the students to develop their creativity.  Outline of the Course S.No   Topic     Minimum No. of Hours   1. Review Of Mathematical Theory           5 2. Regular Languages And Finite Automata     6 3. Context Free Grammar (CFG) and PDA               10 4. Turing Machine (TM)        6 5. Basics of Compiler & Lexical Analysis     5 6. Syntax Analysis                 10 7. Syntax-Directed Translation       6 8. Dynamic Memory Allocation & Memory Management   6 9. Code Optimization And Code Generation     6 Lectures  =            60 Practicals/Tutorials =            60 Total   =          120 Detailed Syllabus  1. Review Of Mathematical Theory  Sets  functions  logical statements  proofs  relations  languages  Mathematical induction  strong principle  Recursive definitions.  2. Regular Languages And Finite Automata  Regular expressions  regular languages  applications  Types of grammar: 0  1  2 and 3  Automata with output-Moore machine  Mealy machine  Finite automata  memory requirement in a recognizer  definition  union  intersection and complement of regular languages  Non Determinism Finite Automata  Conversion from NFA to FA  Kleenes Theorem  Minimization of Finite automata.  3. Context Free Grammar (CFG) and PDA       Definition  Unions Concatenations And Kleens* of Context free language Regular grammar  Derivations and Languages  Relationship between derivation and derivation trees  ambiguity  Unambiguous cfg And Algebraic Expressions  Bacos Naur Form (BNF)  Normal B Level Syllabus R4    239  Form  CNF  Deterministic PDA  Equivalence of CFG and PDA  Context free language (CFL)  Pumping lemma for CFL. 4.     Turing Machine (TM) TM Definition  Model Of Computation And Church Turning Thesis  computing functions with TM  Combining TM  Variations Of TM  Non Deterministic TM  Universal TM  Recursively and Enumerable Languages  Context sensitive languages and Chomsky hierarchy.  5. Basics of Compiler and Lexical Analysis A Simple Compiler Difference between interpreter  assembler and compiler. Overview and use of linker and loader   types of Compiler  Analysis of the Source Program  The Phases of a Compiler  The Grouping of Phases  Compiler-Construction Tools.  The Role of the Lexical Analyzer  Input Buffering  Specification of Tokens  Recognition of Tokens  A Language for Specifying Lexical Analyzers  Design of a Lexical Analyzer Generator  Optimization of DFA-Based Pattern Matchers  6. Syntax Analysis The Role of the Parser  Context-Free Grammars  Writing a Grammar  Top-Down Parsing  Bottom-Up Parsing  Operator-Precedence Parsing  LR Parsers  Using Ambiguous Grammars  Parser Generators.  7. Syntax-Directed Translation Syntax-Directed Definitions  Construction of Syntax Trees  Bottom-Up Evaluation of S-Attributed Definitions  L-Attributed Definitions  Top Down Translation  Analysis of Syntax-Directed Definitions   Type Systems  Specification of a Simple Type Checker  Equivalence of Type Expressions  Type Conversions.  8. Dynamic Memory Allocation & Memory Management Source Language Issues  Storage Organization  Storage-Allocation Strategies  Access to Nonlocal Names  Parameter Passing  Symbol Tables  Language Facilities for Dynamic Storage Allocation  Dynamic Storage Allocation Techniques. 9. Code Optimization And Code generation  Intermediate Languages   The Principal Sources of Optimization  Optimization of Basic Blocks  Loops in Flow Graphs  Iterative Solution of Data-Flow Equations  Code-Improving Transformations  Data-Flow Analysis of Structured Flow Graphs  Efficient Data-Flow Algorithms  Symbolic Debugging of Optimized Code.  Issues in the Design of a Code Generator  The Target Machine  Run-Time Storage Management  A Simple Code Generator  Register Allocation and Assignment  The DAG Representation of Basic Blocks  Peephole Optimization  Generating Code from DAGs  Dynamic Programming Code-Generation Algorithm  Code-Generator Generators. RECOMMENDED BOOKS  MAIN READING  1. John C. Martin Introduction to Languages and Theory of Computation TMH; Third Edition 2. Alfred Aho  Ravi Sethi  Jeffrey D Ullman  Compilers Principles  Techniques and Tools  Pearson Education Asia  SUPPLEMENTARY BOOKS 1. Adesh K. Pandey An introduction to automata theory and formal languages  Publisher: S.K. Kataria & Sons. 2.         Deniel I. Cohen   Joh Wiley & Sons  Inc Introduction to computer theory. 3.  Allen I. Holub Compiler Design in C  Prentice Hall of India. 4.    J.P. Bennet  Introduction to Compiler Techniques  Tata McGraw-Hill  Second                Edition. B Level Syllabus R4    240  B5.2-R4: AUTOMATA THEORY AND COMPILER DESIGN Model Question Paper NOTE : 1. Answer question 1 and any FOUR questions from 2 to 7. 2.  Parts of the same question should be answered together and in the same sequence.  Time : 3 Hours       Total Marks: 100  1. a). Briefly describe the four main tasks of a lexical analyzer  b). Give a regular expression for the set of programming language floating point constants  where each such constant contains either a decimal point or an exponent part  e.g.  123.45  123e45  1.23e45. The strings 123. and .45 are not floating point constants for the purposes of this question. Ignore the possibility of negative constants or negative exponents.  c). Give a context-free grammar for the set of nonempty strings of as and bs that are palindromes  i.e.  that read the same forwards and backwards  e.g.  a  abba  bbababb. d). Describe a typical data structure used to implement a symbol table  and justify two main features of the data structure. e). What is the difference between top-down and bottom-up parsing? f). What is operator grammar? Define operator precedence parsing. g). Construct deterministic automaton for (0|1)*011 (7x4) 2. a). Consider the following grammar G=(T ={m n q $} NT ={S S0 A B C} S0 P). P :  (a) Compute the FIRST and FOLLOW sets for the non-terminals in G         b). Draw a NFA- for 010* + 0(01+10)* 11. c). Write a short-note on Universal Turing machine d). Briefly describe the two main tasks of a semantic analyzer. (8 3 4 3) 3.  a). For the following FA  use the minimization algorithm to find a minimum-state FA recognizing the same language B Level Syllabus R4    241  b). Construct a syntax-directed translation scheme that translates arithmetic expression from infix notation into postfix notation in which an operator appears after its operands.give the annonated parse tree for the input 9-5*2.            (9  9) 4.  a). Show that the following grammar is LR(1) but not LALR(1).  S -> Aa|bAc|Bc|bBa  A -> d   B -> d b). Explain code optimization technique in detail.  c). write a short note on Chomskys hierarchy of grammars (type 0 1 2 and 3).  Give salient comparative characteristics also.            (9 5 4) 5. a). Consider the following grammar:  E -> E+T|T  T -> TF|F  F -> F*|a|b  Construct SLR Parsing table for it. b). Let M1 and M2 be the two FAs as given below-Draw FA recognizing (L2-L1) where L1 and L2 are the two language corresponding to M1 and M2 respectively.      c). write a short note on Register allocation and Assignments.       (9 4 5) 6. a). Give transition tables for Push Down Automata (PDA) recognizing the following language  L = The language of all non-palindromes over {a b}. b). write a short note on LEX and YACC. c). write a short note on Primitive Recursive function and its examples.  (9 5 4) 10. Write short notes on the followings. a). Advantages of LR parser. b). NP Complete Problems. c). Recursively Enumerable Languages. (6 x 3) B Level Syllabus R4    242  B5.2-R4: AUTOMATA THEORY AND COMPILER DESIGN  Assignment 1.  Implement a program which accepts all strings in which both number of 0s and 1s are even using C language Assignment 2.  Convert following NFA to DFA.  Assignment 3.  Implement a program to implement simple lexical analyzer using C language.  Assignment 4.  Draw a DFA : 1(01+10)* + 0(11+10)*.  Assignment 5.  Implement a program for a predictive parser (grammar from the book).  Assignment 6.  Draw DFA for following: (010+00)*(10)* (0+10)*1* (0+00+)(1+10+100)*  B Level Syllabus R4    243  Assignment 7.  Implement RDP for a grammar. E->TE E->+TE | ^ T->FT T->*FT | ^ F->(E) | id  Assignment 8.  Write a program to eliminate left recursion from a grammar.  Assignment 9.  Write a program to left factor a grammar. Assignment 10.  Write a program that will find the FIRST SET of the grammar.  Assignment 11.  Write a program that will find the FOLLOW SET of the grammar.  Assignment 12.  Write a Lexical Analyzer using Lex or Flex utility of UNIX for following:  1. A lexer to print out all numbers from a given file. (Hint: By default lex reads from standard input). 2. A lexer to print out all HTML tags in a file. 3. A lexer which adds line numbers to the given file and display the same onto the standardoutput. 4. A lexer which attempt to extract only comments from a C program and display the same on standard output. 5. A lexer which replaces all the occurrence of rama with RAMA and sita with SITA. 6. A lexer to do the word count functions of the wc command in UNIX. It prints the number of lines  words and characters in a file. 7. A lexer which classifies tokens as words  numbers or ""other"". 8. A lexer that changes all numbers to hexadecimal in input file while ignoring all others. 9. This lexer prints only words followed by punctuation. If the following sentence was the input from standard input:  ""I was here""  they said.  But were they? I cannot tell.  It will print the words here  said  they  and tell. It will not print the punctuation; only the words. 10. Implement lexical analyzer for C language program.  Assignment 13.  Write a Parser using yacc or  utility of UNIX for following:  1. Write a Program for a simple desk calculator using YACC Specification and      Also implements the code that checks semantic error from string B Level Syllabus R4    244  B5.3-R4: Network Management & Information Security  Objective of Course  The objective of this course is to provide an overview of information security and network security and management. The course covers a broad range of security related concepts and issues that face industries today. The course will also examine the practical aspects of the issues involved in secure systems and networks and industry practices being adopted to protect information systems. Students will gain the knowledge  skills and abilities to incorporate good information security practice in any organization. 2   The following topics are addressed in this course: security requirements of information system assets  vulnerabilities  threats  risk management  authentication  access control  security policy models  network security  cryptography  digital signatures  network management  security protocols used in internet and e-commerce applications  technologies  applications and systems development and vulnerabilities assessment.  S.No   Topic      Minimum No. of Hours  1.  Introduction to Information Security     4 2. Identification & Entity Authentication     4 3.   Security Policy Design and Risk Assessment   6  4.   Cryptography        6  5.   Public Key Infrastructure & Message Authentication   8  6.   Network Security       8 7.   Network Management       8  8.   Web Security & Application Security     6 9. Firewalls        6 10.  Cyber Law          4   Lectures = 60       Practicals/Tutorials =  60                 Total  =  120 Detailed Syllabus  1. Introduction to Information Security      4 Hours  Security Goal Services  Attributes of Information Security  Authentication  Confidentiality  Integrity  Availability  Non Repudiation   Access control Threats & Vulnerabilities  Security attacks Unauthorized Access Impersonation Denial of Service   Malicious Software    Viruses  Worms  Trojan  spyware Security Mechanisms 2. Identification & Entity Authentication    4 Hours Definitions Types of authentication Password Authentication Password Vulnerabilities & Attacks  Brute Force & Dictionary Attacks Password Policy & Discipline B Level Syllabus R4    245  Alternate Approaches  Biometric authentication 3.  Security Policy Design and Risk assessment   6  Hours  Definition: Security Policy  Best practices in security Policy                    Formulate Security policy          Issue in Security Policy Implementation Risk Management   Risk analysis     Risk Assessment   Identification of assets   Identification of Threats to assets   Risk Calculation Incident Handling  Preparation  Detection of an Incident  Responding to an Incident  Recovering from an Incident  Building an Incident Response Team  4. Cryptography       6 Hours  Cryptography Basics  Plain Text  Cipher Text  Encryption Algorithm  Decryption Algorithm  Requirements for Cryptography Cryptanalysis and attacks Conventional Symmetric Encryption Algorithms  Symmetric vs Asymmetric  Block and Stream ciphers  DES  Double and Triple DES Stream Cipher: RC4 and RC5.  Cryptographic Modes  5. Public Key Infrastructure & Message Authentication  8 Hours  Public Key Cryptography Principles & Applications Algorithms RSA  Diffe-Hellman Key Exchange  DSS  Elliptic-curve One way Hash Functions  Message Digest MD5  SHA1 Digital Signatures Public Key Infrastructure (PKI)  Digital Certificates  Certificate Authorities  6. Network Security       8 Hours Overview of IPV4  OSI Model  Maximum Transfer Unit  IP  TCP  UDP  ICMP  ARP  RARP  DNS  Ping  Traceroute Network Attacks  Buffer Overflow  IP Spoofing  TCP Session Hijacking  Sequence Guessing  Network Scanning   ICMP  TCP sweeps   Basic Port Scans B Level Syllabus R4    246  IPSEC  IPsec Overview  IP security architectureAuthentication Headers  ESP    Internet Key Exchange (IKE)  Security Associations              Virtual Private Network: concepts   PPTP  L2TP 7. Network Management      8 hours  Network Management Architecture & Applications  Management Standards and Models Network Management Functions  Configuration  Configuration Management   Configuration Database & Reports  ASN.1 Network Management Functions  Fault   Management   Identification and Isolation  Security   Protecting Sensitive Information   Host and User Authentication SNMP v1  SNMP  v3  Structure of Management Information  Std. Management Information Base  Protocols Network Management Accounting & Performance Functions  Accounting Management  Performance Management  Network Usage  Metrics and Quotas  8. Web Security & Application Security    6 Hours   Web security Consideration  Secured Socket Layer and Transport layer security  Secured Electronic Transaction  Secured Mail Pretty Good Privacy (PGP)  S/MIME  9. Firewalls                  6 hours  Firewall Design Principles  Firewall Characteristics Types of Firewalls  Packet Filtering Router  Stateful Inspection Firewall  Application Level Gateway or Proxy  Circuit level gateway  Bastion Host Firewall Configuration  Screened Host Firewall System Screened Subnet Firewall System  10.  Cyber Crime and Cyber law     4 hours          Cyber crimes Crimes against the computer Crimes using a computer Indian IT Act 2000 B Level Syllabus R4    247  Objectives Provisions  Offenses and grey areas Recommended Reading  1. William Stallings  Network Security Essentials  First Indian Reprint  2000  Pearson Education Asia 2. Gollmann  Dieter  Computer Security  First Edition  1999  John Wiley & Sons Ltd. 3. Micki Krause  Harold F. Tipton  Handbook of Information Security Management  1999  Auerbach Publications 4. K.Mandia  Chris Prosise  Matt Pepe  Incident Response and Computer forensics  2nd edition  Tata Mc-grawhill  5. Simson Garfield  Web Security  Privacy Commerce  Second Edition  2002  OReilly Publications 6. Dr. R.K.Tiwari P.K.Sastri K.V.Ravikumar  Computer Crime and Computer Forensics  First Edition  2002  Select Publishers 7. Behrouz A. Forouzan   Cryptography and Network Security The McGraw-Hill Edition  2007   Recommended Web Sites  1. www.mit.gov.in - For IT Act details 2. www.cert.org 3. www.securityfocus.com 4. www.cerias.purdue.edu 5. www.ietf.org 6. www.w3c.org 7. www.sans.org 8. www.genome.wi.mit.edu/WWW/faqs/www-security-faq-html B Level Syllabus R4    248  B5.2  R4 NETWORK MANAGEMENT & INFORMATION SECURITY - I  1  a) Describe various attacks on communication across a network b) List out types of attach on encrypted messages. Also explain how the average time required exhaustive key search affected by key size. c) How does the anti replay service is implemented through AH Protocol? d) How a hash function can be used to provide message authentication without using a key? e) Discuss various fields in X.509 digital certificate. What is role of CA and RA while certificate creation process. f) Briefly Explain the operational description of  PGP g) Explain the various criteria for evaluating the security policy defined for an organization.  (7X4) 2  a) What is ASN.1 with respect to network management function? What is the purpose of ASN.1? Explain with the help of an example. b) Name the main component of the public key cryptosystem and formulate the security requirements. Discuss the use of the system for security and authencity. c) Briefly explain Elliptic curve cryptography  (6+ 9+3) 3  a) Explain the Digital Signature Standard (DSS) approach to digital signatures b) Perform the encryption and decryption of the plain text  M= 8 where  recipients  RSA public  key are (n=77 e =17). c) Give a detail description of single round of DES algorithm   (6+6+6) 4  a) What is the purpose of SNMP? An SNMP operation is performed using Protocol Data Unit (PDU)  basically a word for packet. List all PDU used and explain each of them. b) Discuss possible intrusion detection strategies. Clearly define two broad classes of strategies. What ate the advantages and shortcoming of the two strategies? c) Security policy can generally be subdivided into many categories  depending on their audience and scope. Explain each category with suitable example.  (7+7+4) 5  a) Explain the major issues in Security Policy implementation in organization. b) What is Role based access control? What are the advantages of using Role based access control over Mandatory access control (MAC) and Discretionary Access control (DAC)? c) Explain how two users can exchange secret key with confidentiality and authentication using public key distribution  (3+8+7) 6  a) List all the participants in the Secured Electronic Transaction (SET) System.  Briefly explain the the sequence of events that are required for a SET. b) Explain the implementation of Virtual Private Network c) Consider the following identification protocol  Peggy given her name to victor. Victor tossed an unbiased coin. If the coin comes up heads  victor accepts Peggy otherwise he rejects. Compute the False rejection and Acceptance rates. Is the protocol practical?  (7+7+4) B Level Syllabus R4    249  7  a) Is there any difference between conventional crime and cyber crime? Cyber crime may be broadly classified in three groups. Explain each of them. What precautions one has to take to prevent cyber crime in the society? b) What is a firewall? What is the difference between a Packet filter router and a   stateful inspection Firewall c) Discuss some grey areas of Indian IT act 2000.  (9+6+4)  B Level Syllabus R4    250  BE5.2-R4   Network Management & Information Security  Practical Assignments No. Aim Assignment 1 To implement Caesar cipher encryption-decryption. Assignment 2. To implement Monoalphabetic cipher encryption-decryption. Assignment 3. To implement Playfair cipher encryption-decryption. Assignment 4. To implement Polyalphabetic cipher encryption-decryption. Assignment 5. To implement columnar transposition cipher encryption-decryption Assignment 6. To implement Hill cipher encryption-decryption. Assignment 7. To implement Rail-Fence cipher encryption-decryption. Assignment 8. To implement diffie-hellman key exchange algorithm. Assignment 9. To implement RSA encryption-decryption. Assignment 10. To implement Triple DES encryption-decryption Assignment 11. Case study: Digital Signature Assignment 12. Case study: Java Security Features Assignment 13. Case study: Authentication in Kerberos security  Assignment 14. Case study: Windows 2000 active directory  B Level Syllabus R4    251  BE1-R4 EMBEDDED SYSTEMS Detailed syllabus OBJECTIVES:   To introduce students to the embedded systems  its hardware and software.  To introduce devices and buses used for embedded networking.  To explain programming concepts and embedded programming in C and C++.  To explain real time operating systems  inter-task communication. Outline of Course     S.No   Topic      Minimum No. of Hours 1. Introduction To Embedded System           10 2. Processor technology used in embedded system          10 3. Real time operating system (RTOS)                                 10 4. Programming embedded system        10 5. Techniques of connectivity and networking.            6 6. Interrupt service routines               7 7. Embedded application development             7 Lectures =          60        Practicals/Tutorials =           60       Total =               120  Detailed Syllabus 1.Introduction To Embedded System                      10  Embedded System Overview 1. Definition 2. Characteristics of Embedded Computing Applications. 3. Design Challenges.  Design Process 1. Requirement  2. Specification  3. Architecture Design. 4. Designing Of Components 5. System Integration.  Computer Essentials 1. Instruction Sets- CISC & RISC. 2. Memory Types- RAM ROM  UVROM  EEPROM  DRAM  Flash Memory  Hybrid Types. 3. Organizing Memory.  Microprocessor And Microcontrollers 1. Microprocessor 2. Microcontrollers Family. B Level Syllabus R4    252  3. PIC Microcontrollers.  Processor Technology 1.5.1   General Purpose Processor-Software. 1.5.2   Single Purpose Processor- Hardware. 1.5.3   Application Specific Processor.             1.6 Embedded System on Chip (SoC)              1.7 I/O Devices                   1.7.1   Timers and Counters                              1.7.1.1   Watchdog Timer.                    1.7.2   Interrupt Controller.                   1.7.3   DMA Controller.                   1.7.4   ADC and DAC.                   1.7.5   Infrared Devices.                   1.7.6   UART.                   1.7.7   Displays and Keyboards.  2. Processor technology used in embedded system     10      2.1 Memory system architecture 2.1.1 Caches 2.1.2 Virtual memory. 2.1.3 Memory management unit and address translation.     2.2 I/O subsystem                2.2.1 Busy-wait I/O.                2.2.2 DMA.                2.2.3 Interrupt driven I/O. 2.3 16/32 bit embedded processor and microcontrollers         2.3.1 CISC & RISC- 8051  Motorola 68HC11  ARM  Atmel 905xx series.         2.3.2 DSP processors. 2.4. Processor performance enhancement       2.4.1 Pipelining.        2.4.2 Superscalar execution and VLIW architecture. 3. Real time operating system (RTOS)                                                       10  3.1 Basic features of OS.        3.2 Task and Task States.       3.3 Semaphores.        3.4 RTOS architecture.      3.5 RTOS task enrollment.      3.6 RTOS scheduling. B Level Syllabus R4    253  3.6.1 Handling of task scheduling and latency and deadlines as performance metrics.            3.6.2 Co-operative round robin scheduling.            3.6.3 Cyclic scheduling with time slicing.            3.6.4 Rate monotonic co-operative scheduling.   3.6.5 Pre-emptive scheduling model strategy by a scheduler.   3.6.6 Critical section service by pre-emptive scheduler.   3.6.7 Fixed (static) real time scheduling of tasks.   3.6.8 Hard real time scheduling.  3.7 RTOS kernel.   3.7.1 Polled loop system.   3.7.2 Co-routines.   3.7.3 Interrupt driven system.   3.7.4 Multi rate system.  3.8 Process and Threads.  3.9 Synchronization and Interprocess communication   3.9.1 Shared data problem.   3.9.2 Use of semaphores.   3.9.3 Priority inversion problem.  3.10 Comparison and study of RTOS          3.10.1 VX WORKS.   3.10.2 PSOS.   3.10.3 QNX.  3.11 Criteria for choosing RTOS.            4. Programming embedded system      10    4.1 Programming languages.   4.1.1 desired language characteristics.   4.1.2 Introduction to object oriented programming.   4.1.3 Data typing -overloading and polymorphism.   4.1.4 Control.   4.1.5 Multitasking and task scheduling.   4.1.6 Timing specifications.   4.1.7 Run time exception handling.  4.2 Use of high level languages C  OOPS  JAVA for embedded systems.             4.3 Programming and run time environment.   4.3.1 Compiling  C program compiler and cross compilers.   4.3.2 Assembling.   4.3.3 Linking.   4.3.4 Debugging. B Level Syllabus R4    254   4.4 Program Validation and Testing. 5. Techniques of connectivity and networking.     6  5.1 Interfacing.   5.1.1 Memory interfacing.   5.1.2 I/O device interfacing.    5.1.2.1 Interfacing protocols.     5.1.2.1.1 GPIB.     5.1.2.1.2 FIREWIRE.     5.1.2.1.3 USB.     5.1.2.1.4 IrDA.  5.2 Infrared connectivity   5.2.1 IrDA and PIC microcontroller  5.3 Radio connectivity   5.3.1 Bluetooth.   5.3.2 Zigbee.   5.3.3 Zigbee and PIC microcontroller.  5.4 Controller area networks(CAN) and local area interconnect network(LIN).   5.4.1 CAN.   5.4.2 CAN and PIC microcontroller.   5.4.3 LIN.   5.4.4 LIN and PIC microcontroller.  5.5 Embedded System and Internet. 6. Interrupt service routines        7  6.1. Watch dog timer.  6.2. Flash memory basic toolset.  6.3 Hosts and Debugging.  6.4 Remote Debugging.  6.5 ROM emulator.  6.6 Logic Analyzer.  6.7. Caches.  6.8. Computer optimization.  6.9. Statistical profiling. 7. Embedded application development      7  7.1. Design methodologies   7.1.1 UML as design tool.   7.1.2 UML notations.   7.1.3 Requirement analysis and use case modeling.   7.1.4 Static modeling.   7.1.5 Object and class structuring. B Level Syllabus R4    255    7.1.6 Dynamic modeling.  7.2 Embedded Database Applications.  7.3 Voice over IP.  7.4 Mobile JAVA applications.  7.5 Design Examples-  Telephone PBX.  SET TOP box.  ATM system.  Washing machine. Recommended Books: Main book:- 1. fundamentals of embedded software where C and assembly meet by Daniel W. Lewis.  PHI  2002  2. Embedded system design: a unified hardware/software introduction  Frank Vahid   Tony Givargis  Wiley publishers  2003. Supplementary book:- 1. Designing embedded system PIC microcontroller by Tim Wilmshurst  Newness. 2. Embedded system design  CMP book  USA 2002. B Level Syllabus R4    256  BE1- R4  : EMBEDDED SYSTEMS  Model Question Paper Time : 3 Hrs.                                                                                       Maxmum Marks: 100 1.  Explain the following in brief- 1. Define system on chip (SOC) with an example. 2. Give any two uses of VLSI designed circuits. 3. Expand and explain GPIB. 4. What are the characteristics of PIC microcontroller? 5. Why do you need a cross compiler? 6. What are the advantages of building ISR queues? 7. Explain the objectives of Kernel. 8. What are the uses of semaphores? 9. What is the meaning of Task Service functions? 10. What are the queue related functions? 11. What is an embedded System? 12. Describe micro controller. 13. Explain Watch Dog Timer 14. Explain Inter Task Communication                                                     (14*2=28). 2.   a) Explain hardware timer and software timer.       b) Explain why single-purpose processors (hardware) and general-purpose processors            are essentially the same  and then describe how they differ in terms of design             metrics.        c) Briefly define each of the following: mask-programmed ROM  PROM  EPROM                  EEPROM   flash EEPROM  RAM  SRAM  DRAM  PSRAM  and NVRAM.                                                                                                                                   (6+6+6) 3.  a) Describes the salient features of ARM family processors.      b) How will you describe superscalar processing  pipelining  branch and data           dependency penalties? Explain a three stage pipeline. (4 + 2 = 6)      c) explain  by giving one example of each RISC and CISC processors.                                                                                                                                                  (6+6+6) 4.    a) Differentiate Real Time Operating System and Typical Operating Systems.         b) Explain a scheduler in which the RTOS inserts into a list the ready tasks for              sequential execution in a cooperative round robin model.         c) Explain the VX WORKS facilities in detail.                                              (6+8+4)  B Level Syllabus R4    257          5.    a) . Show how to extend the number of ports on a 4-port 8051 to 8 by using                       extended parallel I/O. Using block diagrams for the 8051 and the extended                       parallel I/O device   (i) Draw and label all interconnections and I/O ports. Clearly indicate the names and widths of all connections.  (ii) Give C code for a function that could be used to write to the              extended ports.                b) Define the following terms-                      i) linker.                     ii) locator.                     iii) debugger.                     iv) exception.             c) Explain the concepts of OOPS and describe how it is beneficial in                   programming of embedded systems.                                                         (7+6+5) 6. a)  Explain the difference between port-based I/O and bus-based I/O. b) How does the USB protocol provide for a device attachment   configuration  reset  reconfiguration  and bandwidth sharing with other devices and device detachment . c) Why does IrDA use a form of low level protocols  while Bluetooth employs security at the link level?                                                                                            (4+8+6) 7.      a) What are the advantages of using multiple function calls in cyclic order in the               main? Also write the advantages of building ISR queues?  (4+3)          b) What are the 15 points strategy must be taken into account for designing the code               for synchronization between the processes  ISRs  OS functions and tasks and for               resource management?  (7)           c) What is an emulator? What are the various components of an emulator? What                  are the advantages of  ICE.  (4)                                                                  8.       a) Give a brief note on Exemplary Applications of each type of Embedded system..            b) i) What are the characteristics taken into consideration when interfacing a device                    and a port?   (3)               (ii) What are the Sophisticated Interfacing features in Device Ports?  (3)          c) Why is UML used? Explain the various relationships with UML notation. Also                 enumerate the steps involved in modeling static and dynamic types.        (7)                                                                                                                                                                                            (5+6+7)                 B Level Syllabus R4    258  BE1-R4 Embedded System  Practical Assignments  1.  LED interfacing with Microcontroller 89S51.        2.  LCD interfacing with Microcontroller 89S51.  3. Keyboard interfacing with microcontroller 89S51.  4. Write C language codes in Keil IDE software.        5. Write C language codes in Keil IDE software.  6. Write C language codes in Keil IDE software.        7. Write C language codes in Keil IDE software.      8. a. To study directory structure of Fedora-Linux.         b. To study basic commands of Linux.         c. To study installation steps of Fedora-Linux.      9. Write and compile the C codes on Fedora-Linux. (At least 2          Application based C program which uses the structure  structure          Pointer  pointer and link-list)      10. To study the PRAYOG board for ARM Processor.   B Level Syllabus R4    259  BE2  R4 Artificial Intelligence and Neural Networks Objective of Course The main objective of the course is to provide insight into the artificial intelligence  neural networks and applications. This course will enable students to bring together an identifiable core of ideas  techniques  and applications that characterize the emerging field of Artificial Intelligence.   The course serves to introduce students about this critically important technology to increase their understanding of its implications  to pique their curiosity about the remarkable developments that are taking place and helps to familiarize students with many faces of Artificial Intelligence and Neural Networks. An overview covering introductory concepts  knowledge acquisition  representation  problem solving  search and control Strategies  LISP & PROLOG program languages  natural language processing and neural networks along with basic models and their applications are considered. With the new knowledge systems  students will be able to engage in intelligent activities such as tackling natural problems in a systematic way to provide effective and optimal solutions  and also conducting natural conversations with people and solving complex problems.   Course Description This course briefly introduces the basic techniques of artificial intelligence: problem solving  heuristic search  knowledge representation  logic system and inference  and also covers some application techniques such as planning  probabilistic reasoning  and intelligent systems. Students should survey and design some practical artificial intelligence applications in any information system domain. The course also introduces the concepts and theoretical groundwork about Artificial Neural Networks. The course topics include some of the neural network models  like perceptrons  feed forward networks  recurrent networks and self organization networks. Learning and training of different neural network paradigms is also included. Outline of the Course  Unit 1:    Introduction to Artificial Intelligence (AI) 4 Hrs. Unit 2:    Problem Solving  Search and Control Strategies  4 Hrs. Unit 3:     Heuristic Search Techniques 5 Hrs. Unit 4:    Knowledge Representation and Inference 9 Hrs. Unit 5:    Knowledge Acquistion and Updation 5 Hrs. Unit6:     Probabilistic Reasoning and Uncertainties 6 Hrs. Unit 7:    AI Programming 8 Hrs. Unit 8:    Natural Language Processing 4 Hrs. Unit 9:  Artificial Neural Networks 5 Hrs. Unit 10:  Neural Network Architectures 6 Hrs. Unit 11:  Learning Paradigms in Artificial Neural Networks 4 Hrs. Total Lectures  60 Hrs. Practical/Tutorials 60 Hrs. Total 120 Hrs. B Level Syllabus R4    260  Detailed Syllabus Unit 1: Introduction to Artificial Intelligence (AI) 4 Hrs. Natural and Artificial Intelligence Definitions of AI Nature of AI Solutions Testing Intelligence AI Techniques Testing Intelligence - Turing Test - Chinese Room Test Data Pyramid  Computer Based Information Systems in the Pyramid AI Applications Areas - Mundane Tasks  formal Tasks and Expert Tasks Unit 2: Problem Solving  Search and Control Strategies  4 Hrs. Problems and Problem Spaces Problem Characteristics Production Systems Control Strategies - Forward Chaining - Backward Chaining Exhaustive Searches and Blind Methods - Depth First Search - Breadth First Search Unit 3: Heuristic Search Techniques  5 Hrs. Introduction and Characteristics of Weak Methods Heuristic Search Techniques Generate and Test Hill Climbing Branch and Bound technique  Best First Search and A* Algorithm  Problem Reduction AND / OR graphs AO* Algorithm Constraint Satisfaction Problems Means Ends Analysis Unit 4: Knowledge  Representation and Inference 9 Hrs. Knowledge Representation (KR) - Formal KR (First Order Predicate Logic) - Procedural KR (Rule  Semantic Nets  Frames  Conceptual Dependency Scripts  and Semantic Web)  - KR  Issues and Limitations B Level Syllabus R4    261  Using Predicate logic  -Syntax and Semantics for FOPL -Properties of Wffs -Conversion to clausal form -Horn's clauses -Unification -Resolution Principles -Deduction Rules -  Unit 5: Knowledge Acquisition  and Updation 5 Knowledge Based Systems (KBS) Architecture  - Knowledge Base - Inference Engine - Explanation and Reasoning - Self Learning - User Interface Difficulties with KBS Development Process Knowledge Acquisition (KA) - Techniques - Role of Knowledge Engineer (KE) - Knowledge Sharing and Dealing with Multiple Experts - KA Issues and Limitations Knowledge Update - Update by KE - Update by Experts Self-Learning Unit 6:  Probabilistic Reasoning and Uncertainties 6 Hrs. Crisp and Fuzzy Logic Fuzzy Membership Functions Fuzzy Rule Based Systems Probability and Bayes Theorem Certainty factors Dempster-Shafer theory Non Monotonic Reasoning and Truth Monitoring Systems Unit 7: AI Programming  8 Hrs. Introduction to AI Languages like LISP  CLISP  PROLOG  Visual PROLOG  Artificial Intelligence Markup Language  Java Expert System Shell  etc.  Introduction to PROLOG Programming - Anatomy of PROLOG Program - Clauses: Facts  Goal  Variable  Predicates and Rules - Unification and Backtracking - Lists and Recursion - Arithmetic and Comparison - Fail and Cut Predicates B Level Syllabus R4    262  Unit 8: Natural Language Processing 04 Hrs. Introduction to Natural Language Processing Syntactic Processing Semantic Analysis Parsing techniques Context free grammar  Recursive Transitions Nets  (RTN)  Augmented Transition Nets (ATN) Case and Logic Grammars Unit 9: Artificial Neural Networks 05 Hrs. Introduction to Neural Computing and Artificial Neural Network (ANN) Fundamental Concepts   -  Biological Neuron   -  Artificial Neuron  Activation Function and Output Functions   -  Introduction to ANN Architectures   -  Applications of ANN Unit 10: Neural Network Architectures 06 Hrs. Hopfield Model  Parallel Relaxation Perceptron  Lineraly Separable Problems  and Fixed Increment Perceptron Learning Multi layer Perceptron  Non-Lineraly Separable Problems  and Back Propagation Learning Self Organizing Networks: Kohonens Networks Recurrent Networks Unit 11: Learning Paradigms in Artificial Neural Networks 04 Hrs. Objectives of Learning Hebbs Rule Delta Rule Supervised Learning Unsupervised Learning Recommended books  Main Reading 1. Akerker and Sajja  Knowledge-Based Systems  Jones and Bartlett  MA  USA  2009. 2. Clocksin  and C.S. Melish  Programming in PROLOG  Narosa Publishing House  Reprint 2002. 3. Dan W. Patterson  Introduction to Artificial Intelligence and Expert Systems  Prentice Hall of India  1990 4. Elaine Rich and Kevin Knight  Artificial Intelligence  Tata McGraw Hill Publishing Co. Pvt. Ltd.  1991. 5. Siman Haykin: Neural Networks  A comprehensive Foundation  Pearson Education  II edition  2001.  B Level Syllabus R4    263  Supplementary Reading 1. Jacek M. Zurada  Introduction to Artificial Neural systems  Jaico Publishing House   1994. 2. Nils J. Nilsson  Principles of Artificial Intelligence  Narosa Publishing House  New Delhi  Reprint 2002.  3. Robert J Schalkoff  Artificial Neural networks  McGraw Hill  1997. 4. Peter Jackson  Introduction to Expert Systems  Addison Wesley Publishing Company  1998.  B Level Syllabus R4    264  BE2  R4 Artificial Intelligence and Neural Networks Model Question Paper Answer Any Five Full Questions. [20 marks each]  Q1  A Give your own definition of Artificial Intelligence (AI) and justify it with suitable examples. Classify AI applications into different categories and explain it with proper examples.   [10] B What is a production system? List all component of a production system with one line description of each. [2.5]  a. Describe characteristics of AI systems in one to two lines. What types of solutions are offered by AI?  [2.5]  b. List techniques of testing AI systems. Explain any one in detail. [2.5]  c.      Draw data pyramid ad show computer based information systems in it. Also give major difference between the AI systems and non-AI systems. [2.5] Q2  A Explain Hill climbing technique for searching solution from the given solution space. Show working of the algorithm with sample data. What is the variation of the Hill climbing method called?  [10] B What do you mean by heuristic? Give an example of a heuristic function which can be utilized in AI based search. Explain role of the heuristic function in the search.  [10] Q3  A Explain planning using AI techniques by taking an example from the domain  Blocks Word.  [10] B (i) Differentiate weak method and strong method of AI searching. Also give a major difference between generate and test and random search methods. [5]  (ii) Explain backward chaining control strategy with example.  [5] Q4  A Draw structure of a knowledge based system.  Explain working of each component in brief.  [10] B  (i)       What are the difficulties associated with development of an intelligent   systems? List a few.  [5]  (ii)       Explain process of knowledge acquisition in detail. [5] Q5  A List components of a Script. Also write a script to visit to a dentist. [5] B Translate the following knowledge base into the predicate logic: (i) Jack and Jill are children. (ii) Everyone loves either a Jack or a Jill. (iii) Anyone who likes children has a friend. (iv) Everyone has a friend. (v) Anyone who has friend is healthy. [5] C Explain anatomy and main components of a typical PROLOG program. Also consider the following facts and rules:  (i) A fast car is fun.  (ii) A big car is nice.  (iii) A little car is practical.   (iv) Bill likes a car if the car is fun. What is the deduction from the above facts and rules according to PROLOG [10] B Level Syllabus R4    265  language?     Q6  A Define the term NLP.  Explain the various advantages achieved by utilization of it.  Also list the problems and limitations of it.  [10] B Briefly explain Bayesian method of probabilistic reasoning. Also discuss its limitations. [10] Q7  A Explain Minimax search procedure with a neat illustration. [10] B Explain perceptron. Draw perceptron that simulates the logical functions AND and OR. [10] Q8 A  Differentiate Supervised and Unsupervised learning methods. [5] B Explain the following terms: (i) Activation Function (ii) Self Organizing Network  (iii) Linearly Separable Problem (iv) Forward Pass and Backward Pass [5] C Explain back-propagation learning algorithm for multi layer perceptron.  [10]  B Level Syllabus R4    266  BE2-R4: AI & Neural Networks Practical Assignments 1. Write a Turbo Prolog program for your Family Tree. 2. Develop a medical diagnostic expert system. (Small model). 3. Enter the facts for the following predicates for a Turbo Prolog program   likes (person  drink)  enjoy (person  hobby) plays (person  instrument) And obtain answer to the queries at goal prompt for the following questions  Who likes wine?    Does anybody like wine?   Is true that nobody likes wine?  Who likes wine as well as enjoys playing cricket and piano.  Does anybody playing at least one instrument?  Who likes to play chess  drink coke but does not play any instrument.  Who share at least one hobby and at least one instrument?  Who are the person sharing common instruments but no hobbies are in      Common? 4. Write programs for performing the following operations on List. a. print member of a list b. write list c. membership d. add item e. append list f. delete from a list g. finding last element h. finding nth element i. reversing a list j. merge list k. finding sub list l. find max from a list m. permutation  5. Write prolog program to solve tower of Hanoi problem using recursion.  6. Write following programs demonstrating Recursion concept. a. Print number from 1 to 10 b. Reverse the number printed in (a) c. Find out sum of numbers printed in (a) d. Print the following pattern: 1 8 27 64 125 e. Find out factorial of a number 7. Write a program to implement generalized water jug problem: (having 2  Water Jugs of capacities 4 and 3 liters each and it is required to generate solution path leading to a water jug containing exact two liters of water)  8. Write a program to check whether a year is leap year or not. B Level Syllabus R4    267  9. Write a program to concatenate name and surname. 10. Write a program to generate Fibonacci series. 11. Create a database of students name  addresses  list of subjects and list of marks. Then for a given student calculate and display marks. 12. Write a program to check whether the number is less than 27 or not. 13. Write a program to display integer numbers from 1 to 100 on successive lines. However when  a number is divisible by 3 or 7  display  ""Buzz 3""  or Buzz 7"" respectively next to  the number. 14. Write a program to find out roots of quadratic equation. 15. Write a program to check the user name and password is valid or not. a. Give an opportunity to user to re-enter the password n no. of times  on entering wrong password b. Give an opportunity to user to re-enter the password three times  on entering wrong password. 16. Write a program that demonstrates use of arithmetic operators (menu driven). 17. Write a program that prints inorder  preorder and postorder traversal of a tree. 18. Explain Compound Object  fail and cut. WAP to store knowledge regarding employees of a company and display a list of employees whose birth-date is in current month. Employee (emp_id  name  b_date  address) 19. Study of neural network and Design Neural Network for Character recognition of English Alphabets. B Level Syllabus R4    268  BE3  R4 : E-BUSINESS   Objective of the Course  # To acquaint the participants with the basic knowledge of introduction to electronic business and role of independent third parties  regulatory environment  EDI  electronic commerce and the internet  internet security standards  electronic commerce payment mechanism and e-commerce applications.  # To gain an understanding of how information systems are devised and applied to create innovative business models among corporate and consumers. # To acquaint with the latest technology of electronic commerce such as web architecture  interoperable and secure information systems. # To develop elementary skills in developing an effective e-business solution architecture.  Outline of Course  S.No. Topic     Minimum No. of Hours  1. E-Business Models  05 2. E-Business Architecture  05 3. Planning On-line Business  10 4. Internet Security and Firewall Systems   06 5. E-Payment Systems                                                        06 6. Consumer oriented & Business Oriented E-commerce     08 7. Security in E-commerce E-Markets  10 8. Laws relating   to on line transactions                         05 9.     case studies                                                                 05   Lectures =  60  Practicals/Tutorials =  60  Total =  120 Detailed Syllabus  1.1.1.1.  E-Business Models                                                                                     05 Hrs. E-business:-characteristics  Drivers  Advantages  limitations  Problems of E-commerce. Categories of E-commerce :-Business-to-Business  Business-to-Consumer   Consumer-to-Business  Consumer-to-Consumer Models and impact of electronic commerce on business models. SCM 2.2.2.2.  E-Business Architecture                                                            05 Hrs. Internet and WWW as enablers of electronic commerce  Internet Protocol suite  brief history of Web  Web system Architecture  URL  overview of HTTP & CGI  Applet/Servlet  Client Server Architecture. 3.3.3.3.  Planning On-line Business                                                             10 Hrs. Types of Business models-Pure business model and Brick and Click Model  Difference between Brick and Mortar and E-commerce; which model is successful  Launching business on Internet : The Life cycle approach- Business planning and Strategising phase  Infrastructure phase  Design phase  Marketing phase  Fulfillment phase   Maintenance and enhancement phase Feedback phase   4.4.4.4.  Internet Security and Firewall Systems                                                06 Hrs. IPSec protocol  S-HTTP  Secure Socket Layer (SSL)  IP Spoofing  Firewall Systems  Packet Filtering Firewall  Application Level Firewall  and Circuit level Firewall.  5.5.5.5.  E-Payment Systems                                                                                     06 Hrs. SET Protocols  E-Check  E-Cash  Micro Payment Systems  Smart Card  Electronic Fund Transfer. The payment gateways.  B Level Syllabus R4    269  6.6.6.6.  Consumer oriented and Business Oriented E-commerce                              8 Hrs. Virtual Organizations: working  Benefits  Limitation; E-services:-E-retailing; On-line service sector banking  travel  stocktrading and investing  career  education  real estate  E-Auctions (C2C auctions  B2Bauctions)  Reverse Auction  entertainment. E-Government Procurement (EGP) .E-business Models.   7.7.7.7.        Security in E-commerce                                                                         10 Hrs. Threats to E-commerce  security  objectives of E-commerce security infrastructure  security controls  Encryption of Message using Cryptography  Data Encryption Standards  RSA  Public and private keys  Digital Signature  Digital Certificate. Certificate issuances  Certificate Authorities and Hierarchy 8.8.8.8.  Laws  relating   to on line transactions                                        05 Hrs. Intellectual Property-copyright  Patent  Trademark; Tort Law on Internet   Domain Name Disputes  Web Linking Disputes Product Liability Law  Encryption Laws  Legal disputes in B2C Internet based e-commerce    9.9.9.9.        Case studies                                                                                              05 Hrs.  RECOMMENDED BOOKS   Main Reading  1. Henery Chan  Raymond Lee  Tharam Dillon and E Chang  E-Commerce: Fundamentals and Applications  January 2002  John Wiley & Sons. 2. Sushila Madan  E-Commerce   4th Edition  Mayur Paperbacks Publication New Delhi.  Supplementary Reading  1. S J Joseph  P T  E- commerce: An Indian Perspective 3rd Edition  PHI  2. Kalakota and M Robinson  E-Business Roadmap for Success  2nd Edition  Dec 2000  Addison Wesley Professional.. . B Level Syllabus R4    270  BE3-R4: E-BUSINESS Model Question Paper Note: Question No. 1 is compulsory. Answer any FOUR questions from 2 to 6. Time: 3 Hrs.       Maximum Marks: 100 Q1. Give brief answer to the following questions: a) Explain the concept virtual organization. b) What is the difference between Applet and servlet? Give an example to explain it further. c) Explain the concept of Domain name. d) What is Smart card? e) Explain the difference between Reverse auction and Forward auction. f) Explain any two main functionalities of network firewall. g) What is a certification authority? State its importance in e-commerce.                                                                                                               (4*7)         Q2        a) What key indicators suggest that E-commerce is here to stay? Explain.                     (6)                                                                       b) How a Website can be promoted?                                                  (6)                                      c) Write a short note on cookie.                                                 (6)                                                                                               Q3 a) What is e-money? Differentiate between credit card and debit card.     b)Explain the advantages and disadvantages of online education from the point of university student.                                          (9x2)  Q4. a)  Explain how digital certificates help in verifying the identity of server by its clients. Explain various classes of digital certificates? Further explain the process of acquiring digital certificate.                (10)       b) What are different threats to e-commerce security?                   (8)         Q5.a) Describe the working of virtual organizations. Also state its pitfalls.                    (8)       b) How is copyright law is different from patent law?                    (5)       c) Explain Web system architecture.               (5)  Q6. a) Explain how web based marketing is different from traditional marketing. What are the various options available for marketing a product online? Explain each of them with an example.               (8)       b) Explain the scope of businessto-business model .            (5)       c)  Briefly explain SSL handshake protocol.                                (5) B Level Syllabus R4    271  BE3-R4 :   E-business  Practical Assignments 1. Explore the java classes related to digital certificates. 2. Create a digital certificate request using the software provided by a web server. 3. Case study on digital signature. 4. Design and implement Rc5 algorithm. 5. Design and implement RSA algorithm. 6. Case study on IP Security and IP spoofing. 7. Case study on paypal. 8. Case study on Google AdSense 9. Create banner using java applet 10. Create Java servlet which counting how many times the servlet is accessed. 11. Create java servlet to insert the values in the database table from the html form. 12. Case study on Service Oriented Architecture (SOA) 13. Case study on IT Act of India. 14. Case study on Internet Security. 15. Implement monoalphabetic cryptographic technique using java programming.  B Level Syllabus R4    272  BE4-R4: System Modeling and Computer Simulation  Objective of the Course  Models of most real systems are highly complex and analytically intractable. However  their behavior can be understood by resorting to simulation techniques  primarily based on discrete event system simulation. This course is designed to help students acquire basic skills in simulation techniques for solving problems in a wide variety of areas like management science  business  industrial  service  and computer science. This course will also give a brief exposure to modeling frameworks. In order to pursue this course a basic understanding of computer science  mathematics  Numerical Techniques  Probability and statistics is required.                                                            Outline of Course S.No. Topic                                                 Minimum No. of Hours 1 System models and System studies 04 2 What is Simulation? 06 3 Continuous System Simulation 06 4 Concepts in Discrete-event Simulation 06 5  Queuing Models       08 6 Simulation Software 06 7 Random Numbers and Non-Uniform random  variate   generation 08 8 Analysis of Simulation Data  04 9 Verification and Validation of Simulation Models 04 10 Simulation of Computer Systems and Manufacturing   Systems 08                                                                             Lecture = 60                                                                             Practicals/Tutorials = 60                                                                                  Total = 120 Detailed Syllabus 1. System models and System studies Concept of a System  Deterministic and Stochastic Activities  Continuous and Discrete Systems  System Modeling  Types of Models  Principles used in Modeling  Corporate Model  System Design.  2. What is Simulation? Technique of Simulation  The Monte-Carlo Method  Comparison of Simulation and Analytical Methods  Experimental nature of Simulation  Types of System Simulation  Numerical Computation Techniques for Continuous Models  Numerical Computation Techniques for Discrete Models  Distributed Lag Models  Cobweb Models.    3. Continuous System Simulation  Continuous System Models  Differential Equations & Applications  Feedback Systems  Simulation of an Autopilot  Interactive systems  Real Time Systems.  4. Concepts in Discrete Event Simulation The Event Scheduling / Time Advance Algorithm  World Views  Manual Simulation B Level Syllabus R4    273  using Event Scheduling  List Processing: Lists-Basic properties and operations  Use of arrays for List Processing  Using Dynamic Allocation and Linked Lists. 5. Queuing Models Characteristics of Queuing Systems  Arrival and Service Patterns  Queue Discipline  Long Run Measures of Performance of Queuing  Systems  Time-Average Number in System  Server Utilization  Costs in Queuing Problems  Steady State behavior of Infinite Population Markovian Models  Multiserver Queue: M/M/C//.  6. Simulation software                          Comparison of Simulation Packages with Programming Languages  Classification of Simulation Software: General Purpose vs Application Oriented Simulation Packages   Desirable Software Features: General Capabilities  H/w and S/w Requirements  Animation and Dynamic Graphics  Statistical Capabilities  General Purpose Simulation Packages  Object Oriented Simulation  Examples of Application-oriented Simulation packages  Simulation in GPSS.  7.Random Number  Non-Uniform random  variate Generation  and Monte-Carlo Method  Linear Congruential Generators  Testing Random Number Generators: Empirical and Theoretical tests  Non-Uniform  Random Variate Generator: Inverse Transform  Composition. Generating Continuous Random Variates: Uniform  Exponential  Gamma  and Normal. Generating Discrete Random Variates: Bernoulli  Binomial  Poisson.  Monte-Carlo Method: Evaluation of Integral-Hit or Miss Method.   8.Analysis of Simulation Data  Identifying the Distribution with Data  Types of Simulations with respect to Output Analysis  Stochastic nature of Output Data  Measures of Performance and their Estimation: Point  Estimation  Confidence-Interval Estimation  Output Analysis for Terminating Simulations: Statistical Background  Confidence-Intervals with Specified Precision  Output Analysis for Steady State Simulations  Variance-Reduction Technique-Antithetic variates.  9. Verification and Validation of Simulation Models  Model Building- Verification and Validation  Verification of Simulation Models  Calibration and Validation of Models: Validation of Model Assumptions  Validating Input-output Transformations  Input-Output Validation   10.10.10.10. System Simulation:  Case Studies  Manufacturing Systems: Introduction  Objectives of Simulation in Manufacturing  Simulation Software for Manufacturing  Modeling System Randomness: Source of Randomness  Machine Downtime. Computer Systems: Simulation Tools  Process Orientation  Event Orientation  High Level Computer System Simulation  CPU Simulation  Memory Simulation  RECOMMENDED BOOKS  MAIN READING  1. Banks  Jerry  Carson John S. II  Nelson Barry L. and Nicol David M.  Discrete Event        System simulation  4th Ed  Pearson Education  2005.  2.   Geoffrey Gordon  System simulation  3rd Edition  PHI  2009. 3.   Law.Averill.M: Simulation Modeling and Analysis  4th Edition        Tata- McGraw Hill  2008 .  B Level Syllabus R4    274  BE4-R4: - System Modeling and Computer Simulation                                    Model Question Paper Q.1 is Compulsory. Answer Any Four Questions From Q.2 to Q.7. Time: 3 Hours         Max. Marks: 100 Q-1   a) Name three principle entities  attributes and activities to be considered if you were to simulate operation of a cafeteria.  b) In the aircraft system  suppose the control surface angle y is made to be A times the error signal. The response of the aircraft to the control surface is found to be  Find the conditions under which the aircraft motion is oscillatory.  c) Draw a cobweb model for the following market:                             D = 12.4  1.2 P                             S = 8.0   0.6 P-1                               P0 = 1.0  d) Is the following table realizable for a finite buffer state-independent M/M/1 system? Why or why not? n                  0                 1                2               3                >=4         p(n)             0.4              0.3             0.2            0.1              0.0          e) Outline Hit or Miss Monte Carlo method to estimate pi ? Can you provide an error estimate?  f) State the major goals of manufacturing-simulation models. What are the common measures of system performance?  g) Describe briefly the features which are to be considered when selecting simulation software.  h) Compare validation in simulation to the validation of theories in physical sciences.     Q-2 (a) Give inverse-transform algorithm for generating random numbers from                                                         for  -1   x   1                                              f(x)   =                                                 0                      elsewhere  (b) Suggest an algorithm to generate Binomially distributed random variates with parameters n and p.  (c) What is antithetic sampling? How is it used in simulation studies?   Q-3   a) There are many possible measures of performance for queuing systems. Discuss some measures that are commonly used in the mathematical study of Queuing systems.  B Level Syllabus R4    275  b) For the single server queuing system  M/M/1  define L(t) to be the total number of customers in the system at time t and Q(t) denotes the number of customers in queue at time t.  i) Is it true that L(t) = Q(t) + 1? Why or why not? ii) Make the plot of L(t) vs t.     (c) Consider a physician who schedules patients every 10 minutes and who spends Si minutes with ith patient  where                                              minutes with probability 0.9                                                        Si   =                                                  12 minutes with probability 0.1                        Compute E[Si] and V[Si]. Find percentage of time in the long run the physician will be busy.   Q-4 (a)  Bring out the importance of list processing in system simulation.   (b)  Comment on the relative merits of manual vs computerized simulations.  (c)  Outline various steps  which guide a model builder in thorough and sound       simulation study. Q-5   a) When analyzing simulation output data  a distinction is made between transient and steady state simulations. Distinguish between two types of simulations.  b)      Consider a terminating simulation that runs over time interval [0 T] and results in observations Y1  Y2    Yn. How will you estimate                                                                =   and confidence interval for a fixed number of replications. Q-6 (a) The purpose of model verification is to assure that the conceptual model is reflected accurately in the operational model. Outline suggestions that can be given for use in the verification process.  (b)     As an aid in the validation process  a three-step approach has been widely discussed.   1. Build a model that has high face validity. 2. Validate model assumptions. 3. Compare the input-output transformations to corresponding input-output      transformations for the real system.      Describe each step in detail. Q-7 (a)          Consider a machine that operates continuously until a part jams; i.e.  it is never starved or blocked. Suppose that a part has probability p of jamming  independently of all other parts. What is the probability distribution of the number of parts produced before the first jam and what is its mean?  (b) Consider a machine that operates 24 hours a day for 7 days a week. The uptimes U1 U2 ... and downtimes D1 D2  are available but not the corresponding busy times B1 B2  Suppose  for simplicity  that an exponential distribution fits the Uis. B Level Syllabus R4    276  The average number of parts produced per-8 hour shift is known  as well as the average processing time for parts. Assuming that the exponential distribution is also a good model for the Bis  what mean should be used for a machine-breakdown model based on busy time?  BE4-R4: System Modeling and Computer Simulation List of Practical Assignments 1. Simulation of a major traffic intersection is to be conducted with the objective of improving the current traffic flow. Discuss problem formulation  setting-up of objectives and overall project plan  Model conceptualization and data collection.   2. Use Monte-Carlo method to estimate the size of the shaded area enclosed within the rectangular area of 1000 X 500 m2.    3. A bank has one drive-in teller and room for one additional customer to wait. Customers arriving when the queue is full  park  and go inside the bank to transact business. The times between arrivals and service time distributions follow:  Time between arrivals (mins) Probability Service time (mins) Probability 0 0.09 1 0.20 1 0.17 2 0.40 2 0.27 3 0.28 3 0.20 4 0.12 4 0.15   5 0.12   Simulate the operation of the drive-in teller for 10 new customers. The first of the 10 new customers arrives at a time determined at random. Start the simulation with one customer being served  leaving in queue. How many customers went into the bank to transact business? 4. A warehouse holds 1000 m3 of cartons. These cartons come in three sizes: Little- 1(m3)  Medium-2 (m3)  and Large- 3 (m3). The cartons arrive at the following rates: Little: every 10 +/- 10 minutes; Medium: every 15 minutes; and Large  every 8 +/- 8 minutes. If no cartons are removed  how long will it take to fill an empty warehouse?   5. Given the following distributions    Normal(10 4)  Triangular (4 10 16) B Level Syllabus R4    277  Uniform (4 16)  Find the probability that 6 < X < 8 for each of the distributions.  6.  Use the Linear-Congruential Method to generate sequence of random numbers with X0 = 27   a = 17  c= 43  and m = 100. Generate the sequence of Xi and corresponding random numbers Ri = Xi /m. Are these random numbers uniformly distributed?  7. Draw a cobweb model for the following market:                             D = 12.4  1.2 P                             S = 8.0   0.6 P-1                               P0 = 1.0  8. A torsional pendulum consists of a bar suspended from a spring that winds and unwinds as the bar oscillates up and down. If x is the vertical displacement and  is the angle the spring turns  the following differential equations describe the motion:  Assume the system starts from rest with x and  equal to zero. F(t) remains zero for all time and G(t) is 1 for t >= 0. Solve the equation for the following values:  a = e = 1       b = f = 40     c = g = 4.  9. The following data yield the arrival times and service times that each customer will require  for the first 13 customers at a single server system. Upon arrival  a customer either enters service if the server is free or joins the waiting line. When the server completes work on a customer  the next one in line (i.e. the one who has been waiting the longest) enters service.  Arrival Times: 12  31   63   95   99   154   198   221  304  346  411  455  537 Service Times: 40 32   55  48    18    50     47    18     28     54    40    72   12.      a) Determine the departure times of these 13 customers. b) Repeat (a) when there are two servers and a customer can be served by either one. c) Repeat (a) under the new assumption that when the server completes a service  the next customer to enter service is the one who has been waiting the least time.  10. A mouse is trapped in a maze and desperately wants out. After spending between 1 and 3 minutes  uniformly distributed  of trying  there is   30 % chance that it will choose the right path. Otherwise  it will wander around aimlessly for between 2 and 3 mins  uniformly distributed  and eventually end up where it started only to try once again. The mouse can try freedom as many times as it pleases  but there is limit to everything. With so much energy expended in trying and retrying  the mouse is sure to die if it does not make it within a period that is normally distributed with a mean of 10 mins and a standard deviation of 2 mins. Write a simulation that will estimate the probability that the mouse will be free. For the purpose of estimating the probability  assume that 100 miles will be processed by the model.  B Level Syllabus R4    278  BE5-R4: PARALLEL COMPUTING  Objective of the Course This course is aimed at providing students with a deep knowledge of the techniques and tools needed to understand todays and tomorrows high performance computers  and to efficiently program them.  Todays high performance computers range from expensive highly parallel shared/distributed memory platforms down to cheap local networks of standard workstations. But the problems associated with software development are the same on all architectures: the user needs to recast his or her algorithm or application in terms of parallel entities (tasks  processes  threads  or whatever) that will execute concurrently. Parallelism is difficult to detect in an automatic fashion because of data dependencies. In many cases  one needs to perform some form of algorithm restructuring to expose the parallelism. Finally  to realize the restructured algorithm in terms of software on a specific architecture may be quite complicated.  In this course we plan to cover and understand the nuts and bolts of developing parallel applications. For instance our study of Shared memory parallel architectures and programming with OpenMP and Ptheards  Distributed memory message-passing parallel architectures and programming  portable parallel message-passing programming using MPI. This will also include design and implementation of parallel numerical and non-numerical algorithms for scientific and engineering  and commercial applications. In addition we will study performance evaluation and benchmarking on todays high-performance computers.   At the end of the course the student will understand: 1. Basics of Parallel Computing 2. The impact of high-speed computation on current research  as well as the advancement of knowledge 3. Networking technology for support of high-speed computing 4. Taxonomy  models and architectural trends of parallel processing 5. General hardware (architecture) concepts  new technologies enabling the realization of such new concepts as well as details of commercially available systems 6. Performance measurement results on state-of-the-art systems  Outline of the course  S.No   Topic    Minimum no. of hours 1.        Parallel Computers-Introduction         06 Hrs 2.        Parallel Computer Architecture        10 Hrs 3. System Interconnection and Gigabit Network             10 Hrs 4. Parallel Programming                    06 Hrs 5. Performance Metrics and Benchmarks                  10 Hrs 6. Parallel Paradigms and Programming Models                 10 Hrs 7. Parallel Algorithms and Applications           08 Hrs       Lectures        60 Hrs     Practicals/Tutorials                  60 Hrs     Total          120 Hrs B Level Syllabus R4    279  Detailed Syllabus  1. Parallel Computers-Introduction            06 Hrs The Demand of Computational Speed  Types of Parallel Computers  Architectural Features of Message passing Multicomputer  Networked Computers As a  Multicomputer Platform  Potential for increased computational speed.  2. Parallel Computer Architecture            10 Hrs A Taxonomy of Parallel Architectures  Control Mechanism  Address-space Organization  Interconnection Networks  Processors Granularity ;SIMD Architecture : Overview of SIMD Architecture  Design and Performance Issues; MIMD Architecture : Shared Memory Architecture  Uniform and Non-uniform Memory Access Multi Processors  Parallel Vector Processors (PVP)  Symmetric Multiple Processors (SMP)  CC-NUMA  NUMA and COMA Architectures ;Distributed Memory Architecture : Cluster Architecture - Design and other Issues MPP Architecture 3. System Interconnection and Gigabit Network                  10 Hrs Basics of Interconnection Network  Network Topologies and Properties  Buses  Corssbar  and Multistage switches  Gigabit Network Technologies  Comparision of Network Technologies 4. Parallel Programming                         06 Hrs Paradigms and Programmability : Algorithmic Paradigms  Programmability issues Parallel Programming Examples; Parallel Programming Models : Implicit Parallelism  Explicit Parallel Models  Other Parallel Programming Models ;Shared Memory Programming  : The POSIX Threads (Pthreads) Model  The Open MP Standard ;Message-Passing Programming : The Message Passing Paradigm  Message Passing Interface (MPI)  Parallel Virtual Machine (PVM);Data Parallel Programming : The Data Parallel Model  The Fortran 90 Approach  Other Data Parallel Approaches   5. Performance Metrics and Benchmarks                   10 Hrs Performance Metrics for Parallel Systems: Run Time  Speedup  Efficiency Cost.; Scalability and Speedup Analysis: Amdahls Law: Fixed Problem Size  Gustafsons Law: Fixed Time  Sun and Nis Law: Memory Bounding  Isoperformance Models; System and Application Benchmarks : Micro Benchmarks  Parallel Computing Benchmarks  Business and TPC Benchmarks  SPEC Benchmark Family ; Performance v/s Cost  Performance of parallel Computers  Performance of Parallel Programs  6. Parallel Paradigms and Programming Models                 10 Hrs Parallel Programming Models: Implicit Parallelism  Explicit Parallel Models  Other Parallel Programming Models; Shared Memory Programming: The POSIX Threads (Pthreads) Model  The Open MP Standard; Message-Passing Programming: The Message Passing Paradigm  Message Passing Interface (MPI)  Parallel Virtual Machine (PVM); Data Parallel Programming: The Data Parallel Model  the FORTRAN 90 Approach  Other Data Parallel Approaches  7. Parallel Algorithms and Applications              08 Hrs Sorting Algorithms  Searching Algorithms  Dynamic Programming  Matrix Multiplication  Dense Matrix Computations  Sparse Matrix Computations B Level Syllabus R4    280  MAIN READING: 1. Kai Hwang and Zhiwei Xu  Scalable Parallel Computing  1997  McGraw Hill New York. SUPPLEMENTARY READING: 1. Barry Wilkinson and Michael Allen  Parallel Programming  1999  Pearson Education Asia. 2. Steven Brawer   Introduction to Parallel Programming 3. M. Shasikumar  Dinesh shikhare and P. Ravi Prakash  Introduction to Parallel  Processing. 4. V. Rajaraman and C. Siva Ram Murthy  Parallel Computers-Architecture and Programming  B Level Syllabus R4    281  BE5-R4: PARALLEL COMPUTING MODEL QUESTION PAPER NOTE: TOTAL TIME: 3 HOURS          TOTAL MARKS: 100                        1.  a) What are the representatives of Micro and Macro Benchmark suites? b) What there is need for sorting and searching parallel algorithm? c) Which factors can affect the scalability of a parallel system? d) What are the differences between SMP (Symmetric multi processor) and NUMA (Non-Uniform Multiple access)? e)  In parallel computing interconnection of computational devices play important roles. What are the basics network components? f)  What are parallel programming languages? g) What are the fiber channel interconnection topologies?  (7 X 4) 2. a)  Write a short note on PVM.  b) What is dense matrix computation? How it differs from sparse metric computation?  (10 + 8) 3. a) How is a networked computer providing platform form parallel computing? b)  Write a short note on networking topologies for interconnection network. c) How are latency and bandwidth metrics asses the performance   of          interconnection network system architecture?  (3+10+5) 4. a) What are the main features of Data-Parallel  Message-Passing and Shared-variable models? b) How performance of the parallel computers can be measured?   c) What is implicit parallelism in Parallel Programming model? How it can be applied to increase performance of parallel computing?  (5+5 +8) 5. a) POSIX Thread is parallel programming model? Explain the basic thread management primitives. b) Write a short note on: Types of Parallel Computers. (8+10)  6. a) How to achieve load balancing in parallel computing? b) What are the comparisons of three communication modes which exist in Message passing Models? c) What are the potentials for increasing computational speed? (3+7+8) 7. a) Define the following basic terms for interconnection networks.   1) Network Diameter   2) Bisection Bandwidth 1. Answer question 1 and any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the same sequence. B Level Syllabus R4    282    3) Crossbar Switches   4) Cell switches network b) Using fixed problem size  explain how metrics can be used to analyze and predict the scalability of parallel computer-program?  c) In parallel computing  how one can derive performance v/s cost?   (8+6+4)  B Level Syllabus R4    283  BE5-R4: PARALLEL COMPUTING  PRACTICAL ASSIGNMENTS Assignment 1.  Write a program which creates child process and prints its process Ids  Assignment 2.  Shared Memory Programming - I 1) Write a program to copy content of an array to another array using 2 processes 2) Write a program which performs Addition of 2 Arrays. 3) Write a program which performs Matrix Addition  Write a program that finds factorial of a number Assignment 3.  Shared Memory Programming  II 1) Write a program which performs Matrix Multiplication Write a program sum 1 To N using M process (Mutual Exclusion) Assignment 4.  Shared Memory Programming  III 1) Write a program to sum an array of N elements using self-scheduling  (Mutual Exclusion) Write a program to calculate Standard Deviation Assignment 5.  Shared Memory Programming  IV 1) Write a program to calculate Standard Deviation (Barrier) Write a program to create histogram Assignment 6. Thread-Based Implementation - I 1) Write a program to create and join Thread 2) Write a program to sum an array of N elements using loop splitting Write a program to sum an array of N elements using self scheduling Assignment 7. Thread-Based Implementation  II 1) Write a program to illustrate producer Consumer Problem Write a program to calculate Standard Deviation      Assignment 8.  Write programs which explain working of Expression Splitting  Assignment 9  Write a program to illustrate indirect scheduling.  Assignment 10  Write  programs which explain working of Induction Variable  B Level Syllabus R4    284  BE6-R4: DATA WAREHOUSEING AND DATA MINING Objective of the Course Data warehousing and data mining are the essential components of decision support systems for the modern day industry and business. These techniques enable the knowledge worker (analysis  manager  executive) to make better and faster decisions. The objective of this course is to introduce the student to various Data Warehousing and Data Mining concepts and Techniques. A database perspective has to be used throughout the course to introduce principles  algorithm  architecture   design and implementation  of data mining and data warehousing techniques. Outline of Course  S. No.        Topic Minimum No. Of Hours    1 Introduction and Background  06 2 Data Warehousing and OLAP 11 3 Data Mining Primitives 05 4 Concept Description: Characterization and Comparison 06 5 Association Analysis 06 6 Classification and Predictions 08 7 Cluster Analysis 06 8 Mining Complex Types of Data 09 9 Application of Data Warehousing and Data Mining 03 Lecture =     60 Practices/Tutorials =    60 Totals    =  120 Detailed Syllabus  1. Introduction and Background                              6 hrs  An introduction to multidisciplinary filed of data mining  Discussion on the evolutionary path of database technology that has led to the need for data warehousing and data mining  different kind of data on which data mining applied  classification of data mining system  Major issues in Data miming  Stress on important of its application potential.  2. Data Warehousing and OLAP                           11 hrs  Concepts of Data warehouse  deference between operational database system and data warehouse  Multidimensional Data Model: data cube  Stars  Snowflakes  Fact schemas for multidimensional database  measures  concept hierarchies  OLAP operation on multidimensional Data Model  Data Warehouse architecture  Types of OLAP servers  Life cycle of data warehouse implementation  Relationship between data warehouse and data mining. 3. Data Mining Primitives                              5 hrs  Data Preprocessing including Data cleaning - Data integration - Data transformation  Discretization and concept Hierarchy generation  Definition  and Specification of a B Level Syllabus R4    285  generic data miming task  Description of Data mining query language with few example queries. 4. Concept Description: Characterization and Comparison                         6 hrs  Introduction to concept description  Data Generalization and Summarization based characterization: Attribute Oriented Induction (AOI)  Efficient implementation of AOI  Analytical Characterization  Mining class comparison: Discriminating between Different classes  Mining Descriptive Measures in Large database. 5. Association Analysis                               6 hrs  Association rule mining  Mining Single Dimensional Boolean Association rule in truncation database  Mining multilevel association rule  Discussion on few association rule algorithm such as Apriori  frequent pattern growth  etc..  From Association rule to correlation analysis. 6. Classification and Predictions                             8 hrs  Issues regarding classification and predication  Different classification methods including Decision tree induction  Bayesian Classification  Neural network technology  K- Nearest Neighbor Classifier- Case-based Reasoning - Fuzzy set theory - genetic algorithm  Prediction: Linear and Multiple Regression  Nonlinear Regression  Other Regression Models  Classifier Accuracy 7. Cluster Analysis                               6 hrs  Types of data in cluster analysis  Partition based Clustering  Hierarchical Clustering  Density based Clustering  Grid based Clustering  Model based Clustering  Discussion on scalability of clustering algorithm  Outlier analysis  Parallel approaches to clustering 8. Mining Complex Types of Data                             9 hrs  Data mining issues in object oriented databases  spatial databases and multimedia databases  time series databases  text databases  web mining: web usage mining  web content mining  web log attribute.  9. Application of Data Warehousing and Data Mining                          3 hrs  Exploration of web sites on data warehousing and data mining application including bibliography databases  Corporate Houses and Research labs. Use of data mining packages and data warehousing packages  e.g. SAS  IBM  excel miner tools.   MAIN READING 1. Data Mining: Concepts and Techniques  Second Edition (The Morgan Kaufmann Series in Data Management Systems) Jiawei Han and Micheline Kamber  ISBN-10: 1558609016 ISBN-13: 978-1558609013; 2005 SUPPLEMENTARY READING 1. Arun K Pujari  ""Data Mining Techniques"" ISBN; 8173713804; ISBN-13: 9788173713804;978-8173713804; Universities Press. 2. M. Jarke  M. Lenzerni  Y. Vassiliou  and P. Vassiladis  Fundamentals of Data Warehouses  1st edition""; Year of Publication: 1999  ISBN:3540653651 Springer-Verlag New York  Inc.  Secaucus  NJ  USA. B Level Syllabus R4    286  3. Margaret Dunham  ""Data mining: Introductory and Advanced Topics"" ISBN-10: 0130888923  ISBN-13: 978-0130888921 Publisher: Prentice Hall; 1 edition (September 1  2002). BE6-R4: DATA WAREHOUSING AND DATA MINING Model Question paper NOTE:  TOTAL TIME: 3 HOURS                        TOTAL MARKS: 100  1.    a) What is (are) the motivation(s) behind knowledge discovery in database (KDD)? b) Give architecture of data warehouse. List out the components of data warehouse. c) What are the disadvantages of query driven approach? How to overcome those? d) Explain Data Discretization and Concept Hierarchy Generation. e) Explain the difference between Star schema and Fact constellation schema in terms of their usage. f) What do you men by noise? How to handle noisy data?  g) For what purpose Data Cube Aggregation and Dimensionality Reduction strategies are used.                       (7x4) 2.         a) Suppose the data for analysis include the attribute age. The age values for data tuple are: 13 15 16 16 19 20 20 21 22 22 25 25 25 25 30 33 33 35 35 35 35 36 40 45 46 52 70. 1. What are the mean  median and mode of the data. 2. Find first quartile (Q1) and third quartile (Q3) of the data. 3. Give the fine number summary of the data. b)  Suppose that a data warehouse consists of the three dimensions time  doctor and patient  and two measures count and charge 1. Draw a schema diagram 2. Give OLAP operations in order to list the total fee collected by each doctor in 2000? c) Why fact constellation schema data warehouse model is not suitable for data marts? Which process model is suited for designing data marts? d) How to calculate the measure value at a given point? Which kind of measures rank ( ) and median ( ) are? (6+4+4+4) 3. a) Which are the pattern interestingness criteria? Define support and confidence. For a company-X  min_sup is 10% and min_conf is 75%  while for another company-Y  min_sup is 20% and min_conf is 60%. For which of the two companies  the rule A B is more strong? Why?  b)       For class characterization  what are the major differences between a data cube based implementation and a relational implementation such as AOI? Discuss which method is the efficient & under what conditioned? c) What defines a data mining task?     (10+4+4) 4. 1. Answer question 1 and any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the same sequence. B Level Syllabus R4    287  a) Why is scaling important for clustering? Give the methods/expressions used for scaling the following types of variables:  Interval-scaled Variables  Ordinal Variables  Binary Variables  Nominal Variables  b) Market Basket Analysis is a kind of classification is this correct? If yes  justify  if no correct the statement & give the reason.  c)       Can a quantitative characterization rule and a quantitative discriminant rule be            expressed together in the form of the rule? Justify. d) When mining association rules  how can the data mining system tell which rules are likely to be interesting to the user?              (5+5+4+4) 5. a) Differentiate between clustering and classification. What are the similarities? Can we replace/use one in place of another? b) Briefly describe each type of CH with example. c) Explain the algorithm for inducing a decision tree from training samples. d) Where Attribute Relevance Analysis is used? How entropy based method is related to it? Explain in detail.             (5+3+3+7) 6. a) Consider the following data.               B             ~B   A       200            45 ~A         50          150 Find correlation between A and B.    b) Explain in detail with example 3-4-5 rule that is used to segment numeric data into natural intervals.  c) Where are supervised and unsupervised learning are used and what purpose do they serve? How to improve the accuracy of the classifiers?                                               (6+6+6)  7.    a)  Compare Bayesian classifier with Decision Tree and Neural Networks. b) Compare analytical characterization with relevance analysis and without relevance analysis. c) What is backpropagation? How does backpropagation work? How is it possible to understand what the backpropagation network has learned?                                                                                                                                           (6+6+6)  B Level Syllabus R4    288  BE6-R4 :Data Warehousing and Data Mining Practical List 1. Suppose that a data warehouse consists of the three dimensions time  doctor and patient  and two measures count and charge 1. Draw a schema diagram 2. Give OLAP operations in order to list the total fee collected by each doctor in 2000? 2. Propose an algorithm in pseudo code for the following. The automatic generation of a concept hierarchy for numeric data based on the equidepth partitioning rule. 3. Following is the sorted data for price (in Rs.)              40 80 150 210 210 240 250 280  340.  Partition the above data into equidepth bins.  Smooth the data by bin means and bin boundaries.  4. Consider the following transaction database:  TID                Item List  1                       1 2 5  2                       2 4  3                       2 3  4                       1 2 4  5                       1 3      6                       2 3  7                       1 3  8                       1 2 3 5  9                       1 2 4 Find the frequent pattern using FP Growth algorithm. 5. Major (x  science)  Status (x  undergraduate). Total 5000 students are there. 56% of undergraduate at the university  Major in Science. 64% students are registered in undergraduate program and that 70% students are majoring in the science. Compute the utility and certainty Major (x  Biology)  Status (x  undergraduate) [7%  80%]. Suppose 30% of the science students are majoring in biology. Then will you consider the above rule novel with respect to given rule. 6. Suppose that the data for analysis include the attribute age. The age values for the data tuple are: 13 15 16 16 19 20 20 21 22 22 25 25 25 25 25 30 33 35 35 35 35 36 40 45 46 52 70. a. Use min-max normalization to transform the value 35 for age on to 0-1 range b. Use z-score normalization to transform value 35  where std. Deviation is 12.94 yrs. c. Use normalization by decimal scaling to transform value 35 for age. 7. Which are the pattern interestingness criteria. Define support and confidence. For a company-X  min_sup is 10% and min_conf is 75%  while for another company-Y  min_sup is 20% and min_conf is 60%. For which of the two companies  the rule A B is more strong? Why? B Level Syllabus R4    289  8. There are nine transactions in the database: T100             I1 I2 I5 T200             I2 I4 T300             I2 I3 T400             I1 I2 I4 T500             I1 I3 T600             I2 I3 T700             I1 I3 T800             I1 I2 I3 I5 T900             I1 I2 I3 Generate candidate 3-itemset and frequent 3-itemset.  9.  Suppose a Data Ware Warehouse consists of three dimensions: - Time         - Doctor          - Patient    and two measures - Count       - Charge  where charge is the fee that a doctor charges a patient   for a visit. a) Draw a star schema diagram for above warehouse What specific OLAP operations should be performed in order to list the total fees collected by each doctor in 2006?  10. Write an algorithm for k-nearest neighbour classification given k and n  the number of attributes describing each sample. 11. Suppose that the university course database for Delhi University includes the following attributes describing students: Name  address  status (undergraduate/postgraduate)  major and GPA.  Propose a concept hierarchy for the attributes address  status  major and GPA. For each concept hierarchy  as proposed above  state the type of concept hierarchy. 12. Suppose that the following table is derived by AOI. Class Sales country Count  USA 180 Salesman Others 120  USA 20 Salesgirl Others 80 Transform the table into a cross tab showing the associated t-weights and d-weights.  13. A database has four transactions. Let min_sup=60 and min_conf=80%. TID Date Items_bought T100 02/02/08 {A B C E} T200 07/02/08 {A B C D E} T300 12/02/08 {A B D K} T400 23/02/08 {A B D} Find all frequent itemset using FP Growth. B Level Syllabus R4    290  BE7-R4: SOFTWARE TESTING AND QUALITY MANAGEMENT  Objective of the Course  This objective of the course is to make students aware about the importance of the software testing during software development. The course covered to be in line with the development tools and languages taught in this level. The course will prepare the student for software testing and debugging. It will further laid the foundation for advanced courses in Software quality assurances.  Outline of Course  S. No.   Topic Minimum number of hours 1. Introduction  02 2. Importance of Software Testing 04 3. Testing Techniques and Strategy 10 4. Verification and Validation 06 5. Building Test Cases and Plans 20 6. Quality Assurance and Standards 10 7. Debugging Technique and Tools 04 8. External Source of Errors 04 Lectures = 60 Practical/tutorials = 60 Total = 120     Detailed Syllabus  1. Introduction                  02 Hrs. Software program and its objective  Software development techniques  top-down verses bottom-up approach  modular and structures programming. A brief introduction about object oriented approach.   2. Importance of Software Testing                 04 Hrs. Software testing and its importance  software development life cycle verses software testing life cycle  Deliverables  version and error control   3. Testing Techniques and Strategy               10 Hrs. Unit testing  Integration testing  System testing  Acceptance testing White-Box testing: Flow Graph notation  Cyclomatic Complexity  Graph matrices  control structure and loop testing.  Black-Box testing: Equivalence partitioning  Boundary Value Analysis  Orthogonal Array testing.  4. Verification and Validation                06 Hrs. Requirement verification  Coding standards  Walk through  Formal Inspection  Design validation and verification  Function test  Design metrics  correctness proof and its requirement.   5. Building Test Cases and Plans                 20 Hrs. Format of test cases  Du  dc and other data paths  Test data selection  branch coverage  statement coverage  pre-condition and post-condition  Test schedule and check pointing  suitable exercises for creating test cases for each type of techniques mentioned in para 3.   6. Quality Assurance and Standards                  10Hrs. Basic software quality parameters and its metrics  Software Configuration Change and types of errors  Quality management models: ISO  SPICE  IEEE  CMM  B Level Syllabus R4    291  7. Debugging Technique and Tools               04 Hrs. Integrated development environment  debugging  tracing  data inspection  exception errors  code and data redundancy  unreachable code.   8. External Source of Errors                04 Hrs. Main memory  conflicting dll and unknown interface as source of error and their rectification. Note: Any open-source Software Tools may be utilized  such as winrunner.  RECOMMENDED BOOKS  MAIN READING  1. Desikan S  Ramesh G  Software Testing  Pearson Education  2008. 2. Tamres L  Introducing Software Testing  Pearson Education  2007. 3. Mathur A.P  Fundamentals of Software Testing  Pearson Education  2008. SUPPLEMENTARY READING  1. Brian Marick  The Craft of Software Testing  Pearson Education  2008. 2. Rajani & Oak  Software Testing : Methodology  Tools and Processes Tata McGraw-Hill  2007. 3. R. Pressman  Software Engineering  6th Edition  Tata McGraw-Hill. B Level Syllabus R4    292  BE7-R4: SOFTWARE TESTING AND QUALITY MANAGEMENT  Model Question Paper NOTE:  1. There are two part in this paper  TOTAL TIME: 3 Hours               TOTAL MARKS: 100                  (PART ONE -40; PART TWO-60)   PART ONE (Answer ALL Questions; each question carries ONE mark) 3. Each question below gives a multiple choices of answers. Chose the most appropriate one. 3.1 Verification is:  a) Checking that we are building the right system b) Checking that we are building the system right c) Performed by an independent test team d) Making sure that it is what the user really wants 3.2 A regression test: a) Will always be automated b) Will help ensure unchanged areas of the software have not been affected c) Will help ensure changed areas of the software have not been affected d) Can only be run during user acceptance testing 3.3 Which of the following could be a reason for a failure 1) Testing fault 2) Software fault 3) Design fault 4) Environment Fault 5) Documentation Fault    a) 2 is a valid reason; 1 3 4 & 5 are not b) 1 2 3 4 are valid reasons; 5 is not c) 1 2 3 are valid reasons; 4 & 5 are not d) All of them are valid reasons for failure 3.4 Test is prioritized so that:  a) you shorten the time required for testing b) You do the best testing in the time available c) You do more effective testing d) You find more faults 3.5 Which of the following is not a static testing technique  a) Error guessing b) Walkthrough c) Data flow analysis d) Inspections 1. There are TWO PARTS in this Module/Paper. PART ONE contains FOUR questions and PART TWO contains FIVE questions. 2. PART ONE is objective type and PART TWO is descriptive type. Time allotted for PART ONE is one hour.  3. Maximum time allotted for PART ONE is ONE HOUR out of the maximum time of three hours for the entire paper. B Level Syllabus R4    293  3.6 During which test activity could faults be found most cost effectively?  a) Execution b) Design c) Planning d) Check Exit criteria completion 3.7 The purpose of requirement phase is  a) To freeze requirements b) To understand user needs c) To define the scope of testing d) All of the above 3.8 The process starting with the terminal modules is called - a) Top-down integration b) Bottom-up integration c) None of the above d) Module integration 3.9 The inputs for developing a test plan are taken from  a) Project plan b) Business plan c) Support plan d) None of the above 3.10  Inspections can find all the following except  a) Variables not defined in the code b) Spelling and grammar faults in the documents c) Requirements that have been omitted from the design documents d) How much of the code has been covered 4. Each statement below is either TRUE or False. Identify and mark them accordingly in the answer book.                                                                                                                                  4.1 In information technology  we often build products requirements/specifications which although documented not true quality needs of our customers. 4.2 Our products must be corrected so that they will eventually meet our customers' true quality needs.  2.3 Can produce products at our convenience and at any cost 2.4 Quality is not an attribute of product 2.5 Quality is not a binary state 2.6 Quality need not be defined in quantitative terms in order to be measurable. 2.7 Quality can be controlled only if it is measured. 2.8 Non conformance must be detected as early as possible measured. 2.9 High defect prone products and processes are identified testing the product after all processes are over. 2.11   0% of all defects are attributable to incorrect ineffective processes.   3.      Match words and phrases in column X with the nearest in meaning in column Y                   X Y  3.1 A process of selecting test cases/data by identifying the boundaries that separate valid and invalid conditions a) Quality Assurance  3.2 It is based upon graphical representation of the program process b) Software Configuration  3.3 The input domain of the system is partitioned into classes of representative values  so that the no of test cases can be limited to one-per-class  which represents the minimum no. of test cases that must be executed. c) CMM-Managed B Level Syllabus R4    294   3.4 A planned and systematic set of activities necessary to provide adequate confidence that requirements are properly established and products or services conform to specified requirements  d) Data flow modeling  3.5 Foundation for continuing improvement and optimization of process e) Boundary value    Analysis  3.6 The nodes represent the data objects. The links represent the transformations that occur to translate one data object to another. f) Equivalence testing  3.7 Computer programs (source code and executables)  documentation (technical and user)  data (internal and external to programs)   g) Unit Testing  3.8 Brainstorming meeting  whose goal is to identify the problem  propose elements of a solution  negotiate different approaches  and specify a preliminary set of solution requirements h) Black Box  3.9 Iis the process of testing each software component individually using stubs and/or drivers. i) Control Flow Analysis  3.10 A technique in which the input domain is divided into classes of equivalent data items j) Facilitated application specification technique (FAST). 4. Fill in the blanks in 4.1 to 4.10 below  by choosing appropriate words and phrases given in the list below:           (a) Quality control (b) Design  (c) Management cycle (d14  (e) Customer (f)  Acceptable quality level (g) Test tools (h) implementation and test  (i) White box (j) optimising process    4.11 For quality to happen  there must be well-defined standards and procedures which are followed 4.12 Quality means fit for use. This is ________________view. 4.13 The no of principles in Dr. W. Edwards Deming's quality principles is ____________. 4.14 The other name PDCA referred to  is _________. 4.15 With the__________  the data is available to justify the application of technology to various critical tasks  and numerical evidence is available on the effectiveness with which the process has been applied to any given product 4.16 If changes are not controlled  then orderly _________________ is impossible and no quality plan can be effective.  4.17 AQL stands for_________________. 4.18 Is a vehicle for performing a test process________________. 4.19 The process by which product quality is compared with applicable standards; and the action taken when nonconformance is detected is called _________________. 4.20 cyclomatic Complexity method  is one of the method  of __________________Testing. PART TWO (Answer ANY FOUR questions) 5. d. How does software differ from the artifacts produced by other engineering disciplines? e.  How do software process metrics differ from software project metrics? f. What is meant by the term software reliability? B Level Syllabus R4    295  (5+5+5) 6. f. What  are the  names of the five levels of  the SEI  Capability  Maturity Model?  In your own words  briefly describe each. g. Describe the change control process for a modern software development project.                          (10+5) 7. b. System Testing b. What is equivalence partitioning as it applies to software testing? h. Boundary Value Analysis i. Black box vs. white box testing j. Acceptance Testing (3+3+3+3+3) 8.       a.  What are the key differences between validation testing goals and acceptance testing goals?      b.  A computer system is required that will support the following small garage business.      Customers bring their cars to the garage for servicing and repair. The attendant must check the car in  record details about the owner and the car  along with any specific customer requests. The workshop manager inspects each car and creates a job specification for it. He then schedules the job and assigns a mechanic to complete the specified tasks. During this process  if any new problems are discovered a new job specification is created by the workshop manager before carrying out the work. When the job is finished the mechanic completes a report detailing the time spent  work done and materials used. This information is used by the attendant to create an invoice for the customer when they come to collect their car. Represent the system described above as a use-case diagram         (5+10) 9.        b. What is the difference between testing Techniques and tools? Give examples.       Quality control activities are focused on identifying defects in the actual products produced; however your boss wants you to identify and define processes that would prevent defects. How would you explain to him to distinguish between QA and QC responsibilities? b.   Describe the process used in the UML (unified modeling language) approach to object-oriented design.  (10+5) B Level Syllabus R4    296  BE7-R4: SOFTWARE TESTING AND QUALITY MANAGEMENT  Assignment 1.   A program reads three integer values  representing the lengths of the sides if the triangle.  The program prints whether the triangle is scalene  isosceles or equilateral. Develop a set of test cases that would test the program adequately. Assignment 2.   Derive a flow graph for the above program and apply basis path testing to develop test cases that will guarantee the execution of all the statements. Execute the cases and show the results.  Assignment 3.  Given the following procedure   PROCEDURE AVERAGE   Interface Returns avg  input  valid  Interface accepts value  min  max  int value [100]; int avg; input  valid  min  max  sum  i  i = 1; input = valid = 0;  sum = 0 Do WHILE value [i]   - 999 and input = min and value [I]  0 THEN avg = sum/valid ELSE  Avg = -999 END IF B Level Syllabus R4    297  END AVERAGE  d) Draw a flow graph for the above given algorithm. e) Determine the cyclomatic complexity by applying  iv) Number of regions v) Edges and nodes vi) Predicate nodes f) Determine a basis set of linearly independent paths.  Assignment 4.   Prepare the test cases corresponding to each independent path identified in Q3.  Assignment 5.   Draw a Graph Matrix corresponding to algorithm given in Q3 & compute the cyclomatic complexity. Prepare the test cases of the given algorithm to test the conditions using CONDITION TESTING.  Assignment 6.   Write a program in any programming language to accept a number and generate a table. Draw a flow graph and design various test cases for testing all possible paths.  Assignment 7.  Write a program in a programming language  specified by the examiner  to accept a 10 numbers & sort them in the order accepted at run time. Make a flow graph and design test cases for the condition testing. Also mention the expected results.  Assignment 8.  You are to prepare a Test Plan.  What are the various test factors to be analyzed that correspond to Project Risks?  Assignment 9.  A universitys web site allows students to enroll online bio-data. The form contains following fields: x. Name of the student xi. Fathers name xii. Address xiii. City xiv. State xv. Pin code xvi. Sex xvii. Date of Birth xviii. Academic Qualifications a. Exam Passed b. University/Board c. Marks obtained d. Division e. Max Marks B Level Syllabus R4    298  Design the validation checks for the given fields.  Assignment 10.  Assume there is functionality to log-in through the screen given below:  Write a set of black box test cases to test the functionality of the given screen.  Assignment 11.  Prepare a checklist to review the Requirements and Design  Assignment 12.  Write a program to find the sum of the matrices.  Write all the test cases so as to verify the correctness of the logic.  Assignment 13.  Write the code for binary and linear search. Find the cyclomatic complexity of the two by drawing the flow graph.  Assignment 14.  Prepare a list of checks to test date  numeric and alpha fields in any data entry screen. Assignment 15.  Create du and dc graph for the following program: scanf(x y);  if (y < 0)    pow = pow  y;  else     pow = y;   z = 1.0; while(pow != 0) {  z = z * x;  pow = pow  1; Log in name: ___________ Password  ____________ SUBMIT B Level Syllabus R4    299  } if (y < 0)  z = 1.0/z; printf(z); Assignment 16.  Create the flow graph of the above Q15 and compute the cyclomatic complexity.  Assignment 17.  Prepare the list of test cases for q16  Assignment 18.  Write a program to compute the factorial of a number and create du and dc graph for the same. Assignment 19.  Create the graph matrix of the Q18 and compute the cyclomatic complexity.  Assignment 20.  Prepare the list of test cases for q19 Assignment 21.  Write a program to create fibonacci series and and create du and dc graph for the same.  Assignment 22.   Create the flow graph of Q21 and compute the cyclomatic complexity.  Assignment 23.  Prepare the list of test cases for q22  Assignment 24.  Prepare a checklist to test the Graphical User Interface of Windows based application.  Assignment 25.  Prepare a comprehensive checklist to test a WEB Site  B Level Syllabus R4    300  BE8  R4: Digital Image Processing  Objective of Course: This course Explain why the ability to perform digital processing of radiographic images is a significant advantage. It Cover the basic theory and algorithms that are widely used in digital image processing and Expose students to current technologies and issues that are specific to image processing systems. It gives to students the fundamentals of digital image processing  covering some topics from the following list: inverse problems in imaging; image enhancement; edge detection; feature extraction; and geometric diffusion. Describe the general relationship between image contrast and pixel values. Outline of Course S. No Topic       Minimum No of Hours 1. Introduction       10 2. Image Digitization      06 3. Image Enhancement      14 4. Image Restoration      10 5. Image Compression      10 6.  Image registration and Multi-valued Image Processing 10        Lecture : 60       Practical  :  60       Total  :         120 Detailed Syllabus  1. Introduction         10 Hrs Introduction of Image Processing with its applications  Components of Image processing system  Image Formation model. 2.  Image Digitization         06 Hrs Image digitization process  Image representation schemes like  GIF  TIFF  BMP  JPEG  PNG 3. Image Enhancement        14 Hrs Introduction of Image enhancement  Image enhancement techniques: Contrast intensification by Linear stretching  Non-Linear stretching  Exponential stretching  Noise cleaning or Smoothing by Image averaging  Special filters like Mean filter  Median Filter   Max filter  Mean filter and Image  sharpening and Crispening 4. Image Restoration        10 Hrs Minimum Mean-square Error restoration  Least-square error restoration  Restoration by Singular Value Decomposition  Restoration by Maximum Posterior Estimation  Restoration by Homomorphic Filtering 5. Image Compression        10 Hrs Introduction  Error Criterion (Objective and Subjective)  Stages of Image compression  Difference between Lossy Compression techniques and Loss less image compression techniques  Compression techniques like Huffman coding  Run Length Encoding  Lempel-Ziv-welch (LZW) coding  JPEG  Transform compression   Block Truncation compression. 6. Image registration and Multi-valued Image Processing   10 Hrs Introduction of image registration  Geometric transformation  Plane to plane Transformation  Mapping  Stereo imaging  Multi-modal and Multi-spectral image processing  Pseudo and False coloring  Image fusion. Color Models like RGB  CMY  YIQ  YcbCr  HIS B Level Syllabus R4    301  Textbook: 1. Rafael C. Gonzalez & Richard E. Woods: Digital Image Processing  Addision-Wesley Publishing Company  1993 References:  1. B. Chanda  D. Dutta Majumder: Digital Image Processing and Analysis  PHI  2000. 2. Rafael C. Gonzalez  Richard E. Woods  Steven L. Eddins:  Digital Image Processing using MATLAB  Pearsons Education Asia  2004 3. Nick Afford: Digital Image Processing  Addison-Wesley Publishing Company  2000. 4. Scott E Umbaugh : Computer  Vision and Image Processing  PHI  1998.  B Level Syllabus R4    302  BE8  R4: DIGITAL IMAGE PROCESSING  NOTE:  TIME: 3 HOURS                                                TOTAL MARKS: 100  Q.1  a) What is Bit Plane Slicing? What effects will be there is LSB details from the image is removed? b) Compare Low pass filtering in spatial domain & frequency domain  c) Calculate memory required to store 1024x768  8bit grayscale image and RGB image.  d) Derive Laplacian Mask for 4way & 8 way neighborhoods.   e) Explain brightness adaptation and discrimination. f) How you can inverse the image using Discrete Fourier Transform. Give the steps.  g) Explain Image Enhancement by Arithmetic and Logic Operation  (7x4)   Q.2  a) Explain fundamental steps in Digital Image Processing. b) Describe methods for image acquisition using single sensor  sensor strip and sensor array. c) How smoothing can be done in frequency domain? how edge detection can be done in frequency domain?  (6+6+6) Q.3  a) Explain Fidelity criteria. b) Explain Adaptive mean filter for image restoration and compare with mean filter. c) Describe Spatial resolution & Gray level-Resolution.  Also show how image content are affected with change of both.  (6+6+6) Q.4  a) Explain Un-sharp Masking & High Boost Filtering. b) Compare RGB  CMYK and HIS color models. c) How Histogram processing used for colored image? Explain with example.  (6+6+6)  Q.5  a) Explain Order Statistics Filters. Describe Median and Max filter. b) Calculate D4 distance  D8 distance and Dm distance for pixels in square. Find the connected component for each if possible & give minimum path length. Set V={3} 3121221243423341133132322223543452212333 (8+10) Q.6  a) If source of image (data) is known  it is easy get detect redundancy for images.  Justify the statement. Explain various types of redundancy  related to image data   3. Answer question 1 and any FOUR questions from 2 to 7. 4. Parts of the same question should be answered together and in the same sequence.  B Level Syllabus R4    303  b) Generate Huffman code for Following set of  data: 33172117212117214333432133334317173333173321332121212133534333435321211721333333 (8+10) Q.7  a) Explain Basic Thresholding method to decide a threshold T. for images having Bi-modal histogram. b) Explain homomorphic filtering process in frequency domain. c) Explain simultaneous contrasts and Mach bands.     (6+6+6)  B Level Syllabus R4    304  BE8-R4: Digital Image Processing  Practical List  Assignment 1. Introduction to MATLAB & Image processing Toolbox. Assignment 2. Write a m-function for following image transforms for grayscale image.  (Input: Gray Scale Image)  i. Inverse Transform ii. Power-law Transform iii. Log Transform Assignment 3. Write m-function for Histogram Equalization for grayscale image. (Input: Gray Scale Image) Assignment 4. Write m-function for Local Histogram Equalization. (Input: Gray Scale Image) Assignment 5. Write m-function for Histogram Specification for grayscale image. (Input: 2 Gray Scale Images) Assignment 6. Demonstrate the use of Smoothing and Sharpening using various Filters for Smoothing (Average(Mean) Filter  Weighted Filter  Median Filter  Gaussian Averaging Filter  Laplacian Filter  for Sharpening (H-V and H-V-D)) (Input: Gray Scale Image) Assignment 7. Perform the BIT PLANE SLICING for the gray scale image. Show the effect of removing the each bit plane from the image. (Input: Gray Scale Image) Assignment 8. Demonstrate the use of Filtering in Frequency Domain. Implement the function for the IDEAL  GAUSSIAN  and BUTTERWORTH (both High pass and Low pass) filters. Also compare and analyze results. (Input: Gray Scale Image) Assignment 9. Demonstrate the use of different filter applied for image restoration which is degraded by Raleigh  Gaussian  and Salt & Pepper Noise. Implement following filters: i. Mean Filter a. Arithmetic Mean filter b. Geometric filter c. Harmonic Filter d. Contra Harmonic filter ii. Order Statistics Filters d. Median filter e. Max & Min Filters f. Mid point Filter (Input: Gray Scale Image) 5. Demonstrate use of Prewit   Sobel  Robert  Canny edge detector for Edge detection. (Input: Gray Scale Image) 6. Implement Fourier Descriptor for shape detection and prepare CHAIN CODE for shape. (Input: Binary Image with one Shape) 7. Demonstrate use of Morphological Operations (Dilate & Erosion). (Input: Binary Image with one Shape) 8. Write a M-function for Color space Transformation. (RGBYUVCMYK)   (Input: Color Code) Software Requirement: MATLAB 6.0   B Level Syllabus R4    305  BE9-R4 : ACCOUNTANCY AND FINANCIAL MANAGEMENT  Objective of the Course  Managerial decision making has ever remained a crucial economic activity in accounting and financial management  for the nature and quality of decision is at the back of economic and financial prospect of the firm. Sound  intelligent and objective decisions depend to a larger degree upon the skills the managers hone within them  coupled with an efficient MIS. Accounting systems are an integral part of the MIS responsible for providing necessary  relevant and timely information to managers. Hence  the management of the organization along with its team of existing and prospective accountants must possess thorough understanding of the nature of accountancy. In view of this  the present course on accountancy and financial management is designed to equip the students with necessary skills  tools and techniques  which the accountants and the managers of tomorrow would use for appreciating the issues involved in system designing and using the accounting information for important managerial decisions.   The present course has broadly three segments-first  on financial accounting; second on cost accounting and third  on financial management. The first segment focuses on accounting provides a recordable language for business communication along with necessary financial information as crucial inputs for managerial decisions. As a system financial accounting aims at recording financial transactions of all types (between a firm and the external world)in various accounting books and then processes and transforms such transactions to provide for financial statements of the firm. Such financial statements are reflections on the financial health of a firm which must be an outcome of important managerial decisions. Cost accounting as a system process necessary information pertaining to the cost of inputs  which is not part of financial accounting but such information is certainly useful for a number of decisions to be made. The focus of this segment is to make the students appreciate how such a cost data is important for cost management and cost control Finance is one of the most important functional areas of management. This segment is designed keeping in mind that students must appreciate the issues involved in the management of corporate finance. It is expected that after the course each student must appreciate importance of financial management in the organizational context and understand further how sound financial management provides a strong lever to help the firm take-off for better and unprecedented prospects.   After the completion of the course  the following is expected from the students:   # Appreciation of the objectives and importance of Accounting Information System in an organisation. # Perfect knowledge of how different transactions are recorded in various accounting books.  # Understanding of how the records are processed to generate Profit and Loss Account  Balance Sheet  Funds Flow Statement and Cash Flow Statement. # Knowledge about analysis of the information obtained in the form of financial statements of a firm to determine its financial health and for taking certain decisions. # Appreciation of various cost concepts and relevance thereof in decision making. Skills to process cost information so as to determine the cost of a product/service.  Using cost data for better cost management and control; and for taking intelligent decisions.  # What are various financial decisions a finance manager has to take in a firm  what tools  techniques  information etc. one uses for decision making. # Appreciation and understanding of contemporary corporate finance related issues. B Level Syllabus R4    306  Outline of Course  S.No. Topic Minimum No. of Hours  1. Financial Accounting: An Introduction    6 2 Preparation of Final Financial statements  10 3 Analysis of Financial Statements  06 4 Cost Accounting: An Introduction  03 5 Overheads  02 6 Cost Accumulation Systems  03 7 Variable and Absorption Costing  03 8 Cost-Volume-Profit Analysis  03 9 Budgeting  04 10 Financial Management: An Introduction  03 11 Time value of Money and Mathematics of Finance  03 12 Capital Budgeting Decisions  04 13 Cost of Capital and Sources of Finance  04 14 Capital Structure and Dividend Decisions  03 15 Working Capital Management  03  Lectures  = 60 Practical/Tutorials  = 60 Total  = 120 Detailed Syllabus  1.1.1.1. Financial Accounting : Basic Accounting Concepts                                   06 Hrs. Need for Accounting  Its relationship with other subjects. The Profession of Accounting. Meaning and nature of Accounting - Accounting as a language of the business and accounting as an information system. Accounting Process and the final output of the accounting system. Principles of accounting and double entry system  recording of  transactions in journal. Recording transactions in cash-book (single column only)  sales- book and purchase-book  posting of transactions into ledger and the preparation of trial balance. The Financial Accounting Framework  Accounting Policies. The Accounting Equation  Accounting Standards on Disclosure of Accounting Policies. The Nature of Income. The Accounting Period concept Interim Reports.  Relation between income and Owners' Equity.  Income:  Not the Same as Increase in Cash. The Conservatism concept An Introduction to Accounting Standard on Valuation of Inventory. Revenue Recognition.  The Realization Concept.  The Matching Concept. Recognition of Expenses: Criteria for Expense Recognition  Expenses and  Expenditures. The Consistency Concept.  The Materiality Concept. The Income Statement: Revenues  Cost of Sales  Gross Margin  Expenses  Net  Income. Relation between Balance Sheet and Income Statement  Accrual versus Cash-Basis Accounting. Net Profit or Loss Prior period items  extraordinary items  2.2.2.2. Preparation of Final Financial statements                                            10 Hrs. Process leading to preparation of financial statements. Preparation of Final Accounts - Profit and Loss Account and Balance Sheet (with simple adjustments)  Preparation of Statements of Changes in Financial Statements-Funds Flow Statement and Cash Flow Statement  3.3.3.3. Analysis of Financial Statements                             06 Hrs. Horizontal (Trend) Analysis and Vertical (Common-Size) Analysis  Ratio Analysis  Liquidity Ratios  Turnover Ratios  Profitability Ratios  Solvency Ratios and Market Ratios  Du Pont Analysis  Analysis of Statements of Changes in Financial Position - Funds Flow Statement and Cash Flow Statement  B Level Syllabus R4    307  4.4.4.4. Cost Accounting : Basic Concepts                          03 Hrs. Meaning  nature and importance of cost accounting system in an organization. Elements of costs and various cost concepts such as direct and indirect costs  fixed and variable costs  sunk cost  opportunity cost  out of pocket and imputed costs  preparation of cost sheet  5.5.5.5. Overheads                                02 Hrs. Allocation  Apportionment and Absorption of Overheads  6.6.6.6. Cost Accumulation Systems                                                                 03 Hrs. Job costing system (simple treatment)  process costing system (simple treatment)  7.7.7.7. Variable and Absorption Costing                                                       03 Hrs. Estimation of profit under absorption costing system and under variable costing system (simple cases)  Understanding and appreciating the differences in profits calculated under both the systems. Importance of variable costing for decision making.  8.8.8.8. Cost-Volume-Profit Analysis                                                                03 Hrs. Understanding the nature of variable cost and fixed cost (total as well as per unit)  contribution  P/V Ratio  Break-Even-Point  Assumptions of Cost-Volume-Profit Analysis and studying the relation between cost  volume and profit  Graphical Analysis of Break-Even-Point and Profit-Volume Relation  Use of Cost-Volume-Profit Analysis for Decision Making  Limitations of Cost-Volume-Profit Analysis  9.9.9.9. Budgeting                                                                                    04 Hrs. Meaning  objectives and importance of budgeting in an organisation  Budget as a management control system. Different approaches to Budgets including. Preparation of cash budget  fixed and flexible budgets  zero-base budgeting  10.10.10.10. Financial Management  : Basic Concepts                                                  03 Hrs. Nature  objectives and scope  Financial decision-making and types of financial decisions  Role of a finance manager in a firm  Basic axioms of Financial Management  Risk-Return framework for financial decision - making. Corporate Finance. 11.11.11.11. Time value of Money and Mathematics of Finance                                 03 Hrs. Interest rates and term structure of interest rate. Time value of money and the opportunity cost of money  Present value and future value and interest rate and discount rate  Annuities and their types  Numerical related to the calculation of present values and future value  12.12.12.12. Capital Budgeting Decisions                                                                04 Hrs. Nature and kinds of capital budgeting decisions  Techniques of evaluating capital budgeting decisions  discounted and non-discounted methods of investment appraisals such as payback period  accounting rate of return  NPV  IRR and profitability index  13.13.13.13. Cost of Capital and Sources of Finance                                           04 Hrs. Basic valuation model  concept of cost of capital - weighted average cost and marginal cost  cost of debt and cost of equity - simple cases  Various long - term sources of funds  for a firm. New paradigm of institutional and packaged finance.  Loan syndication and loan consortia.  14.14.14.14. Capital Structure and Dividend Decisions                                           03 Hrs. Concept of capital structure  financial leverage and capital structure  determinants of capital B Level Syllabus R4    308  structure. Dividend and its forms - cash dividend  right and bonus shares  and buy-back of shares. Determinants of dividend policy of a firm  15.15.15.15. Working Capital Management                                                                03 Hrs. Basics of working capital management : Meaning of gross and net working capital  components of working capital  risk-return framework for working capital decisions. Determinants of working capital requirement   Sources of financing working capital requirement. Recommended Reading  Main Reading 1.1.1.1. R.Narayanaswamy: Financial Accounting: A Managerial Perspective  PHI 2.2.2.2. MN Arora: Copst and Management Accounting  Vikas Publications 3.3.3.3. Prasanna Chandra  Financial Mnagement : Theory and Practices  5th Edition  2001  Tata McGraw Hill. Supplementary Reading 3. Robert  N. Anthony and James s. Reece : Accounting Principles 4. S.N. Mahesweri : Advanced Accountancy 5. M.Y. Khan and P.K. Jain  Management : Accounting  Second Edition  1995 (Tata  McGraw Hill Publishing Co. Ltd  New Delhi.  6. R.L. Gupta  and M. Radhaswamy : Advanced Accountancy 7. Horngran  C.T.  Foster G and Sales  S.M.  Cost Accounting: A Managerial           Emphasis  10th Edition  2000  Prentice Hall of India. 8. Paresh Shah  Management Accounting  OUP 9. Ravi M. Kishore  Cost and Management Accounting  Taxmann 10. Pandey I.M.   Financial Manager  7th Edition  2002 Vikas Publishing Pvt.Ltd. 11. Ravi M. Kishore   Financial Management : Problems and Solutions  Taxmann B Level Syllabus R4    309  BE9- R4 : ACCOUNTANCY AND FINANCIAL MANAGEMENT  NOTE: 1.  a) Explain the concepts of Historical Cost and Conservatism in financial accounting.  What are the possible implications if a firm does not follow these concepts?       (4)                                                                                  b) Record the following transactions in journal  post them  and prepare a trial balance in the books of Falgun Private Limited:                          (6) Sl. No. Details of transactions i Promoters were issued 75 000 equity shares with a face value of Rs. 10 each at a premium of 20% in cash. Ii Plant and machinery were purchased against issue of 10% preference shares worth Rs. 2.00 lakhs. Transport charges of Rs. 25 000 were paid to bring the plant and machinery to the factory. Iii Purchase of Rs. 1.50 lakhs was made at 10% trade discount. Iv Bank account was opened with BOI by depositing Rs. 6.00 lakhs. V Credit sale of Rs. 1.80 lakhs was made on the terms 2/15  net 45 to M/s Patel Bros; the Party cleared 50% payment through cheque on the 12th day. Vi Salary of Rs. 35 000 & printing expenses for the same amount were paid by cheque. vii Purchase of Rs. 2.00 lakhs was made from Amrut by cheque.  c) Answer the following in about 100 words each:  i) Distinguish between Absorption Costing and Variable costing.                    (4)  ii) Distinguish between Job costing and Process Costing.             (3) iii) Explain the concept of Zero Base Budgeting.                  (4)  iv) Explain the difference between NPV and IRR                     (4)  v) Explain how weighted average cost of capital is computed.                   (3) 2. The summarized balance sheet of Sharad Co. Ltd. as on 31st March 2007 and 31st March 2008 is given below:                                                                                                                              (18) Figures in Rs. Liabilities 31-03-07 31-03-08 Assets 31-03-07 31-03-08 Eqity shares of Rs. 10 each 1 000 000 1 500 000  Goodwill       40 000        30 000  General Reserves 600 000    200 000  Fixed Assets 1 300 000  2 230 000  Profit & Loss A/c 100 000    120 000  Investments    150 000      120 000  10% Debentures -    500 000  Stocks    100 000   150 000  Creditors 450 000    510 000  Debtors    550 000      350 000  Provision for Taxation 150 000    170 000  Cash & bank    120 000        90 000     Preliminary expenses      40 000        30 000  TOTAL 2 300 000  3 000 000  TOTAL 2 300 000  3 000 000  The following additional information is also available: (a) On 1-4-2007  bonus shares at one share for every two shares were issued by capitalizing General Reserve. (b) Income Tax of  Rs. 1 40 000 was paid during the year. 1. Answer Question 1 any FOUR questions from 2 to 7. 2. Parts of the same question should be answered together and in the same sequence. B Level Syllabus R4    310  (c) Interim dividend of Rs. 90 000 was paid during the year. (d) Depreciation of Rs. 50 000 was provided on Fixed Assets (e) Investments costing Rs. 50 000 were sold at a profit of Rs. 10 000 and the profit was credited to profit and loss  account.  Prepare a cash flow statement from the above information.  3.    The summarised balance sheets of Sarjon Limited are given in the following table:                      Figures in Rs. LIABILITIES 31-12-05 31-12-06 ASSETS 31-12-05 31-12-06 Equity share capital 150 000 200 000 Fixed assets 350 000 350 000 General reserve 30 000 50 000 Debtors 50 000 60 000 Profit- loss a/c 20 000 25 000 Bills receivables 23 000 31 250 9% debentures 200 000 150 000 Stock 65 000 105 250 Creditors 75 000 95 000 Cash 12 000 3 500 Bills payables 15 000 20 000    Bank O.D. 10 000 10 000    Total 500 000 550 000 Total 500 000 550 000 Additional information         2005 2006 Sales (20% cash sales) 450 000 540 000 Cost of sales           217 500     321 200 Administrative  selling and other financial expenses (Other than int.& tax at 35%)          32 500      25 300 Stock at 31-12-2004 was Rs. 35 000     From the above information calculate following ratios:     (9x2) I. Current ratio II. Acid test ratio III. Cash ratio IV. Gross Profit margin ratio V. Operating profit  VI. Net profit ratio VII. Stock turnover ratio VIII. Debtors ratio (days of the yr. 360) IX. Rate of return on capital employed 4. Prepare a cash budget for three months ending 30th June 2005 from the information given below:                           (18)                     Figures in Rs. Month Sales Materials Wages Overheads Feb 14 000 9 600 3 000 1 700 Mar 15 000 9 000 3 000 1 500 Apr 16 000 9 200 3 200 2 000 May 17 000 10 000 3 600 2 200 Jun 18 000 10 400 4 000 2 300 B Level Syllabus R4    311   Credit terms are: Sales and debtors: 10% of sales are on cash  50% of the credit sales are collected next month and the balance in the following month.  Creditors:-    Materials :            2 months     Wages  :             month      Overhead :         month  Cash & bank balance on 1st April  2005 is expected to be Rs. 6 000.  Other relevant data are: I. Plant and machinery will be installed in February 2005 at a cost of Rs. 96 000. The monthly instalment of Rs. 2 000 is payable from April onwards. II. Dividend @ 5% on Preference share capital of Rs. 2 000 000 will be paid on 1st June. III. Advance to be received for sale of vehicles Rs. 9 000 in June. IV. Dividends from investments amounting to Rs. 1 000 are expected to be received in June. V. Income tax (advantage) to be paid in June is Rs. 2 000. 5. A company currently operating at 80% capacity has following particulars:           Figures in Rs. Sales   6 400 000 Direct Material    2 000 000 Direct labour    800 000 Variable Overheads  400 000 Fixed Overheads   2 600.000 An export order has been received that would utilize half of the capacity of the factory. The order cannot be split  i.e. it has either to be taken in full and executed at 10% below the normal domestic prices or rejected totally. The alternatives available to the management are: I. Reject the order and continue with the domestic sales only (as at present)  or  II.  Accept the order  split capacity between overseas and domestic sales and turn away excess domestic demand  or III. Increase capacity so as to accept the export order and maintain the present domestic sales by: - Buying the equipment that will increase capacity by 10%. This will result in an increase of Rs. 2 00 000 in fixed cost  and  - Work overtime to meet balance of required capacity. In that case labour will be paid at one and a half times the normal wage rate Prepare a comparative statement of profitability and suggest the best alternative.    (18)  6.  a) The following data are obtained from the records of factory:          Figures in Rs. Sales  100 000 Material consumed  40 000 Variable overheads 10 000 Labour charges 20 000 Fixed Overheads 18 000 Net  Profit 12 000 Calculate: I. The number of units by selling which the company will neither lose nor gain anything. II. The sales needed to earn a profit of 20% on sales. B Level Syllabus R4    312  III. The extra units which should be sold to obtain the present profit if it is proposed to reduce the selling price by 20% and 25%. IV. The selling price to be fixed to bring down its break-even point to 500 units under present conditions.        (2+2+4+2)  b)      A company has the following capital structure   (Rs.Lakh)             --------------------------------------------------------------------------------------------------------------------- Equity capital  1  00 000 shares of Rs. 10 each           10 Reserves and surplus (retained earnings)                                                08  12% debentures  5 000 numbers of Rs. 100 each                             05                                      23           -------------------------------------------------------------------------------------------------------- i. If the company is paying dividend at 27%  calculate the cost of equity and weighted average of capital  based on book values.                                                                                                         (4) ii.  If the market value of equity shares is Rs  15 each and if the debentures are quoted at Rs. 95 each  what is the weighted average cost of capital  based on market values.                                         (4)   Note. Tax rate both cases is 35%.  7. Toy limited has a new project for the manufacture of a computerised toy. The product is a novelty in the toy market. The company had already spent an amount of Rs. 720 000 in developing the product and is eager to place it in the market as quickly as possible. The company estimates a five-year market life for the product. The maximum number it can produce in any given year is limited to 36 lakhs units. The expected market scenario will support a sale equivalent of 20%  50%  100%  100%  and 30% of the capacity in the 1st year  2nd year  3rd year  4th year and 5th year respectively.   Investment in the project is expected to be completed in one year and will have the following major components:                                                                                                                    (Rs. Lakhs)  Land building and civil works  12.50     Machinery and equipment  87.50   Interest during construction 8.00   The cost structure of the toy is as given below:     Materials                                                                 Rs. 2.00   Conversion cost excluding depreciation                    Rs. 1.00  Materials are required to be held in stock for I5 days at an average while finished goods may be held or up to 60 days. Production cycle is. 12 days. Credit expectancy of the market is 30 days  both on sales and purchases. It s the usual practice of the company to keep a cash-in hand reserve for 15 days expenses not provided for specifically elsewhere in the working capital estimates.  Working capital requirement should be worked out on the above basis for the first year. The same level in terms of money will be maintained in the subsequent years  though the composition may change.  The following assumptions are made:  i. Project will be financed by a combination of equity and term loans in a ratio as close to 30:70 as practicable. ii.  Loans will carry an interest of 14% p.a.  B Level Syllabus R4    313  iii. Loan disbursement will be uniform throughout the period of construction at a simple interest at the same rate as above.  iv. Selling price per unit will be Rs. 6.  v. One year moratorium on the principal will be available.  vi. Promotion expenses for the first three years will be Rs. 2.00 lakhs  Rs.1.00 lakh and Rs. 0.50 lakh respectively.  vii. Production is prorated every month equally.  viii. The factory operates one shift for 360 days in year. ix.  Ignore interest on overdraft.  x. Working capital requirement will not increase after the initial first year.  Calculate the following: a) Initial working capital required.       (4) b) Total financial investment in the project and its financing.  (4) c)  Profit before depreciation and interest charges for 5 years.              (6)         d)  Debt service coverage ratio.      (4)B Level Syllabus R4    314  BE 9 -R4 : ACCOUNTANCY AND FINANCIAL MANAGEMENT ASSIGNMENTS Assignment 1. Case study on the Basic Accounting Concepts and give the answer of following questions: 1. What are the accounting principles assumptions and concepts? 2.  What is the difference between capital expenditure and revenue expenditure? 3.  What is the accrual basis of accounting? 4.  At what point are revenues considered to be earned? 5.  What is the difference between net cash flow and net income? 6. Pass journal entries for the following: (a) Purchase of goods worth Rs.1000 at a discount of Rs.100. (b) Issue of shares at par having face value of Rs.10 for purchase of fixed assets  worth Rs.10000.  ) Issue of shares at Rs.8 having face value of Rs.10 for purchase of fixed assets worth Rs.10000. (d) Issue of shares at Rs.12 having face value of Rs.10 for purchase of fixed assets worth Rs.12000 (e) Paid Rs. 10000 to Mr X in full and final settlement of his dues worth Rs. 11000. (f) Withdrawn goods for personal use (sale price Rs.1500  cost Rs.1200). (g )Goods distributed to children in an orphanage (sale price Rs.1500  cost Rs.1300). (h) Goods stolen (sale price Rs.1500  cost Rs.1200). (i) Goods destroyed by fire (sale price Rs.1500  cost Rs.1200). (j) Goods used in furnishing the office  (sale price Rs.1500  cost Rs.1200). (k) Recovered from Mr. K half the amount which was written off as bad. Rs.400 was written off as bad earlier. (l) Cheque received from X for Rs.1000 was dishonored by bank. (m) Received Rs.1000 as advance for goods ordered by S. Assignment 2. Case study on preparation of  Final Financial Statements and give the answer of following questions: 1. What is accrued income? 2. What does a balance sheet tell us? 3. Why isnt land depreciated? 4. Where is a contingent liability recorded? 5. What is the difference between a balance sheet and a trial balance? 6. What is an intangible asset? 7. What are accruals? 8. Where does revenue received in advance go on a balance sheet? 9. What is the difference between reserve and provision? 10. What are accrued expenses and when are they recorded? 11. What is the difference between bad debt and doubtful debt? 12. What is the difference between the Cash Flow and Funds Flow statements? 13. Why is the Cash Flow Statement identified as one of the financial statements  B Level Syllabus R4    315  14. An extract of the trail balance as at 31 Dec. 2004 of the firm of William  and Moraes is available. The partners share profit and losses in the proportion of 60% and 40% respectively with following further stipulations:  i. Each partner is entitled to be paid Rs. 2 000 p.m. by way of salary; and ii. Interest at the rate of 15% will be charged on drawing other than salary. Trial Balance as at 31.12.2004                                                                                            Dr.                      Cr.  Capital Accouts:  Rs. Rs.     William  -- 80 000      Moraes  -- 80 000 Sundry Creditors  -- 35 000 Fixed assets  1 82 000 -- Goodwill  20 000 -- Stock in trade(31.12.2004)  42 250 -- Sundry debtors  71 450 -- Cash in hand  13 000 -- Staff salary advance   3 000 -- Partners Salaries  48 000 -- Office expenses outstanding  --         1 000 Depreciation  18 000 -- Staff Salaries  20 000 -- Trading Account (Gross Profit)  -- 2 40 000 Office expenses  18000 --------------------- -- -------------------  4 36 000 -------------------__________ 4 36000 ------------------  Utilise the following additional information you are required to prepare: i. Profit and Loss Account for the year 2004. ii. Balance sheet   as at 31 December 2004; and iii. Partners Capital Account B Level Syllabus R4    316  Additional Information: a) A perusal of the payment voucher for January 2005 indicates payment of salaries of Rs.2 000 and office expense of Rs. 8 000  relating to the periods before 31.12.2004. b) Partners have drawings in their accounts as follows: Moraes:  on 1.1.2004  Rs 20 000 Williams:  on 1.5.2004  Rs 20 000 c)    Rs 1 000out of staff salary advance is to be carried forward to 2005  Assignment  3. Case study on Analysis Of  Financial Statements and give the answer of following questions: 1. What is the accounts receivable collection period? 2. What is the fixed asset turnover ratio? 3. What is the debt ratio? 4. What is the total asset turnover ratio? 5. What is the return on assets ratio? 6. What is the working capital turnover ratio? 7. What is the working capital ratio? 8. What is the days sales in accounts receivable ratio? 9. What is a liquidity ratio? 10. What is the days sales in inventory ratio? 11. What is the inventory turnover ratio? 12. What is the debt to equity ratio? 13. What is the accounts receivable turnover ratio? 14. What is the acid test ratio? 15. What is the current ratio? 16. Redraft the following Profit and Loss account and Balance Sheet  and calculate the following ratios: A) Gross profit ratio B) Overall profitability ratio C) Current ratio D) Debt- Equity ratio E) Stock turnover ratio F) liquidity ratio  Profit and Loss Account  Particulars  Rs.  Particulars Rs. Opening stock of finished goods 1 00 000  sales 10 00 000 Opening stock of Raw materials   50 000  Closing Stock of Raw materials   1 50 000 Purchase of Raw materials 3 00 000  Closing Stock of Finished goods   1 00 000 Direct Wages 2 00 000        50 000 Manufacturing Expenses 1 00 000       Administration Expenses     50 000    Selling and distribution Expenses     50 000    Loss on sale of plants    55 000    Interest on debentures    10 000    Net Profit 3 85 000    B Level Syllabus R4    317   ----------- 13 00 000   13 00 000 BALANCE SHEET  Liabilities  Rs.  Assets Rs. Share Capital:   Fixed Assets 2 50 000 Equity Share Capital 1 00 000  Stock of Raw materials 1 50 000 Preference Share Capital 1 00 000  Stock of finished goods 1 00 000 Reserves 1 00 000  Sundry Debtors 1 00 000 Debentures 2 00 000  Bank balance    50 000 Sundry creditors 1 00 000    Bills Payable     50 000     ------------ 6 50 000 ------------   --------------6 50 000 ------------- Assignment 4. Case study on Basic Concepts Of Cost Accounting and give the answer of following questions: 1. What are fixed costs?   2. What are variable costs? 3.  What are direct costs? 4.  What are indirect costs?  5. What are sunk costs? 6. What are indirect costs? 7. What are opportunity costs? 8. What are out-of-pocket costs? 9. What are imputed costs?  Assignment 5. Case study on Overheads and give the answer of following questions: 1 What are overheads? 2. How overheads are allocated  apportioned  and absorbed?     Assignment 6. Case study on Cost Accumulation Systems and give the answer of following questions: 1. Explain job-order costing and process costing techniques. 2. Differentiate between job-order costing and process costing techniques. 3. How costs are allocated under job-order costing and process costing techniques?   Assignment 7. Case study on Variable and Absorption Costing and give the answer of following questions:  1. Describe Variable( Marginal) Costing and Absorption Costing.  2. Differentiate between Variable( Marginal) Costing and Absorption Costing. 3. From the following data preoare statements of cost according to both Variable( Marginal) Costing and Absorption Costing:                                                       Product A             ProductB             ProductC                                                            Rs.                         Rs.                           Rs.     Sales                                             30 000                     60 000                  80 000      Direct Material                              12 000                    25 000                  36 000    Direct Labour                                8 000                      10 000                  14 000  B Level Syllabus R4    318           Fixed  Overheads                          6 000                        8 000                     6 000           Variable  Overheads                     2 000                        3 000                     5 000           Fixed Administration overheads  1 000                        2 000                     2 000           Fixed selling overheads                2 000                       2 000                     3 000           Variable selling overheads           1 000                        3 000                     3 000   Assignment8. Case study on Cost-Volume- Profit Analysis and give the answer of following questions: 1. Describe the following terms: A) Fixed Cost  B) Variable cost C) Contribution D) Profit/ Volume Ratio(P/V Ratio) E) Key Factor F) Break- Even  Point 2. What are the assumptions underlying Cost-Volume- Profit Analysis? 3. Comment on the relative profitability of the following two products.                                                                           Production cost/ unit         Particulars                                             ProductA(Rs.)        Product B(Rs.) Material                                                            200                        150 Wages                                                               100                        200 Fixed Overheads                                               350                        100 Variable Overheads                                          150                        200 Profit                                                                 200                        350 Sale price per unit                                             1000                      1000 Output per day                                                   200 units               100 units  4. A company manufacturing machines has the capacity to produce 500 machines per annum. The variable cost of each machine is Rs.200 and the selling price of each machine is Rs.250. Fixed overheads are Rs.12000 per annum. Calculate the break-even-point for output and sales and show what profit would result if the output is 90% of the capacity. 5. What is marginal cost and how does it differs from total cost? 6. What happens to P/V ratio and Break-Even-point when: a) Unit selling price of product increases. b) Unit variable cost increases. c) Total fixed cost increases. d) Number of units sold increases. 7. What are the advantages and limitations of  Break-Even-Charts?                       Assignment9. Case study on Budgeting and give the answer of following questions:  1     Explain the meaning of budget. What are the advantages of budgetary control? 2.  Differentiate between Fixed and Flexible budgeting. 3.  Explain Zero Base Budgeting. 4.  With the following information for a 60% activity  prepare a budget at 80% and     100% activity. Production at 60% activity-   6000units. Materials Rs.100 per unit Labour Rs.40 per unit Expenses Rs.10 per unit Factory expenses Rs.4 00 000 (40% Fixed) Administration expenses Rs.3 00 000 (60% Fixed)   Assignment10. Case study on Basic Concepts of Financial Management and give the answer of following questions:   B Level Syllabus R4    319  1. Briefly describe the major types of Financial Management Decisions taken in a company. 2. Describe the relationship between Financial Accounting and Financial Management.   Assignment11. Case study on Time Value Of  Money and Mathematics of Finance and give the answer of following questions: 1. What is the meaning of present value of a future amount? How are the present values and future values calculated?   2. Explain the discounting technique of adjusting for time value of money. 3. What is the minimum amount which a person should be ready to accept today from a debtor who otherwise has to pay a sum of Rs.5000 today  Rs. 6000  Rs.8000  Rs.9000  Rs. 10000 at the end of year 1 2 3 4 respectively from today. The rate of interest may be taken at 10%.  4. A firm purchases a machinery for Rs.8 00 000 by making a down payment of Rs. ! 50 000 and remainder in equal installments of Rs. 1 50 000 for six years. What is the rate of interest to the firm?      Assignment 12. Case study on Capital Budgeting Decisions and give the answer of following questions:  1. What is capital budgeting decision? Why is it significant to a firm? 2. Describe the concept of discounted cash flows in making investment decisions and its superiority over the traditional methods of investment evaluation. 3. How is pay back period calculated? How is it helpful in determining IRR? 4. What is profitability index? Which is superior ranking criteria  PI or NPV? 5. Make a comparison between NPV and IRR methods.  6. How do you calculate the Accounting Rate Of Return? Explain the treatment of depreciation in calculating the net investment. What are the limitations of ARR? 7. A company is considering an investment proposal to install a new machinery. The project will cost Rs. 50 000. The new machine has a life expectancy of 5 years and no salvage value. The company tax rate is 40%. The firm uses straight line method of depreciation. The estimated profits before tax from the proposed investment are as follows:               Year                                         Profit(Rs.) 1 10 000 2 11 000 3 14 000 4 15 000 5 25 000            Compute the following: A. Pay back period B. Average rate of return C. Internal rate of return D. Net present value at 10% discount rate E. Profitability index at 10% discount rate 8. A firm whose cost of capital is 10% is considering two mutually exclusive projects X and Y   the details of which are:                    Year                     Project X                   Project Y                                 0                          100000                         100000                                1                           10000                         50000                                2                             20000                         40000                                3                              30000                         20000                                4                              45000                         10000                                5                              60000                          10000 B Level Syllabus R4    320                   Compute the net present value at 10%  Profitability Index  and the Internal Rate of Return for the two projects.                  Assignment 13.   Case study on Cost of Capital and Sources of Finance and give the answer of following questions: 1. Why debt is considered as the cheapest source of finance for a profit making company? 2. Explain the different approaches to the calculation of cost of equity. Are retained earnings       cost free? 3. Is the cost of debt the same as the rate of interest? 4. Describe the various long-term sources of funds for a firm. 5. Calculate the cost of capital in each of the following cases:      a) A company issues 10% non-redeemable preference shares at Rs. 105 (FV =100)      b) The current market price of share is Rs. 90 and the expected dividend at the end of           current year is Rs.4.5 with a growth rate of 8%. c) A company is considering raising of funds of about Rs.100 lacs by one of the two      alternative methods  viz  14% term loan from bank or 13% non-convertible debentures.  The term loan would attract no major incidental cost. The debentures would have to be issued at a discount of 2.5% and involve cost of issue of Rs.1 00 000 Advice the company as to the better option based  on the effective cost of capital in each case. Assume a tax rate of 50%. 6.     What is loan syndication and loan consortia?  Assignment 14. Case study on Capital Structure and Dividend Decisions and give the answer of following questions: 1. What is the meaning of the term capital structure? 2. Explain the factors that are relevant in determining the capital structure. 3. Explain Financial Leverage. 4. Briefly explain the factors which influence the dividend policy of a company.   Assignment15. Case study on  Working Capital Management and give the answer of following questions:  1. Explain the following terms: a) Working Capital b) Gross working capital c) Net working capital 2. Explain the factors that determine the working capital requirement. 3. Explain the effects of excessive working capital as well as of inadequate working capital. 4. What are the different sources of financing working capital requirement? B Level Syllabus R4    321  BE10-R4: APPLIED OPERATIONS RESEARCH   Objective of the Course This course is designed so as to familiarize students with OR models and the quantitative techniques that are used to handle real life problems. The principal aim of the course is to get a practical orientation of the subject matter. Case studies have also been given due importance in the course. The recommended books give leads to many interesting case studies that require challenging and comprehensive analysis with substantial use of computer and easily available software packages in an interactive mode.  A significant portion of the syllabus has been devoted to conceptual development of important topics  such as linear and Integer programming and network analysis  which have wide applicability in many fields including computer sciences. Driven by the need to meet the challenges of decision making in a highly competitive environment  some important and relevant topics like game theory have been included.  Practical exercises and tutorials are suggested in the course besides providing exposure to practical OR models. These exercises are expected to equip students with necessary analytical skills and programming expertise to help face the challenges of the IT industry.   Outline of Course  S.No. Topic                                                   Minimum No. of Hours  1.        Introduction to Quantitative Techniques and OR Modeling 02 2.         Linear Programming  (a)       Model formulation and Case Studies 03                     (b)       Linear Programming Methodologies 08              (c)       Transportation and Assignment Problems 06 3.          Integer Programming 04 4.          Job Sequencing  04 5.          Network Analysis 07 6.          Project Scheduling by PERT / CPM 06 7.          Basic Queuing Theory 06 8.          Inventory Control 04 9.          Game Theory 06 10.        Unconstrained Optimization: Steepest Descent Method  04                                                                            Lectures = 60                                                                            Practical/Tutorials = 60                                                                             Total = 120 B Level Syllabus R4    322  Detailed Syllabus  1. Introduction to Quantitative Techniques and OR Modeling 2Hrs. Defining the problem  acquiring the data  modeling a decision problem  different types of models  formulating mathematical model for decision problems  testing the model   developing its solution  analyzing the result; implementation of above concepts through simple examples or case studies.  2. Linear Programming                                                    a) Model Formulation and Case Studies:             3 Hrs. Assumptions in linear programming  Formulation of linear programming models  Practical Case Studies. (Practical: Use of Microsoft or Lotus Spreadsheet use to formulate a case study is recommended). Graphical illustrations and understanding of special cases  no feasible solutions  no finite optimum solutions  multiple solutions  and degenerate solutions   b) Linear Programming Methodology:             8 Hrs. The geometry of linear programming problem  the algebra of Simplex method including the concepts of convex set  extreme points  basic feasible solutions  slack   surplus  artificial variables  computational aspects of the Simplex algorithm and the two phase method  numerical examples illustrating all types of cases  viz. infeasibility  unbounded problems  alternate optimal solution  etc. (Practical exercises  development or software for simplex method is recommended).  Duality theory in linear programming  dual formulation for all types of linear programming problems  including equality inequality constraints  unrestricted variables  maximization and minimization in objective function; Economic Interpretation of duality  all duality  theorems (without proofs) and their applications. (Tutorial on practical case studies and interpretation or duality in those cases)  c) Transportation problems and assignment problems:                                   6 Hrs. General models of the two problems as special linear programming problems  Basic feasible solution computation for TP problems by north-west rule  matrix minima method and Vogels method  determining the optimal transportation schedule   the Hungarian method for AP problems with stress on finding their optimal solutions (Development or software for Hungarian method is recommended)   3. Integer Programming  4 Hrs.    Integer Programming modeling and  0-1 programming modeling through examples  like  resource allocation  investment decision  fixed charge problem  traveling salesman problem etc.; Understanding the non-linearity in such problems  Branch and Bound algorithm with numerical examples (Practical: development or code for traveling salesman problem using the branch and bound and Hungarian methods is recommended)  4.        Job Sequencing 4 Hrs.  Sequencing models  Johnsons algorithm for processing n jobs -two machines and n-jobs three machines  Processing 2 jobs through n machines; graphical solution. (Tutorial on developing model for job sequencing with precedence constraints as an integer programming model)   B Level Syllabus R4    323  5. Network Analysis  7 Hrs.  Examples of Network Flow Problems  modeling of network flow problem as a linear programming problem  node-arc incidence matrix  the concept of spanning tree  min cut  max flow-min cut theorem and its relationship with linear programming duality; labeling algorithm for the max-flow problems  illustration through numerical examples. Shortest-Path network problems  applications of shortest path problem  Dijkstras Algorithm (It is suggested to formulate a practical model from logistics or transportation sector as a network problem and determine its solution).  6. Project Scheduling by PERT/CPM 6 Hrs.  Project management: PERT  CPM; applications of PERT/ CPM  drawing PERT/CPM networks  critical path evaluation by network analysis and CPM method  determination of negative floats and negative slacks  probability of project completion  program evaluation and review technique.  (Practical: Use of MS Project is recommended)   7. Basic Queuing Theory 6 Hrs.  Basic elements of queuing systems through examples  exponential Distribution and Poisson distribution; Steady state measure of performance of a Queuing system  Single server single channel model (M/M/1)  multi-channel queuing model (M/M/m).  (Practical: Development of software modules for simulating M/M/1 queue from manufacturing / communication field is recommended)   8. Inventory Control  4 Hrs.  Introduction to Inventory control and applications  deterministic Models: the basic EOQ model  inventory models with non-zero lead time  EOQ problems with Discount rates and price breaks  EOQ with shortages  multi-item deterministic Inventory models 9. Game Theory  6 Hrs.  Introduction to Game theoretic models  Zero-sum games; concepts of pure strategies and mixed strategies  law of dominance  graphical solution of 2xn or mx2 games; relationship between game problem and linear programming and linear programming duality  linear programming based solutions of game (Practical: suggested to develop a code for solving a zero sum matrix game through the Simplex algorithm of linear programming)  10.  Unconstrained Optimization            4 Hrs.  Introduction to nonlinear Unconstrained Optimization problems  steepest descent direction  steepest descent algorithm  geometrical interpretation  simple numerical examples  RECOMMENDED BOOKS   MAIN READING   1. Hamdy  A Taha   Operations Research: An Introduction  8th edition (with CD ROM)    2002  Pearson Education  Inc 2. S. Chandra  Jayadeva  A. Mehra  Numerical optimization with Applications  Narosa Publishing House  2009  B Level Syllabus R4    324  3.   A.  Ravindran  D. T. Phillips  J. J. Soleberg  Operations Research: Principle and Practice  Wiley  1987.  SUPPLEMENTARY READING  1. P. C. Tulsian and V. Pandey  Quantitative Techniques: Theory and Problems  Pearson  2002. 2. F. S. Hiller and  G. J. Lieberman   Introduction to Operations Research  7th edition  McGraw Hill  2002. REFERENCES  1.http://www.ms.ic.ac.uk/jeb/or/contents.html  2.http://www.bus.colorado.edu/faculty/lawrence/bap6100/schedule.ht  B Level Syllabus R4    325  BE10-R4: APPLIED OPERATIONS RESEARCH       Model Question Paper  Time: 3 Hrs.        Maximum Marks: 100  Note: First question below is compulsory.  Answer any four questions from questions 2 to 7.  1. a) Write dual of the following linear programming problem Minimize Z = 0.4x1 + 0.5x2  Subject to   0.3x1+0.1x2  2.7  0.5x1+0.1x2 = 6  0.6x1+0.4x2  6          x1  x2  0    b) Solve the assignment problem with the following cost table:                                             Task       1                    2                     3                  4    Assignee                        A                                        B                                        C                                        D 8 6 5 7 6 5 3 4 7 8 4 6 6 7 5 6 c) Construct the project network with the following activities and relationships.   Activity Immediate Predecessors Estimated Duration A - 2 B - 3 C A B 2 D A B 2 E D 3 d) Detail how the following conditional constraints can be formulated in an integer            program:     Either 3x1 + 2x2  18 or x1 + 4x2  8  e) Suppose that the demand for a product is 30 units per month and the items are withdrawn at a constant rate.  The setup cost each time a production run is undertaken to replenish inventory is Rs.15.  The production cost is Re1 per item and holding cost is 0.30 per item per month. Assuming shortages are not allowed.  Determine how often to make a production run and what size it should be.  If shortages are allowed but cost Rs.3 per item per month  determine the frequency of production runs its size. f) Check whether the following zero-sum game has a solution in pure strategies?                       Strategy Player 2 1                          2                        3 Player 1                    1 0 -2 2                                  2 5 4 -3                                  3 2 3 -4 g) Find the steepest descent direction to the function  f(x  y  z) =  100  -  x2  -  2y2  - z2  xy  xz    at (2 1 -1).     (7 * 4 marks) B Level Syllabus R4    326  2. (i) Define a basic solution and basic feasible solution in a linear programming  problem.  Find all basic solutions of the following linear system of equations.    x1 + x3 = 4    2x2 + x4 = 12  (ii) Larry Edison is the director of the computer center for Buckly College.  He now needs to schedule the staffing of the center.  It is open from 8am until midnight.  Larry has monitored the usages of the center at various times of the day  and determined that the following number of computer consultants is required. Time of the day Minimum number of consultants required to be on duty 8am to noon 4 Noon to 4pm 8 4pm to 8pm 10 8pm to midnight 6  Two types of computer consultants can be hired: full-time and part-time.  The full-time consultants work for 8 consecutive hours in any of the following shifts: (8am to 4pm)  (noon to 8pm) and evening 4pm to midnight.  Full-time consultants are paid $14 per hour.  Part-time consultants can be hired to work any of the four shifts mentioned above and are paid $12 per hour.  An additional requirement is that during every time period  there must be at least two full time consultants on duty for every part time consultant on duty.  Larry would like to determine how many full-time and how many part-time consultants should work each shift to meet the requirements at the minimal possible cost.  Give a linear programming formulation for Larrys problem. (iii) Six jobs need drilling first followed by tapering.  Processing times on drill machine and the lathe which does tapering are given as follows: M/c J1 J2 J3 J4 J5 J6       Drill M(1) 4 7 3 12 11 9                            Tap (M2) 11 7 10 8 10 13   Find a sequence that minimizes the make span. (6 * 3 marks) 3.(i) Consider the following transportation tableau.  Use MODI method to determine whether the solution shown (in bold) provides the minimal transportation cost.  If it is not  find the minimal cost solution.  Does the problem have an alternative solution? Find one  if it has so. Destinations / Origin D1 D2 D3 D4 Supply O1                    5  25                    7                  10  50                   5   75 O2                    6                    5                   8 100                   2   75 175 O3                   6  100                    6                 12                   7  100 O4                   8                    5                 100                  14                   4                   50 150 B Level Syllabus R4    327  Demand 125 100 150 125  (ii) Use the branch and bound method to solve the following integer programming problem       Maximize  z = 7x1 + 9 x2    Subject to 5x1 + 7x2  35      4x1 + 9x2  36       x1  x2  0 and are integers (2 * 9 marks)  4.   (i) Find the shortest path between nodes O and T through the following network where the numbers along the arcs represent the actual distances between corresponding nodes.  (ii)   The coach of an age group swim team needs to assign swimmers to a 200 yard medley relay team to send to the Junior Olympics.  Since most of his best swimmers should be assigned to each of the four strokes.  The five fastest swimmers and the best times they have achieved in each of the strokes for 50 yards are Stroke Carl Chris David Tony Ken Backstroke 37 32 33 37 35 Breaststroke 43 33 42 34 41 Butterfly 33 28 38 30 33 Freestyle 29 26 29 28 31  Find the optimal assignment of 4 swimmers to 4 strokes so that the total time of completing the relay gets minimized. (2 * 9 marks) 5. (i) In a highway network the traffic flow capacities are as shown in the figure.  What is the maximal flow in vehicles per hour through the system?  How many vehicles per hour must travel over each road to obtain this maximal flow?  D 6 1 4 5 1 6 5 2 5 O A T E B C 4 7 B Level Syllabus R4    328  (ii) Starting from (2  -2) perform two complete iterations of the steepest descent method to minimize a function f(x  y) = x2 + xy + 2y2.  (2 * 9 marks)  6. (i) Use Linear Programming to solve the following zero-sum game.  Player 1 Player 2                 Strategy Strategy  1                              2                           3 1 0 -2 2 2 5 4 -3 3 2 3 -4 (ii) The following table gives the activities of construction project and duration    Activity  1-2 1-3 2-3 2-4 3-4 4-5   Duration (days) 20 25 10 12 6 10  Draw the network of the project. Find the critical path and minimum time of completion of the project.  (2 * 9 marks)  7. (i)    Assume the following quantity discount schedule.  If annual demand is 120 units  ordering costs are Rs.20 per order  and the annual holding cost rate is 25%  what order quantity would you recommend? Order Size Discount Unit cost 0 to 49 0 30 50 to 99 5 28.50 11 or more 10  27.00 (ii)  Customers arrive at a window with Poisson distribution with mean of 10 minutes and service time 6 minutes per customer. The space in front of window can accommodate only 3 persons including the serviced one. Find the probability that the arriving customer can go directly to the space in front of the window. How long the customer has to wait before getting the service?           (2 * 9 marks)  1 2 5 6 4 3 3 4 6 4 2 2 2 3 3 2 3 3 6 2 B Level Syllabus R4    329  BE10-R4: Applied Operation Research  Practical List  The student is advice to write the computer programs of the following algorithms and implement them on some real life problems. This will enable them to appreciate and understand the theoretical aspects of the course. 1. Simplex Method with mixed constraints & solution of its dual 2. North West corner method in transportation problems 3. Least cost method  4. Vogels approximation method    5. Finding float in a network  6. Replacement of machines w/o P.V.F.  7. Replacement of machines with P.V.F.  8. Replacement of machine 1 with machine 2  9. Shortest path algorithm in networks 10. Dijkastras algorithm 11. Simulation of Inventory  12. Simulation of Queue    13. Any one model from Queuing theory  14. Steepest descent algorithm B Level Syllabus R4    330  BE11-R4: WIRELESS & MOBILE COMMUNICATION   Objective of course  The objective of this course is to provide an overview of wireless and mobile communication. The course covers a broad range of concepts  standard and issues related to wireless and mobile networks. The course will also examine the practical aspects of the issues involved in wireless and mobile communication and standard practices being adopted by the Communication Industry. Students will gain the knowledge  skills and abilities related to hardware  software  technologies  standards and applications used in wireless and mobile communication and their practices in any organization.   The following topics are addressed in this course: aspects of Wireless Communication Technology  Wireless communication types  Digital cellular system and standards  third generation mobile services  Wireless LAN  Broadband Wireless network  Bluetooth technology of communication  Wireless in local loop and operating system and application development for mobile devices. Outline of Course  S.No. Topic                                                   Minimum No. of Hours 1. Overview of Computer Networks                                                                                4 2. Multiple Access Technologies for Wireless Communication                                         6  3. Mobile Data Communication                                                                                       10  4. Personal Wireless Communication Systems                                                                 5  5. Digital Cellular Systems and Standards (2 G)                                                           10  6. Third Generation Mobile Services (3 G)                                                                      6  7. Wireless Local Area Networks (WLAN)  :  IEEE 802.11                                            8  8. Broadband   Wireless Network Standards for WLMAN (WiMax)                                2 9. Bluetooth Technology (WPAN):                                                                                  2                       10. Wireless in Local Loop (WLL)                                                                                      2  11.  Application Development and Operating Systems for Mobile Devices                5     Lectures         60 Practical/Tutorials     60 Total                      120  Detailed Syllabus  1. Overview of Computer Networks                                                                                4 Hrs.      Network Classification  LAN  MAN  WAN etc. and internetworking.   2. Multiple Access Technologies for Wireless Communication                                      6 Hrs.     FDMA  TDMA : Fixed TDM  Pure ALOHA and Slotted         ALOHA CDMA : Spread Spectrum Techniques   3. Mobile Data Communication                                                                                       10 Hrs. B Level Syllabus R4    331  Cellular Telephony  Radiopropagation : Small Scale Fading and Multipath Fading  Speech coding  Error Coding and Error Correction.  Mobility Management  Hand off Management : Soft Hand off and Hard Hand off  Switching and authentication  MTSO Interconnections.  Circuit Switched Data Services on Cellular Networks  Packet Switched Data Services on Cellular Networks.   4. Personal Wireless Communication Systems                                                               5 Hrs.  Personal Communication Systems (PCS) Architecture  Cordless Telephony (CT2)  Digital Enhanced Cordless Telecommunications (DECT)  Personal Access Communication System (PACS)  Personal Handy Phone System (PHS).   5. Digital Cellular Systems and Standards (2 G)                                                          10 Hrs.  Global System for Mobile Communication (GMS) System Overview : GSM Architecture  European TDM  Digital Cellular Standard  GSM Protocol model  GSM mobility management  Short Message Service (SMS) security aspects.  Analog Mobile Phone Service (DAMPS) : IS-136 North American TDMA Standard. Code Division Multiple Access (CDMA) :  IS95 Digital Cellular Standard.  General Packet Radio Service (GPRS) : GPRS Architecture  GPRS Network  Interfaces and Procedures (2.5 G).   6. Third Generation Mobile Services (3 G)                                                                  6 Hrs. UMTS and International Mobile Telecommunications (IMT-2000)  W-C DMA and CDMA 2000  Quality of Service in 3 G.  7. Wireless Local Area Networks (WLAN)  :  IEEE 802.11                                      8 Hrs.  Components and working of WLAN  Transmission Media for WLAN : Radio Transmission  Infrared Transmission  (IrDA)  Direct Sequence Spread Spectrum Technology (DSSS)  Frequency Hopping  Spread Spectrum technology (FHSS)   IEEE 802.11 standards and WLAN types : Ad-hoc WLAN  Infrastructure WLAN.  Protocols for WLAN : CSMA/CA  RTS/CTS  Hidden Terminal Problem  Wired Equivalent Privacy (WEP) Products for WLAN: Access Points and WLAN (Wi -Fi) cards.   8. Broadband   Wireless Network Standards for WLMAN (WiMax)                              2 Hrs. WiMax Model and Architecture  WiMax Protocols and 802.16 standards Protocols and  9. Bluetooth Technology (WPAN):                                                                                  2 Hrs.                       Introduction to Personal Area Networks (PAN): Features and Goals  Bluetooth Architecture   IEEE 802.15 standards  Protocol Stack  Bluetooth products and security  10. Wireless in Local Loop (WLL)                                                                                      2 Hrs. WLL Architecture  WLL Technologies  WLL Products. B Level Syllabus R4    332  11.  Application Development and Operating Systems for Mobile Devices         5 Hrs.     Introduction to Windows CE  Palm OS  Symbian O/S  Application development using Nokia Tool-Kit.  Development tools for Java  J2ME  Embedded Java. RECOMMENDED BOOKS  MAIN READING   1. Theodore S. Rappaport  Wireless Communications: Principles and Practice  Second  Edition  2002  Pearson Education Asia. 2. Jochen Schiller  Mobile Communication  2000  Pearson Education Asia. 3. Rajesh & Balasubramanian Computer Networks : Fundamentals and Application  2002         Vikas Publishing House.. 4. Hansmann  et. Al. Principles of Mobile Computing  Springer-Verlag Publishers  2003.  SUPPLEMENTARY READING  1. Raj Pandya  Mobile and Personal Communication Systems and Services  Prentice Hall         of India  2001. 2. Yi-Bing Lin and Imrich Chlamatac  Wireless and Mobile Network Architectures  John          Wiley and Sons.  2001. 3. Dr. Kamilo Feher  Wireless Digital Communication: Modulation and Spread Spectrum             Applications  Prentice Hall of India  2005. 4. Asoke Talukder  Roopa Yavagal  Mobile Computing: Technology  Applications and           Service Creation  TMH Publishing Co.  2005. B Level Syllabus R4    333  BE11-R4 Wireless & Mobile Communication Practical Assignments Assignment 1 Study the Wireless Application Protocol.  Assignment 2. Write a Program that shows the welcome greeting on a simulator screen. (Simulator can be Openwave/Nokia WAP toolkit / any online emulator) Assignment3. Study of Nokia Mobile Browser (NMB)  Nokia Mobile Internet Toolkit (NMIT) and Nokia Mobile Gateway Simulator tools Assignment4.  The Information Master Application The Information Master application deals with providing information about movies and the weather to the client. Its made up of three WML files  one WMLS file and one graphic file. The script file has just one function for generating the random numbers for the display of maximum and minimum temperatures on the screen. Application Structure The case study discussed here contains the following files : Information.wml Movie.wml Weather.wml Weather.wmls Sun.ico  The first three files are the WML application files; the fourth is the script file that will be used by Weather.wml file  Sun.ico is an image file used to display the image of sun on the browser screen by the Weather.wml code file.   Application Work Flow   B Level Syllabus R4    334  The application opens a menu with two options: Movie and Weather  if the user clicks Movie  the Movie.wml file  which displays the name of movies and show timing  appears.  If the user clicks Weather  the Weather.wml file  which display the maximum and minimum temperatures of various cities on the screen  appears. The temperatures are generated by using Lang.rand() in the script file and by Weather.wml to display them on-screen.   Assignment 5.  The Restaurant Application   This application starts with a menu from which the user can select different items to order from restaurant. After the user selects the items  the bill is generated accordingly.   Application Structure The application is made up of file files: ResScript.wmls  The scripting file Restaurant.wml  The main menu file to select the category South.wml  Link file to select items of the South India dishes category Soft.wml  Link file to select items of Soft Drinks category Snacks.wml  Link file to select items of Snacks category Application Work Flow The main file is Restaurant.wml  which shows three items: South Indian (South.wml) Soft Drink (Soft.wml) Snacks (Snacks.wml) After you click a particular item  the system calls the corresponding WML file and shows the item related to that category. B Level Syllabus R4    335  Assignment 6.  To do list:  creation of child process with error handling capacity  (spawn  throw  catch)  once can use ""fieldset"" to group the similar elements  should provide information regarding deck and its access control information  (head)  ""link"" option  ""postfield"" option for passing information to http server  ""receive"" from child process  ""table"" for tabular structure  ""timer"" to perform some task after some period Assignment 7. Write a program which displays the information in a formatted form.  Assignment 8. Write a program which displays the information in an aligned form with                             images.  Assignment 9. Write a program to create a screen saver.  Assignment 10. Introduction of WML script library and dialogs library and programs based                              on this.   Assignment 11 Programs using language Library.  Assignment 12. Programs using float library and string library.  Assignment 14. Programs using URL library and WML browser library.  Assignment 14. Programs on connectivity between database and WML scripts.  Assignment 15. Implement game using WML and WML script.  Assignment 16. Create small application with J2ME to display greetings.  Assignment 17.  Create an application in J2ME to demonstrate sending and receiving                                SMS.  Assignment 18. Design small website using WML/WML Script.  Assignment 19. Do the complete project by the end of the semester. You can come up                                with your own ideas. some of the listings are done for your help (project                               is among 3-4 students)  Select any game for mobile  To update the stock values from the website. if the change is beyond certain    limit  message should be flashed on the screen  Location based service to be provided for the mobile user  Sending SMS in group. Things will be controlled by the PC  address book  B Level Syllabus R4    336                          and other things will be maintained by PC. SMS sending will be done                         automatically.  SMS Banking  Tamper proof. If the mobile is not unlocked and still some person is tampering the keys of the instrument  then some kind of bad noise and bad pictures should start on its own. This is to disturb the person so that he/she stops playing with the mobile keys.  Note: The projects can be done using WML and WML Scripts. If some group students wish to do the project using .NET Compaq libraries or JAVA  they can go for it. B Level Syllabus R4    337  BE12  R4: Information Storage & Management  1. Course Objectives  The elective module on Information Storage & Management provides detailed knowledge  practical training  and insight into the implementation and management of various storage technologies with a focus towards applying these technologies in an information lifecycle paradigm. This module focuses on the following key aspects:   The evolution of storage and implementation models  Storage devices principles including structure  host I/O processing  & core algorithms  Storage classes (SAN  NAS. CAS)  interconnection protocols  and management principles  Storage network design principles  Networked storage capabilities (Snaps  mirroring  virtualization)  Backup  Business Continuity  and Disaster Recovery principles  Storage implementation planning and analysis  Tiered storage models using hybrid storage technologies  2. Pre-requisites to take the elective module on Information Storage & Management   At a minimum  a student should have successfully completed the following modules:  M3-R4 Programming & Problem Solving through C language A4-R4  Computer System Architecture A6-R4  Data Structures through C++ Language A9-R4  Data Communication & Computer Network Infrastructure A8-R4  Operating Systems  3. Why the new elective in Information Storage & Management?  With the advent of internet & the increased use of computers  the volume of information being handled by individuals & organizations is increasing at a very fast pace. This has necessitated the use of large storage devices & the management thereof.  The elective module on Information Storage & Management provides detailed knowledge  practical training  and insight into the implementation and management of various storage technologies with a focus towards applying these technologies in an information lifecycle paradigm.   4. Hardware Requirements  Processor: Pentium III or higher  Memory: 256 MB or higher  Video card: standard video Minimum Display resolution: 1024 X 768 Free space in hard disk: 150 MB beyond base OS  other applications  and local files. (The simulator environment is a 50MB+ download) CD/ROM drive: not needed  unless installing from CD Mouse: Standard Audio: Sound Card/Speakers or headphones B Level Syllabus R4    338  5. Software Required  Minimum Browser: IE 5.X Supporting Software: Java  JavaScript  Real Player  Shockwave/Flash:  Java Run Time Environment (JRE ) 5.0 or later Operating System: Windows 2000  XP   or later  6. Course Outline  S.No Topic Lecture (hours) Tutorial/Practicals (Hours) 1 Introduction to Storage Technology 9 8 2 Storage Systems Architecture 8.5 10 3 Introduction to Network Storage 9.5 9 4 Introduction to Information Availability 5.5 6 5 Managing and Monitoring 4 4 6 Networked Storage Design  SAN 14.5 13 7 Networked Storage Design  NAS 10 10 Total (Hours) 61 60  7. Detailed Syllabus  Section 1 Introduction to Storage Technology    (9 hours) Data proliferation and the varying value of data with time & usage  Sources of data and states of data creation  Data center requirements and evolution to accommodate storage needs  Overview of basic storage management skills and activities  The five pillars of technology  Overview of storage infrastructure components  Evolution of storage  Information Lifecycle Management concept  Data categorization within an enterprise  Storage and Regulations  Section 2 Storage Systems Architecture           (8.5 hours) Intelligent disk subsystems overview  Contrast of integrated vs. modular arrays  Component architecture of intelligent disk subsystems  Disk physical structure- components  properties  performance  and specifications   Logical partitioning of disks  RAID & parity algorithms  hot sparing  Physical vs. logical disk organization  protection  and back end management  Array caching properties and algorithms  Front end connectivity and queuing properties  Front end to host storage provisioning  mapping  and operation  Interaction of file systems with storage  Storage system connectivity protocols  Section 3 Introduction to Networked Storage             (9.5 hours) JBOD  DAS  SAN  NAS  & CAS evolution  Direct Attached Storage (DAS) environments: elements  connectivity  & management  Storage Area Networks (SAN): elements & connectivity  Fibre Channel principales  standards  & network management principles  SAN management principles  Network Attached Storage (NAS): elements  connectivity options  connectivity protocols (NFS  CIFS  ftp)  & management principles  IP SAN elements  standards (iSCSI  FCIP  iFCP)  connectivity principles  security  and management principles   B Level Syllabus R4    339  Content Addressable Storage (CAS): elements  connectivity options  standards  and management principles  Hybrid Storage solutions overview including technologies like virtualization & appliances.  Section 4 Introduction to Information Availability             (5.5 hours) Business Continuity and Disaster Recovery Basics  Local business continuity techniques  Remote business continuity techniques  Disaster Recovery principles & techniques  Section 5 Managing & Monitoring      (4 hours) Management philosophies (holistic vs. system & component)  Industry management standards (SNMP  SMI-S  CIM)  Standard framework applications  Key management metrics (thresholds  availability  capacity  security  performance)  Metric analysis methodologies & trend analysis  Reactive and pro-active management best practices  Provisioning & configuration change planning  Problem reporting  prioritization  and handling techniques  Management tools overview  Section 6 Network Storage Design - SAN           (14.5 hours) Basic SAN design criteria  Fibre Channel infrastructure design principles  Storage needs data collection: existing  growth capacity  performance requirements  data location  business continuity and disaster recovery needs  data center consolidation requirements  etc.  Requirements data  & infrastructure analysis  Developing a SAN design plan with emphasis on the key design criteria:  scalability  availability  performance  security  capacity  and manageability  SAN design components  infrastructure models  properties  and usage patterns  Studies and critiques of existing SAN design scenarios (partial mesh  full mesh  core/edge  & tiered designs)  SAN management activities associated with design (configuration  discovery  zoning  LUN masking  login rights  etc.)  Advance SAN management topics: SNMP configuration  policy management  task automation  Section 7 Network Storage Design - NAS     (10 hours) Basic NAS design criteria  Network infrastructure design principles  NAS unique technologies:  Wide Area File Services (WAFS)  and policy based hierarchical storage management (HSM)  Storage needs data collection: existing  growth capacity  performance  requirements  data location  business continuity and disaster recovery needs  data center consolidation requirements    NAS unique requirements:  protocol usage  server consolidation needs  network traffic loading  global data access needs  WAN requirements  Requirements data  & infrastructure analysis  Developing a NAS design plan with emphasis on the key design criteria:  scalability  availability  performance  security  capacity  and manageability  NAS design components  infrastructure models  properties  and usage patterns  Studies and critiques of existing NAS design scenarios (local area  LAN core/edge  WAN core/edge  WAFS  & HSM  NAS management activities associated with design (protocol configuration  discovery  permissions mapping  data migration)  Advance NAS management topics: SNMP configuration  policy management  task automation  VTLU setup  FTP setup  Windows server consolidation  LAN trunking  IP SAN considerations:  client / LUN mapping  CHAPS authentication  driver interoperability  security considerations  B Level Syllabus R4    340  8. Recommended Books  Main Reading   1. Marc Farley Osborne  Building Storage Networks  Tata McGraw Hill  2. Robert Spalding  Storage Networks: The Complete Reference   Tata Mcgraw Hill   Supplementary Reading   1. NIIT  Introduction to Information Security Risk Management   Prentice-Hall of India   9. Examination Pattern   The theory examination for the module would be for three hours and the total marks for the subject would be 100. There can be one practical examination of 100 marks.   Other homework  papers  and spot quizzes can be given by the individual instructor at their discretion. 10. Credit Scheme  Total Number of theory hours = 60 Total Number of Tutorials/Practicals hours = 60 L( No. of hours per week for Lectures) = 3 T/P(Number of hours per week for Tutorials/Practicals) = 3 Credits for the module = 5 Total number of credits has been calculated using the AICTE formula C= L+ (T+P)/2 where L  T and P indicate the number of hours per week for lectures  Tutorials and Practicals  B Level Syllabus R4    341  BE12-R4: Information Storage & Management Model Question Paper Duration: 3 hours                                    Maximum Marks:        100 Marks  Questions 1  8 are compulsory.  Choose any five questions from Questions 9 to 19.  1)  a)  What are the Five Pillars of Information Technology? b) For a financial institution  specifically for a bank  given examples of active data  inactive data  and Aged Data                                           (5 Marks)  2) Describe and contrast the environmental  operational  and infrastructure in a data center that would tend to make you use of NAS instead of SAN or SAN instead of NAS? Outline what the impact of these considerations would be?      (5 Marks)  3) Outline 4 key factors in operation risk assessment when planning business continuity and how they impact the process of planning for business continuity?                    (7 Marks) 4) You have purchased an intelligent disk subsystem for you data center.  Pertinent facts about this purchase are:  This subsystem has 10 spindles which can be configured as RAID 0  up to 5 LUNs of RAID 1  or 2 LUNS of RAID 5.    Each spindle holds 150 GB of data formatted  The array has two connections to the SAN switch which can  on average  process 80 MB/sec.  The array has two individual processors which  on average  can process a sustained load of 70 MB/sec  Each storage process can read/write to LUNs assigned to it at native speed.  Each storage process can read/write to LUNs not assigned to it at  the sustained throughput  Each spindle in the array on average can sustain a load of 5 MB/sec  The array will be connected to 4 servers  each dual connected to the SAN switch.  The data load and requirements: Server nameStorage requirement Sustained throughput A 100 GB 20 MB/sec B 500 GB 50 MB/sec C 300 GB 10 MB/sec D 700 GB 70 MB/sec Describe how you would configure the storage for this environment and why?  Provide an estimate of the maximum through put you would expect from this array given the performance data provided and explain how you derived this estimate.                                   (10 Marks)    5) You are the storage administrator for a data center that currently has 700 GB of active storage on fibre channel  RAID 5 based storage. An additional 200 GB of old  archived data is kept on RAID 5  ATA based storage.  Your new  active data increases at a rate of 2 GB/Day.  0.1 GB/day of archived data is restored to active status. 0.3 GB/day of active data can be migrated to archive status. Answer the following questions and explain how you reached your results: a) How much total Fibre Channel storage will you need in 1 year (365 days) from now?  B Level Syllabus R4    342  b) How much total ATA storage will you need in 1 year (365 days) from now?  c) How much additional Fibre Channel storage will you need for the next year?  d) How much additional ATA storage will you need for the next year?  e) Can you eliminate any storage over the course of the next year?  If so  state how much. If not  explain why not.     (10 Marks)  6) Explain  in brief terms  the difference between the different types of Networked Storage?               (5 Marks) 7)  What factors govern disk I/O performance?  Which are most significant?    (10 Marks)  8)  Answer the following questions about business continuity concepts: a) What is the operational difference between a point in time copy and a clone? b) What is the common name for a point in time copy? c) Contrast and compare under what operational conditions would you use a point in time copy as compared to a clone? d) Explain the operational differences between a synchronous mirror and an asynchronous mirror. e) Under what operational conditions would you use a synchronous mirror?                 (8 Marks)  9) An automated data characterization of an existing small data center shows the following general size information (all values in GB): Server purpose .doc .xls .ppt .txt .mp3 / .jpg .pdf .pst  other Home directories 40 5 20 1 50 2 55 2 Source code  1 0 1 6 0 0 0 223 Database server 20 2 2 20 30 0 0 119 E-mail 4 3 8 1 5 1 435 4  Using the information from the table provide your best estimates (in GB) of:  a) How much data is picture or video based? b) How much data is part of an active database? c) How much data is file & print data? d) Which data and how much data must be protected to ensure that active databases and e-mail is available? e) What is the percentage of e-mail  active database  source code  and other data?                 (8 Marks)  10)  Explain the functional differences and benefits of the following disk seeking algorithms:  FIFO (first in  first out)  smallest I/O request first  largest I/O request first  shortest track distance first Which method is the best?  Justify your answer.         (8 Marks)  11) You manage a small data center in Mumbai with 20 servers and total storage of 5 TB of data in 2 individual storage arrays. A data characterization study shows: B Level Syllabus R4    343   40% of the data is mission critical databases with a change rate of 200 GB/day  20% of the data is email with a change rate of 10GB day.  10% of the data is file and print for user accounts with a change rate of 1 GB/day  30% of the data is test generated data with a change rate of 500 GB/day Your data center is located on the first floor of a building located near the airport and is susceptible to occasional flooding during monsoon. You have sister facilities in Pune and Chennai.  You have been tasked to develop an affordable disaster recovery plan that covers the most crucial activities for business operations. Assume no growth in data over the next year.  What strategy would you recommend?  In your answer be sure to specify:  What DR situations would you plan for and why?  Which site would you use as a DR site and why?  What data would be included in the DR plan?  What technologies would you use in building the DR plan?  How would the DR process work?    (8 Marks) 12) You are planning to setup an asynchronous mirror between Bangalore and New York.  Your analysis of the data and connectivity testing show:  A sustained throughput through the link of 400 Kbps.  You cannot commit more than 40% of the link capacity to the mirroring operation.  The data set to be mirrored is 200 GB.  The change rate of this data set is 5% per day. Answer the following:  What is the throughput that can be committed to mirroring?  How long will it take to silver the mirror over the existing link?  How much change data will be queued up during this silvering process?  What size would you recommend for each change set? Why?  How often would you ship change sets from the primary array to the mirror? Why?  How long could the mirror be broken before you would recommend re-silvering the mirror from scratch?      (8 Marks) 13) You have a ""hot"" failover site setup between your primary campus in Bangalore and your backup site in Mysore (60km) using synchronous mirroring. Your workers are housed in a second site in Bangalore that connects to the primary data/server site via the network.    What would be the key steps to execute a successful failover to the secondary site?    What would be the key steps to fail back to the primary site?               (8 Marks) 14) You have been tasked with setting up a high performance NAS file server.  Environmental conditions you know include:  The NAS device will have 4 network interfaces  one per front end processing unit  and each interface will be attached to a different LAN  There are 2000 users spread evenly over the 4 local area networks  Each user is to receive 2 GB of space for use  The intelligent storage array has four independent fibre channel loops with each disk dual ported to independent loops  The disks purchased are 140 GB fibre channel disks; there are 10 disks per shelf in the array.   All the disks in the same shelf must be tied to the same two fibre channel loops  There can be no more than 10 shelves in the array  The user directories must be laid out on RAID 5 storage Understanding that the goal is to get the best I/O performance you can by maximizing the use of spindles and loops explain the following (use drawing as necessary):  B Level Syllabus R4    344  How would you connect the disk shelves to the fibre channel loops?  How would you organize RAID groups on the shelves?  How would you allocate file systems to these LUNs?                (8 Marks) 15) Describe the basic principles of how Content Addressable Storage works. Be certain to discuss how object tagging and data protection works with a CAS device.                      (8 Marks 16) Contrast the behavioral difference between the protocols CIFS  NFS  and FTP.  Be certain to discuss how these protocols operate and cover the impact that network disconnects have relative to each protocol.         (8 Marks) 17) Outline the basic structure of the SMI-S and CIM standards.  Which is used for what types of management operations?          (8 Marks) 18) You are responsible for establishing a standard backup process for your data center. Your data center is arranged as follows. BackupServerIPIPSANSANServersTapeLibraryStorageSpecifics are:  There are 2 storage arrays each holding 2 TB of data to be backed up.  The storage arrays have 2 connections to the SAN for load balancing  but can supply only 60 MB/sec of data on average.  There are two dual CPUs backup servers.  Each backup server can move 30 MB/sec to the tape library.  The tape library has 4 tape drives each connected to the SAN via a separate fibre channel connection  Each tape can write  using compression  up to 50 GB/tap at a sustained rate of 10 MB/sec. Answer the following: a) What components in this data center limit the total backup throughput? b) What is the maximum data throughput that can be committed to tape? c) How many tapes are required to make a full back up of all the data? d) Assuming you can keep the backup running at maximum speed  how long will it take to put a full backup to tape in the library?    (8 Marks) 19) Answer the following questions about IP storage: a) Describe briefly the differences between iSCSI  FCIP  iFCP. b) Explain how CHAPS authentication works for iSCSI c) Describe the I/O flow in an IP SAN environment.   (8 Marks) B Level Syllabus R4    345  BE12-R4: Information Storage & Management Example Practical / Project Assignments Sample Exercise 1   (Section 5  Lab 1  Monitoring Case Study  3 hours)  You work for an enterprise with a main campus located in New Delhi with remote offices located in Hyderabad  Bangalore  and Mumbai. Each office remote location is connected to the main campus through ATM backbone using VPN tunneling with firewall security  and each remote office has its own firewall for WAN access. The main campus has 50 servers for various applications and 10 TB of storage platform supporting approximately 500 employees  remote office in Hyderabad has 30 servers and 8 TB of storage platform supporting 200 employees  remote office in Bangalore has 50 servers and 12 TB supporting 600 employees  and the remote office in Mumbai has 25 servers and 10 TB of storage platform supporting 300 employees. Keeping these requirements in mind  perform the following  1. Research and identify network monitoring tools available in market today best suited for your enterprise            120 min 2. Design a monitoring infrastructure for these enterprise using SNMP protocol  for performance monitoring  CPU and memory monitoring  host performance  Channel and connectivity performance  Storage array performance  spindle contention  and trend analysis             120 min 3. Redesign step 2 using TCP/IP             60 min 4. Discuss and explain pros and cons for the design you recommended in step 2 and step 3  make sure that you consider cost of solution in your discussion         50 min 5. If you are in a budget approving authority  which design will you pick to implement in your enterprise               10 min  Sample Exercise 2   (Section 5  Lab 2  System Management Case Study  3.5 hours)  You are responsible for provide IT related service to several large corporations in USA with an agreed upon SLA with mandates you to have 99.1% uptime  business continuity  and disaster recovery with no down time during a natural or man-made disaster. i. How would you approach to show your customers that you are compliant with the terms in SLA                 30 min ii. How can you achieve a cost effective management system for your customers -15 min iii. How do you plan to deploy patches and updates to the machines with the enterprise       15 min iv. Conduct research to determine at least three off-the-shelf management system capable of solving issues on steps i  ii  and iii              120 min v. Select one of the management system from your research and discuss why you selected the tool              30 min  B Level Syllabus R4    346  Sample Exercise 3   (Section 4  Lab 3  Disaster Recovery Case Study  3 hours)  You manage an enterprise for a software services company in Mumbai with 30 servers in a cluster configuration with 100 TB of storage platform  your company has a remote office in Chennai with 20 servers with 100 TB of storage platform  and you have a joint venture with another software company in Kashmir which has recently purchased 500 TB of storage platform  and currently only utilize 50TB of that storage platform. You have VPN connectivity with the Joint Venture partner in Kashmir and have permission to utilize their available storage platform for up to 400 TB.   Federal government of India has just notified the state officials that a typhoon is forming in the Arabian sea and it is projected to reach Mumbai as early as 72 hours or as late as 96 hours. You have connections within state government  and your connection informs you that according to the projections  Mumbai will have massive flooding and your office location will definitely be under water with no power for several days  you have no disaster recovery plan in place and business continuity is essential for your business. Take 60 minutes to develop a disaster recovery plan individually.  Your instructor will divide the class in several groups. Once you are in your group  discuss your plan with others  and formulate a disaster recovery plan based on best practices within the plans in the group  prepare to answer questions as why certain practice was chosen when you formulate a group plan-        60 minutes  You have 15 minutes to present your group plan to the class               60 minutes  Sample Exercise 4   (Section 2  Lab 1  Seeking Algorithm Assignment  6 hours)  This exercise will allow us to study the effects of several disk seeking algorithms. You will develop a software simulation program that will mimic the physical behavior of a disk drive under an I/O load. You will then vary the program by changing the disk seeking algorithm to study how performance changes based on the behavior of the algorithm.  This exercise will be completed in 3 parts:  Part 1 Develop a program to simulate the behavior of a disk drive Part 2 Develop procedures for different seeking algorithms that can be substituted into the simulation program Part 3 Run the simulation with varying I/O loads against each seeking algorithm. Plot the resulting data to show how disk throughput varies based on I/O load and seek algorithm.  Part 1 The physical parameters of the disk under study are:  Number of writable platters 4 Number of cylinders / platter 512 (numbered 0  511) Number of sectors / cylinder 8 Read time of a sector 8 msec Disk RPM 5400 Head movement delay 20 usec / track Avg. electrical switching delay per I/O 3 usec Logical sector addresses 0  16383  logical sectors 0  4095 are on platter 0  4096  8191 are on platter 1  and so on in sequential order. Sector size 512 bytes / sector Writable disk size 8 MB  B Level Syllabus R4    347  An I/O into this simulation model will be a logical sector number (0  16383) and an I/O request size (0  64 sectors).  The program must keep track of the disk head position relative to the physical cylinder and the last logical block number read at all times.  Assume when the program begins that the heads are on cylinder 0 nearest to the spindle and at logical sector address 0.   For the purposes of this assignment assume that the disk is under constant load and that as soon as an I/O is completed another is queued to be processed with no delay.  Also assume that for measurement a total of 10 000 I/O requests will be processed to determine the throughput.  Note  make the number of I/O request to process be an input item to the program on each run.  We will vary this later.  For the purposes of Part 1 assume that all I/O processing is FIFO (first in  first out). This means the I/O requests must be processed in the order they are received.  You program will use a random number generator of your design to get the logical sector number and I/O request size for each I/O.  The program  using the current known state of the simulation environment from the preceding I/O request will calculate the time required to process the I/O.  These processing times will be summed for each of the 10 000 I/O requests.  When the simulation is complete it will report:   Total time to service the 10 000 (or whatever) I/O requests (sec.)  Average I/O request time (msec)  Throughput of the disk for this I/O load (I/Os / sec.) The average electrical switching delay should be added to each I/O request. You may assume that  of a rotational delay must be added for each track read from to satisfy the I/O request.  Part 2  Develop procedures for seeking algorithms to replace the FIFO seeking model and verify that the algorithm works properly with the base simulation program. The algorithms to implement are  First in  First out (FIFO). This was done in Part 1 Minimum seek Implement a logical I/O queue of 5 requests and immediately fill it with the first 5 I/O requests.  Sort this queue so the next I/O request to process is the closest of the 5 to the current logical sector address.  This list should be resorted with the addition of each I/O request.  For each sorting algorithm add 2 usec to each I/O request to cover the sorting overhead. Maximum seek Using the same 5 request queue in the minimum seek algorithm order each I/O request so that the next I/O request to be processed is the furthermost logical sector address from the current logical sector address. Update this ordering with each new I/O request. Assume the same 2 usec time addition for each I/O request as you did for the minimum seek algorithm. Large request size seek Using the same 5 request queue from the minimum seek algorithm order the I/O requests so the largest I/O request gets processed next. Update this ordering with each new I/O request. Assume the same 2 usec time addition for each I/O request as you did for the minimum seek algorithm. Small request size seek Using the same 5 request queue from the minimum seek algorithm order the I/O requests so the smallest I/O B Level Syllabus R4    348  request gets processed next. Update this ordering with each new I/O request. Assume the same 2 usec time addition for each I/O request as you did for the minimum seek algorithm. MySeek Algorithm Develop your own seek algorithm staying within the following parameters.  The I/O queue must be 5 I/O requests.  For each manipulation of the queue you must add 2 usec to the I/O processing time. Part 3  Using the simulation and seek algorithms developed in Parts 1 & 2 run the simulations in the table below:  Seek Algorithm I/O requests FIFO 100 500 1000 5000 10000 Minimum seek algorithm 100 500 1000 5000 10000 Maximum seek algorithm 100 500 1000 5000 10000 Large request size seek algorithm 100 500 1000 5000 10000 Smallest request size seek algorithm 100 500 1000 5000 10000 My Seek algorithm100 100 500 1000 5000 10000  Provide 2 graphs based on this data. The first should show disk throughput  by algorithm  as a function of number of I/O requests.  The second graph should show average I/O request time  by algorithm  as a function of the number of I/O requests.  Sample Exercise 5   (Section 8  Lab 2  Unique File Key Study  3 hours)  A basic principle of content addressable storage is concept of deriving a unique ID tag based on the contents of a data object and being able to retrieve the data object based on this id tag. In this exercise we will undertake the following:  Develop software to build a unique key for files submitted to the store  Store the files based on the key tag  Develop a method for handling ID tag collisions  Demonstrate file retrieval Part 1  unique file key procedure  Develop a procedure that will build a unique key for a file submitted to it for analysis. For this exercise we will assume that all our storage will consist of text files.  You are free to use any technique you like  but we recommend for simplicity you develop the key by summing together the individual bytes of a file into a 32 bit unsigned integer allowing the overflow to fall off. For example the text string ABCD would evaluate as:  Binary (16 bits) decimal character 0100 0001 41 A 0100 0010 42 B 0100 0011 43 C 0100 0100 44 D 0101 1010 170 N/A  This procedure will take any file presented to it and compute a unique key. This key (a 32 bit unsigned integer) will be returned from the procedure.  B Level Syllabus R4    349  Part 2  File repository & data store  Using the procedure from part 1  expand your program to accomplish the following tasks:   Create a directory to serve as a file repository.  Through a simple user interface query the user for a filename or pathname of a file to be added to the repository.  Open the file specified and generate a unique key for the file using the procedure from part 1.  Present the user with the key number (as an unsigned integer) along with the original file name.  Copy the file to the file repository saving it under a filename which is the unique file key converted to a text string.  For example  the filename of the example in part one would be 41.  Store the file key and the original file name in an array or linked list catalogue for later usage.  Ensure this user interface will allow the user to submit multiple files into the repository  Demonstrate that the program at this stage will place files into the repository correctly with the correct file key.  Part 3  File retrieval  Expand the program from Part 2 to accomplish the following:   Modify the user interface to support both file repository submission and retrieval.  For file retrieval present the user with a list of the catalogue contents sorted by original filename.  Allow the user to select the file for restoration using the position number in the list.  When a file is selected for retrieval  use the file key to find and open the file in the repository.  Ask the user where to place the file being retrieved (pathname) and copy the file to that directory giving it the original filename.  Return the use to the main menu for additional file storage or retrieval operations.  Demonstrate that file retrieval works properly.  Part 4  File Key Collisions  Expand the program from part 3 to handle situations where a file  due to its content  generates the same file key.  For this exercise submitting the same original file twice to the repository or two individual files with the same content will generate this scenario.   Specifically expand the program to accomplish the following:   When a file key is generated check the catalogue to see if it is a duplicate.  Expand the catalogue to hold not only the file key and original file name but also add a sequence key.  When a file is stored in the repository for the first time set its sequence key to the integer value 0.  If a file key is duplicated determine what the last sequence number was and add one to the sequence number when this catalogue entry is made.  Store the file in the repository using a filename that is based on the file key and sequence number.  Using our example from part 1 the second file with that key would be named 41-1. B Level Syllabus R4    350   Expand the file retrieval list to show the sequence number. Be sure to sort the retrieval list alphabetically by filename and sequence number.  A file retrieval is copied to the destination directory. If the file already exists store the file by the original filename hyphenated with the sequence number. Demonstrate that this final program version can store and retrieve file with duplicate file keys.  11. Example Subjective Questions and Answers  1) Question Describe environmental conditions that would tend to make you use NAS instead of SAN or SAN instead of NAS? Answer When making the evaluation of SAN over NAS or vice-versa I tend to look at the following aspects:   What are the performance requirements of the storage solution?  What is the storage model in use today?  What would be the infrastructure cost for any proposed change in storage solution?  What applications must be used in conjunction with this storage solution?  What is the training & background of the storage administration staff?  What is the management style of the storage administration staff?  What is the networking (IP & Fibre Channel) capability of the customers environment?  None of these aspects in and of itself would mandate a specific solution  but the alignment  or non-alignment of these aspect give guidance about what storage solution models are likely to be acceptable to the customer. Looking deeper:   If the storage solution will be under constant heavy I/O load or needs to meet specific response times requirements in a variable I/O load model then I would give preference to a SAN solution. In general the performance will be greater with less variability in I/O response times.  If the customer is already significantly invested in SAN infrastructure it is often the case that you can expand or leverage existing infrastructure saving costs. Likewise  customers having existing SANs will typically be over much of the initial training hurdle that SAN management typically entails. However  if the customer has no pre-existing SAN  nor preference to it then I would lean toward NAS.  Most customers will have the necessary infrastructure (10 Mpbs / 100 Mbps / 1 Gbps networks) in place. Some will argue that NAS management is easier than SAN management  but given many of the concepts are the same it is not clear this is an advantage for NAS.  If the infrastructure change is small then proposing either SAN or NAS if probably fine depending on customer preference.  However  if the customer does not have a SAN infrastructure and would need to make a significant investment then NAS is typically the cheaper cost option on a per-port basis. However  one must be care about the type of infrastructure.  If the customer needs 1 Gbps network to sustain the load  but has only a 10 or 100 Mbps infrastructure the cost of new network cable and switches normalizes the cost quickly between the two options.  Applications are not created equal when looking at SAN and NAS storage. Most applications will work with both. Some applications do not tolerate variable network response times gracefully. Such applications are not good candidates for NAS. Some older database applications were susceptible to this.  Likewise  many applications do not need the higher I/O throughput capabilities of SANs (file and print services come to mind). So unless there are other reasons  like increasing disk utilization  for moving to a SAN the additional cost may not be worth it. B Level Syllabus R4    351   If the storage administration staff has no experience with SAN then starting with NAS can often be an easier transition.  The storage management is more like what most administrators are familiar with from setting up and managing Windows based servers.  However  experienced UNIX administrators who are familiar with logical disks  software RAID  etc. will not be daunted by SANs. The big thing is to identify any knowledge gaps and organize the training necessary to ensure storage administration happens correctly.  Finally is the aspect of style.  Administrators who want to have direct control over every option at every level of the infrastructure tend to want and like SAN administration for they can interact at the lowest levels of the storage infrastructure.  Administrators who are task oriented tend to like NAS administration better.  In most NAS platforms you can work and administer at the lowest levels  but in general most NAS administration is task oriented vs. object oriented. 2) Question What factors govern disk I/O performance?  Which are most significant? Answer Disk performance is governed by many characteristics  some that even interact with others. In general the key factors  in order of performance contribution  break down into:  Seek time In general  this is the time to move the head from one track on the platter to another track. However  the actual seek time can be influenced by the algorithms used in the disk firmware to order the seeks (trying to minimize seek time)  the incoming I/O pattern  the command queue depth on the disk (impacts seek ordering)  movement speed of the heads  the layout of sectors on a track  the physical diameter of the platter  and the inter-track gap on the platter surface. Rotational delay This is the time it takes for a specific sector on a track to pass beneath the read/write head.  It is governed almost exclusively by the rotational speed of the disk  but can also be influenced by newer variable speed disks that will vary the rotational speed slightly based upon track positioning to allow more sectors on a track to increase overall capacity. Electrical Delay This is the time required by the disk firmware to read and analyze I/O requests plus the time necessary to perform any electrical switching to match up read/write head with the processing electronics and channel selection for multi-channel drives. Of the parameters given seek time is the most dominate constituting usually over 60% of the overall performance. 3) Question Outline 4 key factors in operation risk assessment when planning business continuity and how they impact the process of planning business continuity? Answer In planning business continuity I would pay attention to the following factors:  What are the types of data in my business?  What is the intrinsic value of each to my business?  How does the business value of each data class vary over time?  How does each data class drive my ability to earn revenue?  How venerable is each class of data to damage or loss via man-made disaster  damaged equipment  weather disasters  planned operational down time  system overloading?  What is the restoration time requirement for each class of data to be available before there is 5% revenue impact to my business  25%  & 50%?  I would work through a process of completing the categorizations for each key areas above and sift the results. This results should yield  in general  a two dimensional table with the B Level Syllabus R4    352  business value (in terms of revenue impact) on one axis and the vulnerability of the data on the second axis.  See the example below.  The data categories that map into the high value  high risk quadrant is the candidates to being planning for business continuity services. Data grouping in this quadrant have the greatest and most timely impact on business operations. They are ones that need the most reactive (in terms of failover / restore time) and the most solid processes for protection  backup  & restoration in the event of a data emergency.  From this point the process is mostly determining what services levels are needed  the costs to implement those service levels and comparing the cost to implement against what can be afforded.  Data vulnerability Business Value of Data High Value Low Risk High Value High Risk Low Value Low Risk Low Value High Risk RecommendedSTARTUP - SHARE TO SUCCESS",facilitated application specification technique, 'Personal computer',https://dokumen.tips/documents/syllabus-b-5616b0f274f06.html,'parallel system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,life cycle model, 'Personal computer',https://www.researchgate.net/publication/222303021_The_ProSet-Linda_approach_to_prototyping_parallel_systems,'parallel system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,public domain software, 'Personal computer',https://www.researchgate.net/publication/221537517_Parallel_programming_using_public_domain_software,'parallel system'
  This course introduces software reliability process  reliability growth  models and shows techniques to improve and predict software reliability.  Concepts such as defining necessary reliability  developing operational profiles   techniques to improve and predict software reliability  preparing and executing test   black box testing  white box testing  unit testing  system testing  and integration  testing will be explained.     The SENG 637 course home page contains links to up-to-date course information   problem assignments  announcements  as well as laboratory and examination scheduling.  The SENG 637 course home page is available through the B.H. Far's home page at the URL:    (http://www.enel.ucalgary.ca/People/far/Lectures/SENG637/)       ,quality assurance ( sqa ), 'Personal computer',https://people.ucalgary.ca/~far/Lectures/SENG637/index.html,'parallel system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.Do you want to read the rest of this article?You can request the full-text of this article directly from the authors on ResearchGate.,capability maturity model ( cmm ), 'Personal computer',https://www.researchgate.net/publication/222087605_Software_metrics_in_the_process_maturity_framework,'successful computer'
SDLC Requirements Phase Input: Product requirements from Sales; Product Management; Customers; Software Bugs List. Output: Product Requirements Document (PRD) or Market Requirements Specification (MRS). PRD/MRS then converted to Functional Requirements Specification (FRS). (p. 214) The Software Development Life Cycle (SDLC) for regulated software can take various forms  but it always begins with development of an agreed set of requirements. For custom software projects  the URS and PRS provide important input for converting work process needs into software features and functions for a Functional Requirements Specification (FRS).For configurable or Off the Shelf (OTS) commercial software  the supplier uses diverse sources to compile a Product Requirements Document (PRD) or Market Requirements Specification (MRS). With input from sales  product management  current and prospective customers  software bug lists and competitive products  supplier management agrees on a set of required deliverables in a PRD or MRS. Engineering then converts the PRD/MRS into an FRS that describers a more technical view of the software features and functions necessary to deliver on PRD/MRS requirements.Suppliers use various Computer Assisted Software Engineering (CASE) tools to support and manage the development work process. One such tool type can manage uniquely identified requirements and trace them from FRS through design and formal testing. This is a huge and complex task for most commercial software suppliers and using automated tools is essential to get the job done. CASE tools are available both as high end commercial products and also as open source programs.A standard approach to creating a PRD/MRS document is to organize related requirements in tables where each requirement has a unique identifier  a customer focused description  and a way to test for it as a purchased system. Having a column for Use Case Test Topics is essential to ensure that the PRD/MRS has only real testable requirements. If it can’t be tested  it is a wish and not a requirement. Creating the FRS requires mapping the PRD/MRS requirements to the respective technical features and functions needed to deliver the agreed requirements. Again  no “wishes” are allowed. There MUST be a way to verify that the software performs technically as expected.ID(s) Then one can record Test Script IDs in the last column. This will make an instant OQ Trace Matrix. The requirement ID trace between FRS and PRD/MRS may be one to one  one to many  or many to many. Next Month: Validation Package Model – Human ControlThere are three streams of validation work that must be controlled and documented within each package. The first workflow is control of human interaction with the system starting with approved requirements  system specifications  and service level agreements with suppliers. (p. 61),development life cycle ( sdlc ), 'Personal computer',http://gxpinternational.com/28-software-supplier-requirements-prdmrsfrs/,'successful computer'
,earliest start time, 'Personal computer',https://www.scribd.com/document/283026098/Connect-Plus-Test-Centre-Technical-Guide-V1-6,'successful computer'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,evolutionary prototyping, 'Personal computer',https://www.researchgate.net/publication/2360847_Requirements_Engineering_for_Software_Reuse,'successful computer'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.Do you want to read the rest of this conference paper?You can request the full-text of this conference paper directly from the authors on ResearchGate.,life cycle model, 'Personal computer',https://www.researchgate.net/publication/220831759_The_Life_Cycle_of_Test_Cases_in_a_CBR_System,'successful computer'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,object oriented requirement analysis, 'Personal computer',https://www.researchgate.net/publication/220744085_A_Relational_Model_for_Formal_Object-Oriented_Requirement_Analysis_in_UML,'successful computer'
,operational feasibility, 'Personal computer',https://www.scribd.com/document/51990867/76-27-kmsdoc,'successful computer'
This division of quality roles is often lacking in software suppliers who frequently do not have a separate QA role in the  company… sometimes they are confused by the common practice of calling their formal testing group a software quality assurance (SQA) function. In reality  the software testing group is actively involved in building quality into the product and operates as a software quality control (SQC) function. (264) The Quality Assurance (QA) role establishes the quality management system (QMS) for an organization and provides the Policies and Standard Operating Procedures (SOPs) as a process framework for quality practices that QA then audits against for compliance. The QA role itself must remain independent of the work process employing the quality practices in order to be unbiased in monitoring and auditing that work process and its product for compliance.The Quality Control (QC) role operates within the work process and uses QMS procedures and quality practices to test and assess product quality as product is being made. The QC role itself is part of the work process and looks to identify quality issues and product noncompliance to correct it before any release of product from the work process. Both an embedded QC role and an independent QA role are needed for an organization to have successful computer validation and compliance.Often in start-up and small companies  the QA function is considered to be an overhead luxury for later implementation rather than a core essential for establishing the foundation of the organization’s corporate culture and long term success.  A Quality Management System is not about papering over mistakes or just meeting regulations. A QMS is about defining an organization’s view of who and how good it thinks it is (Policies) and how it operates to achieve that vision (SOPs). The QA function then operates as the corporate conscience (internal & vendor audits) to see that the organization lives up to its stated goals for quality in products and services.For computer validation success  it is important that QA do more than just issue Policy saying that computers handling regulated data will be validated. A standard approach to validation work needs to be defined in SOPs and forms established for the types of documentation required in validation packages. A consistent approach to system validation makes the job clear  easier to do and shows management control of the validation process across multiple systems in the company.  In addition  a forum for management review should be established to allocate validation resources in line with business priorities  resolve conflicts of interest between system user groups  and monitor the ongoing status of critical systems. Next Month: The Archivist role for Electronic ArchivesBackup tapes are not electronic archives. …System backups are designed to serve the immediate needs of the IT department for restoring interrupted services and disaster recovery. …Long term in the IT world is six months  not six years  or more than 20 years as in regulatory terms. (297-298),quality assurance ( sqa ), 'Personal computer',http://gxpinternational.com/qa-qc-roles-validation/,'successful computer'
Don't have an account? Sign upBy clicking Join now  you agree to the LinkedIn User Agreement  Privacy Policy  and Cookie Policy.Already have an account? Sign in,capability maturity model ( cmm ), 'Personal computer',https://www.linkedin.com/in/sheryl-louis,'tandem system'
" « The Google File System |                         Main                         | Improving the Reliability of Commodity Operating Systems » Jim Gray. Why Do Computers Stop and What Can Be Done About It?. Tandem Tech Report TR-85.7  June 1985.Reviews due Thursday  11/20. Posted by Michael Swift on November 14  2008 03:55 PM | Permalink In  ""Why computers stop "" Gray discusses the origins and implications are of failure. As part of this discussion  he draws on the interviewed experiences of systems administrators of large cluster setups. Among other things  he determined that operator mistakes  then software  then the environment  and only then hardware was the order of the most significant contributors to machine failures.-We gain from this a written expression of what it means for a system to be available and reliable. Intuitively  reliability is how long we can expect a system to run between failures  and availability is the fraction of time that the system is available over many such failures (thus including time to repair. Gray also points out some promising trends  the most critical being that software flaws tend to be soft. Frequent computer users know this intuitively. Usually  when something goes wrong  a simple restart of the application or of the machine sets everything to the right again. The programmer is increasingly familiar with this kind of bug also  where reproduction of the error is frequently more difficult than the fix. Another positive finding is that hardware tends to have a very high infant-mortality rate. This sounds bad  except that it infant mortality is the best kind of fail-fast behavior one can have; it fails before you've had a chance to rely on it for anything. Gray further posits that hardware will trend to increased reliability  moving the problem further into highly-malleable software. In software  Gray notes a few methods which we now employ together as often as possible: modularity  containment  redundancy  and recoverability. Of the five methods he suggests for recoverability  all are seen now  but the  ""hard-to-program"" downsides have occasionally been obviated by increased modularity (such as the separation of a database from the front of a web application.What isn't promising about the outlook is that software is trending to the more complex  and to the more unmanageable (from a bug-finding perspective). Gray discusses the incentives (or lack thereof) for operators to update their installed software  and concludes that they are in direct conflict. On the one hand  new software introduces new bugs and more of them due to increased complexity. On the other hand  new software fixes the old bugs and offers more features (which I imagine might include a more resilient architecture). What's missing from Gray's discussion here is a notion of how software is built. He seems to assume a waterfall model  where stages of deployed softwares are designed  built  debugged  and released in repeating monolithic batches. Some newer software development methodologies have emphases on different points of development. XP and other agile methodologies test first  and develop to agree with those tests. This has two implications for reliability and what I will call deployability (answering  ""should I update my software?""): The list of known bugs and known ex-bugs are verified at every point  and the environment is designed to tolerate incremental improvements and feature addition. The latter  especially  may mean to a systems administrator that there were a significantly stronger benefit to upgrade.                                  Posted by:                                  Tack  |                                  November 22  2008 02:04 PM Problem Outlined In Why Do Computers Stop and What Can Be Done About It  Jim Gray notes that increasingly more problems in complex systems are the result of human error instead of hardware failure.  He discusses the nature of these faults and how to mitigate their effects.The Solution It seems like Gray feels that transactional behavior is the key to fault tolerance in software systems.  The approach: have groups of programs run beside each other  dedicated to providing a service.  Did one of them encounter an unexpected signal?  Did its TCP session die?  Did another program just write over the data it was supposed to read?  That's OK: just fail the transaction associated with its task; another program in the group will take over for it.Gray advocates bundling operations together as transactions  reducing the complexity of the failure space in an effort to help programmers isolate problems faster.  He also likes the fail-fast behavior of transactions.  The mentality: don't let programs limp along after a failure; instead  make them give up and alert some authority to the existence of a problem in a particular module.Finally  Gray feels transactions help a system handle seemingly inexplicable “heisenbugs” gracefully.What's Missing Transactions  though useful  are not a silver bullet.  Reasoning about the behavior of many concurrent transactions is often made difficult by the existence of a scheduler that retries failed transactions at a later time (an approach commonly used in these systems) or immediately instructs an already-running program to take over.Similarly  software redundancy is also not a silver bullet.  It is hard to guarantee a backup copy of a process won't encounter the same the problem that caused the first to fail.On a related note  using transactions as an approach to dealing with heisenbugs encourages building software on top of transactional routines that are poorly understood.  If you don't know the cause of the bug  how can you be sure its frequency of incidence won't increase to an unacceptable level later?                                  Posted by:                                  James Jolly  |                                  November 20  2008 09:12 AM Why do computers fail and what can be done about it ?  Summary	The author analyzes the failure statistics of the large fault tolerant systems and classifies sources of failure on the basis of frequency of occurance. Then  he establishes that system administration and software failures dominate. So  he proposes and evaluates various approaches like ""process pairs""  ""trasactional communication  storage"" etc for building fault tolerant   self-recovering software components.Description of the problem being solved	The problem is to find out the major sources of failures in large systems used in availability critical applications like hospitals etc and then address these sources of failures to build a non-stop computer with a mean time to failure in several years.  Contributions of the paper	1) A thorough analysis of real world failure statistics and the establishment of the fact that hardware components are doing better in term of fault tolerance  but software components are not.	2) Identifying process as a clean unit of modularity   service   fault containment and failure. And that they should be fail fast. That is they should work or they should quickly fail but not do anything in between these two approaches.  	3) Process pairs to increase availability by redundancy is inspired from hardware redundancy approach. This is a very practical approach is improving existing software as compared other approaches like improving software devlelopment process etc. to build robust components of the future.	4) Classification of bugs as bohr-bugs and heisen-bugs is insightful.	5) Using transactions coupled with process pairs to arrive at a easy to program and yet very fault tolerant software building approach.   Flaws in the paper	1) Does not talk about process state backup for persistant process pairs in the light of  for multi processor or multi thread scenarios.	2) Could have quantified the easiness in building persistant process pairs by providing details on how much it took for them to build software using this approach.  Techniques used to achieve performance	1) Redundancy to achive fault tolerance: process pairs are a combination of processes where the backup process takes over when the primary fails.  	2) Partitioning data and storing them at different geographical locations to limit the scope of a failure.  	3) Remote replication for data availability: seems like todays cloud storage concept.  Tradeoff made	1) Trading Space and performance for fault tolerance and availability: Storing state for the backup process to recover consume additional space as well as computing resources but provides availability.   Another part of OS where this technique could be applied	1) This concept can be applied to faulty parts of the modern operating systems too. For eg. Prof. Swift has worked on extra state storage to recover from device driver failures which occur most often.	2) partioning of data and redundancy are the basis of many storage device techniques like RAID.                                  Posted by:                                  Leo Prasath Arulraj  |                                  November 20  2008 08:18 AM Summary This paper analyzes failure data reported to Tandem Corporation by its customers as well as gives an overview of other studies at the time to suggest ways to make systems more reliable. Problem The paper reports that at the time  well managed systems could expect 99.6% availability  which is unacceptable to critical systems like patient monitoring  financial transaction processing and the like. Contributions / Techniques Notes that hardware is fairly easy to make highly available through the use of redundant and fail-fast modules. The author analyzes failure data to determine what are most important types of failures to address  and gives recommendations about how to deal with them. Infant mortality  which refers to product immaturity – avoid immature products Software bugs – the author notes that in production machines  most software bugs are “soft”.  By this he means they are seemingly transient and very difficult to debug.  Therefore he analyzes primary ways to structure software to provide reliability in the face of these kinds of bugs: modularity for fault isolation  process pairing to provide “hot” backup in the case of a crash  ample data checking to detect errors  and transactions to provide a clean recovery mechanism. Administrative errors – the author recommends automating administration as much as possible and making simple interfaces.  He uses the example of a hardware device that can be installed without instructions because it is “obvious.” Flaws This paper is very well written. The only flaw I can see is that it seems to make conclusions from failure data of one Tandem system.  While useful  it would be nice to see analysis of data from a broader set of systems Other uses: Almost every software and hardware system strives for reliability  so these techniques are applicable nearly everywhere.  Notably  transactions with ACID properties are widely used in database applications.  In operating systems one area this may be useful is in making changes to critical system data (configuration files  registry  etc.) that is saved on disk. More generally though  file systems attempt to provide ACID like properties through the use of journaling.                                   Posted by:                                  Dale Emmons  |                                  November 20  2008 07:58 AM Summary Despite work toward making computer systems more reliable  most systems still suffer failures. In “Why Do Computers Stop and What Can Be Done About It?” Jim Gray analyzes failure data from users and postulates ways to make systems more reliable.Problem Typical  well-managed systems of the time had a 99.6% availability – translating to about ninety minutes of down time every two weeks. While 99.6% availability sounds very good  there are applications in which this availability is not sufficient. With the rise of dependence on computer systems  the importance of availability continues to become more and more important. Certain applications require a system that is practically perpetually available; to arrive at such systems  it is important to plan for systems in which a variety of failures can be tolerated and recovered from without affecting the availability of the service which the system provides.Contributions •	Analyzing failure data to find what failures were caused by: most prominent were failures due to “infant mortality” – failures due to new software or hardware that still had bugs that were being worked out. Looking beyond the “infant mortality” problem  the most common source of errors was system administration  followed by software  then hardware  and finally environmental failures.  •	Using the failure data to present an approach by which failures could be minimized: designing systems to tolerate operation and software faults. •	Observing that hardware-related failures are relatively rare and that  since hardware is becoming more reliable  these sorts of failures are likely to become less of a problem with time and also that software related errors are currently more abundant and that they are likely to become even more so as systems become more complex. This implies that the focus should be put upon improving software related reliability.Flaws •	Failure statistics are not necessarily exact – some failures were not reported  possibly causing the proportion of the causes of failures to differ from what is described. Furthermore  the statistics only come from one specific system  increasing the potential that the statistics are not broadly applicable (for example  perhaps this specific system had better than average hardware reliability and lower than average software quality  possibly inverting the proportions of the failures attributed to those categories).Techniques New techniques are not defined in this paper  rather  it is suggested that available techniques should be employed in order to increase reliability. Jim Gray implies that allowing some performance to be sacrificed and that adding some additional complexity in order to achieve higher reliability is acceptable.                                  Posted by:                                  Mark Sieklucki  |                                  November 20  2008 07:16 AM  Summary The paper provides statistics of the reasons for system outages. Infant mortality failures  system administration and software faults are identified as the major source of system outages. It addresses software fault tolerance issue by quantitatively discussing the benefits of modular software  fail-fast processes  process pairs with transactions  fault tolerant storage through replication.  Problem attempted Computer systems used in critical applications like patient monitoring  stock markets etc. have to be systems which virtually never fail. The focus of this paper is to achieve this objective through various mechanisms that guarantee a very high Mean Time Between Failures (MTBF) Contributions 1) The paper provides useful statistics on the reasons for system outages. About a third of the failures are due to infant mortality (i.e. products that  are yet to stabilize)  another one third due to system maintenance issues  and 25% due to software faults. 2) The main conclusions drawn from these statistics are : hardware fault-tolerance can be achieved through redundancy; maintenance difficulties can be reduced by simplifying maintenence interfaces and by not meddling with the system unnnecessarily; software bug fixes need not be installed unless the bug is very critical. 3) Softwares crash very less compared to what must be expected with a bug in about every 1000 lines of code. This is primarily due to their modularity through processes where process is the unit of failure. Terminating a misbehaving process is always a simple and effective solution. 4) The paper suggests process pairs as an effective method of improving software fault tolerance. Here a pair of processes  namely the primary and backup processes  are dedicated to servicing a requestor. 5) In one implementation of process pairs  the primary process sends state changes and reply messages to its backup after each major event. This being complicated to code  authors suggest another implementation of process pairs (called as persistence) where the backup waking up with a null state and being unaware of all that happened before primary failure. 6) When persistence process pairs are used with transactions  the cleaning up of the inconsistent database and system states due to all uncommitted transactions associated with the failed primary is taken care of.  Flaws 1) The paper doesn't address the system becoming unavailable due to malicious attacks like Denial of Service attacks. In general  the issue of Systems being robust against intended attacks has not been addressed at all. Tradeoffs 1) Reliability and availability vs Performance -- Transactions and process pairs are sure to bring down the performance. But they provide effective fault tolerance. A similar tradeoff is there between reliability and cost  where having redundant hardwares improves reliability but it increases the cost  though cost is not a very serious concern for critical systems.  Techniques used 1) Modularity - Software  must have a modular design for effective fault isolation and minimal redundancy.2) Fault tolerance through redundancy is a classic technique used in storage (RAID).                                   Posted by:                                  Balasubramanian Sivan  |                                  November 20  2008 03:12 AM Introduction: This paper by Jim Gray is a high-level analysis of different modes of failure in computer systems. The author analyzes real-world failure characteristics and concludes that software and human errors are the primary causes of system failures. He analyzes techniques used in hardware to decrease failure rate and applies the same concepts to software.What were they trying to solve: Mission critical computer systems have a steep penalty for failures. Even when an error occurs  the time to restart the system back to an operational state is very high. Also  errors are more prone to happen during peak loads  which further exacerbate the problem of availability. While hardware reliability improved steadily with technology  the reliability of systems actually decreased with time superseded by higher software complexity.Contributions:  The MTTF of hardware systems can be increased by a large factor by:  			 Increased Modularity 			 Make them fail-fast: they either work correctly or stop working 			 Prompt detection of faulty hardware.	 			 Extra modules to pick up load in case of failure.   The following observations about system failures were noted:  	 Most systems fail due to administrator  user or software errors. ""Infant software""  which is newly installed software accounts for a large chunk of failures. 	 Most software bugs are soft: they are hard to reproduce.   Simpler maintainance interfaces decrease administrative errors.  Software errors can be minimized by:  	 Software modularity provides software isolation. 	 Like in hardware  software modules must be fail-fast. 	 Redundancy at process level using process pairs 	 Transaction based system for maintaining ACID properties.   Communication systems can be made fault-tolerant by introducing session semantics: All communication follows a well-ordered protocol.  Storage systems can be made fault-tolerant by replication		 Flaws: 	 The paper is too general and only provides a high-level solution to problems. Real systems often have to made tradeoffs between performance and fault-tolerance  as well as between cost and fault-tolerance. 	 The analysis of errors is largely empirical and extrapolated from a small sample space. While general trends may hold true  some of the specific assumptions may not hold true in general.Techniques used  Hierarchical self-contained Modules   Redundancy at each level.  Transactions to maintain consistency Tradeoffs:  Redundancy vs utilization: Redundancy comes at a cost of resources not being utilized for actual work.  Software complexity vs reliability: Reliable software in general has to handle cases which may never or rarely occur. another part of the OS where the technique could be applied:  Redundancy and paralellism is used extensively wherever recovery from error is required. For example  RAID can mirror data into two devices.  Modularity is also extensively used to provide isolation. SIPs in Singularity is	a good example of that.                                  Posted by:                                  priyananda  |                                  November 20  2008 02:35 AM Summary Jim Gray in this paper  presents his views on software reliability and availability. He shows that hardware fault tolerance works and draws parallels with similar solutions in the software domain. He claims that by including modularity and redundancy in software design  the mean time between failures(MTBF) can be increased.Problem Jim Gray analysed the system outage reports from vendors to analyse the top reasons for a system failure. Based on his analysis  he concluded that most of the outages are caused by administrative/operator errors followed by software failures/bugs(25%). He noticed the fact that hardware failures were comparatively a rare occurrence. So by reducing the software failure rate  the MTBF for the system can be increased. Contributions - He uses concepts that have been used in hardware systems and tries to apply them to software systems to increase their fault tolerance. Just like in hardware systems  software should be decomposed into fail-fast independent modules. (e.g. SIP from Singularity). - He also suggests using redundancy of modules so that failures are not even visible to the users. By combining process-pairs with transactions  we can have redundancy and hence high availability without saving too much state or increasing the load on the programmer. - Apart from acting as a backup  secondary processes also help in handling HeisenBugs(transient bugs). As the backup process  starts with a clean slate  it has high chance of succeeding if the failure was caused due to a transient bug(e.g. race condition) - Using similar concepts of redundancy(multiple paths) and session management  availability of a communication network can also be increased. Redundancy(replication) of data also helps in providing fault tolerant storage systems.Flaws - Process-pairs become complicated in a multi-threaded process where there is no set point at which all transactions have ended. As a result  we may not have any point at which we can snapshot the system and safely restart. - Everything cant be roll-backed(network/printer) because of which transactions have a limited scope. So the guarantee of atomicity may not be always be feasible.Technique - Modularity and redundancy are the basic techniques suggested by the author to ensure fault tolerance. - For achieving this level of fault tolerance and high MTBF  hardware costs(for twice the hardware) and memory size(for snapshots/transaction) increase. - The basic techniques suggested in this paper are used in almost every fault tolerant system.(even in our day to day activities-duplicate keys)                                   Posted by:                                  Tushar Khot  |                                  November 20  2008 02:18 AM Summary: This paper presents some causes and remedies for failures in computer system (in 1985)  which are still pertinent. Administration and software soft-faults are the primary causes for failure. The remedies (as proposed in this paper) are transactions  per-process pairs and reliable storage  etc. Problem: This paper  by the famous Jim Gray  presents a view of how computer systems looked back in 1985 and studies the failure statistics of a commercially available fault-tolerant system. Further  it proposes different approaches to software fault-tolerance such as persistent processes  process pairs and transactions.Contributions: One of the major contributions of the paper is to differentiate between the concepts of availability and reliability. Modularity and redundancy can increase the reliability of the system  thereby inturn improving its availability.  It isolates the different causes behind failures of a commercially available computer system at Tandem. Major sources of faults reported are administration  maintenance  software and operations. The author proposes defensive programming  process-pairs to increase redundancy and thereby improving fault-tolerance. Further transactions and persistent processes can provide ACID guarantees to operations in the system.Flaws: The paper is actually reflecting the opinion of a Turing award winner - Jim Gray. I believe finding a flaw in the paper will be inappropriate  though my opinion may differ at some points. For the Tandem statistics  under-reporting and lack of knowledge of events  has forced the author not to isolate some failure causes at many instances  (eg. about double failures).Techniques used: Prevention is better than cure. Redundant modules can always help in avoiding the damages caused by the soft faults in a system. Automation  persistent processes and transactions can come to rescue for fault-tolerant communication as well as execution.Tradeoffs: Redundancy (even at a factor of 2)  unlike the Von Neumann model  can increase the cost of the systems. There is a famous philosophical riddle - ""If a tree falls in a forest and no one is around to hear it  does it make a sound?"". Based on these lines  I believe redundancy of certain modules is irrelevant in case their failure does not affect the overall availability of the system.Alternative uses: Transactions and the ACID properies are well known in the domain of databases. Redundancy has found place in reliable storage systems (RAID). Modularity is well known-concept used in the design of object-oriented OS and in the form of process abstractions in almost all OSes.                                  Posted by:                                  Mohit Saxena  |                                  November 20  2008 01:15 AM Summary: Paper talks about different reason of system failure. It also explain different mechanism like Modularity plus redundancy to improve the reliability of system.Problem:  Critical system application like patient monitoring  online transaction processing require high availability. How to provide high available system is the main problem discussed in this paper.Work Summary / Contribution: 1.	At hardware level  high availability is obtained by constructing fail-fast modules and putting redundant module. Redundant module will be used in case primary module fails. 2.	According to paper 1/3 of failure are caused by infant morality (immature product ). So customer should stay away form such product  which has not been tested properly. 3.	Most software bugs are soft so re-execution in case of failure solve the problem in most of the case but issue here is who should re-execute and from where should re-execution start. If other process re-execute then how to undo the changes done by failed process or if back-up process re-execute from the state in which failed process left then how to communicate the state information among process pairs. 4.	Paper talk about different approaches to process-pair. Each approach has its issue but Persistent approach is easier to implement but leave hardware or system  in mess. So if transaction is combined with persistent approach then this provide excellent fault tolerance execution. Transaction will make sure that if failure happens in middle of transaction then system is brought back to pre-transaction state. 5.	Fault tolerant communication can be obtained by having multiple data paths.  6.	System configuration  system maintenance are the reason for many system failure. Only solution to such failure is reducing interaction between system operator and system.  Flaws: 1.	Paper make conclusion about failure from data of only one tandem system.Tradeoffs: 1.	Tradeoff is made against high availability/reliability versus cost. If double hardware is used for high availability then cost will be doubled as well.Another part of OS where technique can be applied:  1.	Communication fault tolerance technique is used currently in network system to deliver packets reliably. In Internet node are connected by multiple paths so in case some link is failed alternative path is used to deliver packets. 2.	Fault Tolerant storage technique is used in RAID to provide the high reliability and availability. Two or more disks are combined together and one of them works as mirror so incase one disk fails mirror disk can be used.                                   Posted by:                                  Nikhil Teletia  |                                  November 20  2008 01:04 AM Summary The paper analyses the different reasons for failures in computer systems and identifies the main ones to be software and administration. It then proposes an approach involving modularity  automatic configuration  process redundancy  and transaction model to alleviate the failure effects and improve system availabilityProblem Statement The key problem addressed in this paper is system failures and resultant availability figures. The paper goes on to identify a viable approach to address this problem and build reliable systems.Contributions - The primary contribution of the paper is a rather multifaceted analysis of failure conditions in systems  and an evaluation of a few ways to address these. - The paper identifies software and administration as two key causes for failures. - The paper stesses on automating system configuration to the greatest extent to reduce human errors at maintenance which affect availability adversely. - The paper proposes a pair redundancy model for processes coupled with transactional processing to improve software availability.Flaws/shortcomings - The paper uses the Tandem systems alone for it's analysis of reliable systems. - The paper tends to generalize from instances a lot.Technique used The key technique used is redundancy at the process level. That is coupled with transactional processing to achieve reliability.Tradeoff Complexity and development overhead is the tradeoff in using process redundancy and transactional model. Also  this would possibly tax the CPU more.Applications The process redundancy concept is employed in Cisco's latest router oprating system Cisco IOX. Here  each process has a redundant standby process which takes over when the current master porcess fails. And the standby inturn creates another standby process when it becomes the master now..                                  Posted by:                                  Varghese Mathew  |                                  November 20  2008 12:43 AM In this paper  Jim Gray describes the sources of failure in fault-tolerant systems. He presents failure statistics based on the Tandem NonStop system  analyzes them and then discusses various approaches to software fault-tolerance.Many computer applications such as online transaction processing and patient monitoring require high availability. In these systems outages are unacceptable. In commercial fault-tolerant systems the major sources of failure are administration and software. The author presents the advantages and drawbacks of some approaches which can be used for software-fault tolerance.In my opinion the major contribution of the paper is a systematic analysis of the failures of a system. The author collects data  presents failure statistics  analyzes them and finally proposes some solutions. This paper is worth to read as it shows how a systematic study of a topic should be done. Another contribution of the paper is that it shows that most failures are caused by software and administration and not by hardware. This happens because the techniques used for fault-tolerant hardware are quite successful. For this reason the author discusses various techniques that could be used for software fault-tolerance. The author proposes to decompose the system into modules  so that a failure if a module does not propagate beyond the module. The modules should be designed fail-fast because fail-fast software has small detection latency. The author  then presents the advantages and drawbacks of several approaches to design process-pairs. Moreover  he argues that by using transactions the application programmer don’t have to handle many errors. Transactions combined with persistent processes can give excellent fault-tolerant execution. Moreover  persistent processes are simple to program.  Fault tolerant communication can be obtained by combining transactions with sessions. As far as it concerns storage  we can achieve fault-tolerant storage by replicating the data.In my opinion one flaw of the paper is that only the Tandem system was considered. The statistics might have been different if other systems were also considered. Finally  although the paper presents a very good analysis of the data  I think that there are some assumptions when evaluating it (e.g some failures were under-reported). However  I don’t think it is easy not to make these assumptions and find totally “real” data.The paper doesn’t present new techniques. It points the need for software fault-tolerance. The approaches discussed are presented in the second paragraph. The author proposes to use modularity and redundancy in order to achieve higher availability. A disadvantage of this approach is that more space is needed and of course more hardware. This means that the cost is higher.                                  Posted by:                                  Avrilia Floratou  |                                  November 20  2008 12:11 AM Summary: Besides a careful analysis of computer failures  this paper is mostly a position paper. It advocates self healing software composed of modules that fails fast in case of errors. They propose redundancy and transaction like processing for increased reliability and availability.Problem: In many circumstances even small chances of failures are not acceptable. By classifying many reported failures  they observed that the largest part is caused by administration and software bugs. Administration failure are caused by humans  but 'to err is human' so they are ultimately attributed to software usability. After heavy testing  the bugs left in software are likely to be unreproducible and go away when retried. Finally  they note that monolythical systems  besides being hard to understand  tend to fail completely in case of errors. Contributions & Reliability Techniques: They show that availability depends not only on the Mean Time Between Failures (MTBF) but also decreases with a large Mean Time To Repair (MTTR). They propose modules as the unit of failure or replacement. Redundant modules are much less likely to all fail than single modules. Besides  when one module is down  the other can instantly take over  reducing MTTR. However  this insight is successfully used in hardware  but it is less obvious how to apply in a software environment. The author's insight is that in production code  many software bugs are irreproducible. Moreover  one doesn't have to retry from start  merely from the last consistent state and still 'miss' the bug. They define transactions as group of operation that either fail or (atomically) take the system from one consistent state to another. Finally  they propose combining process pairs (where processes can be physical or logical entities) with transaction as the solution for software module redundancy. If one process fails  the other one takes over from the last checkpoint state  possibly undoing changes of failed transaction (and is unlikely to fail). For this to work  one needs reliable communication between processes and reliable storage to maintain the checkpoint state. For these  replication is again the key to reliability: multiple data paths for communications with resumable sessions  and storage in multiple locations (and if possible different environment). The storage process itself is viewed as a transaction with ACID properties. As for the reduction in human error  they advocate self configured systems.Weaknesses: Not all software can be organized in transactions  and in some cases the overhead for maintaining and communicating state may not be acceptable. They disregard ""infant mortality"" (most likely caused by reproducible bugs)  but infancy can be half the life of an IT product in today's fast innovation pace. Also 1 failure for 100 computers running each 10h is considered as 1failure/1000h. This is a good approximation  but omits the actual aging: one computer that runs 1000h may fail more often simply because of aging components. Similar considerations could apply for Software  where eliminating ""infancy bugs"" may cause code bloating and an increase in transient bugs.                                  Posted by:                                  Daniel Luchaup  |                                  November 20  2008 12:11 AM WHY DO COMPUTERS STOP AND WHAT CAN BE DONE ABOUT IT	SUMMARY 	This paper performs an analysis on commercial fault-tolerant systems and discuses different approaches to software fault-tolerance that current systems use. They analyze the reported failures in the systems of four clients of Tandem Computers Inc. systems. They distribute the failures in five different categories: administration  software  hardware and environment.  	PROBLEM 	This paper determines that faults in a system are usually due to administration and software errors. Software grows constantly and its is more and more difficult to have perfect coding practices and coding testing. There are fixes for software faults that can be installed and solve known bugs. But we need systems that are software fault-tolerant. This paper presents some of the solutions to this problem.   	CONTRIBUTIONS 	This paper establish the differences between availability and reliability. It states that availability is doing the right thing in the specified time and reliability is not doing the wrong thing. Based on this concepts it studies the availability and reliability obtained through different techniques. 	Hardware fault-tolerant systems achieve high availability through modularity and redundancy.  These techniques are also found in software fault-tolerant systems.  	Software modularity consists in decomposing large system into separate modules. Processes as the unit of execution provide isolation  and can be stop when they are not operating correctly. Fail fast software modules means that the processes will work properly or will fail. So recovery activity can be started faster. 	Most production software bugs are soft. Software bugs may be due to strange hardware conditions  if the program is restarted and the instruction executed again it will most likely work. A solution for these errors are process-pairs. They consist in having extra software modules that can execute in different ways to obtain higher availability overcoming different types of errors: lockstep  state checkpointing  automatic checkpointing  delta check pointing  and persistence.    	Transaction mechanisms provide a very good result when used with process-pairs. Transactions are operations in which all the instructions success or none success  this way you always know the state of the system.  Using transactions with persistent process-pairs solves the problem of the unknown state  for the backup process.  	Fault tolerant communication and storage are both obtained through duplication of the sent messages over different paths and duplication of the data. 	FLAWS 	It is difficult to find flaws in this survey paper. The data collected at the beginning on the paper seems to be not very accurate and based on lots of assumptions  although it is enough to have a good idea of what causes failures in a system. It is not clear the number of systems they are looking at and if they were all the same version or they were acquired at different times  which may have made some systems have the same problems due to infant errors or development errors common to all systems. We should also consider that all the systems are from the same company. 	PERFORMANCE	 	The techniques proposed are techniques to reduce software and hardware failures in any system. These techniques are modularity  redundancy  fast fail modules and transactions for software errors. 	Redundancy trades space and price (in the case of hardware) for reliability.  Modularity implies more design effort for a more reliable and available program.  	All these techniques are widely used in OS. Check pointing is used in file systems to recover after a crash. Redundancy can be used in distributed systems to increase response time. Transactions are used in any part of the OS where we want atomicity and consistency.                                  Posted by:                                  Paula Aguilera  |                                  November 19  2008 11:47 PM Summary:  The paper discusses a variety of causes for failures of computer systems and the ones which have the most impact on them. A very high availability is able to be provided by fault tolerant hardware  while a lot of errors or outrages are contributed by software and administration problem  so several techniques are provided in this paper to improve software reliability so that the MTBF (Mean Time between Failures) or MTTR (Mean Time to Repair) can be improved.The goal the paper was trying to deal with:  In order to reduce the frequency of outages caused by software and administration  the goal of the author is to make the software to be fault-tolerant by suggesting using some techniques including modularity and redundancy. Contributions 1．	The paper makes a convincing argument that most system errors or outrages are caused by software and administration  instead of hardware failures  and proposes some new mechanisms to deal with these faults and to improve availability. 2．	A variety of techniques are discussed in this paper for developing fault-tolerant software. These techniques include process pairs  transactions for data integrity  fault tolerant communications and so on. These methods are quite useful to improve MTBF (Mean Time between Failures) or MTTR (Mean Time to Repair).  3．	The paper wisely reuses the concepts of 'transactions' and 'sessions' from database domain for fault-tolerance - in execution  communication and storage. Transactions are Group of operations that form a consistent transformation of state – ACID  which are Atomic  Consistent  and durable. 4．	The paper suggests that computer should avoid immature products for achieving high availability.Flaws: (1) The first flaw of this paper is that a lot of guesses are made without justifying them. (2) The second flaw of this paper is that the author proposes this results only by looking at the data from one type of system (a commercial system made by Tandem Computers)  the author is supposed to derive this results from observing more systems. (3) I do not agree that hardware necessarily gets better with time. If increasing software complexity triggers more bugs  hardware complexity increases should also cause less reliability.Tradeoffs: The major goal of the paper is to increase fault tolerance  however one tradeoff is made because costs are also increasing due to redundancy.                                   Posted by:                                  Tao Wu  |                                  November 19  2008 11:23 PM Summary Why do computers stop discusses techniques that can help increase the Mean Time Before Failure (MTBF)  The paper first discusses an analysis of  failures from one product  and then explains properties of fault tolerant systems.Description of Problem This paper presents properties that can be implemented to help improve the MTBF of more conventional machines that fail about once every two weeks.Summary of Contributions - Subjectively concluding that software failures  operator actions  system configuration and system maintenance consist of a large portion of failures of a system. - Enforcing the idea of modularity  independence  and parallelism are necessary to improve reliability. Software modularity with processes and messages for simplicity. Parallelism with software and hardware allow one to fail while still having a redundant secondary. - Bringing together a number of ideas from previous authors  such as Mourad  and Neumann as well as associating software bugs to the Heisenberg physics principle - Categorized failure causes (although subjective) in order to isolate the primary causes of system failures. - Present the idea that fault tolerance needs to be designed into the system  and not an afterthought.Flaws The papers primary flaw is the low level of detail and concrete evidence presented. The author could have analyzed the faults in a number of different product lines and stronger rules on the categorization that was done. In addition  the paper presents ideas and data that could use more enforcement.Techniques The paper does not necessarily present any new techniques  but expresses a need for developing software fault-tolerance techniques into systems. The techniques of this paper focus on replication for fault-tolerant storage  robustness in the communication layers for fault-tolerant communication  and transactions and persistent processes for software fault tolerance. The primary tradeoff is improved MTBF for additional design features. The techniques could be applied to all developers of an operating system to help them think about fault handling at the design stage since this is important for increasing the MTBF.                                   Posted by:                                  Cory Casper  |                                  November 19  2008 11:21 PM Summary This paper analyzes the sources of failure in a fault-tolerant system and discusses a number of issues relating to software fault toleranceProblem Systems that are unavailable due to failure create delays and problems  especially in specific systems and peak times. We would like to reduce the frequency of such failures and/or minimize the time to recover from failures.Contributions Notions of Mean Time Between Failures (MTBF) and Mean Time To Repair (MTTR) are used to define a straightforward notion of availability. The author notes that it is common in a hardware setting to use redundancy (such as hardware pairs) and modularity to significantly increase the MTBF. As well  if the MTTR is small  it is perceived as a delay rather than a failure. Redundancy allows some parts to fail while the rest continue on.The paper analyzes sources of failures  namely: administration (including operator actions)  hardware  software  and environmental factors. In order to decrease administration and operator failures  systems should be self-maintaining or easy to maintain. Hardware is already fairly reliable  considering methods such as redundancy  and the hardware itself will continue to become more reliable.Software fault-tolerance is considered in depth  as an area that can be improved  although it may not be as evident. Particularly  it is argued that in more or less proven systems  fixing remaining bugs can do more harm than good. Furthermore  in proven systems  remaining bugs are generally soft (as with hardware). That is  they are hard to duplicate  and upon retry  often disappear. Thus  methods applied to hardware (such as pairs) can be successfully applied to software and this sort of fault tolerance can be more fruitful than attempting to fix the remaining bugs. The author suggests using persistent process-pairs with transactions to guarantee data integrity.                                  Posted by:                                  Sam Javner  |                                  November 19  2008 10:53 PM Summary This paper presents analysis of causes and anatomy of system failures and shows that software and administration are the major contributors to it. Various approaches to software fault-tolerance are discussed and persistent process-pairs with transactions provide highly fault tolerant system.Problems: System failures are completely unacceptable in certain environments. There has been no analysis on commercial fault tolerant system. The software faults and administrative errors are much more than hardware failures. This paper proposes using modularity and redundancy in software as a way to improve software reliability.Contributions:•	Extremely high MTTR can hide failures.  •	Hierarchically decompose the system into modules. Redundancy increases availability. Both these techniques provide continuous service even if few components fail. •	Modules are designed fail-fast-   it either functions properly or stops. •	Administrative and maintenance should be simplified to have minimal operator intervention. •	For high availability  avoid immature products. •	Software faults are soft  heisenberg bug and are difficult to reproduce. •	Process-pairs provide high tolerance with transactional system.  When primary process fails  backup comes up and takes care of all operations. Transactional system maintains the system of incomplete operations and rolls back. •	Transactions plus resumable communication sessions give fault-tolerant communications. Transactions plus data replication give fault-tolerant storage.Flaws: The resulting systems hardware system is said to have MTBF measured in decades or centuries. There are no actual facts about it. The paper consists of many assumed data  so don’t know how reliable the calculations are? The author says that data is missing  so how can results be so sure? The paper doesn’t include infant system into study; they account for 30% of total system failure and should have been part of study.Performance: The paper talks about improving the reliability of the system by modularization and redundancy. They improve software fault tolerance by introducing process-pairs with transactions.Tradeoffs: The software is made more complex for higher reliability. Process-pair requires lot of effort to program correctly. Redundancy can be applied to almost every application area for fault tolerance.                                  Posted by:                                  Rachita Dhawan  |                                  November 19  2008 10:13 PM Summary: The author of this paper presents the argument that administration and software problems are the leading causes of machine failure based on a study of Tandem NonStop system. Using these statistics the author presents different suggestions to help prevent these types of introduced faults.  Problem to Solve: The problem the author is trying to categorize in a real study the cause of system failures. They are also trying to point out how fault-tolerance is achieved in some of these situations and determine how future MTBF can be increased in certain situations by introducing minimal amounts of redundancy.  Contributions: One thing they mention is that software should be modular. Modularity in software allows one piece of code to fail and be isolated from the rest and allow for easy fixes because the fault can be traced to a single part of the code. Another thing they mention is the idea of fail-fast software. This means the if the software is wrong it should signal a fault and stop processing otherwise it should function as normal. This is important because you now know that if a process is running it should only be doing correct things. One contribution they make is the introduction of the ACID property into transactions. ACID is a unique technique that allows the programmer to reset the system to a consistent state. They also introduce the notion of process pairs for fault-tolerant execution. This is an important technique that truly makes fault tolerant work in practice through different types of redundancy.  Flaws: Although the authors present advice on improving system performance  it seems like a lot of the advice is really only targeting the system maintenance part of the problem. Sure system redundancy is helping with system configuration  but this is a very small part of system configuration as we know it today.  What tradeoff is made: One tradeoff is increased hardware costs for increase fault tolerance.                                  Posted by:                                  Holly Esquivel  |                                  November 19  2008 09:44 PM This paper discusses why computer systems fail. Jim Gray motivates the problem by aggregating and categorizing anecdotal evidence  then formally expresses availability and discusses how we can increase availability.The main contribution is the systematic study of why systems fail.  Surprisingly  systems mostly fail because of non-hardware faults. The key to achieving high availability is therefore the ability to detect and mask all types of failures. Detection is made easy if systems are fail-fast: they stop and complain loudly that something bad happened. Masking failures is achieved by redundancy. Finally  having modular systems prevents propagating faults and minimizing restart time increases availability in the presence of transient errors. Unfortunately  no redundancy scheme is proposed for masking operator faults.The paper sets a modest goal and straightforwardly answers the question  which makes finding a flaw much more difficult. One criticism might be that Jim Gray's world is a world of concrete guarantees: the database is consistent or not  the transaction either aborts or commits  the system must be 99.99% available or the deal is off. In a world where eventual consistency and k-safety are starting to be accepted as properties that are ""good enough"" for an increasing number of applications  it would be interesting to expand the notion of availability to include those techniques as well and make a comparison of how each property affects the availability of the system.The paper demonstrates why building reliable systems is hard: redundancy  modularity and transactions are essential if one wants to achieve high availability. This trade-off impacts all aspects of design and significantly affects the final cost of the system.                                   Posted by:                                  Spyros Blanas  |                                  November 19  2008 06:51 PM  Name:   Email Address:   URL:                                              Remember personal info?  Comments:   ",communication systems, 'Personal computer',http://pages.cs.wisc.edu/~swift/classes/cs736-fa08/blog/2008/11/why_do_computers_stop_and_what.html,'tandem system'
Don't have an account? Sign upBy clicking Join now  you agree to the LinkedIn User Agreement  Privacy Policy  and Cookie Policy.Already have an account? Sign in,development life cycle ( sdlc ), 'Personal computer',https://jm.linkedin.com/pub/khalid-khan/2/443/aa5%3Ftrk%3Dseokp-post-author-name,'tandem system'
,earliest start time, 'Personal computer',https://archive.org/stream/DTIC_ADA455233/DTIC_ADA455233_djvu.txt,'tandem system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.Do you want to read the rest of this article?You can request the full-text of this article directly from the authors on ResearchGate.,operational feasibility, 'Personal computer',https://www.researchgate.net/publication/236600019_A_Tandem_Laboratory_Scale_Protein_Purification_Process_Using_Protein_A_Affinity_and_Anion_Exchange_Chromatography_Operated_in_a_Weak_Partitioning_Mode,'tandem system'
,public domain software, 'Personal computer',https://archive.org/stream/mpms-2/mpms-2_djvu.txt,'tandem system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,quality assurance ( sqa ), 'Personal computer',https://www.researchgate.net/publication/221417841_Exploring_Software_Quality_Classification_with_a_Wrapper-Based_Feature_Ranking_Technique,'tandem system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,capability maturity model ( cmm ), 'Personal computer',https://www.researchgate.net/profile/Marco_Kuhrmann/publication/277930589_Full_Raw_Data_Software_Process_Improvement_Where_is_the_Evidence/data/5576b9bf08aeb6d8c01b077f/data-final-web.xlsx,'light system'
"Watch the lights. A visual communication system.PubMedRahtz  S K1989-01-01The trend for hospitals to market their emergency care services results in a greater demand on radiology departments  states Ms. Rahtz. Radiology must provide efficient service to both departments  even when it is difficult to predict patient flow in the emergency care center. Improved communication is the key  and a light system installed at Morton Plant Hospital is one alternative for solving the problem.Orbital Angular Momentum Multiplexing over Visible Light Communication SystemsNASA Astrophysics Data System (ADS)Tripathi  Hardik RameshchandraThis thesis proposes and explores the possibility of using Orbital Angular Momentum multiplexing in Visible Light Communication system. Orbital Angular Momentum is mainly applied for laser and optical fiber transmissions  while Visible Light Communication is a technology using the light as a carrier for wireless communication. In this research  the study of the state of art and experiments showing some results on multiplexing based on Orbital Angular Momentum over Visible Light Communication system were done. After completion of the initial stage; research work and simulations were performed on spatial multiplexing over Li-Fi channel modeling. Simulation scenarios which allowed to evaluate the Signal-to-Noise Ratio  Received Power Distribution  Intensity and Illuminance were defined and developed.Efficient resource allocation scheme for visible-light communication systemNASA Astrophysics Data System (ADS)Kim  Woo-Chan; Bae  Chi-Sung; Cho  Dong-Ho; Shin  Hong-Seok; Jung  D. K.; Oh  Y. J.2009-01-01A visible-light communication utilizing LED has many advantagies such as visibility of information  high SNR (Signal to Noise Ratio)  low installation cost  usage of existing illuminators  and high security. Furthermore  exponentially increasing needs and quality of LED have helped the development of visible-light communication. The visibility is the most attractive property in visible-light communication system  but it is difficult to ensure visibility and transmission efficiency simultaneously during initial access because of the small amount of initial access process signals. In this paper  we propose an efficient resource allocation scheme at initial access for ensuring visibility with high resource utilization rate and low data transmission failure rate. The performance has been evaluated through the numerical analysis and simulation results.Visible Light Communication System Using an Organic Bulk Heterojunction PhotodetectorPubMed CentralArredondo  BelÃ©n; Romero  Beatriz; Pena  JosÃ© Manuel SÃ¡nchez; FernÃ¡ndez-Pacheco  AgustÃ­n; Alonso  Eduardo; Vergaz  Ricardo; de Dios  Cristina2013-01-01A visible light communication (VLC) system using an organic bulk heterojunction photodetector (OPD) is presented. The system has been successfully proven indoors with an audio signal. The emitter consists of three commercial high-power white LEDs connected in parallel. The receiver is based on an organic photodetector having as active layer a blend of poly(3-hexylthiophene) (P3HT) and phenyl C61-butyric acid methyl ester (PCBM). The OPD is opto-electrically characterized  showing a responsivity of 0.18 A/W and a modulation response of 790 kHz at âˆ’6 V. PMID:24036584Unequal error control scheme for dimmable visible light communication systemsNASA Astrophysics Data System (ADS)Deng  Keyan; Yuan  Lei; Wan  Yi; Li  Huaan2017-01-01Visible light communication (VLC)  which has the advantages of a very large bandwidth  high security  and freedom from license-related restrictions and electromagnetic-interference  has attracted much interest. Because a VLC system simultaneously performs illumination and communication functions  dimming control  efficiency  and reliable transmission are significant and challenging issues of such systems. In this paper  we propose a novel unequal error control (UEC) scheme in which expanding window fountain (EWF) codes in an on-off keying (OOK)-based VLC system are used to support different dimming target values. To evaluate the performance of the scheme for various dimming target values  we apply it to H.264 scalable video coding bitstreams in a VLC system. The results of the simulations that are performed using additive white Gaussian noises (AWGNs) with different signal-to-noise ratios (SNRs) are used to compare the performance of the proposed scheme for various dimming target values. It is found that the proposed UEC scheme enables earlier base layer recovery compared to the use of the equal error control (EEC) scheme for different dimming target values and therefore afford robust transmission for scalable video multicast over optical wireless channels. This is because of the unequal error protection (UEP) and unequal recovery time (URT) of the EWF code in the proposed scheme.Mobile health-monitoring system through visible light communication.PubMedTan  Yee-Yong; Chung  Wan-Young2014-01-01Promising development in the light emitting diode (LED) technology has spurred the interest to adapt LED for both illumination and data transmission. This has fostered the growth of interest in visible light communication (VLC)  with on-going research to utilize VLC in various applications. This paper presents a mobile-health monitoring system  where healthcare information such as biomedical signals and patient information are transmitted via the LED lighting. A small and portable receiver module is designed and developed to be attached to the mobile device  providing a seamless monitoring environment. Three different healthcare information including ECG  PPG signals and HL7 text information is transmitted simultaneously  using a single channel VLC. This allows for a more precise and accurate monitoring and diagnosis. The data packet size is carefully designed  to transmit information in a minimal packet error rate. A comprehensive monitoring application is designed and developed through the use of a tablet computer in our study. Monitoring and evaluation such as heart rate and arterial blood pressure measurement can be performed concurrently. Real-time monitoring is demonstrated through experiment  where non-hazardous transmission method can be implemented alongside a portable device for better and safer healthcare service.A CDMA system implementation with dimming control for visible light communicationNASA Astrophysics Data System (ADS)Chen  Danyang; Wang  Jianping; Jin  Jianli; Lu  Huimin; Feng  Lifang2018-04-01Visible light communication (VLC)  using solid-state lightings to transmit information  has become a complement technology to wireless radio communication. As a realistic multiple access scheme for VLC system  code division multiple access (CDMA) has attracted more and more attentions in recent years. In this paper  we address and implement an improved CDMA scheme for VLC system. The simulation results reveal that the improved CDMA scheme not only supports multi-users' transmission but also maintains dimming value at about 50% and enhances the system efficiency. It can also realize the flexible dimming control by adjusting some parameters of system structure  which rarely affects the system BER performance. A real-time experimental VLC system with improved CDMA scheme is performed based on field programmable gate array (FPGA)  reaching a good BER performance.Optical Fiber Connection Navigation System Using Visible Light Communication in Central Office with Economic EvaluationNASA Astrophysics Data System (ADS)Waki  Masaki; Uruno  Shigenori; Ohashi  Hiroyuki; Manabe  Tetsuya; Azuma  YujiWe propose an optical fiber connection navigation system that uses visible light communication for an integrated distribution module in a central office. The system realizes an accurate database  requires less skilled work to operate and eliminates human error. This system can achieve a working time reduction of up to 88.0% compared with the conventional work without human error for the connection/removal of optical fiber cords  and is economical as regards installation and operation.Influence of non-line of sight luminescent emitters in visible light communication systemsNASA Astrophysics Data System (ADS)Ghorai  Anaranya; Walvekar  Pratik; Nayak  Shreyas; Narayan  K. S.2018-01-01We introduce and demonstrate concepts which utilize the non-line of sight fraction of light incident on a detector assembly in a visible-light communication (VLC) system. In addition to ambient light  realistic enclosures where VLC is implemented consist of a sizable fraction of scattered and reflected light. We present results of VLC systems with detectors responding to contributions from the light source scattered off a surface embedded with fluorescent and phosphorescent emitters besides the direct line of sight signal. Contribution from the emitters takes a form of discernible fluctuations in the detector signal. The implication of our results from noise analysis of these fluctuations indicates the possibility of utilizing smart coatings to further tailor VLC capabilities.Massive MIMO-OFDM indoor visible light communication system downlink architecture designNASA Astrophysics Data System (ADS)Lang  Tian; Li  Zening; Chen  Gang2014-10-01Multiple-input multiple-output (MIMO) technique is now used in most new broadband communication system  and orthogonal frequency division multiplexing (OFDM) is also utilized within current 4th generation (4G) of mobile telecommunication technology. With MIMO and OFDM combined  visible light communication (VLC) system's diversity gain is increase  yet system capacity for dispersive channels is also enhanced. Moreover  with the emerging massive MIMO-OFDM VLC system  there are significant advantages than smaller systems' such as channel hardening  further increasing of energy efficiency (EE) and spectral efficiency (SE) based on law of large number. This paper addresses one of the major technological challenges  system architecture design  which was solved by semispherical beehive structure (SBS) receiver and so that diversity gain can be identified and applied in Massive MIMO VLC system. Simulation results shows that the proposed design clearly presents a spatial diversity over conventional VLC systems.Energy efficient lighting and communicationsNASA Astrophysics Data System (ADS)Zhou  Z.; Kavehrad  M.; Deng  P.2012-01-01As Light-Emitting Diode (LED)'s increasingly displace incandescent lighting over the next few years  general applications of Visible Light Communication (VLC) technology are expected to include wireless internet access  vehicle-to-vehicle communications  broadcast from LED signage  and machine-to-machine communications. An objective in this paper is to reveal the influence of system parameters on the power distribution and communication quality  in a general plural sources VLC system. It is demonstrated that sources' Half-Power Angles (HPA)  receivers' Field-Of Views (FOV)  sources layout and the power distribution among sources are significant impact factors. Based on our findings  we developed a method to adaptively change working status of each LED respectively according to users' locations. The program minimizes total power emitted while simultaneously ensuring sufficient light intensity and communication quality for each user. The paper also compares Orthogonal Frequency-Division Multiplexing (OFDM) and On-Off Keying (OOK) signals performance in indoor optical wireless communications. The simulation is carried out for different locations where different impulse response distortions are experienced. OFDM seems a better choice than prevalent OOK for indoor VLC due to its high resistance to multi-path effect and delay spread. However  the peak-to-average power limitations of the method must be investigated for lighting LEDs.Indoor visible light communication localization system utilizing received signal strength indication technique and trilateration methodNASA Astrophysics Data System (ADS)Mousa  Farag I. K.; Almaadeed  Noor; Busawon  Krishna; Bouridane  Ahmed; Binns  Richard; Elliot  Ian2018-01-01Visible light communication (VLC) based on light-emitting diodes (LEDs) technology not only provides higher data rate for indoor wireless communications and offering room illumination but also has the potential for indoor localization. VLC-based indoor positioning using the received optical power levels from emitting LEDs is investigated. We consider both scenarios of line-of-sight (LOS) and LOS with non-LOS (LOSNLOS) positioning. The performance of the proposed system is evaluated under both noisy and noiseless channel as is the impact of different location codes on positioning error. The analytical model of the system with noise and the corresponding numerical evaluation for a range of signal-to-noise ratio (SNR) are presented. The results show that an accuracy of <10 cm on average is achievable at an SNR>12 dB.Orthogonal frequency-division multiplexing access (OFDMA) based wireless visible light communication (VLC) systemNASA Astrophysics Data System (ADS)Sung  Jiun-Yu; Yeh  Chien-Hung; Chow  Chi-Wai; Lin  Wan-Feng; Liu  Yang2015-11-01An orthogonal frequency-division multiplexing access (OFDMA) based visible light communication (VLC) system is proposed in this paper. The architecture of the proposed system is divided into several VLC cells  which is defined in this paper. The deployment and upgrade of the system involve only simple combination of the VLC cells. Hence it is economically advantageous. To guarantee smooth communication  nearly equal data rate is provided at every location within the system with no concern on the system scale. The user location monitor strategy is also discussed to solve the region division issues. The characteristics of the proposed system are analyzed in detail in this paper. A one-dimensional experiment was demonstrated with 13.6 Mb/s data rate.High security chaotic multiple access scheme for visible light communication systems with advanced encryption standard interleavingNASA Astrophysics Data System (ADS)Qiu  Junchao; Zhang  Lin; Li  Diyang; Liu  Xingcheng2016-06-01Chaotic sequences can be applied to realize multiple user access and improve the system security for a visible light communication (VLC) system. However  since the map patterns of chaotic sequences are usually well known  eavesdroppers can possibly derive the key parameters of chaotic sequences and subsequently retrieve the information. We design an advanced encryption standard (AES) interleaving aided multiple user access scheme to enhance the security of a chaotic code division multiple access-based visible light communication (C-CDMA-VLC) system. We propose to spread the information with chaotic sequences  and then the spread information is interleaved by an AES algorithm and transmitted over VLC channels. Since the computation complexity of performing inverse operations to deinterleave the information is high  the eavesdroppers in a high speed VLC system cannot retrieve the information in real time; thus  the system security will be enhanced. Moreover  we build a mathematical model for the AES-aided VLC system and derive the theoretical information leakage to analyze the system security. The simulations are performed over VLC channels  and the results demonstrate the effectiveness and high security of our presented AES interleaving aided chaotic CDMA-VLC system.A hybrid CATV/16-QAM-OFDM visible laser light communication systemNASA Astrophysics Data System (ADS)Lin  Chun-Yu; Li  Chung-Yi; Lu  Hai-Han; Chen  Chia-Yi; Jhang  Tai-Wei; Ruan  Sheng-Siang; Wu  Kuan-Hung2014-10-01A visible laser light communication (VLLC) system employing a vertical cavity surface emitting laser and spatial light modulator with hybrid CATV/16-QAM-OFDM modulating signals over a 5â€‰m free-space link is proposed and demonstrated. With the assistance of a push-pull scheme  low-noise amplifier  and equalizer  good performances of composite second-order and composite triple beat are obtained  accompanied by an acceptable carrier-to-noise ratio performance for a CATV signal  and a low bit error rate value and clear constellation map are achieved for a 16-QAM-OFDM signal. Such a hybrid CATV/16-QAM-OFDM VLLC system would be attractive for providing services including CATV  Internet and telecommunication services.Discrete Indoor Three-Dimensional Localization System Based on Neural Networks Using Visible Light CommunicationPubMed CentralLey-Bosch  Carlos; Quintana-SuÃ¡rez  Miguel A.2018-01-01Indoor localization estimation has become an attractive research topic due to growing interest in location-aware services. Many research works have proposed solving this problem by using wireless communication systems based on radiofrequency. Nevertheless  those approaches usually deliver an accuracy of up to two metres  since they are hindered by multipath propagation. On the other hand  in the last few years  the increasing use of light-emitting diodes in illumination systems has provided the emergence of Visible Light Communication technologies  in which data communication is performed by transmitting through the visible band of the electromagnetic spectrum. This brings a brand new approach to high accuracy indoor positioning because this kind of network is not affected by electromagnetic interferences and the received optical power is more stable than radio signals. Our research focus on to propose a fingerprinting indoor positioning estimation system based on neural networks to predict the device position in a 3D environment. Neural networks are an effective classification and predictive method. The localization system is built using a dataset of received signal strength coming from a grid of different points. From the these values  the position in Cartesian coordinates (x y z) is estimated. The use of three neural networks is proposed in this work  where each network is responsible for estimating the position by each axis. Experimental results indicate that the proposed system leads to substantial improvements to accuracy over the widely-used traditional fingerprinting methods  yielding an accuracy above 99% and an average error distance of 0.4 mm. PMID:29601525Implementation of a light-route TDMA communications satellite system for advanced business networksNASA Astrophysics Data System (ADS)Hanson  B.; Smalley  A.; Zuliani  M.The application of Light Route TDMA systems to various business communication requirements is discussed. It is noted that full development of this technology for use in advanced business networks will be guided by considerations of flexibility  reliability  security  and cost. The implementation of the TDMA system for demonstrating these advantages to a wide range of public and private organizations is described in detail. Among the advantages offered by this system are point-to-point and point-to-multipoint (broadcast) capability; the ability to vary the mix and quantity of services between destinations in a fully connected mesh network on an almost instantaneous basis through software control; and enhanced reliability with centralized monitor  alarm and control functions by virtue of an overhead channel.White LED visible light communication technology researchNASA Astrophysics Data System (ADS)Yang  Chao2017-03-01Visible light communication is a new type of wireless optical communication technology. White LED to the success of development  the LED lighting technology is facing a new revolution. Because the LED has high sensitivity  modulation  the advantages of good performance  large transmission power  can make it in light transmission light signal at the same time. Use white LED light-emitting characteristics  on the modulation signals to the visible light transmission  can constitute a LED visible light communication system. We built a small visible optical communication system. The system composition and structure has certain value in the field of practical application  and we also research the key technology of transmitters and receivers  the key problem has been resolved. By studying on the optical and LED the characteristics of a high speed modulation driving circuit and a high sensitive receiving circuit was designed. And information transmission through the single chip microcomputer test  a preliminary verification has realized the data transmission function.An in-Depth Survey of Visible Light Communication Based Positioning SystemsPubMed CentralDo  Trong-Hop; Yoo  Myungsik2016-01-01While visible light communication (VLC) has become the candidate for the wireless technology of the 21st century due to its inherent advantages  VLC based positioning also has a great chance of becoming the standard approach to positioning. Within the last few years  many studies on VLC based positioning have been published  but there are not many survey works in this field. In this paper  an in-depth survey of VLC based positioning systems is provided. More than 100 papers ranging from pioneering papers to the state-of-the-art in the field were collected and classified based on the positioning algorithms  the types of receivers  and the multiplexing techniques. In addition  current issues and research trends in VLC based positioning are discussed. PMID:27187395Multiple-input multiple-output visible light communication system based on disorder dispersion componentsNASA Astrophysics Data System (ADS)Yang  Tao; Zhang  Qi; Hao  Yue; Zhou  Xin-hui; Yi  Ming-dong; Wei  Wei; Huang  Wei; Li  Xing-ao2017-10-01A multiple-input multiple-output visible light communication (VLC) system based on disorder dispersion components is presented. Instead of monochromatic sources and large size photodetectors used in the traditional VLC systems  broadband sources with different spectra act as the transmitters and a compact imaging chip sensor accompanied by a disorder dispersion component and a calculating component serve as the receivers in the proposed system. This system has the merits of small size  more channels  simple structure  easy integration  and low cost. Simultaneously  the broadband sources are suitable to act as illumination sources for their white color. A regularized procedure is designed to solve a matrix equation for decoding the signals at the receivers. A proof-of-concept experiment using on-off keying modulation has been done to prove the feasibility of the design. The experimental results show that the signals decoded by the receivers fit well with those generated from the transmitters  but the bit error ratio is increased with the number of the signal channels. The experimental results can be further improved using a high-speed charge-coupled device  decreasing noises  and increasing the distance between the transmitters and the receivers.1Ã—2 demultiplexer for a light waveguide communications system based on a holographic gratingNASA Astrophysics Data System (ADS)Ren  Xuechang; Zhang  Xiangsu; Wang  Canhui; Liu  Shou2009-05-012-channel multiplexer/demultiplexer (Muxer/Demuxer) is a key component for bidirectional data traffics applied for optical communication. Up to date various types of Muxer/Demuxer have been proposed and demonstrated. A grating coupler diffracts light into substrates or waveguides  along which light beam propagates by total internal reflection. In addition  one can exploit the dispersive and filtering characteristics of gratings  for dropping or separating one or several wavelengths from one another. When a laser beam containing two wavelengths is striking the surface of the grating with an incident angle within certain range  four diffracted beams will be generated. If two diffracted beams  corresponding to different wavelengths  meet the condition of total internal reflection  they will propagate inside the glass substrate (performs as a waveguide). While the third one cannot meet total reflection condition  and the last one should become the evanescent wave. Therefore it can separate two signals and couple signals to different waveguides. These functions are suited for WDM application and directional couplers. For convenience sake  the visible lights at 458nm and 633nm were used as the incident laser beams. To give a simple sample for 1Ã—2 demultiplexing system  a holographic grating was recorded  with the period around 441nm which was chose discretionally within the certain range. The primary experimental results indicate that the two-wavelength signal can be separated and coupled into the respective waveguide as long as the grating is recorded and operated complying with the certain condition. The average insertion loss and crosstalk of the device were presented in this paper.Time domain reshuffling for OFDM based indoor visible light communication systems.PubMedYou  Xiaodi; Chen  Jian; Yu  Changyuan; Zheng  Huanhuan2017-05-15For orthogonal frequency division multiplexing (OFDM) based indoor visible light communication (VLC) systems  partial non-ideal transmission conditions such as insufficient guard intervals and a dispersive channel can result in severe inter-symbol crosstalk (ISC). By deriving from the inverse Fourier transform  we present a novel time domain reshuffling (TDR) concept for both DC-biased optical (DCO-) and asymmetrically clipped optical (ACO-) OFDM VLC systems. By using only simple operations in the frequency domain  potential high peaks can be relocated within each OFDM symbol to alleviate ISC. To simplify the system  we also propose an effective unified design of the TDR schemes for both DCO- and ACO-OFDM. Based on Monte-Carlo simulations  we demonstrate the statistical distribution of the signal high peak values and the complementary cumulative distribution function of the peak-to-average power ratio under different cases for comparison. Simulation results indicate improved bit error rate (BER) performance by adopting TDR to counteract ISC deterioration. For example  for binary phase shift keying at a BER of 10 -3   the signal to noise ratio gains are ~1.6 dB and ~6.6 dB for DCO- and ACO-OFDM  respectively  with ISC of 1/64. We also show a reliable transmission by adopting TDR for rectangle 8-quadrature amplitude modulation with ISC of < 1/64.Performance analysis of visible light communication using the STBC-OFDM technique for intelligent transportation systemsNASA Astrophysics Data System (ADS)Li  Changping; Yi  Ying; Lee  Kyujin; Lee  Kyesan2014-08-01Visible light communication (VLC) applied in an intelligent transportation system (ITS) has attracted growing attentions  but it also faces challenges  for example deep path loss and optical multi-path dispersion. In this work  we modelled an actual outdoor optical channel as a Rician channel and further proposed space-time block coding (STBC) orthogonal frequency-division multiplexing (OFDM) technology to reduce the influence of severe optical multi-path dispersion associated with such a mock channel for achieving the effective BER of 10-6 even at a low signal-to-noise ratio (SNR). In this case  the optical signals transmission distance can be extended as long as possible. Through the simulation results of STBC-OFDM and single-input-single-output (SISO) counterparts in bit error rate (BER) performance comparison  we can distinctly observe that the VLC-ITS system using STBC-OFDM technique can obtain a strongly improved BER performance due to multi-path dispersion alleviation.A power-efficient ZF precoding scheme for multi-user indoor visible light communication systemsNASA Astrophysics Data System (ADS)Zhao  Qiong; Fan  Yangyu; Deng  Lijun; Kang  Bochao2017-02-01In this study  we propose a power-efficient ZF precoding scheme for visible light communication (VLC) downlink multi-user multiple-input-single-output (MU-MISO) systems  which incorporates the zero-forcing (ZF) and the characteristics of VLC systems. The main idea of this scheme is that the channel matrix used to perform pseudoinverse comes from the set of optical Access Points (APs) shared by more than one user  instead of the set of all involved serving APs as the existing ZF precoding schemes often used. By doing this  the waste of power  which is caused by the transmission of one user's data in the un-serving APs  can be avoided. In addition  the size of the channel matrix needs to perform pseudoinverse becomes smaller  which helps to reduce the computation complexity. Simulation results in two scenarios show that the proposed ZF precoding scheme has higher power efficiency  better bit error rate (BER) performance and lower computation complexity compared with traditional ZF precoding schemes.Multiple wavelength spectral system simulating background light noise environment in satellite laser communicationsNASA Astrophysics Data System (ADS)Lu  Wei; Sun  Jianfeng; Hou  Peipei; Xu  Qian; Xi  Yueli; Zhou  Yu; Zhu  Funan; Liu  Liren2017-08-01Performance of satellite laser communications between GEO and LEO satellites can be influenced by background light noise appeared in the field of view due to sunlight or planets and some comets. Such influences should be studied on the ground testing platform before the space application. In this paper  we introduce a simulator that can simulate the real case of background light noise in space environment during the data talking via laser beam between two lonely satellites. This simulator can not only simulate the effect of multi-wavelength spectrum  but also the effects of adjustable angles of field-of-view  large range of adjustable optical power and adjustable deflection speeds of light noise in space environment. We integrate these functions into a device with small and compact size for easily mobile use. Software control function is also achieved via personal computer to adjust these functions arbitrarily. Keywords:Experimental investigation of analog and digital dimming techniques on photometric performance of an indoor Visible Light Communication (VLC) systemNASA Astrophysics Data System (ADS)Zafar  Fahad; Kalavally  Vineetha; Bakaul  Masuduzzaman; Parthiban  R.2015-09-01For making commercial implementation of light emitting diode (LED) based visible light communication (VLC) systems feasible  it is necessary to incorporate it with dimming schemes which will provide energy savings  moods and increase the aesthetic value of the places using this technology. There are two general methods which are used to dim LEDs commonly categorized as analog and digital dimming. Incorporating fast data transmission with these techniques is a key challenge in VLC. In this paper  digital and analog dimming for a 10 Mb/s non return to zero on-off keying (NRZ-OOK) based VLC system is experimentally investigated considering both photometric and communicative parameters. A spectrophotometer was used for photometric analysis and a line of sight (LOS) configuration in the presence of ambient light was used for analyzing communication parameters. Based on the experimental results  it was determined that digital dimming scheme is preferable for use in indoor VLC systems requiring high dimming precision and data transmission at lower brightness levels. On the other hand  analog dimming scheme is a cost effective solution for high speed systems where dimming precision is insignificant.Active tracking system for visible light communication using a GaN-based micro-LED and NRZ-OOK.PubMedLu  Zhijian; Tian  Pengfei; Chen  Hong; Baranowski  Izak; Fu  Houqiang; Huang  Xuanqi; Montes  Jossue; Fan  Youyou; Wang  Hongyi; Liu  Xiaoyan; Liu  Ran; Zhao  Yuji2017-07-24Visible light communication (VLC) holds the promise of a high-speed wireless network for indoor applications and competes with 5G radio frequency (RF) system. Although the breakthrough of gallium nitride (GaN) based micro-light-emitting-diodes (micro-LEDs) increases the -3dB modulation bandwidth exceptionally from tens of MHz to hundreds of MHz  the light collected onto a fast photo receiver drops dramatically  which determines the signal to noise ratio (SNR) of VLC. To fully implement the practical high data-rate VLC link enabled by a GaN-based micro-LED  it requires focusing optics and a tracking system. In this paper  we demonstrate an active on-chip tracking system for VLC using a GaN-based micro-LED and none-return-to-zero on-off keying (NRZ-OOK). Using this novel technique  the field of view (FOV) was enlarged to 120Â° and data rates up to 600 Mbps at a bit error rate (BER) of 2.1Ã—10 -4 were achieved without manual focusing. This paper demonstrates the establishment of a VLC physical link that shows enhanced communication quality by orders of magnitude  making it optimized for practical communication applications.An easy to deploy street light control system based on wireless communication and LED technology.PubMedElejoste  Pilar; Angulo  Ignacio; Perallos  Asier; Chertudi  Aitor; Zuazola  Ignacio Julio GarcÃ­a; Moreno  Asier; Azpilicueta  Leire; Astrain  JosÃ© Javier; Falcone  Francisco; Villadangos  JesÃºs2013-05-16This paper presents an intelligent streetlight management system based on LED lamps  designed to facilitate its deployment in existing facilities. The proposed approach  which is based on wireless communication technologies  will minimize the cost of investment of traditional wired systems  which always need civil engineering for burying of cable underground and consequently are more expensive than if the connection of the different nodes is made over the air. The deployed solution will be aware of their surrounding's environmental conditions  a fact that will be approached for the system intelligence in order to learn  and later  apply dynamic rules. The knowledge of real time illumination needs  in terms of instant use of the street in which it is installed  will also feed our system  with the objective of providing tangible solutions to reduce energy consumption according to the contextual needs  an exact calculation of energy consumption and reliable mechanisms for preventive maintenance of facilities.An Easy to Deploy Street Light Control System Based on Wireless Communication and LED TechnologyPubMed CentralElejoste  Pilar; Angulo  Ignacio; Perallos  Asier; Chertudi  Aitor; Zuazola  Ignacio Julio GarcÃ­a; Moreno  Asier; Azpilicueta  Leire; Astrain  JosÃ© Javier; Falcone  Francisco; Villadangos  JesÃºs2013-01-01This paper presents an intelligent streetlight management system based on LED lamps  designed to facilitate its deployment in existing facilities. The proposed approach  which is based on wireless communication technologies  will minimize the cost of investment of traditional wired systems  which always need civil engineering for burying of cable underground and consequently are more expensive than if the connection of the different nodes is made over the air. The deployed solution will be aware of their surrounding's environmental conditions  a fact that will be approached for the system intelligence in order to learn  and later  apply dynamic rules. The knowledge of real time illumination needs  in terms of instant use of the street in which it is installed  will also feed our system  with the objective of providing tangible solutions to reduce energy consumption according to the contextual needs  an exact calculation of energy consumption and reliable mechanisms for preventive maintenance of facilities. PMID:23681092Interface Control Document for the Traffic Lights and Emergency Communications System at Gretna and Governor Nicholls Traffic Light FacilitiesDOT National Transportation Integrated Search1997-11-06Gretna and Governor Nicholls Light facilities are two manned shore side : facilities mounted in critical areas on the banks of the Mississippi River in : the port of New Orleans  Louisiana. Coast Guard plans call for the lights to : be remotely contr...Long-range high-speed visible light communication system over 100-m outdoor transmission utilizing receiver diversity technologyNASA Astrophysics Data System (ADS)Wang  Yiguang; Huang  Xingxing; Shi  Jianyang; Wang  Yuan-quan; Chi  Nan2016-05-01Visible light communication (VLC) has no doubt become a promising candidate for future wireless communications due to the increasing trends in the usage of light-emitting diodes (LEDs). In addition to indoor high-speed wireless access and positioning applications  VLC usage in outdoor scenarios  such as vehicle networks and intelligent transportation systems  are also attracting significant interest. However  the complex outdoor environment and ambient noise are the key challenges for long-range high-speed VLC outdoor applications. To improve system performance and transmission distance  we propose to use receiver diversity technology in an outdoor VLC system. Maximal ratio combining-based receiver diversity technology is utilized in two receivers to achieve the maximal signal-to-noise ratio. A 400-Mb/s VLC transmission using a phosphor-based white LED and a 1-Gb/s wavelength division multiplexing VLC transmission using a red-green-blue LED are both successfully achieved over a 100-m outdoor distance with the bit error rate below the 7% forward error correction limit of 3.8Ã—10-3. To the best of our knowledge  this is the highest data rate at 100-m outdoor VLC transmission ever achieved. The experimental results clearly prove the benefit and feasibility of receiver diversity technology for long-range high-speed outdoor VLC systems.Design of an indoor self-positioning system for the visually impaired--simulation with RFID and Bluetooth in a visible light communication system.PubMedLiu  Xiaohan; Makino  Hideo; Kobayashi  Suguru; Maeda  Yoshinobu2007-01-01After a public experiment of the indoor guidance system using FLC (fluorescent light communication)  we found that FLC provides a promising medium for the installation of a guidance system for the visually impaired. However  precise self-positioning was not satisfactorily achieved. In this article  we propose a new self-positioning method  one that uses a combination of RFID (Radio-frequency identification)  Bluetooth and FLC. We analyzed the situation and developed a model that combined the three communication modes. Then we performed a series of experiments and get some results in the first step.Indoor high precision three-dimensional positioning system based on visible light communication using modified genetic algorithmNASA Astrophysics Data System (ADS)Chen  Hao; Guan  Weipeng; Li  Simin; Wu  Yuxiang2018-04-01To improve the precision of indoor positioning and actualize three-dimensional positioning  a reversed indoor positioning system based on visible light communication (VLC) using genetic algorithm (GA) is proposed. In order to solve the problem of interference between signal sources  CDMA modulation is used. Each light-emitting diode (LED) in the system broadcasts a unique identity (ID) code using CDMA modulation. Receiver receives mixed signal from every LED reference point  by the orthogonality of spreading code in CDMA modulation  ID information and intensity attenuation information from every LED can be obtained. According to positioning principle of received signal strength (RSS)  the coordinate of the receiver can be determined. Due to system noise and imperfection of device utilized in the system  distance between receiver and transmitters will deviate from the real value resulting in positioning error. By introducing error correction factors to global parallel search of genetic algorithm  coordinates of the receiver in three-dimensional space can be determined precisely. Both simulation results and experimental results show that in practical application scenarios  the proposed positioning system can realize high precision positioning service.Image secure transmission for optical orthogonal frequency-division multiplexing visible light communication systems using chaotic discrete cosine transformNASA Astrophysics Data System (ADS)Wang  Zhongpeng; Zhang  Shaozhong; Chen  Fangni; Wu  Ming-Wei; Qiu  Weiwei2017-11-01A physical encryption scheme for orthogonal frequency-division multiplexing (OFDM) visible light communication (VLC) systems using chaotic discrete cosine transform (DCT) is proposed. In the scheme  the row of the DCT matrix is permutated by a scrambling sequence generated by a three-dimensional (3-D) Arnold chaos map. Furthermore  two scrambling sequences  which are also generated from a 3-D Arnold map  are employed to encrypt the real and imaginary parts of the transmitted OFDM signal before the chaotic DCT operation. The proposed scheme enhances the physical layer security and improves the bit error rate (BER) performance for OFDM-based VLC. The simulation results prove the efficiency of the proposed encryption method. The experimental results show that the proposed security scheme not only protects image data from eavesdroppers but also keeps the good BER and peak-to-average power ratio performances for image-based OFDM-VLC systems.Experimental demonstration of an OFDM based visible light communication system using inter-block precoding and superimposed pilotsNASA Astrophysics Data System (ADS)Zhang  Junwei; Hong  Xuezhi; Liu  Jie; Guo  Changjian2018-04-01In this work  we investigate and experimentally demonstrate an orthogonal frequency division multiplexing (OFDM) based high speed wavelength-division multiplexed (WDM) visible light communication (VLC) system using an inter-block data precoding and superimposed pilots (DP-SP) based channel estimation (CE) scheme. The residual signal-to-pilot interference (SPI) can be eliminated by using inter-block data precoding  resulting in a significant improvement in estimated accuracy and the overall system performance compared with uncoded SP based CE scheme. We also study the power allocation/overhead problem of the training for DP-SP  uncoded SP and conventional preamble based CE schemes  from which we obtain the optimum signal-to-pilot power ratio (SPR)/overhead percentage for all above cases. Intra-symbol frequency-domain averaging (ISFA) is also adopted to further enhance the accuracy of CE. By using the DP-SP based CE scheme  aggregate data rates of 1.87-Gbit/s and 1.57-Gbit/s are experimentally demonstrated over 0.8-m and 2-m indoor free space transmission  respectively  using a commercially available red  green and blue (RGB) light emitting diode (LED) with WDM. Experimental results show that the DP-SP based CE scheme is comparable to the conventional preamble based CE scheme in term of received Q factor and data rate while entailing a much smaller overhead-size.A Probability-Based Algorithm Using Image Sensors to Track the LED in a Vehicle Visible Light Communication System.PubMedHuynh  Phat; Do  Trong-Hop; Yoo  Myungsik2017-02-10This paper proposes a probability-based algorithm to track the LED in vehicle visible light communication systems using a camera. In this system  the transmitters are the vehicles' front and rear LED lights. The receivers are high speed cameras that take a series of images of the LEDs. Thedataembeddedinthelightisextractedbyï¬rstdetectingthepositionoftheLEDsintheseimages. Traditionally  LEDs are detected according to pixel intensity. However  when the vehicle is moving  motion blur occurs in the LED images  making it difï¬cult to detect the LEDs. Particularly at high speeds  some frames are blurred at a high degree  which makes it impossible to detect the LED as well as extract the information embedded in these frames. The proposed algorithm relies not only on the pixel intensity  but also on the optical ï¬‚ow of the LEDs and on statistical information obtained from previous frames. Based on this information  the conditional probability that a pixel belongs to a LED is calculated. Then  the position of LED is determined based on this probability. To verify the suitability of the proposed algorithm  simulations are conducted by considering the incidents that can happen in a real-world situation  including a change in the position of the LEDs at each frame  as well as motion blur due to the vehicle speed.Visible light communication applications in healthcare.PubMedMuhammad  Shoaib; Qasid  Syed Hussain Ahmed; Rehman  Shafia; Rai  Aitzaz Bin Sulltan2016-01-01With the development in science  methods of communication are also improved  replacing old ones with new advanced ways in an attempt to make data transfer more secure  safer for health  and time as well as cost efficient. One of such methods is Visible Light Communication  as the name implies data is transferred through a light equipment such as incandescent or florescent bulb having speed of 10 Kb/s or LEDs approaching speed of 500 Mb/s [1]. VLC uses visible light between 384 and 789 THz [2 3]. Though range is limitation of VLC  however data transfer up-to distance of 1 to 2 km although at lower transfer rate has been reached.The VLC system comprises of light source like LED and receiver equipment  however  with advancement  now LEDs are used for both sending and receiving data. LED remains on all the time  and there is no change in brightness level during the whole process  making it safe for eyes. Currently  VLC system is facing some serious technical challenges before it could be applied in daily life.Signal source optimization of visible light communication for communication equalityNASA Astrophysics Data System (ADS)Yun  Liu; Wen  Shangsheng; Xie  Canyu; Chen  Yincong2018-03-01Square and circular light source layouts conventionally employed in visible light communication (VLC) systems suffer from communication blind spots and received signal nonuniformity as well as from large power fluctuations in the middle of the room. To address these shortcomings  we use the cross square and annulus layouts in conjunction with the cross-fertilize particle swarm optimization algorithm to improve VLC system performance. The distribution of the unit area received power (RPUA)  the distribution of the signal-to-noise ratio (SNR)  and the bit error rate (BER) performance were simulated and the rationality of the algorithm was compared. The results show that after optimization  the RPUA fluctuation value of the cross square layout decreases from 2.32 to 1.59 dB / m2  the SNR fluctuation value reduces from 8.5 to 4.2 dB  and the RPUA fluctuation value of the annulus layout decreases from 4.69 to 3.46 dB / m2  the SNR fluctuation value decreases from 13.3 to 8.8 dB. The RPUA value of cross-square layout fluctuates between -1.5 and -0.5 dB / m2  and the receiving area accounts for 93.4% in this range while in the case of the square layout  this area is only 86.7%. Therefore  it suggests that this scheme is reasonable for the equality of communication quality and system performance heightens greatly.Nanopatterned organic semiconductors for visible light communicationsNASA Astrophysics Data System (ADS)Yang  Xilu; Dong  Yurong; Zeng  Pan; Yu  Yan; Xie  Yujun; Gong  Junyi; Shi  Meng; Liang  Rongqing; Ou  Qiongrong; Chi  Nan; Zhang  Shuyu2018-03-01Visible light communication (VLC) is becoming an important and promising supplement to the existing Wi-Fi network for the coming 5G communications. Organic light-emitting semiconductors present much fast fluorescent decay rates compared to those of conventional colour-converting phosphors  therefore capable of achieving much higher bandwidths. Here we explore how nanopatterned organic semiconductors can further enhance the data rates of VLC links by improving bandwidths and signal-to-noise ratios (SNRs) and by supporting spatial multiplexing. We first demonstrate a colour-converting VLC system based on nanopatterned hyperbolic metamaterials (HMM)  the bandwidth of which is enhanced by 50%. With regard to enhancing SNRs  we achieve a tripling of optical gain by integrating a nanopatterned luminescent concentrator to a signal receiver. In addition  we demonstrate highly directional fluorescent VLC antennas based on nanoimprinted polymer films  paving the way to achieving parallel VLC communications via spatialmultiplexing. These results indicate nanopatterned organic semiconductors provide a promising route to high speed VLC links.Quantum communication with coherent states of light.PubMedKhan  Imran; Elser  Dominique; Dirmeier  Thomas; Marquardt  Christoph; Leuchs  Gerd2017-08-06Quantum communication offers long-term security especially  but not only  relevant to government and industrial users. It is worth noting that  for the first time in the history of cryptographic encoding  we are currently in the situation that secure communication can be based on the fundamental laws of physics (information theoretical security) rather than on algorithmic security relying on the complexity of algorithms  which is periodically endangered as standard computer technology advances. On a fundamental level  the security of quantum key distribution (QKD) relies on the non-orthogonality of the quantum states used. So even coherent states are well suited for this task  the quantum states that largely describe the light generated by laser systems. Depending on whether one uses detectors resolving single or multiple photon states or detectors measuring the field quadratures  one speaks of  respectively  a discrete- or a continuous-variable description. Continuous-variable QKD with coherent states uses a technology that is very similar to the one employed in classical coherent communication systems  the backbone of today's Internet connections. Here  we review recent developments in this field in two connected regimes: (i) improving QKD equipment by implementing front-end telecom devices and (ii) research into satellite QKD for bridging long distances by building upon existing optical satellite links.This article is part of the themed issue 'Quantum technology for the 21st century'. Â© 2017 The Author(s).Quantum communication with coherent states of lightNASA Astrophysics Data System (ADS)Khan  Imran; Elser  Dominique; Dirmeier  Thomas; Marquardt  Christoph; Leuchs  Gerd2017-06-01Quantum communication offers long-term security especially  but not only  relevant to government and industrial users. It is worth noting that  for the first time in the history of cryptographic encoding  we are currently in the situation that secure communication can be based on the fundamental laws of physics (information theoretical security) rather than on algorithmic security relying on the complexity of algorithms  which is periodically endangered as standard computer technology advances. On a fundamental level  the security of quantum key distribution (QKD) relies on the non-orthogonality of the quantum states used. So even coherent states are well suited for this task  the quantum states that largely describe the light generated by laser systems. Depending on whether one uses detectors resolving single or multiple photon states or detectors measuring the field quadratures  one speaks of  respectively  a discrete- or a continuous-variable description. Continuous-variable QKD with coherent states uses a technology that is very similar to the one employed in classical coherent communication systems  the backbone of today's Internet connections. Here  we review recent developments in this field in two connected regimes: (i) improving QKD equipment by implementing front-end telecom devices and (ii) research into satellite QKD for bridging long distances by building upon existing optical satellite links. This article is part of the themed issue 'Quantum technology for the 21st century'.Performance of a novel LED lamp arrangement to reduce SNR fluctuation for multi-user visible light communication systems.PubMedWang  Zixiong; Yu  Changyuan; Zhong  Wen-De; Chen  Jian; Chen  Wei2012-02-13This paper investigates the performance of our recently proposed LED lamp arrangement to reduce the SNR fluctuation from different locations in the room for multi-user visible light communications. The LED lamp arrangement consists of 4 LED lamps positioned in the corners and 12 LED lamps spread evenly on a circle. Our studies show that the SNR fluctuation under such a LED lamp arrangement is reduced from 14.5 dB to 0.9 dB  which guarantees that users can obtain almost identical communication quality  regardless of their locations. After time domain zero-forcing (ZF) equalization  the BER performances and channel capacities of 100-Mbit/s and 200-Mbit/s bipolar on-off-keying (OOK) signal with most significant inter-symbol interference (ISI) are very close to that of the channel without any ISI caused by this LED lamp arrangement.Conduits to care: call lights and patients' perceptions of communication.PubMedMontie  Mary; Shuman  Clayton; Galinato  Jose; Patak  Lance; Anderson  Christine A; Titler  Marita G2017-01-01Call light systems remain the primary means of hospitalized patients to initiate communication with their health care providers. Although there is vast amounts of literature discussing patient communication with their health care providers  few studies have explored patients' perceptions concerning call light use and communication. The specific aim of this study was to solicit patients' perceptions regarding their call light use and communication with nursing staff. Patients invited to this study met the following inclusion criteria: proficient in English  been hospitalized for at least 24 hours  aged â‰¥21 years  and able to communicate verbally (eg  not intubated). Thirty participants provided written informed consent  were enrolled in the study  and completed interviews. Using qualitative descriptive methods  five major themes emerged from patients' perceptions (namely; establishing connectivity  participant safety concerns  no separation: health care and the call light device  issues with the current call light  and participants' perceptions of ""nurse work""). Multiple minor themes supported these major themes. Data analysis utilized the constant comparative methods of Glaser and Strauss. Findings from this study extend the knowledge of patients' understanding of not only why inconsistencies occur between the call light and their nurses  but also why the call light is more than merely a device to initiate communication; rather  it is a direct conduit to their health care and its delivery.Conduits to care: call lights and patientsâ€™ perceptions of communicationPubMed CentralMontie  Mary; Shuman  Clayton; Galinato  Jose; Patak  Lance; Anderson  Christine A; Titler  Marita G2017-01-01Background Call light systems remain the primary means of hospitalized patients to initiate communication with their health care providers. Although there is vast amounts of literature discussing patient communication with their health care providers  few studies have explored patientsâ€™ perceptions concerning call light use and communication. The specific aim of this study was to solicit patientsâ€™ perceptions regarding their call light use and communication with nursing staff. Methods Patients invited to this study met the following inclusion criteria: proficient in English  been hospitalized for at least 24 hours  aged â‰¥21 years  and able to communicate verbally (eg  not intubated). Thirty participants provided written informed consent  were enrolled in the study  and completed interviews. Results Using qualitative descriptive methods  five major themes emerged from patientsâ€™ perceptions (namely; establishing connectivity  participant safety concerns  no separation: health care and the call light device  issues with the current call light  and participantsâ€™ perceptions of â€œnurse workâ€). Multiple minor themes supported these major themes. Data analysis utilized the constant comparative methods of Glaser and Strauss. Discussion Findings from this study extend the knowledge of patientsâ€™ understanding of not only why inconsistencies occur between the call light and their nurses  but also why the call light is more than merely a device to initiate communication; rather  it is a direct conduit to their health care and its delivery. PMID:29075125Resource allocation for multichannel broadcasting visible light communicationNASA Astrophysics Data System (ADS)Le  Nam-Tuan; Jang  Yeong Min2015-11-01Visible light communication (VLC)  which offers the possibility of using light sources for both illumination and data communications simultaneously  will be a promising incorporation technique with lighting applications. However  it still remains some challenges especially coverage because of field-of-view limitation. In this paper  we focus on this issue by suggesting a resource allocation scheme for VLC broadcasting system. By using frame synchronization and a network calculus QoS approximation  as well as diversity technology  the proposed VLC architecture and QoS resource allocation for the multichannel-broadcasting MAC (medium access control) protocol can solve the coverage limitation problem and the link switching problem of exhibition service.Catadioptric lenses in Visible Light CommunicationsNASA Astrophysics Data System (ADS)Garcia-Marquez  J.; Valencia  J. C.; Perez  H.; Topsu  S.2015-04-01Since few years ago  visible light communications (VLC) have experience an accelerated interest from a research point of view. The beginning of this decade has seen many improvements in VLC at an electronic level. High rates of transmission at low bit error ratios (BER) have been reported. A few numbers of start-ups have initiated activities to offer a variety of applications ranging from indoor geo-localization to internet  but in spite of these advancements  some other problems arise. Long-range transmissions mean a high BER which reduce the number of applications. In this sense  new redesigned optical collectors or in some cases  optical reflectors must be considered to ensure a low BER at higher distance transmissions. Here we also expose a preliminary design of a catadioptric and monolithical lens for a LI-FI receiver with two rotationally symmetrical main piecewise surfaces za and zb. These surfaces are represented in a system of cylindrical coordinates with an anterior surface za with a central and refractive sector surrounded by a peripheral reflective sector and a back piecewise surface zb with a central refractive sector and a reflective sector  both characterized as ideal for capturing light within large acceptance angles.Indoor visible light communication with smart lighting technologyNASA Astrophysics Data System (ADS)Das Barman  Abhirup; Halder  Alak2017-02-01An indoor visible-light communication performance is investigated utilizing energy efficient white light by 2D LED arrays. Enabled by recent advances in LED technology  IEEE 802.15.7 standardizes high-data-rate visible light communication and advocates for colour shift keying (CSK) modulation to overcome flicker and to support dimming. Voronoi segmentation is employed for decoding N-CSK constellation which has superior performance compared to other existing decoding methods. The two chief performance degrading effects of inter-symbol interference and LED nonlinearity is jointly mitigated using LMS post equalization at the receiver which improves the symbol error rate performance and increases field of view of the receiver. It is found that LMS post equalization symbol at 250MHz offers 7dB SNR improvement at SER10-6Secure video communications systemDOEpatentsSmith  Robert L.1991-01-01A secure video communications system having at least one command network formed by a combination of subsystems. The combination of subsystems to include a video subsystem  an audio subsystem  a communications subsystem  and a control subsystem. The video communications system to be window driven and mouse operated  and having the ability to allow for secure point-to-point real-time teleconferencing.Turn on the lights: leveraging visible light for communications and positioningNASA Astrophysics Data System (ADS)Hranilovic  Steve2015-01-01The need for ubiquitous broadband connectivity is continually growing  however  radio spectrum is increasingly scarce and limited by interference. In addition  the energy efficiency of many radio transmitters is low and most input energy is converted to heat. A widely overlooked resource for positioning and broadband access is optical wireless communication reusing existing illumination installations. As many of the 14 billion incandescent bulbs in use worldwide are converted to energy efficient LED lighting  a unique opportunity exists to augment them with visible light communications (VLC) and visible light positioning (VLP). VLC- and VLP- enabled LED lighting is not only energy efficient but enables a host of new use cases such as location-aware ubiquitous high-speed wireless communication links. This talk presents the recent work of the Free-space Optical Communication Algorithms Laboratory (FOCAL) at McMaster University in Hamilton  Canada in developing novel signaling and indoor localization techniques using illumination devices. Developments in the signaling design for VLC systems will be presented along with several prototype VLC communication systems. Novel approaches to the integration of VLC networks with power line communications (PLC) are discussed. The role of visible light communications and ranging for automotive safety will also be highlighted. Several approaches to indoor positioning using illumination devices and simple smartphone-based receivers will be presented. Finally  a vision for VLC and VLP technologies will be presented along with our ongoing research directions.Communication System and MethodNASA Technical Reports Server (NTRS)Sanders  Adam M. (Inventor); Strawser  Philip A. (Inventor)2014-01-01A communication system for communicating over high-latency  low bandwidth networks includes a communications processor configured to receive a collection of data from a local system  and a transceiver in communication with the communications processor. The transceiver is configured to transmit and receive data over a network according to a plurality of communication parameters. The communications processor is configured to divide the collection of data into a plurality of data streams; assign a priority level to each of the respective data streams  where the priority level reflects the criticality of the respective data stream; and modify a communication parameter of at least one of the plurality of data streams according to the priority of the at least one data stream.Optical receiving system based on a compound parabolic concentrator and a hemispherical lens for visible light communication.PubMedWang  Yun; Lan  Tian; Ni  Guoqiang2016-12-20We propose a scheme for designing a new optical receiving system that can reduce the received-energy spot size via integration of a compound parabolic concentrator with a hemispherical lens. SolidWorks is used to model the receiving system  while TracePro is employed for simulations. The field of view is set to 30Â° and the radius of the compound parabolic concentrator outlet is 5 mm  which is also the radius of the hemispherical lens. Ray-tracing results show that under the given simulation conditions  the radius of the spot area is reduced from 5 to 3 mm at the receiving system and the gain is 5.2. In regard to the relations between received power and the radius of the hemispherical lens R  and the received power and the distance d between the compound parabolic concentrator and hemispherical lens  our detailed analysis yields the following characteristics: (1) the received power increases as R increases  but decreases as d increases; (2) as R increases  the spot area increases and the received flux is dispersed over the receiving plane  which dispersion is disadvantageous for high-speed communication; (3) the gain of the receiving system also varies with R and d; (4) an increase in d leads to decrease in the received flux and gain when d>-2â€‰â€‰mm. Based on these characteristics  we set R=5â€‰â€‰mm and calculate the energy efficiency. We obtain maximum energy efficiencies for different detection areas.Three Corner Sat Communications SystemNASA Technical Reports Server (NTRS)Anderson  Bobby; Horan  Stephen2000-01-01Three Corner Satellite is a constellation of three nanosatellites designed and built by students. New Mexico State University has taken on the design of the communications system for this constellation. The system includes the forward link  return link  and the crosslink. Due to size  mass  power  and financial constraints  we must design a small  light  power efficient  and inexpensive communications system. This thesis presents the design of a radio system to accomplish the data transmission requirements in light of the system constraints. In addition to the hardware design  the operational commands needed by the satellite's on-board computer to control and communicate with the communications hardware will be presented. In order for the hardware to communicate with the ground stations  we will examine the link budgets derived from the radiated power of the transmitters  link distance  data modulation  and data rate for each link. The antenna design for the constellation is analyzed using software and testing the physical antennas on a model satellite. After the analysis and testing  a combination of different systems will meet and exceed the requirements and constraints of the Three Corner Satellite constellation.Natural light illumination system.PubMedWhang  Allen Jong-Woei; Chen  Yi-Yung; Yang  Shu-Hua; Pan  Po-Hsuan; Chou  Kao-Hsu; Lee  Yu-Chi; Lee  Zong-Yi; Chen  Chi-An; Chen  Cheng-Nan2010-12-10In recent years  green energy has undergone a lot of development and has been the subject of many applications. Many research studies have focused on illumination with sunlight as a means of saving energy and creating healthy lighting. Natural light illumination systems have collecting  transmitting  and lighting elements. Today  most daylight collectors use dynamic concentrators; these include Sun tracking systems. However  this design is too expensive to be cost effective. To create a low-cost collector that can be easily installed on a large building  we have designed a static concentrator  which is prismatic and cascadable  to collect sunlight for indoor illumination. The transmission component uses a large number of optical fibers. Because optical fibers are expensive  this means that most of the cost for the system will be related to transmission. In this paper  we also use a prismatic structure to design an optical coupler for coupling n to 1. With the n-to-1 coupler  the number of optical fibers necessary can be greatly reduced. Although this new natural light illumination system can effectively guide collected sunlight and send it to the basement or to other indoor places for healthy lighting  previously there has been no way to manage the collected sunlight when lighting was not desired. To solve this problem  we have designed an optical switch and a beam splitter to control and separate the transmitted light. When replacing traditional sources  the lighting should have similar characteristics  such as intensity distribution and geometric parameters  to those of traditional artificial sources. We have designed  simulated  and optimized an illumination lightpipe with a dot pattern to redistribute the collected sunlight from the natural light illumination system such that it equals the qualities of a traditional lighting system. We also provide an active lighting module that provides lighting from the natural light illumination system or LED auxiliaryPerformance Analysis of Visible Light Communication Using CMOS Sensors.PubMedDo  Trong-Hop; Yoo  Myungsik2016-02-29This paper elucidates the fundamentals of visible light communication systems that use the rolling shutter mechanism of CMOS sensors. All related information involving different subjects  such as photometry  camera operation  photography and image processing  are studied in tandem to explain the system. Then  the system performance is analyzed with respect to signal quality and data rate. To this end  a measure of signal quality  the signal to interference plus noise ratio (SINR)  is formulated. Finally  a simulation is conducted to verify the analysis.Communication system modelingNASA Technical Reports Server (NTRS)Holland  L. D.; Walsh  J. R.  Jr.; Wetherington  R. D.1971-01-01This report presents the results of work on communications systems modeling and covers three different areas of modeling. The first of these deals with the modeling of signals in communication systems in the frequency domain and the calculation of spectra for various modulations. These techniques are applied in determining the frequency spectra produced by a unified carrier system  the down-link portion of the Command and Communications System (CCS). The second modeling area covers the modeling of portions of a communication system on a block basis. A detailed analysis and modeling effort based on control theory is presented along with its application to modeling of the automatic frequency control system of an FM transmitter. A third topic discussed is a method for approximate modeling of stiff systems using state variable techniques.Satellite communications system 'Tyulpan'NASA Astrophysics Data System (ADS)Tchuyan  R. K.; Tarasov  E. V.; Belousov  A. P.; Balyk  V. M.; Kovtunenko  V. M.; Morozov  V. A.; Andreev  V. A.; v'yunenko  K. A.1993-10-01A concept of the satellite communication system called 'Tyulpan' (because or its tulip-resembling shape) is considered. This conception envisages the use of six satellites-retranslators installed on high-latitude elliptic orbits. Such a system can provide the communication for mean- and high-latitude region of Europe  Asia  and America. For the communication  super small ground stations of 0.4 m in diameter can be used. In the development of system conception  the already existing technical solutions and possibility of conversion or existing installations of military destination were taken into account. Therefore  the system considered can be realized at the earliest possible date.4.5-Gb/s RGB-LED based WDM visible light communication system employing CAP modulation and RLS based adaptive equalization.PubMedWang  Yiguang; Huang  Xingxing; Tao  Li; Shi  Jianyang; Chi  Nan2015-05-18Inter-symbol interference (ISI) is one of the key problems that seriously limit transmission data rate in high-speed VLC systems. To eliminate ISI and further improve the system performance  series of equalization schemes have been widely investigated. As an adaptive algorithm commonly used in wireless communication  RLS is also suitable for visible light communication due to its quick convergence and better performance. In this paper  for the first time we experimentally demonstrate a high-speed RGB-LED based WDM VLC system employing carrier-less amplitude and phase (CAP) modulation and recursive least square (RLS) based adaptive equalization. An aggregate data rate of 4.5Gb/s is successfully achieved over 1.5-m indoor free space transmission with the bit error rate (BER) below the 7% forward error correction (FEC) limit of 3.8x10(-3). To the best of our knowledge  this is the highest data rate ever achieved in RGB-LED based VLC systems.An experimental distribution of analog and digital information in a hybrid wireless visible light communication system based on acousto-optic modulation and sinusoidal gratingsNASA Astrophysics Data System (ADS)GÃ³mez ColÃ­n  R.; GarcÃ­a JuÃ¡rez  A.; ZaldÃ­var Huerta  I. E.; Marquina  A. Vera; GarcÃ­a Delgado  L. A.; Leal Cruz  A. L.; GÃ³mez Fuentes  R.2016-03-01In this paper we propose a photonic architecture as an alternative tool to distribute point to multipoint analog and digital information over a hybrid wireless visible optical communication system. The experimental set-up is composed of a red laser pointer  an acousto-optic modulator  a sinusoidal grating and a photo-detector array. By using a simple and variable interferometric system  diffraction gratings with different spatial frequencies are generated and recorded on a photoemulsion which is composed of vanilla with dichromate gelatin. Analog video and digital information are first transmitted and recovered over a wireless communication system using a microwave carrier at 4.52 GHz which is generated by distributed feedback lasers operating in the low laser threshold current region. Separately  the recovered video information and digital data are combined with a radio frequency signal of 80 MHz  obtaining a subcarrier of information that is imposed on the optical carrier of the pointer laser using an acousto-optic modulator which is operated with an angle of incident light that satisfies the Bragg condition. The modulated optical carrier is sent to a sinusoidal grating  the diffraction pattern is photo-detected using an array of PIN photo-detectors. The use of sinusoidal gratings with acousto-optic modulators allows that number of channels to be increased when both components are placed in cascade.AMPA experimental communications systemsNASA Technical Reports Server (NTRS)Beckerman  D.; Fass  S.; Keon  T.; Sielman  P.1982-01-01The program was conducted to demonstrate the satellite communication advantages of Adaptive Phased Array Technology. A laboratory based experiment was designed and implemented to demonstrate a low earth orbit satellite communications system. Using a 32 element  L-band phased array augmented with 4 sets of weights (2 for reception and 2 for transmission) a high speed digital processing system and operating against multiple user terminals and interferers  the AMPA system demonstrated: communications with austere user terminals  frequency reuse  communications in the face of interference  and geolocation. The program and experiment objectives are described  the system hardware and software/firmware are defined  and the test performed and the resultant test data are presented.Combined peak-to-average power ratio reduction and physical layer security enhancement in optical orthogonal frequency division multiplexing visible-light communication systemsNASA Astrophysics Data System (ADS)Wang  Zhongpeng; Chen  Shoufa2016-07-01A physical encryption scheme for discrete Hartley transform (DHT) precoded orthogonal frequency division multiplexing (OFDM) visible-light communication (VLC) systems using frequency domain chaos scrambling is proposed. In the scheme  the chaos scrambling  which is generated by a modified logistic mapping  is utilized to enhance the physical layer of security  and the DHT precoding is employed to reduce of OFDM signal for OFDM-based VLC. The influence of chaos scrambling on peak-to-average power ratio (PAPR) and bit error rate (BER) of systems is studied. The experimental simulation results prove the efficiency of the proposed encryption method for DHT-precoded  OFDM-based VLC systems. Furthermore  the influence of the proposed encryption to the PAPR and BER of systems is evaluated. The experimental results show that the proposed security scheme can protect the DHT-precoded  OFDM-based VLC from eavesdroppers  while keeping the good BER performance of DHT-precoded systems. The BER performance of the encrypted and DHT-precoded system is almost the same as that of the conventional DHT-precoded system without encryption.Performance improvement by orthogonal pulse amplitude modulation and discrete multitone modulation signals in hybrid fiber-visible laser light communication systemNASA Astrophysics Data System (ADS)Zhang  Fangliu; He  Jing; Deng  Rui; Chen  Qinghui; Chen  Lin2016-10-01A modulation format  orthogonal pulse amplitude modulation and discrete multitone modulation (O-PAM-DMT)  is experimentally demonstrated in a hybrid fiber-visible laser light communication (fiber-VLLC) system using a cost-effective directly modulated laser and blue laser diode. In addition  low overhead is achieved by utilizing only one training sequence to implement synchronization and channel estimation. Through adjusting the ratio of PAM and DMT signal  three types of O-PAM-DMT signals are investigated. After transmission over a 20-km standard single-mode fiber and 5-m free-space VLLC  the receiver sensitivity for 4.36-Gbit/s O-PAM-DMT signals can be improved by 0.4  1.4  and 2.7 dB  respectively  at a bit error rate of 1Ã—10-3  compared with a conventional DMT signal.Violet Laser Diode Enables Lighting Communication.PubMedChi  Yu-Chieh; Huang  Yu-Fang; Wu  Tsai-Chen; Tsai  Cheng-Ting; Chen  Li-Yin; Kuo  Hao-Chung; Lin  Gong-Ru2017-09-05Violet laser diode (VLD) based white-light source with high color rendering index (CRI) for lighting communication is implemented by covering with Y 3 Al 5 O 12 :Ce 3+ (YAG:Ce) or Lu 3 Al 5 O 12 :Ce 3+ /CaAlSiN 3 :Eu 2+ (LuAG:Ce/CASN:Eu) phosphorous diffuser plates. After passing the beam of VLD biased at 70â€‰mA (~2I th ) through the YAG:Ce phosphorous diffuser  a daylight with a correlated color temperature (CCT) of 5068â€‰K and a CRI of 65 is acquired to provide a forward error correction (FEC) certified data rate of 4.4 Gbit/s. By using the VLD biased at 122â€‰mA (~3.5I th ) to excite the LuAG:Ce/CASN:Eu phosphorous diffuser with 0.85-mm thickness  a warm white-light source with a CCT of 2700â€‰K and a CRI of 87.9 is obtained at a cost of decreasing transmission capacity to 2.4 Gbit/s. Thinning the phosphor thickness to 0.75 mm effectively reduces the required bias current by 32â€‰mA to achieve the same CCT for the delivered white light  which offers an enlarged CRI of 89.1 and an increased data rate of 4.4 Gbit/s. Further enlarging the bias current to 105â€‰mA remains the white-light transmission capacity at 4.4 Gbit/s but reveals an increased CCT of 3023â€‰K and an upgraded CRI of 91.5.Pupillary efficient lighting systemDOEpatentsBerman  Samuel M.; Jewett  Don L.1991-01-01A lighting system having at least two independent lighting subsystems each with a different ratio of scotopic illumination to photopic illumination. The radiant energy in the visible region of the spectrum of the lighting subsystems can be adjusted relative to each other so that the total scotopic illumination of the combined system and the total photopic illumination of the combined system can be varied independently. The dilation or contraction of the pupil of an eye is controlled by the level of scotopic illumination and because the scotopic and photopic illumination can be separately controlled  the system allows the pupil size to be varied independently of the level of photopic illumination. Hence  the vision process can be improved for a given level of photopic illumination.Improving Communications SystemsNASA Technical Reports Server (NTRS)1997-01-01The Space Shuttle has many communications systems which are used throughout a typical mission. Given that the radio spectrum has become increasingly congested  the ability to hear extremely weak signals requires greater receiver sensitivity. Dryden Flight Research Center approached Angle Linear  a manufacturer of linear radio frequency products and peripherals for communications  to solve the problem. The solution was a receiving preamplifier specially crafted for NASA. Communications with the Space Shuttle are now more reliable with Dryden being able to also support local missions without purchasing additional equipment. The work has carried over into the Mir Space Station communication support effort and is under evaluation by other NASA centers. The company's preamplifier line was greatly expanded to cover a broader range of frequencies  providing the same sensational improvement to other areas of communication including business  government  trucking  land mobile  cellular and broadcast.Communication Systems in HealthcarePubMed CentralCoiera  Enrico2006-01-01The care of patients now almost inevitably seems to involve many different individuals  all needing to share patient information and discuss their management. As a consequence there is increasing interest in  and use of  information and communication technologies to support health services. Yet  while there is significant discussion of  and investment in  information technologies  communication systems receive much less attention and the clinical adoption of even simpler services like voice-mail or electronic mail is still not commonplace in many health services. There remain enormous gaps in our broad understanding of the role of communication services in health care delivery. Laboratory medicine is perhaps even more poorly studied than many other areas  such as the interface between primary care and hospital services. Given this lack of specific information about laboratory communication services  this paper will step back and generally review the components of a communication system  including the basic concepts of a communication channel  service  device and interaction mode. The review will then try and summarise some of what is known about specific communication problems that arise across health services in the main  including the community and hospital service delivery. PMID:17077879Digital communication systemNASA Technical Reports Server (NTRS)Monford  L. G.  Jr. (Inventor)1974-01-01A digital communication system is reported for parallel operation of 16 or more transceiver units with the use of only four interconnecting wires. A remote synchronization circuit produces unit address control words sequentially in data frames of 16 words. Means are provided in each transceiver unit to decode calling signals and to transmit calling and data signals. The transceivers communicate with each other over one data line. The synchronization unit communicates the address control information to the transceiver units over an address line and further provides the timing information over a clock line. A reference voltage level or ground line completes the interconnecting four wire hookup.Airborne wireless communication systems  airborne communication methods  and communication methodsDOEpatentsDeaton  Juan D [Menan  ID; Schmitt  Michael J [Idaho Falls  ID; Jones  Warren F [Idaho Falls  ID2011-12-13An airborne wireless communication system includes circuitry configured to access information describing a configuration of a terrestrial wireless communication base station that has become disabled. The terrestrial base station is configured to implement wireless communication between wireless devices located within a geographical area and a network when the terrestrial base station is not disabled. The circuitry is further configured  based on the information  to configure the airborne station to have the configuration of the terrestrial base station. An airborne communication method includes answering a 911 call from a terrestrial cellular wireless phone using an airborne wireless communication system.Performance Analysis of Visible Light Communication Using CMOS SensorsPubMed CentralDo  Trong-Hop; Yoo  Myungsik2016-01-01This paper elucidates the fundamentals of visible light communication systems that use the rolling shutter mechanism of CMOS sensors. All related information involving different subjects  such as photometry  camera operation  photography and image processing  are studied in tandem to explain the system. Then  the system performance is analyzed with respect to signal quality and data rate. To this end  a measure of signal quality  the signal to interference plus noise ratio (SINR)  is formulated. Finally  a simulation is conducted to verify the analysis. PMID:26938535Communication Systems. Laboratory Activities.ERIC Educational Resources Information CenterSutherland  Barbara  Ed.This communication systems guide provides teachers with learning activities for secondary students. Introductory materials include an instructional planning outline and worksheet  an outline of essential elements  a list of objectives  a course description  and a content outline. The guide contains 32 modules on the following topics: storyâ€¦Modulation selection for visible light communications using lighting LEDsNASA Astrophysics Data System (ADS)Siuzdak  Jerzy2015-09-01The paper analyzes suitability of various spectrally efficient modulations (PAM  CAP  OFDM/DMT) in a VLC system using lighting LEDs as a transmitter. Although under ideal conditions all modulation have similar efficiency i.e. they produce similar throughputs with a given BER  their practical performances are different. For example  the level of nonlinear distortions generated by each modulation is the least for PAM and by far the greatest for OFDM/DMT locating CAP in the middle. The suitability of various OFDM/DMT variants in a VLC LED link was also analyzed proving that the asymmetrically clipped (ACO) OFDM has a worse performance as compared with DC biased (DCO) OFDM.Low-complexity peak-to-average power ratio reduction scheme for flip-orthogonal frequency division multiplexing visible light communication system based on Î¼-law mappingNASA Astrophysics Data System (ADS)Wang  Jianping; Zhang  Peiran; Lu  Huimin; Feng  LiFang2017-06-01An orthogonal frequency division multiplexing (OFDM) technique called flipped OFDM (flip-OFDM) is apposite for a visible light communication system that needs the transmitted signal to be real and positive. Flip-OFDM uses two consecutive OFDM subframes to transmit the positive and negative parts of the signal. However  peak-to-average power ratio (PAPR) for flip-OFDM is increased tremendously due to the low value of total average power that arises from many zero values in both the positive and flipped frames. We first analyze the performance of flip-OFDM and perform a comparison with the conventional DC-biased OFDM (DCO-OFDM); then we propose a flip-OFDM scheme combined with Î¼-law mapping to reduce the high PAPR. The simulation results show that the PAPR of the system is reduced about 17.2 and 5.9 dB when compared with the normal flip-OFDM and DCO-OFDM signals  respectively.Sources of background light on space based laser communications linksNASA Astrophysics Data System (ADS)Farrell  Thomas C.2018-05-01We discuss the sources and levels of background light that should be expected on space based laser communication (lasercom) crosslinks and uplinks  as well as on downlinks to ground stations. The analyses are valid for both Earth orbiting satellites and inter-planetary links. Fundamental equations are derived suitable for first order system engineering analyses of potential lasercom systems. These divide sources of background light into two general categories: extended sources which fill the field of view of a receiver's optics  and point sources which cannot be resolved by the optics. Specific sources of background light are discussed  and expected power levels are estimated. For uplinks  reflected sunlight and blackbody radiation from the Earth dominates. For crosslinks  depending on specific link geometry  sources of background light may include the Sun in the field of view (FOV)  reflected sunlight and blackbody radiation from planets and other bodies in the solar system  individual bright stars in the FOV  the amalgam of dim stars in the FOV  zodiacal light  and reflected sunlight off of the transmitting spacecraft. For downlinks  all of these potentially come into play  and the effects of the atmosphere  including turbulence  scattering  and absorption contribute as well. Methods for accounting for each of these are presented. Specific examples are presented to illustrate the relative contributions of each source for various link geometries.Peak-to-average power ratio reduction in orthogonal frequency division multiplexing-based visible light communication systems using a modified partial transmit sequence techniqueNASA Astrophysics Data System (ADS)Liu  Yan; Deng  Honggui; Ren  Shuang; Tang  Chengying; Qian  Xuewen2018-01-01We propose an efficient partial transmit sequence technique based on genetic algorithm and peak-value optimization algorithm (GAPOA) to reduce high peak-to-average power ratio (PAPR) in visible light communication systems based on orthogonal frequency division multiplexing (VLC-OFDM). By analysis of hill-climbing algorithm's pros and cons  we propose the POA with excellent local search ability to further process the signals whose PAPR is still over the threshold after processed by genetic algorithm (GA). To verify the effectiveness of the proposed technique and algorithm  we evaluate the PAPR performance and the bit error rate (BER) performance and compare them with partial transmit sequence (PTS) technique based on GA (GA-PTS)  PTS technique based on genetic and hill-climbing algorithm (GH-PTS)  and PTS based on shuffled frog leaping algorithm and hill-climbing algorithm (SFLAHC-PTS). The results show that our technique and algorithm have not only better PAPR performance but also lower computational complexity and BER than GA-PTS  GH-PTS  and SFLAHC-PTS technique.Wireless Headset Communication SystemNASA Technical Reports Server (NTRS)Lau  Wilfred K.; Swanson  Richard; Christensen  Kurt K.1995-01-01System combines features of pagers  walkie-talkies  and cordless telephones. Wireless headset communication system uses digital modulation on spread spectrum to avoid interference among units. Consists of base station  4 radio/antenna modules  and as many as 16 remote units with headsets. Base station serves as network controller  audio-mixing network  and interface to such outside services as computers  telephone networks  and other base stations. Developed for use at Kennedy Space Center  system also useful in industrial maintenance  emergency operations  construction  and airport operations. Also  digital capabilities exploited; by adding bar-code readers for use in taking inventories.Optimization lighting layout based on gene density improved genetic algorithm for indoor visible light communicationsNASA Astrophysics Data System (ADS)Liu  Huanlin; Wang  Xin; Chen  Yong; Kong  Deqian; Xia  Peijie2017-05-01For indoor visible light communication system  the layout of LED lamps affects the uniformity of the received power on communication plane. In order to find an optimized lighting layout that meets both the lighting needs and communication needs  a gene density genetic algorithm (GDGA) is proposed. In GDGA  a gene indicates a pair of abscissa and ordinate of a LED  and an individual represents a LED layout in the room. The segmented crossover operation and gene mutation strategy based on gene density are put forward to make the received power on communication plane more uniform and increase the population's diversity. A weighted differences function between individuals is designed as the fitness function of GDGA for reserving the population having the useful LED layout genetic information and ensuring the global convergence of GDGA. Comparing square layout and circular layout  with the optimized layout achieved by the GDGA  the power uniformity increases by 83.3%  83.1% and 55.4%  respectively. Furthermore  the convergence of GDGA is verified compared with evolutionary algorithm (EA). Experimental results show that GDGA can quickly find an approximation of optimal layout.Continuous zoom antenna for mobile visible light communication.PubMedZhang  Xuebin; Tang  Yi; Cui  Lu; Bai  Tingzhu2015-11-10In this paper  we design a continuous zoom antenna for mobile visible light communication (VLC). In the design  a right-angle reflecting prism was adopted to fold the space optical path  thus decreasing the antenna thickness. The surface of each lens in the antenna is spherical  and the system cost is relatively low. Simulation results indicated that the designed system achieved the following performance: zoom ratio of 2.44  field of view (FOV) range of 18Â°-48Â°  system gain of 16.8  and system size of 18 mmÃ—6â€‰â€‰mm. Finally  we established an indoor VLC system model in a room the size of 5â€‰â€‰m Ã—5â€‰â€‰m Ã—3â€‰â€‰m and compared the detection results of the zoom antenna and fixed-focus antenna obtained in a multisource communication environment  a mobile VLC environment  and a multiple-input multiple-output communication environment. The simulation results indicated that the continuous zoom antenna could realize large FOV and high gain. Moreover  the system showed improved stability  mobility  and environmental applicability.Cyber Security for Lighting SystemsSciTech ConnectNoneFact sheet discusses cyber threats unique to lighting control systems in buildings and helps facility managers identify the types of lighting control systems that could introduce cybersecurity risks. Download the fact sheet.Inductive Communication System Design SummaryDOT National Transportation Integrated Search1978-09-01The report documents the experience obtained during the design and development of the Inductive Communications System used in the Morgantown People Mover. The Inductive Communications System is used to provide wayside-to-vehicle and vehicle-to-waysid...Engineering quantum communication systemsNASA Astrophysics Data System (ADS)Pinto  Armando N.; Almeida  Ãlvaro J.; Silva  Nuno A.; Muga  Nelson J.; Martins  Luis M.2012-06-01Quantum communications can provide almost perfect security through the use of quantum laws to detect any possible leak of information. We discuss critical issues in the implementation of quantum communication systems over installed optical fibers. We use stimulated four-wave mixing to generate single photons inside optical fibers  and by tuning the separation between the pump and the signal we adjust the average number of photons per pulse. We report measurements of the source statistics and show that it goes from a thermal to Poisson distribution with the increase of the pump power. We generate entangled photons pairs through spontaneous four-wave mixing. We report results for different type of fibers to approach the maximum value of the Bell inequality. We model the impact of polarization rotation  attenuation and Raman scattering and present optimum configurations to increase the degree of entanglement. We encode information in the photons polarization and assess the use of wavelength and time division multiplexing based control systems to compensate for the random rotation of the polarization during transmission. We show that time division multiplexing systems provide a more robust solution considering the values of PMD of nowadays installed fibers. We evaluate the impact on the quantum channel of co-propagating classical channels  and present guidelines for adding quantum channels to installed WDM optical communication systems without strongly penalizing the performance of the quantum channel. We discuss the process of retrieving information from the photons polarization. We identify the major impairments that limit the speed and distance of the quantum channel. Finally  we model theoretically the QBER and present results of an experimental performance assessment of the system quality through QBER measurements.Visible light communication technology for fine-grained indoor localizationNASA Astrophysics Data System (ADS)Vieira  M.; Vieira  M. A.; Louro  P.; Fantoni  A.; Vieira  P.2018-02-01This paper focuses on designing and analysing a visible light based communication and positioning system. The indoor positioning system uses trichromatic white Light Emitting Diodes (LEDs)  both for illumination purposes and as transmitters  and an optical processor  based on a-SiC:H technology  as mobile receiver. On-Off Keying (OOK) modulation scheme is used  proving a good trade-off between system performance and implementation complexity. In the following  the relationship between the transmitted data and the received output levels is decoded. LED bulbs work as transmitters  sending information together with different identifiers  IDs  related to their physical locations. Square and diamond topologies for the unit cell are analyzed  and a 2D localization design  demonstrated by a prototype implementation  is presented. Fine-grained indoor localization is tested. The received signal is used in coded multiplexing techniques for supporting communications and navigation concomitantly on the same channel. The location and motion information is found by mapping the position and estimating the location areas.Wireless Computers: Radio and Light Communications May Bring New Freedom to Computing.ERIC Educational Resources Information CenterHartmann  Thom1984-01-01Describes systems which use wireless terminals to communicate with mainframe computers or minicomputers via radio band  discusses their limitations  and gives examples of networks using such systems. The use of communications satellites to increase their range and the possibility of using light beams to transmit data are also discussed. (MBR)Network coding multiuser scheme for indoor visible light communicationsNASA Astrophysics Data System (ADS)Zhang  Jiankun; Dang  Anhong2017-12-01Visible light communication (VLC) is a unique alternative for indoor data transfer and developing beyond point-to-point. However  for realizing high-capacity networks  VLC is facing challenges including the constrained bandwidth of the optical access point and random occlusion. A network coding scheme for VLC (NC-VLC) is proposed  with increased throughput and system robustness. Based on the Lambertian illumination model  theoretical decoding failure probability of the multiuser NC-VLC system is derived  and the impact of the system parameters on the performance is analyzed. Experiments demonstrate the proposed scheme successfully in the indoor multiuser scenario. These results indicate that the NC-VLC system shows a good performance under the link loss and random occlusion.Visible light communication based vehicle positioning using LED street light and rolling shutter CMOS sensorsNASA Astrophysics Data System (ADS)Do  Trong Hop; Yoo  Myungsik2018-01-01This paper proposes a vehicle positioning system using LED street lights and two rolling shutter CMOS sensor cameras. In this system  identification codes for the LED street lights are transmitted to camera-equipped vehicles through a visible light communication (VLC) channel. Given that the camera parameters are known  the positions of the vehicles are determined based on the geometric relationship between the coordinates of the LEDs in the images and their real world coordinates  which are obtained through the LED identification codes. The main contributions of the paper are twofold. First  the collinear arrangement of the LED street lights makes traditional camera-based positioning algorithms fail to determine the position of the vehicles. In this paper  an algorithm is proposed to fuse data received from the two cameras attached to the vehicles in order to solve the collinearity problem of the LEDs. Second  the rolling shutter mechanism of the CMOS sensors combined with the movement of the vehicles creates image artifacts that may severely degrade the positioning accuracy. This paper also proposes a method to compensate for the rolling shutter artifact  and a high positioning accuracy can be achieved even when the vehicle is moving at high speeds. The performance of the proposed positioning system corresponding to different system parameters is examined by conducting Matlab simulations. Small-scale experiments are also conducted to study the performance of the proposed algorithm in real applications.Lighting system with thermal management systemDOEpatentsArik  Mehmet; Weaver  Stanton Earl; Stecher  Thomas Elliot; Seeley  Charles Erklin; Kuenzler  Glenn Howard; Wolfe  Jr.  Charles Franklin; Utturkar  Yogen Vishwas; Sharma  Rajdeep; Prabhakaran  Satish; Icoz  Tunc2015-02-24Lighting systems having unique configurations are provided. For instance  the lighting system may include a light source  a thermal management system and driver electronics  each contained within a housing structure. The light source is configured to provide illumination visible through an opening in the housing structure. The thermal management system is configured to provide an air flow  such as a unidirectional air flow  through the housing structure in order to cool the light source. The driver electronics are configured to provide power to each of the light source and the thermal management system.Lighting system with thermal management systemDOEpatentsArik  Mehmet; Weaver  Stanton Earl; Stecher  Thomas Elliot; Seeley  Charles Erklin; Kuenzler  Glenn Howard; Wolfe  Jr.  Charles Franklin; Utturkar  Yogen Vishwas; Sharma  Rajdeep; Prabhakaran  Satish; Icoz  Tunc2015-08-25Lighting systems having unique configurations are provided. For instance  the lighting system may include a light source  a thermal management system and driver electronics  each contained within a housing structure. The light source is configured to provide illumination visible through an opening in the housing structure. The thermal management system is configured to provide an air flow  such as a unidirectional air flow  through the housing structure in order to cool the light source. The driver electronics are configured to provide power to each of the light source and the thermal management system.Lighting system with thermal management systemDOEpatentsArik  Mehmet; Weaver  Stanton; Stecher  Thomas; Seeley  Charles; Kuenzler  Glenn; Wolfe  Jr.  Charles; Utturkar  Yogen; Sharma  Rajdeep; Prabhakaran  Satish; Icoz  Tunc2013-05-07Lighting systems having unique configurations are provided. For instance  the lighting system may include a light source  a thermal management system and driver electronics  each contained within a housing structure. The light source is configured to provide illumination visible through an opening in the housing structure. The thermal management system is configured to provide an air flow  such as a unidirectional air flow  through the housing structure in order to cool the light source. The driver electronics are configured to provide power to each of the light source and the thermal management system.Lighting system with thermal management systemDOEpatentsArik  Mehmet; Weaver  Stanton Earl; Stecher  Thomas Elliot; Seeley  Charles Erklin; Kuenzler  Glenn Howard; Wolfe  Jr  Charles Franklin; Utturkar  Yogen Vishwas; Sharma  Rajdeep; Prabhakaran  Satish; Icoz  Tunc2016-10-11Lighting systems having unique configurations are provided. For instance  the lighting system may include a light source  a thermal management system and driver electronics  each contained within a housing structure. The light source is configured to provide illumination visible through an opening in the housing structure. The thermal management system is configured to provide an air flow  such as a unidirectional air flow  through the housing structure in order to cool the light source. The driver electronics are configured to provide power to each of the light source and the thermal management system.A comparative study of optical concentrators for visible light communicationsNASA Astrophysics Data System (ADS)Mulyawan  Rahmat; Gomez  Ariel; Chun  Hyunchae; Rajbhandari  Sujan; Manousiadis  Pavlos P.; Vithanage  Dimali A.; Faulkner  Grahame; Turnbull  Graham A.; Samuel  Ifor D. W.; Collins  Stephen; O'Brien  Dominic2017-01-01Given the imminent radio frequency spectrum crunch  Visible Light Communication (VLC) is being proposed as an alternative wireless technology allowing for scalable connectivity to potentially millions of mobile and Internet-of- Things (IoT) devices. A VLC system uses a photo-detector (PD) receiver that converts the optically modulated light from a light source into a modulated electrical signal. The corresponding receiver electrical bandwidth is typically inversely proportional to the PD active area. Consequently  to construct a high-speed VLC link  the PD active area is often substantially reduced and an optical concentrator is used to enhance the receiver collection area. However  to achieve high concentrating factor  the link field-of-view (FOV) needs to be narrow due to the Ã©tendue conservation in linear passive optical systems. This paper studies a Fluorescent Concentrator (FC) that breaks this Ã©tendue conservation. The FC is not only based on reflective and refractive principles but also makes use of fluorescence process. A comparison between the FC and conventional optical concentrators  namely Compound Parabolic Concentrator (CPC) is also investigated. The trade-off between received signal strength and incoming link angle is demonstrated over 60Â° coverage. Experimental results show that performance degradation as the link angle increases using FC-based receivers is significantly lower than for conventional CPC.Digital and analog communication systemsNASA Technical Reports Server (NTRS)Shanmugam  K. S.1979-01-01The book presents an introductory treatment of digital and analog communication systems with emphasis on digital systems. Attention is given to the following topics: systems and signal analysis  random signal theory  information and channel capacity  baseband data transmission  analog signal transmission  noise in analog communication systems  digital carrier modulation schemes  error control coding  and the digital transmission of analog signals.Information Systems and Business Communication.ERIC Educational Resources Information CenterBeswick  Raymond W.  Ed.; Williams  Alfred B.  Ed.Intended to provide orientation about the integration of business communication  business systems  and the researching and teaching of business communication  this books offers articles on a variety of topics concerning business communication. Titles of the articles and their authors are as follows: (1) ""Office Technology: Voice Store-and-Forward""â€¦Communications systems checkout studyNASA Technical Reports Server (NTRS)Ginter  W. G.1972-01-01The results and conclusions of an engineering study of Space Station communications subsystem checkout are reported. The primary purpose of the study is to recommend specific guidelines and constraints for the design and utilization of the communications subsystem leading to a practical and effective means of onboard checkout implementation. Major study objectives are as follows: (1) identify candidate communications subsystem checkout concepts  (2) determine implementation impacts of feasible concepts  (3) evaluate practicality and effectiveness of alternative concepts  (4) propose baseline modifications to accommodate preferred concepts  and (5) recommend areas for additional investigation. In addition  study results are interpreted  where appropriate  in terms of their applicability to checkout of Shuttle-Orbiter communications subsystem.INMARSAT's personal communicator systemNASA Astrophysics Data System (ADS)Hart  Nick; Haugli  Hans-C.; Poskett  Peter; Smith  K.Inmarsat has been providing near global mobile satellite communications since 1982 and Inmarsat terminals are currently being used in more than 130 countries. The terminals have been reduced in size and cost over the years and new technology has enabled the recent introduction of briefcase sized personal telephony terminals (Inmarsat-M). This trend continues and we are likely to see Inmarsat handheld terminals by the end of the decade. These terminals are called Inmarsat-P and this paper focuses on the various elements required to support a high quality service to handheld terminals. The main system elements are: the handheld terminals; the space segment with the associated orbits; and the gateways to terrestrial networks. It is both likely and desirable that personal handheld satellite communications will be offered by more than one system provider and this competition will ensure strong emphasis on service quality and cost of ownership. The handheld terminals also have to be attractive to a large number of potential users  and this means that the terminals must be small enough to fit in a pocket. Battery lifetime is another important consideration  and this coupled with radiation safety requirements limits the maximum radiated EIRP. The terminal G/T is mainly constrained by the gain of the omnidirectional antenna and the noise figure of the RF front end (including input losses). Inmarsat has examined  with the support of industry  a number of Geosynchronous (GSO)  Medium Earth Orbit (MEO) and Low Earth Orbit (LEO) satellite options for the provision of a handheld mobile satellite service. This paper describes the key satellite and orbit parameters and tradeoffs which affect the overall quality of service and the space segment costing. The paper also stresses not only the importance of using and sharing the available mobile frequency band allocations efficiently  but also the key considerations affecting the choice of feeder link bands. The design of the gatewaysINMARSAT's personal communicator systemNASA Technical Reports Server (NTRS)Hart  Nick; Haugli  HANS-C.; Poskett  Peter; Smith  K.1993-01-01Inmarsat has been providing near global mobile satellite communications since 1982 and Inmarsat terminals are currently being used in more than 130 countries. The terminals have been reduced in size and cost over the years and new technology has enabled the recent introduction of briefcase sized personal telephony terminals (Inmarsat-M). This trend continues and we are likely to see Inmarsat handheld terminals by the end of the decade. These terminals are called Inmarsat-P and this paper focuses on the various elements required to support a high quality service to handheld terminals. The main system elements are: the handheld terminals; the space segment with the associated orbits; and the gateways to terrestrial networks. It is both likely and desirable that personal handheld satellite communications will be offered by more than one system provider and this competition will ensure strong emphasis on service quality and cost of ownership. The handheld terminals also have to be attractive to a large number of potential users  and this means that the terminals must be small enough to fit in a pocket. Battery lifetime is another important consideration  and this coupled with radiation safety requirements limits the maximum radiated EIRP. The terminal G/T is mainly constrained by the gain of the omnidirectional antenna and the noise figure of the RF front end (including input losses). Inmarsat has examined  with the support of industry  a number of Geosynchronous (GSO)  Medium Earth Orbit (MEO) and Low Earth Orbit (LEO) satellite options for the provision of a handheld mobile satellite service. This paper describes the key satellite and orbit parameters and tradeoffs which affect the overall quality of service and the space segment costing. The paper also stresses not only the importance of using and sharing the available mobile frequency band allocations efficiently  but also the key considerations affecting the choice of feeder link bands. The design of the gatewaysLight Emitting Diodes for Fiber Optic Communications.DTIC Science & Technology1981-03-31asC.3~~ in.(c)- above and do- (1) pcait by volu.3 of dicst.iLle =zto.- Pazo 10 .61Edd  tcxcopt colvonts used cha-l bo: * ( a ) Methyl. alcohbl I7or 04...AD Â£101 480 LASER DIODE LABS INC NEW BRUNSWICK NJ / 1 / L I GT EMITTING DIODES FOR FIBER OPTIC COWMICATIONS.Cul AR  at A GENNARO DAARO-76-C-813 NA 1...PRArrcmA. P . 1""UNISPE-D TO DDC CONTAINE A II&~-’llryBE v.  R OF :AO   MflG DO 9W CORADCOM U S ARMY COMMUNICATIONS RESEARCH 9 DEVELOPMENT COMMANDNew computer and communications environments for light armored vehiclesNASA Astrophysics Data System (ADS)Rapanotti  John L.; Palmarini  Marc; Dumont  Marc2002-08-01Light Armoured Vehicles (LAVs) are being developed to meet the modern requirements of rapid deployment and operations other than war. To achieve these requirements  passive armour is minimized and survivability depends more on sensors  computers and countermeasures to detect and avoid threats. The performance  reliability  and ultimately the cost of these components  will be determined by the trends in computing and communications. These trends and the potential impact on DAS (Defensive Aids Suite) development were investigated and are reported in this paper. Vehicle performance is affected by communication with other vehicles and other ISTAR (Intelligence  Surveillance  Target Acquisition and Reconnaissance) battlefield assets. This investigation includes the networking technology Jini developed by SUN Microsystems  which can be used to interface the vehicle to the ISTAR network. VxWorks by Wind River Systems  is a real time operating system designed for military systems and compatible with Jini. Other technologies affecting computer hardware development include  dynamic reconfiguration  hot swap  alternate pathing  CompactPCI  and Fiber Channel serial communication. To achieve the necessary performance at reasonable cost  and over the long service life of the vehicle  a DAS should have two essential features. A fitted for  but not fitted with approach will provide the necessary rapid deployment without a need to equip the entire fleet. With an expected vehicle service life of 50 years  5-year technology upgrades can be used to maintain vehicle performance over the entire service life. A federation of modules instead of integrated fused sensors will provide the capability for incremental upgrades and mission configurability. A plug and play capability can be used for both hardware and expendables.Subcarrier intensity modulation for MIMO visible light communicationsNASA Astrophysics Data System (ADS)Celik  Yasin; Akan  Aydin2018-04-01In this paper  subcarrier intensity modulation (SIM) is investigated for multiple-input multiple-output (MIMO) visible light communication (VLC) systems. A new modulation scheme called DC-aid SIM (DCA-SIM) is proposed for the spatial modulation (SM) transmission plan. Then  DCA-SIM is extended for multiple subcarrier case which is called DC-aid Multiple Subcarrier Modulation (DCA-MSM). Bit error rate (BER) performances of the considered system are analyzed for different MIMO schemes. The power efficiencies of DCA-SIM and DCA-MSM are shown in correlated MIMO VLC channels. The upper bound BER performances of the proposed models are obtained analytically for PSK and QAM modulation types in order to validate the simulation results. Additionally  the effect of power imbalance method on the performance of SIM is studied and remarkable power gains are obtained compared to the non-power imbalanced cases. In this work  Pulse amplitude modulation (PAM) and MSM-Index are used as benchmarks for single carrier and multiple carrier cases  respectively. And the results show that the proposed schemes outperform PAM and MSM-Index for considered single carrier and multiple carrier communication scenarios.Single-chip microprocessor that communicates directly using light.PubMedSun  Chen; Wade  Mark T; Lee  Yunsup; Orcutt  Jason S; Alloatti  Luca; Georgas  Michael S; Waterman  Andrew S; Shainline  Jeffrey M; Avizienis  Rimas R; Lin  Sen; Moss  Benjamin R; Kumar  Rajesh; Pavanello  Fabio; Atabaki  Amir H; Cook  Henry M; Ou  Albert J; Leu  Jonathan C; Chen  Yu-Hsin; AsanoviÄ‡  Krste; Ram  Rajeev J; PopoviÄ‡  MiloÅ¡ A; StojanoviÄ‡  Vladimir M2015-12-24Data transport across short electrical wires is limited by both bandwidth and power density  which creates a performance bottleneck for semiconductor microchips in modern computer systems--from mobile phones to large-scale data centres. These limitations can be overcome by using optical communications based on chip-scale electronic-photonic systems enabled by silicon-based nanophotonic devices. However  combining electronics and photonics on the same chip has proved challenging  owing to microchip manufacturing conflicts between electronics and photonics. Consequently  current electronic-photonic chips are limited to niche manufacturing processes and include only a few optical devices alongside simple circuits. Here we report an electronic-photonic system on a single chip integrating over 70 million transistors and 850 photonic components that work together to provide logic  memory  and interconnect functions. This system is a realization of a microprocessor that uses on-chip photonic devices to directly communicate with other chips using light. To integrate electronics and photonics at the scale of a microprocessor chip  we adopt a 'zero-change' approach to the integration of photonics. Instead of developing a custom process to enable the fabrication of photonics  which would complicate or eliminate the possibility of integration with state-of-the-art transistors at large scale and at high yield  we design optical devices using a standard microelectronics foundry process that is used for modern microprocessors. This demonstration could represent the beginning of an era of chip-scale electronic-photonic systems with the potential to transform computing system architectures  enabling more powerful computers  from network infrastructure to data centres and supercomputers.The Picture Exchange Communication System.PubMedBondy  A; Frost  L2001-10-01The Picture Exchange Communication System (PECS) is an alternative/augmentative communication system that was developed to teach functional communication to children with limited speech. The approach is unique in that it teaches children to initiate communicative interactions within a social framework. This article describes the advantages to implementing PECS over traditional approaches. The PECS training protocol is described wherein children are taught to exchange a single picture for a desired item and eventually to construct picture-based sentences and use a variety of attributes in their requests. The relationship of PECS's implementation to the development of speech in previously nonvocal students is reviewed.Communications device identification methods  communications methods  wireless communications readers  wireless communications systems  and articles of manufactureDOEpatentsSteele  Kerry D [Kennewick  WA; Anderson  Gordon A [Benton City  WA; Gilbert  Ronald W [Morgan Hill  CA2011-02-01Communications device identification methods  communications methods  wireless communications readers  wireless communications systems  and articles of manufacture are described. In one aspect  a communications device identification method includes providing identification information regarding a group of wireless identification devices within a wireless communications range of a reader  using the provided identification information  selecting one of a plurality of different search procedures for identifying unidentified ones of the wireless identification devices within the wireless communications range  and identifying at least some of the unidentified ones of the wireless identification devices using the selected one of the search procedures.Single-chip microprocessor that communicates directly using lightNASA Astrophysics Data System (ADS)Sun  Chen; Wade  Mark T.; Lee  Yunsup; Orcutt  Jason S.; Alloatti  Luca; Georgas  Michael S.; Waterman  Andrew S.; Shainline  Jeffrey M.; Avizienis  Rimas R.; Lin  Sen; Moss  Benjamin R.; Kumar  Rajesh; Pavanello  Fabio; Atabaki  Amir H.; Cook  Henry M.; Ou  Albert J.; Leu  Jonathan C.; Chen  Yu-Hsin; AsanoviÄ‡  Krste; Ram  Rajeev J.; PopoviÄ‡  MiloÅ¡ A.; StojanoviÄ‡  Vladimir M.2015-12-01Data transport across short electrical wires is limited by both bandwidth and power density  which creates a performance bottleneck for semiconductor microchips in modern computer systemsâ€”from mobile phones to large-scale data centres. These limitations can be overcome by using optical communications based on chip-scale electronic-photonic systems enabled by silicon-based nanophotonic devices8. However  combining electronics and photonics on the same chip has proved challenging  owing to microchip manufacturing conflicts between electronics and photonics. Consequently  current electronic-photonic chips are limited to niche manufacturing processes and include only a few optical devices alongside simple circuits. Here we report an electronic-photonic system on a single chip integrating over 70 million transistors and 850 photonic components that work together to provide logic  memory  and interconnect functions. This system is a realization of a microprocessor that uses on-chip photonic devices to directly communicate with other chips using light. To integrate electronics and photonics at the scale of a microprocessor chip  we adopt a â€˜zero-changeâ€™ approach to the integration of photonics. Instead of developing a custom process to enable the fabrication of photonics  which would complicate or eliminate the possibility of integration with state-of-the-art transistors at large scale and at high yield  we design optical devices using a standard microelectronics foundry process that is used for modern microprocessors. This demonstration could represent the beginning of an era of chip-scale electronic-photonic systems with the potential to transform computing system architectures  enabling more powerful computers  from network infrastructure to data centres and supercomputers.Ultramicrowave communications system  phase 3NASA Technical Reports Server (NTRS)1981-01-01The ultramicrowave communications system program investigated the feasibility of a solid state system that meets the projected space to space requirements  while using the advantages of the 100 to 200 GHz band. The program successfully demonstrated a laboratory model of a high frequency communications system operating between 100 to 200 GHz. In the process  vendor claims for performance specifications of discrete components were evaluated  and a window was provided into system design and integration problems.Communication  Work Systems and HRDERIC Educational Resources Information CenterPace  R. Wayne2013-01-01Purpose: The purpose of this article is to show the foundational place that communication theory and its practice occupies in functioning work systems. Design/methodology/approach: This paper defines the word communication in terms of the creation and interpretation of displays  describes what it means to have a theoretical foundation for aâ€¦Using advertisement light-panel and CMOS image sensor with frequency-shift-keying for visible light communication.PubMedChow  Chi-Wai; Shiu  Ruei-Jie; Liu  Yen-Chun; Liao  Xin-Lan; Lin  Kun-Hsien; Wang  Yi-Chang; Chen  Yi-Yuan2018-05-14A frequency-shift-keying (FSK) visible light communication (VLC) system is proposed and demonstrated using advertisement light-panel as transmitter and mobile-phone image sensor as receiver. The developed application program (APP) in mobile-phone can retrieve the rolling shutter effect (RSE) pattern produced by the FSK VLC signal effectively. Here  we also define noise-ratio value (NRV) to evaluate the contrast of different advertisements displayed on the light-panel. Both mobile-phones under test can achieve success rate > 96% even when the transmission distance is up to 200 cm and the NRVs are low.Introduction to Communication SystemsDTIC Science & Technology2013-08-18nonlinear differential equations involved  and to compare the results with the linearized analysis. Nonlinear model for the first order PLL: Let us try to...approaches to scaling up data rates: increasing spatial reuse (i.e.  using the same time -bandwidth resources at locations that are far enough apart)  and... Even when this music is recorded onto a digital storage medium such as a CD ( using the digital communication framework outlined in Section 1.1.2)  whenQuantum Communications SystemsDTIC Science & Technology2012-09-21metrology practical. The strategy was to develop robust photonic quantum states and sensors serving as an archetype for loss-tolerant information...communications and metrology. Our strategy consisted of developing robust photonic quantum states and sensors serving as an archetype for loss-tolerant...developed atomic memories in caesium vapour  based on a stimulated Raman transition  that have demonstrated a TBP greater than 1000 and are uniquely suitedLED-based high-speed visible light communicationsNASA Astrophysics Data System (ADS)Chi  Nan; Shi  Meng; Zhao  Yiheng; Wang  Fumin; Shi  Jianyang; Zhou  Yingjun; Lu  Xingyu; Qiao  Liang2018-01-01We are seeing a growing use of light emitting diodes (LEDs) in a range of applications including lighting  TV and backlight board screen  display etc. In comparison with the traditional incandescent and fluorescent light bulbs  LEDs offer long life-space  much higher energy efficiency  high performance cost ratio and above all very fast switching capability. LED based Visible Light Communications (VLC) is an emerging field of optical communications that focuses on the part of the electromagnetic spectrum that humans can see. Depending on the transmission distance  we can divide the whole optical network into two categories  long haul and short haul. Visible light communication can be a promising candidate for short haul applications. In this paper  we outline the configuration of VLC  its unique benefits  and describe the state of the art research contributions consisting of advanced modulation formats including adaptive bit loading OFDM  carrierless amplitude and phase (CAP)  pulse amplitude modulation (PAM) and single carrier Nyquist  linear equalization and nonlinear distortion mitigation based on machine learning  quasi-balanced coding and phase-shifted Manchester coding. These enabling technologies can support VLC up to 10Gb/s class free space transmission.Survey of Inductive Communication SystemsDOT National Transportation Integrated Search1975-04-01A survey is made of various inductive systems proposed for low frequency train communication. It is found that thick dielectric jackets or coaxial and metallic shields may be required to reduce the environmental effects that lead to high attenuation....Lighting Control Systems Handbook.DTIC Science & Technology1985-06-01cost  both initial and operating. Initially  the control system designer must collect in- formation and then study and weigh several areas including...8217odLe 045. Pearl Harbor. III: Code 11 Pearl Harbor ar ho I ir I L ’ odk 402. R IYI& [’. Plearl II arbor I II: Li bra ry. Pearl HaIitrbor. I aiLighting Control SystemsDTIC Science & Technology2004-02-26Shorter payback periods After 19 Cost Benefit of Powerlink Rule of Thumb for Powerlink: Powerlink becomes more cost effective beyond 16 controlled...web enabled control (and management software) Increase in level of integration between building systems Increase in new features  functions  benefits ...focus on reducing run-time via Scheduling  Sensing  Switching Growing focus on payback Direct energy cost (with demand) Additional maintenance benefitsMobile User Connectivity in Relay-Assisted Visible Light Communications.PubMedPeÅ¡ek  Petr; Zvanovec  Stanislav; Chvojka  Petr; Bhatnagar  Manav R; Ghassemlooy  Zabih; Saxena  Prakriti2018-04-07In this paper  we investigate relay-assisted visible light communications (VLC) where a mobile user acts as a relay and forwards data from a transmitter to the end mobile user. We analyse the utilization of the amplify-and-forward (AF) and decode-and-forward (DF) relaying schemes. The focus of the paper is on analysis of the behavior of the mobile user acting as a relay while considering a realistic locations of the receivers and transmitters on a standard mobile phone  more specifically with two photodetectors on both sides of a mobile phone and a transmitting LED array located upright. We also investigate dependency of the bit error rate (BER) performance on the azimuth and elevation angles of the mobile relay device within a typical office environment. We provide a new analytical description of BER for AF and DF-based relays in VLC. In addition we compare AF and DF-based systems and show that DF offers a marginal improvement in the coverage area with a BER < 10 -3 and a data rate of 100 Mb/s. Numerical results also illustrate that relay-based systems offer a significant improvement in terms of the coverage compared to direct non-line of sight VLC links.Mobile User Connectivity in Relay-Assisted Visible Light CommunicationsPubMed CentralPeÅ¡ek  Petr; Zvanovec  Stanislav; Chvojka  Petr; Bhatnagar  Manav R.; Ghassemlooy  Zabih; Saxena  Prakriti2018-01-01In this paper  we investigate relay-assisted visible light communications (VLC) where a mobile user acts as a relay and forwards data from a transmitter to the end mobile user. We analyse the utilization of the amplify-and-forward (AF) and decode-and-forward (DF) relaying schemes. The focus of the paper is on analysis of the behavior of the mobile user acting as a relay while considering a realistic locations of the receivers and transmitters on a standard mobile phone  more specifically with two photodetectors on both sides of a mobile phone and a transmitting LED array located upright. We also investigate dependency of the bit error rate (BER) performance on the azimuth and elevation angles of the mobile relay device within a typical office environment. We provide a new analytical description of BER for AF and DF-based relays in VLC. In addition we compare AF and DF-based systems and show that DF offers a marginal improvement in the coverage area with a BER < 10â€“3 and a data rate of 100 Mb/s. Numerical results also illustrate that relay-based systems offer a significant improvement in terms of the coverage compared to direct non-line of sight VLC links. PMID:29642432Emergency Lighting SystemNASA Technical Reports Server (NTRS)1994-01-01When power outages occurred at Landmark Plastic Corporation  it took seven to twelve minutes for the primary mercury lamps to cool down enough to relight and two to seven minutes for the ELS incandescent lamps to relight. Production could not resume for as much as seven minutes. An article in NASA Tech Briefs describing the capabilities of photosensing devices led Landmark employee  Steve Keller to design a system now activated by any voltage loss in the main lamp circuit and coupled with photosensing devices used to keep them on until the primary mercury lamps reach full brightness.Advanced satellite communication systemNASA Technical Reports Server (NTRS)Staples  Edward J.; Lie  Sen1992-01-01The objective of this research program was to develop an innovative advanced satellite receiver/demodulator utilizing surface acoustic wave (SAW) chirp transform processor and coherent BPSK demodulation. The algorithm of this SAW chirp Fourier transformer is of the Convolve - Multiply - Convolve (CMC) type  utilizing off-the-shelf reflective array compressor (RAC) chirp filters. This satellite receiver  if fully developed  was intended to be used as an on-board multichannel communications repeater. The Advanced Communications Receiver consists of four units: (1) CMC processor  (2) single sideband modulator  (3) demodulator  and (4) chirp waveform generator and individual channel processors. The input signal is composed of multiple user transmission frequencies operating independently from remotely located ground terminals. This signal is Fourier transformed by the CMC Processor into a unique time slot for each user frequency. The CMC processor is driven by a waveform generator through a single sideband (SSB) modulator. The output of the coherent demodulator is composed of positive and negative pulses  which are the envelopes of the chirp transform processor output. These pulses correspond to the data symbols. Following the demodulator  a logic circuit reconstructs the pulses into data  which are subsequently differentially decoded to form the transmitted data. The coherent demodulation and detection of BPSK signals derived from a CMC chirp transform processor were experimentally demonstrated and bit error rate (BER) testing was performed. To assess the feasibility of such advanced receiver  the results were compared with the theoretical analysis and plotted for an average BER as a function of signal-to-noise ratio. Another goal of this SBIR program was the development of a commercial product. The commercial product developed was an arbitrary waveform generator. The successful sales have begun with the delivery of the first arbitrary waveform generator.Secure communications systemNASA Technical Reports Server (NTRS)Doland  G. D.1977-01-01System employs electronically randomized variant of quadraphase modulation and demodulation between two synchronized transceivers. System uses off-the-shelf components. It may be used with digital data  command signals  delta-modulated voice signals  digital television signals  or other data converted to digital form.The picture exchange communication system.PubMedBondy  A S; Frost  L A1998-01-01The Picture Exchange Communication System (PECS) was developed as a means to teach children with autism and related developmental disabilities a rapidly acquired  self-initiating  functional communication system. Its theoretical roots combine principles from applied behavior analysis and guidelines established within the field of alternative and augmentative communication. This approach has several potential advantages relative to imitation-based strategies (both vocal and gestural) and symbol selection strategies. The system begins with the exchange of simple icons but rapidly builds ""sentence"" structure. The system also emphasizes developing the request function prior to developing responding to simple questions and commenting. The development of requesting with a sentence structure also permits the rapid development of attributes more traditionally taught within a receptive mode. The relationship between the introduction of PECS and various other behavioral issues (i.e.  social approach and behavior management) as well as its relationship to the codevelopment of speech are reviewed.33 CFR 127.109 - Lighting systems.Code of Federal Regulations  2013 CFR2013-07-01... 33 Navigation and Navigable Waters 2 2013-07-01 2013-07-01 false Lighting systems. 127.109 Section... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.109 Lighting systems. (a) The marine transfer area for LNG must have a lighting system and separate emergency lighting. (b) All outdoor lighting must be...33 CFR 127.109 - Lighting systems.Code of Federal Regulations  2014 CFR2014-07-01... 33 Navigation and Navigable Waters 2 2014-07-01 2014-07-01 false Lighting systems. 127.109 Section... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.109 Lighting systems. (a) The marine transfer area for LNG must have a lighting system and separate emergency lighting. (b) All outdoor lighting must be...33 CFR 127.109 - Lighting systems.Code of Federal Regulations  2012 CFR2012-07-01... 33 Navigation and Navigable Waters 2 2012-07-01 2012-07-01 false Lighting systems. 127.109 Section... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.109 Lighting systems. (a) The marine transfer area for LNG must have a lighting system and separate emergency lighting. (b) All outdoor lighting must be...33 CFR 127.109 - Lighting systems.Code of Federal Regulations  2011 CFR2011-07-01... 33 Navigation and Navigable Waters 2 2011-07-01 2011-07-01 false Lighting systems. 127.109 Section... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.109 Lighting systems. (a) The marine transfer area for LNG must have a lighting system and separate emergency lighting. (b) All outdoor lighting must be...33 CFR 127.109 - Lighting systems.Code of Federal Regulations  2010 CFR2010-07-01... 33 Navigation and Navigable Waters 2 2010-07-01 2010-07-01 false Lighting systems. 127.109 Section... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.109 Lighting systems. (a) The marine transfer area for LNG must have a lighting system and separate emergency lighting. (b) All outdoor lighting must be...The PLATO IV Communications System.ERIC Educational Resources Information CenterSherwood  Bruce Arne; Stifle  JackThe PLATO IV computer-based educational system contains its own communications hardware and software for operating plasma-panel graphics terminals. Key echoing is performed by the central processing unit: every key pressed at a terminal passes through the entire system before anything appears on the terminal's screen. Each terminal is guaranteedâ€¦Time reversal communication systemDOEpatentsCandy  James V.; Meyer  Alan W.2008-12-02A system of transmitting a signal through a channel medium comprises digitizing the signal  time-reversing the digitized signal  and transmitting the signal through the channel medium. The channel medium may be air  earth  water  tissue  metal  and/or non-metal.Advanced imaging communication systemNASA Technical Reports Server (NTRS)Hilbert  E. E.; Rice  R. F.1977-01-01Key elements of system are imaging and nonimaging sensors  data compressor/decompressor  interleaved Reed-Solomon block coder  convolutional-encoded/Viterbi-decoded telemetry channel  and Reed-Solomon decoding. Data compression provides efficient representation of sensor data  and channel coding improves reliability of data transmission.A Model of Internal Communication in Adaptive Communication Systems.ERIC Educational Resources Information CenterWilliams  M. LeeA study identified and categorized different types of internal communication systems and developed an applied model of internal communication in adaptive organizational systems. Twenty-one large organizations were selected for their varied missions and diverse approaches to managing internal communication. Individual face-to-face or telephoneâ€¦A review of gallium nitride LEDs for multi-gigabit-per-second visible light data communicationsNASA Astrophysics Data System (ADS)Rajbhandari  Sujan; McKendry  Jonathan J. D.; Herrnsdorf  Johannes; Chun  Hyunchae; Faulkner  Grahame; Haas  Harald; Watson  Ian M.; O'Brien  Dominic; Dawson  Martin D.2017-02-01The field of visible light communications (VLC) has gained significant interest over the last decade  in both fibre and free-space embodiments. In fibre systems  the availability of low cost polymer optical fibre (POF) that is compatible with visible data communications has been a key enabler. In free-space applications  the availability of hundreds of THz of the unregulated spectrum makes VLC attractive for wireless communications. This paper provides an overview of the recent developments in VLC systems based on gallium nitride (GaN) light-emitting diodes (LEDs)  covering aspects from sources to systems. The state-of-the-art technology enabling bandwidth of GaN LEDs in the range of >400 MHz is explored. Furthermore  advances in key technologies  including advanced modulation  equalisation  and multiplexing that have enabled free-space VLC data rates beyond 10 Gb s-1 are also outlined.Pilot-based parametric channel estimation algorithm for DCO-OFDM-based visual light communicationsNASA Astrophysics Data System (ADS)Qian  Xuewen; Deng  Honggui; He  Hailang2017-10-01Due to wide modulation bandwidth in optical communication  multipath channels may be non-sparse and deteriorate communication performance heavily. Traditional compressive sensing-based channel estimation algorithm cannot be employed in this kind of situation. In this paper  we propose a practical parametric channel estimation algorithm for orthogonal frequency division multiplexing (OFDM)-based visual light communication (VLC) systems based on modified zero correlation code (ZCC) pair that has the impulse-like correlation property. Simulation results show that the proposed algorithm achieves better performances than existing least squares (LS)-based algorithm in both bit error ratio (BER) and frequency response estimation.The ORBCOMM data communications systemNASA Technical Reports Server (NTRS)Schoen  David C.; Locke  Paul A.1993-01-01The ORBCOMM system is designed to provide low-cost  two-way data communications for mobile and remote users. The communications system is ideally configured for low data rate applications where communicating devices are geographically dispersed and two-way communications through terrestrial means is cumbersome and not cost effective. The remote terminals use VHF frequencies which allow for the use of very small  low-cost terminals. ORBCOMM has entered into joint development agreements with several large manufacturers of both consumer and industrial electronics to design and build the remote terminals. Based on prototype work  the estimated retail cost of these units will range from $50 to $400 depending on the complexity of the design. Starting in the fall of 1993  ORBCOMM will begin service with a demonstration network consisting of two operating satellites. By the end of 1994  a full operating network of 26 satellites  four Gateway Earth Stations  and a Network Control Center will be in place. The full constellation will provide full coverage of the entire world with greater than 94 percent communications availability for the continental U.S. This paper describes the ORBCOMM system  the technology used in its implementation  and its applications.BODIPY star-shaped molecules as solid state colour converters for visible light communicationsNASA Astrophysics Data System (ADS)Vithanage  D. A.; Manousiadis  P. P.; Sajjad  M. T.; Rajbhandari  S.; Chun  H.; Orofino  C.; Cortizo-Lacalle  D.; Kanibolotsky  A. L.; Faulkner  G.; Findlay  N. J.; O'Brien  D. C.; Skabara  P. J.; Samuel  I. D. W.; Turnbull  G. A.2016-07-01In this paper  we study a family of solid-state  organic semiconductors for visible light communications. The star-shaped molecules have a boron-dipyrromethene (BODIPY) core with a range of side arm lengths which control the photophysical properties. The molecules emit red light with photoluminescence quantum yields ranging from 22% to 56%. Thin films of the most promising BODIPY molecules were used as a red colour converter for visible light communications. The film enabled colour conversion with a modulation bandwidth of 73 MHz  which is 16 times higher than that of a typical phosphor used in LED lighting systems. A data rate of 370 Mbit/s was demonstrated using On-Off keying modulation in a free space link with a distance of Ëœ15 cm.BODIPY star-shaped molecules as solid state colour converters for visible light communicationsSciTech ConnectVithanage  D. A.; Manousiadis  P. P.; Sajjad  M. T.In this paper  we study a family of solid-state  organic semiconductors for visible light communications. The star-shaped molecules have a boron-dipyrromethene (BODIPY) core with a range of side arm lengths which control the photophysical properties. The molecules emit red light with photoluminescence quantum yields ranging from 22% to 56%. Thin films of the most promising BODIPY molecules were used as a red colour converter for visible light communications. The film enabled colour conversion with a modulation bandwidth of 73â€‰MHz  which is 16 times higher than that of a typical phosphor used in LED lighting systems. A data rate of 370moreÂ Â» Mbit/s was demonstrated using On-Off keying modulation in a free space link with a distance of âˆ¼15â€‰cm.Â«Â lessRapidly deployable emergency communication systemDOEpatentsGladden  Charles A.; Parelman  Martin H.1979-01-01A highly versatile  highly portable emergency communication system which permits deployment in a very short time to cover both wide areas and distant isolated areas depending upon mission requirements. The system employs a plurality of lightweight  fully self-contained repeaters which are deployed within the mission area to provide communication between field teams  and between each field team and a mobile communication control center. Each repeater contains a microcomputer controller  the program for which may be changed from the control center by the transmission of digital data within the audible range (300-3 000 Hz). Repeaters are accessed by portable/mobile transceivers  other repeaters  and the control center through the transmission and recognition of digital data code words in the subaudible range.Ultramicrowave communications system  phase 2NASA Technical Reports Server (NTRS)1980-01-01Communications system design was completed and reviewed. Minor changes were made in order to make it more cost effective and to increase design flexibility. System design activities identified the techniques and procedures to generate and monitor high data rate test signals. Differential bi-phase demodulation is the proposed method for this system. The mockup and packaging designs were performed  and component layout and interconnection constraints were determined  as well as design drawings for dummy parts of the system. The possibility of adding a low cost option to the transceiver system was studied. The communications program has the advantage that new technology signal processing devices can be readily interfaced with the existing radio frequency subsystem to produce a short range radar.Odyssey personal communications satellite systemNASA Technical Reports Server (NTRS)Spitzer  Christopher J.1993-01-01The spectacular growth of cellular telephone networks has proved the demand for personal communications. Large regions of the world are too sparsely populated to be economically served by terrestrial cellular communications. Since satellites are well suited to this application  TRW filed with the FCC on May 31  1993 for the Odyssey construction permit. Odyssey will provide high quality wireless communication services worldwide from satellites. These services will include: voice  data  paging  and messaging. Odyssey will be an economical approach to providing communications. A constellation of 12 satellites will be orbited in three  55 deg. inclined planes at an altitude of 10 354 km to provide continuous coverage of designated regions. Two satellites will be visible anywhere in the world at all times. This dual visibility leads to high line-of-sight elevation angles  minimizing obstructions by terrain  trees and buildings. Each satellite generates a multibeam antenna pattern that divides its coverage area into a set of contiguous cells. The communications system employs spread spectrum CDMA on both the uplinks and downlinks. This signaling method permits band sharing with other systems and applications. Signal processing is accomplished on the ground at the satellite's 'Gateway' stations. The 'bent pipe' transponders accommodates different regional standards  as well as signaling changes over time. The low power Odyssey handset will be cellular compatible. Multipath fade protection is provided in the handset.Encrypted IP video communication systemNASA Astrophysics Data System (ADS)Bogdan  Apetrechioaie; LuminiÅ£a  Mateescu2010-11-01Digital video transmission is a permanent subject of development  research and improvement. This field of research has an exponentially growing market in civil  surveillance  security and military aplications. A lot of solutions: FPGA  ASIC  DSP have been used for this purpose. The paper presents the implementation of an encrypted  IP based  video communication system having a competitive performance/cost ratio .Optical antenna for a visible light communications receiverNASA Astrophysics Data System (ADS)Valencia-Estrada  Juan Camilo; GarcÃ­a-MÃ¡rquez  Jorge; Topsu  Suat; Chassagne  Luc2018-01-01Visible Light Communications (VLC) receivers adapted to be used in high transmission rates will eventually use either  high aperture lenses or non-linear optical elements capable of converting light arriving to the receiver into an electric signal. The high aperture lens case  reveals a challenge from an optical designers point-of-view. As a matter of fact  the lens must collect a wide aperture intensity flux using a limited aperture as its use is intended to portable devices. This last also limits both  lens thickness and its focal length. Here  we show a first design to be adapted to a VLC receiver that take these constraints into account. This paper describes a method to design catadioptric and monolithic lenses to be used as an optical collector of light entering from a near point light source as a spherical fan L with a wide acceptance angle Î±Â° and high efficiency. These lenses can be mass produced and therefore one can find many practical applications in VLC equipped devices. We show a first design for a near light source without magnification  and second one with a detector's magnification in a meridional section. We utilize rigorous geometric optics  vector analysis and ordinary differential equations.Communications satellite systems capacity analysisNASA Technical Reports Server (NTRS)Browne  L.; Hines  T.; Tunstall  B.1982-01-01Analog and digital modulation techniques are compared with regard to efficient use of the geostationary orbit by communications satellites. Included is the definition of the baseline systems (both space and ground segments)  determination of interference susceptibility  calculation of orbit spacing  and evaluation of relative costs. It is assumed that voice or TV is communicated at 14/11 GHz using either FM or QPSK modulation. Both the Fixed-Satellite Service and the Broadcasting-Satellite Service are considered. For most of the cases examined the digital approach requires a satellite spacing less than or equal to that required by the analog approach.49 CFR 193.2519 - Communication systems.Code of Federal Regulations  2012 CFR2012-10-01... 49 Transportation 3 2012-10-01 2012-10-01 false Communication systems. 193.2519 Section 193.2519...: FEDERAL SAFETY STANDARDS Operations Â§ 193.2519 Communication systems. (a) Each LNG plant must have a primary communication system that provides for verbal communications between all operating personnel at...49 CFR 193.2519 - Communication systems.Code of Federal Regulations  2013 CFR2013-10-01... 49 Transportation 3 2013-10-01 2013-10-01 false Communication systems. 193.2519 Section 193.2519...: FEDERAL SAFETY STANDARDS Operations Â§ 193.2519 Communication systems. (a) Each LNG plant must have a primary communication system that provides for verbal communications between all operating personnel at...49 CFR 193.2519 - Communication systems.Code of Federal Regulations  2011 CFR2011-10-01...: FEDERAL SAFETY STANDARDS Operations Â§ 193.2519 Communication systems. (a) Each LNG plant must have a primary communication system that provides for verbal communications between all operating personnel at... 49 Transportation 3 2011-10-01 2011-10-01 false Communication systems. 193.2519 Section 193.2519...Global services systems - Space communicationNASA Technical Reports Server (NTRS)Shepphird  F. H.; Wolbers  H. L.1979-01-01The requirements projected to the year 2000 for space-based global service systems  including both personal communications and innovative services  are developed based on historic trends and anticipated worldwide demographic and economic growth patterns. The growing demands appear to be best satisfied by developing larger  more sophisticated space systems in order to reduce the size  complexity  and expense of ground terminals. The availability of low-cost ground terminals will  in turn  further stimulate the generation of new services and new customers.Communicating awareness of light pollution with the schools in NepalNASA Astrophysics Data System (ADS)Acharya  Jayanta2015-08-01Nepal is also highly polluted by the lights and other dusts partials  but lacks the formal education of light pollutions and effect of light for astronomy observations. When we get Sky Quality Meter (SQM) last year (2014) we have installed it in Kathmandu.This paper will highlight about installation SQM in Nepal  measurement of brightness of the night sky in magnitudes per square arc second. Research work of light pollution of Kathmandu will be more in focus. Highlight of the Astronomy programs by different Schools in Nepal along with the background of coverage of Astronomy education in the syllables of different education level. The various procedure   technique and idea used in providing the space education through different activities and program to school studentsThe paper will also deal with the Importance of light and use of artificial light. Beside it will also highlight the possibility of development of various observatories in Nepal because of its tremendous topography increasing the Astro tourism in Nepal.Hence the paper would focus on the light pollution of the city like Kathmandu and light system in Nepal and Astronomy education to its implementation along with its outreach to Nepalese society.New Trends in Educational Lighting Systems.ERIC Educational Resources Information CenterMurphy  Peter2001-01-01Explores technological trends for improving campus lighting  including the use of direct-indirect suspended fluorescent lighting  suspended linear lighting  high-efficiency optical systems  and occupancy and daylight sensors. (GR)NASA's First Laser Communication SystemNASA Image and Video Library2017-12-08A new NASA-developed  laser-based space communication system will enable higher rates of satellite communications similar in capability to high-speed fiber optic networks on Earth. The space terminal for the Lunar Laser Communication Demonstration (LLCD)  NASA's first high-data-rate laser communication system  was recently integrated onto the Lunar Atmosphere and Dust Environment Explorer (LADEE) spacecraft. LLCD will demonstrate laser communications from lunar orbit to Earth at six times the rate of the best modern-day advanced radio communication systems. Credit: NASA ----- What is LADEE? The Lunar Atmosphere and Dust Environment Explorer (LADEE) is designed to study the Moon's thin exosphere and the lunar dust environment. An ""exosphere"" is an atmosphere that is so thin and tenuous that molecules don't collide with each other. Studying the Moon's exosphere will help scientists understand other planetary bodies with exospheres too  like Mercury and some of Jupiter's bigger moons. The orbiter will determine the density  composition and temporal and spatial variability of the Moon's exosphere to help us understand where the species in the exosphere come from and the role of the solar wind  lunar surface and interior  and meteoric infall as sources. The mission will also examine the density and temporal and spatial variability of dust particles that may get lofted into the atmosphere. The mission also will test several new technologies  including a modular spacecraft bus that may reduce the cost of future deep space missions and demonstrate two-way high rate laser communication for the first time from the Moon. LADEE now is ready to launch when the window opens on Sept. 6  2013. Read more: www.nasa.gov/ladee NASA image use policy. NASA Goddard Space Flight Center enables NASAâ€™s mission through four scientific endeavors: Earth Science  Heliophysics  Solar System Exploration  and Astrophysics. Goddard plays a leading role in NASAâ€™s accomplishments by contributingPAPR reduction based on tone reservation scheme for DCO-OFDM indoor visible light communications.PubMedBai  Jurong; Li  Yong; Yi  Yang; Cheng  Wei; Du  Huimin2017-10-02High peak-to-average power ratio (PAPR) leads to out-of-band power and in-band distortion in the direct current-biased optical orthogonal frequency division multiplexing (DCO-OFDM) systems. In order to effectively reduce the PAPR with faster convergence and lower complexity  this paper proposes a tone reservation based scheme  which is the combination of the signal-to-clipping noise ratio (SCR) procedure and the least squares approximation (LSA) procedure. In the proposed scheme  the transmitter of the DCO-OFDM indoor visible light communication (VLC) system is designed to transform the PAPR reduced signal into real-valued positive OFDM signal without doubling the transmission bandwidth. Moreover  the communication distance and the light emitting diode (LED) irradiance angle are taking into consideration in the evaluation of the system bit error rate (BER). The PAPR reduction efficiency of the proposed scheme is remarkable for DCO-OFDM indoor VLC systems.Communications Handbook for Traffic Control SystemsDOT National Transportation Integrated Search1993-04-01The communications system generally proves the most critical and expensive element of a traffic control system/IVHS. Therefore the successful design  implementation  and operation of the communications system become key to the effectiveness of the ov...Non-flickering 100 m RGB visible light communication transmission based on a CMOS image sensor.PubMedChow  Chi-Wai; Shiu  Ruei-Jie; Liu  Yen-Chun; Liu  Yang; Yeh  Chien-Hung2018-03-19We demonstrate a non-flickering 100 m long-distance RGB visible light communication (VLC) transmission based on a complementary-metal-oxide-semiconductor (CMOS) camera. Experimental bit-error rate (BER) measurements under different camera ISO values and different transmission distances are evaluated. Here  we also experimentally reveal that the rolling shutter effect- (RSE) based VLC system cannot work at long distance transmission  and the under-sampled modulation- (USM) based VLC system is a good choice.Short-range communication systemNASA Technical Reports Server (NTRS)Alhorn  Dean C. (Inventor); Howard  David E. (Inventor); Smith  Dennis A. (Inventor)2012-01-01A short-range communication system includes an antenna  a transmitter  and a receiver. The antenna is an electrical conductor formed as a planar coil with rings thereof being uniformly spaced. The transmitter is spaced apart from the plane of the coil by a gap. An amplitude-modulated and asynchronous signal indicative of a data stream of known peak amplitude is transmitted into the gap. The receiver detects the coil's resonance and decodes same to recover the data stream.Communication as an ecological system.PubMedBorg  Erik; Bergkvist  Christina; Olsson  Inga-Stina; WikstrÃ¶m  Carina; Borg  Birgitta2008-11-01A conceptual framework for human communication  based on traditional biological ecology  is further developed. The difference between communication at the message and behavioural levels is emphasized. Empirical data are presented from various studies  showing that degree of satisfaction with communication is correlated with how close the outcome is to the memory of function prior to hearing impairment. We found no indication that hearing-impaired subjects overestimated their previous hearing or the hearing of normal-hearing people. Satisfaction was also correlated with the outcome and degree of fulfillment of expectations. It did not correlate with improvement of function. The concept of balance was presented and tested using a semi-quantitative approach. Several projects were presented in which the framework was applied: the hearing impaired as counsellor  choosing sides in unilateral deafness  a monitoring device for the deafblind  interaction between Swedish as a second language and hearing impairment  language development in hearing impaired children. By regarding hearing as a component of a communicative system  the perspective of audiological analysis and rehabilitation is broadened.Information Communication System at Tsukuba EXPO'85NASA Astrophysics Data System (ADS)Sakagami  YasuhikoAt Tsukuba EXPO'85 information communication system which employs the most advanced technology such as optical technology  is operated to conduct EXPO information guide  environmental and security control at the site  and office management  which is effective for smooth management of Exposition and appropriate service to visitors. The author outlines the characteristics of the whole communication system  and also describes how communication system using optical technology is located in the whole communication system  and the system outline.33 CFR 127.1111 - Communication systems.Code of Federal Regulations  2012 CFR2012-07-01... 33 Navigation and Navigable Waters 2 2012-07-01 2012-07-01 false Communication systems. 127.1111... systems. (a) The marine transfer area for LHG must possess a communication system that enables continuous... in charge of transfer for the facility. (b) The communication system required by paragraph (a) of...33 CFR 127.1111 - Communication systems.Code of Federal Regulations  2014 CFR2014-07-01... 33 Navigation and Navigable Waters 2 2014-07-01 2014-07-01 false Communication systems. 127.1111... systems. (a) The marine transfer area for LHG must possess a communication system that enables continuous... in charge of transfer for the facility. (b) The communication system required by paragraph (a) of...33 CFR 127.1111 - Communication systems.Code of Federal Regulations  2013 CFR2013-07-01... 33 Navigation and Navigable Waters 2 2013-07-01 2013-07-01 false Communication systems. 127.1111... systems. (a) The marine transfer area for LHG must possess a communication system that enables continuous... in charge of transfer for the facility. (b) The communication system required by paragraph (a) of...33 CFR 127.1111 - Communication systems.Code of Federal Regulations  2011 CFR2011-07-01... 33 Navigation and Navigable Waters 2 2011-07-01 2011-07-01 false Communication systems. 127.1111... systems. (a) The marine transfer area for LHG must possess a communication system that enables continuous... in charge of transfer for the facility. (b) The communication system required by paragraph (a) of...33 CFR 127.1111 - Communication systems.Code of Federal Regulations  2010 CFR2010-07-01... 33 Navigation and Navigable Waters 2 2010-07-01 2010-07-01 false Communication systems. 127.1111... systems. (a) The marine transfer area for LHG must possess a communication system that enables continuous... in charge of transfer for the facility. (b) The communication system required by paragraph (a) of...Energy-efficient lighting system for televisionDOEpatentsCawthorne  Duane C.1987-07-21A light control system for a television camera comprises an artificial light control system which is cooperative with an iris control system. This artificial light control system adjusts the power to lamps illuminating the camera viewing area to provide only sufficient artificial illumination necessary to provide a sufficient video signal when the camera iris is substantially open.Generation and communication of dynamic maps using light projectionNASA Astrophysics Data System (ADS)Busch  Steffen; Schlichting  Alexander; Brenner  Claus2018-05-01Many accidents are caused by miscommunication between traffic participants. Much research is being conducted in the area of car to car and car to infrastructure communication in order to eliminate this cause of accidents. How-ever  less attention is paid to the question how the behavior of a car can be communicated to pedestrians. Especially considering automated traffic  there is a lack of communication between cars and pedestrians. In this paper  we address the question how an autonomously driving car can inform pedestrians about its intentions. Especially in case of highly automated driving  making eye contact with a driver will give no clue about his or her intensions. We developed a prototype which continuously informs pedestrians about the intentions of the vehicle by projecting visual patterns onto the ground. Furthermore  the system communicates its interpretation of the observed situation to the pedestrians to warn them or to encourage them to perform a certain action. In order to communicate adaptively  the vehicle needs to develop an understanding of the dynamics of a city to know what to expect in certain situations and what speed is appropriate. To support this  we created a dynamic map  which estimates the number of pedestrians and cyclists in a certain area  which is then used to determine how `hazardous' the area is. This dynamic map is obtained from measurement data from many time instances  in contrast to the static car navigation maps  which are prevalent today. Apart from being used for communication purposes  the dynamic map can also influence the speed of a car  be it manually or autonomously driven. Adapting the speed in hazardous areas will avoid accidents where a car drives too fast  so that neither a human nor a computer-operated system would be able to stop in time.Self-reverse-biased solar panel optical receiver for simultaneous visible light communication and energy harvesting.PubMedShin  Won-Ho; Yang  Se-Hoon; Kwon  Do-Hoon; Han  Sang-Kook2016-10-31We propose a self-reverse-biased solar panel optical receiver for energy harvesting and visible light communication. Since the solar panel converts an optical component into an electrical component  it provides both energy harvesting and communication. The signal component can be separated from the direct current component  and these components are used for communication and energy harvesting. We employed a self-reverse-biased receiver circuit to improve the communication and energy harvesting performance. The reverse bias on the solar panel improves the responsivity and response time. The proposed system achieved 17.05 mbps discrete multitone transmission with a bit error rate of 1.1 x 10-3 and enhanced solar energy conversion efficiency.Airborne space laser communication system and experimentsNASA Astrophysics Data System (ADS)Li  Xiao-Ming; Zhang  Li-zhong; Meng  Li-Xin2015-11-01Airborne space laser communication is characterized by its high speed  anti-electromagnetic interference  security  easy to assign. It has broad application in the areas of integrated space-ground communication networking  military communication  anti-electromagnetic communication. This paper introduce the component and APT system of the airborne laser communication system design by Changchun university of science and technology base on characteristic of airborne laser communication and Y12 plan  especially introduce the high communication speed and long distance communication experiment of the system that among two Y12 plans. In the experiment got the aim that the max communication distance 144Km  error 10-6 2.5Gbps - 10-7 1.5Gbps capture probability 97%  average capture time 20s. The experiment proving the adaptability of the APT and the high speed long distance communication.Lighting system with heat distribution face plateDOEpatentsArik  Mehmet; Weaver  Stanton Earl; Stecher  Thomas Elliot; Kuenzler  Glenn Howard; Wolfe  Jr.  Charles Franklin; Li  Ri2013-09-10Lighting systems having a light source and a thermal management system are provided. The thermal management system includes synthetic jet devices  a heat sink and a heat distribution face plate. The synthetic jet devices are arranged in parallel to one and other and are configured to actively cool the lighting system. The heat distribution face plate is configured to radially transfer heat from the light source into the ambient air.Efficient Visible Light Communication Transmitters Based on Switching-Mode dc-dc Converters.PubMedRodrÃ­guez  Juan; Lamar  Diego G; Aller  Daniel G; Miaja  Pablo F; SebastiÃ¡n  Javier2018-04-07Visible light communication (VLC) based on solid-state lighting (SSL) is a promising option either to supplement or to substitute existing radio frequency (RF) wireless communication in indoor environments. VLC systems take advantage of the fast modulation of the visible light that light emitting diodes (LEDs) enable. The switching-mode dc-to-dc converter (SMC dc-dc ) must be the cornerstone of the LED driver of VLC transmitters in order to incorporate the communication functionality into LED lighting  keeping high power efficiency. However  the new requirements related to the communication  especially the high bandwidth that the LED driver must achieve  converts the design of the SMC dc-dc into a very challenging task. In this work  three different methods for achieving such a high bandwidth with an SMC dc-dc are presented: increasing the order of the SMC dc-dc output filter  increasing the number of voltage inputs  and increasing the number of phases. These three strategies are combinable and the optimum design depends on the particular VLC application  which determines the requirements of the VLC transmitter. As an example  an experimental VLC transmitter based on a two-phase buck converter with a fourth-order output filter will demonstrate that a bandwidth of several hundred kilohertz (kHz) can be achieved with output power levels close to 10 W and power efficiencies between 85% and 90%. In conclusion  the design strategy presented allows us to incorporate VLC into SSL  achieving high bit rates without damaging the power efficiency of LED lighting.Efficient Visible Light Communication Transmitters Based on Switching-Mode dc-dc ConvertersPubMed Central2018-01-01Visible light communication (VLC) based on solid-state lighting (SSL) is a promising option either to supplement or to substitute existing radio frequency (RF) wireless communication in indoor environments. VLC systems take advantage of the fast modulation of the visible light that light emitting diodes (LEDs) enable. The switching-mode dc-to-dc converter (SMCdc-dc) must be the cornerstone of the LED driver of VLC transmitters in order to incorporate the communication functionality into LED lighting  keeping high power efficiency. However  the new requirements related to the communication  especially the high bandwidth that the LED driver must achieve  converts the design of the SMCdc-dc into a very challenging task. In this work  three different methods for achieving such a high bandwidth with an SMCdc-dc are presented: increasing the order of the SMCdc-dc output filter  increasing the number of voltage inputs  and increasing the number of phases. These three strategies are combinable and the optimum design depends on the particular VLC application  which determines the requirements of the VLC transmitter. As an example  an experimental VLC transmitter based on a two-phase buck converter with a fourth-order output filter will demonstrate that a bandwidth of several hundred kilohertz (kHz) can be achieved with output power levels close to 10 W and power efficiencies between 85% and 90%. In conclusion  the design strategy presented allows us to incorporate VLC into SSL  achieving high bit rates without damaging the power efficiency of LED lighting. PMID:29642455Quantum light in novel systemsNASA Astrophysics Data System (ADS)Rai  Amit2011-12-01In this thesis we have focused on the study of various systems which are presently widely studied in different areas of quantum optics and quantum information sciences. These  for example  include the coupled system of photonic waveguides which are known to be highly efficient in manipulating the flow of light. The Hamiltonian describing the evolution of field mode in coupled waveguides is effectively identical to the well-known tight binding Hamiltonian used in solid state physics. The advantage of waveguide system is the possibility to control various interactions by design and their low decoherence rate. The excellent stability offered by coupled waveguides has led to the observation of many key coherent effects such as quantum walk  Bloch oscillation  and discrete Talbot effect. For example  Bloch oscillations have been investigated in coupled waveguides using coherent beam of light. We wanted to inquire whether coherent phenomena such as Bloch oscillations can be possible with incoherent single photon sources. We discovered that Bloch oscillations are indeed possible with single photons provided we prepare single photons in a W state. Moreover  coupled waveguides also find applications in the field of quantum information processing. Since entanglement plays a prominent role in all these applications  it is important to understand the entanglement dynamics in these structures. We considered the case of squeezed input in one of the waveguide and showed that one can generate entanglement between the waveguide modes. We further continued our work on the entanglement generation in coupled waveguides by incorporating the effect of loss in the waveguide structure for the squeezed and photon number input states. We considered relevant experimental parameters and showed that waveguide structures are reasonably robust against the effect of loss. Another system which has attracted a great deal of interest is the optomechanical system. We consider an optomechanical system33 CFR 127.111 - Communications systems.Code of Federal Regulations  2011 CFR2011-07-01... 33 Navigation and Navigable Waters 2 2011-07-01 2011-07-01 false Communications systems. 127.111... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.111 Communications systems. (a) The marine transfer area for LNG must have a ship-to-shore communication system and a separate emergency ship-to-shore...33 CFR 127.111 - Communications systems.Code of Federal Regulations  2014 CFR2014-07-01... 33 Navigation and Navigable Waters 2 2014-07-01 2014-07-01 false Communications systems. 127.111... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.111 Communications systems. (a) The marine transfer area for LNG must have a ship-to-shore communication system and a separate emergency ship-to-shore...33 CFR 127.111 - Communications systems.Code of Federal Regulations  2012 CFR2012-07-01... 33 Navigation and Navigable Waters 2 2012-07-01 2012-07-01 false Communications systems. 127.111... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.111 Communications systems. (a) The marine transfer area for LNG must have a ship-to-shore communication system and a separate emergency ship-to-shore...33 CFR 127.111 - Communications systems.Code of Federal Regulations  2013 CFR2013-07-01... 33 Navigation and Navigable Waters 2 2013-07-01 2013-07-01 false Communications systems. 127.111... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.111 Communications systems. (a) The marine transfer area for LNG must have a ship-to-shore communication system and a separate emergency ship-to-shore...33 CFR 127.111 - Communications systems.Code of Federal Regulations  2010 CFR2010-07-01... 33 Navigation and Navigable Waters 2 2010-07-01 2010-07-01 false Communications systems. 127.111... Waterfront Facilities Handling Liquefied Natural Gas Â§ 127.111 Communications systems. (a) The marine transfer area for LNG must have a ship-to-shore communication system and a separate emergency ship-to-shore...Portable light detection system for the blindNASA Technical Reports Server (NTRS)Wilber  R. L.; Carpenter  B. L.1973-01-01System can be used to detect ""ready"" light on automatic cooking device  to tell if lights are on for visitors  or to tell whether it is daylight or dark outside. Device is actuated like flashlight. Light impinging on photo cell activates transistor which energizes buzzer to indicate presence of light.Communications satellite system for AfricaNASA Astrophysics Data System (ADS)Kriegl  W.; Laufenberg  W.1980-09-01Earlier established requirement estimations were improved upon by contacting African administrations and organizations. An enormous demand is shown to exist for telephony and teletype services in rural areas. It is shown that educational television broadcasting should be realized in the current African transport and communications decade (1978-1987). Radio broadcasting is proposed in order to overcome illiteracy and to improve educational levels. The technical and commercial feasibility of the system is provided by computer simulations which demonstrate how the required objectives can be fulfilled in conjunction with ground networks.3.375-Gb/s RGB-LED based WDM visible light communication system employing PAM-8 modulation with phase shifted Manchester coding.PubMedChi  Nan; Zhang  Mengjie; Zhou  Yingjun; Zhao  Jiaqi2016-09-19Optical background noise and second-order nonlinear distortions are two main challenges faced by indoor high-speed VLC system. In this paper  a novel phase shifted Manchester (PS-Manchester) coding based on PAM-8 is proposed and experimentally demonstrated to mitigate these noise and distortions. With the aid of PS-Manchester coding and WDM  a total data rate of 3.375-Gb/s can be successfully achieved in the RGB-LED based VLC system. The BER is under 7% HD-FEC limit of 3.8x10-3 after 1-m indoor free space transmission. To the best of our knowledge  this is the highest data rate ever achieved in PAM VLC systems.Wireless augmented reality communication systemNASA Technical Reports Server (NTRS)Devereaux  Ann (Inventor); Agan  Martin (Inventor); Jedrey  Thomas (Inventor)2006-01-01The system of the present invention is a highly integrated radio communication system with a multimedia co-processor which allows true two-way multimedia (video  audio  data) access as well as real-time biomedical monitoring in a pager-sized portable access unit. The system is integrated in a network structure including one or more general purpose nodes for providing a wireless-to-wired interface. The network architecture allows video  audio and data (including biomedical data) streams to be connected directly to external users and devices. The portable access units may also be mated to various non-personal devices such as cameras or environmental sensors for providing a method for setting up wireless sensor nets from which reported data may be accessed through the portable access unit. The reported data may alternatively be automatically logged at a remote computer for access and viewing through a portable access unit  including the user's own.Wireless Augmented Reality Communication SystemNASA Technical Reports Server (NTRS)Jedrey  Thomas (Inventor); Agan  Martin (Inventor); Devereaux  Ann (Inventor)2014-01-01The system of the present invention is a highly integrated radio communication system with a multimedia co-processor which allows true two-way multimedia (video  audio  data) access as well as real-time biomedical monitoring in a pager-sized portable access unit. The system is integrated in a network structure including one or more general purpose nodes for providing a wireless-to-wired interface. The network architecture allows video  audio and data (including biomedical data) streams to be connected directly to external users and devices. The portable access units may also be mated to various non-personal devices such as cameras or environmental sensors for providing a method for setting up wireless sensor nets from which reported data may be accessed through the portable access unit. The reported data may alternatively be automatically logged at a remote computer for access and viewing through a portable access unit  including the user's own.Wireless Augmented Reality Communication SystemNASA Technical Reports Server (NTRS)Agan  Martin (Inventor); Devereaux  Ann (Inventor); Jedrey  Thomas (Inventor)2016-01-01The system of the present invention is a highly integrated radio communication system with a multimedia co-processor which allows true two-way multimedia (video  audio  data) access as well as real-time biomedical monitoring in a pager-sized portable access unit. The system is integrated in a network structure including one or more general purpose nodes for providing a wireless-to-wired interface. The network architecture allows video  audio and data (including biomedical data) streams to be connected directly to external users and devices. The portable access units may also be mated to various non-personal devices such as cameras or environmental sensors for providing a method for setting up wireless sensor nets from which reported data may be accessed through the portable access unit. The reported data may alternatively be automatically logged at a remote computer for access and viewing through a portable access unit  including the user's own.Visible light communications for the implementation of internet-of-thingsNASA Astrophysics Data System (ADS)Chen  Chia-Wei; Wang  Wei-Chung; Wu  Jhao-Ting; Chen  Hung-Yu; Liang  Kevin; Wei  Liang-Yu; Hsu  Yung; Hsu  Chin-Wei; Chow  Chi-Wai; Yeh  Chien-Hung; Liu  Yang; Hsieh  Hsiang-Chin; Chen  Yen-Ting2016-06-01It is predicted that the number of internet-of-things (IoT) devices will be >28 billion in 2020. Due to the shortage of the conventional radio-frequency spectrum  using visible light communication (VLC) for IoT can be promising. IoT networks may only require very low-data rate communication for transmitting sensing or identity information. The implementation of a VLC link on existing computer communication standards and interfaces is important. Among the standards  universal asynchronous receiver/transmitter (UART) is very popular. We propose and demonstrate a VLC-over-UART system. Bit error rate analysis is performed. Different components and modules used in the proposed VLC-over-UART system are discussed. Then  we also demonstrate a real-time simultaneous temperature  humidity  and illuminance monitoring using the proposed VLC link.Communication System Architecture for Planetary ExplorationNASA Technical Reports Server (NTRS)Braham  Stephen P.; Alena  Richard; Gilbaugh  Bruce; Glass  Brian; Norvig  Peter (Technical Monitor)2001-01-01Future human missions to Mars will require effective communications supporting exploration activities and scientific field data collection. Constraints on cost  size  weight and power consumption for all communications equipment make optimization of these systems very important. These information and communication systems connect people and systems together into coherent teams performing the difficult and hazardous tasks inherent in planetary exploration. The communication network supporting vehicle telemetry data  mission operations  and scientific collaboration must have excellent reliability  and flexibility.Phosphorous Diffuser Diverged Blue Laser Diode for Indoor Lighting and CommunicationPubMed CentralChi  Yu-Chieh; Hsieh  Dan-Hua; Lin  Chung-Yu; Chen  Hsiang-Yu; Huang  Chia-Yen; He  Jr-Hau; Ooi  Boon; DenBaars  Steven P.; Nakamura  Shuji; Kuo  Hao-Chung; Lin  Gong-Ru2015-01-01An advanced light-fidelity (Li-Fi) system based on the blue Gallium nitride (GaN) laser diode (LD) with a compact white-light phosphorous diffuser is demonstrated for fusing the indoor white-lighting and visible light communication (VLC). The phosphorous diffuser adhered blue GaN LD broadens luminescent spectrum and diverges beam spot to provide ample functionality including the completeness of Li-Fi feature and the quality of white-lighting. The phosphorous diffuser diverged white-light spot covers a radiant angle up to 120o with CIE coordinates of (0.34  0.37). On the other hand  the degradation on throughput frequency response of the blue LD is mainly attributed to the self-feedback caused by the reflection from the phosphor-air interface. It represents the current state-of-the-art performance on carrying 5.2-Gbit/s orthogonal frequency-division multiplexed 16-quadrature-amplitude modulation (16-QAM OFDM) data with a bit error rate (BER) of 3.1â€‰Ã—â€‰10âˆ’3 over a 60-cm free-space link. This work aims to explore the plausibility of the phosphorous diffuser diverged blue GaN LD for future hybrid white-lighting and VLC systems. PMID:26687289Phosphorous Diffuser Diverged Blue Laser Diode for Indoor Lighting and CommunicationNASA Astrophysics Data System (ADS)Chi  Yu-Chieh; Hsieh  Dan-Hua; Lin  Chung-Yu; Chen  Hsiang-Yu; Huang  Chia-Yen; He-Hau  Jr.; Ooi  Boon; Denbaars  Steven P.; Nakamura  Shuji; Kuo  Hao-Chung; Lin  Gong-Ru2015-12-01An advanced light-fidelity (Li-Fi) system based on the blue Gallium nitride (GaN) laser diode (LD) with a compact white-light phosphorous diffuser is demonstrated for fusing the indoor white-lighting and visible light communication (VLC). The phosphorous diffuser adhered blue GaN LD broadens luminescent spectrum and diverges beam spot to provide ample functionality including the completeness of Li-Fi feature and the quality of white-lighting. The phosphorous diffuser diverged white-light spot covers a radiant angle up to 120o with CIE coordinates of (0.34  0.37). On the other hand  the degradation on throughput frequency response of the blue LD is mainly attributed to the self-feedback caused by the reflection from the phosphor-air interface. It represents the current state-of-the-art performance on carrying 5.2-Gbit/s orthogonal frequency-division multiplexed 16-quadrature-amplitude modulation (16-QAM OFDM) data with a bit error rate (BER) of 3.1â€‰Ã—â€‰10-3 over a 60-cm free-space link. This work aims to explore the plausibility of the phosphorous diffuser diverged blue GaN LD for future hybrid white-lighting and VLC systems.Simultaneous light emission and detection of InGaN/GaN multiple quantum well diodes for in-plane visible light communicationNASA Astrophysics Data System (ADS)Wang  Yongjin; Xu  Yin; Yang  Yongchao; Gao  Xumin; Zhu  Bingcheng; Cai  Wei; Yuan  Jialei; Zhang  Rong; Zhu  Hongbo2017-03-01This paper presents the design  fabrication  and experimental characterization of monolithically integrated p-n junction InGaN/GaN multiple quantum well diodes (MQWDs) and suspended waveguides. Suspended MQWDs can be used as transmitters and receivers simultaneously  and suspended waveguides are used for light coupling to create an in-plane visible light communication system. Compared to the waveguide with separation trench  the calculated total light efficiency is increased from 18% to 22% for the continuous waveguide. The MQWDs are characterized by their typical current-voltage performance  and the pulse excitation measurements confirm that the InGaN/GaN MQWDs can achieve the light emission and photodetection at the same time. The photocurrent measurements indicate that the photocurrent is modulated by a bias voltage and that the photons are being supplied from another transmitter. An experimental demonstration is presented showing that the proposed device works well for in-plane full-duplex communication using visible light.Systems  Purposes  Images  Plans: A Communication Model.ERIC Educational Resources Information CenterHildum  Donald C.A definition and a general description of communication that makes use of the insights of linguistics and psychology are presented in this paper  along with a conceptual model of communication that incorporates a systems approach. Following a lengthy discussion of the components required for a communication exchange  the systems approach model isâ€¦Complex Communication System and Social Change.ERIC Educational Resources Information CenterChang  Won H.The basic question under examination is the underlying force that brings forth changes in cultural and social organizations. By employing general system theory and communication systemic analysis  the author concludes that communication  especially human communication  is the main vehicle of change. Human interchange  it is suggested  is constantâ€¦Game theory-based mode cooperative selection mechanism for device-to-device visible light communicationNASA Astrophysics Data System (ADS)Liu  Yuxin; Huang  Zhitong; Li  Wei; Ji  Yuefeng2016-03-01Various patterns of device-to-device (D2D) communication  from Bluetooth to Wi-Fi Direct  are emerging due to the increasing requirements of information sharing between mobile terminals. This paper presents an innovative pattern named device-to-device visible light communication (D2D-VLC) to alleviate the growing traffic problem. However  the occlusion problem is a difficulty in D2D-VLC. This paper proposes a game theory-based solution in which the best-response dynamics and best-response strategies are used to realize a mode-cooperative selection mechanism. This mechanism uses system capacity as the utility function to optimize system performance and selects the optimal communication mode for each active user from three candidate modes. Moreover  the simulation and experimental results show that the mechanism can attain a significant improvement in terms of effectiveness and energy saving compared with the cases where the users communicate via only the fixed transceivers (light-emitting diode and photo diode) or via only D2D.On-off keying transmitter design for navigation by visible light communicationNASA Astrophysics Data System (ADS)Louro  P.; Vieira  M.; Costa  J.; Vieira  M. A.2018-02-01White LEDS revolutionized the field of illumination technology mainly due to the energy saving effects. Besides lighting purposes LEDs can also be used in wireless communication systems when integrated in Visible Light Communication (VLC) systems. Indoor positioning for navigation in large buildings is currently under research to overcome the difficulties associated with the use of GPS in such environments. The motivation for this application is also supported by the possibility of taking advantage of an existing lighting and WiFi infrastructure. In this work it is proposed an indoor navigation system based on the use of VLC technology. The proposed system includes trichromatic white LEDs with the red and blue chips modulated at different frequencies and a pinpin photodetector with selective spectral sensitivity. Optoelectronic features of both optical sources and photodetector device are analyzed. The photodetector device consists two pin structures based on a-SiC:H and a-Si:H with geometrical configuration optimized for the detection of short and large wavelengths in the visible range. Its sensitivity is externally tuned by steady state optical bias. The localization algorithm makes use of the Fourier transform to identify the frequencies present in the photocurrent signal and the wavelength filtering properties of the sensor under front and back optical bias to detect the existing red and blue signals. The viability of the system was demonstrated through the implementation of an automatic algorithm to infer the photodetector cardinal direction. A capacitive optoelectronic model supports the experimental results and explains the device operation.Smart Grid Communications System BlueprintNASA Astrophysics Data System (ADS)Clark  Adrian; Pavlovski  Chris2010-10-01Telecommunications operators are well versed in deploying 2G and 3G wireless networks. These networks presently support the mobile business user and/or retail consumer wishing to place conventional voice calls and data connections. The electrical power industry has recently commenced transformation of its distribution networks by deploying smart monitoring and control devices throughout their networks. This evolution of the network into a `smart grid' has also motivated the need to deploy wireless technologies that bridge the communication gap between the smart devices and information technology systems. The requirements of these networks differ from traditional wireless networks that communications operators have deployed  which have thus far forced energy companies to consider deploying their own wireless networks. We present our experience in deploying wireless networks to support the smart grid and highlight the key properties of these networks. These characteristics include application awareness  support for large numbers of simultaneous cell connections  high service coverage and prioritized routing of data. We also outline our target blueprint architecture that may be useful to the industry in building wireless and fixed networks to support the smart grid. By observing our experiences  telecommunications operators and equipment manufacturers will be able to augment their current networks and products in a way that accommodates the needs of the emerging industry of smart grids and intelligent electrical networks.A Reconfigurable Communications System for Small SpacecraftNASA Technical Reports Server (NTRS)Chu  Pong P.; Kifle  Muli2004-01-01Two trends of NASA missions are the use of multiple small spacecraft and the development of an integrated space network. To achieve these goals  a robust and agile communications system is needed. Advancements in field programmable gate array (FPGA) technology have made it possible to incorporate major communication and network functionalities in FPGA chips; thus this technology has great potential as the basis for a reconfigurable communications system. This report discusses the requirements of future space communications  reviews relevant issues  and proposes a methodology to design and construct a reconfigurable communications system for small scientific spacecraft.Capacity on wireless quantum cellular communication systemNASA Astrophysics Data System (ADS)Zhou  Xiang-Zhen; Yu  Xu-Tao; Zhang  Zai-Chen2018-03-01Quantum technology is making excellent prospects in future communication networks. Entanglement generation and purification are two major components in quantum networks. Combining these two techniques with classical cellular mobile communication  we proposed a novel wireless quantum cellular(WQC) communication system which is possible to realize commercial mobile quantum communication. In this paper  the architecture and network topology of WQC communication system are discussed  the mathematical model of WQC system is extracted and the serving capacity  indicating the ability to serve customers  is defined and calculated under certain circumstances.Wireless Augmented Reality Communication SystemNASA Technical Reports Server (NTRS)Agan  Martin (Inventor); Devereaux  Ann (Inventor); Jedrey  Thomas (Inventor)2015-01-01A portable unit is for video communication to select a user name in a user name network. A transceiver wirelessly accesses a communication network through a wireless connection to a general purpose node coupled to the communication network. A user interface can receive user input to log on to a user name network through the communication network. The user name network has a plurality of user names  at least one of the plurality of user names is associated with a remote portable unit  logged on to the user name network and available for video communication.Wireless Augmented Reality Communication SystemNASA Technical Reports Server (NTRS)Jedrey  Thomas (Inventor); Agan  Martin (Inventor); Devereaux  Ann (Inventor)2017-01-01A portable unit is for video communication to select a user name in a user name network. A transceiver wirelessly accesses a communication network through a wireless connection to a general purpose node coupled to the communication network. A user interface can receive user input to log on to a user name network through the communication network. The user name network has a plurality of user names  at least one of the plurality of user names is associated with a remote portable unit  logged on to the user name network and available for video communication.Spacecraft Multiple Array Communication System Performance AnalysisNASA Technical Reports Server (NTRS)Hwu  Shian U.; Desilva  Kanishka; Sham  Catherine C.2010-01-01The Communication Systems Simulation Laboratory (CSSL) at the NASA Johnson Space Center is tasked to perform spacecraft and ground network communication system simulations  design validation  and performance verification. The CSSL has developed simulation tools that model spacecraft communication systems and the space and ground environment in which the tools operate. In this paper  a spacecraft communication system with multiple arrays is simulated. Multiple array combined technique is used to increase the radio frequency coverage and data rate performance. The technique is to achieve phase coherence among the phased arrays to combine the signals at the targeting receiver constructively. There are many technical challenges in spacecraft integration with a high transmit power communication system. The array combining technique can improve the communication system data rate and coverage performances without increasing the system transmit power requirements. Example simulation results indicate significant performance improvement can be achieved with phase coherence implementation.Communicative Lighting Preserving Creative Expression by Challenging Standards and Diversifying ApplicationsNASA Astrophysics Data System (ADS)Uchihara  SatoshiThe scope and significance of light on the culture and development of human societies throughout history is nothing short of astounding. From ancient times  light has provided essential substance for life and spirituality  spawning cultural diversity and artistic inspiration around the globe. Indeed  from the rudiments of civilization to the Enlightenment  throughout the Industrial Revolution to contemporary societies  the lighting technology that humankind has brought into this world has enhanced civilizations  driving advances in productivity and ever higher standards of living. And yet  we presently stand at an important crossroads  where evolutionary factors are taking us in new directions  and a choice must be made about the course and meaning of lighting in our lives. Paramount to this issue is the growing significance of LED as a source of light and the behavioral change it is causing within our industry. The technological innovation driven by LED has drastically changed the systems of manufacturing and distribution and  thus  is transforming the economy. Perhaps  equally significant  this influence has begun to alter the philosophy and culture of our industry. The direction of this evolutionary process is not automatic  however. We lighting designers  lighting equipment manufacturers  and astute judges of life quality through lighting  have a choice to lead or be led by recognizing the constraints of industry standards and reactionary views of technology  and what can be done to remain flexible and artistically expressive. In this effort  my belief is that we must remain sensitive to the delicate connection between light and people  as a means to an important new priority that I call Communicative Lighting.Transition From NASA Space Communication Systems to Commerical Communication ProductsNASA Technical Reports Server (NTRS)Ghazvinian  Farzad; Lindsey  William C.1994-01-01Transitioning from twenty-five years of space communication system architecting  engineering and development to creating and marketing of commercial communication system hardware and software products is no simple task for small  high-tech system engineering companies whose major source of revenue has been the U.S. Government. Yet  many small businesses are faced with this onerous and perplexing task. The purpose of this talk/paper is to present one small business (LinCom) approach to taking advantage of the systems engineering expertise and knowledge captured in physical neural networks and simulation software by supporting numerous National Aeronautics and Space Administration (NASA) and the Department of Defense (DoD) projects  e.g.  Space Shuttle  TDRSS  Space Station  DCSC  Milstar  etc. The innovative ingredients needed for a systems house to transition to a wireless communication system products house that supports personal communication services and networks (PCS and PCN) development in a global economy will be discussed. Efficient methods for using past government sponsored space system research and development to transition to VLSI communication chip set products will be presented along with notions of how synergy between government and industry can be maintained to benefit both parties.Considerations for lunar colony communications systemsNASA Technical Reports Server (NTRS)Dowling  Richard P.1992-01-01This paper addresses system aspects of communications for a lunar colony. Human factors are particularly noted. The practical aspects of communications infrastructure are emphasized rather than specific technologies. Communications needs for mission support and morale are discussed along with potential means of satisfying them. Problem areas are identified and some possible solutions are considered.Apollo experience report: Lunar module communications systemNASA Technical Reports Server (NTRS)Dietz  R. H.; Rhoades  D. E.; Davidson  L. J.1972-01-01The development of the lunar module communications system is traced from the initial concept to the operational system used on manned lunar missions. The problems encountered during the development  the corrective actions taken  and recommendations for similar equipment in future programs are included. The system was designed to provide communications between the lunar module and the manned space flight network  between the lunar module and the command and service module  and between the lunar module and the extravehicular crewmen. The system provided the equipment necessary for voice  telemetry  and television communications; ranging information; and various communications links.46 CFR 130.440 - Communications system.Code of Federal Regulations  2010 CFR2010-10-01... 46 Shipping 4 2010-10-01 2010-10-01 false Communications system. 130.440 Section 130.440 Shipping COAST GUARD  DEPARTMENT OF HOMELAND SECURITY (CONTINUED) OFFSHORE SUPPLY VESSELS VESSEL CONTROL  AND MISCELLANEOUS EQUIPMENT AND SYSTEMS Automation of Unattended Machinery Spaces Â§ 130.440 Communications system...Communications and Intelligent Systems Division OverviewNASA Technical Reports Server (NTRS)Emerson  Dawn2017-01-01This presentation provides an overview of the research and engineering work being performed in the competency fields of advanced communications and intelligent systems with emphasis on advanced technologies  architecture definition  and systems development for application in current and future aeronautics and space communications systems.Communications and Intelligent Systems Division - Division OverviewNASA Technical Reports Server (NTRS)Miranda  Felix A.2017-01-01This presentation provides an overview of the research and engineering work being performed in the competency fields of advanced communications and intelligent systems with emphasis on advanced technologies  architecture definition and systems development for application in current and future aeronautics and space communications systems.Communications and Intelligent Systems Division - Division OverviewNASA Technical Reports Server (NTRS)Miranda  Felix A.2017-01-01This presentation provides an overview of the research and engineering work being performed in the competency fields of advanced communications and intelligent systems with emphasis on advanced technologies  architecture definition  and systems development for application in current and future aeronautics and space communications systems.46 CFR 130.440 - Communications system.Code of Federal Regulations  2014 CFR2014-10-01... MISCELLANEOUS EQUIPMENT AND SYSTEMS Automation of Unattended Machinery Spaces Â§ 130.440 Communications system. (a) Each OSV must have a communications system to immediately summon a crew member to the machinery... room  and crew accommodations that eitherâ€” (i) Is a sound-powered telephone; or (ii) Gets its power...46 CFR 130.440 - Communications system.Code of Federal Regulations  2013 CFR2013-10-01... MISCELLANEOUS EQUIPMENT AND SYSTEMS Automation of Unattended Machinery Spaces Â§ 130.440 Communications system. (a) Each OSV must have a communications system to immediately summon a crew member to the machinery... room  and crew accommodations that eitherâ€” (i) Is a sound-powered telephone; or (ii) Gets its power...46 CFR 130.440 - Communications system.Code of Federal Regulations  2011 CFR2011-10-01... MISCELLANEOUS EQUIPMENT AND SYSTEMS Automation of Unattended Machinery Spaces Â§ 130.440 Communications system. (a) Each OSV must have a communications system to immediately summon a crew member to the machinery... room  and crew accommodations that eitherâ€” (i) Is a sound-powered telephone; or (ii) Gets its power...46 CFR 130.440 - Communications system.Code of Federal Regulations  2012 CFR2012-10-01... MISCELLANEOUS EQUIPMENT AND SYSTEMS Automation of Unattended Machinery Spaces Â§ 130.440 Communications system. (a) Each OSV must have a communications system to immediately summon a crew member to the machinery... room  and crew accommodations that eitherâ€” (i) Is a sound-powered telephone; or (ii) Gets its power...Communications and Intelligent Systems Division OverviewNASA Technical Reports Server (NTRS)Emerson  Dawn2017-01-01Provides expertise  and plans  conducts and directs research and engineering development in the competency fields of advanced communications and intelligent systems technologies for applications in current and future aeronautics and space systems.Advances communication systems engineering  development and analysis needed for Glenn Research Center's leadership in communications and intelligent systems technology. Focus areas include advanced high frequency devices  components  and antennas; optical communications  health monitoring and instrumentation; digital signal processing for communications and navigation  and cognitive radios; network architectures  protocols  standards and network-based applications; intelligent controls  dynamics and diagnostics; and smart micro- and nano-sensors and harsh environment electronics. Research and discipline engineering allow for the creation of innovative concepts and designs for aerospace communication systems with reduced size and weight  increased functionality and intelligence. Performs proof-of-concept studies and analyses to assess the impact of the new technologies.Communications and Intelligent Systems Division OverviewNASA Technical Reports Server (NTRS)Emerson  Dawn2016-01-01This presentation provides an overview of the research and engineering in the competency fieldsof advanced communications and intelligent systems with emphasis on advanced technologies  architecture definitionand system development for application in current and future aeronautics and space systems.Advanced integrated WDM system for POF communicationNASA Astrophysics Data System (ADS)Haupt  M.; Fischer  U. H. P.2009-01-01Polymer Optical Fibres (POFs) show clear advantages compared to copper and glass fibres. In essence  POFs are inexpensive  space-saving and not susceptible to electromagnetic interference. Thus  the usage of POFs have become a reasonable alternative in short distance data communication. Today  POFs are applied in a wide number of applications due to these specific advantages. These applications include automotive communication systems and in-house-networks. State-of-the-art is to transmit data with only one channel over POF  this limits the bandwidth. To solve this problem  an integrated MUX/DEMUX-element for WDM over POF is designed and developed to use multiple channels. This integration leads to low costs  therefore this component is suitable for mass market applications. The fundamental idea is to separate the chromatic parts of the light in its monochromatic components by means of a grating based on an aspheric mirror. Due to the high NA of the POF the setup has to be designed in a 3D-approach. Therefore this setup cannot be compared with the planar solutions available on market  they would result high losses in the 3rd dimension. To achieve a fast and optimized design an optical simulation program is used. Particular attention has to be paid to the design of the POF as a light source in the simulation program and the optimisation of the grating. The following realization of the demultiplexer is planed to be done with injection molding. This technology offers easy and very economical processing. These advantages make this technology first choice for optical components in the low-cost array.Nonlinear degradation of a visible-light communication link: A Volterra-series approachNASA Astrophysics Data System (ADS)Kamalakis  Thomas; Dede  Georgia2018-06-01Visible light communications can be used to provide illumination and data communication at the same time. In this paper  a reverse-engineering approach is presented for assessing the impact of nonlinear signal distortion in visible light communication links. The approach is based on the Volterra series expansion and has the advantage of accurately accounting for memory effects in contrast to the static nonlinear models that are popular in the literature. Volterra kernels describe the end-to-end system response and can be inferred from measurements. Consequently  this approach does not rely on any particular physical models and assumptions regarding the individual link components. We provide the necessary framework for estimating the nonlinear distortion on the symbol estimates of a discrete multitone modulated link. Various design aspects such as waveform clipping and predistortion are also incorporated in the analysis. Using this framework  the nonlinear signal-to-interference is calculated for the system at hand. It is shown that at high signal amplitudes  the nonlinear signal-to-interference can be less than 25 dB.Optimization of light quality from color mixing light-emitting diode systems for general lightingNASA Astrophysics Data System (ADS)Thorseth  Anders2012-03-01Given the problem of metamerisms inherent in color mixing in light-emitting diode (LED) systems with more than three distinct colors  a method for optimizing the spectral output of multicolor LED system with regards to standardized light quality parameters has been developed. The composite spectral power distribution from the LEDs are simulated using spectral radiometric measurements of single commercially available LEDs for varying input power  to account for the efficiency droop and other non-linear effects in electrical power vs. light output. The method uses electrical input powers as input parameters in a randomized steepest decent optimization. The resulting spectral power distributions are evaluated with regard to the light quality using the standard characteristics: CIE color rendering index  correlated color temperature and chromaticity distance. The results indicate Pareto optimal boundaries for each system  mapping the capabilities of the simulated lighting systems with regard to the light quality characteristics.Advanced optical fiber communication systemsNASA Astrophysics Data System (ADS)Kazovsky  Leonid G.1994-03-01Our research is focused on three major aspects of advanced optical fiber communication systems: dynamic wavelength division multiplexing (WDM) networks  fiber nonlinearities  and high dynamic range coherent analog optical links. In the area of WDM networks  we have designed and implemented two high-speed interface boards and measured their throughput and latency. Furthermore  we designed and constructed an experimental PSK/ASK transceiver that simultaneously transmits packet-switched ASK data and circuit-switched PSK data on the same optical carrier. In the area of fiber nonlinearities  we investigated the theoretical impact of modulation frequency on cross-phase modulation (XPM) in dispersive fibers. In the area of high dynamic range coherent analog optical links  we developed theoretical expressions for the RF power transfer ratio (or RF power gain) and the noise figure (NF) of angle-modulated links. We then compared the RF power gains and noise figures of these links to that of an intensity modulated direct detection (DD) link.Systems and Methods for Radar Data CommunicationNASA Technical Reports Server (NTRS)Bunch  Brian (Inventor); Szeto  Roland (Inventor); Miller  Brad (Inventor)2013-01-01A radar information processing system is operable to process high bandwidth radar information received from a radar system into low bandwidth radar information that may be communicated to a low bandwidth connection coupled to an electronic flight bag (EFB). An exemplary embodiment receives radar information from a radar system  the radar information communicated from the radar system at a first bandwidth; processes the received radar information into processed radar information  the processed radar information configured for communication over a connection operable at a second bandwidth  the second bandwidth lower than the first bandwidth; and communicates the radar information from a radar system  the radar information communicated from the radar system at a first bandwidth.33 CFR 127.1109 - Lighting systems.Code of Federal Regulations  2013 CFR2013-07-01... 33 Navigation and Navigable Waters 2 2013-07-01 2013-07-01 false Lighting systems. 127.1109 Section 127.1109 Navigation and Navigable Waters COAST GUARD  DEPARTMENT OF HOMELAND SECURITY (CONTINUED... Waterfront Facilities Handling Liquefied Hazardous Gas Design and Construction Â§ 127.1109 Lighting systems...33 CFR 127.1109 - Lighting systems.Code of Federal Regulations  2014 CFR2014-07-01... 33 Navigation and Navigable Waters 2 2014-07-01 2014-07-01 false Lighting systems. 127.1109 Section 127.1109 Navigation and Navigable Waters COAST GUARD  DEPARTMENT OF HOMELAND SECURITY (CONTINUED... Waterfront Facilities Handling Liquefied Hazardous Gas Design and Construction Â§ 127.1109 Lighting systems...33 CFR 127.1109 - Lighting systems.Code of Federal Regulations  2011 CFR2011-07-01... 33 Navigation and Navigable Waters 2 2011-07-01 2011-07-01 false Lighting systems. 127.1109 Section 127.1109 Navigation and Navigable Waters COAST GUARD  DEPARTMENT OF HOMELAND SECURITY (CONTINUED... Waterfront Facilities Handling Liquefied Hazardous Gas Design and Construction Â§ 127.1109 Lighting systems...33 CFR 127.1109 - Lighting systems.Code of Federal Regulations  2012 CFR2012-07-01... 33 Navigation and Navigable Waters 2 2012-07-01 2012-07-01 false Lighting systems. 127.1109 Section 127.1109 Navigation and Navigable Waters COAST GUARD  DEPARTMENT OF HOMELAND SECURITY (CONTINUED... Waterfront Facilities Handling Liquefied Hazardous Gas Design and Construction Â§ 127.1109 Lighting systems...Hybrid solar lighting distribution systems and componentsDOEpatentsMuhs  Jeffrey D [Lenoir City  TN; Earl  Dennis D [Knoxville  TN; Beshears  David L [Knoxville  TN; Maxey  Lonnie C [Powell  TN; Jordan  John K [Oak Ridge  TN; Lind  Randall F [Lenoir City  TN2011-07-05A hybrid solar lighting distribution system and components having at least one hybrid solar concentrator  at least one fiber receiver  at least one hybrid luminaire  and a light distribution system operably connected to each hybrid solar concentrator and each hybrid luminaire. A controller operates all components.Hybrid solar lighting systems and componentsDOEpatentsMuhs  Jeffrey D [Lenoir City  TN; Earl  Dennis D [Knoxville  TN; Beshears  David L [Knoxville  TN; Maxey  Lonnie C [Powell  TN; Jordan  John K [Oak Ridge  TN; Lind  Randall F [Lenoir City  TN2007-06-12A hybrid solar lighting system and components having at least one hybrid solar concentrator  at least one fiber receiver  at least one hybrid luminaire  and a light distribution system operably connected to each hybrid solar concentrator and each hybrid luminaire. A controller operates each component.33 CFR 127.1109 - Lighting systems.Code of Federal Regulations  2010 CFR2010-07-01... 33 Navigation and Navigable Waters 2 2010-07-01 2010-07-01 false Lighting systems. 127.1109 Section 127.1109 Navigation and Navigable Waters COAST GUARD  DEPARTMENT OF HOMELAND SECURITY (CONTINUED... Waterfront Facilities Handling Liquefied Hazardous Gas Design and Construction Â§ 127.1109 Lighting systems...A Future of Communication Theory: Systems Theory.ERIC Educational Resources Information CenterLindsey  Georg N.Concepts of general systems theory  cybernetics and the like may provide the methodology for communication theory to move from a level of technology to a level of pure science. It was the purpose of this paper to (1) demonstrate the necessity of applying systems theory to the construction of communication theory  (2) review relevant systemsâ€¦Performance Information Management System (PIMS) CommunicationDTIC Science & Technology1992-10-15AD-A267 040 AD 14IPR NO: 92Mâ€¢2501 TITLE: PERFORMANCE INFORMATION MANAGEMENT SYSTEM (PIMS) COMMUNICATION V G  cÂ¶â€¢ PRINCIPAL INVESTIGATOR: Kathryn P...Performance Information Management System (PIMS) MIPR No. Communication 92MM2501 6. AUTHOR(S) Kathryn P. Winter 7. PERFORMING ORGANIZATION NAME(S) ANDPerformance Information Management System (PIMS) CommunicationDTIC Science & Technology1993-12-3134AD-A284 851 AD MIPR NO. MIPR 92MM2501 TITLE: Performance Information Management System (PIMS) Communication PRINCIPAL INVESTIGATOR: Kathryn P...93 . . ..- F â€¢nal . 12/1/91 - 12/31/93- ...... . ..... PIMS-Performance Information Management System Communications 92MM2501 Kathryn P. Winter NavyEffects of Picture Exchange Communication System on Communication and Behavioral Anomalies in AutismPubMed CentralMalhotra  Shahzadi; Rajender  Gaurav; Bhatia  Manjeet S.; Singh  Tej B.2010-01-01Communication skills deficits and stereotyped behaviors are frequently found among people with pervasive developmental disabilities like autism. These communication and behavioral oddities of autism are often considered to be difficult to treat and are challenging. Picture exchange communication system (PECS) is a six-phase picture system based on applied behavior analysis and is specially designed to overcome these communication difficulties in children with autism by encouraging the child to be the communication initiator. The present paper throws light on the process of using PECS along with other traditional behavioral approaches in managing communication deficits and behavioral stereotypies in a seven-year-old male child diagnosed as having childhood autism. The identified target behaviors of repeated head turning  flapping his hands  poor communication skills were assessed using various rating scales including visual analogue scale as per clinician observation and parental reports and managed using PECS as an adjunct to traditional behavioral techniques of contingency management  differential reinforcement  task direction and reprimand. Outcome was assessed using same tools after thirty-two sessions of interventions spread over three months. Significant improvements of around 60% were observed in the target behaviors. PMID:21716776Effects of picture exchange communication system on communication and behavioral anomalies in autism.PubMedMalhotra  Shahzadi; Rajender  Gaurav; Bhatia  Manjeet S; Singh  Tej B2010-07-01Communication skills deficits and stereotyped behaviors are frequently found among people with pervasive developmental disabilities like autism. These communication and behavioral oddities of autism are often considered to be difficult to treat and are challenging. Picture exchange communication system (PECS) is a six-phase picture system based on applied behavior analysis and is specially designed to overcome these communication difficulties in children with autism by encouraging the child to be the communication initiator. The present paper throws light on the process of using PECS along with other traditional behavioral approaches in managing communication deficits and behavioral stereotypies in a seven-year-old male child diagnosed as having childhood autism. The identified target behaviors of repeated head turning  flapping his hands  poor communication skills were assessed using various rating scales including visual analogue scale as per clinician observation and parental reports and managed using PECS as an adjunct to traditional behavioral techniques of contingency management  differential reinforcement  task direction and reprimand. Outcome was assessed using same tools after thirty-two sessions of interventions spread over three months. Significant improvements of around 60% were observed in the target behaviors.Representation of chromatic distribution for lighting systemNASA Astrophysics Data System (ADS)Rossi  Maurizio; Musante  Fulvio2015-01-01For the luminaire manufacturer  the measurement of the lighting intensity distribution (LID) emitted by lighting fixture is based on photometry. So light is measured as an achromatic value of intensity and there is no the possibility to discriminate the measurement of white vs. colored light. At the Laboratorio Luce of Politecnico di Milano a new instrument for the measurement of spectral radiant intensities distribution for lighting system has been built: the goniospectra- radiometer. This new measuring tool is based on a traditional mirror gonio-photometer with a CCD spectraradiometer controlled by a PC. Beside the traditional representation of photometric distribution we have introduced a new representation where  in addition to the information about the distribution of luminous intensity in space  new details about the chromaticity characteristic of the light sources have been implemented. Some of the results of this research have been applied in developing and testing a new line of lighting system ""My White Light"" (the research project ""Light  Environment and Humans"" funded in the Italian Lombardy region Metadistretti Design Research Program involving Politecnico di Milano  Artemide  Danese  and some other SME of the Lighting Design district)  giving scientific notions and applicative in order to support the assumption that colored light sources can be used for the realization of interior luminaries that  other than just have low power consumption and long life  may positively affect the mood of people.Streetlight Control System Based on Wireless Communication over DALI ProtocolPubMed CentralBellido-OuteiriÃ±o  Francisco JosÃ©; Quiles-Latorre  Francisco Javier; Moreno-Moreno  Carlos Diego; Flores-Arias  JosÃ© MarÃ­a; Moreno-GarcÃ­a  Isabel; Ortiz-LÃ³pez  Manuel2016-01-01Public lighting represents a large part of the energy consumption of towns and cities. Efficient management of public lighting can entail significant energy savings. This work presents a smart system for managing public lighting networks based on wireless communication and the DALI protocol. Wireless communication entails significant economic savings  as there is no need to install new wiring and visual impacts and damage to the facades of historical buildings in city centers are avoided. The DALI protocol uses bidirectional communication with the ballast  which allows its status to be controlled and monitored at all times. The novelty of this work is that it tackles all aspects related to the management of public lighting: a standard protocol  DALI  was selected to control the ballast  a wireless node based on the IEEE 802.15.4 standard with a DALI interface was designed  a network layer that considers the topology of the lighting network has been developed  and lastly  some user-friendly applications for the control and maintenance of the system by the technical crews of the different towns and cities have been developed. PMID:27128923System Would Predictively Preempt Traffic Lights for Emergency VehiclesNASA Technical Reports Server (NTRS)Bachelder  Aaron; Foster  Conrad2004-01-01Two electronic communication-and-control systems have been proposed as means of modifying the switching of traffic lights to give priority to emergency vehicles. Both systems would utilize the inductive loops already installed in the streets of many municipalities to detect vehicles for timing the switching of traffic lights. The proposed systems could be used alone or to augment other automated emergency traffic-light preemption systems that are already present in some municipalities  including systems that recognize flashing lights or siren sounds or that utilize information on the positions of emergency vehicles derived from the Global Positioning System (GPS). Systems that detect flashing lights and siren sounds are limited in range  cannot ""see"" or ""hear"" well around corners  and are highly vulnerable to noise. GPS-based systems are effective in rural areas and small cities  but are often ineffective in large cities because of frequent occultation of GPS satellite signals by large structures. In contrast  the proposed traffic-loop forward prediction system would be relatively invulnerable to noise  would not be subject to significant range limitations  and would function well in large cities -- even in such places as underneath bridges and in tunnels  where GPS-based systems do not work. One proposed system has been characterized as ""car-active"" because each participating emergency vehicle would be equipped with a computer and a radio transceiver that would communicate with stationary transceivers at the traffic loops. The other proposed system has been characterized as ""car-passive"" because a passive radio transponder would be installed on the underside of a participating vehicle.System Models of Information  Communication and Mass Communication: Revaluation of Some Basic Concepts of Communication.ERIC Educational Resources Information CenterWiio  Osmo A.A more unified approach to communication theory can evolve through systems modeling of information theory  communication modes  and mass media operations. Such systematic analysis proposes  as is the case care here  that information models be based upon combinations of energy changes and exchanges and changes in receiver systems. The mass media isâ€¦LED Context Lighting System in Residential AreasPubMed CentralIm  Kyoung-Mi2014-01-01As issues of environment and energy draw keen interest around the globe due to such problems as global warming and the energy crisis  LED with high optical efficiency is brought to the fore as the next generation lighting. In addition  as the national income level gets higher and life expectancy is extended  interest in the enhancement of life quality is increasing. Accordingly  the trend of lightings is changing from mere adjustment of light intensity to system lighting in order to enhance the quality of one's life as well as reduce energy consumption. Thus  this study aims to design LED context lighting system that automatically recognizes the location and acts of a user in residential areas and creates an appropriate lighting environment. The proposed system designed in this study includes three types of processing: first  the creation of a lighting environment index suitable for the user's surroundings and lighting control scenarios and second  it measures and analyzes the optical characteristics that change depending on the dimming control of lighting and applies them to the index. Lastly  it adopts PIR  piezoelectric  and power sensor to grasp the location and acts of the user and create a lighting environment suitable for the current context. PMID:25101325ETS-VI multibeam satellite communications systemsNASA Astrophysics Data System (ADS)Kawai  Makoto; Tanaka  Masayoshi; Ohtomo  Isao1989-10-01The fixed and mobile satellite communications systems of the Japanese Engineering Test Satellite-VI (ETS-VI) are described. The system requirements are outlined along with the system configuration. The ETS-VI multibeam system employs three frequency bands. When used for Ka-band fixed communications  it covers the Japanese main islands with thirteen 0.3-degree-wide spot beam. Four of the beams are active for ETS-VI. When used for S-band mobile communications  five beams cover the area within 200 nautical miles from the Japanese coast. The C-band beam for fixed communications covers the central area of the Japanese main islands with a single beam. The onboard antenna system is described along with the transponders and their associated onboard systems. A discussion of the system technology follows  covering the TDMA transmisssion system  the relay function  rainfall compensation  and the antenna and propagation performance.Optimal pulse design for communication-oriented slow-light pulse detection.PubMedStenner  Michael D; Neifeld  Mark A2008-01-21We present techniques for designing pulses for linear slow-light delay systems which are optimal in the sense that they maximize the signal-to-noise ratio (SNR) and signal-to-noise-plus-interference ratio (SNIR) of the detected pulse energy. Given a communication model in which input pulses are created in a finite temporal window and output pulse energy in measured in a temporally-offset output window  the SNIR-optimal pulses achieve typical improvements of 10 dB compared to traditional pulse shapes for a given output window offset. Alternatively  for fixed SNR or SNIR  window offset (detection delay) can be increased by 0.3 times the window width. This approach also invites a communication-based model for delay and signal fidelity.Performance enhancement technique of visible light communications using passive photovoltaic cellNASA Astrophysics Data System (ADS)Wu  Jhao-Ting; Chow  Chi-Wai; Liu  Yang; Hsu  Chin-Wei; Yeh  Chien-Hung2017-06-01The light emitting diode (LED) based visible light communication (VLC) system can provide lighting and communication simultaneously. It has attracted much attenuation recently. As the photovoltaic cell (also known as solar cell) is physically flexible  low cost  and easily available  it could be a good choice for the VLC receiver (Rx). Furthermore  besides acting as the VLC Rx  the solar cell can convert VLC signal into electricity for charging up the Rx devices. Hence  it could be a promising candidate for the future internet-of-thing (IoT) networks. However  using solar cell as VLC Rx is challenging  since the response of the solar cell is highly limited and it will limit the VLC data rate. In this work  we propose and demonstrate for the first time using pre-distortion Manchester coding (MC) signal to enhance the signal performance of solar cell Rx based VLC. The proposed scheme can significantly mitigate the slow response  as well as the direct-current (DC) wandering effect of the solar cell; hence 50 times increase in data rate can be experimentally achieved.Satellite Communication Hardware Emulation System (SCHES)NASA Technical Reports Server (NTRS)Kaplan  Ted1993-01-01Satellite Communication Hardware Emulator System (SCHES) is a powerful simulator that emulates the hardware used in TDRSS links. SCHES is a true bit-by-bit simulator that models communications hardware accurately enough to be used as a verification mechanism for actual hardware tests on user spacecraft. As a credit to its modular design  SCHES is easily configurable to model any user satellite communication link  though some development may be required to tailor existing software to user specific hardware.Roadside-based communication system and methodNASA Technical Reports Server (NTRS)Bachelder  Aaron D. (Inventor)2007-01-01A roadside-based communication system providing backup communication between emergency mobile units and emergency command centers. In the event of failure of a primary communication  the mobile units transmit wireless messages to nearby roadside controllers that may take the form of intersection controllers. The intersection controllers receive the wireless messages  convert the messages into standard digital streams  and transmit the digital streams along a citywide network to a destination intersection or command center.Remote monitoring of LED lighting system performanceNASA Astrophysics Data System (ADS)Thotagamuwa  Dinusha R.; Perera  Indika U.; Narendran  Nadarajah2016-09-01The concept of connected lighting systems using LED lighting for the creation of intelligent buildings is becoming attractive to building owners and managers. In this application  the two most important parameters include power demand and the remaining useful life of the LED fixtures. The first enables energy-efficient buildings and the second helps building managers schedule maintenance services. The failure of an LED lighting system can be parametric (such as lumen depreciation) or catastrophic (such as complete cessation of light). Catastrophic failures in LED lighting systems can create serious consequences in safety critical and emergency applications. Therefore  both failure mechanisms must be considered and the shorter of the two must be used as the failure time. Furthermore  because of significant variation between the useful lives of similar products  it is difficult to accurately predict the life of LED systems. Real-time data gathering and analysis of key operating parameters of LED systems can enable the accurate estimation of the useful life of a lighting system. This paper demonstrates the use of a data-driven method (Euclidean distance) to monitor the performance of an LED lighting system and predict its time to failure.Multi-band transmission color filters for multi-color white LEDs based visible light communicationNASA Astrophysics Data System (ADS)Wang  Qixia; Zhu  Zhendong; Gu  Huarong; Chen  Mengzhu; Tan  Qiaofeng2017-11-01Light-emitting diodes (LEDs) based visible light communication (VLC) can provide license-free bands  high data rates  and high security levels  which is a promising technique that will be extensively applied in future. Multi-band transmission color filters with enough peak transmittance and suitable bandwidth play a pivotal role for boosting signal-noise-ratio in VLC systems. In this paper  multi-band transmission color filters with bandwidth of dozens nanometers are designed by a simple analytical method. Experiment results of one-dimensional (1D) and two-dimensional (2D) tri-band color filters demonstrate the effectiveness of the multi-band transmission color filters and the corresponding analytical method.A new encoding scheme for visible light communications with applications to mobile connectionsNASA Astrophysics Data System (ADS)Benton  David M.; St. John Brittan  Paul2017-10-01A new  novel and unconventional encoding scheme called concurrent coding  has recently been demonstrated and shown to offer interesting features and benefits in comparison to conventional techniques  such as robustness against burst errors and improved efficiency of transmitted power. Free space optical communications can suffer particularly from issues of alignment which requires stable  fixed links to be established and beam wander which can interrupt communications. Concurrent coding has the potential to help ease these difficulties and enable mobile  flexible optical communications to be implemented through the use of a source encoding technique. This concept has been applied for the first time to optical communications where standard light emitting diodes (LEDs) have been used to transmit information encoded with concurrent coding. The technique successfully transmits and decodes data despite unpredictable interruptions to the transmission causing significant drop-outs to the detected signal. The technique also shows how it is possible to send a single block of data in isolation with no pre-synchronisation required between transmitter and receiver  and no specific synchronisation sequence appended to the transmission. Such systems are robust against interference - intentional or otherwise - as well as intermittent beam blockage.A 1000+ channel bionic communication system.PubMedSchulman  Joseph H; Mobley  J Phil; Wolfe  James; Stover  Howard; Krag  Adrian2006-01-01The wireless electronic nervous system interface known as the functional electrical stimulation-battery powered bion system is being developed at the Alfred Mann Foundation. It contains a real-time propagated wave micro-powered multichannel communication system. This system is designed to send bi-directional messages between an external master controller unit (MCU)  and each one of a group of injectable stimulator-sensor battery powered bion implants (BPB). The system is capable of communicating in each direction about 90 times per second using a structure of 850 time slots within a repeating 11 millisecond time window. The system's total Time Division Multiple Access (TDMA) communication capability is about 77 000 two-way communications per second on a single 5 MHz wide radio channel. Each time slot can be used by one BPB  or shared alternately by two or more BPBs. Each bidirectional communication consists of a 15 data bit message sent from the MCU sequentially to each BPB and 10 data bit message sent sequentially from each BPB to the MCU. Redundancy bits are included to provide error detection and correction. This communication system is designed to draw only a few microamps from the 3.6 volt  3.0 mAHr lithium ion (LiIon) battery contained in each BPB  and the majority of the communications circuitry is contained within a 1.4x5 mm integrated circuit.Preliminary Thoughts on Netted Cable Communication Systems.ERIC Educational Resources Information CenterEldridge  Frank; Mason  WilliamThere are five categories of cable communication systems: Conventional Community Antenna Television (CATV)  Pay-TV  Subscriber Response Systems  Electronic Information Handling Systems  and Two-Way Audio/Visual Systems. CATV and Pay-TV systems are designed for the one-way transmission of programs  the former providing for better qualityâ€¦How to Bootstrap a Human Communication SystemERIC Educational Resources Information CenterFay  Nicolas; Arbib  Michael; Garrod  Simon2013-01-01How might a human communication system be bootstrapped in the absence of conventional language? We argue that motivated signs play an important role (i.e.  signs that are linked to meaning by structural resemblance or by natural association). An experimental study is then reported in which participants try to communicate a range of pre-specifiedâ€¦Electronic Subsystems For Laser Communication SystemNASA Technical Reports Server (NTRS)Long  Catherine; Maruschak  John; Patschke  Robert; Powers  Michael1992-01-01Electronic subsystems of free-space laser communication system carry digital signals at 650 Mb/s over long distances. Applicable to general optical communications involving transfer of great quantities of data  and transmission and reception of video images of high definition.Strategic Choices for Data Communications Systems.ERIC Educational Resources Information CenterArns  Robert G.; Urban  Patricia A.Issues and strategies for developing a campus data communications system are discussed. It is suggested that individual microcomputer (MC) workstations will occasionally have a need for (1) access  via a data communications network  to a more powerful processor; (2) specialized software; (3) sophisticated output devices; (4) central data sets; orâ€¦Communications Processor Operating System Study. Executive Summary DTIC Science & Technology1980-11-01AD-A095 b36 ROME AIR DEVELOPMENT CENTER GRIFFISS AFB NY F/e 17/2 COMMUNICATIONS PROCESSOR OPERATING SYSTEM STUDY. EXECUTIVE SUMMâ€”ETC(U) NOV 80 J...COMMUNICATIONS PROCESSOR OPERATING SYSTEM STUDY Julian Gitlih SPTIC ELECTEÂ«^ FEfi 2 6 1981^ - E APPROVED FOR PUBLIC RELEASE; DISTRIBUTION UNLIMITED ""a O...Subtitle) EXECUTIVE^SUMMARY 0F> COMMUNICATIONS PROCESSOR OPERATING SYSTEM $t - â€¢ >X W tdLl - ’â€¢â€¢ â€¢ 7 AUTHORfÂ«! !   JulianColor coded multiple access scheme for bidirectional multiuser visible light communications in smart home technologiesNASA Astrophysics Data System (ADS)Tiwari  Samrat Vikramaditya; Sewaiwar  Atul; Chung  Yeon-Ho2015-10-01In optical wireless communications  multiple channel transmission is an attractive solution to enhancing capacity and system performance. A new modulation scheme called color coded multiple access (CCMA) for bidirectional multiuser visible light communications (VLC) is presented for smart home applications. The proposed scheme uses red  green and blue (RGB) light emitting diodes (LED) for downlink and phosphor based white LED (P-LED) for uplink to establish a bidirectional VLC and also employs orthogonal codes to support multiple users and devices. The downlink transmission for data user devices and smart home devices is provided using red and green colors from the RGB LEDs  respectively  while uplink transmission from both types of devices is performed using the blue color from P-LEDs. Simulations are conducted to verify the performance of the proposed scheme. It is found that the proposed bidirectional multiuser scheme is efficient in terms of data rate and performance. In addition  since the proposed scheme uses RGB signals for downlink data transmission  it provides flicker-free illumination that would lend itself to multiuser VLC system for smart home applications.Piezo-Phototronic Effect Controlled Dual-Channel Visible light Communication (PVLC) Using InGaN/GaN Multiquantum Well Nanopillars.PubMedDu  Chunhua; Jiang  Chunyan; Zuo  Peng; Huang  Xin; Pu  Xiong; Zhao  Zhenfu; Zhou  Yongli; Li  Linxuan; Chen  Hong; Hu  Weiguo; Wang  Zhong Lin2015-12-02Visible light communication (VLC) simultaneously provides illumination and communication via light emitting diodes (LEDs). Keeping a low bit error rate is essential to communication quality  and holding a stable brightness level is pivotal for illumination function. For the first time  a piezo-phototronic effect controlled visible light communication (PVLC) system based on InGaN/GaN multiquantum wells nanopillars is demonstrated  in which the information is coded by mechanical straining. This approach of force coding is also instrumental to avoid LED blinks  which has less impact on illumination and is much safer to eyes than electrical on/off VLC. The two-channel transmission mode of the system here shows great superiority in error self-validation and error self-elimination in comparison to VLC. This two-channel PVLC system provides a suitable way to carry out noncontact  reliable communication under complex circumstances. Â© 2015 WILEY-VCH Verlag GmbH & Co. KGaA  Weinheim.Automobile inspection system based on wireless communicationNASA Astrophysics Data System (ADS)Miao  Changyun; Ye  Chunqing2010-07-01This paper aims to research the Automobile Inspection System based on Wireless Communication  and suggests an overall design scheme which uses GPS for speed detection and Bluetooth and GPRS for communication. The communication between PDA and PC was realized by means of GPRS and TCP/IP; and the hardware circuit and software for detection terminal were devised by means of JINOU-3264 Bluetooth Module after analyzing the Bluetooth and its communication protocol. According to the results of debugging test  this system accomplished GPRS based data communication and management as well as the real-time detection on auto safety performance parameters in crash test via PC  whereby the need for mobility and reliability was met and the efficiency and level of detection was improved.A Review and Analysis of the Picture Exchange Communication System (PECS) for Individuals With Autism Spectrum Disorders Using a Paradigm of Communication CompetenceERIC Educational Resources Information CenterOstryn  Cheryl; Wolfe  Pamela S.; Rusch  Frank R.2008-01-01Research related to the use of the Picture Exchange Communication System (PECS) with individuals having autism spectrum disorders (ASDs) was examined using a communication competence paradigm detailed by J. C. Light (1988  1989  2003). Communication components were operationalized based on skills identified in ASD research. A review was conductedâ€¦System Design for Nano-Network CommunicationsNASA Astrophysics Data System (ADS)ShahMohammadian  HodaThe potential applications of nanotechnology in a wide range of areas necessities nano-networking research. Nano-networking is a new type of networking which has emerged by applying nanotechnology to communication theory. Therefore  this dissertation presents a framework for physical layer communications in a nano-network and addresses some of the pressing unsolved challenges in designing a molecular communication system. The contribution of this dissertation is proposing well-justified models for signal propagation  noise sources  optimum receiver design and synchronization in molecular communication channels. The design of any communication system is primarily based on the signal propagation channel and noise models. Using the Brownian motion and advection molecular statistics  separate signal propagation and noise models are presented for diffusion-based and flow-based molecular communication channels. It is shown that the corrupting noise of molecular channels is uncorrelated and non-stationary with a signal dependent magnitude. The next key component of any communication system is the reception and detection process. This dissertation provides a detailed analysis of the effect of the ligand-receptor binding mechanism on the received signal  and develops the first optimal receiver design for molecular communications. The bit error rate performance of the proposed receiver is evaluated and the impact of medium motion on the receiver performance is investigated. Another important feature of any communication system is synchronization. In this dissertation  the first blind synchronization algorithm is presented for the molecular communication channels. The proposed algorithm uses a non-decision directed maximum likelihood criterion for estimating the channel delay. The Cramer-Rao lower bound is also derived and the performance of the proposed synchronization algorithm is evaluated by investigating its mean square error.Systems Theory and Communication. Annotated Bibliography.ERIC Educational Resources Information CenterCovington  William G.  Jr.This annotated bibliography presents annotations of 31 books and journal articles dealing with systems theory and its relation to organizational communication  marketing  information theory  and cybernetics. Materials were published between 1963 and 1992 and are listed alphabetically by author. (RS)Tyurin in Zvezda with communication systemNASA Image and Video Library2007-02-24ISS014-E-14765 (24 Feb. 2007) --- Cosmonaut Mikhail Tyurin  Expedition 14 flight engineer representing Russia's Federal Space Agency  uses a communication system in the Zvezda Service Module of the International Space Station.Communication Systems for Dual Mode TransportationDOT National Transportation Integrated Search1974-02-01A program is underway to develop and demonstrate transportation systems based on vehicles which are capable of automatic operation on special guideways and manual operation on conventional roads. Adequate and reliable communications to and from vehic...Student Involvement Through a Communication SystemERIC Educational Resources Information CenterBromley  Phillip1975-01-01The communication system outlined in this article rests on the assumption that schools can operate on a rational  well-ordered  democratic base of shared involvement. Idealistic? Many schools have instituted or are interested in instituting a similar plan. (Editor)A design of Si-based nanoplasmonic structure as an antenna and reception amplifier for visible light communicationSciTech ConnectYan  J. H.; Lin  Z. Y.; Liu  P.2014-10-21Visible light communication has been widely investigated due to its larger bandwidth and higher bit rate  and it can combine with the indoor illumination system that makes it more convenient to carry out. Receiving and processing the visible light signal on chip request for nanophotonics devices performing well. However  conventional optical device cannot be used for light-on-chip integration at subwavelength dimensions due to the diffraction limit. Herein  we propose a design of Si-based nanoplasmonic structure as an antenna and reception amplifier for visible light communication based on the interaction between Si nanoparticle and Au nanorod. This device integrates the uniquemoreÂ Â» scattering property of high-refractive index dielectric Si nanoparticles  whose scattering spectrum is dependent on the particle size  with the localized surface plasmon resonance of Au nanorod. We calculated the spectra collected by plane detector and near field distribution of nanostructure  and theoretically demonstrate that the proposed device can act as good receiver  amplifier and superlens during the visible light signal receiving and processing. Besides  unlike some other designs of nanoantenna devices focused less on how to detect the signals  our hybrid nanoantenna can realize the transfer between the scattering source and the detector effectively by Au nanorod waveguides. These findings suggest that the designed nanoplasmonic structure is expected to be used in on-chip nanophotonics as antenna  spectral splitter and demultiplexer for visible light communication.Â«Â lessA model for plant lighting system selection.PubMedCiolkosz  D E; Albright  L D; Sager  J C; Langhans  R W2002-01-01A decision model is presented that compares lighting systems for a plant growth scenario and chooses the most appropriate system from a given set of possible choices. The model utilizes a Multiple Attribute Utility Theory approach  and incorporates expert input and performance simulations to calculate a utility value for each lighting system being considered. The system with the highest utility is deemed the most appropriate system. The model was applied to a greenhouse scenario  and analyses were conducted to test the model's output for validity. Parameter variation indicates that the model performed as expected. Analysis of model output indicates that differences in utility among the candidate lighting systems were sufficiently large to give confidence that the model's order of selection was valid.14 CFR 23.1385 - Position light system installation.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Position light system installation. 23.1385... Lights Â§ 23.1385 Position light system installation. (a) General. Each part of each position light system... requirements of Â§Â§ 23.1387 through 23.1397. (b) Left and right position lights. Left and right position lights...14 CFR 23.1385 - Position light system installation.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Position light system installation. 23.1385... Lights Â§ 23.1385 Position light system installation. (a) General. Each part of each position light system... requirements of Â§Â§ 23.1387 through 23.1397. (b) Left and right position lights. Left and right position lights...14 CFR 23.1385 - Position light system installation.Code of Federal Regulations  2012 CFR2012-01-01... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Position light system installation. 23.1385... Lights Â§ 23.1385 Position light system installation. (a) General. Each part of each position light system... requirements of Â§Â§ 23.1387 through 23.1397. (b) Left and right position lights. Left and right position lights...14 CFR 23.1385 - Position light system installation.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Position light system installation. 23.1385... Lights Â§ 23.1385 Position light system installation. (a) General. Each part of each position light system... requirements of Â§Â§ 23.1387 through 23.1397. (b) Left and right position lights. Left and right position lights...Reflector system for a lighting fixtureDOEpatentsSiminovitch  Michael J.; Page  Erik; Gould  Carl T.1998-01-01Disclosed herein is a reflector system for a lighting fixture having a illumination source surrounded by an envelope. The reflector system includes a first reflector surrounding the illumination source. The reflector system also includes a second reflector which is non-contiguous with the first reflector and which surrounds the illumination source. The illumination source creates light rays which are reflected by the first and second reflectors. The first reflector directs light rays toward the center line of the fixture. However  the reflected rays despite being so reflected do not substantially intersect the envelope. The reflected light rays from the second reflector being directed so that they diverge from the center line of the fixture avoiding intersection with the semi-transparent envelope.Reflector system for a lighting fixtureDOEpatentsSiminovitch  Michael J.; Page  Erik; Gould  Carl T.2001-01-01Disclosed herein is a reflector system for a lighting fixture having a illumination source surrounded by an envelope. The reflector system includes a first reflector surrounding the illumination source. The reflector system also includes a second reflector which is non-contiguous with the first reflector and which surrounds the illumination source. The illumination source creates light rays which are reflected by the first and second reflectors. The first reflector directs light rays toward the center line of the fixture. However  the reflected rays despite being so reflected do not substantially intersect the envelope. The reflected light rays from the second reflector being directed so that they diverge from the center line of the fixture avoiding intersection with the semi-transparent envelope.Reflector system for a lighting fixtureDOEpatentsSiminovitch  M.J.; Page  E.; Gould  C.T.1998-09-08Disclosed herein is a reflector system for a lighting fixture having a illumination source surrounded by an envelope. The reflector system includes a first reflector surrounding the illumination source. The reflector system also includes a second reflector which is non-contiguous with the first reflector and which surrounds the illumination source. The illumination source creates light rays which are reflected by the first and second reflectors. The first reflector directs light rays toward the center line of the fixture. However  the reflected rays despite being so reflected do not substantially intersect the envelope. The reflected light rays from the second reflector being directed so that they diverge from the center line of the fixture avoiding intersection with the semi-transparent envelope. 5 figs.Research on target information optics communications transmission characteristic and performance in multi-screens testing systemNASA Astrophysics Data System (ADS)Li  Hanshan2016-04-01To enhance the stability and reliability of multi-screens testing system  this paper studies multi-screens target optical information transmission link properties and performance in long-distance  sets up the discrete multi-tone modulation transmission model based on geometric model of laser multi-screens testing system and visible light information communication principle; analyzes the electro-optic and photoelectric conversion function of sender and receiver in target optical information communication system; researches target information transmission performance and transfer function of the generalized visible-light communication channel; found optical information communication transmission link light intensity space distribution model and distribution function; derives the SNR model of information transmission communication system. Through the calculation and experiment analysis  the results show that the transmission error rate increases with the increment of transmission rate in a certain channel modulation depth; when selecting the appropriate transmission rate  the bit error rate reach 0.01.Study of LED layout in indoor visible light communication and performance analysisNASA Astrophysics Data System (ADS)Wang  Jiaan; Che  Ying; Wang  Xinlan; Guo  Linyang; Li  Jing2017-10-01Light emitting diodes(LED) could provide both illumination and data communication in indoor visible light communication(VLC) that owns the modulation bandwith from several from several MHz to seneral hundreds of MHz. The layout of LED plays an important role in maintaining a steady optical power distribution over the receiving plane. The existing rectangular LED layout does not provide a full coverage on the receiving plane leaving receiving optical power outage area  which in turn affects the best performance of the VLC system. This paper design a circular layout scheme of LED in 5mX5mX3m room based on the criterion of the illumination minimum mean square deviation. The influence of the distribution of the intensity of illumination with the radius of 1m and 1.5m for including the wall reflection and not including the wall reflection  and make a comparison with rectangular LED layout of illumination distribution  when the number of LEDs with rectangular layout as same as circular layout. Including the number of LEDs are 4 and 16.For a specific simulation parameters as following:height of receiving plane is 0.85m a single LEDs is composed of 60X60 LED chips  the parameters of a single chip is that transmitting power is 20mW center luminous intensity is 0.73cd.semiangle at half power is 70deg.The parameters of concentrator is that photodiode area is 1cm2 photodiode responsivity is 0.4 field of view at the receiver is 85deg.Other parameters are that reflective index of concentrator is 1.5 reflectivity of wall is 0.8.Circular layout and rectangular layout are analyzed through simulation of the received optical power distribution  signal noise ratio distribution in non line of sight(including the wall reflection) and line of sight(not including the wall reflection) when the number of the LED is different. It is clear from the results that the received optical power distribution of non line of sight is better than line of sight  when the number of the LED are same  butTricolor R/G/B Laser Diode Based Eye-Safe White Lighting Communication Beyond 8â€‰Gbit/s.PubMedWu  Tsai-Chen; Chi  Yu-Chieh; Wang  Huai-Yung; Tsai  Cheng-Ting; Huang  Yu-Fang; Lin  Gong-Ru2017-01-31White light generation by mixing red  green  and blue laser diodes (RGB LDs) was demonstrated with Commission International de l'Eclairage coordinates of (0.2928  0.2981)  a correlated color temperature of 8382â€‰K  and a color rendering index of 54.4 to provide a maximal illuminance of 7540 lux. All the white lights generated using RGB LDs were set within the risk group-1 criterion to avoid the blue-light hazard to human eyes. In addition  the RGB-LD mixed white light was diffused using a frosted glass to avoid optical aberration and to improve the performance of the lighting source. In addition  visible light communication (VLC) by using RGB-LD mixed white-light carriers and a point-to-point scheme over 1â€‰m was performed in the directly modulated 16-QAM OFDM data format. In back-to-back transmission  the maximal allowable data rate at 10.8  10.4  and 8â€‰Gbps was determined for R  G  and B LDs  respectively. Moreover  the RGB-LD mixed white light-based indoor wavelength-division multiplexing (WDM)-VLC system yielded a total allowable transmission data rate of 8.8â€‰Gbps over 0.5â€‰m in free space. Such a high-speed RGB-LD mixed WDM-VLC system without any channel interference can be used to simultaneously provide data transmission and white lighting in an indoor environment.Matrix light and pixel light: optical system architecture and requirements to the light sourceNASA Astrophysics Data System (ADS)Spinger  Benno; Timinger  Andreas L.2015-09-01Modern Automotive headlamps enable improved functionality for more driving comfort and safety. Matrix or Pixel light headlamps are not restricted to either pure low beam functionality or pure high beam. Light in direction of oncoming traffic is selectively switched of  potential hazard can be marked via an isolated beam and the illumination on the road can even follow a bend. The optical architectures that enable these advanced functionalities are diverse. Electromechanical shutters and lens units moved by electric motors were the first ways to realize these systems. Switching multiple LED light sources is a more elegant and mechanically robust solution. While many basic functionalities can already be realized with a limited number of LEDs  an increasing number of pixels will lead to more driving comfort and better visibility. The required optical system needs not only to generate a desired beam distribution with a high angular dynamic  but also needs to guarantee minimal stray light and cross talk between the different pixels. The direct projection of the LED array via a lens is a simple but not very efficient optical system. We discuss different optical elements for pre-collimating the light with minimal cross talk and improved contrast between neighboring pixels. Depending on the selected optical system  we derive the basic light source requirements: luminance  surface area  contrast  flux and color homogeneity.Tags  wireless communication systems  tag communication methods  and wireless communications methodsDOEpatentsScott ; Jeff W.   Pratt; Richard  M [Richland  WA2006-09-12Tags  wireless communication systems  tag communication methods  and wireless communications methods are described. In one aspect  a tag includes a plurality of antennas configured to receive a plurality of first wireless communication signals comprising data from a reader  a plurality of rectifying circuits coupled with. respective individual ones of the antennas and configured to provide rectified signals corresponding to the first wireless communication signals  wherein the rectified signals are combined to produce a composite signal  an adaptive reference circuit configured to vary a reference signal responsive to the composite signal  a comparator coupled with the adaptive reference circuit and the rectifying circuits and configured to compare the composite signal with respect to the reference signal and to output the data responsive to the comparison  and processing circuitry configured to receive the data from the comparator and to process the data.Early Communication System (ECOMM) for ISSNASA Technical Reports Server (NTRS)Gaylor  Kent; Tu  Kwei1999-01-01The International Space Station (ISS) Early Communications System (ECOMM) was a Johnson Space Center (JSC) Avionic Systems Division (ASD) in-house developed communication system to provide early communications between the ISS and the Mission Control Center-Houston (MCC-H). This system allows for low rate commands (link rate of 6 kbps) to be transmitted through the Tracking and Data Relay Satellite System (TDRSS) from MCC-H to the ISS using TDRSS's S-band Single Access Forward (SSA/) link service. This system also allows for low rate telemetry (link rate of 20.48 kbps) to be transmitted from ISS to MCC-H through the TDRSS using TDRSS's S-band Single Access Return (SSAR) link service. In addition this system supports a JSC developed Onboard Communications Adapter (OCA) that allows for a two-way data exchange of 128 kbps between MCC-H and the ISS through TDRSS. This OCA data can be digital video/audio (two-way videoconference)  and/or file transfers  and/or ""white board"". The key components of the system  the data formats used by the system to insure compatibility with the future ISS S-Band System  as well as how other vehicles may be able to use this system for their needs are discussed in this paper.Multi-dimensional spatial light communication made with on-chip InGaN photonic integrationNASA Astrophysics Data System (ADS)Yang  Yongchao; Zhu  Bingcheng; Shi  Zheng; Wang  Jinyuan; Li  Xin; Gao  Xumin; Yuan  Jialei; Li  Yuanhang; Jiang  Yan; Wang  Yongjin2017-04-01Here  we propose  fabricate and characterize suspended photonic integration of InGaN multiple-quantum-well light-emitting diode (MQW-LED)  waveguide and InGaN MQW-photodetector on a single chip. The unique light emission property of InGaN MQW-LED makes it feasible to establish multi-dimensional spatial data transmission using visible light. The in-plane light communication system is comprised of InGaN MQW-LED  waveguide and InGaN MQW-photodetector  and the out-of-plane data transmission is realized by detecting the free-space light emission via a commercial photodiode module. Moreover  a full-duplex light communication is experimentally demonstrated at a data transmission rate of 50 Mbps when both InGaN MQW-diodes operate under simultaneous light emission and detection mode. The in-plane superimposed signals are able to be extracted through the self-interference cancellation method  and the out-of-plane superimposed signals are in good agreement with the calculated signals according to the extracted transmitted signals. These results are promising for the development of on-chip InGaN photonic integration for diverse applications.Light-emitting device test systemsSciTech ConnectMcCord  Mark; Brodie  Alan; George  JamesLight-emitting devices  such as LEDs  are tested using a photometric unit. The photometric unit  which may be an integrating sphere  can measure flux  color  or other properties of the devices. The photometric unit may have a single port or both an inlet and outlet. Light loss through the port  inlet  or outlet can be reduced or calibrated for. These testing systems can provide increased reliability  improved throughput  and/or improved measurement accuracy.Multiagent robotic systems' ambient light sensorNASA Astrophysics Data System (ADS)Iureva  Radda A.; Maslennikov  Oleg S.; Komarov  Igor I.2017-05-01Swarm robotics is one of the fastest growing areas of modern technology. Being subclass of multi-agent systems it inherits the main part of scientific-methodological apparatus of construction and functioning of practically useful complexes  which consist of rather autonomous independent agents. Ambient light sensors (ALS) are widely used in robotics. But speaking about swarm robotics  the technology which has great number of specific features and is developing  we can't help mentioning that its important to use sensors on each robot not only in order to help it to get directionally oriented  but also to follow light emitted by robot-chief or to help to find the goal easier. Key words: ambient light sensor  swarm system  multiagent system  robotic system  robotic complexes  simulation modellingFull-duplex optical communication systemNASA Technical Reports Server (NTRS)Shay  Thomas M. (Inventor); Hazzard  David A. (Inventor); Horan  Stephen (Inventor); Payne  Jason A. (Inventor)2004-01-01A method of full-duplex electromagnetic communication wherein a pair of data modulation formats are selected for the forward and return data links respectively such that the forward data electro-magnetic beam serves as a carrier for the return data. A method of encoding optical information is used wherein right-hand and left-hand circular polarizations are assigned to optical information to represent binary states. An application for an earth to low earth orbit optical communications system is presented which implements the full-duplex communication and circular polarization keying modulation format.A native IP satellite communications systemNASA Astrophysics Data System (ADS)Koudelka  O.; Schmidt  M.; Ebert  J.; Schlemmer  H.; Kastner-Puschl  S.; Riedler  W.2004-08-01â‰ª In the framework of ESA's ARTES-5 program the Institute of Applied Systems Technology (Joanneum Research) in cooperation with the Department of Communications and Wave Propagation has developed a novel meshed satellite communications system which is optimised for Internet traffic and applications (L*IPâ€”Local Network Interconnection via Satellite Systems Using the IP Protocol Suite). Both symmetrical and asymmetrical connections are supported. Bandwidth on demand and guaranteed quality of service are key features of the system. A novel multi-frequency TDMA access scheme utilises efficient methods of IP encapsulation. In contrast to other solutions it avoids legacy transport network techniques. While the DVB-RCS standard is based on ATM or MPEG transport cells  the solution of the L*IP system uses variable-length cells which reduces the overhead significantly. A flexible and programmable platform based on Linux machines was chosen to allow the easy implementation and adaptation to different standards. This offers the possibility to apply the system not only to satellite communications  but provides seamless integration with terrestrial fixed broadcast wireless access systems. The platform is also an ideal test-bed for a variety of interactive broadband communications systems. The paper describes the system architecture and the key features of the system.New medical workstation for multimodality communication systemsNASA Astrophysics Data System (ADS)Kotsopoulos  Stavros A.; Lymberopoulos  Dimitris C.1993-07-01The introduction of special teleworking and advanced remote expert consultation procedures in the modern multimodality medical communication systems  has an effective result in the way of confronting synchronous and asynchronous patient cases  by the physicians. The common denominator in developing the above procedures is to use special designated Medical Workstations (MWS). The present paper deals with the implementation of a MWS which facilitates the doctors of medicine to handle efficiently multimedia data in an ISDN communication environment.A 30 Mbps in-plane full-duplex light communication using a monolithic GaN photonic circuitNASA Astrophysics Data System (ADS)Gao  Xumin; Yuan  Jialei; Yang  Yongchao; Li  Yuanhang; Yuan  Wei; Zhu  Guixia; Zhu  Hongbo; Feng  Meixin; Sun  Qian; Liu  Yuhuai; Wang  Yongjin2017-07-01We propose  fabricate and characterize photonic integration of a InGaN/GaN multiple-quantum-well light-emitting diode (MQW-LED)  waveguide  ring resonator and InGaN/GaN MQW-photodiode on a single chip  in which the photonic circuit is suspended by the support beams. Both experimental observations and simulation results illustrate the manipulation of in-plane light coupling and propagation by the waveguide and the ring resonator. The monolithic photonic circuit forms an in-plane data communication system using visible light. When the two suspended InGaN/GaN MQW-diodes simultaneously serve as the transmitter and the receiver  an in-plane full-duplex light communication is experimentally demonstrated with a transmission rate of 30 Mbps  and the superimposed signals are extracted using the self-interference cancellation method. The suspended photonic circuit creates new possibilities for exploring the in-plane full-duplex light communication and manufacturing complex GaN-based monolithic photonic integrations.A systems approach to animal communication.PubMedHebets  Eileen A; Barron  Andrew B; Balakrishnan  Christopher N; Hauber  Mark E; Mason  Paul H; Hoke  Kim L2016-03-16Why animal communication displays are so complex and how they have evolved are active foci of research with a long and rich history. Progress towards an evolutionary analysis of signal complexity  however  has been constrained by a lack of hypotheses to explain similarities and/or differences in signalling systems across taxa. To address this  we advocate incorporating a systems approach into studies of animal communication--an approach that includes comprehensive experimental designs and data collection in combination with the implementation of systems concepts and tools. A systems approach evaluates overall display architecture  including how components interact to alter function  and how function varies in different states of the system. We provide a brief overview of the current state of the field  including a focus on select studies that highlight the dynamic nature of animal signalling. We then introduce core concepts from systems biology (redundancy  degeneracy  pluripotentiality  and modularity) and discuss their relationships with system properties (e.g. robustness  flexibility  evolvability). We translate systems concepts into an animal communication framework and accentuate their utility through a case study. Finally  we demonstrate how consideration of the system-level organization of animal communication poses new practical research questions that will aid our understanding of how and why animal displays are so complex. Â© 2016 The Author(s).On-Demand Sensor Node Wake-Up Using Solar Panels and Visible Light CommunicationPubMed CentralCarrascal  Carolina; Demirkol  Ilker; Paradells  Josep2016-01-01To significantly reduce  or eliminate completely  the energy waste caused by the standby (idle) mode of wireless sensor nodes  we propose a novel on-demand wake-up system  which allows the nodes to be put into sleep mode unless their activation is truly necessary. Although there have been many studies proposing RF-based wake-up radio systems  in this work  we develop the first visible light communication (VLC)-based wake-up system. The developed system can extend the existing VLC systems and can be exploited to derive new application areas such as VLC tags. The system uses an off-the-shell indoor solar panel as receptor device of the wake-up signal as well as for energy harvesting purposes  through which it is able to harvest enough energy for its autonomous work. The design  implementation details and the experimental evaluation results are presented  which include flickering characterization and wake-up range evaluations. The results show that the developed system achieve reasonable wake-up distances for indoor environments  mainly where the use of VLC systems are considered. PMID:27011190On-Demand Sensor Node Wake-Up Using Solar Panels and Visible Light Communication.PubMedCarrascal  Carolina; Demirkol  Ilker; Paradells  Josep2016-03-22To significantly reduce  or eliminate completely  the energy waste caused by the standby (idle) mode of wireless sensor nodes  we propose a novel on-demand wake-up system  which allows the nodes to be put into sleep mode unless their activation is truly necessary. Although there have been many studies proposing RF-based wake-up radio systems  in this work  we develop the first visible light communication (VLC)-based wake-up system. The developed system can extend the existing VLC systems and can be exploited to derive new application areas such as VLC tags. The system uses an off-the-shell indoor solar panel as receptor device of the wake-up signal as well as for energy harvesting purposes  through which it is able to harvest enough energy for its autonomous work. The design  implementation details and the experimental evaluation results are presented  which include flickering characterization and wake-up range evaluations. The results show that the developed system achieve reasonable wake-up distances for indoor environments  mainly where the use of VLC systems are considered.Fiber Optic Communication System For Medical ImagesNASA Astrophysics Data System (ADS)Arenson  Ronald L.; Morton  Dan E.; London  Jack W.1982-01-01This paper discusses a fiber optic communication system linking ultrasound devices  Computerized tomography scanners  Nuclear Medicine computer system  and a digital fluoro-graphic system to a central radiology research computer. These centrally archived images are available for near instantaneous recall at various display consoles. When a suitable laser optical disk is available for mass storage  more extensive image archiving will be added to the network including digitized images of standard radiographs for comparison purposes and for remote display in such areas as the intensive care units  the operating room  and selected outpatient departments. This fiber optic system allows for a transfer of high resolution images in less than a second over distances exceeding 2 000 feet. The advantages of using fiber optic cables instead of typical parallel or serial communication techniques will be described. The switching methodology and communication protocols will also be discussed.School Planning  Evaluation and Communication System (SPECS).ERIC Educational Resources Information CenterFlocco  Edward C.A comprehensive school planning tool is available from General Learning Corporation and the Center for the Advanced Study of Educational Administration at the University of Oregon. This School Planning  Evaluation and Communication System (SPECS) provides a deliverable system of training  implementation strategies and materials and technicalâ€¦A Systemic Perspective of Communication and Sexism.ERIC Educational Resources Information CenterDrecksel  DebraCommunication and sexism are analyzed from a systemic perspective  illustrating how sexism is perpetuated through sexist interaction and symbol systems. Sexism is shown to be a disease in our society  which creates a societal situation with double-binding sex-role symbols which limit our adaptability. A remedy for sexism is suggested whichâ€¦Small Drinking Water Systems Communication and Outreach ...EPA Pesticide FactsheetsAs part of our small drinking water systems efforts  this poster highlights several communications and outreach highlights that EPA's Office of Research and Development and Office of Water have been undertaking in collaboration with states and the Association of State Drinking Water Administrators. To share information at EPA's annual small drinking water systems workshopCommunication  Systems  and Misconduct with Adolescent StudentsERIC Educational Resources Information CenterHargrave  Terry D.; Brammer  Robert2006-01-01This article examines communication and system issues in dealing with misconduct in adolescents. The initial focus is an analysis of the goals of misconduct  including attention  power  revenge  and display of inadequacy. The second focus encourages the school system to consider its own part in the problems of misconduct  by examining circularâ€¦A Wireless Communications Systems Laboratory CourseERIC Educational Resources Information CenterGuzelgoz  Sabih; Arslan  Huseyin2010-01-01A novel wireless communications systems laboratory course is introduced. The course teaches students how to design  test  and simulate wireless systems using modern instrumentation and computer-aided design (CAD) software. One of the objectives of the course is to help students understand the theoretical concepts behind wireless communicationâ€¦Leveraging brightness from transportation lighting systems through light source color.DOT National Transportation Integrated Search2013-11-01Roadway transportation lighting is installed for multiple reasons including traffic safety and pedestrian : security. Judgments of pedestrian safety and security along roadways are not strictly correlated to : specified light levels  but the color of...RDS-SL VS Communication SystemSciTech Connect2012-09-12The RDS-SL VS Communication System is a component of the Radiation Detection System for Strategic  Low-Volume Seaports. Its purpose is to acquire real-time data from radiation portal monitors and cameras  record that data in a database  and make it available to system operators and administrators via a web interface. The software system contains two components: a standalone data acquisition and storage component and an ASP.NETweb application that implements the web interface.Space Station communications and tracking systemNASA Technical Reports Server (NTRS)Dietz  Reinhold H.1987-01-01A comprehensive description of the existing Space Station communications and tracking system requirements  architecture  and design concepts is provided. Areas which will require innovative solutions to provide cost-effective flight systems are emphasized. Among these are the space-to-space links  the differential global positioning system for determining relative position with free-flying vehicles  multitarget radar  packet/isochronous signal processing  and laser docking systems. In addition  the importance of advanced development  tests  and analyses is summarized.New gonioscopy system using only infrared light.PubMedSugimoto  Kota; Ito  Kunio; Matsunaga  Koichi; Miura  Katsuya; Esaki  Koji; Uji  Yukitaka2005-08-01To describe an infrared gonioscopy system designed to observe the anterior chamber angle under natural mydriasis in a completely darkened room. An infrared light filter was used to modify the light source of the slit-lamp microscope. A television monitor connected to a CCD monochrome camera was used to indirectly observe the angle. Use of the infrared system enabled observation of the angle under natural mydriasis in a completely darkened room. Infrared gonioscopy is a useful procedure for the observation of the angle under natural mydriasis.Pilot Evaluations of Runway Status Light SystemNASA Technical Reports Server (NTRS)Young  Steven D.; Wills  Robert W.; Smith  R. Marshall1996-01-01This study focuses on use of the Transport Systems Research Vehicle (TSRV) Simulator at the Langley Research Center to obtain pilot opinion and input on the Federal Aviation Administration's Runway Status Light System (RWSL) prior to installation in an operational airport environment. The RWSL has been designed to reduce the likelihood of runway incursions by visually alerting pilots when a runway is occupied. Demonstrations of the RWSL in the TSRV Simulator allowed pilots to evaluate the system in a realistic cockpit environment.Microelectromechanical Systems (MEMS) Broadband Light Source DevelopedNASA Technical Reports Server (NTRS)Tuma  Margaret L.2003-01-01A miniature  low-power broadband light source has been developed for aerospace applications  including calibrating spectrometers and powering miniature optical sensors. The initial motivation for this research was based on flight tests of a Fabry-Perot fiberoptic temperature sensor system used to detect aircraft engine exhaust gas temperature. Although the feasibility of the sensor system was proven  the commercial light source optically powering the device was identified as a critical component requiring improvement. Problems with the light source included a long stabilization time (approximately 1 hr)  a large amount of heat generation  and a large input electrical power (6.5 W). Thus  we developed a new light source to enable the use of broadband optical sensors in aerospace applications. Semiconductor chip-based light sources  such as lasers and light-emitting diodes  have a relatively narrow range of emission wavelengths in comparison to incandescent sources. Incandescent light sources emit broadband radiation from visible to infrared wavelengths; the intensity at each wavelength is determined by the filament temperature and the materials chosen for the filament and the lamp window. However  present commercial incandescent light sources are large in size and inefficient  requiring several watts of electrical power to obtain the desired optical power  and they emit a large percentage of the input power as heat that must be dissipated. The miniature light source  developed jointly by the NASA Glenn Research Center  the Jet Propulsion Laboratory  and the Lighting Innovations Institute  requires one-fifth the electrical input power of some commercial light sources  while providing similar output light power that is easily coupled to an optical fiber. Furthermore  it is small  rugged  and lightweight. Microfabrication technology was used to reduce the size  weight  power consumption  and potential cost-parameters critical to future aerospace applications. This chip14 CFR 27.1401 - Anticollision light system.Code of Federal Regulations  2012 CFR2012-01-01... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Anticollision light system. 27.1401 Section... AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...14 CFR 29.1401 - Anticollision light system.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Anticollision light system. 29.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...14 CFR 27.1401 - Anticollision light system.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Anticollision light system. 27.1401 Section... AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...14 CFR 27.1401 - Anticollision light system.Code of Federal Regulations  2013 CFR2013-01-01... 14 Aeronautics and Space 1 2013-01-01 2013-01-01 false Anticollision light system. 27.1401 Section... AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...14 CFR 27.1401 - Anticollision light system.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Anticollision light system. 27.1401 Section... AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...14 CFR 29.1401 - Anticollision light system.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Anticollision light system. 29.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...14 CFR 27.1401 - Anticollision light system.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Anticollision light system. 27.1401 Section... AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...14 CFR 29.1401 - Anticollision light system.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Anticollision light system. 29.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1401 Anticollision light system. (a... light system thatâ€” (1) Consists of one or more approved anticollision lights located so that their...Performance Test for the SIGMA Communication SystemNASA Astrophysics Data System (ADS)Jeong  Seonyeong; Lee  Hyojeong; Lee  Seongwhan; Shin  Jehyuck; Lee  Jungkyu; Jin  Ho2016-12-01Scientific CubeSat with Instruments for Global Magnetic Fields and Radiations (SIGMA) is a 3-U size CubeSat that will be operated in low earth orbit (LEO). The SIGMA communication system uses a very high frequency (VHF) band for uplink and an ultra high frequency (UHF) band for downlink. Both frequencies belong to an amateur band. The ground station that communicates with SIGMA is located at Kyung Hee Astronomical Observatory (KHAO). For reliable communication  we carried out a laboratory (LAB) test and far-field tests between the CubeSat and a ground station. In the field test  we considered test parameters such as attenuation  antenna deployment  CubeSat body attitude  and Doppler frequency shift in transmitting commands and receiving data. In this paper  we present a communication performance test of SIGMA  a link budget analysis  and a field test process. We also compare the link budget with the field test results of transmitting commands and receiving data.Shuttle payload S-band communications systemNASA Technical Reports Server (NTRS)Batson  B. H.; Teasdale  W. E.; Pawlowski  J. F.; Schmidt  O. L.1985-01-01The Shuttle payload S-band communications system design  operational capabilities  and performance are described in detail. System design requirements  overall system and configuration and operation  and laboratory/flight test results are presented. Payload communications requirements development is discussed in terms of evolvement of requirements as well as the resulting technical challenges encountered in meeting the initial requirements. Initial design approaches are described along with cost-saving initiatives that subsequently had to be made. The resulting system implementation that was finally adopted is presented along with a functional description of the system operation. A description of system test results  problems encountered  how the problems were solved  and the system flight experience to date is presented. Finally  a summary of the advancements made and the lessons learned is discussed.Communication Simulations for Power System ApplicationsSciTech ConnectFuller  Jason C.; Ciraci  Selim; Daily  Jeffrey A.2013-05-29New smart grid technologies and concepts  such as dynamic pricing  demand response  dynamic state estimation  and wide area monitoring  protection  and control  are expected to require considerable communication resources. As the cost of retrofit can be high  future power grids will require the integration of high-speed  secure connections with legacy communication systems  while still providing adequate system control and security. While considerable work has been performed to create co-simulators for the power domain with load models and market operations  limited work has been performed in integrating communications directly into a power domain solver. The simulation of communication and power systemsmoreÂ Â» will become more important as the two systems become more inter-related. This paper will discuss ongoing work at Pacific Northwest National Laboratory to create a flexible  high-speed power and communication system co-simulator for smart grid applications. The framework for the software will be described  including architecture considerations for modular  high performance computing and large-scale scalability (serialization  load balancing  partitioning  cross-platform support  etc.). The current simulator supports the ns-3 (telecommunications) and GridLAB-D (distribution systems) simulators. Ongoing and future work will be described  including planned future expansions for a traditional transmission solver. A test case using the co-simulator  utilizing a transactive demand response system created for the Olympic Peninsula and AEP gridSMART demonstrations  requiring two-way communication between distributed and centralized market devices  will be used to demonstrate the value and intended purpose of the co-simulation environment.Â«Â lessUniversal light-switchable gene promoter systemDOEpatentsQuail  Peter H.; Huq  Enamul; Tepperman  James; Sato  Sae2005-02-22An artificial promoter system that can be fused upstream of any desired gene enabling reversible induction or repression of the expression of the gene at will in any suitable host cell or organisms by light is described. The design of the system is such that a molecule of the plant photoreceptor phytochrome is targeted to the specific DNA binding site in the promoter by a protein domain that is fused to the phytochrome and that specifically recognizes this binding site. This bound phytochrome  upon activation by light  recruits a second fusion protein consisting of a protein that binds to phytochrome only upon light activation and a transcriptional activation domain that activates expression of the gene downstream of the promoter.Fiber-Optic Communications Systems DTIC Science & Technology1983-12-15inherent noise level and a large dynamic diapason. Usually  an amplifier with reverse reaction  which is composed of a preamplifier and wide band amplifier...which are attached to a preamplifier on the base of an FET transistor and has an amplification of of around of 20 dB  an adaptation part and a low...systems are used to connect anti-submarine sonar to computers for signal processing. One such transmission line can connect 52 parallel channels with aCommunications data delivery system analysis task 2 report : high-level options for secure communications data delivery systems.DOT National Transportation Integrated Search2012-05-16This Communications Data Delivery System Analysis Task 2 report describes and analyzes options for Vehicle to Vehicle (V2V) and Vehicle to Infrastructure (V2I) communications data delivery systems using various communication media (Dedicated Short Ra...Space Station communications system design and analysisNASA Technical Reports Server (NTRS)Ratliff  J. E.1986-01-01Attention is given to the methodologies currently being used as the framework within which the NASA Space Station's communications system is to be designed and analyzed. A key aspect of the CAD/analysis system being employed is its potential growth in size and capabilities  since Space Station design requirements will continue to be defined and modified. The Space Station is expected to furnish communications between itself and astronauts on EVA  Orbital Maneuvering Vehicles  Orbital Transfer Vehicles  Space Shuttle orbiters  free-flying spacecraft  coorbiting platforms  and the Space Shuttle's own Mobile Service Center.A small terminal for satellite communication systemsNASA Technical Reports Server (NTRS)Xiong  Fuqin; Wu  Dong; Jin  Min1994-01-01A small portable  low-cost satellite communications terminal system incorporating a modulator/demodulator and convolutional-Viterbi coder/decoder is described. Advances in signal processing and error-correction techniques in combination with higher power and higher frequencies aboard satellites allow for more efficient use of the space segment. This makes it possible to design small economical earth stations. The Advanced Communications Technology Satellite (ACTS) was chosen to test the system. ACTS  operating at the Ka band incorporates higher power  higher frequency  frequency and spatial reuse using spot beams and polarization.How to bootstrap a human communication system.PubMedFay  Nicolas; Arbib  Michael; Garrod  Simon2013-01-01How might a human communication system be bootstrapped in the absence of conventional language? We argue that motivated signs play an important role (i.e.  signs that are linked to meaning by structural resemblance or by natural association). An experimental study is then reported in which participants try to communicate a range of pre-specified items to a partner using repeated non-linguistic vocalization  repeated gesture  or repeated non-linguistic vocalization plus gesture (but without using their existing language system). Gesture proved more effective (measured by communication success) and more efficient (measured by the time taken to communicate) than non-linguistic vocalization across a range of item categories (emotion  object  and action). Combining gesture and vocalization did not improve performance beyond gesture alone. We experimentally demonstrate that gesture is a more effective means of bootstrapping a human communication system. We argue that gesture outperforms non-linguistic vocalization because it lends itself more naturally to the production of motivated signs. Â© 2013 Cognitive Science Society  Inc.Evolution of a radio communication relay systemNASA Astrophysics Data System (ADS)Nguyen  Hoa G.; Pezeshkian  Narek; Hart  Abraham; Burmeister  Aaron; Holz  Kevin; Neff  Joseph; Roth  Leif2013-05-01Providing long-distance non-line-of-sight control for unmanned ground robots has long been recognized as a problem  considering the nature of the required high-bandwidth radio links. In the early 2000s  the DARPA Mobile Autonomous Robot Software (MARS) program funded the Space and Naval Warfare Systems Center (SSC) Pacific to demonstrate a capability for autonomous mobile communication relaying on a number of Pioneer laboratory robots. This effort also resulted in the development of ad hoc networking radios and software that were later leveraged in the development of a more practical and logistically simpler system  the Automatically Deployed Communication Relays (ADCR). Funded by the Joint Ground Robotics Enterprise and internally by SSC Pacific  several generations of ADCR systems introduced increasingly more capable hardware and software for automatic maintenance of communication links through deployment of static relay nodes from mobile robots. This capability was finally tapped in 2010 to fulfill an urgent need from theater. 243 kits of ruggedized  robot-deployable communication relays were produced and sent to Afghanistan to extend the range of EOD and tactical ground robots in 2012. This paper provides a summary of the evolution of the radio relay technology at SSC Pacific  and then focuses on the latest two stages  the Manually-Deployed Communication Relays and the latest effort to automate the deployment of these ruggedized and fielded relay nodes.Illuminating system and method for specialized and decorative lighting using liquid light guidesDOEpatentsZorn  Carl J.; Kross  Brian J.; Majewski  Stanislaw; Wojcik  Randolph F.1998-01-01The present invention comprises an illumination system for specialized decorative lighting including a light source  a flexible plastic tube sheath for distributing the light to a remote location  a transparent liquid core filling the tube that has an index of refraction greater than that of the plastic tube and an arrangement where light coupled from the light source is caused to leak from the liquid light guide at desired locations for the purposes of specialized lighting  such as underwater illumination in swimming pools.Electronics systems test laboratory testing of shuttle communications systemsNASA Technical Reports Server (NTRS)Stoker  C. J.; Bromley  L. K.1985-01-01Shuttle communications and tracking systems space to space and space to ground compatibility and performance evaluations are conducted in the NASA Johnson Space Center Electronics Systems Test Laboratory (ESTL). This evaluation is accomplished through systems verification/certification tests using orbiter communications hardware in conjunction with other shuttle communications and tracking external elements to evaluate end to end system compatibility and to verify/certify that overall system performance meets program requirements before manned flight usage. In this role  the ESTL serves as a multielement major ground test facility. The ESTL capability and program concept are discussed. The system test philosophy for the complex communications channels is described in terms of the major phases. Results of space to space and space to ground systems tests are presented. Several examples of the ESTL's unique capabilities to locate and help resolve potential problems are discussed in detail.Parallel processing spacecraft communication systemNASA Technical Reports Server (NTRS)Bolotin  Gary S. (Inventor); Donaldson  James A. (Inventor); Luong  Huy H. (Inventor); Wood  Steven H. (Inventor)1998-01-01An uplink controlling assembly speeds data processing using a special parallel codeblock technique. A correct start sequence initiates processing of a frame. Two possible start sequences can be used; and the one which is used determines whether data polarity is inverted or non-inverted. Processing continues until uncorrectable errors are found. The frame ends by intentionally sending a block with an uncorrectable error. Each of the codeblocks in the frame has a channel ID. Each channel ID can be separately processed in parallel. This obviates the problem of waiting for error correction processing. If that channel number is zero  however  it indicates that the frame of data represents a critical command only. That data is handled in a special way  independent of the software. Otherwise  the processed data further handled using special double buffering techniques to avoid problems from overrun. When overrun does occur  the system takes action to lose only the oldest data.A systems approach to animal communicationPubMed CentralBarron  Andrew B.; Balakrishnan  Christopher N.; Hauber  Mark E.; Hoke  Kim L.2016-01-01Why animal communication displays are so complex and how they have evolved are active foci of research with a long and rich history. Progress towards an evolutionary analysis of signal complexity  however  has been constrained by a lack of hypotheses to explain similarities and/or differences in signalling systems across taxa. To address this  we advocate incorporating a systems approach into studies of animal communicationâ€”an approach that includes comprehensive experimental designs and data collection in combination with the implementation of systems concepts and tools. A systems approach evaluates overall display architecture  including how components interact to alter function  and how function varies in different states of the system. We provide a brief overview of the current state of the field  including a focus on select studies that highlight the dynamic nature of animal signalling. We then introduce core concepts from systems biology (redundancy  degeneracy  pluripotentiality  and modularity) and discuss their relationships with system properties (e.g. robustness  flexibility  evolvability). We translate systems concepts into an animal communication framework and accentuate their utility through a case study. Finally  we demonstrate how consideration of the system-level organization of animal communication poses new practical research questions that will aid our understanding of how and why animal displays are so complex. PMID:26936240A packet switched communications system for GRONASA Astrophysics Data System (ADS)Husain  Shabu; Yang  Wen-Hsing; Vadlamudi  Rani; Valenti  Joseph1993-11-01This paper describes the packet switched Instrumenters Communication System (ICS) that was developed for the Command Management Facility at GSFC to support the Gamma Ray Observatory (GRO) spacecraft. The GRO ICS serves as a vital science data acquisition link to the GRO scientists to initiate commands for their spacecraft instruments. The system is ready to send and receive messages at any time  24 hours a day and seven days a week. The system is based on X.25 and the International Standard Organization's (ISO) 7-layer Open Systems Interconnection (OSI) protocol model and has client and server components. The components of the GRO ICS are discussed along with how the Communications Subsystem for Interconnection (CSFI) and Network Control Program Packet Switching Interface (NPSI) software are used in the system.Experimental demonstration of OFDM/OQAM transmission with DFT-based channel estimation for visible laser light communicationsNASA Astrophysics Data System (ADS)He  Jing; Shi  Jin; Deng  Rui; Chen  Lin2017-08-01Recently  visible light communication (VLC) based on light-emitting diodes (LEDs) is considered as a candidate technology for fifth-generation (5G) communications  VLC is free of electromagnetic interference and it can simplify the integration of VLC into heterogeneous wireless networks. Due to the data rates of VLC system limited by the low pumping efficiency  small output power and narrow modulation bandwidth  visible laser light communication (VLLC) system with laser diode (LD) has paid more attention. In addition  orthogonal frequency division multiplexing/offset quadrature amplitude modulation (OFDM/OQAM) is currently attracting attention in optical communications. Due to the non-requirement of cyclic prefix (CP) and time-frequency domain well-localized pulse shapes  it can achieve high spectral efficiency. Moreover  OFDM/OQAM has lower out-of-band power leakage so that it increases the system robustness against inter-carrier interference (ICI) and frequency offset. In this paper  a Discrete Fourier Transform (DFT)-based channel estimation scheme combined with the interference approximation method (IAM) is proposed and experimentally demonstrated for VLLC OFDM/OQAM system. The performance of VLLC OFDM/OQAM system with and without DFT-based channel estimation is investigated. Moreover  the proposed DFT-based channel estimation scheme and the intra-symbol frequency-domain averaging (ISFA)-based method are also compared for the VLLC OFDM/OQAM system. The experimental results show that  the performance of EVM using the DFT-based channel estimation scheme is improved about 3dB compared with the conventional IAM method. In addition  the DFT-based channel estimation scheme can resist the channel noise effectively than that of the ISFA-based method.White House Communications Agency (WHCA) Presidential Voice Communications Rack Mount System Mechanical Drawing PackageDTIC Science & Technology2015-12-01Rack Mount System Mechanical Drawing Package by Steven P Callaway Approved for public release; distribution unlimited...Laboratory White House Communications Agency (WHCA) Presidential Voice Communications Rack Mount System Mechanical Drawing Package by Steven P...Note 3. DATES COVERED (From - To) 04/2013 4. TITLE AND SUBTITLE White House Communications Agency (WHCA) Presidential Voice Communications RackConstruction of a Communication Audit: An Examination of Communication Systems and Their Effectiveness.ERIC Educational Resources Information CenterPeterson  Brent D.  Ed.; Greenbaum  Howard H.  Ed.Abstracts of 12 papers concerning the effectiveness of various communication systems are printed here. Subjects of the papers are: the appraisal of organizational communication systems  and evaluation of ECCO analysis as a communication audit methodology  assessment of attitude and opinion change effects of the communication audit  organizationalâ€¦Strategic Choices for Data Communications Systems.ERIC Educational Resources Information CenterArns  Robert G.; Urban  Patricia A.1984-01-01Issues in determining how to develop a data communications system at colleges and universities are discussed including; technical requirements; cost; implications for coordination and (de)centralization of hardware/software; deciding when to create a data network; data security  information integrity  and organizational development. (Author/MLW)Communications and Tracking Distributed Systems Evolution StudyNASA Technical Reports Server (NTRS)Culpepper  William1990-01-01The Communications and Tracking (C & T) techniques and equipment to support evolutionary space station concepts are being analyzed. Evolutionary space station configurations and operational concepts are used to derive the results to date. A description of the C & T system based on future capability needs is presented. Included are the hooks and scars currently identified to support future growth.MMIC technology for advanced space communications systemsNASA Astrophysics Data System (ADS)Downey  A. N.; Connolly  D. J.; Anzic  G.The current NASA program for 20 and 30 GHz monolithic microwave integrated circuit (MMIC) technology is reviewed. The advantages of MMIC are discussed. Millimeter wavelength MMIC applications and technology for communications systems are discussed. Passive and active MMIC compatible components for millimeter wavelength applications are investigated. The cost of a millimeter wavelength MMIC's is projected.MMIC technology for advanced space communications systemsNASA Technical Reports Server (NTRS)Downey  A. N.; Connolly  D. J.; Anzic  G.1984-01-01The current NASA program for 20 and 30 GHz monolithic microwave integrated circuit (MMIC) technology is reviewed. The advantages of MMIC are discussed. Millimeter wavelength MMIC applications and technology for communications systems are discussed. Passive and active MMIC compatible components for millimeter wavelength applications are investigated. The cost of a millimeter wavelength MMIC's is projected.49 CFR 193.2519 - Communication systems.Code of Federal Regulations  2010 CFR2010-10-01... 49 Transportation 3 2010-10-01 2010-10-01 false Communication systems. 193.2519 Section 193.2519 Transportation Other Regulations Relating to Transportation (Continued) PIPELINE AND HAZARDOUS MATERIALS SAFETY ADMINISTRATION  DEPARTMENT OF TRANSPORTATION (CONTINUED) PIPELINE SAFETY LIQUEFIED NATURAL GAS FACILITIES...Hermitian symmetry free optical-single-carrier frequency division multiple access for visible light communicationNASA Astrophysics Data System (ADS)Azim  Ali W.; Le Guennec  Yannis; Maury  Ghislaine2018-05-01Optical-orthogonal frequency division multiplexing (O-OFDM) is an effective scheme for visible light communications (VLC)  offering a candid extension to multiple access (MA) scenarios  i.e.  O-OFDMA. However  O-OFDMA exhibits high peak-to-average power ratio (PAPR)  which exacerbates the non-linear distortions from the light emitting diode (LED). To overcome high PAPR while sustaining MA  optical-single-carrier frequency-division multiple access (O-SCFDMA) is used. For both O-OFDMA and O-SCFDMA  Hermitian symmetry (HS) constraint is imposed in frequency-domain (FD) to obtain a real-valued time-domain (TD) signal for intensity modulation-direct detection (IM-DD) implementation of VLC. Howbeit  HS results in an increase of PAPR for O-SCFDMA. In this regard  we propose HS free (HSF) O-SCFDMA (HSFO-SCFDMA). We compare HSFO-SCFDMA with several approaches in key parameters  such as  bit error rate (BER)  optical power penalty  PAPR  quantization  electrical power efficiency and system complexity. BER performance and optical power penalty is evaluated considering multipath VLC channel and taking into account the bandwidth limitation of LED in combination with its optimized driver. It is illustrated that HSFO-SCFDMA outperforms other alternatives.Miniaturization of the atmospheric laser communication APT systemNASA Astrophysics Data System (ADS)Sun  Wei; Ai  Yong; Yang  Jinling; Huang  Haibo2003-09-01The paper presents a scheme of the miniaturization of APT system and the design of the system based on the investigation of status in quo. It deals with the infrared image of the other terminal's beacon from the Charge Coupled Device (CCD) by the Complex Programmable Logic Device (CPLD). The result of the transaction is delivered to Single Chip Microcomputer (SCM)  which controls the micro-servomotor. Subsequently  the precision drive system drives the optical system that uses only one light axis for signal beam and beacon to finish the acquisition  pointing  and tracking of the communication terminals. The anlayses of the APT system's error indicate that the tracking error limits in 70uRad with the weight of the system lighter than 8-kilogram.Communicating with Light: A New Dawn in the Information AgeNASA Technical Reports Server (NTRS)Raible  Daniel2016-01-01You and I are living in a very special time; the age of Solar System exploration. Our Solar System is a complex masterpiece of which we knew so little from our ground-based observations. But within the span of a single lifetime  NASA has sent spacecraft to every planet and several moons  our first eyes to set upon undiscovered lands. Before we endeavored on this journey everything we knew of Pluto could have fit on a single file card  and now we downlink new data every day.Land-mobile satellite communication systemNASA Technical Reports Server (NTRS)Yan  Tsun-Yee (Inventor); Rafferty  William (Inventor); Dessouky  Khaled I. (Inventor); Wang  Charles C. (Inventor); Cheng  Unjeng (Inventor)1993-01-01A satellite communications system includes an orbiting communications satellite for relaying communications to and from a plurality of ground stations  and a network management center for making connections via the satellite between the ground stations in response to connection requests received via the satellite from the ground stations  the network management center being configured to provide both open-end service and closed-end service. The network management center of one embodiment is configured to provides both types of service according to a predefined channel access protocol that enables the ground stations to request the type of service desired. The channel access protocol may be configured to adaptively allocate channels to open-end service and closed-end service according to changes in the traffic pattern and include a free-access tree algorithm that coordinates collision resolution among the ground stations.Energy efficiency in wireless communication systemsDOEpatentsCaffrey  Michael Paul; Palmer  Joseph McRae2012-12-11Wireless communication systems and methods utilize one or more remote terminals  one or more base terminals  and a communication channel between the remote terminal(s) and base terminal(s). The remote terminal applies a direct sequence spreading code to a data signal at a spreading factor to provide a direct sequence spread spectrum (DSSS) signal. The DSSS signal is transmitted over the communication channel to the base terminal which can be configured to despread the received DSSS signal by a spreading factor matching the spreading factor utilized to spread the data signal. The remote terminal and base terminal can dynamically vary the matching spreading factors to adjust the data rate based on an estimation of operating quality over time between the remote terminal and base terminal such that the amount of data being transmitted is substantially maximized while providing a specified quality of service.High power communication satellites power systems studyNASA Astrophysics Data System (ADS)Josloff  Allan T.; Peterson  Jerry R.1995-01-01This paper discusses a planned study to evaluate the commercial attractiveness of high power communication satellites and assesses the attributes of both conventional photovoltaic and reactor power systems. These high power satellites can play a vital role in assuring availability of universally accessible  wide bandwidth communications  for high definition TV  super computer networks and other services. Satellites are ideally suited to provide the wide bandwidths and data rates required and are unique in the ability to provide services directly to the users. As new or relocated markets arise  satellites offer a flexibility that conventional distribution services cannot match  and it is no longer necessary to be near population centers to take advantage of the telecommunication revolution. The geopolitical implications of these substantially enhanced communications capabilities can be significant.A lighting metric for quantitative evaluation of accent lighting systemsNASA Astrophysics Data System (ADS)Acholo  Cyril O.; Connor  Kenneth A.; Radke  Richard J.2014-09-01Accent lighting is critical for artwork and sculpture lighting in museums  and subject lighting for stage  Film and television. The research problem of designing effective lighting in such settings has been revived recently with the rise of light-emitting-diode-based solid state lighting. In this work  we propose an easy-to-apply quantitative measure of the scene's visual quality as perceived by human viewers. We consider a well-accent-lit scene as one which maximizes the information about the scene (in an information-theoretic sense) available to the user. We propose a metric based on the entropy of the distribution of colors  which are extracted from an image of the scene from the viewer's perspective. We demonstrate that optimizing the metric as a function of illumination configuration (i.e.  position  orientation  and spectral composition) results in natural  pleasing accent lighting. We use a photorealistic simulation tool to validate the functionality of our proposed approach  showing its successful application to two- and three-dimensional scenes.Research on synchronization technology of frequency hopping communication systemNASA Astrophysics Data System (ADS)Zhao  Xiangwu; Quan  Houde; Cui  Peizhang2018-05-01Frequency Hopping (FH) communication is a technology of spread spectrum communication. It has strong anti-interference  anti-interception and security capabilities  and has been widely applied in the field of communications. Synchronization technology is one of the most crucial technologies in frequency hopping communication. The speed of synchronization establishment and the reliability of synchronous system directly affect the performance of frequency hopping communication system. Therefore  the research of synchronization technology in frequency hopping communication has important value.Map synchronization in optical communication systemsNASA Technical Reports Server (NTRS)Gagliardi  R. M.; Mohanty  N.1973-01-01The time synchronization problem in an optical communication system is approached as a problem of estimating the arrival time (delay variable) of a known transmitted field. Maximum aposteriori (MAP) estimation procedures are used to generate optimal estimators  with emphasis placed on their interpretation as a practical system device  Estimation variances are used to aid in the design of the transmitter signals for best synchronization. Extension is made to systems that perform separate acquisition and tracking operations during synchronization. The closely allied problem of maintaining timing during pulse position modulation is also considered. The results have obvious application to optical radar and ranging systems  as well as the time synchronization problem.Communications and tracking expert systems studyNASA Technical Reports Server (NTRS)Leibfried  T. F.; Feagin  Terry; Overland  David1987-01-01The original objectives of the study consisted of five broad areas of investigation: criteria and issues for explanation of communication and tracking system anomaly detection  isolation  and recovery; data storage simplification issues for fault detection expert systems; data selection procedures for decision tree pruning and optimization to enhance the abstraction of pertinent information for clear explanation; criteria for establishing levels of explanation suited to needs; and analysis of expert system interaction and modularization. Progress was made in all areas  but to a lesser extent in the criteria for establishing levels of explanation suited to needs. Among the types of expert systems studied were those related to anomaly or fault detection  isolation  and recovery.Security alarm communication and display systems developmentSciTech ConnectWaddoups  I.G.1990-01-01Sandia National Laboratories has developed a variety of alarm communication and display systems for a broad spectrum of users. This paper will briefly describe the latest systems developed for the Department of Energy (DOE)  the Department of Defense (DoD)  and the Department of State (DOS) applications. Applications covered will vary from relatively small facilities to large complex sites. Ongoing system developments will also be discussed. The concluding section will summarize the practical  implementable state-of-the-art features available in new systems. 6 figs.Acoustic system for communication in pipelinesDOEpatentsMartin  II  Louis Peter; Cooper  John F [Oakland  CA2008-09-09A system for communication in a pipe  or pipeline  or network of pipes containing a fluid. The system includes an encoding and transmitting sub-system connected to the pipe  or pipeline  or network of pipes that transmits a signal in the frequency range of 3-100 kHz into the pipe  or pipeline  or network of pipes containing a fluid  and a receiver and processor sub-system connected to the pipe  or pipeline  or network of pipes containing a fluid that receives said signal and uses said signal for a desired application.Security aspects of RFID communication systemsNASA Astrophysics Data System (ADS)BÃ®ndar  ValericÇŽ; Popescu  Mircea; BÇŽrtuÅŸicÇŽ  RÇŽzvan; Craciunescu  Razvan; Halunga  Simona2015-02-01The objective of this study is to provide an overview of basic technical elements and security risks of RFID communication systems and to analyze the possible threats arising from the use of RFID systems. A number of measurements are performed on a communication system including RFID transponder and the tag reader  and it has been determined that the uplink signal level is 62 dB larger than the average value of the noise at the distance of 1m from the tag  therefore the shielding effectiveness has to exceed this threshold. Next  the card has been covered with several shielding materials and measurements were carried  under similar conditions to test the recovery of compromising signals. A very simple protection measure to prevent unauthorized reading of the data stored on the card has been proposed  and some electromagnetic shielding materials have been proposed and tested.Enabling MEMS technologies for communications systemsNASA Astrophysics Data System (ADS)Lubecke  Victor M.; Barber  Bradley P.; Arney  Susanne2001-11-01Modern communications demands have been steadily growing not only in size  but sophistication. Phone calls over copper wires have evolved into high definition video conferencing over optical fibers  and wireless internet browsing. The technology used to meet these demands is under constant pressure to provide increased capacity  speed  and efficiency  all with reduced size and cost. Various MEMS technologies have shown great promise for meeting these challenges by extending the performance of conventional circuitry and introducing radical new systems approaches. A variety of strategic MEMS structures including various cost-effective free-space optics and high-Q RF components are described  along with related practical implementation issues. These components are rapidly becoming essential for enabling the development of progressive new communications systems technologies including all-optical networks  and low cost multi-system wireless terminals and basestations.14 CFR 23.1401 - Anticollision light system.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Anticollision light system. 23.1401 Section... AIRWORTHINESS STANDARDS: NORMAL  UTILITY  ACROBATIC  AND COMMUTER CATEGORY AIRPLANES Equipment Lights Â§ 23.1401 Anticollision light system. (a) General. The airplane must have an anticollision light system that: (1) Consists...14 CFR 27.1385 - Position light system installation.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Position light system installation. 27.1385... AIRCRAFT AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 29.1385 - Position light system installation.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Position light system installation. 29.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 25.1385 - Position light system installation.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Position light system installation. 25.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 25.1401 - Anticollision light system.Code of Federal Regulations  2010 CFR2010-01-01... 14 Aeronautics and Space 1 2010-01-01 2010-01-01 false Anticollision light system. 25.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1401 Anticollision light system. (a) General. The airplane must have an anticollision light system thatâ€” (1) Consists of one or more approved...14 CFR 25.1385 - Position light system installation.Code of Federal Regulations  2013 CFR2013-01-01... 14 Aeronautics and Space 1 2013-01-01 2013-01-01 false Position light system installation. 25.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 23.1401 - Anticollision light system.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Anticollision light system. 23.1401 Section... AIRWORTHINESS STANDARDS: NORMAL  UTILITY  ACROBATIC  AND COMMUTER CATEGORY AIRPLANES Equipment Lights Â§ 23.1401 Anticollision light system. (a) General. The airplane must have an anticollision light system that: (1) Consists...14 CFR 25.1401 - Anticollision light system.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Anticollision light system. 25.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1401 Anticollision light system. (a) General. The airplane must have an anticollision light system thatâ€” (1) Consists of one or more approved...14 CFR 29.1385 - Position light system installation.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Position light system installation. 29.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 25.1385 - Position light system installation.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Position light system installation. 25.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 27.1385 - Position light system installation.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Position light system installation. 27.1385... AIRCRAFT AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 25.1401 - Anticollision light system.Code of Federal Regulations  2013 CFR2013-01-01... 14 Aeronautics and Space 1 2013-01-01 2013-01-01 false Anticollision light system. 25.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1401 Anticollision light system. (a) General. The airplane must have an anticollision light system thatâ€” (1) Consists of one or more approved...14 CFR 29.1385 - Position light system installation.Code of Federal Regulations  2013 CFR2013-01-01... 14 Aeronautics and Space 1 2013-01-01 2013-01-01 false Position light system installation. 29.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 23.1401 - Anticollision light system.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Anticollision light system. 23.1401 Section... AIRWORTHINESS STANDARDS: NORMAL  UTILITY  ACROBATIC  AND COMMUTER CATEGORY AIRPLANES Equipment Lights Â§ 23.1401 Anticollision light system. (a) General. The airplane must have an anticollision light system that: (1) Consists...14 CFR 27.1385 - Position light system installation.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Position light system installation. 27.1385... AIRCRAFT AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 27.1385 - Position light system installation.Code of Federal Regulations  2013 CFR2013-01-01... 14 Aeronautics and Space 1 2013-01-01 2013-01-01 false Position light system installation. 27.1385... AIRCRAFT AIRWORTHINESS STANDARDS: NORMAL CATEGORY ROTORCRAFT Equipment Lights Â§ 27.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 25.1385 - Position light system installation.Code of Federal Regulations  2014 CFR2014-01-01... 14 Aeronautics and Space 1 2014-01-01 2014-01-01 false Position light system installation. 25.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...14 CFR 25.1401 - Anticollision light system.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Anticollision light system. 25.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1401 Anticollision light system. (a) General. The airplane must have an anticollision light system thatâ€” (1) Consists of one or more approved...14 CFR 29.1385 - Position light system installation.Code of Federal Regulations  2011 CFR2011-01-01... 14 Aeronautics and Space 1 2011-01-01 2011-01-01 false Position light system installation. 29.1385... AIRCRAFT AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1385 Position light system installation. (a) General. Each part of each position light system must meet the applicable...Communications and control for electric power systemsNASA Technical Reports Server (NTRS)Kirkham  H.; Goettsche  A.; Niebur  D.; Friend  H.; Johnston  A.1991-01-01The first section of the report describes the AbNET system  a hardware and software communications system designed for distribution automation (it can also find application in substation monitoring and control). The topology of the power system fixes the topology of the communications network  which can therefore be expected to include a larger number of branch points  tap points  and interconnections. These features make this communications network unlike any other. The network operating software has to solve the problem of communicating to all the nodes of a very complex network in as reliable a way as possible even if the network is damaged  and it has to do so with minimum transmission delays and at minimum cost. The design of the operating protocols is described within the framework of the seven-layer Open System Interconnection hierarchy of the International Standards Organization. Section 2 of the report describes the development and testing of a high voltage sensor based on an electro-optic polymer. The theory of operation is reviewed. Bulk fabrication of the polymer is discussed  as well as results of testing of the electro-optic coefficient of the material. Fabrication of a complete prototype sensor suitable for use in the range 1-20 kV is described. The electro-optic polymer is shown to be an important material for fiber optic sensing applications. Appendix A is theoretical support for this work. The third section of the report presents the application of an artificial neural network  Kohonen's self-organizing feature map  for the classification of power system states. This classifier maps vectors of an N-dimensional space to a 2-dimensional neural net in a nonlinear way preserving the topological order of the input vectors. These mappings are studied using a nonlinear power system model.Energy-efficient constellations design and fast decoding for space-collaborative MIMO visible light communicationsNASA Astrophysics Data System (ADS)Zhu  Yi-Jun; Liang  Wang-Feng; Wang  Chao; Wang  Wen-Ya2017-01-01In this paper  space-collaborative constellations (SCCs) for indoor multiple-input multiple-output (MIMO) visible light communication (VLC) systems are considered. Compared with traditional VLC MIMO techniques  such as repetition coding (RC)  spatial modulation (SM) and spatial multiplexing (SMP)  SCC achieves the minimum average optical power for a fixed minimum Euclidean distance. We have presented a unified SCC structure for 2Ã—2 MIMO VLC systems and extended it to larger MIMO VLC systems with more transceivers. Specifically for 2Ã—2 MIMO VLC  a fast decoding algorithm is developed with decoding complexity almost linear in terms of the square root of the cardinality of SCC  and the expressions of symbol error rate of SCC are presented. In addition  bit mappings similar to Gray mapping are proposed for SCC. Computer simulations are performed to verify the fast decoding algorithm and the performance of SCC  and the results demonstrate that the performance of SCC is better than those of RC  SM and SMP for indoor channels in general.Orbiter Interface Unit and Early Communication SystemNASA Technical Reports Server (NTRS)Cobbs  Ronald M.; Cooke  Michael P.; Cox  Gary L.; Ellenberger  Richard; Fink  Patrick W.; Haynes  Dena S.; Hyams  Buddy; Ling  Robert Y.; Neighbors  Helen M.; Phan  Chau T.;   2004-01-01This report describes the Orbiter Interface Unit (OIU) and the Early Communication System (ECOMM)  which are systems of electronic hardware and software that serve as the primary communication links for the International Space Station (ISS). When a space shuttle is at or near the ISS during assembly and resupply missions  the OIU sends groundor crew-initiated commands from the space shuttle to the ISS and relays telemetry from the ISS to the space shuttle s payload data systems. The shuttle then forwards the telemetry to the ground. In the absence of a space shuttle  the ECOMM handles communications between the ISS and Johnson Space Center via the Tracking and Data Relay Satellite System (TDRSS). Innovative features described in the report include (1) a ""smart data-buffering algorithm that helps to preserve synchronization (and thereby minimize loss) of telemetric data between the OIU and the space-shuttle payload data interleaver; (2) an ECOMM antenna-autotracking algorithm that selects whichever of two phased-array antennas gives the best TDRSS signal and electronically steers that antenna to track the TDRSS source; and (3) an ECOMM radiation-latchup controller  which detects an abrupt increase in current indicative of radiation-induced latchup and temporarily turns off power to clear the latchup  restoring power after the charge dissipates.Integrated communications and optical navigation systemNASA Astrophysics Data System (ADS)Mueller  J.; Pajer  G.; Paluszek  M.2013-12-01The Integrated Communications and Optical Navigation System (ICONS) is a flexible navigation system for spacecraft that does not require global positioning system (GPS) measurements. The navigation solution is computed using an Unscented Kalman Filter (UKF) that can accept any combination of range  range-rate  planet chord width  landmark  and angle measurements using any celestial object. Both absolute and relative orbit determination is supported. The UKF employs a full nonlinear dynamical model of the orbit including gravity models and disturbance models. The ICONS package also includes attitude determination algorithms using the UKF algorithm with the Inertial Measurement Unit (IMU). The IMU is used as the dynamical base for the attitude determination algorithms. This makes the sensor a more capable plug-in replacement for a star tracker  thus reducing the integration and test cost of adding this sensor to a spacecraft. Recent additions include an integrated optical communications system which adds communications  and integrated range and range rate measurement and timing. The paper includes test results from trajectories based on the NASA New Horizons spacecraft.14 CFR 29.1385 - Position light system installation.Code of Federal Regulations  2012 CFR2012-01-01... position lights and the rear position light must make a single circuit. (e) Light covers and color filters. Each light cover or color filter must be at least flame resistant and may not change color or shape or... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Position light system installation. 29.1385...14 CFR 27.1385 - Position light system installation.Code of Federal Regulations  2012 CFR2012-01-01... position lights and the rear position light must make a single circuit. (e) Light covers and color filters. Each light cover or color filter must be at least flame resistant and may not change color or shape or... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Position light system installation. 27.1385...VHF downline communication system for SLAR dataNASA Technical Reports Server (NTRS)Schertler  R. J.; Chase  T. L.; Mueller  R. A.; Kramarchuk  I.; Jirberg  R. J.; Gedney  R. T.1979-01-01A real time VHF downlink communication system is described for transmitting side-looking airborne radar (SLAR) data directly from an aircraft to a portable ground/shipboard receiving station. Use of this receiving station aboard the U.S. Coast Guard icebreaker Mackinaw for generating real-time photographic quality radar images is discussed. The system was developed and demonstrated in conjunction with the U.S Coast Guard and NOAA National Weather Service as part of the Project Icewarn all weather ice information system for the Great Lakes Winter Navigation Program.Emergence of a Communication System: International SignNASA Astrophysics Data System (ADS)Rosenstock  RachelInternational Sign (henceforth IS) is a communication system that is used widely in the international Deaf Community. The present study is one of the first to research extensively the origin of both the IS lexicon and grammatical structures. Findings demonstrate that IS is both influenced by naturally evolved sign languages used in grown deaf communities (henceforth SLs) and relies heavily on iconic  universal structures. This paper shows that IS continues to develop from a simplistic iconic system into a conventionalized system with increasingly complex rules.Symmetric splitting of very light systemsSciTech ConnectGrotowski  K.; Majka  Z.; Planeta  R.1984-10-01Inclusive and coincidence measurements have been performed to study symmetric products from the reactions 74--186 MeV /sup 12/C+ /sup 40/Ca  141 MeV /sup 9/Be+ /sup 40/Ca  and 153 MeV /sup 6/Li+ /sup 40/Ca. The binary decay of the composite system has been verified. Energy spectra  angular distributions  and fragment correlations are presented. The total kinetic energies for the symmetric products from these very light composite systems are compared to liquid drop model calculations and fission systematics.High-dimensional structured light coding/decoding for free-space optical communications free of obstructions.PubMedDu  Jing; Wang  Jian2015-11-01Bessel beams carrying orbital angular momentum (OAM) with helical phase fronts exp(ilÏ†)(l=0;Â±1;Â±2;â€¦)  where Ï† is the azimuthal angle and l corresponds to the topological number  are orthogonal with each other. This feature of Bessel beams provides a new dimension to code/decode data information on the OAM state of light  and the theoretical infinity of topological number enables possible high-dimensional structured light coding/decoding for free-space optical communications. Moreover  Bessel beams are nondiffracting beams having the ability to recover by themselves in the face of obstructions  which is important for free-space optical communications relying on line-of-sight operation. By utilizing the OAM and nondiffracting characteristics of Bessel beams  we experimentally demonstrate 12 m distance obstruction-free optical m-ary coding/decoding using visible Bessel beams in a free-space optical communication system. We also study the bit error rate (BER) performance of hexadecimal and 32-ary coding/decoding based on Bessel beams with different topological numbers. After receiving 500 symbols at the receiver side  a zero BER of hexadecimal coding/decoding is observed when the obstruction is placed along the propagation path of light.The 'INMARSAT' international maritime satellite communication systemNASA Astrophysics Data System (ADS)Atserov  Iu. S.1982-12-01The history  design  operating characteristics  achievements  and prospects of INMARSAT are discussed. More than 1300 ships are presently equipped to operate within the system  and this number is expected to rise to about 5000 by 1986. The principle of operation involves single coordinating earth stations allocating telephone channels in their zones between other earth stations. The messages reach a common signalling channel with which all ship stations keep in touch. The ship stations are connected to the international telex network. The INMARSAT system enables ships in the automated mode of operation to establish telephone and telegraph comunication with any subscriber on the shore of any country. The quality of the communication is practically independent of the distance between ship and shore at any time of year and under any meteorological conditions. Estimates indicate that the use of satellite communication with ships reduces losses from accidents by 10 percent per year.Building intelligent communication systems for handicapped aphasiacs.PubMedFu  Yu-Fen; Ho  Cheng-Seen2010-01-01This paper presents an intelligent system allowing handicapped aphasiacs to perform basic communication tasks. It has the following three key features: (1) A 6-sensor data glove measures the finger gestures of a patient in terms of the bending degrees of his fingers. (2) A finger language recognition subsystem recognizes language components from the finger gestures. It employs multiple regression analysis to automatically extract proper finger features so that the recognition model can be fast and correctly constructed by a radial basis function neural network. (3) A coordinate-indexed virtual keyboard allows the users to directly access the letters on the keyboard at a practical speed. The system serves as a viable tool for natural and affordable communication for handicapped aphasiacs through continuous finger language input.Multi-access laser communications transceiver systemNASA Technical Reports Server (NTRS)Ross  Monte (Inventor); Lokerson  Donald C. (Inventor); Fitzmaurice  Michael W. (Inventor); Meyer  Daniel D. (Inventor)1993-01-01A satellite system for optical communications such as a multi-access laser transceiver system. Up to six low Earth orbiting satellites send satellite data to a geosynchronous satellite. The data is relayed to a ground station at the Earth's surface. The earth pointing geosynchronous satellite terminal has no gimbal but has a separate tracking mechanism for tracking each low Earth orbiting satellite. The tracking mechanism has a ring assembly rotatable about an axis coaxial with the axis of the field of view of the geosynchronous satellite and a pivotable arm mounted for pivotal movement on the ring assembly. An optical pickup mechanism at the end of each arm is positioned for optical communication with one of the orbiting satellites by rotation of the ring.System-Level Planning  Coordination  and CommunicationPubMed CentralKanter  Robert K.; Dries  David; Luyckx  Valerie; Lim  Matthew L.; Wilgis  John; Anderson  Michael R.; Sarani  Babak; Hupert  Nathaniel; Mutter  Ryan; Devereaux  Asha V.; Christian  Michael D.; Kissoon  Niranjan; Christian  Michael D.; Devereaux  Asha V.; Dichter  Jeffrey R.; Kissoon  Niranjan; Rubinson  Lewis; Amundson  Dennis; Anderson  Michael R.; Balk  Robert; Barfield  Wanda D.; Bartz  Martha; Benditt  Josh; Beninati  William; Berkowitz  Kenneth A.; Daugherty Biddison  Lee; Braner  Dana; Branson  Richard D; Burkle  Frederick M.; Cairns  Bruce A.; Carr  Brendan G.; Courtney  Brooke; DeDecker  Lisa D.; De Jong  Marla J.; Dominguez-Cherit  Guillermo; Dries  David; Einav  Sharon; Erstad  Brian L.; Etienne  Mill; Fagbuyi  Daniel B.; Fang  Ray; Feldman  Henry; Garzon  Hernando; Geiling  James; Gomersall  Charles D.; Grissom  Colin K.; Hanfling  Dan; Hick  John L.; Hodge  James G.; Hupert  Nathaniel; Ingbar  David; Kanter  Robert K.; King  Mary A.; Kuhnley  Robert N.; Lawler  James; Leung  Sharon; Levy  Deborah A.; Lim  Matthew L.; Livinski  Alicia; Luyckx  Valerie; Marcozzi  David; Medina  Justine; Miramontes  David A.; Mutter  Ryan; Niven  Alexander S.; Penn  Matthew S.; Pepe  Paul E.; Powell  Tia; Prezant  David; Reed  Mary Jane; Rich  Preston; Rodriquez  Dario; Roxland  Beth E.; Sarani  Babak; Shah  Umair A.; Skippen  Peter; Sprung  Charles L.; Subbarao  Italo; Talmor  Daniel; Toner  Eric S.; Tosh  Pritish K.; Upperman  Jeffrey S.; Uyeki  Timothy M.; Weireter  Leonard J.; West  T. Eoin; Wilgis  John; Ornelas  Joe; McBride  Deborah; Reid  David; Baez  Amado; Baldisseri  Marie; Blumenstock  James S.; Cooper  Art; Ellender  Tim; Helminiak  Clare; Jimenez  Edgar; Krug  Steve; Lamana  Joe; Masur  Henry; Mathivha  L. Rudo; Osterholm  Michael T.; Reynolds  H. Neal; Sandrock  Christian; Sprecher  Armand; Tillyard  Andrew; White  Douglas; Wise  Robert; Yeskey  Kevin2014-01-01BACKGROUND: System-level planning involves uniting hospitals and health systems  local/regional government agencies  emergency medical services  and other health-care entities involved in coordinating and enabling care in a major disaster. We reviewed the literature and sought expert opinions concerning system-level planning and engagement for mass critical care due to disasters or pandemics and offer suggestions for system-planning  coordination  communication  and response. The suggestions in this chapter are important for all of those involved in a pandemic or disaster with multiple critically ill or injured patients  including front-line clinicians  hospital administrators  and public health or government officials. METHODS: The American College of Chest Physicians (CHEST) consensus statement development process was followed in developing suggestions. Task Force members met in person to develop nine key questions believed to be most relevant for system-planning  coordination  and communication. A systematic literature review was then performed for relevant articles and documents  reports  and other publications reported since 1993. No studies of sufficient quality were identified upon which to make evidence-based recommendations. Therefore  the panel developed expert opinion-based suggestions using a modified Delphi process. RESULTS: Suggestions were developed and grouped according to the following thematic elements: (1) national government support of health-care coalitions/regional health authorities (HC/RHAs)  (2) teamwork within HC/RHAs  (3) system-level communication  (4) system-level surge capacity and capability  (5) pediatric patients and special populations  (6) HC/RHAs and networks  (7) models of advanced regional care systems  and (8) the use of simulation for preparedness and planning. CONCLUSIONS: System-level planning is essential to provide care for large numbers of critically ill patients because of disaster or pandemic. It also entails aFree-space laser communication system with rapid acquisition based on astronomical telescopes.PubMedWang  Jianmin; Lv  Junyi; Zhao  Guang; Wang  Gang2015-08-10The general structure of a free-space optical (FSO) communication system based on astronomical telescopes is proposed. The light path for astronomical observation and for communication can be easily switched. A separate camera is used as a star sensor to determine the pointing direction of the optical terminal's antenna. The new system exhibits rapid acquisition and is widely applicable in various astronomical telescope systems and wavelengths. We present a detailed analysis of the acquisition time  which can be decreased by one order of magnitude compared with traditional optical communication systems. Furthermore  we verify software algorithms and tracking accuracy.Electronic circuits for communications systems: A compilationNASA Technical Reports Server (NTRS)1972-01-01The compilation of electronic circuits for communications systems is divided into thirteen basic categories  each representing an area of circuit design and application. The compilation items are moderately complex and  as such  would appeal to the applications engineer. However  the rationale for the selection criteria was tailored so that the circuits would reflect fundamental design principles and applications  with an additional requirement for simplicity whenever possible.The interactive evolution of human communication systems.PubMedFay  Nicolas; Garrod  Simon; Roberts  Leo; Swoboda  Nik2010-04-01This paper compares two explanations of the process by which human communication systems evolve: iterated learning and social collaboration. It then reports an experiment testing the social collaboration account. Participants engaged in a graphical communication task either as a member of a community  where they interacted with seven different partners drawn from the same pool  or as a member of an isolated pair  where they interacted with the same partner across the same number of games. Participants' horizontal  pair-wise interactions led ""bottom up"" to the creation of an effective and efficient shared sign system in the community condition. Furthermore  the community-evolved sign systems were as effective and efficient as the local sign systems developed by isolated pairs. Finally  and as predicted by a social collaboration account  and not by an iterated learning account  interaction was critical to the creation of shared sign systems  with different isolated pairs establishing different local sign systems and different communities establishing different global sign systems. Copyright Â© 2010 Cognitive Science Society  Inc.Spectrally balanced chromatic landing approach lighting systemNASA Technical Reports Server (NTRS)Chase  W. D. (Inventor)1981-01-01Red warning lights delineate the runway approach with additional blue lights juxtaposed with the red lights such that the red lights are chromatically balanced. The red/blue point light sources result in the phenomenon that the red lights appear in front of the blue lights with about one and one-half times the diameter of the blue. To a pilot observing these lights along a glide path  those red lights directly below appear to be nearer than the blue lights. For those lights farther away seen in perspective at oblique angles  the red lights appear to be in a position closer to the pilot and hence appear to be above the corresponding blue lights. This produces a very pronounced three dimensional effect referred to as chromostereopsis which provides valuable visual cues to enable the pilot to perceive his actual position above the ground and the actual distance to the runway.A cooperative positioning with Kalman filters and handover mechanism for indoor microcellular visible light communication networkNASA Astrophysics Data System (ADS)Xiong  Jieqing; Huang  Zhitong; Zhuang  Kaiyu; Ji  Yuefeng2016-08-01We propose a novel handover scheme for indoor microcellular visible light communication (VLC) network. With such a scheme  the room  which is fully coverage by light  is divided into several microcells according to the layout of light-emitting diodes (LEDs). However  the directionality of light arises new challenges in keeping the connectivity between the mobile devices and light source under the mobile circumstances. The simplest solution is that all LEDs broadcast data of every user simultaneously  but it wastes too much bandwidth resource  especially when the amount of users increases. To solve this key problem  we utilize the optical positioning assisting handover procedure in this paper. In the positioning stage  the network manager obtains the location information of user device via downlink and uplink signal strength information  which is white light and infrared  respectively. After that  a Kalman filter is utilized for improving the tracking performance of a mobile device. Then  the network manager decides how to initiate the handover process by the previous information. Results show that the proposed scheme can achieve low-cost  seamless data communication  and a high probability of successful handover.Hybrid daylight/light-emitting diode illumination system for indoor lighting.PubMedGe  Aiming; Qiu  Peng; Cai  Jinlin; Wang  Wei; Wang  Junwei2014-03-20A hybrid illumination method using both daylight and light-emitting diodes (LEDs) for indoor lighting is presented in this study. The daylight can be introduced into the indoor space by a panel-integration system. The daylight part and LEDs are combined within a specific luminaire that can provide uniform illumination. The LEDs can be turned on and dimmed through closed-loop control when the daylight illuminance is inadequate. We simulated the illumination and calculated the indoor lighting efficiency of our hybrid daylight and LED lighting system  and compared this with that of LED and fluorescent lighting systems. Simulation results show that the efficiency of the hybrid daylight/LED illumination method is better than that of LED and traditional lighting systems  under the same lighting conditions and lighting time; the method has hybrid lighting average energy savings of T5 66.28%  and that of the LEDs is 41.62%.Innovative Patient Room Lighting System with Integrated Spectrally Adaptive ControlSciTech ConnectManiccia  Dorene A.; Rizzo  Patricia; Kim  James adaptable â€“ by their form  dimensions  and optical materials â€“ to mix multicolor LED platforms uniformly and deliver target design lumen levels. The Blue Sky luminaire was selected for the patient bed area to give the illusion of skylight while providing white light on the patient bed. Luminaires used existing 2-channel tunable white LED boards  and newly developed 4-channel LED boards. Red-Orange  Blue  Green  and Blue-shifted Yellow LED chips were selected based on spectral characteristics and their ability to produce high quality white light. 4-channel Power over Ethernet (PoE) drivers were developed and firmware written so they would communicate with both 2- and 4-channel boards. These components formed the backbone of the connected lighting infrastructure. Software  flexible and nuanced in its complexity  was written to set behaviors for myriad lighting scenes in the room throughout the 24 hour day â€“ and all could be overridden by manual controls. This included a dynamic tunable white program  three color changing automatic programs that simulated degrees of sunrise to sunset palettes  and an amber night lighting system that offered visual cues for postural stability to minimize the risk of falls. All programs were carefully designed to provide visual comfort for all occupants  support critical task performance for staff  and to support the patientâ€™s 24hr rhythms. A full scale mockup room was constructed in the Philips Cambridge Lab. The lighting system was installed  tested and functionality demonstrated to ensure smooth operation of system components â€“ luminaires  drivers  PoE switches  wall controls  patient remote  and daylight and occupancy sensors. How did the system perform? It met visual criteria  confirmed by calculations  simulations and measurements in the field. It met non-visual criteria  confirmed by setting circadian stimulus (CS) targets and performing calculations using the calculator developed by the Lighting Research Center. Finally  human14 CFR 25.1401 - Anticollision light system.Code of Federal Regulations  2012 CFR2012-01-01...  but not 180 cycles per minute. (d) Color. Each anticollision light must be either aviation red or... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Anticollision light system. 25.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY AIRPLANES Equipment Lights Â§ 25.1401 Anticollision light system. (a...14 CFR 29.1401 - Anticollision light system.Code of Federal Regulations  2012 CFR2012-01-01... minute. (d) Color. Each anticollision light must be aviation red and must meet the applicable... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Anticollision light system. 29.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1401 Anticollision light system. (a...14 CFR 29.1401 - Anticollision light system.Code of Federal Regulations  2013 CFR2013-01-01... minute. (d) Color. Each anticollision light must be aviation red and must meet the applicable... 14 Aeronautics and Space 1 2013-01-01 2013-01-01 false Anticollision light system. 29.1401 Section... AIRWORTHINESS STANDARDS: TRANSPORT CATEGORY ROTORCRAFT Equipment Lights Â§ 29.1401 Anticollision light system. (a...Modular  Microprocessor-Controlled Flash Lighting SystemNASA Technical Reports Server (NTRS)Kiefer  Dwayne; Gray  Elizabeth; Skupinski  Robert; Stachowicz  Arthur; Birchenough  William2006-01-01A microprocessor-controlled lighting system generates brief  precisely timed  high-intensity flashes of light for scientific imaging at frame rates up to about 1 kHz. The system includes an array of light-emitting diodes (LEDs) that are driven in synchronism with an externally generated timing signal (for example  a timing signal generated by a video camera). The light output can be varied in peak intensity  pulse duration  pulse delay  and pulse rate  all depending on the timing signal and associated externally generated control signals. The array of LEDs comprises as many as 16 LED panels that can be attached together. Each LED panel is a module consisting of a rectangular subarray of 10 by 20 LEDs of advanced design on a printed-circuit board in a mounting frame with a power/control connector. The LED panels are controlled by an LED control module that contains an AC-to-DC power supply  a control board  and 8 LED-panel driver boards. In prior LED panels  the LEDs are packaged at less than maximum areal densities in bulky metal housings that reduce effective active areas. In contrast  in the present LED panels  the LEDs are packed at maximum areal density so as to afford 100-percent active area and so that when panels are joined side by side to form the array  there are no visible seams between them and the proportion of active area is still 100 percent. Each panel produces an illuminance of .5 x 10( exp 4) lux at a distance of 5.8 in. (approx.1.6 cm). The LEDs are driven according to a pulse-width-modulation control scheme that makes it safe to drive the LEDs beyond their rated steady-state currents in order to generate additional light during short periods. The drive current and the pulse-width modulation for each LED panel can be controlled independently of those of the other 15 panels. The maximum allowable duration of each pulse of drive current is a function of the amount of overdrive  the total time to be spent in overdrive operation  and the limitationsMulti-frequency communication system and methodDOEpatentsCarrender  Curtis Lee; Gilbert  Ronald W.2004-06-01A multi-frequency RFID remote communication system is provided that includes a plurality of RFID tags configured to receive a first signal and to return a second signal  the second signal having a first frequency component and a second frequency component  the second frequency component including data unique to each remote RFID tag. The system further includes a reader configured to transmit an interrogation signal and to receive remote signals from the tags. A first signal processor  preferably a mixer  removes an intermediate frequency component from the received signal  and a second processor  preferably a second mixer  analyzes the IF frequency component to output data that is unique to each remote tag.Satellite communications systems and technology. Executive SummaryNASA Technical Reports Server (NTRS)Edelson  Burton I.; Pelton  Joseph N.; Bostian  Charles W.; Brandon  William T.; Chan  Vincent W. S.; Hager  E. Paul; Helm  Neil R.; Jennings  Raymond D.; Kwan  Robert; Mahle  Christoph E.1993-01-01NASA and the National Science Foundation (NSF) commissioned a panel of US experts to study the international status of satellite communications systems and technology. The study covers emerging systems concepts  applications  services  and the attendant technologies. The panel members travelled to Europe  Japan  and Russia to gather information first-hand. They visited 17 sites in Europe  20 sites in Japan  and four in Russia. These included major manufacturers  government organizations  service providers  and associated R&D facilities. The panel's report was reviewed by the sites visited  by the panel  and by representatives of US industry. The report details the information collected and compares it to US activities.A Website System for Communicating Psychological Science.PubMedDiener  Ed2017-07-01The peer review and journal system have shortcomings  and both computers and the Internet have made complementary or alternative systems attractive. In this article  I recommend that we implement a new platform for open communication of psychological science on a dedicated website to complement the current review and journal system  with reader reviews of the articles and with all behavioral scientists being eligible to publish and review articles. The judged merit of articles would be based on the citations and the ratings of the work by the whole scientific community. This online journal will be quicker  more democratic  and more informative than the current system. Although the details of the system should be debated and formulated by a committee of scientists  adding this online journal to the existing publications of a society such as the Association for Psychological Science has few risks and many possible gains. An online journal deserves to be tried and assessed.Organizational Culture and the Design of Computer-Mediated Communication Systems: Issues for Organizational Communication Research.ERIC Educational Resources Information CenterHacker  Kenneth L.; And OthersThe study of computer mediated communication (CMC) systems in organizations is necessary for a complete examination and explanation of organizational culture and communication. Research has shown that the effects of CMC systems have been both positive and negative. Positively  they have helped to augment oral communication. Negatively  they haveâ€¦HORIZONTAL HYBRID SOLAR LIGHT PIPE: AN INTEGRATED SYSTEM OF DAYLIGHT AND ELECTRIC LIGHTEPA Science InventoryThis project will test the feasibility of an advanced energy efficient perimeter lighting system that integrates daylighting  electric lighting  and lighting controls to reduce electricity consumption. The system is designed to provide adequate illuminance levels in deep-floor...Rube Goldberg Salad System: Teaching Systems Theory in CommunicationERIC Educational Resources Information CenterLinabary  Jasmine R.; Long  Ziyu; Mouton  Ashton; Rao  Ranjani L.; Buzzanell  Patrice M.2016-01-01Systems theory has been a staple in organizational communication textbooks since the field's inception (Miller  2015; Poole  2014). Nevertheless  the authors' classroom experiences have revealed that systems theory may not seem applicable to students due to its complicated nature. While examples and cases can help students make sense of theâ€¦Illuminating system and method for specialized and decorative lighting using liquid light guidesDOEpatentsZorn  C.J.; Kross  B.J.; Majewski  S.; Wojcik  R.F.1998-08-25The present invention comprises an illumination system for specialized decorative lighting including a light source  a flexible plastic tube sheath for distributing the light to a remote location  a transparent liquid core filling the tube that has an index of refraction greater than that of the plastic tube and an arrangement where light coupled from the light source is caused to leak from the liquid light guide at desired locations for the purposes of specialized lighting  such as underwater illumination in swimming pools. 5 figs.Synchronization using pulsed edge tracking in optical PPM communication systemNASA Technical Reports Server (NTRS)Gagliardi  R.1972-01-01A pulse position modulated (PPM) optical communication system using narrow pulses of light for data transmission requires accurate time synchronization between transmitter and receiver. The presence of signal energy in the form of optical pulses suggests the use of a pulse edge tracking method of maintaining the necessary timing. The edge tracking operation in a binary PPM system is examined  taking into account the quantum nature of the optical transmissions. Consideration is given first to pure synchronization using a periodic pulsed intensity  then extended to the case where position modulation is present and auxiliary bit decisioning is needed to aid the tracking operation. Performance analysis is made in terms of timing error and its associated statistics. Timing error variances are shown as a function of system signal to noise ratio.Global Positioning System Synchronized Active Light Autonomous Docking SystemNASA Technical Reports Server (NTRS)Howard  Richard T. (Inventor); Book  Michael L. (Inventor); Bryan  Thomas C. (Inventor); Bell  Joseph L. (Inventor)1996-01-01A Global Positioning System Synchronized Active Light Autonomous Docking System (GPSSALADS) for automatically docking a chase vehicle with a target vehicle comprising at least one active light emitting target which is operatively attached to the target vehicle. The target includes a three-dimensional array of concomitantly flashing lights which flash at a controlled common frequency. The GPSSALADS further comprises a visual tracking sensor operatively attached to the chase vehicle for detecting and tracking the target vehicle. Its performance is synchronized with the flash frequency of the lights by a synchronization means which is comprised of first and second internal clocks operatively connected to the active light target and visual tracking sensor  respectively  for providing timing control signals thereto  respectively. The synchronization means further includes first and second Global Positioning System receivers operatively connected to the first and second internal clocks  respectively  for repeatedly providing simultaneous synchronization pulses to the internal clocks  respectively. In addition  the GPSSALADS includes a docking process controller means which is operatively attached to the chase vehicle and is responsive to the visual tracking sensor for producing commands for the guidance and propulsion system of the chase vehicle.Global Positioning System Synchronized Active Light Autonomous Docking SystemNASA Technical Reports Server (NTRS)Howard  Richard (Inventor)1994-01-01A Global Positioning System Synchronized Active Light Autonomous Docking System (GPSSALADS) for automatically docking a chase vehicle with a target vehicle comprises at least one active light emitting target which is operatively attached to the target vehicle. The target includes a three-dimensional array of concomitantly flashing lights which flash at a controlled common frequency. The GPSSALADS further comprises a visual tracking sensor operatively attached to the chase vehicle for detecting and tracking the target vehicle. Its performance is synchronized with the flash frequency of the lights by a synchronization means which is comprised of first and second internal clocks operatively connected to the active light target and visual tracking sensor  respectively  for providing timing control signals thereto  respectively. The synchronization means further includes first and second Global Positioning System receivers operatively connected to the first and second internal clocks  respectively  for repeatedly providing simultaneous synchronization pulses to the internal clocks  respectively. In addition  the GPSSALADS includes a docking process controller means which is operatively attached to the chase vehicle and is responsive to the visual tracking sensor for producing commands for the guidance and propulsion system of the chase vehicle.An Improvised Eye-Pointing Communication System for Temporary Use.ERIC Educational Resources Information CenterKing  Thomas W.1990-01-01The construction and use of an improvised eye-pointing communication device is described. It is suggested for temporary use to establish and enhance initial communication with communication-disabled clients in situations where no other augmentative communication system or assistive technology is yet available. (Author)Spectrally-balanced chromatic approach-lighting systemNASA Technical Reports Server (NTRS)Chase  W. D.1977-01-01Approach lighting system employing combinations of red and blue lights reduces problem of color-based optical illusions. System exploits inherent chromatic aberration of eye to create three-dimensional effect  giving pilot visual clues of position.An Investigation of Laser Lighting Systems to Assist AircraftDOT National Transportation Integrated Search1979-01-01A model for the visual detectability of narrow light beams was developed and used to evaluate the system performance of two laser lighting system configurations: (1) a laser VASI and (2) a crossed beam glide path indicator. Laboratory experiments con...21 CFR 890.3700 - Nonpowered communication system.Code of Federal Regulations  2010 CFR2010-04-01... 21 Food and Drugs 8 2010-04-01 2010-04-01 false Nonpowered communication system. 890.3700 Section 890.3700 Food and Drugs FOOD AND DRUG ADMINISTRATION  DEPARTMENT OF HEALTH AND HUMAN SERVICES... Nonpowered communication system. (a) Identification. A nonpowered communication system is a mechanical device...21 CFR 890.3710 - Powered communication system.Code of Federal Regulations  2010 CFR2010-04-01... 21 Food and Drugs 8 2010-04-01 2010-04-01 false Powered communication system. 890.3710 Section 890.3710 Food and Drugs FOOD AND DRUG ADMINISTRATION  DEPARTMENT OF HEALTH AND HUMAN SERVICES (CONTINUED... communication system. (a) Identification. A powered communication system is an AC- or battery-powered device...21 CFR 892.2050 - Picture archiving and communications system.Code of Federal Regulations  2010 CFR2010-04-01... 21 Food and Drugs 8 2010-04-01 2010-04-01 false Picture archiving and communications system. 892.2050 Section 892.2050 Food and Drugs FOOD AND DRUG ADMINISTRATION  DEPARTMENT OF HEALTH AND HUMAN... communications system. (a) Identification. A picture archiving and communications system is a device that...29 CFR 1915.85 - Vessel radar and communication systems.Code of Federal Regulations  2014 CFR2014-07-01... 29 Labor 7 2014-07-01 2014-07-01 false Vessel radar and communication systems. 1915.85 Section... Working Conditions Â§ 1915.85 Vessel radar and communication systems. (a) The employer shall service each vessel's radar and communication systems in accordance with 29 CFR 1915.89  Control of Hazardous Energy...29 CFR 1915.85 - Vessel radar and communication systems.Code of Federal Regulations  2012 CFR2012-07-01... 29 Labor 7 2012-07-01 2012-07-01 false Vessel radar and communication systems. 1915.85 Section... Working Conditions Â§ 1915.85 Vessel radar and communication systems. (a) The employer shall service each vessel's radar and communication systems in accordance with 29 CFR 1915.89  Control of Hazardous Energy...Decoding mobile-phone image sensor rolling shutter effect for visible light communicationsNASA Astrophysics Data System (ADS)Liu  Yang2016-01-01Optical wireless communication (OWC) using visible lights  also known as visible light communication (VLC)  has attracted significant attention recently. As the traditional OWC and VLC receivers (Rxs) are based on PIN photo-diode or avalanche photo-diode  deploying the complementary metal-oxide-semiconductor (CMOS) image sensor as the VLC Rx is attractive since nowadays nearly every person has a smart phone with embedded CMOS image sensor. However  deploying the CMOS image sensor as the VLC Rx is challenging. In this work  we propose and demonstrate two simple contrast ratio (CR) enhancement schemes to improve the contrast of the rolling shutter pattern. Then we describe their processing algorithms one by one. The experimental results show that both the proposed CR enhancement schemes can significantly mitigate the high-intensity fluctuations of the rolling shutter pattern and improve the bit-error-rate performance.Human Communication  Semiotics  and General Systems: Personal and Social Communication.ERIC Educational Resources Information CenterRuben  Brent D.Questions as to the nature of sign and symbol processes and the functions and behavioral consequences of human significant phenomena are of central concern in semiotics and communication. These matters continue to be of critical importance and are still largely unresolved. Scholars in both areas of inquiry have sought unification of scientificâ€¦Efficient demodulation scheme for rolling-shutter-patterning of CMOS image sensor based visible light communications.PubMedChen  Chia-Wei; Chow  Chi-Wai; Liu  Yang; Yeh  Chien-Hung2017-10-02Recently even the low-end mobile-phones are equipped with a high-resolution complementary-metal-oxide-semiconductor (CMOS) image sensor. This motivates using a CMOS image sensor for visible light communication (VLC). Here we propose and demonstrate an efficient demodulation scheme to synchronize and demodulate the rolling shutter pattern in image sensor based VLC. The implementation algorithm is discussed. The bit-error-rate (BER) performance and processing latency are evaluated and compared with other thresholding schemes.Arctic communications techniques: Remote unattended power systemsNASA Astrophysics Data System (ADS)Walker  G.1986-02-01The purpose of this report is to describe the accomplishments during the reporting period  16 December 1985 through 1 February 1986  on the project entitled Arctic Communications Techniques: Remote Unattended Power Systems. All of the fabricated component parts for the first Ross-Stirling engine were completed. During the assembly process several interferences between some of the parts in the rotating mechanism were discovered causing drawing changes and subsequent rework to a few of the components. Assembly of the first engine was then completed. On the first attempt the engine ran successfully at approximately 3500 rpm.Photodiodes for ten micrometer laser communication systemsNASA Technical Reports Server (NTRS)Cohen  S. C.1972-01-01The performance is discussed of 10-micron mercury-cadmiumtelluride and lead-tin-telluride photodiodes in laser heterodyne communication systems. The dependence of detector quantum efficiency  resistance  frequency response  and signal-to-noise ratio on temperature  bias  and local oscillator power are examined. Included in the discussion is an analysis of the feasibility of high temperature operation  and ability of the detector to dissipate power to a heat sink is explored. Some aspects of direct detection response are considered and figures showing flux levels from a blackbody presented.Antenna technology for advanced mobile communication systemsNASA Technical Reports Server (NTRS)Rammos  Emmanuel; Roederer  Antoine; Rogard  Roger1988-01-01The onboard antenna front end is the key subsystem conditioning configuration and performance of mobile communication satellites. The objectives of this paper are to demonstrate this key role and to review L-band satellite antenna technology for earth coverage and regional applications. Multibeam arrays are first discussed  then unfurlable and inflatable reflector antennas are described. These technologies are now qualified in Europe for future mobile systems  for which the optimum choice of antenna technology has been found to be the key to efficient use of spectrum and power resources.Deployable Propulsion  Power and Communications Systems for Solar System ExplorationNASA Technical Reports Server (NTRS)Johnson  L.; Carr  J.; Boyd  D.2017-01-01NASA is developing thin-film based  deployable propulsion  power  and communication systems for small spacecraft that could provide a revolutionary new capability allowing small spacecraft exploration of the solar system. By leveraging recent advancements in thin films  photovoltaics  and miniaturized electronics  new mission-level capabilities will be enabled aboard lower-cost small spacecraft instead of their more expensive  traditional counterparts  enabling a new generation of frequent  inexpensive deep space missions. Specifically  thin-film technologies are allowing the development and use of solar sails for propulsion  small  lightweight photovoltaics for power  and omnidirectional antennas for communication.Random digital encryption secure communication systemNASA Technical Reports Server (NTRS)Doland  G. D. (Inventor)1982-01-01The design of a secure communication system is described. A product code  formed from two pseudorandom sequences of digital bits  is used to encipher or scramble data prior to transmission. The two pseudorandom sequences are periodically changed at intervals before they have had time to repeat. One of the two sequences is transmitted continuously with the scrambled data for synchronization. In the receiver portion of the system  the incoming signal is compared with one of two locally generated pseudorandom sequences until correspondence between the sequences is obtained. At this time  the two locally generated sequences are formed into a product code which deciphers the data from the incoming signal. Provision is made to ensure synchronization of the transmitting and receiving portions of the system.An advanced domestic satellite communications systemNASA Technical Reports Server (NTRS)1980-01-01An updated traffic projection for U.S. domestic satellite communications service covering a period of 15 years; mid-1980 to mid-1995 was prepared. This model takes into account expected technology advances and reductions in transmission costs  legislative and regulatory changes permitting increased competition  and rising energy costs which will encourage more extensive substitution of telecommunications for travel. The historical development and current status of satellite systems are discussed as well as the characteristics of follow-on systems. Orbital arc utilization  spacecraft configuration for single shuttle launch  Earth station configuration  and system costs are examined. Areas which require technology development include multiple beam frequency reuse antennas  on-board switching  intersatellite links  and ka-band operation. Packing and deployment schemes for enclosing the satellite within the shuttle orbiter bay must also be devised.ECS - The European Communication Satellite systemNASA Astrophysics Data System (ADS)Wooster  C. B.1981-09-01The evolution of the European Communication Satellite system (ECS) is traced from feasibility studies in 1970 to the development and launch in 1978 of the Orbital Test Satellite (OTS) by the European Space Agency to prove the new satellite and radio transmission technology being used on ECS. This was followed by the establishment of 'Interim EUTELSAT' in 1979 as the organization to operate ECS. The satellite  which operates at 11/14 GHz  covers all the capitals in Europe via three spot beam antennas  supplemented by a 'Eurobeam' regional coverage antenna which extends the range to cover all of Europe and the Mediterranean basin. Telephony channels are transmitted digitally using time division multiple access (TDMA) with digital speech interpolation (DSI) to optimize satellite capacity. Television transmission is by analog FM over the Eurobeam antenna to North African as well as European capitals. System implications of TDMA operation are discussed  and the EUTELSAT policy for Special Services or satellite business systems is discussed.14 CFR 25.1385 - Position light system installation.Code of Federal Regulations  2012 CFR2012-01-01...) Light covers and color filters. Each light cover or color filter must be at least flame resistant and may not change color or shape or lose any appreciable light transmission during normal use. [Doc. No... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Position light system installation. 25.1385...A Model for Communications Satellite System Architecture AssessmentDTIC Science & Technology2011-09-01This is shown in Equation 4. The total system cost includes all development  acquisition  fielding  operations  maintenance and upgrades  and system...protection. A mathematical model was implemented to enable the analysis of communications satellite system architectures based on multiple system... implemented to enable the analysis of communications satellite system architectures based on multiple system attributes. Utilization of the model inAn Experimental Study of a Micro-Projection Enabled Optical Terminal for Short-Range Bidirectional Multi-Wavelength Visible Light CommunicationsPubMed CentralTsai  Cheng-Yu; Jiang  Jhih-Shan2018-01-01A micro-projection enabled short-range communication (SRC) approach using red-  green- and blue-based light-emitting diodes (RGB-LEDs) has experimentally demonstrated recently that micro-projection and high-speed data transmission can be performed simultaneously. In this research  a reconfigurable design of a polarization modulated image system based on the use of a Liquid Crystal on Silicon based Spatial Light Modulator (LCoS-based SLM) serving as a portable optical terminal capable of micro-projection and bidirectional multi-wavelength communications is proposed and experimentally demonstrated. For the proof of concept  the system performance was evaluated through a bidirectional communication link at a transmission distance over 0.65 m. In order to make the proposed communication system architecture compatible with the data modulation format of future possible wireless communication system  baseband modulation scheme  i.e.  Non-Return-to-Zero On-Off-Keying (NRZ_OOK)  M-ary Phase Shift Keying (M-PSK) and M-ary Quadrature Amplitude Modulation (M-QAM) were used to investigate the system transmission performance. The experimental results shown that an acceptable BER (satisfying the limitation of Forward Error Correction  FEC standard) and crosstalk can all be achieved in the bidirectional multi-wavelength communication scenario. PMID:29587457Going beyond 4 Gbps data rate by employing RGB laser diodes for visible light communication.PubMedJanjua  Bilal; Oubei  Hassan M; DurÃ¡n Retamal  Jose R; Ng  Tien Khee; Tsai  Cheng-Ting; Wang  Huai-Yung; Chi  Yu-Chieh; Kuo  Hao-Chung; Lin  Gong-Ru; He  Jr-Hau; Ooi  Boon S2015-07-13With increasing interest in visible light communication  the laser diode (LD) provides an attractive alternative  with higher efficiency  shorter linewidth and larger bandwidth for high-speed visible light communication (VLC). Previously  more than 3 Gbps data rate was demonstrated using LED. By using LDs and spectral-efficient orthogonal frequency division multiplexing encoding scheme  significantly higher data rates has been achieved in this work. Using 16-QAM modulation scheme  in conjunction with red  blue and green LDs  data rates of 4.4 Gbps  4 Gbps and 4 Gbps  with the corresponding BER/SNR/EVM of 3.3 Ã— 10â»Â³/15.3/17.9  1.4 Ã— 10â»Â³/16.3/15.4 and 2.8 Ã— 10â»Â³/15.5/16.7were obtained over transmission distance of ~20 cm. We also simultaneously demonstrated white light emission using red  blue and green LDs  after passing through a commercially available diffuser element. Our work highlighted that a tradeoff exists in operating the blue LDs at optimum bias condition while maintaining good color temperature. The best results were obtained when encoding red LDs which gave both the strongest received signal amplitude and white light with CCT value of 5835K.Identical synchronization of chaotic secure communication systems with channel induced coherence resonanceNASA Astrophysics Data System (ADS)Sepantaie  Marc M.; Namazi  Nader M.; Sepantaie  Amir M.2016-05-01This paper is devoted to addressing the synchronization  and detection of random binary data exposed to inherent channel variations existing in Free Space Optical (FSO) communication systems. This task is achieved by utilizing the identical synchronization methodology of Lorenz chaotic communication system  and its synergetic interaction in adversities imposed by the FSO channel. Moreover  the Lorenz system has been analyzed  and revealed to induce Stochastic Resonance (SR) once exposed to Additive White Gaussian Noise (AWGN). In particular  the resiliency of the Lorenz chaotic system  in light of channel adversities  has been attributed to the success of the proposed communication system. Furthermore  this paper advocates the use of Haar wavelet transform for enhanced detection capability of the proposed chaotic communication system  which utilizes Chaotic Parameter Modulation (CPM) technique for means of transmission.Ultrasonic speech translator and communications systemSciTech ConnectAkerman  M.A.; Ayers  C.W.; Haynes  H.D.1996-07-23A wireless communication system undetectable by radio frequency methods for converting audio signals  including human voice  to electronic signals in the ultrasonic frequency range  transmitting the ultrasonic signal by way of acoustical pressure waves across a carrier medium  including gases  liquids  or solids  and reconverting the ultrasonic acoustical pressure waves back to the original audio signal. The ultrasonic speech translator and communication system includes an ultrasonic transmitting device and an ultrasonic receiving device. The ultrasonic transmitting device accepts as input an audio signal such as human voice input from a microphone or tape deck. The ultrasonic transmitting device frequency modulatesmoreÂ Â» an ultrasonic carrier signal with the audio signal producing a frequency modulated ultrasonic carrier signal  which is transmitted via acoustical pressure waves across a carrier medium such as gases  liquids or solids. The ultrasonic receiving device converts the frequency modulated ultrasonic acoustical pressure waves to a frequency modulated electronic signal  demodulates the audio signal from the ultrasonic carrier signal  and conditions the demodulated audio signal to reproduce the original audio signal at its output. 7 figs.Â«Â lessUltrasonic speech translator and communications systemDOEpatentsAkerman  M.A.; Ayers  C.W.; Haynes  H.D.1996-07-23A wireless communication system undetectable by radio frequency methods for converting audio signals  including human voice  to electronic signals in the ultrasonic frequency range  transmitting the ultrasonic signal by way of acoustical pressure waves across a carrier medium  including gases  liquids  or solids  and reconverting the ultrasonic acoustical pressure waves back to the original audio signal. The ultrasonic speech translator and communication system includes an ultrasonic transmitting device and an ultrasonic receiving device. The ultrasonic transmitting device accepts as input an audio signal such as human voice input from a microphone or tape deck. The ultrasonic transmitting device frequency modulates an ultrasonic carrier signal with the audio signal producing a frequency modulated ultrasonic carrier signal  which is transmitted via acoustical pressure waves across a carrier medium such as gases  liquids or solids. The ultrasonic receiving device converts the frequency modulated ultrasonic acoustical pressure waves to a frequency modulated electronic signal  demodulates the audio signal from the ultrasonic carrier signal  and conditions the demodulated audio signal to reproduce the original audio signal at its output. 7 figs.Ultrasonic speech translator and communications systemDOEpatentsAkerman  M. Alfred; Ayers  Curtis W.; Haynes  Howard D.1996-01-01A wireless communication system undetectable by radio frequency methods for converting audio signals  including human voice  to electronic signals in the ultrasonic frequency range  transmitting the ultrasonic signal by way of acoustical pressure waves across a carrier medium  including gases  liquids  or solids  and reconverting the ultrasonic acoustical pressure waves back to the original audio signal. The ultrasonic speech translator and communication system (20) includes an ultrasonic transmitting device (100) and an ultrasonic receiving device (200). The ultrasonic transmitting device (100) accepts as input (115) an audio signal such as human voice input from a microphone (114) or tape deck. The ultrasonic transmitting device (100) frequency modulates an ultrasonic carrier signal with the audio signal producing a frequency modulated ultrasonic carrier signal  which is transmitted via acoustical pressure waves across a carrier medium such as gases  liquids or solids. The ultrasonic receiving device (200) converts the frequency modulated ultrasonic acoustical pressure waves to a frequency modulated electronic signal  demodulates the audio signal from the ultrasonic carrier signal  and conditions the demodulated audio signal to reproduce the original audio signal at its output (250).Social-Communicative Effects of the Picture Exchange Communication System (PECS) in Autism Spectrum DisordersERIC Educational Resources Information CenterLerna  Anna; Esposito  Dalila; Conson  Massimiliano; Russo  Luigi; Massagli  Angelo2012-01-01Background: The Picture Exchange Communication System (PECS) is a common treatment choice for non-verbal children with autism. However  little empirical evidence is available on the usefulness of PECS in treating social-communication impairments in autism. Aims: To test the effects of PECS on social-communicative skills in children with autism â€¦Design of optical transmitting antenna with enhance performance in visible light communicationNASA Astrophysics Data System (ADS)Kuang  Dang; Wang  Jianping; Lu  Huimin2016-10-01An optical transmitting antenna for visible light communication(VLC) is designed in this work  in which the antenna is positioned before the light-emitting diodes (LED) source to change the lighting distribution  in order to achieve uniform received power effect. The method to design antenna is introduced into physical optical lens principle. According to the energy conservation law and Snell law  the antenna is designed via establishing energy mapping between the luminous flux emitted by a LED source with Lambertian distribution and the target plane. The coordinates of the antenna model are obtained under matrix laboratory (MATLAB). The antenna model entity is generated through three dimensional (3D) composition software AutoCAD with the coordinates of antenna. Ray-tracing software Tracepro is used to trace the ray which through antenna  and validate the irradiance maps. The uniformity of illumination and received power of the designed VLC is improved from approximately 35% to over 83%.47 CFR 90.465 - Control of systems of communication.Code of Federal Regulations  2010 CFR2010-10-01... 47 Telecommunication 5 2010-10-01 2010-10-01 false Control of systems of communication. 90.465 Section 90.465 Telecommunication FEDERAL COMMUNICATIONS COMMISSION (CONTINUED) SAFETY AND SPECIAL RADIO SERVICES PRIVATE LAND MOBILE RADIO SERVICES Transmitter Control Â§ 90.465 Control of systems of communication. (a) Depending on design considerations...SAW based systems for mobile communications satellitesNASA Technical Reports Server (NTRS)Peach  R. C.; Miller  N.; Lee  M.1993-01-01Modern mobile communications satellites  such as INMARSAT 3  EMS  and ARTEMIS  use advanced onboard processing to make efficient use of the available L-band spectrum. In all of these cases  high performance surface acoustic wave (SAW) devices are used. SAW filters can provide high selectivity (100-200 kHz transition widths)  combined with flat amplitude and linear phase characteristics; their simple construction and radiation hardness also makes them especially suitable for space applications. An overview of the architectures used in the above systems  describing the technologies employed  and the use of bandwidth switchable SAW filtering (BSSF) is given. The tradeoffs to be considered when specifying a SAW based system are analyzed  using both theoretical and experimental data. Empirical rules for estimating SAW filter performance are given. Achievable performance is illustrated using data from the INMARSAT 3 engineering model (EM) processors.Polarization rotation in meteor burst communication systemsNASA Astrophysics Data System (ADS)Cannon  P. S.1986-06-01Theoretical modeling of several meteor burst communication (MBC) paths indicates that polarization rotation losses are significant for a linearly polarized system operating near 40 MHz. Losses for a hybrid system with physical installation problems  consisting of linearly polarized transmitting and circularly polarized receiving antennas  were found to be less. Both ionospheric Faraday rotation polarization changes  and underdense meteor trail scattering wave polarization rotation  are considered. These losses are found to cause a 15-70 percent data throughput reduction of the value predicted for the situation without polarization rotation  in the two 40-MHz linearly polarized links considered for noon summer solstice conditions during high solar sunspot number periods. Qualitative experimental confirmation is provided through a cross polarization approach.Enhanced performance of visible light communication employing 512-QAM N-SC-FDE and DD-LMS.PubMedWang  Yuanquan; Huang  Xingxing; Zhang  Junwen; Wang  Yiguang; Chi  Nan2014-06-30In this paper  a novel hybrid time-frequency adaptive equalization algorithm based on a combination of frequency domain equalization (FDE) and decision-directed least mean square (DD-LMS) is proposed and experimentally demonstrated in a Nyquist single carrier visible light communication (VLC) system. Adopting this scheme  as well with 512-ary quadrature amplitude modulation (512-QAM) and wavelength multiplexing division (WDM)  an aggregate data rate of 4.22-Gb/s is successfully achieved employing a single commercially available red-green-blue (RGB) light emitting diode (LED) with low bandwidth. The measured Q-factors for 3 wavelength channels are all above the Q-limit. To the best of our knowledge  this is the highest data rate ever achieved by employing a commercially available RGB-LED.Polarization-multiplexed 2Ã—2 phosphor-LED wireless light communication without using analog equalization and optical blue filterNASA Astrophysics Data System (ADS)Yeh  C. H.; Chen  H. Y.; Liu  Y. L.; Chow  C. W.2015-01-01We propose and experimentally demonstrate a 380 (2Ã—190) Mbps phosphor-light-emitting-diode (LED) based visible light communication (VLC) system by using 2Ã—2 polarization-multiplexing design for in-building access applications. To the best of our knowledge  this is the first time of employing polarization-multiplexing to achieve a high VLC transmission capacity by using phosphor-based white-LED without optical blue filter. Besides  utilizing the optimum resistor-inductor-capacity (RLC) bias-tee design  it can not only perform the function of combining the direct-current (DC) and the electrical data signal  but also act as a simple LED-Tx circuit. No optical blue filter and complicated post-equalization are required at the Rx. Here  the orthogonal-frequency-division-multiplexing (OFDM) quadrature-amplitude-modulation (QAM) with bit-loading is employed to enhance the transmission data rate.A review on channel models in free space optical communication systemsNASA Astrophysics Data System (ADS)Anbarasi  K.; Hemanth  C.; Sangeetha  R. G.2017-12-01Free Space Optical communication (FSO) is a wireless communication technology which uses light to transmit the data in free space. FSO has advantages like unlicensed spectrum and higher bandwidth. In this paper FSO system merits and demerits  challenges in FSO  and various channel models are discussed. To mitigate the turbulence in FSO the mitigation techniques like relaying  diversity schemes and adopting different modulation techniques used in different channels are discussed and its performance comparison is given.Communicating Research to Small Drinking Water Systems: Dissemination by ResearchersEPA Science InventoryThis talk discusses the challenges of disseminating research relevant to small systems. The presentation discusses efforts by the U.S. EPAâ€™s Office of Research and Development to effectively communicating drinking water information. In particular  communication approaches ...Risk communication strategy development using the aerospace systems engineering processNASA Technical Reports Server (NTRS)Dawson  S.; Sklar  M.2004-01-01This paper explains the goals and challenges of NASA's risk communication efforts and how the Aerospace Systems Engineering Process (ASEP) was used to map the risk communication strategy used at the Jet Propulsion Laboratory to achieve these goals.Crew/computer communications study. Volume 1: Final report. [onboard computerized communications system for spacecrewsNASA Technical Reports Server (NTRS)Johannes  J. D.1974-01-01Techniques  methods  and system requirements are reported for an onboard computerized communications system that provides on-line computing capability during manned space exploration. Communications between man and computer take place by sequential execution of each discrete step of a procedure  by interactive progression through a tree-type structure to initiate tasks or by interactive optimization of a task requiring man to furnish a set of parameters. Effective communication between astronaut and computer utilizes structured vocabulary techniques and a word recognition system.Odyssey  an optimized personal communications satellite systemNASA Astrophysics Data System (ADS)Rusch  Roger J.Personal communications places severe demands on service providers and transmission facilities. Customers are not satisfied with the current levels of service and want improvements. Among the characteristics that users seek are: lower service rates  hand held convenience  acceptable time delays  ubiquitous service  high availability  reliability  and high quality. The space industry is developing commercial space systems for providing mobile communications to personal telephones. Provision of land mobile satellite service is fundamentally different from the fixed satellite service provided by geostationary satellites. In fixed service  the earth based antennas can depend on a clear path from user to satellite. Mobile users in a terrestrial environment commonly encounter blockage due to vegetation  terrain or buildings. Consequently  high elevation angles are of premium value. TRW studied the issues and concluded that a Medium Earth Orbit constellation is the best solution for Personal Communications Satellite Service. TRW has developed Odyssey  which uses twelve satellites in medium altitude orbit to provide personal communications satellite service. The Odyssey communications system projects a multibeam antenna pattern to the Earth. The attitude control system orients the satellites to ensure constant coverage of land mass and coastal areas. Pointing can be reprogrammed by ground control to ensure optimized coverage of the desired service areas. The payload architecture features non-processing  ""bent pipe"" transponders and matrix amplifiers to ensure dynamic power delivery to high demand areas. Circuit capacity is 3000 circuits per satellite. Each satellite weighs 1917 kg (4226 pounds) at launch and the solar arrays provide 3126 Watts of power. Satellites are launched in pairs on Ariane  Atlas  or other vehicles. Each satellite is placed in a circular orbit at an altitude of 10 354 km. There are three orbit planes inclined at 55Â° to the equatorial planeOdyssey  an optimized personal communications satellite systemNASA Astrophysics Data System (ADS)Rusch  Roger J.Personal communications places severe demands on service providers and transmission facilities. Customers are not satisfied with the current levels of service and want improvements. Among the characteristics that users seek are: lower service rates  hand held convenience  acceptable time delays  ubiquitous service  high availability  reliability  and high quality. The space industry in developing commercial space systems for providing mobile communications to personal telephones. Provision of land mobile satellite service is fundamentally different from the fixed satellite service provided by geostationary satellites. In fixed service  the earth based antennas can depend on a clear path from user to satellite. Mobile users in a terrestrial environment commonly encounter blockage due to vegetation  terrain or buildings. Consequently  high elevation angles are of premium value. TRW studied the issues and concluded that a Medium Earth Orbit constellation is the best solution for Personal Communications Satellite Service. TRW has developed Odyssey  which uses twelve satellites in medium altitude orbit to provide personal communications satellite service. The Odyssey communications system projects a multibeam antenna pattern to the Earth. The attitude control system orients the satellites to ensure constant coverage of land mass and coastal areas. Pointing can be reprogrammed by ground control to ensure optimized coverage of the desired service areas. The payload architecture features non-processing  'bent pipe' transponders and matrix amplifiers to ensure dynamic power delivery to high demand areas. Circuit capacity is 3000 circuits per satellite. Each satellite weighs 1917 kg (4226 pounds) at launch and the solar arrays provide 3126 watts of power. Satellites are launched in pairs on Ariane  Atlas  or other vehicles. Each satellite is placed in a circular orbit at an altitude of 10 354 km.  A novel amblyopia treatment system based on LED light sourceNASA Astrophysics Data System (ADS)Zhang  Xiaoqing; Chen  Qingshan; Wang  Xiaoling2011-05-01A novel LED (light emitting diode) light source of five different colors (white  red  green  blue and yellow) is adopted instead of conventional incandescent lamps for an amblyopia treatment system and seven training methods for rectifying amblyopia are incorporated so as for achieving an integrated therapy. The LED light source is designed to provide uniform illumination  adjustable light intensity and alterable colors. Experimental tests indicate that the LED light source operates steadily and fulfills the technical demand of amblyopia treatment.A novel amblyopia treatment system based on LED light sourceNASA Astrophysics Data System (ADS)Zhang  Xiaoqing; Chen  Qingshan; Wang  Xiaoling2010-12-01A novel LED (light emitting diode) light source of five different colors (white  red  green  blue and yellow) is adopted instead of conventional incandescent lamps for an amblyopia treatment system and seven training methods for rectifying amblyopia are incorporated so as for achieving an integrated therapy. The LED light source is designed to provide uniform illumination  adjustable light intensity and alterable colors. Experimental tests indicate that the LED light source operates steadily and fulfills the technical demand of amblyopia treatment.Integrated source and channel encoded digital communication system design studyNASA Technical Reports Server (NTRS)Huth  G. K.; Udalov  S.1974-01-01This study investigated the configuration and integration of a wideband communication system with a Ku-band rendezvous radar system. The goal of the study was to provide as much commonality between the two systems as possible. The antenna design was described with the only change being the requirement for dual polarization (linear for the radar system and circular for the communication system).New Binary Systems With Asymmetric Light CurvesNASA Astrophysics Data System (ADS)Virnina  Natalia A.2010-12-01We present the results of investigation of the light curves of 27 newly discovered binary systems. Among the examined curves  there were 10 curves with statistically significant asymmetry of maximums  according the 3Ïƒ criterion for the difference between the maximal brightness. Half of these 10 curves have a higher first maximum  another half the second one. Two of these 10 curves  USNO-B1.0 1629-0064825 = VSX J052807.9+725606 and USNO-B1.0 1586-0116785  show the largest difference between magnitudes in maxima. The star VSX J052807.9+725606 also shows the secondary minimum  which is shifted from the phase Ï† = 0.5. The shape of the curve argues that the physical processes of this star could be close to that of well known short periodic binary system V361 Lyr  which has a spot on the surface of one star of the system. Another star  USNO-B1.0 1586-0116785  probably has a cold spot  or several spots  in the photosphere of one of the components.LightingSciTech ConnectMcKay  H.N.The lighting section of ASHRAE standard 90.1 is discussed. It applies to all new buildings except low-rise residential  while excluding specialty lighting applications such as signage  art exhibits  theatrical productions  medical and dental tasks  and others. In addition  lighting for indoor plant growth is excluded if designed to operate only between 10 p.m. and 6 a.m. Lighting allowances for the interior of a building are determined by the use of the system performance path unless the space functions are not fully known  such as during the initial stages of design or for speculative buildings. In such cases  the prescriptive pathmoreÂ Â» is available. Lighting allowances for the exterior of all buildings are determined by a table of unit power allowances. A new addition the exterior lighting procedure is the inclusion of facade lighting. However  it is no longer possible to trade-off power allotted for the exterior with the interior of a building or vice versa. A significant change is the new emphasis on lighting controls.Â«Â lessField Commissioning of a Daylight-Dimming Lighting System.ERIC Educational Resources Information CenterFloyd  David B.; Parker  Danny S.A Florida elementary school cafeteria  retrofitted with a fluorescent lighting system that dims in response to available daylight  was evaluated through real time measurement of lighting and air conditioning power  work plane illumination  and interior/exterior site conditions. The new system produced a 27 percent reduction in lighting power dueâ€¦Space-to-Space Communications SystemNASA Technical Reports Server (NTRS)Tu  Kwei; Gaylor  Kent; Vitalpur  Sharada; Sham  Cathy1999-01-01The Space-to-Space Communications System (SSCS) is an Ultra High Frequency (UHF) Time-Division-Multiple Access (TDMA) system that is designed  developed  and deployed by the NASA Johnson Space Center (JSC) to provide voice  commands  telemetry and data services in close proximity among three space elements: International Space Station (ISS)  Space Shuttle Orbiter  and Extravehicular Mobility Units (EMU). The SSCS consists of a family of three radios which are  Space-to-Space Station Radio (SSSR)  Space-to-Space Orbiter Radio (SSOR)  and Space-to-Space Extravehicular Mobility Radio (SSER). The SSCS can support up to five such radios at a time. Each user has its own time slot within which to transmit voice and data. Continuous Phase Frequency Shift Keying (CPFSK) carrier modulation with a burst data rate of 695 kbps and a frequency deviation of 486.5 kHz is employed by the system. Reed-Solomon (R-S) coding is also adopted to ensure data quality. In this paper  the SSCS system requirements  operational scenario  detailed system architecture and parameters  link acquisition strategy  and link performance analysis will be presented and discussedRadiation-hardened microwave communications systemNASA Astrophysics Data System (ADS)Smith  S. F.; Bible  D. W.; Crutcher  R. I.; Hannah  J. H.; Moore  J. A.; Nowlin  C. H.; Vandermolen  R. I.; Chagnot  D.; Leroy  A.1993-03-01To develop a wireless communication system to meet the stringent requirements for a nuclear hot cell and similar environments  including control of advanced servomanipulators  a microwave signal transmission system development program was established to produce a demonstration prototype for the Consolidated Fuel Reprocessing Program at Oak Ridge National Laboratory (ORNL). Proof-of-principle tests in a partially metal lined enclosure at ORNL successfully demonstrated the feasibility of directed microwave signal transmission techniques for remote systems applications. The potential for much more severe radio-frequency (RF) multipath propagation conditions in fully metal lined cells led to a programmatic decision to conduct additional testing in more typical hot-cell environments at other sites. Again  the test results were excellent. Based on the designs of the earlier systems  an advanced microwave signal transmission system configuration was subsequently developed that  in highly reflective environments  will support both high-performance video channels and high baud-rate digital data links at total gamma dose tolerance levels exceeding 10(exp 7) rads and at elevated ambient temperatures.Digital Autonomous Terminal Access Communication (DATAC) systemNASA Technical Reports Server (NTRS)Novacki  Stanley M.  III1987-01-01In order to accommodate the increasing number of computerized subsystems aboard today's more fuel efficient aircraft  the Boeing Co. has developed the DATAC (Digital Autonomous Terminal Access Control) bus to minimize the need for point-to-point wiring to interconnect these various systems  thereby reducing total aircraft weight and maintaining an economical flight configuration. The DATAC bus is essentially a local area network providing interconnections for any of the flight management and control systems aboard the aircraft. The task of developing a Bus Monitor Unit was broken down into four subtasks: (1) providing a hardware interface between the DATAC bus and the Z8000-based microcomputer system to be used as the bus monitor; (2) establishing a communication link between the Z8000 system and a CP/M-based computer system; (3) generation of data reduction and display software to output data to the console device; and (4) development of a DATAC Terminal Simulator to facilitate testing of the hardware and software which transfer data between the DATAC's bus and the operator's console in a near real time environment. These tasks are briefly discussed.The system analysis of light field information collection based on the light field imagingNASA Astrophysics Data System (ADS)Wang  Ye; Li  Wenhua; Hao  Chenyang2016-10-01Augmented reality(AR) technology is becoming the study focus  and the AR effect of the light field imaging makes the research of light field camera attractive. The micro array structure was adopted in most light field information acquisition system(LFIAS) since emergence of light field camera  micro lens array(MLA) and micro pinhole array(MPA) system mainly included. It is reviewed in this paper the structure of the LFIAS that the Light field camera commonly used in recent years. LFIAS has been analyzed based on the theory of geometrical optics. Meanwhile  this paper presents a novel LFIAS  plane grating system  we call it ""micro aperture array(MAA."" And the LFIAS are analyzed based on the knowledge of information optics; This paper proves that there is a little difference in the multiple image produced by the plane grating system. And the plane grating system can collect and record the amplitude and phase information of the field light.A Micro Satellite Communication System ArchitectureNASA Astrophysics Data System (ADS)Fragale  Francesco; Boccia  Luigi2002-01-01In 2000 the European Space Agency's (ESA) Office for Educational Project Outreach Activities has started the Student Space Exploration &Technology Initiative (SSETI). The main objective of this project is to construct and to launch a microsatellite developed by a network of European students. The microsatellite will be mainly used to transmit pictures of the space to earth  to perform plasma experiments and to test all the subsystems for further missions. The data transfer from on-board the satellite to the ground station will be ensued through an innovative communication system composed of two different channels alternatively used to built a connection with the earth. A low data rate channel has to be activated to download telemetry and upload telecommand during the stabilisation mode or when the satellite is not visible from the earth. During the microsatellite nominal operation mode  pictures and data of scientific interest have to be sent from space to the ground station through an additional high data rate channel. As the satellite operation mode changes  a switching system optimizes the onboard power budget selecting the most convenient option between a directive and an omnidirectional antenna  designed to implement the high and low data rate channels respectively. The low gain channel uses two circular polarised patches while a 2x2 microstrip array has been chosen for realising the high rate communication link. Both the antennas are low profile radiators and they have been designed to be conformally mounted onto the microsatellite surface. Prototypes of the two antennas have been realised and tested. A description of the antenna's design process will be given together with a review of the entire system architecture rationale.Tone-activated  remote  alert communication systemNASA Technical Reports Server (NTRS)Baker  C. D.; Couvillon  L. A.; Hubbard  W. P.; Kollar  F. J.; Postal  R. B.; Tegnelia  C. R.1971-01-01Pocket sized transmitter  frequency modulated by crystal derived tones  with integral loop antenna provides police with easy operating alert signal communicator which uses patrol car radio to relay signal. Communication channels are time shared by several patrol units.Quantum communications system with integrated photonic devicesSciTech ConnectNordholt  Jane E.; Peterson  Charles Glen; Newell  Raymond ThorsonSecurity is increased in quantum communication (QC) systems lacking a true single-photon laser source by encoding a transmitted optical signal with two or more decoy-states. A variable attenuator or amplitude modulator randomly imposes average photon values onto the optical signal based on data input and the predetermined decoy-states. By measuring and comparing photon distributions for a received QC signal  a single-photon transmittance is estimated. Fiber birefringence is compensated by applying polarization modulation. A transmitter can be configured to transmit in conjugate polarization bases whose states of polarization (SOPs) can be represented as equidistant points on a great circle on themoreÂ Â» Poincare sphere so that the received SOPs are mapped to equidistant points on a great circle and routed to corresponding detectors. Transmitters are implemented in quantum communication cards and can be assembled from micro-optical components  or transmitter components can be fabricated as part of a monolithic or hybrid chip-scale circuit.Â«Â lessMaritime Navigation/Communications Program. Volume 1. Navigation and Communications System Study.DOT National Transportation Integrated Search1984-10-01A Maritime Administration/Transportation Systems Center team has been conducting a program to study navigation and communication systems on the Great Lakes and St. Lawrence River with the objective of defining technologies and systems that have the p...Design and implementation of a CMOS light pulse receiver cell array for spatial optical communications.PubMedSarker  Md Shakowat Zaman; Itoh  Shinya; Hamai  Moeta; Takai  Isamu; Andoh  Michinori; Yasutomi  Keita; Kawahito  Shoji2011-01-01A CMOS light pulse receiver (LPR) cell for spatial optical communications is designed and evaluated by device simulations and a prototype chip implementation. The LPR cell consists of a pinned photodiode and four transistors. It works under sub-threshold region of a MOS transistor and the source terminal voltage which responds to the logarithm of the photo current are read out with a source follower circuit. For finding the position of the light spot on the focal plane  an image pixel array is embedded on the same plane of the LPR cell array. A prototype chip with 640 Ã— 240 image pixels and 640 Ã— 240 LPR cells is implemented with 0.18 Î¼m CMOS technology. A proposed model of the transient response of the LPR cell agrees with the result of the device simulations and measurements. Both imaging at 60 fps and optical communication at the carrier frequency of 1 MHz are successfully performed. The measured signal amplitude and the calculation results of photocurrents show that the spatial optical communication up to 100 m is feasible using a 10 Ã— 10 LED array.Study and Validation of Eavesdropping Scenarios over a Visible Light Communication Channel.PubMedMarin-Garcia  Ignacio; Guerra  Victor; Perez-Jimenez  Rafael2017-11-21The security and privacy provided by Visible Light Communication (VLC) technologies is an area that has been slightly addressed due to the misconception that  since light does not go through solid objects like walls  VLC-based communications cannot be eavesdropped on by outside observers. As an upcoming technology  VLC is expected to be used in multiple environments were  due to radio frequency RF overuse or limitations  RF solutions cannot or should not be employed. In this work  we study the eavesdropping characteristics of a VLC-based communication. To evaluate these concerns  a two-step process was followed. First  several simulations of a standardly used scenario were run. Later on  experimental tests were performed. Following those tests  the results of the simulations and the experimental tests were analyzed. The results of these simulations and tests seemed to indicate that VLC channels can be eavesdropped on without considerable difficulties. Furthermore  the results showed that sniffing attacks could be performed from areas outside the expected coverage of the VLC infrastructure. Finally  the use of the simulation such as the one implemented in this work to recognize places from which sniffing is possible helps determine the risk for eavesdropping that our VLC-based network has.Study and Validation of Eavesdropping Scenarios over a Visible Light Communication ChannelPubMed CentralPerez-Jimenez  Rafael2017-01-01The security and privacy provided by Visible Light Communication (VLC) technologies is an area that has been slightly addressed due to the misconception that  since light does not go through solid objects like walls  VLC-based communications cannot be eavesdropped on by outside observers. As an upcoming technology  VLC is expected to be used in multiple environments were  due to radio frequency RF overuse or limitations  RF solutions cannot or should not be employed. In this work  we study the eavesdropping characteristics of a VLC-based communication. To evaluate these concerns  a two-step process was followed. First  several simulations of a standardly used scenario were run. Later on  experimental tests were performed. Following those tests  the results of the simulations and the experimental tests were analyzed. The results of these simulations and tests seemed to indicate that VLC channels can be eavesdropped on without considerable difficulties. Furthermore  the results showed that sniffing attacks could be performed from areas outside the expected coverage of the VLC infrastructure. Finally  the use of the simulation such as the one implemented in this work to recognize places from which sniffing is possible helps determine the risk for eavesdropping that our VLC-based network has. PMID:29160800Laser Communication Demonstration System (LSCS) and Future Mobile Satellite ServicesNASA Technical Reports Server (NTRS)Chen  C. -C.; Lesh  J. R.1995-01-01The Laser Communications Demonstration System (LCDS) is a proposed in-orbit demonstration of high data rate laser communications technology conceived jointly by NASA and U.S. industry. The program objectives are to stimulate industry development and to demonstrate the readiness of high data rate optical communications in Earth Orbit. For future global satellite communication systems using intersatellite links (ISLs)  laser communications technology can offer reduced mass   reduced power requirements  and increased channel bandwidths without regulatory restraint. This paper provides comparisons with radio systems and status of the program.Backscatter absorption gas imaging systems and light sources thereforeDOEpatentsKulp  Thomas Jan [Livermore  CA; Kliner  Dahv A. V. [San Ramon  CA; Sommers  Ricky [Oakley  CA; Goers  Uta-Barbara [Campbell  NY; Armstrong  Karla M [Livermore  CA2006-12-19The location of gases that are not visible to the unaided human eye can be determined using tuned light sources that spectroscopically probe the gases and cameras that can provide images corresponding to the absorption of the gases. The present invention is a light source for a backscatter absorption gas imaging (BAGI) system  and a light source incorporating the light source  that can be used to remotely detect and produce images of ""invisible"" gases. The inventive light source has a light producing element  an optical amplifier  and an optical parametric oscillator to generate wavelength tunable light in the IR. By using a multi-mode light source and an amplifier that operates using 915 nm pump sources  the power consumption of the light source is reduced to a level that can be operated by batteries for long periods of time. In addition  the light source is tunable over the absorption bands of many hydrocarbons  making it useful for detecting hazardous gases.Method and system for pipeline communicationDOEpatentsRichardson ; John  G [Idaho Falls  ID2008-01-29A pipeline communication system and method includes a pipeline having a surface extending along at least a portion of the length of the pipeline. A conductive bus is formed to and extends along a portion of the surface of the pipeline. The conductive bus includes a first conductive trace and a second conductive trace with the first and second conductive traces being adapted to conformally couple with a pipeline at the surface extending along at least a portion of the length of the pipeline. A transmitter for sending information along the conductive bus on the pipeline is coupled thereto and a receiver for receiving the information from the conductive bus on the pipeline is also couple to the conductive bus.Three-dimensional high-precision indoor positioning strategy using Tabu search based on visible light communicationNASA Astrophysics Data System (ADS)Peng  Qi; Guan  Weipeng; Wu  Yuxiang; Cai  Ye; Xie  Canyu; Wang  Pengfei2018-01-01This paper proposes a three-dimensional (3-D) high-precision indoor positioning strategy using Tabu search based on visible light communication. Tabu search is a powerful global optimization algorithm  and the 3-D indoor positioning can be transformed into an optimal solution problem. Therefore  in the 3-D indoor positioning  the optimal receiver coordinate can be obtained by the Tabu search algorithm. For all we know  this is the first time the Tabu search algorithm is applied to visible light positioning. Each light-emitting diode (LED) in the system broadcasts a unique identity (ID) and transmits the ID information. When the receiver detects optical signals with ID information from different LEDs  using the global optimization of the Tabu search algorithm  the 3-D high-precision indoor positioning can be realized when the fitness value meets certain conditions. Simulation results show that the average positioning error is 0.79 cm  and the maximum error is 5.88 cm. The extended experiment of trajectory tracking also shows that 95.05% positioning errors are below 1.428 cm. It can be concluded from the data that the 3-D indoor positioning based on the Tabu search algorithm achieves the requirements of centimeter level indoor positioning. The algorithm used in indoor positioning is very effective and practical and is superior to other existing methods for visible light indoor positioning.Architecting Communication Network of Networks for Space System of SystemsNASA Technical Reports Server (NTRS)Bhasin  Kul B.; Hayden  Jeffrey L.2008-01-01The National Aeronautics and Space Administration (NASA) and the Department of Defense (DoD) are planning Space System of Systems (SoS) to address the new challenges of space exploration  defense  communications  navigation  Earth observation  and science. In addition  these complex systems must provide interoperability  enhanced reliability  common interfaces  dynamic operations  and autonomy in system management. Both NASA and the DoD have chosen to meet the new demands with high data rate communication systems and space Internet technologies that bring Internet Protocols (IP)  routers  servers  software  and interfaces to space networks to enable as much autonomous operation of those networks as possible. These technologies reduce the cost of operations and  with higher bandwidths  support the expected voice  video  and data needed to coordinate activities at each stage of an exploration mission. In this paper  we discuss  in a generic fashion  how the architectural approaches and processes are being developed and used for defining a hypothetical communication and navigation networks infrastructure to support lunar exploration. Examples are given of the products generated by the architecture development process.Near field communication (NFC) model for arduino uno based security systems office systemNASA Astrophysics Data System (ADS)Chairunnas  A.; Abdurrasyid  I.2018-03-01Currently  many offices or companies that start growing rapidly in a company or office should have a very limited room to enter only people entitled to enter the room and use the facilities contained in it  for example  Files in it must have many files and documents very important because to reduce the abuse of files and irresponsible person. Because it will be made room door security system by using Near Field Communication on android smartphone. Software used is Arduino IDE. The tools used in this system are Arduino Uno R3  NFC shield  pear sensor  bell  led  servo  16 Ã— 2 LCD  and Near Field Communication (NFC) in android smartphone. This system runs based on 2 inputs of a new technology that is Near Field Communication (NFC) in android smartphone. And also use pear sensor to detect unauthorized person entering the room. If the correct password is entered then the door will open and the pear sensor will light off if wrong then the bell will light up.The photocytotoxicity of different lights on mammalian cells in interior lighting system.PubMedSong  Jiayin; Gao  Tingting; Ye  Maole; Bi  Hongtao; Liu  Gang2012-12-05In the present paper  two light sources commonly used in interior lighting system: incandescent light and light emitting diode (LED) were chosen to evaluate their influences on three kinds of mammalian cells  together with UVA and UVB  and the mechanism of the photocytotoxicity was investigated in terms of intracellular ROS production  lipid peroxidation  SOD activity and GSH level assays. The results showed that LED and incandescent light both had some photocytotoxicities. In the interior lighting condition (100lx-250lx)  the cytotoxicities of LED and incandescent lamp on RF/6A cells (rhesus retinal pigment epithelium cell line) were stronger than that on two fibroblast cell lines  while the cytotoxicity of UVA and UVB on HS68 cells (fibroblast cell line) was highest in the tests. The mechanism analysis revealed that the photocytotoxicities of LED and incandescent lamp were both caused by cell lipid peroxidation. LED and incandescent light could promote the production of ROS  raise lipid peroxidation level and lower the activity of the antioxidant key enzymes in mammalian cells  and finally cause a number of cells death. However  the negative function of LED was significantly smaller than incandescent light and ultraviolet in daily interior lighting condition. And the significantly lower photocytotoxicity of LED might be due to the less existence of ultraviolet. Therefore  LED is an efficient and relative safe light source in interior lighting system  which should be widely used instead of traditional light source. Copyright Â© 2012 Elsevier B.V. All rights reserved.Using the combination refraction-reflection solid to design omni-directional light source used in underwater wireless optical communicationNASA Astrophysics Data System (ADS)Rao  Jionghui; Yao  Wenming; Wen  Linqiang2015-10-01Underwater wireless optical communication is a communication technology which uses laser as an information carrier and transmits data through water. Underwater wireless optical communication has some good features such as broader bandwidth  high transmission rate  better security  antiâ€”interference performance. Therefore  it is promising to be widely used in the civil and military communication domains. It is also suitable for high-speed  short-range communication between underwater mobile vehicles. This paper presents a design approach of omni-directional light source used in underwater wireless optical communication  using TRACEPRO simulation tool to help design a combination solid composed of the lens  conical reflector and parabolic reflector  and using the modulated DPSS green laser in the transmitter module to output the laser beam in small divergence angles  after expanded by the combination refraction-reflection solid  the angle turns into a space divergence angle of 2Ï€  achieving the omni-directional light source of hemisphere space  and test in the air and underwater  the result shows that the effect is fine. This paper analyzes the experimental test in the air and water  in order to make further improvement of the uniformity of light distribution  we optimize the reflector surface parameters of combination refraction-reflection solid and test in the air and water. The result shows that omni-directional light source used in underwater wireless optical communication optimized could achieve the uniformity of light distribution of underwater space divergence angle of 2Ï€. Omni-directional light source used in underwater wireless optical communication designed in this paper has the characteristics of small size and uniformity of light distribution  it is suitable for application between UUVs  AUVs  Swimmer Delivery Vehicles (SDVs) and other underwater vehicle fleet  it realizes point-to-multipoint communications.Compact optical duplicate system for satellite-ground laser communications: application of averaging effectsNASA Astrophysics Data System (ADS)Nakayama  Tomoko; Takayama  Yoshihisa; Fujikawa  Chiemi; Watanabe  Eriko; Kodate  Kashiko2014-09-01In recent years  there has been considerable interest in satellite-ground laser communication due to an increase in the quantity of data exchanged between satellites and the ground. However  improving the quality of this data communication is necessary as laser communication is vulnerable to air fluctuation. We first verify the spatial and temporal averaging effects using light beam intensity images acquired from middle-range transmission experiments between two ground positions and the superposition of these images using simulations. Based on these results  we propose a compact and lightweight optical duplicate system as a multi-beam generation device with which it is easy to apply the spatial averaging effect. Although an optical duplicate system is already used for optical correlation operations  we present optimum design solutions  design a compact optical duplicate system for satellite-ground laser communications  and demonstrate the efficacy of this system using simulations.An underwater optical wireless communication system based on LED sourceNASA Astrophysics Data System (ADS)Rao  Jionghui; Wei  Wei; Wang  Feng; Zhang  Xiaohui2011-11-01Compared with other communication methods  optical wireless communication (OWC) holds the merits of higher transmitting rate and sufficient secrecy. So it is an efficacious communicating measure for data transmitting between underwater carriers. However  due to the water attenuation and the transmitter & the receiver (TX/RX) collimation  this application is restrained in underwater mobile carriers. A prototype for underwater OWC was developed  in which a high-powered green LED array was used as the light source which partly raveled the TX/RX collimation out. A small pumped-multiple-tube (PMT) was used as the detector to increase the communicating range  and FPGA chips were employed to code and decode the communicating data. The data rate of the prototype approached to 4 Mb/s at 8.4m and 1 Mb/s at 22m where voice and Morse communications were achieved in a scope of 30 degree TX/RX angle.Cultural selection drives the evolution of human communication systems.PubMedTamariz  Monica; Ellison  T Mark; Barr  Dale J; Fay  Nicolas2014-08-07Human communication systems evolve culturally  but the evolutionary mechanisms that drive this evolution are not well understood. Against a baseline that communication variants spread in a population following neutral evolutionary dynamics (also known as drift models)  we tested the role of two cultural selection models: coordination- and content-biased. We constructed a parametrized mixed probabilistic model of the spread of communicative variants in four 8-person laboratory micro-societies engaged in a simple communication game. We found that selectionist models  working in combination  explain the majority of the empirical data. The best-fitting parameter setting includes an egocentric bias and a content bias  suggesting that participants retained their own previously used communicative variants unless they encountered a superior (content-biased) variant  in which case it was adopted. This novel pattern of results suggests that (i) a theory of the cultural evolution of human communication systems must integrate selectionist models and (ii) human communication systems are functionally adaptive complex systems.Application of the Iridium Satellite System to Aeronautical CommunicationsNASA Technical Reports Server (NTRS)Kerczewski  Robert J.; Meza  Mike; Gupta  Om2008-01-01The next generation air transportation system will require greater air-ground communications capacity to accommodate more air traffic with increased safety and efficiency. Communications will remain primarily terrestrially based  but satellite communications will have an increased role. Inmarsat s aeronautical services have been approved and are in use for aeronautical safety communications provided by geostationary satellites. More recently the approval process for the Iridium low earth orbit constellation is nearing completion. The current Iridium system will be able to provide basic air traffic services communications suitable for oceanic  remote and polar regions. The planned second generation of the Iridium system  called Iridium NEXT  will provide enhanced capabilities and enable a greater role in the future of aeronautical communications. This paper will review the potential role of satellite communications in the future of air transportation  the Iridium approval process and relevant system testing  and the potential role of Iridium NEXT.A baseline maritime satellite communication systemNASA Technical Reports Server (NTRS)Durrani  S. H.; Mcgregor  D. N.1974-01-01This paper describes a baseline system for maritime communications via satellite during the 1980s. The system model employs three geostationary satellites with global coverage antennas. Access to the system is controlled by a master station; user access is based on time-ordered polling or random access. Each Thor-Delta launched satellite has an RF power of 100 W (spinner) or 250 W (three-axis stabilized)  and provides 10 equivalent duplex voice channels for up to 1500 ships with average waiting times of approximately 2.5 minutes. The satellite capacity is bounded by the available bandwidth to 50 such channels  which can serve up to 10 000 ships with an average waiting time of 5 minutes. The ships must have peak antenna gains of approximately 15.5 dB or 22.5 dB for the two cases (10 or 50 voice channels) when a spinner satellite is used; the required gains are 4 dB lower if a three-axis stabilized satellite is used. The ship antenna requirements can be reduced by 8 to 10 dB by employing a high-gain multi-beam phased array antenna on the satellite.Picture archiving and communication systems (PACS).PubMedGamsu  Gordon; Perez  Enrico2003-07-01Over the past 2 decades  groups of computer scientists  electronic design engineers  and physicians  in universities and industry  have worked to achieve an electronic environment for the practice of medicine and radiology. The radiology component of this revolution is often called PACS (picture archiving and communication systems). More recently it has become evident that the efficiencies and cost savings of PACS are realized when they are part of an enterprise-wide electronic medical record. The installation of PACS requires careful planning by all the various stakeholds over many months prior to installation. All of the users must be aware of the initial disruption that will occur as they become familiar with the systems. Modern fourth generation PACS is linked to radiology and hospital information systems. The PACS consist of electronic acquisition sites-a robust network intelligently managed by a server  multiple viewing sites  and an archive. The details of how these are linked and their workflow analysis determines the success of PACS. PACS evolves over time  components are frequently replaced  and so the users must expect continuous learning about new updates and improved functionality. The digital medical revolution is rapidly being adopted in many medical centers  improving patient care and the success of the institution.Using Sequence Diagrams to Detect Communication Problems Between SystemsNASA Technical Reports Server (NTRS)Lindvall  Mikael; Ackermann  Chris; Stratton  William C.; Sibol  Deane E.; Ray  Arnab; Yonkwa  Lyly; Kresser  Jan; Godfrey  Sally H.; Knodel  Jens2008-01-01Many software systems are evolving complex system of systems (SoS) for which inter-system communication is both mission-critical and error-prone. Such communication problems ideally would be detected before deployment. In a NASA-supported Software Assurance Research Program (SARP) project  we are researching a new approach addressing such problems. In this paper  we show that problems in the communication between two systems can be detected by using sequence diagrams to model the planned communication and by comparing the planned sequence to the actual sequence. We identify different kinds of problems that can be addressed by modeling the planned sequence using different level of abstractions.Considerations on Visible Light Communication security by applying the Risk Matrix methodology for risk assessmentPubMed CentralRabadan  Jose; Perez-Jimenez  Rafael2017-01-01Visible Light Communications (VLC) is a cutting edge technology for data communication that is being considered to be implemented in a wide range of applications such as Inter-vehicle communication or Local Area Network (LAN) communication. As a novel technology  some aspects of the implementation of VLC have not been deeply considered or tested. Among these aspects  security and its implementation may become an obstacle for VLCs broad usage. In this article  we have used the well-known Risk Matrix methodology to determine the relative risk that several common attacks have in a VLC network. Four examples: a War Driving  a Queensland alike Denial of Service  a Preshared Key Cracking  and an Evil Twin attack  illustrate the utilization of the methodology over a VLC implementation. The used attacks also covered the different areas delimited by the attack taxonomy used in this work. By defining and determining which attacks present a greater risk  the results of this work provide a lead into which areas should be invested to increase the safety of VLC networks. PMID:29186184Considerations on Visible Light Communication security by applying the Risk Matrix methodology for risk assessment.PubMedMarin-Garcia  Ignacio; Chavez-Burbano  Patricia; Guerra  Victor; Rabadan  Jose; Perez-Jimenez  Rafael2017-01-01Visible Light Communications (VLC) is a cutting edge technology for data communication that is being considered to be implemented in a wide range of applications such as Inter-vehicle communication or Local Area Network (LAN) communication. As a novel technology  some aspects of the implementation of VLC have not been deeply considered or tested. Among these aspects  security and its implementation may become an obstacle for VLCs broad usage. In this article  we have used the well-known Risk Matrix methodology to determine the relative risk that several common attacks have in a VLC network. Four examples: a War Driving  a Queensland alike Denial of Service  a Preshared Key Cracking  and an Evil Twin attack  illustrate the utilization of the methodology over a VLC implementation. The used attacks also covered the different areas delimited by the attack taxonomy used in this work. By defining and determining which attacks present a greater risk  the results of this work provide a lead into which areas should be invested to increase the safety of VLC networks.Dimming-discrete-multi-tone (DMT) for simultaneous color control and high speed visible light communication.PubMedSung  Jiun-Yu; Chow  Chi-Wai; Yeh  Chien-Hung2014-04-07Visible light communication (VLC) using LEDs has attracted significant attention recently for the future secure  license-free and electromagnetic-interference (EMI)-free optical wireless communication. Dimming technique in LED lamp is advantageous for energy efficiency. Color control can be performed in the red-green-blue (RGB) LEDs by using dimming technique. It is highly desirable to employ dimming technique to provide simultaneous color and dimming control and high speed VLC. Here  we proposed and demonstrated a LED dimming control using dimming-discrete-multi-tone (DMT) modulation. High speed DMT-based VLC with simultaneous color and dimming control is demonstrated for the first time to the best of our knowledge. Demonstration and analyses for several modulation conditions and transmission distances are performed  for instance  demonstrating the data rate of 103.5 Mb/s (using RGB LED) with fast Fourier transform (FFT) size of 512.RCT: 2.02 Communication Systems  Course #33339SciTech ConnectHillmer  Kurt T.This unit will present an overview of communication systems at LANL. Good communication skills are essential to an RCT. RCTs should develop an ability to communicate  using both verbal and nonverbal media. These skills will ensure that important information is transmitted to the proper individuals in a clear and concise manner.Establishing Conventional Communication Systems: Is Common Knowledge Necessary?ERIC Educational Resources Information CenterBarr  Dale J.2004-01-01How do communities establish shared communication systems? The Common Knowledge view assumes that symbolic conventions develop through the accumulation of common knowledge regarding communication practices among the members of a community. In contrast with this view  it is proposed that coordinated communication emerges a by-product of localâ€¦Developing Flexible Networked Lighting Control SystemsScience.gov Websites  Bluetooth  ZigBee and others are increasingly used for building control purposes. Low-cost computation : Bundling digital intelligence at the sensors and lights adds virtually no incremental cost. Coupled with cost. Research Goals and Objectives This project ""Developing Flexible  Networked Lighting ControlGroup consensus control for networked multi-agent systems with communication delays.PubMedAn  Bao-Ran; Liu  Guo-Ping; Tan  Chong2018-05-01This paper investigates group consensus problems in networked multi-agent systems (NMAS) with communication delays. Based on the sed state prediction scheme  the group consensus control protocol is designed to compensate the communication delay actively. In light of algebraic graph theories and matrix theories  necessary and(or) sufficient conditions of group consensus with respect to a given admissible control set are obtained for the NMAS with communication delays under mild assumptions. Finally  simulations are performed to demonstrate the effectiveness of the theoretical results. Copyright Â© 2018 ISA. All rights reserved.A compact  coherent light source system architectureNASA Astrophysics Data System (ADS)Biedron  S. G.; Dattoli  G.; DiPalma  E.; Einstein  J.; Milton  S. V.; Petrillo  V.; Rau  J. V.; Sabia  E.; Spassovsky  I. P.; van der Slot  P. J. M.2016-09-01Our team has been examining several architectures for short-wavelength  coherent light sources. We are presently exploring the use and role of advanced  high-peak power lasers for both accelerating the electrons and generating a compact light source with the same laser. Our overall goal is to devise light sources that are more accessible by industry and in smaller laboratory settings. Although we cannot and do not want to compete directly with sources such as third-generation light sources or that of national-laboratory-based free-electron lasers  we have several interesting schemes that could bring useful and more coherent  short-wavelength light source to more researchers. Here  we present and discuss several results of recent simulations and our future steps for such dissemination.Task five report: Laser communications for data acquisition networks. [characteristics of lasers and laser systems for optical communication applicationsNASA Technical Reports Server (NTRS)1973-01-01Laser communication technology and laser communication performance are reviewed. The subjects discussed are: (1) characteristics of laser communication systems  (2) laser technology problems  (3) means of overcoming laser technology problems  and (4) potential schedule for including laser communications into data acquisition networks. Various types of laser communication systems are described and their capabilities are defined.Gigabit-per-second white light-based visible light communication using near-ultraviolet laser diode and red-  green-  and blue-emitting phosphors.PubMedLee  Changmin; Shen  Chao; Cozzan  Clayton; Farrell  Robert M; Speck  James S; Nakamura  Shuji; Ooi  Boon S; DenBaars  Steven P2017-07-24Data communication based on white light generated using a near-ultraviolet (NUV) laser diode (LD) pumping red-  green-  and blue-emitting (RGB) phosphors was demonstrated for the first time. A III-nitride laser diode (LD) on a semipolar (2021Â¯)Â  substrate emitting at 410 nm was used for the transmitter. The measured modulation bandwidth of the LD was 1 GHz  which was limited by the avalanche photodetector. The emission from the NUV LD and the RGB phosphor combination measured a color rendering index (CRI) of 79 and correlated color temperature (CCT) of 4050 K  indicating promise of this approach for creating high quality white lighting. Using this configuration  data was successfully transmitted at a rate of more than 1 Gbps. This NUV laser-based system is expected to have lower background noise from sunlight at the LD emission wavelength than a system that uses a blue LD due to the rapid fall off in intensity of the solar spectrum in the NUV spectral region.Alternative Line Coding Scheme with Fixed Dimming for Visible Light CommunicationNASA Astrophysics Data System (ADS)Niaz  M. T.; Imdad  F.; Kim  H. S.2017-01-01An alternative line coding scheme called fixed-dimming on/off keying (FD-OOK) is proposed for visible-light communication (VLC). FD-OOK reduces the flickering caused by a VLC transmitter and can maintain a 50% dimming level. Simple encoder and decoder are proposed which generates codes where the number of bits representing one is same as the number of bits representing zero. By keeping the number of ones and zeros equal the change in the brightness of lighting may be minimized and kept constant at 50%  thereby reducing the flickering in VLC. The performance of FD-OOK is analysed with two parameters: the spectral efficiency and power requirement.14 CFR 23.1401 - Anticollision light system.Code of Federal Regulations  2012 CFR2012-01-01...  but not 180  cycles per minute. (d) Color. Each anticollision light must be either aviation red or... 14 Aeronautics and Space 1 2012-01-01 2012-01-01 false Anticollision light system. 23.1401 Section... AIRWORTHINESS STANDARDS: NORMAL  UTILITY  ACROBATIC  AND COMMUTER CATEGORY AIRPLANES Equipment Lights Â§ 23.1401...14 CFR 23.1401 - Anticollision light system.Code of Federal Regulations  2013 CFR2013-01-01...  but not 180  cycles per minute. (d) Color. Each anticollision light must be either aviation red or... 14 Aeronautics and Space 1 2013-01-01 2013-01-01 false Anticollision light system. 23.1401 Section... AIRWORTHINESS STANDARDS: NORMAL  UTILITY  ACROBATIC  AND COMMUTER CATEGORY AIRPLANES Equipment Lights Â§ 23.1401...Communications and control for electric power systemsNASA Technical Reports Server (NTRS)Kirkham  H.1992-01-01A long-term strategy for the integration of new control technologies for power generation and delivery is proposed: the industry would benefit from an evolutionary approach that would adapt to its needs future technologies as well as those that it has so far not heeded. The integrated operation of the entire system  including the distribution system  was proposed as a future goal. The AbNET communication protocols are reviewed  and additions that were made in 1991 are described. In the original network  traffic was controlled by polling at the master station  located at the substation  and routed by a flooding algorithm. In a revised version  the polling and flooding are modified. The question of interfacing low-energy measurement transducers or instrument transformers is considered. There is presently little or no agreement on what the output of optical current transducers (CT's) should be. Appendices deal with the calibration of current transducers; with Delta modulation  a simple means of serially encoding the output of an OCT; and with noise shaping  a method of digital signal processing that trades off the number of bits in a digital sample for a higher number of samples.Gas Main Sensor and Communications Network SystemSciTech ConnectHagen SchempfAutomatika  Inc. was contracted by the Department of Energy (DOE) and with co-funding from the Northeast Gas Association (NGA)  to develop an in-pipe natural gas prototype measurement and wireless communications system for assessing and monitoring distribution networks. This projected was completed in April 2006  and culminated in the installation of more than 2 dozen GasNet nodes in both low- and high-pressure cast-iron and steel mains owned by multiple utilities in the northeastern US. Utilities are currently logging data (off-line) and monitoring data in real time from single and multiple networked sensors over cellular networks and collecting data using wireless bluetoothmoreÂ Â» PDA systems. The system was designed to be modular  using in-pipe sensor-wands capable of measuring  flow  pressure  temperature  water-content and vibration. Internal antennae allowed for the use of the pipe-internals as a waveguide for setting up a sensor network to collect data from multiple nodes simultaneously. Sensor nodes were designed to be installed with low- and no-blow techniques and tools. Using a multi-drop bus technique with a custom protocol  all electronics were designed to be buriable and allow for on-board data-collection (SD-card)  wireless relaying and cellular network forwarding. Installation options afforded by the design included direct-burial and external polemounted variants. Power was provided by one or more batteries  direct AC-power (Class I Div.2) and solar-array. The utilities are currently in a data-collection phase and intend to use the collected (and processed) data to make capital improvement decisions  compare it to Stoner model predictions and evaluate the use of such a system for future expansion  technology-improvement and commercialization starting later in 2006.Â«Â lessHelicopter Visual Segment Approach Lighting System (HALS) Test ReportDTIC Science & Technology1988-08-01this Pegl 23. Ne. a# Palo$ 22. Ptuco Unclassified Unclassified 316 Form DOT F 1700.7 (8-721 Reproduction of e9Isted Ppe authorized TABLE OF CONTENTS...Subject Pilot Range Rate/Vertical Position Plots lii LIST OF ILLUSTRATIONS Figure Page I Basic Heliport IFR Lighting System 4 2 Heliport Approach...Instrument Flight Rules ( IFR ) Heliport Lighting System and a centerline HALS. The Basic IFR Approach Light System is presented in figure 1. It consists ofA Fault Tree Approach to Analysis of Organizational Communication Systems.ERIC Educational Resources Information CenterWitkin  Belle Ruth; Stephens  Kent G.Fault Tree Analysis (FTA) is a method of examing communication in an organization by focusing on: (1) the complex interrelationships in human systems  particularly in communication systems; (2) interactions across subsystems and system boundaries; and (3) the need to select and ""prioritize"" channels which will eliminate noise in theâ€¦46 CFR 121.602 - Internal communications systems.Code of Federal Regulations  2010 CFR2010-10-01... THAN 150 PASSENGERS OR WITH OVERNIGHT ACCOMMODATIONS FOR MORE THAN 49 PASSENGERS VESSEL CONTROL AND MISCELLANEOUS SYSTEMS AND EQUIPMENT Control and Internal Communications Systems Â§ 121.602 Internal... 46 Shipping 4 2010-10-01 2010-10-01 false Internal communications systems. 121.602 Section 121.602...A System for Inter-Library Communication (SILC). Final Report.ERIC Educational Resources Information CenterHayes  R. M.A study was made of the use of time-sharing computer systems as a means of communication  accounting  message switching  and referral in a System for Inter-Library Communication (SILC). The purpose of the study was to develop data on which to evaluate the feasibility of such a system; the results are reported in terms of four issues: technicalâ€¦The Picture Exchange Communication System: Digital Photographs versus Picture SymbolsERIC Educational Resources Information CenterJonaitis  Carmen2011-01-01The Picture Exchange Communication System (PECS) is an augmentative and alternative system (AAC) used to improve and increase communication for children with Autism Spectrum Disorder (ASD) and other developmental disorders. Research addressing the efficacy of this system is increasing; however  there is limited information published that evaluatesâ€¦Research and design of intelligent distributed traffic signal light control system based on CAN busNASA Astrophysics Data System (ADS)Chen  Yu2007-12-01Intelligent distributed traffic signal light control system was designed based on technologies of infrared  CAN bus  single chip microprocessor (SCM)  etc. The traffic flow signal is processed with the core of SCM AT89C51. At the same time  the SCM controls the CAN bus controller SJA1000/transceiver PCA82C250 to build a CAN bus communication system to transmit data. Moreover  up PC realizes to connect and communicate with SCM through USBCAN chip PDIUSBD12. The distributed traffic signal light control system with three control styles of Vehicle flux  remote and PC is designed. This paper introduces the system composition method and parts of hardware/software design in detail.Expeditionary Lighting Systems for Military SheltersDTIC Science & Technology2009-11-04Lumiled LED Housing Nonimaging Beamformer Heat Sink Connector Retractable Cable O Transportation Configuration Physical Optics Corporation (POC) LED...New Lighting Technologies: â€¢ Technology: Light Emitting Diode (LED) o Physical Optics Corp [SBIR] o Techshot [SBIR] [Congressional Effort o Jameson LED...rugged and durableâ€”no lamp to damage or replace â€¢ Custom designed optical diffuser prevents glare and â€œeye spotsâ€ â€¢ Operates on universal voltage  90Ultrasound Picture Archiving And Communication SystemsNASA Astrophysics Data System (ADS)Koestner  Ken; Hottinger  C. F.1982-01-01The ideal ultrasonic image communication and storage system must be flexible in order to optimize speed and minimize storage requirements. Various ultrasonic imaging modalities are quite different in data volume and speed requirements. Static imaging  for example B-Scanning  involves acquisition of a large amount of data that is averaged or accumulated in a desired manner. The image is then frozen in image memory before transfer and storage. Images are commonly a 512 x 512 point array  each point 6 bits deep. Transfer of such an image over a serial line at 9600 baud would require about three minutes. Faster transfer times are possible; for example  we have developed a parallel image transfer system using direct memory access (DMA) that reduces the time to 16 seconds. Data in this format requires 256K bytes for storage. Data compression can be utilized to reduce these requirements. Real-time imaging has much more stringent requirements for speed and storage. The amount of actual data per frame in real-time imaging is reduced due to physical limitations on ultrasound. For example  100 scan lines (480 points long  6 bits deep) can be acquired during a frame at a 30 per second rate. In order to transmit and save this data at a real-time rate requires a transfer rate of 8.6 Megabaud. A real-time archiving system would be complicated by the necessity of specialized hardware to interpolate between scan lines and perform desirable greyscale manipulation on recall. Image archiving for cardiology and radiology would require data transfer at this high rate to preserve temporal (cardiology) and spatial (radiology) information.Performance analysis and enhancement for visible light communication using CMOS sensorsNASA Astrophysics Data System (ADS)Guan  Weipeng; Wu  Yuxiang; Xie  Canyu; Fang  Liangtao; Liu  Xiaowei; Chen  Yingcong2018-03-01Complementary Metal-Oxide-Semiconductor (CMOS) sensors are widely used in mobile-phone and cameras. Hence  it is attractive if these camera can be used as the receivers of visible light communication (VLC). Using the rolling shutter mechanism can increase the data rate of VLC based on CMOS camera  and different techniques have been proposed to improve the demodulation of the rolling shutter mechanism. However  these techniques are too complexity. In this work  we demonstrate and analyze the performance of the VLC link using CMOS camera for different LED luminaires for the first time in our knowledge. Experimental evaluation to compare their bit-error-rate (BER) performances and demodulation are also performed  and it can be summarized that just need to change the LED luminaire with more uniformity light output  the blooming effect would not exist; which not only can reduce the complexity of the demodulation but also enhance the communication quality. In addition  we propose and demonstrate to use contrast limited adaptive histogram equalization to extend the transmission distance and mitigate the influence of the background noise. And the experimental results show that the BER can be decreased by an order of magnitude by using the proposed method.Living in the dark does not mean a blind life: bird and mammal visual communication in dim light.PubMedPenteriani  Vincenzo; Delgado  MarÃ­a Del Mar2017-04-05For many years  it was believed that bird and mammal communication 'in the dark of the night' relied exclusively on vocal and chemical signalling. However  in recent decades  several case studies have conveyed the idea that the nocturnal world is rich in visual information. Clearly  a visual signal needs a source of light to work  but diurnal light (twilight included  i.e. any light directly dependent on the sun) is not the only source of luminosity on this planet. Actually  moonlight represents a powerful source of illumination that cannot be neglected from the perspective of visual communication. White patches of feathers and fur on a dark background have the potential to be used to communicate with conspecifics and heterospecifics in dim light across different contexts and for a variety of reasons. Here: (i) we review current knowledge on visual signalling in crepuscular and nocturnal birds and mammals; and (ii) we also present some possible cases of birds and mammals that  due to the characteristics of their feather and fur coloration pattern  might use visual signals in dim light. Visual signalling in nocturnal animals is still an emerging field and  to date  it has received less attention than many other means of communication  including visual communication under daylight. For this reason  many questions remain unanswered and  sometimes  even unasked.This article is part of the themed issue 'Vision in dim light'. Â© 2017 The Author(s).Lighting system with thermal management system having point contact synthetic jetsDOEpatentsArik  Mehmet; Weaver  Stanton Earl; Kuenzler  Glenn Howard; Wolfe  Jr  Charles Franklin; Sharma  Rajdeep2016-08-30Lighting systems having unique configurations are provided. For instance  the lighting system may include a light source  a thermal management system and driver electronics  each contained within a housing structure. The light source is configured to provide illumination visible through an opening in the housing structure. The thermal management system includes a plurality of synthetic jets. The synthetic jets are arranged within the lighting system such that they are secured at contact points.Lighting system with thermal management system having point contact synthetic jetsDOEpatentsArik  Mehmet; Weaver  Stanton Earl; Kuenzler  Glenn Howard; Wolfe  Jr.  Charles Franklin; Sharma  Rajdeep2016-08-23Lighting systems having unique configurations are provided. For instance  the lighting system may include a light source  a thermal management system and driver electronics  each contained within a housing structure. The light source is configured to provide illumination visible through an opening in the housing structure. The thermal management system includes a plurality of synthetic jets. The synthetic jets are arranged within the lighting system such that they are secured at contact points.Lighting system with thermal management system having point contact synthetic jetsDOEpatentsArik  Mehmet; Weaver  Stanton Earl; Kuenzler  Glenn Howard; Wolfe  Jr.  Charles Franklin; Sharma  Rajdeep2013-12-10Lighting system having unique configurations are provided. For instance  the lighting system may include a light source  a thermal management system and driver electronics  each contained within a housing structure. The light source is configured to provide illumination visible through an opening in the housing structure. The thermal management system includes a plurality of synthetic jets. The synthetic jets are arranged within the lighting system such that they are secured at contact points.MSFC Skylab instrumentation and communication system mission evaluationNASA Technical Reports Server (NTRS)Adair  B. M.1974-01-01An evaluation of the in-orbit performance of the instrumentation and communications systems installed on Skylab is presented. Performance is compared with functional requirements and the fidelity of communications. In-orbit performance includes processing engineering  scientific  experiment  and biomedical data  implementing ground-generated commands  audio and video communication  generating rendezvous ranging information  and radio frequency transmission and reception. A history of the system evolution based on the functional requirements and a physical description of the launch configuration is included. The report affirms that the instrumentation and communication system satisfied all imposed requirements.Apollo experience report: Communications system flight evaluation and verificationNASA Technical Reports Server (NTRS)Travis  D.; Royston  C. L.  Jr.1972-01-01Flight tests of the synergetic operation of the spacecraft and earth based communications equipment were accomplished during Apollo missions AS-202 through Apollo 12. The primary goals of these tests were to verify that the communications system would adequately support lunar landing missions and to establish the inflight communications system performance characteristics. To attain these goals  a communications system flight verification and evaluation team was established. The concept of the team operations  the evolution of the evaluation processes  synopses of the team activities associated with each mission  and major conclusions and recommendations resulting from the performance evaluation are represented.Suitability of ANSI standards for quantifying communication satellite system performanceNASA Technical Reports Server (NTRS)Cass  Robert D.1988-01-01A study on the application of American National Standards X3.102 and X3.141 to various classes of communication satellite systems from the simple analog bent-pipe to NASA's Advanced Communications Technology Satellite (ACTS) is discussed. These standards are proposed as means for quantifying the end-to-end communication system performance of communication satellite systems. An introductory overview of the two standards are given followed by a review of the characteristics  applications  and advantages of using X3.102 and X3.141 to quantify with a description of the application of these standards to ACTS.National Communications System: Ensuring Essential Communications for the HomelandDTIC Science & Technology2002-01-01EP calls receive priority in the Signaling System 7 ( SS7 ) networks that manage calls in the carrier trunk networks. In 1993  the American National...the application of available GETS features. In 1996  ANSI modified the SS7 standards so that NS/EP traffic would have a higher signaling priority...facilitate industry migration to the standard related to SS7 message priority. GETS representatives worked with the GETS interexchange and localPower adaptive multi-filter carrierless amplitude and phase access scheme for visible light communication networkNASA Astrophysics Data System (ADS)Li  Wei; Huang  Zhitong; Li  Haoyue; Ji  Yuefeng2018-04-01Visible light communication (VLC) is a promising candidate for short-range broadband access due to its integration of advantages for both optical communication and wireless communication  whereas multi-user access is a key problem because of the intra-cell and inter-cell interferences. In addition  the non-flat channel effect results in higher losses for users in high frequency bands  which leads to unfair qualities. To solve those issues  we propose a power adaptive multi-filter carrierless amplitude and phase access (PA-MF-CAPA) scheme  and in the first step of this scheme  the MF-CAPA scheme utilizing multiple filters as different CAP dimensions is used to realize multi-user access. The character of orthogonality among the filters in different dimensions can mitigate the effect of intra-cell and inter-cell interferences. Moreover  the MF-CAPA scheme provides different channels modulated on the same frequency bands  which further increases the transmission rate. Then  the power adaptive procedure based on MF-CAPA scheme is presented to realize quality fairness. As demonstrated in our experiments  the MF-CAPA scheme yields an improved throughput compared with multi-band CAP access scheme  and the PA-MF-CAPA scheme enhances the quality fairness and further improves the throughput compared with the MF-CAPA scheme.Blue-light digital communication in underwater environments utilizing orbital angular momentumNASA Astrophysics Data System (ADS)Baghdady  Joshua; Miller  Keith; Osler  Sean; Morgan  Kaitlyn; Li  Wenzhe; Johnson  Eric; Cochenour  Brandon2016-05-01Underwater optical communication has recently become the topic of much investigation as the demands for underwater data transmission have rapidly grown in recent years. The need for reliable  high-speed  secure underwater communication has turned increasingly to blue-light optical solutions. The blue-green visible wavelength window provides an attractive solution to the problem of underwater data transmission thanks to its low attenuation  where traditional RF solutions used in free-space communications collapse. Beginning with GaN laser diodes as the optical source  this work explores the encoding and transmission of digital data across underwater environments of varying turbidities. Given the challenges present in an underwater environment  such as the mechanical and optical turbulences that make proper alignment difficult to maintain  it is desirable to achieve extremely high data rates in order to allow the time window of alignment between the transmitter and receiver to be as small as possible. In this paper  work is done to increase underwater data rates through the use of orbital angular momentum. Results are shown for a range of data rates across a variety of channel types ranging in turbidity from that of a clear ocean to a dirty harbor.Wearable light management system for light stimulated healing of large area chronic wounds (Conference Presentation)NASA Astrophysics Data System (ADS)Kallweit  David; Mayer  Jan; Fricke  SÃ¶ren; Schnieper  Marc; Ferrini  Rolando2016-03-01Chronic wounds represent a significant burden to patients  health care professionals  and health care systems  affecting over 40 million patients and creating costs of approximately 40 billion â‚¬ annually. We will present a medical device for photo-stimulated wound care based on a wearable large area flexible and disposable light management system consisting of a waveguide with incorporated micro- and nanometer scale optical structures for efficient light in-coupling  waveguiding and homogeneous illumination of large area wounds. The working principle of this innovative device is based on the therapeutic effects of visible light to facilitate the self-healing process of chronic wounds. On the one hand  light exposure in the red (656nm) induces growth of keratinocytes and fibroblasts in deeper layers of the skin. On the other hand  blue light (453nm) is known to have antibacterial effects predominately at the surface layers of the skin. In order to be compliant with medical requirements the system will consist of two elements: a disposable wound dressing with embedded flexible optical waveguides for the light management and illumination of the wound area  and a non-disposable compact module containing the light sources  a controller  a rechargeable battery  and a data transmission unit. In particular  we will report on the developed light management system. Finally  as a proof-of-concept  a demonstrator will be presented and its performances will be reported to demonstrate the potential of this innovative device.Fiber optic lighting system for plant productionNASA Astrophysics Data System (ADS)St. George  Dennis R.; Feddes  John J. R.1991-02-01Dennis St. George John Feddes (Dept. of Agricultural Engineering University of Alberta Edmonton AB Canada T6G 2Hl) A prototype light collection and transmission device was developed and evaluated for the potential of irradiating plants grown in an opague growth chamber. Results indicated that the device transmitted light with a photon flux of 130 1amol/s/m2 (4000-7000 nm) to the bottom of the growth chamber when direct solar radiation was 800 W/m2 (300-2500 nm) outside. The overall collection and transmission efficiency for photosynthetically active radiation is 19. 2. A growth trial with plants indicated that artificial lighting is required during cloudy periods. 1.Beacon system based on light-emitting diode sources for runways lightingNASA Astrophysics Data System (ADS)Montes  Mario GonzÃ¡lez; VÃ¡zquez  Daniel; Fernandez-Balbuena  Antonio A.; Bernabeu  Eusebio2014-06-01New aeronautical ground lighting techniques are becoming increasingly important to ensure the safety and reduce the maintenance costs of the plane's tracks. Until recently  tracks had embedded lighting systems whose sources were based on incandescent lamps. But incandescent lamps have several disadvantages: high energy consumption and frequent breakdowns that result in high maintenance costs (lamp average life-time is Ëœ1500 operating hours) and the lamp's technology has a lack of new lighting functions  such as signal handling and modification. To solve these problems  the industry has developed systems based on light-emitting diode (LED) technology with improved features: (1) LED lighting consumes one tenth the power  (2) it improves preventive maintenance (an LED's lifetime range is between 25 000 and 100 000 hours)  and (3) LED lighting technology can be controlled remotely according to the needs of the track configuration. LEDs have been in use for more than three decades  but only recently  around 2002  have they begun to be used as visual aids  representing the greatest potential change for airport lighting since their inception in the 1920s. Currently  embedded LED systems are not being broadly used due to the specific constraints of the rules and regulations of airports (beacon dimensions  power system technology  etc.). The fundamental requirements applied to embedded lighting systems are to be hosted on a volume where the dimensions are usually critical and also to integrate all the essential components for operation. An embedded architecture that meets the lighting regulations for airport runways is presented. The present work is divided into three main tasks: development of an optical system to optimize lighting according to International Civil Aviation Organization  manufacturing prototype  and model validation.A tunable lighting system integrated by inorganic and transparent organic light-emitting diodesNASA Astrophysics Data System (ADS)Zhang  Jing-jing; Zhang  Tao; Jin  Ya-fang; Liu  Shi-shen; Yuan  Shi-dong; Cui  Zhao; Zhang  Li; Wang  Wei-hui2014-05-01A tunable surface-emitting integrated lighting system is constructed using a combination of inorganic light-emitting diodes (LEDs) and transparent organic LEDs (OLEDs). An RB two-color LED is used to supply red and blue light emission  and a green organic LED is used to supply green light emission. Currents of the LED and OLED are tuned to produce a white color  showing different Commission Internationale d'Eclairage (CIE) chromaticity coordinates and correlated color temperatures with a wide adjustable range. Such an integration can compensate for the lack of the LED's luminance uniformity and the transparent OLED's luminance intensity.System for diffusing light from an optical fiber or light guideDOEpatentsMaitland  Duncan J [Pleasant Hill  CA; Wilson  Thomas S [San Leandro  CA; Benett  William J [Livermore  CA; Small  IV  Ward [2008-06-10A system for diffusing light from an optical fiber wherein the optical fiber is coupled to a light source  comprising forming a polymer element adapted to be connected to the optical fiber and incorporating a scattering element with the polymer element wherein the scattering element diffuses the light from the polymer element. The apparatus of the present invention comprises a polymer element operatively connected to the optical fiber and a scattering element operatively connected with the shape polymer element that diffuses the light from the polymer element.Fly-by-Light Advanced Systems Hardware (FLASH) programNASA Astrophysics Data System (ADS)Bedoya  Carlos A.1995-05-01Fiber optics are immune to electromagnetic emissions and have the potential to eliminate this concern especially in flight critical applications if they can be developed to the same level of technology as current systems using wire to carry the signals. As aircraft become more and more dependent of digital signals to control all systems  the Electromagnetic Environment (EME) will become more and more a concern for the safe long term operation. The International Severe HIRF electromagnetic environment (EME) is less than 2000 Volts per meter below 400 MHz and reaches a maximum of 6 850 Volts per meter in the 4-6 GHz range. The normal assumption is that a metal or composite aircraft skin with appropriate seals provides 20 dB attenuation of the external environment. This reduces peak levels at the avionics boxes to less than 200 Volts per meter below 400 MHz and a maximum of 685 Volts per meter in the 406 GHz range. MIL-STD-461D imposed an additional box level requirement to 200 Volts per meter from 10 KHz to 40 GHz. This requirement equals or surpasses the attenuated HIRF environment over significant portions of the spectrum and implies that the aircraft must be designed to achieve and maintain this value throughout its service life. Although wires can be shielded and designed to achieve these requirements  it is a more expensive process  adds the weight of shielding and requires maintenance of the shielding integrity at all times. The very light weight and high bandwidth of fiber optics also offer the potential of eliminating the number of connections and weight savings in aircraft. For example on a one to one replacement of wire by fiber  it is estimated that fiber would weight about 1/20 the weight of wire. Current wire buses used for duplex communications in aircraft applications have a bandwidth of about 1 MHz while equivalent buses using fiber optics have a bandwidth of 20 MHz. For other applications such as video and avionics interfaces  fiber buses in theResponse to a Community-Based Information and Communication System.ERIC Educational Resources Information CenterTrachtman  Leon E.; And OthersA study investigated the introduction of an experimental school-centered and neighborhood-oriented communication system in a small midwestern town. It was anticipated that normal parent-teacher-school communication would be enhanced by the electronic messaging potential of the system. Researchers observed the entire adoption process from theâ€¦46 CFR 184.602 - Internal communications systems.Code of Federal Regulations  2010 CFR2010-10-01... controlled from the operating station  an efficient communications system must be provided between the... 46 Shipping 7 2010-10-01 2010-10-01 false Internal communications systems. 184.602 Section 184.602 Shipping COAST GUARD  DEPARTMENT OF HOMELAND SECURITY (CONTINUED) SMALL PASSENGER VESSELS (UNDER 100 GROSS...Applications of Light-Responsive Systems for Cancer Theranostics.PubMedChen  Hongzhong; Zhao  Yanli2018-06-27Achieving controlled and targeted delivery of chemotherapeutic drugs and other therapeutic agents to tumor sites is challenging. Among many stimulus strategies  light as a mode of action shows various advantages such as high spatiotemporal selectivity  minimal invasiveness and easy operation. Thus  drug delivery systems (DDSs) have been designed with the incorporation of various functionalities responsive to light as an exogenous stimulus. Early development has focused on guiding chemotherapeutic drugs to designated location  followed by the utilization of UV irradiation for controlled drug release. Because of the disadvantages of UV light such as phototoxicity and limited tissue penetration depth  scientists have moved the research focus onto developing nanoparticle systems responsive to light in the visible region (400-700 nm)  aiming to reduce the phototoxicity. In order to enhance the tissue penetration depth  near-infrared light triggered DDSs become increasingly important. In addition  light-based advanced systems for fluorescent and photoacoustic imaging  as well as photodynamic and photothermal therapy have also been reported. Herein  we highlight some of recent developments by applying light-responsive systems in cancer theranostics  including light activated drug release  photodynamic and photothermal therapy  and bioimaging techniques such as fluorescent and photoacoustic imaging. Future prospect of light-mediated cancer treatment is discussed at the end of the review. This Spotlights on Applications article aims to provide up-to-date information about the rapidly developing field of light-based cancer theranostics.Internal heat gain from different light sources in the building lighting systemsNASA Astrophysics Data System (ADS)Suszanowicz  Dariusz2017-10-01EU directives and the Construction Law have for some time required investors to report the energy consumption of buildings  and this has indeed caused low energy consumption buildings to proliferate. Of particular interest  internal heat gains from installed lighting affect the final energy consumption for heating of both public and residential buildings. This article presents the results of analyses of the electricity consumption and the luminous flux and the heat flux emitted by different types of light sources used in buildings. Incandescent light  halogen  compact fluorescent bulbs  and LED bulbs from various manufacturers were individually placed in a closed and isolated chamber  and the parameters for their functioning under identical conditions were recorded. The heat flux emitted by 1 W nominal power of each light source was determined. Based on the study results  the empirical coefficients of heat emission and energy efficiency ratios for different types of lighting sources (dependent lamp power and the light output) were designated. In the heat balance of the building  the designated rates allow for precise determination of the internal heat gains coming from lighting systems using various light sources and also enable optimization of lighting systems of buildings that are used in different ways.High speed visible light communication using blue GaN laser diodesNASA Astrophysics Data System (ADS)Watson  S.; Viola  S.; Giuliano  G.; Najda  S. P.; Perlin  P.; Suski  T.; Marona  L.; LeszczyÅ„ski  M.; Wisniewski  P.; Czernecki  R.; Targowski  G.; Watson  M. A.; White  H.; Rowe  D.; Laycock  L.; Kelly  A. E.2016-10-01GaN-based laser diodes have been developed over the last 20 years making them desirable for many security and defence applications  in particular  free space laser communications. Unlike their LED counterparts  laser diodes are not limited by their carrier lifetime which makes them attractive for high speed communication  whether in free space  through fiber or underwater. Gigabit data transmission can be achieved in free space by modulating the visible light from the laser with a pseudo-random bit sequence (PRBS)  with recent results approaching 5 Gbit/s error free data transmission. By exploiting the low-loss in the blue part of the spectrum through water  data transmission experiments have also been conducted to show rates of 2.5 Gbit/s underwater. Different water types have been tested to monitor the effect of scattering and to see how this affects the overall transmission rate and distance. This is of great interest for communication with unmanned underwater vehicles (UUV) as the current method using acoustics is much slower and vulnerable to interception. These types of laser diodes can typically reach 50-100 mW of power which increases the length at which the data can be transmitted. This distance could be further improved by making use of high power laser arrays. Highly uniform GaN substrates with low defectivity allow individually addressable laser bars to be fabricated. This could ultimately increase optical power levels to 4 W for a 20-emitter array. Overall  the development of GaN laser diodes will play an important part in free space optical communications and will be vital in the advancement of security and defence applications.Space Shuttle program communication and tracking systems interface analysisNASA Technical Reports Server (NTRS)Dodds  J. G.; Holmes  J. K.; Huth  G. K.; Iwasaki  R. S.; Nilsen  P. W.; Polydoros  A.; Sampaio  D. R.; Udalov  S.1984-01-01The Space Shuttle Program Communications and Tracking Systems Interface Analysis began April 18  1983. During this time  the shuttle communication and tracking systems began flight testing. Two areas of analysis documented were a result of observations made during flight tests. These analyses involved the Ku-band communication system. First  there was a detailed analysis of the interface between the solar max data format and the Ku-band communication system including the TDRSS ground station. The second analysis involving the Ku-band communication system was an analysis of the frequency lock loop of the Gunn oscillator used to generate the transmit frequency. The stability of the frequency lock loop was investigated and changes to the design were reviewed to alleviate the potential loss of data due the loop losing lock and entering the reacquisition mode. Other areas of investigation were the S-band antenna analysis and RF coverage analysis.Living in the dark does not mean a blind life: bird and mammal visual communication in dim lightPubMed Central2017-01-01For many years  it was believed that bird and mammal communication â€˜in the dark of the nightâ€™ relied exclusively on vocal and chemical signalling. However  in recent decades  several case studies have conveyed the idea that the nocturnal world is rich in visual information. Clearly  a visual signal needs a source of light to work  but diurnal light (twilight included  i.e. any light directly dependent on the sun) is not the only source of luminosity on this planet. Actually  moonlight represents a powerful source of illumination that cannot be neglected from the perspective of visual communication. White patches of feathers and fur on a dark background have the potential to be used to communicate with conspecifics and heterospecifics in dim light across different contexts and for a variety of reasons. Here: (i) we review current knowledge on visual signalling in crepuscular and nocturnal birds and mammals; and (ii) we also present some possible cases of birds and mammals that  due to the characteristics of their feather and fur coloration pattern  might use visual signals in dim light. Visual signalling in nocturnal animals is still an emerging field and  to date  it has received less attention than many other means of communication  including visual communication under daylight. For this reason  many questions remain unanswered and  sometimes  even unasked. This article is part of the themed issue â€˜Vision in dim lightâ€™. PMID:28193809",communication systems, 'Personal computer',https://www.science.gov/topicpages/l/light%2Bcommunication%2Bsystem,'light system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,design language, 'Personal computer',https://www.researchgate.net/publication/303891524_EAST-ADL_An_Architecture_Description_Language_for_Automotive_Software-intensive_Systems_in_the_Light_of_Recent_use_and_Research,'light system'
 DATABASE CONCEPTS Software is set of programs developed for specific purpose. Software has wide range of applications like embedded systems  MS Office  ATM  operating systems  email services  internet banking  social media sites  e-commerce sites  antivirus  software in spacecrafts  safety critical systems  etc. The use of software has penetrated deeper into human lives. People from different professions  age groups require software. Software is applicable to every industry or a domain that you could name like banking & financial services  CRM  telecom  aviation  tourism and so on. IT is a huge industry contributing greatly to the economy of the countries by creating job opportunities  globalizing the business activities. The application of software has proved to be more efficient and reliable than manual activities in business applications.Software industry has rapidly evolved after second world war  standardizing the processes in IT industry. A step by step approach to develop the software is called SDLC -Software Development Life Cycle. The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT.Scope identification: The high-level requirements are gathered from the client by the Business Analyst and/or Project Manager. The client is an entity that gets the software developed from the IT company. Example: Bank of America gets the mobile banking software developed for its customers. Here  Bank of America is client and customers of Bank of America are called as end users. The requirements are often documented in Business requirements document.Plan: In the planning phase  IT Project Manager plans the schedule and budget of the project. All the plans are documented in Project Plan document.Analysis:It’s about the detailing the requirements gathered from client. Each requirementis provided with more specifications. The mock up diagrams  use cases  context diagrams  activity diagrams are more commonly used to explain the client requirements. This task is done by Business Analyst. The documents containing requirements and its specifications are to be signed off from the client. The technical team uses these documents to understand the requirements of client  visualize them and develop the software as per the client expectations.Design: The blueprint or programming logic of software is designed by a Technical Architects team. In the programming logic  the programs  steps in the program  interfaces between the programs  data flow  control flow are designed. The database structure is designed by the database team.Development: The developers or programmers refer to the design of the software for programming or coding. The database development develops the database for the software. There are several programming languages like Java  C#  PHP  etc. that can be used to develop the software.SoftwareTesting: The software is tested at different levels of the software development to identify the defects and verify the requirements of the client by developers  QA team and also vendors.Deployment: The thoroughly tested software is released to the client. The developers with assistance of system administrators get the software installed in the production environment. The installation manual has the steps for installation and configuration of the system for installation.User Acceptance testing: The end users test the software to make sure the software meets their requirements. The software testers and business analysts assist the users for testing. The user manual can be referred by users to understand the functioning of software. There are various technologies and tools used throughout the software projects: development platforms like .Net  database management systems  big data solutions like Hadoop  BizTalk  testing frameworks etc.Check your understanding:This article is written by Priya  Sr. Faculty at H2K Infosys.Nice article1. Scope identification  planning  analysis  design  development  testing  deployment and UAT2.Client is a person or a co-operate group for whom product is developed and sold End-user is the person who just use the software bought by client . 3.Reservation system  classroom management  benefits system GISQ.1.1.Requirements gathering 2.Planning 3.Analysis 4.Design 5.Development 6.Testing 7.Deployment 8.U.A.TQ.2.A Client is a person  group company industry  which a software is developed for by an IT company.e.g Amazon          End User are a group of persons that the client develop the software for they are the ones that use the software.e.g Amazon shoppers Q.3.shopping sites e.g Amazon ebay wish etc1.List the steps of SDLC Scope Identification  Planning  Analysis  Design  Development  Testing  Deployment/installation  UAT 2.What is different between client and end users? Client is the company or person that gets the software developed by the IT company and end users are the customers of the client that ultimately use the developed software. 3.Give the examples of the software applications other than mentioned in the above material. Travel(Airline) reservations  department store online shopping  movie theatre ticket reservation  healthcare portals1. List the steps of SDLC Ans: scope identification  planning  analysis  design  development  testing  deployment and UAT. 2.What is different between client and end users? Ans: The client is an entity that gets the software developed from the IT company and users test the software to make sure the software meets their requirements 3:Give the examples of the software applications other than mentioned in the above material. Ans: Windows  Video Games   anything used in computer calls softwareThe following are the steps in Software Development Life Cycle Scope identification  planning  analysis  design  development  testing  deployment and UAT.Client is an entity that gets the software developed from the IT company. End user is the party who gets to use the product or services.Mobile apps  Adobe flash player.1. The SDLC steps are  scope identification  planning  analysis  design  development  testing  deployment and UAT.2. The client is an organization or department getting the developed software where as enduser is the customers or individuals using the software3. MS office  dropbox  wallet etc1. List the steps of SDLC Ans: Scope identification  Planning  Analysis  Design  Development  Testing  Deployment and UAT. 2.What is different between client and end users? Ans: Client is a person or a co-operate group for whom product is developed and sold. End user can be a person or a group of people that use the software or product once it is sold to client in their domain. 3:Give the examples of the software applications other than mentioned in the above material. Ans: Video Games   Different Mobile apps etcList the steps of SDLC The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT.What is different between client and end users? Client is a co-opration for whom the product get developed. End-user is the person who just use the software bought by that co-operation (client).Give the examples of the software applications other than mentioned in the above material. Dropbox  Googel Drive1. Steps of SDLC – Software Development Life Cycle has been broadly segregated into 8 steps over here. They are Scope Identification  Planning  Analysis  Design  Development  Testing  Deployment and UAT. 2. Difference between Client and End User – Client is referred for the entity who gets software developed as per their requirements and End Users are generally who the software is developed for and would be using the END product when it is ready. 3. Software applications are also used by numerous e-commerce companies  to name a few – eBay  JD Sports  amazon.1.List the steps in SDLC Scope identification   Planning  Analysis  Design  Developement Testing  Deployement  UAT 2.What is different between client and end users? The client is an entity that gets the software developed from the IT company. End user is the one who tests  the software to make sure the software meets their requirements. 3:Give the examples of the software applications other than mentioned in the above material. Windows  Firefox  internet explorer   Safari1.	List the steps of SDLC Ans: The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT. 2.	What is the difference between client and end users? Ans: The client is an entity that gets the software developed for its customers  the end users.3.	Give examples of software applications others than the ones mentioned above? Ans: Travelocity is an example of a software application where users can book flights  hotels  cars  etc.1. List the steps of SDLC  The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT.What is different between client and end users? Client is a company or organisation which wants a particular software developed for their requirement. End users are the users who actually use the software which is delivered to the client .Give the examples of the software applications other than mentioned in the above material. Microsoft Gmail  yahoo  video games etc1.	List the steps of SDLC 1.	The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT. 2.	What is different between client and end users? 1.	The client is an entity that gets the software developed from the IT Company. Eg Amazon is client for online shopping project. 2.	The user is an entity that actually uses the software. Eg: in online shopping software  customer is user. 3.	Give the examples of the software applications other than mentioned in the above material. 1.	Online ticket booking. 2.	Online Shopping1) The steps of SDLC are    Requirement gathering    Planning   Analysis   Design   Development   Testing   Development   User acceptance testing 2) The different between client and end users. Client means the company or organization getting  software developed from the IT company. End user means a group of people  who gets to use the final product or services. 3) The examples of the software applications are internet shopping  safari  yahoo etc1. List the steps of SDLC?     Software development life cycle has following steps:     Scope identification  planning  analysis  design  development  testing  deployment and User acceptance testing . 2. What is different between client and end users?     Client- Client is an organization who gets the software from the IT company Eg-Amazon     End users-people who uses the software and its services  Eg-Customers of Amazon 3. Give the examples of the software applications     MS office Internet Explorer Reservation systems Adobe photo shop Video games  apps etc. 1. List the steps of SDLC Scope Identification  Planning  Analysis  Design  Development  Testing  Deployment  UAT. 2. What is different between client and end users? Client: Its an entity that gets the software developed from the IT company. End users: People who uses the software. 3. Give the examples of the software applications other than mentioned in the above material. Medical domain  Facebook   etc.Q1:  Scope identification  planning  analysis  design  development  testing   deployment  UAT2.Client- the person the product is made for/the person buying the product End-user the person the client intends to use the product 3.Reservation system  classroom management  benefits system GIS1dentification planning analysis design development testing deployment UAT2. Client is  the entity that gets the software developed from the IT company and End users is person who uses the software. 3. Some examples of software applications are Firefox  internet explore  online shopping  google  online games etc.1. List the steps of SDLC Scope Identification  Planning  Analysis  Design  Development  Testing  Deployment  UAT. 2. What is different between client and end users? Client: Is the entity that gets the software developed from the IT company. End users: Individuals who uses the software. 3. Give the examples of the software applications other than mentioned in the above material. Flight reservations  insurance  Micros1.) List the steps of SDLCThe steps of SDLC are scope identification  planning  analysis  design  development  testing  deployment and user acceptance testing. 2.) What is different between client and end users?The difference between clients and end users are that clients develop software but customer may be the end users.3.) Give the examples of the software applications other than mentioned in the above material. Windows  Microsoft Word  Yahoo  MSN  ebay  Gmail  are all examples of the software applications1.The steps of SDLC. Scope identification Planning  Analysis  Development  Testing  Deployment and UAT. 2. Difference between client and users. “Client” is a company or an organization who gets the software from the IT company. “Users” are the end users who download the software and uses on purpose. 3. examples of the software applications other than mentioned in the above material. Gmail  Whatsapp  Windows  Facebook etc.SDLC steps: Identifying  Planning  Analyzing  Designing  Developing  Testing  Deployment  and User Acceptance Testing Client The client is an entity that gets the software developed from the IT company. Costumers of the software developed by the client are called end-users. Examples: iTunes  FaceTime  VMware  BlackboardSteps of SDLC Requirement gathering planning analysis design development testing deployment UAT 2) for example any bank like BB&T bank wants an application for customers so BB&T will be the client for us and the bank users who uses the application will be the end users. 3)google photo MS office amazon snapchat skype firefox 1.List the steps of SDLC. 1.Scope identification  Planning  Analysis  Design  Development  Testing  Deployment  User Acceptance Testing2.What is different between client and end users? 2.Client is an entity or person who gets software done by IT company and End Users are persons who are going to use the software.3.Give the examples of the software applications other than mentioned in the above material. 3.Examples like MS office  Spreadsheet  Campus portal  Snapchat   Google drive   etc1. The steps in Software Development Life Cycle Scope identification  planning  analysis  design  development  testing  deployment and UAT.2. . The client is one who gets the software developed from the IT Company. For example Ebay is client for online shopping project. The user is one  that actually uses the software for example in online shopping software  customer is user.3.The examples of the software applications Online shopping Tickets booking Videos and songs like Hungama site Youtube1. The various phases of Software Development Life Cycle: Scope Identification > Planning > Analysis > Design > Development > Testing/Debugging > Deployment > User training/Acceptance. 2. The client is the entity the gets the software developed and the end user is the one who actually uses it. 3. Examples of Software applications: Social networking apps   Music apps  books online.List the steps of SDLC Scope identification planning analysis design development testing deployment and UAT What is different between client and end users? Client is the one who software companies write programs to perform certain functions based on their requirement. End users are the ones who use the functions. Macy shopping website Macys is client and we people when we go online shopping we are the end users. Give the examples of the software applications other than mentioned in the above material. Education websites  Shopping online  emails  Hospitals online booking appointments and reading info   search engines1. Steps of SDLC: Scope identification  planning  analysis  design  develop  test  deployment  UAT2. Difference between client and end user: Client is an entity who wants to get the software developed  they are the ones who provide requirements to the s/w company of how the s/w should behave  while end users are the actual users of the end product  who will actually be using the s/w.3. s/w applications: mobile applications  gamingssteps of SDLC : scope of identification  planning  design  develop  software testing  deployment  UAT. Difference b/w client and user : client – is the one who wants the software to be build for there particular requirements as per their customer expectations for their specific application. end users – are the customers of client who use the software build by the s/w company.s/w applications – ATM   Banking services  shopping websites  Travel tickets  laboratory results and others.Software development life cycle a) scope identification  planning  analysis  design  development  testing deployment and UATb)The client is the entity which needs the  developed software and the end user is the one who actually utilize the product. c)google photo MS office amazon snap chat Skype  Firefox  mobile applications  gaming1  SDLC : scope identification   planning   analysis    design  development  testing   deployment and UAT. 2. The client is the entity that gets the software developed from IT company .the end user test the software to make sure     the software meets the requirements 3. google  Facebook   eBay  amazon etc1. List the steps of SDLC   The steps of software development life cycle are scope identification planning analysis design development testing deployment and UAT.2.What is different between client and end users?Client is an entity that gets the software developed from the it company according to their requirements. End users are the entities who gets to use the functionalities of the developed software. For example in a banking domain the client gets a software for the customers to access their accounts and use it for transactions and other activities and the end users will use the functionalities of the s/w and access their accounts. 3. Examples of software applications Firefox  Microsoft Windows  Excel  power point  gaming apps.1. The steps of SDLC are scope identification  planning  analysis  design  development  testing  deployment and User Acceptance Testing(UAT) 2. Client is an entity or organization that gets it software developed from IT company  for example AT&T web site  Amazon   Net Banking that they are developed for customers. Any customers who use those software for their daily need are users. 3. Software has wide range of application in human life activities. It can be also used for personal development  such as an artist using portfolio website to advertise his artwork  a health monitor app to keep track of daily health activities  a navigation map to reach the places where we never been  and so on.This topic is about SDLC  which is the scope identification  planning analysis  design  development  testing  deployment and user acceptance testingwe as people that uses web and all this varieties of software are uses. we uses in our daily life when open out computers.Softwares comes in different variety and purposes. Software are being develop everyday for different purposes.1-List the steps of The steps of SDLC : Requirement gathering Planning Analysis Design Development Testing Development User acceptance testingSDLC 2-What is different between client and end users? A Client is a person  group company industry  which a software is developed for by an IT company. The Client gives requirment to developer.e.g Amazon End User are a group of persons that the client develop the software for they are the ones that use the software.e.g Amazon shoppers 3-Give the examples of the software applications other than mentioned in the above material.Dorp box  Google   Amazon  ebay Reservation system  classroom management etc1. Scope identification  plan  analysis  design  development  software testing  deployment  user acceptance testing. 2.  Client is an entity/business that gets the software developed from the it company.  End users are the actual people using the software that the client gets developed. 3.  Software in mobile devices  software in smart TV  applications such as YouTube  Amazon  online shopping1.Scope Identification Plan Analysis Design Development Testing Deployment  Ned UAT 2.Clients are the one who develops the software and the person or organization for whom the software is developed are the end users 3.MS Office  Firefox Safari  chrome Pandora Skype AdobeThe steps of SDLC are:: Scope Identification  Planning  analysing  Designing  Development  Software testing  Deployment and finally user acceptance testing. The difference between client and end user is that: The client is the owner of the software for whom the software is developed i.e. the company and the end users are the people using the software for the purpose for which it was made. Eamples of software applications other than mentioned in the above materials are: Microsoft Office. Adobe  Ebay  facebook  Amazon  Google Chrome  Antivirus etcList the steps of SDLC A1 : Scope identification  Requirement gathering  Planning  Analysis  Designing  Development  Testing  Deployment  UAT.What is different between client and end users? A2 : Client are the Software owner/ business  and based on the specific requirements provided by client  developers will develop the software. End users are the actual users who will be using the software once it is deployed in production environment.Give the examples of the software applications other than mentioned in the above material. A3 : Yahoo!  Facebook  Microsoft  Instagram  Ebay  Amazon  Bank of America   ect.Steps in SDLC : identification planning analysis design development testing deployment UAT.Client is the creator and end user is the real user who is going to be benefited out of this application / softare.Examples – Goodle -  Makemy trip   Yahooo   Bank of America  Veriozn  Amazon. .etcSoftware Development Life Cycle 1. Steps of SDLC -Test requirement gathering – Plan – Analysis – Design – Development – Testing – Deployment -UAT (User Acceptance Test) 2.  Client can be an individual or a company who gives a requirement in detail of specific software or an application. End Users are the people or a real user who uses software after a deployment. 3. Example of software application are mobile banking  online shopping website  hotel reservation website  etc.1 Steps of SDLC: Scope identification  Planning  Analysis  Design   Development  Testing  Deployment  UAT.2.The client is a business organization which gets the software developed from the IT company whereas the end user is the one who utilizes the services.3 Examples of the software applications are Gaming apps  facebook Instagram  online shopping  MS Office etc.1 The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT. 2. Client: Is the company that gets the software developed for the end users and End users: Individuals who uses the software. . 3.Examples of the software applications are  Yahoo  mobile app   online shopping websites etcSDLC = Scope Planning Analysis  design Development Testing  deployment and UAT.Client is the “company” and / or person requesting the software. End user will be the person using the software after compilation. Safari  chrome  Firefox.1- Steps of the SDLC      Requirement      Plane      Analysis      Design      Development      Testing      Deployment      UAT 2- Difference between client and end user     A Client is a person or an organization who ask to develop  the software according to their requirement.    An End user a person or employees of the organization  who use that software. 3-Example of software Application    MS Office  Mobile apps Q1.Scope Identification Planning Analysis design development testing deployment and UAT. Q2.A client is  an entity for whom the software is developed for  while the end users  are  ultimate users of the product or services. Q3.Adode Photoshop netbanking amazon Ebay.Q1. List the steps of SDLC  A. Scope Identification  Planning  Analysis  Design  Development  Testing  Deployment/installation  UAT Q2. What is different between client and end users? A. Client is the company or person that gets the software developed by the IT company and end users are the customers of the client that ultimately use the developed software. Q3. Give the examples of the software applications other than mentioned in the above material. A. Travel(Airline) reservations  department store online shopping  movie  ticket reservation  healthcare portalsList the steps of SDLCScope Identification Planning Analysis Design Development Testing Deployment UATWhat is different between client and end users?Client is an entity that gets software developed from the IT company.End users are the people who use the software.  Give the examples of the software applications other than mentioned in the above material.Space flight. Cars Cell phones1. The steps of SDLC are: Scope Identification  Planning  Analysis  Design  Development  Testing  Deployment  UAT. 2. Client is the one who pays for the software to be developed and the end users are the one who actually use the software. 3. iTunes app  patient portals  etcAns.: 1. The Steps of SDLC are: •	Scope Identification •	Plan •	Analysis •	Design •	Development •	Software Testing •	Deployment •	UAT(User Acceptance Testing) 2. The different between client and end users: •	A client is a person  group  company who gets software developed by IT Company BUT Users are generally who uses software or product once it is sold in their domain. •	Client buy your software  product  services BUT Users use the products  software  services that is buy by client. 3.  Examples of software applications are: gmail  yahoo  spreadsheets  database.Q1.	List the steps of SDLC •	Requirement gathering and analysis: Business requirements are gathered in this phase. After requirement gathering these requirements are analyzed for their validity and the possibility of incorporating the requirements in the system to be development is also studied. Finally  a Requirement Specification document is created which serves the purpose of guideline for the next phase of the model. The testing team follows the Software Testing Life Cycle and starts the Test Planning phase after the requirements analysis is completed. •	Design: In this phase the system and software design are prepared from the requirement specifications which were studied in the first phase. In this phase the testers come up with the Test strategy  where they mention what to test  how to test. •	Implementation / Coding: On receiving system design documents  the work is divided in modules/units and actual coding is started. Since  in this phase the code is produced so it is the main focus for the developer. •	Testing: After the code is developed it is tested against the requirements to make sure that the product is actually solving the needs addressed and gathered during the requirements phase. During this phase all types of functional testing like unit testing  integration testing  system testing  acceptance testing is done as well as non-functional testing are also done. •	Deployment: After successful testing the product is delivered / deployed to the customer for their use. As soon as the product is given to the customers they will first do the beta testing. If any changes are required or if any bugs are caught  then they will report it to the engineering team. Once those changes are made or the bugs are fixed then the final deployment will happen. •	Maintenance: Once when the customers starts using the developed system then the actual problems comes up and needs to be solved from time to time. This process where the care is taken for the developed product is known as maintenance.Q2.	What is different between client and end users? Client is the company who is purchasing the software from our company. End user is the person who is actually going to use the software. Q3.	Give the examples of the software applications other than mentioned in the above material. •	Videoconference applications •	VoIP (voice over Internet Protocol) •	Online gaming •	Community storage solutions •	Some e-commerce transactions •	Chatting •	IM (instant messaging)1) List the steps of SDLC: The SDLC Steps are: Gathering information  Plan  Analyse Design Development Test Deploy UAT .2) What is different between client and end users? Client is a person who has given you the Requirement of application they want Eg. BOA and End User is the who will be using in this case it can be Employees BOA customers Etc.3) Give the examples of the software applications other than mentioned in the above material: Retail Store apps like Kohls  Macy’s etc  Paypal  Amazon  international phone call apps like Raza  reliance.1-steps for SDLC Scope identification Planning and analysis Design Implemention and execution Development Test Deployment UAT2-Client is an entity that gets the software developed from the IT company where as end user means who uses the product or it’s services. 3.some software applications are amazon  eBay  google chrome  PayPalSteps of SDLC Scope identification plan analysis design Development testing deployment UAT The client is the entity that owns the software and the end user are the people going to use the software Eg: Gmail  the Shopping site1. Steps of SDLC: scope identification  planning  analysis  design  development  testing  deployment and UAT 2. Client:  entity that gets the software developed from the IT company. / End user: people that going to use the software 3. example: music streaming site  shopping site  e-book reading site etc.what are the steps in sw development life cycle scope identification  planning analysis  design development  testing  deployment and UAT(user acceptance testing) The brief explanations of V model and the steps to follow to finish the project.1.SDLC -Software Development Life Cycle : The SDLC steps are *Scope Identification *Planning *Analysis *Design *Development *Testing *Deployment and *UAT. 2.Client:Client is a person or organization who develop the software application for their business through IT organization. Users: Users are actual End users who get benefit from the software developed by client. 3.Health care   Logistics Insurance  Manufacturing1.The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and    UAT. 2. (A) Client is a product owner/Organization who wants a project/software to be developed for users     (B) Users are the people or employees of the organization who are going to use the software in real time. 3.  Mobile apps  Healthcare software like NexGen  casamba  amazon  Outlook.1 SDLC steps are: Requirements gathering  planning  analysis  design  development  testing  deployment and UTA. 2 A client is a person or organization who desire a product or software to be develop for their users. B users are  the end users who are going to use the software in their life for their own benefit. 3 Mobile apps  amazon  outlook  logistic  manufacturing  healthcare.Steps of SDLC – scope identification  planning  analysis  design  development  testing  deployment  and UAT Client is the entity which has the requirements to be developed as software and product owner. the end users are uses the software for their benefits. facebook  twitter  mobile apps  online banking system etc1. ANS: SDLC: SCOPE IDENTIFICATION PLAN ANALYSIS DESIGN SOFTWARE TESTING DEPLOYMENT USER ACCEPTANCE TESTING. 2. ANS: A CLIENT IS AN ORGANIZATION WHO SETS THE REQUIREMENTS OF SOFTWARE THAT IS CREATED BY  BUSINESS             ANALYSIS OR  PROJECT MANGER.             END USER IS THE BENEFACTOR OF THE  DEVELOPMENT OF SOFTWARE REQUIREMENTS AS PER THE CLIENTS EXPECTATIONS. 3.ANS;  ADOBE FLASH  MICROSOFT OFFICE  GOOGLE CHROME  PAYPAL  MEDICAL AND HEALTH CARE COMPANY AND SO ON.1.The SDLC steps are : Scope identification  Planning  Analysis  Design Development  Testing Deployment UAT 2. Client-> is an entity that gets the software developed from the IT company. End Users->are the actual users who are going to use the developed software. 3.Examples of software applications are: online gaming instant messaging video streaming1.	Steps of SDLC: Requirement gathering  Project Planning  Analysis  Design  Development  Testing  Deployment & User Acceptance Testing 2.	A client is the owner of software and who sets the requirement to develop the software while end users are who uses the software in real life. 3.	Some of the Examples of the Software application are net banking  McAfee anti-virus software  Makemytrip.com  Facebook etc.Steps of SDLC 1. Scope 2. Plan 3. Analysis 4. Design 5. Development 6. Software tester 7. Deployment 8. UATDifference between client and end user is that client is an entity who get the software developed from the IT company and user is the client customers who use the software. Example of software applications are….skype  video games online  paypal  etc1. Steps of SDLC – Scope Identification/Requirements gathering – Planning – Analysis – Design – Development – Testing – Deployment – User Acceptance Testing (UAT) 2. Client is a company that gets the software developed from an IT company. End users are the users who use the developed software. 3. Examples of some software applications are Smart TV software  Smart watches  Sphero  etc.1.steps of SDLC ———————– o.Scope identification o.Planning o.Analysis o.Design o.Developement o.Testing o.deployment o.UAT The client is an entity that gets the software developed from the IT company and users test the software to make sure the software meets their requirements give the examples of the software applications other than mentioned in the above material. Ans: Windows  Video Games   anything used in computer calls software ReplySteps of SDLC are as follows: 1.Requirement gathering from the client which is done by Business Analyst and the documents prepared are called Business Requirement Documents. 2.Planning is done by Project Manager to decide the release of software  cost estimation: hiring members  hardware installation cost software licensing cost etc. the documents prepared are called Project Plan Documents. 3.Analysis of requirements is done by Business Analyst and documents prepared are called Functional Specification Documents are the documents including functionalities  Data to be supported by software  Users that will be accessing the software at any given time performance of the software the documents prpared are supported with mock up diagrams. 4.Design phase is conducted by Architects who are experienced Developers.They prepare the blue print or programming logic and the design for the project called Design documents. 5.Development take place where developers write the source code for the software. 6.Testing where system testing is done by QA to make sure software is free from defects and the documents prepared by testers are called test documents. 7.Deployment of software is the process where software is installed for the client to use is usually done by either developers or System Administrators and the client is provided with Installation Manual. 8.The final step is UAT(user acceptance testing) which is done by the users of the software either in IT environment where it is called Alpha testing or in real time environment where it is called Beta testing.Client is the entity which can be a business or a person requesting for the software to be produced as per their business needs. Client provides this information to the Business Analyst of IT team in details. Ones the software is produced and installed for the client’s business it could be used by his employees or other entities. The people who end up using the software for conducting business activities are then called End Users .Gaming apps  different language learning apps  GPS  Skype are some of the examples of software applications.Steps of SDLC 1. Scope 2. Plan 3. Analysis 4. Design 5. Development 6. Software tester 7. Deployment 8. UATDifference between client and end user is that client is an entity who get the software developed from the IT company and user is the client customers who use the software.Example of software applications are….FB  online video games  online banking etc1. List the steps of SDLC: A) Planning of the project by IT project manager B) Analysis by BA who gather the requirements from client then create document containing the requirements specifications.  Technical team who uses the document created by BA and approved by client to develop the software. C) Design by the technical architect team of programming logic or bluprint D) Development by developers or programmers who refer to the design of software E) Software testing by QA  Developers and vendors to identify defects and verify requirements of client F) Deployment: Software is released to client. Developers with the assistance of system administrators get the software installed in the production environment. G) Users acceptance testing: Software is tested by end users to make sure the software meets their requirements. 2. What is different between client and end users? Clients: Request the development of the software End users: Are the users who by the software from clients 3.Give the examples of the software applications other than mentioned in the above material. Facebook Gmail Banking Telecommunication1.Steps of SDLC (Software development Life Cycle ): – Scope identification – planning – Analysis – Design – Development – Testing – Deployment – UAT ( User acceptance testing ) 2. Difference between client and end users: Client: Client is an entity that gets the software developed fro the IT company. End users: end users is the party that uses the products and services. 3. Examples of Software applications:  Internet browsers like: FireFox  Google chrome  Internet explorer Shopping sites like: Amazon  Ebay  etc Movie player like:  VLC  Windows  media player etcThis is a very detailed piece on SDLC steps and models with practical analogy used for better understanding.1) Steps of SDLC are scope identification  plan  analysis design  development  software testing  deployment  user acceptance testing. 2) Client the the one who gets the software developed from IT companies and users are the one who uses the developed software. 3)Health care  insurance  manufacturing  google  adobe1.List the steps of SDLC:Scope identification planning analysis design development testing deployment and UAT2.The client is the entity which needs the developed software and the end user is the one who actually utilize the product.3.Gmail ATM  Banking services  shopping websites1.SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT. 2.different between client and end users client: Client is an entity that gets the software developed fro the IT company. End users: end users is the party that uses the products and services. 3. examples of the software applications other than mentioned in the above material Online banking paypal ebay amazon….List the steps of SDLC:Software Development life cycle steps: Scope identification/Requirement gathering-from client to BA BRD(Business Requirement Document) Plan:Done by Project Manager document called Project Plan. Analysis:Done by BA Document called Functional Specificational Document Design:done by Architect Design Document Development: by Developers source code document Testing: done by QA Test Documents Deployment: done by Developers document called Installation Manual UAT: Done by users QA BA…  document called User Manual.What is different between client and end users?Give the examples of the software applications other than mentioned in the above material High level of requirement is given by Client to BA he has the entity that gets the software developed from IT company.Where as end users means who will be benefited by using the software.Software applications are online banking Shopping web sites google chrome antivirus etc.. List the steps of SDLC: 1. Scope Identification 2. Planning 3. Analysis 4. Design 5. Development 6. Testing 7. Deployment and 8. UATWhat is different between client and end users? Client is a company who is paying the product or gives all the requirements to the IT Com . For example Company ABC End users are the ones who will use the program. For example  Marketing DepartmentGive the examples of the software applications other than mentioned in the above material. Applications like fro booking rental cars  hotels  air  shopping online  bidding online  AMazonList the steps of SDLC The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT.What is different between client and end users? Client is the product owner who will list the requirements to the BA and end users are the actual users of the software applicationGive the examples of the software applications other than mentioned in the above material online shopping sites 1.Requirement gathering 2.Planning 3.analysis 4.Design 5.Development 6.Testing 7.Deployment 8.User Acceptance testingClient are the one who gives the requirements or projects. Ex: Google is the client who asked developers to develop gmail End users are the one who uses the application developed and tested.  Ex: we people who uses Gmail application for our business or personal use. H2k Infosys  google.com  macys.com  express.com etc.Q.1. List the steps of SDLC: 1. Scope Identification 2. Planning 3. Analysis 4. Design 5. Development 6. Testing 7. Deployment and 8. UATQ.2. What is difference between client and end users? – Client is an entity that gets the software developed fro the IT company.    End users: end users is the party that uses the products and services.Q.3. Give the examples of the software applications other than mentioned in the above material. – Hotel Management System (HMS) – Airline Reservation System – Retail ( Walmart  H&M  Costco etc) – Health and Dental service – Insurance Domain – Amazon -Wish Shopping  Ali express (online shopping ) – Ceridian ( Pay roll System )1.	List the steps of SDLC Gathering requirements  planning  analysis  design  development  testing  deployment and UAT (user acceptance test). 2.	What is different between client and end users? The persons or organization who are providing the requirements for developing software is called client. The persons who are using developed software is called users. Ex: Bank of America gets the mobile banking software developed for its customers. Here  Bank of America is client and customers of Bank of America are called as end users. 3.	Give the examples of the software applications other than mentioned in the above material. Gmail  shopping sites like amazon  flip kart  Facebook  PayPal.1. List the steps of SDLC The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT. 2. What is different between client and end users? The client is the entity that owns the software and asks for it to be developed. The end users are the people who are going to use the software on a daily basis 3.Give the examples of the software applications other than mentioned in the above material Salesforce  AOL Instant Messenger  MS Outlook  AppleWorks and Lotus 1-2-3Q-1:   Steps of SDLC: 1.	Scope Identification 2.	Planning 3.	Analysis 4.	Design 5.	Development 6.	Testing 7.	Deployment 8.	UAT Q-2:  What is different between client and end users? –	Clients make the requirements and purchase the software from an IT company with the purpose of letting their customers or end-users use it. For example  Bank of America has a software developed through an IT company  so the customers can use it to conduct their daily banking activities. Here  Bank of America is client and customers are end users. Q-3:   Examples of the software applications: –	Social media sites such as Facebook  twitter  Instagram  snapchat etc. –	Online payments methods such a PayPal. –	Online ticket booking sites such as fandango.com  AMC theatre. –	Different mobile applications such as1– List the steps of SDLC 1. Scope identification 2. Plan 3. Analysis 4. Design 5. Development 6. Testing 7. Deployment 8. User Acceptance Testing (UAT) 2– What is different between client and end users? The client is the company or entity that will own the software  therefore made the request to have it build. 3– Give the examples of the software applications other than mentioned in the above material. Internet browsers (Firefox  Chrome  Safari)  Microsoft suite products  Skype  mobile software (Pandora)1. List the steps of SDLC •	Scope identification •	Planning •	Analysis •	Design •	Development •	Testing •	Deployment •	User Acceptance Testing. 2.What is different between client and end users? Client is the entity for whom the software being developed   whereas the end users are the ones who uses the actual s/w after being developed. 3.Give the examples of the software applications other than mentioned in the above material.  Shopping sites  mobile applications  games  online payment applications1.. List the steps of SDLC   Scope Identification    Planning   Analysis   Design   Development   Software Testing   Deployment   User Acceptance Testing2. What is different between client and end users?     The client is an entity that gets the software developed from the IT company. Example: Bank of America gets the mobile banking software developed for its customers. Here  Bank of America is client and customers of Bank of America are called as end users3. •  Give the examples of the software applications other than mentioned in the above material.   Amazon  EBay  Citibank  Bank of America1. ANS: SDLC: SCOPE IDENTIFICATION PLAN ANALYSIS DESIGN SOFTWARE TESTING DEPLOYMENT USER ACCEPTANCE TESTING. 2. ANS: A CLIENT IS AN ORGANIZATION WHO SETS THE REQUIREMENTS OF SOFTWARE THAT IS CREATED BY BUSINESS ANALYSIS OR PROJECT MANGER. END USER IS THE BENEFACTOR OF THE DEVELOPMENT OF SOFTWARE REQUIREMENTS AS PER THE CLIENTS EXPECTATIONS. 3.ANS; ADOBE FLASH  MICROSOFT OFFICE  GOOGLE CHROME  PAYPAL  MEDICAL AND HEALTH CARE COMPANY AND SO ON.Software is a set of programs that can efficiently carry designed activity with less man power in any business. To develop these software  IT industry will follow standardized procedure to develop Software which is called SDLC (Software Development Life Cycle). General steps the carry under SDLC are Business analysts  – gather all the requirements from businesses/clients  Project Manager –  will plan the duration and  budget of the project  Business analysts – analyze and document all the requirements in detail  Architect – design the project  programmers – develop the software  QA team –  test the software  Software is deployed and then end users will test the software with the help of developers and QA team before it is used by client. Clients implements software in there business and Users are employees or customers that use the software to operate any activity.1) Scope identification  plan  analysis  design  development  testing  deployment  user acceptance testing. 2) client who is giving requirements to BA and end user who is using the software application! Amazon—client Customers/shoppers of Amazon—enduser 3) Amazon   PayPal  Kaiser   Walmart etc1.List the steps of SDLCScope Identification Planning Analysis Designing Development Testing Deployment/Installation User Acceptance Testing/ User Testing 2.What is different between client and end users?Client is an entity who has  a requirement and will engage IT company to develop an IT application. End users are the real customers who use the developed IT applications.3.Give the examples of the software applications other than mentioned in the above material.Microsoft Office Suite  Adobe Suite  web browsers like Firefox  Google Chrome  etc…1.  the steps of SDLC The SDLC steps are scope identification  planning  analysis  design  development  testing  deployment and UAT. 2.What is different between client and end users? Client is a company or organisation which wants a particular software developed for their requirement. End users are the users who actually use the software which is delivered to the client . 3. Excel  word office1. List the steps of SDLC? 1.. Scope identification  2. Planning  3. Analysis  4. Design  5. Development  6. Testing  7. Deployment 8.UAT2. difference between client and end user?Client is a person or a co-operate group for whom  the product is developed and sold.The one who is investing for the project is client. End users are the people who are going to use the software or system.The people who are taking advantage of the system 3. Give the examples of the software applications other than mentioned in the above material.?Inventory management system Hospital administration payslip preparation ticket reservationList the Steps of SDLC Software Development Life cycle(SDLC) is a step by step approach to develop the software.  The steps are>> 1)Scope Identification – The BA and/or project Manager gather the high level requirements from the client.  Requirements related to functionality  users  performance  data etc. All these are documented in the Business Requirement Document(BRD) 2) Plan – The project Manager   head of the IT project team prepares the project plan. In which the project Manager documents he Schedule( when to start development  when to start testing  when to end testing etc ) and the budget(cost – hardware  software  resources etc). 3) Analysis – The business Analyst prepares a document known as Functional Specification Document(FSD) OR System Requirement Specifications(SRS). This document is a detail of the requirements with the help of mock up diagrams. These are the technical specifications.  Example: Take a mobile banking application   wherein you have account summary- should be displayed on the horizontal tab or vertical tab  how many transactions should be displayed in a page  should it be displayed as a link or button etc. The BA gets an approval or sign off from the client. 4) Design – The Architect prepares the design document. This contains the list of programs to be created  data flow etc. It is the programming logic/blueprint. What steps are being executed in the back end? 5) Development – By using the design Document the developers write the code or do the programming. Programming can be done using different programming languages like Java  c#  Python  Ruby etc. 6) Testing – The software testing is  done at different levels of software development both by developers and testers.  Testing is the executing of the software to identify defects and verify the requirements are in compliance with the client. 7) Deployment – The thoroughly tested software is released to the client. This is done by the Developers  System administrators. The installation manual is used to install the software. 8) User Acceptance Testing – The client use the software and sees whether it meets their requirements. It is done by the users QA  BA . The user manual is referred by the users to understand the functionality of the software.Mnay differenet tools are used throughout the software project – development platforms like .NET  database management systems  big data solutions( Hadoop  Biztalk etc) etc.What is the difference between client and End users? The  client is an entity who gets the software develped from the IT company.  example: BOFA(Bank of America) gets the mobile banking software developed from the IT company for its customers. Here BOFA is the client and the end users are the customers of BOFA.Give the examples of the software applications other than mentioned in the above material. Health care applications like kaiser  Atrium   Norton anti virus  Travel applications like Cheapoair  kayak etc.1. Planning  Analysis  Designing  Development  Testing  Deployment  and UAT. 2. Client is the one who places the requirement for the software to be created and end users are the one who will actually use the software. 3. some examples gaming applications skype  online banking  tele communication.1.List the steps of SDLC : Scope identification  Analysis  Design  Development  Testing  Deployment and Uat. 2.What is different between client and end users? Client is the one who sets the requirement according to their need and the End users test the software to make sure the software meets their requirements. 3.Give the examples of the software applications other than mentioned in the above material. eg: Paypal  online shopping  Banking app Gmail1.	List the steps of SDLC The SDLC steps are:  Scope identification  planning  analysis  design  development  testing  deployment  UAT.2.	What is different between client and end users? The client is an entity that gets the software developed by the IT company. The end user is the one that would ultimately use the client company’s software.  Example: Bank of America gets the mobile banking software developed for its customers. Here  Bank of America is client and customers of Bank of America are called as end users. 3.	Give the examples of the software applications other than mentioned in the above material. Examples of software application: Gmail Toad Data Point HP Quality centerList the steps of SDLC:  scope identification  planning  analysis  design  development  testing  deployment and uat. what is the difference between client and end user:  The person or some organisation who are providing the requirements to  IT company for develop the software is called client. The person who ever using the developed software is called end user. Give the examples of the software applications other than mentioned in the above material : facebook  gmail  bestbuy  shopping  gomeeting etcAnswer 1. Following are the different steps of SDLC( Software Development Life Cycle) a) Planning/ Requirement gathering b) Analysis c) Designing d) Development e) Testing f) Deployment/ Release g) UAT( User Acceptance Testing)Answer 2. Client is the corporation that pays for the software whereas end user is the party that uses the product and service without paying money.Answer 3. There are different type of Software Applications listed below:- 1) Word Processing software:- MS Word  MS Work  Apple Work 2) Spreadsheet software:- MS Excel  Wuatro Pro  Lotus 1-2-3 3) Desktop publishing software:- Adobe page maker  MS publisher  MS Word 4) Database Software:- MS Access  File Maker Pro 5) Communication Software:- MS Net Meeting  IRC  ICQ 6) Presentation Software:- Hyper studio  MS Power Point  Flash  Super Card  Hyber Card 7) Internet Browsers:- Netscape Navigator  IE Firefox  Chrome  8) Email programs:- Eudora  AQL Browser  MS OutlookSDLC steps: Requirement gathering  planning analysis design development software testing deployment UATThe client is an entity who develops the software for business whereas users are the ones who uses the software Software application examples are healthcare  retail  Flight reservation etcHere are answers for questions related to article. 1.List the steps of SDLC-scope identification  planning  analysis  design  development  testing  deployment and UAT.2.What is different between client and end users? -the client is an entity that gets the software developed from the IT company. Example: Bank of America gets the mobile banking software developed for its customers. Here  Bank of America is client and customers of Bank of America are called as end users. The requirements are often documented in Business requirements document.3.Give the examples of the software applications other than mentioned in the above material. Doordash.com  Parentconnect.com1. steps in SDLC Scope identification  Planning Analysis Design Development  Testing  Deployment UAT 2.What is different between client and end users? The client is an entity that gets the software developed from the IT company. End user is the one who tests the software to make sure the software meets their requirements. 3:Give the examples of the software applications other than mentioned in the above material. Windows  Firefox  internet explorer   Safari* List the steps of SDLC: Requirement Gathering; Planning; Analysis; Designing; Development; Testing; Deployment; UAT * 		What is different between client and end users? Client is the one who wants the software to be developed for a specific purpose ; while the end user is the one who will be using the software. For example  a grocery store getting a online shopping website developed   will be the client  while  online grocery shopper will be the the end user using the website * 	Give the examples of the software applications other than mentioned in the above material.: MS Word  Skype  Facebook  Walmart.com  Wellsfargo.com  gotomeeting.com h2kinfosys.comLIST THE STEPS OF SDLC: 1. Scope identification 2.Planning 3.Analysis 4.Design 5.Development 6.Testing 7.Deployment 8.UATThe client is an entity that gets the software developed from the IT company. Customers are an end user. E.g of software application: Telecom domain  online shopping  uber etc.1) SDLC or Software Development Life Cycle is the step by step approach to develop software. It has the following steps: – Scope identification or requirement gathering ~ The BA or PM gather requirements from the client – Planning ~ The Project Manager prepares a Project Plan document outlining the schedule and budget of the project. – Analysis ~ The project requirements are are laid out with all the details and specifications – Design ~ The programming logic  detailed steps  database structure are designed. – Development ~ The developers or programmers develop the codes  database and programs using languages like Java  C++ – Testing – The software is tested at different levels to identify defects and verify the compliance of client requirements. – Deployment ~ The thoroughly tested software is released to the client and set up in the production environment. – UAT or User Acceptance Testing ~ The end users test the software to make sure it meets client’s needs. 2) The difference between client and end users is that the client is an entity that gets the software developed from the IT company and the end users are the customers or users who actually use the software. 3) Additional examples of software applications are e commerce sites like Walmart  Amazon  e-newspapers and magazines  social media sites like Facebook  Youtube  Snapchat  financial institutions  Security Agencies like FBI  CIA  etc..I. Steps of SDLC           1. Requirement gathering / scope identification        2. Panning            3. Analysis       4. Design        5. Development             6. Testing         7. Deployment          8. Users acceptability         II.  Difference between client and end user An end user is the final customer uses the software or got services from the software after it released. Here the end user don’t have direct contact with the IT Company. While a client could be any company or organization widely use software applications to facilitate its task. Give precise and on time services. Here the client communicate with the IT Company.III. Examples of Software application As far as we are living in computerized world  software application is widely used.  In airports  Traffic light system  Hospitals  construction (Design like Auto cad).1. Plan  Analysis  Design  Development  Testing  Deployment  UAT(User Acceptance Test) 2. Client is the one who give information to BA what are their expectations in the software. End users are the real customer that uses the software. 3. Google  Amazon  Facebook  YahooYour email address will not be published. Required fields are marked *Comment Name * Email * Website    User acceptance testing (UAT) is the last phase of the softw...The acceptance testing is a type of formal testing conducted...Exploratory testing is all about discovery  investigation  a...User acceptance testing is needed to build confidence in the...Types of acceptance testing: 1. User acceptance testing is p...User acceptance testing (UAT) is the last phase of the softw...The acceptance testing is a type of formal testing conducted...Exploratory testing is all about discovery  investigation  a...User acceptance testing is needed to build confidence in the...Types of acceptance testing: 1. User acceptance testing is p...,development life cycle ( sdlc ), 'Personal computer',https://www.h2kinfosys.com/blog/software-development-life-cycle/,'light system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.,earliest start time, 'Personal computer',https://www.researchgate.net/publication/234825694_Towards_Adaptive_Power-Aware_Scheduling_for_Real-Time_Tasks_on_DVS-Enabled_Heterogeneous_Clusters,'light system'
" Go to main page org.apache.cocoon.ResourceNotFoundException:           Unable to locate bitstream  <map:read type=""BitstreamReader""> - context:/file:///srv/tomcat-xmlui-oai/webapps/xmlui/sitemap.xmap - 286:70  Cocoon stacktrace [show]  Java stacktrace [show]            The Manakin interface of the DSpace digital repository software.         ",evolutionary prototyping, 'Personal computer',https://brage.bibsys.no/xmlui/bitstream/handle/11250/252228/356726_FULLTEXT01.pdf%3Fsequence%3D2%26isAllowed%3Dy,'light system'
United StatesOwner name: MICROSOFT CORPORATION  WASHINGTONFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CHILIMBI  TRISHUL;PERELMAN  EREZ;REEL/FRAME:016022/0835Effective date: 20050426Year of fee payment: 4Owner name: MICROSOFT TECHNOLOGY LICENSING  LLC  WASHINGTONFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MICROSOFT CORPORATION;REEL/FRAME:034543/0001Effective date: 20141014Year of fee payment: 8,execution time, 'Personal computer',https://www.google.com/patents/US20060242636,'light system'
"Download presentationWe think you have liked this presentation. If you wish to download it  please recommend it to your friends in any social system. Share buttons are a little bit lower. Thank you!Buttons: Presentation is loading. Please wait.Published byBrent Bradford Modified 10 months ago Object Oriented Analysis And Design-IT0207 iiI SemesterConfiguration management                       1                  Evolutionary Software Process ModelsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/1/Evolutionary+Software+Process+Models.jpg""      ""name"": ""Evolutionary Software Process Models""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         2                  1. Which one of the following is not an Evolutionary Process Model?WINWIN Spiral Model Incremental Model Concurrent Development Model Spiral Model All are Evolutionary Software Models Answer:e Explanation: None. 2. The Incremental Model is a result of combination of elements of which two models? Build & FIX Model & Waterfall Model Linear Model & RAD Model Linear Model & Prototyping Model Waterfall Model & RAD Model Answer:c Explanation: Each linear sequence produces a deliverable “increment” of the software and particularly when we have to quickly  deliver a limited functionality system. 3. What is the major advantage of using Incremental Model? Customer can respond to each increment Easier to test and debug It is used when there is a need to get a product to the market early Both b & c Answer:d Explanation: Incremental Model is generally easier to test and debug than other methods of software development because relatively smaller changes  are made during each iteration and is popular particularly when we have to quickly deliver a limited functionality system.However  option “a” can be seen in other models as well like RAD model hence option “d” answers the question.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/2/1.+Which+one+of+the+following+is+not+an+Evolutionary+Process+Model.jpg""      ""name"": ""1. Which one of the following is not an Evolutionary Process Model""      ""description"": ""WINWIN Spiral Model. Incremental Model. Concurrent Development Model. Spiral Model. All are Evolutionary Software Models. Answer:e Explanation: None. 2. The Incremental Model is a result of combination of elements of which two models Build &amp;amp; FIX Model &amp;amp; Waterfall Model. Linear Model &amp;amp; RAD Model. Linear Model &amp;amp; Prototyping Model. Waterfall Model &amp;amp; RAD Model. Answer:c. Explanation: Each linear sequence produces a deliverable increment of the software and particularly when we have to quickly deliver a limited functionality system. 3. What is the major advantage of using Incremental Model Customer can respond to each increment. Easier to test and debug. It is used when there is a need to get a product to the market early. Both b &amp;amp; c. Answer:d. Explanation: Incremental Model is generally easier to test and debug than other methods of software development because relatively smaller changes are made during each iteration and is popular particularly when we have to quickly deliver a limited functionality system.However  option a can be seen in other models as well like RAD model hence option d answers the question.""      ""width"": ""1024"" }                         3                  4. The spiral model was originally proposed byIBM Barry Boehm Pressman Royce Answer:b Explanation: None. 5. The spiral model has two dimensions namely  	and  	_. diagonal  angular radial  perpendicular radial  angular diagonal  perpendicular Answer:c Explanation: The radial dimension of the model represents the cumulative costs and the angular dimension represents the  progress made in completing each cycle. Each loop of the spiral from X-axis clockwise through 360o  represents one phase. 6. How is WINWIN Spiral Model different from Spiral Model? It defines tasks required to define resources  timelines  and other project related information. It defines a set of negotiation activities at the beginning of each pass around the spiral. It defines tasks required to assess both technical and management risks. It defines tasks required to construct  test  install  and provide user support. Answer:b Explanation: Except option “b” all other tasks/activities are present in Spiral Model as well.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/3/4.+The+spiral+model+was+originally+proposed+by.jpg""      ""name"": ""4. The spiral model was originally proposed by""      ""description"": ""IBM. Barry Boehm. Pressman. Royce. Answer:b Explanation: None. 5. The spiral model has two dimensions namely and _. diagonal  angular. radial  perpendicular. radial  angular. diagonal  perpendicular. Answer:c. Explanation: The radial dimension of the model represents the cumulative costs and the angular dimension represents the progress made in completing each cycle. Each loop of the spiral from X-axis clockwise through 360o represents one phase. 6. How is WINWIN Spiral Model different from Spiral Model It defines tasks required to define resources  timelines  and other project related information. It defines a set of negotiation activities at the beginning of each pass around the spiral. It defines tasks required to assess both technical and management risks. It defines tasks required to construct  test  install  and provide user support. Answer:b. Explanation: Except option b all other tasks/activities are present in Spiral Model as well.""      ""width"": ""1024"" }                         4                  7. Identify the disadvantage of Spiral Model.a) Doesn’t work well for smaller projects High amount of risk analysis Strong approval and documentation control Additional Functionality can be added at a later date Answer:a Explanation: All other options are the advantages of Spiral Model. 8. Spiral Model has user involvement in all its phases. True False Answer:b Explanation: None. 9. How is Incremental Model different from Spiral Model? Progress can be measured for Incremental Model. Changing requirements can be accommodated in Incremental Model. Users can see the system early in Incremental Model.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/4/7.+Identify+the+disadvantage+of+Spiral+Model..jpg""      ""name"": ""7. Identify the disadvantage of Spiral Model.""      ""description"": ""a) Doesn’t work well for smaller projects. High amount of risk analysis. Strong approval and documentation control. Additional Functionality can be added at a later date. Answer:a. Explanation: All other options are the advantages of Spiral Model. 8. Spiral Model has user involvement in all its phases. True. False. Answer:b. Explanation: None. 9. How is Incremental Model different from Spiral Model Progress can be measured for Incremental Model. Changing requirements can be accommodated in Incremental Model. Users can see the system early in Incremental Model.""      ""width"": ""1024"" }                         5                  10. If you were to create client/server applications  which model would you go for?WINWIN Spiral Model Spiral Model Concurrent Model Incremental Model Answer:c Explanation: When applied to client/server applications  the concurrent process model defines activities in two dimensions: a system dimension and a component dimension.Thus Concurrency is achieved by system and component activities occurring simultaneously and can be modeled using the state-oriented approach.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/5/10.+If+you+were+to+create+client%2Fserver+applications%2C+which+model+would+you+go+for.jpg""      ""name"": ""10. If you were to create client/server applications  which model would you go for""      ""description"": ""WINWIN Spiral Model. Spiral Model. Concurrent Model. Incremental Model. Answer:c. Explanation: When applied to client/server applications  the concurrent process model defines activities in two dimensions: a system dimension and a component dimension.Thus Concurrency is achieved by system and component activities occurring simultaneously and can be modeled using the state-oriented approach.""      ""width"": ""1024"" }                         6                  Fourth Generation TechniquesSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/6/Fourth+Generation+Techniques.jpg""      ""name"": ""Fourth Generation Techniques""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         7                  1. Identify a fourth generation language(4GL) from the given below.FORTRAN COBOL Unix shell C++ Answer:c Explanation: Rest all are third generation languages(3GL). 2. Arrange the following activities for making a software product using 4GT. Design strategy Transformation into product Implementation Requirement gathering a) 1  4  3   2 b) 4  3  1  2 c) 4  1  3  2 d) 1  3  4  2 Explanation: The sequence of activities mentioned in option c represents the Fourth Generation Techniques(4GT)Model. 3. 4GL is an example of  	processing. White Box Black Box Functional Both a & b Both b & c Answer:e Explanation: Functional processing/testing is also referred to as black box testing in which contents of the black box are not known.Almost anything  might be referred to as a black box:an algorithm or the human mind.Functionality of the black box is understood in terms of its inputs and outputs.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/7/1.+Identify+a+fourth+generation+language%284GL%29+from+the+given+below..jpg""      ""name"": ""1. Identify a fourth generation language(4GL) from the given below.""      ""description"": ""FORTRAN. COBOL. Unix shell. C++ Answer:c. Explanation: Rest all are third generation languages(3GL). 2. Arrange the following activities for making a software product using 4GT. Design strategy. Transformation into product. Implementation. Requirement gathering a) 1  4  3  2. b) 4  3  1  2. c) 4  1  3  2. d) 1  3  4  2. Explanation: The sequence of activities mentioned in option c represents the Fourth Generation Techniques(4GT)Model. 3. 4GL is an example of processing. White Box. Black Box. Functional. Both a &amp;amp; b. Both b &amp;amp; c. Answer:e. Explanation: Functional processing/testing is also referred to as black box testing in which contents of the black box are not known.Almost anything might be referred to as a black box:an algorithm or the human mind.Functionality of the black box is understood in terms of its inputs and outputs.""      ""width"": ""1024"" }                         8                  4. The 4GT Model is a package of  	.CASE Tools Software tools Software Programs Answer:b Explanation: 4GT encompasses a broad array of software tools enabling the software engineer to specify the  characteristics at a high level leading to an automatically generated source code based on these specifications. 5. Which of the following is not a type of a 4GL? One originating  	_. on Lisp machine on report generators from database query languages from GUI creators Answer:a Explanation: Fifth-generation programming language are built on LISP. 6. In 4GT  we can specify the user requirements in graphic notation or small abbreviated language form. True False Explanation: None.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/8/4.+The+4GT+Model+is+a+package+of+..jpg""      ""name"": ""4. The 4GT Model is a package of .""      ""description"": ""CASE Tools. Software tools. Software Programs. Answer:b. Explanation: 4GT encompasses a broad array of software tools enabling the software engineer to specify the characteristics at a high level leading to an automatically generated source code based on these specifications. 5. Which of the following is not a type of a 4GL One originating _. on Lisp machine. on report generators. from database query languages. from GUI creators. Answer:a. Explanation: Fifth-generation programming language are built on LISP. 6. In 4GT  we can specify the user requirements in graphic notation or small abbreviated language form. True. False. Explanation: None.""      ""width"": ""1024"" }                         9                  7. Productivity of software engineers is reduced in using a 4GT.True False Answer:b Explanation: 4GLs are more programmer-friendly and enhance programming efficiency with usage of English-like words and  phrases  thereby increasing the productivity of professionals able to engage in software development. 8. Which of the following 4GLs invented at IBM and subsequently adopted by ANSI and ISO as the standard language for managing structured data? SQL PROLOG C JAVA Answer:a Explanation: C & JAVA are third generation languages(3GLs) wheras PROLOG is a 5GL. 9. What is a major advantage of using a 4GT Model for producing small scale  products  applications or programs ? Improved productivity of software engineers. Reduction in software development time. 4GT helped by CASE tools and code generators offers a credible solution to many software problems. Explanation: Since automated coding is done using CASE tools & code generators proponents claim a dramatic reduction in  software development time.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/9/7.+Productivity+of+software+engineers+is+reduced+in+using+a+4GT..jpg""      ""name"": ""7. Productivity of software engineers is reduced in using a 4GT.""      ""description"": ""True. False. Answer:b. Explanation: 4GLs are more programmer-friendly and enhance programming efficiency with usage of English-like words and phrases  thereby increasing the productivity of professionals able to engage in software development. 8. Which of the following 4GLs invented at IBM and subsequently adopted by ANSI and ISO as the standard language for managing. structured data SQL. PROLOG. C. JAVA. Answer:a. Explanation: C &amp;amp; JAVA are third generation languages(3GLs) wheras PROLOG is a 5GL. 9. What is a major advantage of using a 4GT Model for producing small scale products  applications or programs Improved productivity of software engineers. Reduction in software development time. 4GT helped by CASE tools and code generators offers a credible solution to many software problems. Explanation: Since automated coding is done using CASE tools &amp;amp; code generators proponents claim a dramatic reduction in software development time.""      ""width"": ""1024"" }                         10                  10. Which of the following model has a major disadvantage in terms of the coding phase of a software life cycle model ? Spiral Model Waterfall Model Rad Model 4GT Model Answer:d Explanation: Since coding phase is eliminated in 4GT Model more expertise is required for analysis design and testing activities.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/10/10.+Which+of+the+following+model+has+a+major+disadvantage+in+terms+of+the+coding+phase+of+a+software+life+cycle+model.jpg""      ""name"": ""10. Which of the following model has a major disadvantage in terms of the coding phase of a software life cycle model""      ""description"": ""Spiral Model. Waterfall Model. Rad Model. 4GT Model. Answer:d. Explanation: Since coding phase is eliminated in 4GT Model more expertise is required for analysis design and testing activities.""      ""width"": ""1024"" }                         11                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/11/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         12                  Selection of a Life Cycle ModelSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/12/Selection+of+a+Life+Cycle+Model.jpg""      ""name"": ""Selection of a Life Cycle Model""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         13                  1. Selection of a model is based onRequirements Development team Users Project type and associated risk All of the mentioned Answer:e Explanation: Each model has to have some requirements  a team of developers  users and the risk involved in developing a project. 2. Which two models doesn’t allow defining requirements early in the cycle? Waterfall & RAD Prototyping & Spiral Prototyping & RAD Waterfall & Spiral Answer:b Explanation: Prototyping Model starts with a requirements analysis phase including techniques like FAST  QFD  Brainstorming.In  case of Spiral model the first phase involves activities related to customer communication like determining objectives. 3. Which of the following life cycle model can be chosen if the development team has less experience on similar projects? Spiral Waterfall RAD Iterative Enhancement Model Answer:a Explanation: Relying on risk assessment/analysis provides more flexibility than required for many applications which  overcomes the criteria of less experienced developers.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/13/1.+Selection+of+a+model+is+based+on.jpg""      ""name"": ""1. Selection of a model is based on""      ""description"": ""Requirements. Development team. Users. Project type and associated risk. All of the mentioned. Answer:e. Explanation: Each model has to have some requirements  a team of developers  users and the risk involved in developing a project. 2. Which two models doesn’t allow defining requirements early in the cycle Waterfall &amp;amp; RAD. Prototyping &amp;amp; Spiral. Prototyping &amp;amp; RAD. Waterfall &amp;amp; Spiral. Answer:b. Explanation: Prototyping Model starts with a requirements analysis phase including techniques like FAST  QFD  Brainstorming.In case of Spiral model the first phase involves activities related to customer communication like determining objectives. 3. Which of the following life cycle model can be chosen if the development team has less experience on similar projects Spiral. Waterfall. RAD. Iterative Enhancement Model. Answer:a. Explanation: Relying on risk assessment/analysis provides more flexibility than required for many applications which overcomes the criteria of less experienced developers.""      ""width"": ""1024"" }                         14                  4. If you were a lead developer of a software company and you are asked to submit a project/product within a stipulated time-frame with no cost barriers  which model would you select? Waterfall Spiral RAD Incremental Answer:c Explanation: RAD model is inapplicable to develop cheaper products/software/projects as the cost of modeling  hiring highly skilled  developers/designers and automated code generation is very high.But here the cost is not an issue  so one can select this model as it  reduces development time. 5. Which two of the following models will not be able to give the desired outcome if user’s participation is not involved? Waterfall & Spiral RAD & Spiral RAD & Waterfall RAD & Prototyping Answer:d Explanation: Active Participation of user is involved in all the four phases of RAD model and in case of the Prototyping model we need user’s presence/involvement every time a new prototype is build or designed. 6. A company is developing an advance version of their current software available in the market  what model approach would they prefer ? Iterative Enhancement Both a & b Answer:c Explanation: None.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/14/4.+If+you+were+a+lead+developer+of+a+software+company+and+you+are+asked+to+submit+a+project%2Fproduct+within+a+stipulated+time-frame+with+no+cost+barriers%2C+which+model+would+you+select.jpg""      ""name"": ""4. If you were a lead developer of a software company and you are asked to submit a project/product within a stipulated time-frame with no cost barriers  which model would you select""      ""description"": ""Waterfall. Spiral. RAD. Incremental. Answer:c. Explanation: RAD model is inapplicable to develop cheaper products/software/projects as the cost of modeling  hiring highly skilled developers/designers and automated code generation is very high.But here the cost is not an issue  so one can select this model as it reduces development time. 5. Which two of the following models will not be able to give the desired outcome if user’s participation is not involved Waterfall &amp;amp; Spiral. RAD &amp;amp; Spiral. RAD &amp;amp; Waterfall. RAD &amp;amp; Prototyping. Answer:d. Explanation: Active Participation of user is involved in all the four phases of RAD model and in case of the Prototyping model we need user’s presence/involvement every time a new prototype is build or designed. 6. A company is developing an advance version of their current software available in the market  what model approach would they prefer Iterative Enhancement. Both a &amp;amp; b. Answer:c Explanation: None.""      ""width"": ""1024"" }                         15                  7. One can choose Waterfall Model if the project development schedule is tight.True False Answer:b Explanation: Real projects rarely follow the sequential flow and iterations in this model are handled indirectly. Thus changes can  cause confusion as the project proceeds thereby delaying the delivery date. 8. Choose the correct option from given below: Prototyping Model facilitates re-usability of components RAD Model Model facilitates re-usability of components Both RAD & Prototyping Model facilitates re-usability of components none Answer:c Explanation: None. 9. Spiral Model has high reliability requirements. Answer:a Explanation: None. 10. RAD Model has high reliability requirements. Answer:b Explanation: None.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/15/7.+One+can+choose+Waterfall+Model+if+the+project+development+schedule+is+tight..jpg""      ""name"": ""7. One can choose Waterfall Model if the project development schedule is tight.""      ""description"": ""True. False. Answer:b. Explanation: Real projects rarely follow the sequential flow and iterations in this model are handled indirectly. Thus changes can cause confusion as the project proceeds thereby delaying the delivery date. 8. Choose the correct option from given below: Prototyping Model facilitates re-usability of components. RAD Model Model facilitates re-usability of components. Both RAD &amp;amp; Prototyping Model facilitates re-usability of components. none. Answer:c Explanation: None. 9. Spiral Model has high reliability requirements. Answer:a Explanation: None. 10. RAD Model has high reliability requirements. Answer:b Explanation: None.""      ""width"": ""1024"" }                         16                  Requirement EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/16/Requirement+Engineering.jpg""      ""name"": ""Requirement Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         17                  1. What are the types of requirements ?Availability Reliability Usability Flexibility All of the mentioned Answer:e Explanation: All the mentioned traits are beneficial for an effective product to be developed. 2. Select the developer specific requirement ? Potability Maintainability Both a and b Answer:d Explanation: Availability is user specific requirement. 3. Which one of the following is not a step of requirement engineering? elicitation design analysis documentation Answer:b Explanation: Requirement Elicitation  Requirement Analysis  Requirement Documentation and Requirement Review are the four  crucial process steps of requirement engineering.Design is in itself a different phase of Software Engineering.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/17/1.+What+are+the+types+of+requirements.jpg""      ""name"": ""1. What are the types of requirements""      ""description"": ""Availability. Reliability. Usability. Flexibility. All of the mentioned. Answer:e. Explanation: All the mentioned traits are beneficial for an effective product to be developed. 2. Select the developer specific requirement Potability. Maintainability. Both a and b. Answer:d. Explanation: Availability is user specific requirement. 3. Which one of the following is not a step of requirement engineering elicitation. design. analysis. documentation. Answer:b. Explanation: Requirement Elicitation  Requirement Analysis  Requirement Documentation and Requirement Review are the four crucial process steps of requirement engineering.Design is in itself a different phase of Software Engineering.""      ""width"": ""1024"" }                         18                  4. FAST stands for Functional Application Specification Technique Fast Application Specification Technique Facilitated Application Specification Technique None of the mentioned Answer:c Explanation: None. 5. QFD stands for quality function design quality function development quality function deployment none of the mentioned 6. A Use-case actor is always a person having a role that different people may play. True False Answer:b Explanation: Use-case Actor is anything that needs to interact with the system  be it a person or another (external) system. 7. The user system requirements are the parts of which document ? SDD SRS DDD Explanation: Software requirements specification (SRS)  is a complete description of the behaviour of a system to be developed and may include a  set of use cases that describe interactions the users will have with the software.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/18/4.+FAST+stands+for+Functional+Application+Specification+Technique.+Fast+Application+Specification+Technique..jpg""      ""name"": ""4. FAST stands for Functional Application Specification Technique. Fast Application Specification Technique.""      ""description"": ""Facilitated Application Specification Technique. None of the mentioned. Answer:c. Explanation: None. 5. QFD stands for. quality function design. quality function development. quality function deployment. none of the mentioned. 6. A Use-case actor is always a person having a role that different people may play. True. False. Answer:b. Explanation: Use-case Actor is anything that needs to interact with the system  be it a person or another (external) system. 7. The user system requirements are the parts of which document SDD. SRS. DDD. Explanation: Software requirements specification (SRS)  is a complete description of the behaviour of a system to be developed and may include a set of use cases that describe interactions the users will have with the software.""      ""width"": ""1024"" }                         19                  8. A stakeholder is anyone who will purchase the completed software system under development.True False Answer:b Explanation: Stakeholders are anyone who has an interest in the project. Project stakeholders are individuals and  organizations that are actively involved in the project  or whose interests may be affected as a result of project execution  or project completion. 9. Conflicting requirements are common in Requirement Engineering  with each client proposing his or her version is the right one. Answer:a Explanation: This situation is seen in every field of work as each professional has his/her way of looking onto things &  would argue to get his/her point approved. 10. Which is one of the most important stakeholder from the following ? Entry level personnel Middle level stakeholder Managers Users of the software Answer:d Explanation: Users are always the most important stakeholders.After all  without users or customers  what’s the point of being in business?.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/19/8.+A+stakeholder+is+anyone+who+will+purchase+the+completed+software+system+under+development..jpg""      ""name"": ""8. A stakeholder is anyone who will purchase the completed software system under development.""      ""description"": ""True. False. Answer:b. Explanation: Stakeholders are anyone who has an interest in the project. Project stakeholders are individuals and organizations that are actively involved in the project  or whose interests may be affected as a result of project execution or project completion. 9. Conflicting requirements are common in Requirement Engineering  with each client proposing his or her version is the right one. Answer:a. Explanation: This situation is seen in every field of work as each professional has his/her way of looking onto things &amp;amp; would argue to get his/her point approved. 10. Which is one of the most important stakeholder from the following Entry level personnel. Middle level stakeholder. Managers. Users of the software. Answer:d. Explanation: Users are always the most important stakeholders.After all  without users or customers  what’s the point of being in business .""      ""width"": ""1024"" }                         20                  Functional and Non-Functional RequirementsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/20/Functional+and+Non-Functional+Requirements.jpg""      ""name"": ""Functional and Non-Functional Requirements""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         21                  1. Which one of the following is a functional requirement ?Maintainability Portability Robustness Testability None of the mentioned Answer:e Explanation: All are non-functional requirements representing quality of the system. Functional requirements describe what the  software has to do. 2. Which one of the following is a requirement that fits in a developer’s module ? Availability Usability Flexibility Answer:b Explanation: A developer needs to test his product before launching it into the market. 3. “Consider a system where  a heat sensor detects an intrusion and alerts the security company.” What kind of a requirement the system is providing ? Functional Non-Functional Known Requirement Answer:a Explanation: Functional requirements describe what the software has to do.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/21/1.+Which+one+of+the+following+is+a+functional+requirement.jpg""      ""name"": ""1. Which one of the following is a functional requirement""      ""description"": ""Maintainability. Portability. Robustness. Testability. None of the mentioned. Answer:e. Explanation: All are non-functional requirements representing quality of the system. Functional requirements describe what the software has to do. 2. Which one of the following is a requirement that fits in a developer’s module Availability. Usability. Flexibility. Answer:b. Explanation: A developer needs to test his product before launching it into the market. 3. Consider a system where  a heat sensor detects an intrusion and alerts the security company. What kind of a requirement the. system is providing Functional. Non-Functional. Known Requirement. Answer:a. Explanation: Functional requirements describe what the software has to do.""      ""width"": ""1024"" }                         22                  4. Which of the following statements explains portabililty in non-functional requirements?It is a degree to which software running on one platform can easily be converted to run on another platform. It can be enhanced by using languages  OS’ and tools that are universally available and standardized. The ability of the system to behave consistently in a user-acceptable manner when operating within the environment for which  the system was intended. Both a and b It refers to the level at which a software system uses scarce computational resources  such as CPU cycles  memory  disk  space  buffers and communication channels. Answer:d Explanation: Option c is termed as reliability and option e refers to efficiency. 5. Functional requirements capture the intended behavior of the system. True False Answer:a Explanation: The behavior of functional requirements may be expressed as services  tasks or functions the system is required  to perform. 6. Choose the incorrect statement with respect to Non-Functional Requirement(NFR). Product-oriented Approach – Focus on system (or software) quality Process-oriented Approach – Focus on how NFRs can be used in the design process Quantitative Approach – Find measurable scales for the functionality attributes Qualitative Approach – Study various relationships between quality goals Answer:c Explanation: Quantitative Approaches in NFRs are used to find measurable scales for the quality attributes like efficiency   flexibility  integrity  usability etc.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/22/4.+Which+of+the+following+statements+explains+portabililty+in+non-functional+requirements.jpg""      ""name"": ""4. Which of the following statements explains portabililty in non-functional requirements""      ""description"": ""It is a degree to which software running on one platform can easily be converted to run on another platform. It can be enhanced by using languages  OS’ and tools that are universally available and standardized. The ability of the system to behave consistently in a user-acceptable manner when operating within the environment for which the system was intended. Both a and b. It refers to the level at which a software system uses scarce computational resources  such as CPU cycles  memory  disk space  buffers and communication channels. Answer:d. Explanation: Option c is termed as reliability and option e refers to efficiency. 5. Functional requirements capture the intended behavior of the system. True. False. Answer:a. Explanation: The behavior of functional requirements may be expressed as services  tasks or functions the system is required to perform. 6. Choose the incorrect statement with respect to Non-Functional Requirement(NFR). Product-oriented Approach – Focus on system (or software) quality. Process-oriented Approach – Focus on how NFRs can be used in the design process. Quantitative Approach – Find measurable scales for the functionality attributes. Qualitative Approach – Study various relationships between quality goals. Answer:c. Explanation: Quantitative Approaches in NFRs are used to find measurable scales for the quality attributes like efficiency  flexibility  integrity  usability etc.""      ""width"": ""1024"" }                         23                  7. How many classification schemes have been developed for NFRs ?Two Three Four Five Answer:d Explanation: Software Quality Tree [Boehm 1976]  Roman [IEEE Computer 1985]  Process-Product-External considerations [Sommerville 1992]  Mc Call’s NFR list and Dimensions of Quality–Components of FURPS+ are the five classification schemes for NFRs. 8. According to components of FURPS+  which of the following does not belong to S ? Testability Speed Efficiency Serviceability Installability Answer:b Explanation: Speed Efficiency belong to Performance (P) in FURPS+. 9. Does software wear & tear by decomposition ? Yes No Explanation: Unlike hardware  software is reliable.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/23/7.+How+many+classification+schemes+have+been+developed+for+NFRs.jpg""      ""name"": ""7. How many classification schemes have been developed for NFRs""      ""description"": ""Two. Three. Four. Five. Answer:d. Explanation: Software Quality Tree [Boehm 1976]  Roman [IEEE Computer 1985]  Process-Product-External considerations [Sommerville 1992]  Mc Call’s NFR list and Dimensions of Quality–Components of FURPS+ are the five classification schemes for NFRs. 8. According to components of FURPS+  which of the following does not belong to S Testability. Speed Efficiency. Serviceability. Installability. Answer:b. Explanation: Speed Efficiency belong to Performance (P) in FURPS+. 9. Does software wear &amp;amp; tear by decomposition Yes. No. Explanation: Unlike hardware  software is reliable.""      ""width"": ""1024"" }                         24                  10. What are the four dimensions of Dependability ?Usability  Reliability  Security  Flexibility Availability  Reliability  Maintainability  Security Availability  Reliability  Security  Safety Security  Safety  Testability  Usability Answer:c Explanation: All the traits of option c sync with dependability. 11. Choose the correct statement on how NFRs integrates with Rational Unified Process ? System responds within 4 seconds on average to local user requests and changes in the environment. System responds within 4 seconds on average to remote user requests and changes in the environment. Answer:b Explanation: System response to a local user is 2 seconds on average.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/24/10.+What+are+the+four+dimensions+of+Dependability.jpg""      ""name"": ""10. What are the four dimensions of Dependability""      ""description"": ""Usability  Reliability  Security  Flexibility. Availability  Reliability  Maintainability  Security. Availability  Reliability  Security  Safety. Security  Safety  Testability  Usability. Answer:c. Explanation: All the traits of option c sync with dependability. 11. Choose the correct statement on how NFRs integrates with Rational Unified Process System responds within 4 seconds on average to local user requests and changes in the environment. System responds within 4 seconds on average to remote user requests and changes in the environment. Answer:b. Explanation: System response to a local user is 2 seconds on average.""      ""width"": ""1024"" }                         25                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/25/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         26                  Extreme Programming Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/26/Extreme+Programming+Source+%26+Courtsey%3A.jpg""      ""name"": ""Extreme Programming Source &amp;amp; Courtsey:""      ""description"": ""Extreme Programming Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         27                  1. Incremental development in Extreme Programming (XP) is supported through a system release once every month. True False Answer:b Explanation: Incremental development is supported through small  frequent system releases. 2. In XP  as soon as the work on a task is complete  it is integrated into the whole system. Answer:a Explanation: XP follows a continuous integration approach.After any such integration  all the unit tests in the system must pass. 3. In XP Increments are delivered to customers every  	weeks. One Two Three Four Explanation: Extreme Programming (XP) takes an ‘extreme’ approach to iterative development.New versions may be  built several times per day  hence delivering the increment for approval every 2nd week after testing the new version.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/27/1.+Incremental+development+in+Extreme+Programming+%28XP%29+is+supported+through+a+system+release+once+every+month..jpg""      ""name"": ""1. Incremental development in Extreme Programming (XP) is supported through a system release once every month.""      ""description"": ""True. False. Answer:b. Explanation: Incremental development is supported through small  frequent system releases. 2. In XP  as soon as the work on a task is complete  it is integrated into the whole system. Answer:a. Explanation: XP follows a continuous integration approach.After any such integration  all the unit tests in the system must pass. 3. In XP Increments are delivered to customers every weeks. One. Two. Three. Four. Explanation: Extreme Programming (XP) takes an ‘extreme’ approach to iterative development.New versions may be built several times per day  hence delivering the increment for approval every 2nd week after testing the new version.""      ""width"": ""1024"" }                         28                  4. User requirements are expressed as  	in Extreme Programming.implementation tasks functionalities scenarios Answer:c Explanation: User requirements are expressed as scenarios or user stories.These are written on cards and the  development team break them down into implementation tasks. These tasks are the basis of schedule and cost estimates. 5. Is a customer involved test development and validation in XP ? Yes No It may vary from Customer to Customer Explanation: The role of the customer in the testing process is to help develop acceptance tests for the stories that are to be implemented in the next release of the system.However  people adopting the customer role have limited time available and so cannot work full-time with the development team. They may feel that providing the requirements was enough of a contribution and so may be reluctant to get involved in the testing process. 6. Programmers prefer programming to testing and sometimes they take short cuts when writing tests. For example  they  may write incomplete tests that do not check for all possible exceptions that may occur. True False Answer:a Explanation: In XP Some tests can be very difficult to write incrementally.For example  in a complex user interface  it is often difficult to write unit tests for the code that implements the ‘display logic’ and workflow between screens.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/28/4.+User+requirements+are+expressed+as+in+Extreme+Programming..jpg""      ""name"": ""4. User requirements are expressed as in Extreme Programming.""      ""description"": ""implementation tasks. functionalities. scenarios. Answer:c. Explanation: User requirements are expressed as scenarios or user stories.These are written on cards and the development team break them down into implementation tasks. These tasks are the basis of schedule and cost estimates. 5. Is a customer involved test development and validation in XP Yes. No. It may vary from Customer to Customer. Explanation: The role of the customer in the testing process is to help develop acceptance tests for the stories that are to be implemented in the next release of the system.However  people adopting the customer role have limited time available and so cannot work full-time with the development team. They may feel that providing the requirements was enough of a contribution and so may be reluctant to get involved in the testing process. 6. Programmers prefer programming to testing and sometimes they take short cuts when writing tests. For example  they may write incomplete tests that do not check for all possible exceptions that may occur. True. False. Answer:a. Explanation: In XP Some tests can be very difficult to write incrementally.For example  in a complex user interface  it is often difficult to write unit tests for the code that implements the ‘display logic’ and workflow between screens.""      ""width"": ""1024"" }                         29                  7. Tests are automated in Extreme Programming.True False Answer:a Explanation: Automated test harnesses are used to run all component tests each time that a new release is built. 8. In XP an automated unit test framework is used to write tests for a new piece of functionality before that functionality itself is  implemented. Explanation: XP follows Test-first development approach. 9. Developers work individually on a release and they compare their results with other developers before forwarding that release to  customers. Answer:b Explanation: XP follows the principle of pair programming which means developers work in pairs  checking each other’s work and providing the support to always do a good job. 10. Which four framework activities are found in the Extreme Programming(XP) ? analysis  design  coding  testing planning  analysis  design  coding planning  design  coding  testing planning  analysis  coding  testing Answer:c Explanation: XP involves the mentioned four activities  and in the same in order.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/29/7.+Tests+are+automated+in+Extreme+Programming..jpg""      ""name"": ""7. Tests are automated in Extreme Programming.""      ""description"": ""True. False. Answer:a. Explanation: Automated test harnesses are used to run all component tests each time that a new release is built. 8. In XP an automated unit test framework is used to write tests for a new piece of functionality before that functionality itself is implemented. Explanation: XP follows Test-first development approach. 9. Developers work individually on a release and they compare their results with other developers before forwarding that release to customers. Answer:b. Explanation: XP follows the principle of pair programming which means developers work in pairs  checking each other’s work and providing the support to always do a good job. 10. Which four framework activities are found in the Extreme Programming(XP) analysis  design  coding  testing. planning  analysis  design  coding. planning  design  coding  testing. planning  analysis  coding  testing. Answer:c. Explanation: XP involves the mentioned four activities  and in the same in order.""      ""width"": ""1024"" }                         30                  Requirement DocumentationSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/30/Requirement+Documentation.jpg""      ""name"": ""Requirement Documentation""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         31                  1. Which of the following property does not correspond to a good Software Requirements Specification (SRS) ? Verifiable Ambiguous Complete Traceable Answer: b Explanation: The SRS should be unambiguous in nature which means each sentence in SRS should have a unique interpretation. 2. Which of the following property of SRS is depicted by the statement : “Conformity to a standard is maintained” ? Correct Consistent Modifiable Explanation: The SRS is complete full labeling and referencing of all figures  tables etc. and definition of all terms and units of  measure is defined. 3. The SRS is said to be consistent if and only if its structure and style are such that any changes to the requirements can be made easily while retaining the style and structure. every requirement stated therein is one that the software shall meet every requirement stated therein is verifiable no subset of individual requirements described in it conflict with each other Answer: d Explanation: Real world object may conflict with each other for example one requirement says that all lights should be red  while the other states that all lights should green.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/31/1.+Which+of+the+following+property+does+not+correspond+to+a+good+Software+Requirements+Specification+%28SRS%29.jpg""      ""name"": ""1. Which of the following property does not correspond to a good Software Requirements Specification (SRS)""      ""description"": ""Verifiable. Ambiguous. Complete. Traceable. Answer: b. Explanation: The SRS should be unambiguous in nature which means each sentence in SRS should have a unique interpretation. 2. Which of the following property of SRS is depicted by the statement : Conformity to a standard is maintained Correct. Consistent. Modifiable. Explanation: The SRS is complete full labeling and referencing of all figures  tables etc. and definition of all terms and units of measure is defined. 3. The SRS is said to be consistent if and only if. its structure and style are such that any changes to the requirements can be made easily while retaining the style and structure. every requirement stated therein is one that the software shall meet. every requirement stated therein is verifiable. no subset of individual requirements described in it conflict with each other. Answer: d. Explanation: Real world object may conflict with each other for example one requirement says that all lights should be red while the other states that all lights should green.""      ""width"": ""1024"" }                         32                  4. Which of the following statements about SRS is/are true ?SRS is written by customer SRS is written by a developer SRS serves as a contract between customer and developer Only i is true Both ii and iii are true All are true Answer: c Explanation: The SRS acts as a communication media between the Customer  Analyst  system developers  maintainers etc. Thus it  is a contract between Purchaser and Supplier. It is essentially written by a developer on the basis of customer’ need but in some  cases it may be written by a customer as well. 5. The SRS document is also known as  	_ 	specification. black-box white-box grey-box Answer: a Explanation: The system is considered as a black box whose internal details are not known that is  only its visible external  (input/output) behavior is documented. 6. Which of the following is included in SRS ? Cost Design Constraints Staffing Delivery Schedule Answer: b Explanation: Design constraints include standards to be incorporated in the software  implementation language  resource limits  operating  environment etc.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/32/4.+Which+of+the+following+statements+about+SRS+is%2Fare+true.jpg""      ""name"": ""4. Which of the following statements about SRS is/are true""      ""description"": ""SRS is written by customer. SRS is written by a developer. SRS serves as a contract between customer and developer. Only i is true. Both ii and iii are true. All are true. Answer: c. Explanation: The SRS acts as a communication media between the Customer  Analyst  system developers  maintainers etc. Thus it is a contract between Purchaser and Supplier. It is essentially written by a developer on the basis of customer’ need but in some cases it may be written by a customer as well. 5. The SRS document is also known as _ specification. black-box. white-box. grey-box. Answer: a. Explanation: The system is considered as a black box whose internal details are not known that is  only its visible external (input/output) behavior is documented. 6. Which of the following is included in SRS Cost. Design Constraints. Staffing. Delivery Schedule. Answer: b. Explanation: Design constraints include standards to be incorporated in the software  implementation language  resource limits  operating environment etc.""      ""width"": ""1024"" }                         33                  7. Which of the following is not included in SRS?Performance Functionality Design solutions External Interfaces Answer: c Explanation: The SRS document concentrates on:”what needs to be done” and carefully avoids the solution (“how to do”) aspects. 8. Arrange the given sequence to form a SRS Prototype outline as per IEEE SRS Standard. General description Introduction Index Appendices Specific Requirements iii  i  ii v  iv iii  ii  i  v  iv ii  i  v  iv  iii Explanation: The given sequence correctly resemble a standard SRS prototype as per IEEE. 9. Consider the following Statement: “The output of a program shall be given within 10secs of event X 10% of the time.”What characteristic of SRS is being depicted here ? Consistent Verifiable Non-verifiable Correct Answer: b Explanation: An SRS is verifiable  if and only if  every requirement stated therein is verifiable.Here the given condition can be verified during  testing phase.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/33/7.+Which+of+the+following+is+not+included+in+SRS.jpg""      ""name"": ""7. Which of the following is not included in SRS""      ""description"": ""Performance. Functionality. Design solutions. External Interfaces. Answer: c. Explanation: The SRS document concentrates on: what needs to be done and carefully avoids the solution ( how to do ) aspects. 8. Arrange the given sequence to form a SRS Prototype outline as per IEEE SRS Standard. General description. Introduction. Index. Appendices. Specific Requirements. iii  i  ii v  iv. iii  ii  i  v  iv. ii  i  v  iv  iii. Explanation: The given sequence correctly resemble a standard SRS prototype as per IEEE. 9. Consider the following Statement: The output of a program shall be given within 10secs of event X 10% of the time. What characteristic of SRS is. being depicted here Consistent. Verifiable. Non-verifiable. Correct. Answer: b. Explanation: An SRS is verifiable  if and only if  every requirement stated therein is verifiable.Here the given condition can be verified during testing phase.""      ""width"": ""1024"" }                         34                  10. Consider the following Statement: “The data set will contain an end of file character.”What characteristic of SRS is being depicted here ? Consistent Non-verifiable Correct Ambiguous Answer: b Explanation: An SRS is unambiguous if and only if  every requirement stated therein has only one unique interpretation. The given statement does not answer the question: “which data set will have an end of file character ?”. 11. Consider the following Statement: “The product should have a good human interface.”What characteristic of SRS is being depicted here ? Non-Verifiable Explanation: An SRS is verifiable  if and only if  every requirement stated therein is verifiable. The statement can only be answered  on completion of the software and customer evaluation but still human interface will vary from person to person. 12. Narrative essay is one of the best types of specification document ? True False Answer:b Explanation: Narrative essay is one of the worst types of specification document as it is difficult to change  difficult to be precise   has scope for contradictions  etc.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/34/10.+Consider+the+following+Statement%3A+The+data+set+will+contain+an+end+of+file+character.+What+characteristic+of+SRS+is+being+depicted+here.jpg""      ""name"": ""10. Consider the following Statement: The data set will contain an end of file character. What characteristic of SRS is being depicted here""      ""description"": ""Consistent. Non-verifiable. Correct. Ambiguous. Answer: b. Explanation: An SRS is unambiguous if and only if  every requirement stated therein has only one unique interpretation. The given. statement does not answer the question: which data set will have an end of file character Consider the following Statement: The product should have a good human interface. What characteristic of SRS is being depicted. here Non-Verifiable. Explanation: An SRS is verifiable  if and only if  every requirement stated therein is verifiable. The statement can only be answered on completion of the software and customer evaluation but still human interface will vary from person to person. 12. Narrative essay is one of the best types of specification document True. False. Answer:b. Explanation: Narrative essay is one of the worst types of specification document as it is difficult to change  difficult to be precise  has scope for contradictions  etc.""      ""width"": ""1024"" }                         35                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/35/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         36                  Software Reliability Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/36/Software+Reliability+Source+%26+Courtsey%3A.jpg""      ""name"": ""Software Reliability Source &amp;amp; Courtsey:""      ""description"": ""Software Reliability Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         37                  1. Which of the following is not a phase of “bath tub curve” of hardware reliability?Useful Life Burn-in Wear-out Time Answer:d Explanation: Time is the horizontal dimension on which the bath tub curve is built and not the phase. 2. How is reliability and failure intensity related to each other? direct relation inverse relation no relation Answer:b Explanation: As the reliability increases  failure intensity decreases. 3. How many product quality factors are proposed in McCall quality model? 2 3 11 8 Explanation: McCall quality model has three product quality factors namely: Product revision  Product operation  Product Transition.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/37/1.+Which+of+the+following+is+not+a+phase+of+bath+tub+curve+of+hardware+reliability.jpg""      ""name"": ""1. Which of the following is not a phase of bath tub curve of hardware reliability""      ""description"": ""Useful Life. Burn-in. Wear-out. Time. Answer:d. Explanation: Time is the horizontal dimension on which the bath tub curve is built and not the phase. 2. How is reliability and failure intensity related to each other direct relation. inverse relation. no relation. Answer:b. Explanation: As the reliability increases  failure intensity decreases. 3. How many product quality factors are proposed in McCall quality model Explanation: McCall quality model has three product quality factors namely: Product revision  Product operation  Product Transition.""      ""width"": ""1024"" }                         38                  4. Which one of the following is not a software quality model?ISO 9000 McCall model Boehm model ISO 9126 Answer:a Explanation: ISO-9000 series of standards is a set of document dealing with quality systems that can be used for quality assurance  purposes. 5. What is MTTF ? Maximum time to failure Mean time to failure Minimum time to failure None of the mentioned Answer:b Explanation: The answer is self explanatory. 6. How is software reliability defined? time efficiency quality speed Explanation: Software Reliability mainly concerned with the time component. It can be seen in various models like Basic Execution  Time Model and Logarithmic Poisson Execution Time Model.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/38/4.+Which+one+of+the+following+is+not+a+software+quality+model.jpg""      ""name"": ""4. Which one of the following is not a software quality model""      ""description"": ""ISO McCall model. Boehm model. ISO Answer:a. Explanation: ISO-9000 series of standards is a set of document dealing with quality systems that can be used for quality assurance purposes. 5. What is MTTF Maximum time to failure. Mean time to failure. Minimum time to failure. None of the mentioned. Answer:b. Explanation: The answer is self explanatory. 6. How is software reliability defined time. efficiency. quality. speed. Explanation: Software Reliability mainly concerned with the time component. It can be seen in various models like Basic Execution Time Model and Logarithmic Poisson Execution Time Model.""      ""width"": ""1024"" }                         39                  7. Suitability  Accuracy  Interpolability and security are what type quality attribute of ISO 9126 ?Reliability Efficiency Functionality Usability Answer:c Explanation: All the Characteristics mentioned in the question are related to achievement of the basic purpose for which the  software is being engineered  which is functionality. 8. Time Behavior and Resource Behavior fall under which quality attribute of ISO 9126 ? Answer:b Explanation: The Characteristics mentioned in the question are related to the relationship between the level of  performance of the software and the amount of resources used  under stated conditions. 9. NHPP stands for Non Homogeneous Poisson Product Non Hetrogeneous Poisson Product Non Hetrogeneous Poisson Process Non Homogeneous Poisson Process Answer:d Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/39/7.+Suitability%2C+Accuracy%2C+Interpolability+and+security+are+what+type+quality+attribute+of+ISO+9126.jpg""      ""name"": ""7. Suitability  Accuracy  Interpolability and security are what type quality attribute of ISO 9126""      ""description"": ""Reliability. Efficiency. Functionality. Usability. Answer:c. Explanation: All the Characteristics mentioned in the question are related to achievement of the basic purpose for which the software is being engineered  which is functionality. 8. Time Behavior and Resource Behavior fall under which quality attribute of ISO 9126 Answer:b. Explanation: The Characteristics mentioned in the question are related to the relationship between the level of performance of the software and the amount of resources used  under stated conditions. 9. NHPP stands for. Non Homogeneous Poisson Product. Non Hetrogeneous Poisson Product. Non Hetrogeneous Poisson Process. Non Homogeneous Poisson Process. Answer:d. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         40                  10. The CMM model is a technique toautomatically maintain the software reliability improve the software process. test the software all of the mentioned Answer:b Explanation: Capability Maturity Model (CMM) is a strategy for improving the software  process  irrespective of the actual life cycle model used.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/40/10.+The+CMM+model+is+a+technique+to.jpg""      ""name"": ""10. The CMM model is a technique to""      ""description"": ""automatically maintain the software reliability. improve the software process. test the software. all of the mentioned. Answer:b. Explanation: Capability Maturity Model (CMM) is a strategy for improving the software process  irrespective of the actual life cycle model used.""      ""width"": ""1024"" }                         41                  Dependability and SecuritySource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/41/Dependability+and+Security.jpg""      ""name"": ""Dependability and Security""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         42                  1. A characteristic of a software system that can lead to a system error is known as?Human error or mistake System fault System error System failure Answer:b Explanation: The answer is self explanatory. 2. An erroneous system state that can lead to system behavior that is unexpected by system users is known as? Answer:c 3. An event that occurs at some point in time when the system does not deliver a service as expected by its users is called . Answer:d  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/42/1.+A+characteristic+of+a+software+system+that+can+lead+to+a+system+error+is+known+as.jpg""      ""name"": ""1. A characteristic of a software system that can lead to a system error is known as""      ""description"": ""Human error or mistake. System fault. System error. System failure. Answer:b. Explanation: The answer is self explanatory. 2. An erroneous system state that can lead to system behavior that is unexpected by system users is known as Answer:c. 3. An event that occurs at some point in time when the system does not deliver a service as expected by its users is called. . Answer:d.""      ""width"": ""1024"" }                         43                  4. A chemical plant system may detect excessive pressure and open a relief valve to reduce these pressures before an explosion occurs. What kind of dependability and security issue the example states? Hazard avoidance Damage limitation Hazard detection Hazard detection and removal Answer:d Explanation: The system is designed so that hazards are detected and removed before they result in an accident. 5. An aircraft engine normally includes automatic fire extinguishers.What kind of dependability and security issue the example states? Answer:b Explanation: The system may include protection features that minimize the damage that may result from an accident. 6. An assessment of the worst possible damage that could result from a particular hazard is known as Risk Hazard probability Hazard severity Mishap Answer:c Explanation: Hazard severity can range from catastrophic  where many people are killed  to minor  where only minor damage results. When an individual death is a possibility  a reasonable assessment of hazard severity is ‘very high’.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/43/4.+A+chemical+plant+system+may+detect+excessive+pressure+and+open+a+relief+valve+to+reduce+these+pressures+before+an+explosion+occurs.+What+kind+of+dependability+and+security+issue+the+example+states.jpg""      ""name"": ""4. A chemical plant system may detect excessive pressure and open a relief valve to reduce these pressures before an explosion occurs. What kind of dependability and security issue the example states""      ""description"": ""Hazard avoidance. Damage limitation. Hazard detection. Hazard detection and removal. Answer:d. Explanation: The system is designed so that hazards are detected and removed before they result in an accident. 5. An aircraft engine normally includes automatic fire extinguishers.What kind of dependability and security issue the example states Answer:b. Explanation: The system may include protection features that minimize the damage that may result from an accident. 6. An assessment of the worst possible damage that could result from a particular hazard is known as. Risk. Hazard probability. Hazard severity. Mishap. Answer:c. Explanation: Hazard severity can range from catastrophic  where many people are killed  to minor  where only minor damage results. When an individual death is a possibility  a reasonable assessment of hazard severity is ‘very high’.""      ""width"": ""1024"" }                         44                  7. which of the following terms is a measure of the probability that the system will cause an accident? Risk Hazard probability Accident Damage Answer:a Explanation: The risk is assessed by considering the hazard probability  the hazard severity  and the probability that the hazard  will lead to an accident. 8. A weakness in a computer-based system that may be exploited to cause loss or harm is known as? Vulnerability Attack Threat Exposure Explanation: The answer is self explanatory. 9. A password checking system that disallows user passwords that are proper names or words that are normally included in a  dictionary is an example of  	with respect to security systems. risk control attack b) asset Answer:b Explanation: A control protective measure that reduces a system’s vulnerability.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/44/7.+which+of+the+following+terms+is+a+measure+of+the+probability+that+the+system+will+cause+an+accident.jpg""      ""name"": ""7. which of the following terms is a measure of the probability that the system will cause an accident""      ""description"": ""Risk. Hazard probability. Accident. Damage. Answer:a. Explanation: The risk is assessed by considering the hazard probability  the hazard severity  and the probability that the hazard will lead to an accident. 8. A weakness in a computer-based system that may be exploited to cause loss or harm is known as Vulnerability. Attack. Threat. Exposure. Explanation: The answer is self explanatory. 9. A password checking system that disallows user passwords that are proper names or words that are normally included in a dictionary is an example of with respect to security systems. risk. control. attack. b) asset. Answer:b. Explanation: A control protective measure that reduces a system’s vulnerability.""      ""width"": ""1024"" }                         45                  10. The safety of a system is a system attribute that reflects the system’s ability to operate  normally or abnormally  without injury to people or damage to the environment. True False Answer:a Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/45/10.+The+safety+of+a+system+is+a+system+attribute+that+reflects+the+system%E2%80%99s+ability+to+operate%2C+normally+or+abnormally%2C+without+injury+to+people+or+damage+to+the+environment..jpg""      ""name"": ""10. The safety of a system is a system attribute that reflects the system’s ability to operate  normally or abnormally  without injury to people or damage to the environment.""      ""description"": ""True. False. Answer:a. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         46                  Dependability and Security SpecificationSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/46/Dependability+and+Security+Specification.jpg""      ""name"": ""Dependability and Security Specification""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         47                  1. How many stages are there in Risk-driven requirements specification?three four five six Answer:b Explanation: These include Risk identification  Risk analysis  Risk reduction and Risk decomposition. 2. Consider a case where the system is unavailable and cannot deliver its services to users. What type of failure is  being described here? Loss of service Incorrect service delivery System/data corruption Answer:a Explanation: One may separate this into loss of critical services and loss of non-critical services  where the consequences  of a failure in non-critical services are less than the consequences of critical service failure. 3. Consider a case where the failure of the system causes damage to the system itself or it data. What type of failure is being described here? Answer:c Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/47/1.+How+many+stages+are+there+in+Risk-driven+requirements+specification.jpg""      ""name"": ""1. How many stages are there in Risk-driven requirements specification""      ""description"": ""three. four. five. six. Answer:b. Explanation: These include Risk identification  Risk analysis  Risk reduction and Risk decomposition. 2. Consider a case where the system is unavailable and cannot deliver its services to users. What type of failure is being described here Loss of service. Incorrect service delivery. System/data corruption. Answer:a. Explanation: One may separate this into loss of critical services and loss of non-critical services  where the consequences of a failure in non-critical services are less than the consequences of critical service failure. 3. Consider a case where the failure of the system causes damage to the system itself or it data. What type of failure is being described here Answer:c. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         48                  4. POFOD stands for Possibility of failure of data Probability of failure of data Possibility of failure on demand Probability of failure on demand Answer:d Explanation: The answer is self explanatory. 5. Which reliability metric sets out the probable number of system failures that are likely to be observed relative to a certain time period? POFOD ROCOF AVAIL None of the mentioned Answer:b Explanation: Rate of occurrence of failures (ROCOF) sets out the probable number of system failures that are likely to be  observed relative to the number of system executions. 6. Which of the following is not a functional reliability requirement for a system? Checking requirements Recovery requirements Redundancy requirements Ambiguous requirements Explanation: All the options are correct except option d.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/48/4.+POFOD+stands+for+Possibility+of+failure+of+data.+Probability+of+failure+of+data.+Possibility+of+failure+on+demand..jpg""      ""name"": ""4. POFOD stands for Possibility of failure of data. Probability of failure of data. Possibility of failure on demand.""      ""description"": ""Probability of failure on demand. Answer:d. Explanation: The answer is self explanatory. 5. Which reliability metric sets out the probable number of system failures that are likely to be observed relative to a certain time period POFOD. ROCOF. AVAIL. None of the mentioned. Answer:b. Explanation: Rate of occurrence of failures (ROCOF) sets out the probable number of system failures that are likely to be observed relative to the number of system executions. 6. Which of the following is not a functional reliability requirement for a system Checking requirements. Recovery requirements. Redundancy requirements. Ambiguous requirements. Explanation: All the options are correct except option d.""      ""width"": ""1024"" }                         49                  7. To specify security requirements  one should identify the risks that are to be dealt with.True False Answer:b Explanation: To specify security requirements  one should identify the assets that are to be dealt with. 8. The aim of preliminary risk analysis and assessment process is to derive security requirements for the system as a whole. Answer:a Explanation: In preliminary risk analysis stage  decisions on the detailed system requirements  the system design  or the implementation  technology have not been made. 9. At which stage of risk analysis specification  the additional security requirements take account of the technologies used in building the system and system design and implementation decisions? Preliminary risk analysis Life-cycle risk analysis Operational risk analysis Explanation: This risk assessment takes place during the system development life cycle after design choices have been made. 10. Which reliability requirements are concerned with maintaining copies of the system? Checking requirements Recovery requirements Redundancy requirements Ambiguous requirements Explanation: These requirements are geared to helping the system recover after a failure has occurred.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/49/7.+To+specify+security+requirements%2C+one+should+identify+the+risks+that+are+to+be+dealt+with..jpg""      ""name"": ""7. To specify security requirements  one should identify the risks that are to be dealt with.""      ""description"": ""True. False. Answer:b. Explanation: To specify security requirements  one should identify the assets that are to be dealt with. 8. The aim of preliminary risk analysis and assessment process is to derive security requirements for the system as a whole. Answer:a. Explanation: In preliminary risk analysis stage  decisions on the detailed system requirements  the system design  or the implementation technology have not been made. 9. At which stage of risk analysis specification  the additional security requirements take account of the technologies used in building the system and. system design and implementation decisions Preliminary risk analysis. Life-cycle risk analysis. Operational risk analysis. Explanation: This risk assessment takes place during the system development life cycle after design choices have been made. 10. Which reliability requirements are concerned with maintaining copies of the system Checking requirements. Recovery requirements. Redundancy requirements. Ambiguous requirements. Explanation: These requirements are geared to helping the system recover after a failure has occurred.""      ""width"": ""1024"" }                         50                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/50/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         51                  Diagrams in UML – 1 Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/51/Diagrams+in+UML+%E2%80%93+1+Source+%26+Courtsey%3A.jpg""      ""name"": ""Diagrams in UML – 1 Source &amp;amp; Courtsey:""      ""description"": ""Diagrams in UML – 1 Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         52                  1. Which of the following UML diagrams has a static view?Collaboration Use case State chart Activity Answer:b Explanation: A use case diagrams captures only the functionality of the system whereas a dynamic  model/view captures the functions as well as the action. 2. What type of core-relationship is represented by the symbol in the figure below? Aggregation Dependency Generalization Association Answer:a Explanation: The figure is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/52/1.+Which+of+the+following+UML+diagrams+has+a+static+view.jpg""      ""name"": ""1. Which of the following UML diagrams has a static view""      ""description"": ""Collaboration. Use case. State chart. Activity. Answer:b. Explanation: A use case diagrams captures only the functionality of the system whereas a dynamic model/view captures the functions as well as the action. 2. What type of core-relationship is represented by the symbol in the figure below Aggregation. Dependency. Generalization. Association. Answer:a. Explanation: The figure is self explanatory.""      ""width"": ""1024"" }                         53                  3. Which core element of UML is being shown in the figure?Node Interface Class Component Answer:d Explanation: The figure is self explanatory. A component is a modular  significant and replaceable part of the system that packages  implementation and exposes a set of interfaces. 4. What type of relationship is represented by Shape class and Square ? Realization Generalization Aggregation Dependency Answer: b Explanation: The generalization relationship is also known as the inheritance relationship. In the figure Square is the sub class of super class shape.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/53/3.+Which+core+element+of+UML+is+being+shown+in+the+figure.jpg""      ""name"": ""3. Which core element of UML is being shown in the figure""      ""description"": ""Node. Interface. Class. Component. Answer:d. Explanation: The figure is self explanatory. A component is a modular  significant and replaceable part of the system that packages implementation and exposes a set of interfaces. 4. What type of relationship is represented by Shape class and Square Realization. Generalization. Aggregation. Dependency. Answer: b. Explanation: The generalization relationship is also known as the inheritance relationship. In the figure Square is the sub class of super class shape.""      ""width"": ""1024"" }                         54                  5. Which diagram in UML shows a complete or partial view of the structure of a modeled system at a specific time? Sequence Diagram Collaboration Diagram Class Diagram Object Diagram Answer: d Explanation: An object diagram focuses on some particular set of object instances and attributes  and the links between the instances. It is a static  snapshot of a dynamic view of the system. 6. Interaction Diagram is a combined term for Sequence Diagram + Collaboration Diagram Activity Diagram + State Chart Diagram Deployment Diagram + Collaboration Diagram None of the mentioned Answer: a Explanation: Interaction diagram are used to formalize the dynamic behavior of the system. 7. Structure diagrams emphasize the things that must be present in the system being modeled. True False Explanation: Since structure diagrams represent the structure they are used extensively in documenting the architecture of software systems 8. Which of the following diagram is time oriented? Collaboration Sequence Activity Answer:b Explanation: A sequence diagrams timeline along which tasks are completed.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/54/5.+Which+diagram+in+UML+shows+a+complete+or+partial+view+of+the+structure+of+a+modeled+system+at+a+specific+time.jpg""      ""name"": ""5. Which diagram in UML shows a complete or partial view of the structure of a modeled system at a specific time""      ""description"": ""Sequence Diagram. Collaboration Diagram. Class Diagram. Object Diagram. Answer: d. Explanation: An object diagram focuses on some particular set of object instances and attributes  and the links between the instances. It is a static snapshot of a dynamic view of the system. 6. Interaction Diagram is a combined term for. Sequence Diagram + Collaboration Diagram. Activity Diagram + State Chart Diagram. Deployment Diagram + Collaboration Diagram. None of the mentioned. Answer: a. Explanation: Interaction diagram are used to formalize the dynamic behavior of the system. 7. Structure diagrams emphasize the things that must be present in the system being modeled. True. False. Explanation: Since structure diagrams represent the structure they are used extensively in documenting the architecture of software systems. 8. Which of the following diagram is time oriented Collaboration. Sequence. Activity. Answer:b. Explanation: A sequence diagrams timeline along which tasks are completed.""      ""width"": ""1024"" }                         55                  Sociotechnical SystemsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/55/Sociotechnical+Systems.jpg""      ""name"": ""Sociotechnical Systems""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         56                  1. A sociotechnical system is a system that includespeople software hardware all of the mentioned Answer:d Explanation: A sociotechnical system is a system that includes people  software  and hardware to show that you need to take a systems  perspective on security and dependability. 2. Which layer is missing in the sociotechnical system stack as shown below: organizational layer application layer physical layer transport layer Answer:b Explanation: The application layer This layer delivers the application-specific functionality that is required.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/56/1.+A+sociotechnical+system+is+a+system+that+includes.jpg""      ""name"": ""1. A sociotechnical system is a system that includes""      ""description"": ""people. software. hardware. all of the mentioned. Answer:d. Explanation: A sociotechnical system is a system that includes people  software  and hardware to show that you need to take a systems perspective on security and dependability. 2. Which layer is missing in the sociotechnical system stack as shown below: organizational layer. application layer. physical layer. transport layer. Answer:b. Explanation: The application layer This layer delivers the application-specific functionality that is required.""      ""width"": ""1024"" }                         57                  3. Consider an example of a system which has a police command and control system that may include a geographical information system to provide details of the location of incidents. What kind of system the example represents? Complex System Technical computer-based system Sociotechnical System Both a and c Answer:d Explanation: Complex systems are usually hierarchical and so include other systems. 4. Which property of a sociotechnical system varies depending on how the component assemblies are arranged and connected? security usability volume reliability Answer:c Explanation: The volume of a system (the total space occupied) varies depending on how the component assemblies are arranged  and connected. 5. Which property of a sociotechnical system depends on the technical system components  its operators  and its operating environment? Answer:b Explanation: Usability reflects how easy it is to use the system.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/57/3.+Consider+an+example+of+a+system+which+has+a+police+command+and+control+system+that+may+include+a+geographical+information+system+to+provide+details+of+the+location+of+incidents.+What+kind+of+system+the+example+represents.jpg""      ""name"": ""3. Consider an example of a system which has a police command and control system that may include a geographical information system to provide details of the location of incidents. What kind of system the example represents""      ""description"": ""Complex System. Technical computer-based system. Sociotechnical System. Both a and c. Answer:d. Explanation: Complex systems are usually hierarchical and so include other systems. 4. Which property of a sociotechnical system varies depending on how the component assemblies are arranged and connected security. usability. volume. reliability. Answer:c. Explanation: The volume of a system (the total space occupied) varies depending on how the component assemblies are arranged and connected. 5. Which property of a sociotechnical system depends on the technical system components  its operators  and its operating environment Answer:b. Explanation: Usability reflects how easy it is to use the system.""      ""width"": ""1024"" }                         58                  6. In a sociotechnical system  you need to consider reliability from perspectives namely:only software reliability only hardware reliability hardware and software reliability hardware  software and operator reliability Answer:d Explanation: In a sociotechnical system  you need to consider reliability from all three perspectives. 7. There are  	overlapping stages in the lifetime of large and complex sociotechnical systems. two three four five Answer:b Explanation: The stages are Procurement  Development and Operation. 8. Sociotechnical systems are deterministic. True False Explanation: Sociotechnical systems are non-deterministic partly because they include people and partly  because changes to the hardware  software  and data in these systems are so frequent.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/58/6.+In+a+sociotechnical+system%2C+you+need+to+consider+reliability+from+perspectives+namely%3A.jpg""      ""name"": ""6. In a sociotechnical system  you need to consider reliability from perspectives namely:""      ""description"": ""only software reliability. only hardware reliability. hardware and software reliability. hardware  software and operator reliability. Answer:d. Explanation: In a sociotechnical system  you need to consider reliability from all three perspectives. 7. There are overlapping stages in the lifetime of large and complex sociotechnical systems. two. three. four. five. Answer:b. Explanation: The stages are Procurement  Development and Operation. 8. Sociotechnical systems are deterministic. True. False. Explanation: Sociotechnical systems are non-deterministic partly because they include people and partly because changes to the hardware  software  and data in these systems are so frequent.""      ""width"": ""1024"" }                         59                  9. What are the two ways to view the human error of a sociotechnical system?hardware and software approach management and users approach person and systems approach Answer:c Explanation: The answer is self explanatory. 10. Human and organizational factors such as organizational structure and politics have a significant  effect on the operation of sociotechnical systems. True False Answer:a Explanation: As people are a part of the system  hence they affect the sociotechnical system.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/59/9.+What+are+the+two+ways+to+view+the+human+error+of+a+sociotechnical+system.jpg""      ""name"": ""9. What are the two ways to view the human error of a sociotechnical system""      ""description"": ""hardware and software approach. management and users approach. person and systems approach. Answer:c. Explanation: The answer is self explanatory. 10. Human and organizational factors such as organizational structure and politics have a significant effect on the operation of sociotechnical systems. True. False. Answer:a. Explanation: As people are a part of the system  hence they affect the sociotechnical system.""      ""width"": ""1024"" }                         60                  Diagrams in UML – 2 Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/60/Diagrams+in+UML+%E2%80%93+2+Source+%26+Courtsey%3A.jpg""      ""name"": ""Diagrams in UML – 2 Source &amp;amp; Courtsey:""      ""description"": ""Diagrams in UML – 2 Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         61                  1. How many diagrams are here in Unified Modelling Language?six seven eight nine Answer:d Explanation: The nine UML diagrams include use-case  sequence  collaboration  activity  state-chart  deployment  class   object and component. 2. Which UML diagram is shown below? Use Case Collaboration Diagram Class Diagram Object Diagram Answer:a Explanation: The diagram is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/61/1.+How+many+diagrams+are+here+in+Unified+Modelling+Language.jpg""      ""name"": ""1. How many diagrams are here in Unified Modelling Language""      ""description"": ""six. seven. eight. nine. Answer:d. Explanation: The nine UML diagrams include use-case  sequence  collaboration  activity  state-chart  deployment  class  object and component. 2. Which UML diagram is shown below Use Case. Collaboration Diagram. Class Diagram. Object Diagram. Answer:a. Explanation: The diagram is self explanatory.""      ""width"": ""1024"" }                         62                  3. Which UML diagram is shown below?Use Case State Chart Activiy Object Diagram Answer:b Explanation: The diagram is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/62/3.+Which+UML+diagram+is+shown+below.jpg""      ""name"": ""3. Which UML diagram is shown below""      ""description"": ""Use Case. State Chart. Activiy. Object Diagram. Answer:b. Explanation: The diagram is self explanatory.""      ""width"": ""1024"" }                         63                  4. Which UML diagram is shown below?Use Case Collaboration Diagram Sequence Diagram Object Diagram Answer:c Explanation: The diagram is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/63/4.+Which+UML+diagram+is+shown+below.jpg""      ""name"": ""4. Which UML diagram is shown below""      ""description"": ""Use Case. Collaboration Diagram. Sequence Diagram. Object Diagram. Answer:c. Explanation: The diagram is self explanatory.""      ""width"": ""1024"" }                         64                  5. Which UML diagram’s symbols are shown below?Deployment diagram Collaboration Diagram Component Diagram Object Diagram Answer:a Explanation: The diagram is self explanatory. 6. Which UML diagram is shown below? Deployment diagram Collaboration Diagram Object Diagram Class Diagram Answer:d Explanation: The diagram is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/64/5.+Which+UML+diagram%E2%80%99s+symbols+are+shown+below.jpg""      ""name"": ""5. Which UML diagram’s symbols are shown below""      ""description"": ""Deployment diagram. Collaboration Diagram. Component Diagram. Object Diagram. Answer:a. Explanation: The diagram is self explanatory. 6. Which UML diagram is shown below Deployment diagram. Collaboration Diagram. Object Diagram. Class Diagram. Answer:d. Explanation: The diagram is self explanatory.""      ""width"": ""1024"" }                         65                  7. Which UML diagram is shown below?Activity State chart Sequence c) Collaboration Answer:a Explanation: The diagram is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/65/7.+Which+UML+diagram+is+shown+below.jpg""      ""name"": ""7. Which UML diagram is shown below""      ""description"": ""Activity. State chart. Sequence. c) Collaboration. Answer:a. Explanation: The diagram is self explanatory.""      ""width"": ""1024"" }                         66                  8. Which UML diagram is shown below?Component Deployment Use Case DFD Answer:a Explanation: The diagram is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/66/8.+Which+UML+diagram+is+shown+below.jpg""      ""name"": ""8. Which UML diagram is shown below""      ""description"": ""Component. Deployment. Use Case. DFD. Answer:a. Explanation: The diagram is self explanatory.""      ""width"": ""1024"" }                         67                  Types of Software MetricsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/67/Types+of+Software+Metrics.jpg""      ""name"": ""Types of Software Metrics""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         68                  1. Which of the following is the task of project indicators:help in assessment of status of ongoing project. track potential risk both a and b none of the mentioned Answer:c Explanation: The answer is self explanatory. 2. Which of the following does not affect the software quality and organizational performance? Market Product Technology People Answer:a Explanation: Market is a collection of competitors  stakeholders  users each having different views on the product. So it does  not affect the software quality. 3. The intent of project metrics is: minimization of development schedule for strategic purposes assessing project quality on ongoing basis both a and c Answer:d Explanation: A project metric is a quantitative measure of the degree to which a system  component or process possesses an attribute.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/68/1.+Which+of+the+following+is+the+task+of+project+indicators%3A.jpg""      ""name"": ""1. Which of the following is the task of project indicators:""      ""description"": ""help in assessment of status of ongoing project. track potential risk. both a and b. none of the mentioned. Answer:c. Explanation: The answer is self explanatory. 2. Which of the following does not affect the software quality and organizational performance Market. Product. Technology. People. Answer:a. Explanation: Market is a collection of competitors  stakeholders  users each having different views on the product. So it does not affect the software quality. 3. The intent of project metrics is: minimization of development schedule. for strategic purposes. assessing project quality on ongoing basis. both a and c. Answer:d. Explanation: A project metric is a quantitative measure of the degree to which a system  component or process possesses an attribute.""      ""width"": ""1024"" }                         69                  4. Which of the following is not a direct measure of SE process?Efficiency Cost Effort Applied All of the mentioned Answer:a Explanation: Efficiency is an indirect measure. 5. Which of the following is an indirect measure of product? Quality Complexity Reliability All of the Mentioned Answer:d Explanation: All the mentioned options are indirect measures of a product. 6. In size oriented metrics  metrics are developed based on the  	. number of Functions number of user inputs number of lines of code amount of memory usage Answer:c Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/69/4.+Which+of+the+following+is+not+a+direct+measure+of+SE+process.jpg""      ""name"": ""4. Which of the following is not a direct measure of SE process""      ""description"": ""Efficiency. Cost. Effort Applied. All of the mentioned. Answer:a. Explanation: Efficiency is an indirect measure. 5. Which of the following is an indirect measure of product Quality. Complexity. Reliability. All of the Mentioned. Answer:d. Explanation: All the mentioned options are indirect measures of a product. 6. In size oriented metrics  metrics are developed based on the . number of Functions. number of user inputs. number of lines of code. amount of memory usage. Answer:c. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         70                  7. Which of the following is not an information domain required for determining function point in FPA ? Number of user Input Number of user Inquiries Number of external Interfaces Number of errors Answer:d Explanation: FPA includes five domains namely input  output  inquiries  interface and logical files. 8. Usability can be measured in terms of: Intellectual skill to learn the system Time required to become moderately efficient in system usage Net increase in productivity All of the mentioned Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/70/7.+Which+of+the+following+is+not+an+information+domain+required+for+determining+function+point+in+FPA.jpg""      ""name"": ""7. Which of the following is not an information domain required for determining function point in FPA""      ""description"": ""Number of user Input. Number of user Inquiries. Number of external Interfaces. Number of errors. Answer:d. Explanation: FPA includes five domains namely input  output  inquiries  interface and logical files. 8. Usability can be measured in terms of: Intellectual skill to learn the system. Time required to become moderately efficient in system usage. Net increase in productivity. All of the mentioned. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         71                  9. A graphical technique for finding if changes and variation in metrics data are meaningful is known as DRE (Defect Removal Efficiency) Function points analysis Control Chart All of the mentioned Answer:c Explanation: Others options are formulaes. 10. Defects removal efficiency (DRE)depends on: E – errors found before software delivery D – defects found after delivery to user both E and D Varies with project Explanation: DRE = E / (E + d).  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/71/9.+A+graphical+technique+for+finding+if+changes+and+variation+in+metrics+data+are+meaningful+is+known+as.jpg""      ""name"": ""9. A graphical technique for finding if changes and variation in metrics data are meaningful is known as""      ""description"": ""DRE (Defect Removal Efficiency) Function points analysis. Control Chart. All of the mentioned. Answer:c. Explanation: Others options are formulaes. 10. Defects removal efficiency (DRE)depends on: E – errors found before software delivery. D – defects found after delivery to user. both E and D. Varies with project. Explanation: DRE = E / (E + d).""      ""width"": ""1024"" }                         72                  Software Testing Techniques – 1Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/72/Software+Testing+Techniques+%E2%80%93+1.jpg""      ""name"": ""Software Testing Techniques – 1""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         73                  1. Which of the following term describes testing?Finding broken code Evaluating deliverable to find errors A stage of all projects None of the mentioned Answer: b Explanation: Software testing is the process of evaluation a software item to detect differences between given input and  expected output. 2. What is Cyclomatic complexity? Black box testing White box testing Yellow box testing Green box testing Explanation: Cyclomatic complexity measures the amount of decision logic in the program module.Cyclomatic complexity  gives the minimum number of paths that can generate all possible paths through the module. 3. Lower and upper limits are present in which chart? Run chart Bar chart Control chart Answer: a Explanation: A run chart is used to monitor the behavior of a variable over time for a process or system. Run charts  graphically display cycles  trends  shifts  or non-random patterns in behavior over time. It contains lower and upper limits.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/73/1.+Which+of+the+following+term+describes+testing.jpg""      ""name"": ""1. Which of the following term describes testing""      ""description"": ""Finding broken code. Evaluating deliverable to find errors. A stage of all projects. None of the mentioned. Answer: b. Explanation: Software testing is the process of evaluation a software item to detect differences between given input and expected output. 2. What is Cyclomatic complexity Black box testing. White box testing. Yellow box testing. Green box testing. Explanation: Cyclomatic complexity measures the amount of decision logic in the program module.Cyclomatic complexity gives the minimum number of paths that can generate all possible paths through the module. 3. Lower and upper limits are present in which chart Run chart. Bar chart. Control chart. Answer: a. Explanation: A run chart is used to monitor the behavior of a variable over time for a process or system. Run charts graphically display cycles  trends  shifts  or non-random patterns in behavior over time. It contains lower and upper limits.""      ""width"": ""1024"" }                         74                  4. Maintenance testing is performed using which methodology?Retesting Sanity testing Breadth test and depth test Confirmation testing Answer: c Explanation: Maintenance Testing is done on the already deployed software. The deployed software needs to be enhanced   changed or migrated to other hardware. The Testing done during this enhancement  change and migration cycle is known as  maintenance testing. 5. White Box techniques are also classified as Design based testing Structural testing Error guessing technique Answer: b Explanation: The structural testing is the testing of the structure of the system or component. Structural testing is often referred to as ‘white box’ or ‘glass box’ or ‘clear-box testing’ because in structural testing we are interested in what is happening ‘inside the system/application’. 6. Exhaustive testing is always possible practically possible impractical but possible impractical and impossible Explanation:Exhaustive testing is the testing where we execute single test case for multiple test data.It means if we are using  single test case for different product or module under manual testing.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/74/4.+Maintenance+testing+is+performed+using+which+methodology.jpg""      ""name"": ""4. Maintenance testing is performed using which methodology""      ""description"": ""Retesting. Sanity testing. Breadth test and depth test. Confirmation testing. Answer: c. Explanation: Maintenance Testing is done on the already deployed software. The deployed software needs to be enhanced  changed or migrated to other hardware. The Testing done during this enhancement  change and migration cycle is known as maintenance testing. 5. White Box techniques are also classified as. Design based testing. Structural testing. Error guessing technique. Answer: b. Explanation: The structural testing is the testing of the structure of the system or component. Structural testing is often referred to as ‘white box’ or ‘glass box’ or ‘clear-box testing’ because in structural testing we are interested in what is happening ‘inside the system/application’. 6. Exhaustive testing is. always possible. practically possible. impractical but possible. impractical and impossible. Explanation:Exhaustive testing is the testing where we execute single test case for multiple test data.It means if we are using single test case for different product or module under manual testing.""      ""width"": ""1024"" }                         75                  7. Which of the following is/are White box technique?Statement Testing Decision Testing Condition Coverage All of these Answer: d Explanation: Statement testing  decision testing  condition coverage all of them uses white box technique. 8. What are the various Testing Levels? Unit Testing System Testing Integration Testing All of the mentioned Explanation: Unit  system  integration testing all of them are levels in testing. 9. Boundary value analysis belong to? White Box Testing Black Box Testing Answer: b Explanation: Boundary value analysis is based on testing at the boundaries between partitions and checks the output with expected output . 10. Alpha testing is done at Developer’s end User’s end Answer: a Explanation: Alpha testing takes place at the developer’s end. Developers observe the users and note problems. Alpha testing is testing  of an application when development is about to complete. Minor design changes can still be made as a result of alpha testing.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/75/7.+Which+of+the+following+is%2Fare+White+box+technique.jpg""      ""name"": ""7. Which of the following is/are White box technique""      ""description"": ""Statement Testing. Decision Testing. Condition Coverage. All of these. Answer: d. Explanation: Statement testing  decision testing  condition coverage all of them uses white box technique. 8. What are the various Testing Levels Unit Testing. System Testing. Integration Testing. All of the mentioned. Explanation: Unit  system  integration testing all of them are levels in testing. 9. Boundary value analysis belong to White Box Testing. Black Box Testing. Answer: b. Explanation: Boundary value analysis is based on testing at the boundaries between partitions and checks the output with expected output Alpha testing is done at. Developer’s end. User’s end. Answer: a. Explanation: Alpha testing takes place at the developer’s end. Developers observe the users and note problems. Alpha testing is testing of an application when development is about to complete. Minor design changes can still be made as a result of alpha testing.""      ""width"": ""1024"" }                         76                  Software Testing Techniques – 2Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/76/Software+Testing+Techniques+%E2%80%93+2.jpg""      ""name"": ""Software Testing Techniques – 2""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         77                  1. The testing in which code is checkedBlack box testing White box testing Red box testing Green box testing Answer: b Explanation: White-box testing is a method of testing software that tests internal structures or workings of an application  as  opposed to its functionality. 2. Testing done without planning and Documentation is called Unit testing Regression testing Adhoc testing None of the mentioned Answer: c Explanation: Adhoc testing is used term for software testing performed without planning and documentation. The tests are  intended to be run only once  unless a defect is discovered. 3. Acceptance testing is also known as Grey box testing Alpha Testing Beta testing Answer: d Explanation: Acceptance testing is a test conducted to determine if the requirements of a specification or contract are met and is  done by users.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/77/1.+The+testing+in+which+code+is+checked.jpg""      ""name"": ""1. The testing in which code is checked""      ""description"": ""Black box testing. White box testing. Red box testing. Green box testing. Answer: b. Explanation: White-box testing is a method of testing software that tests internal structures or workings of an application  as opposed to its functionality. 2. Testing done without planning and Documentation is called. Unit testing. Regression testing. Adhoc testing. None of the mentioned. Answer: c. Explanation: Adhoc testing is used term for software testing performed without planning and documentation. The tests are intended to be run only once  unless a defect is discovered. 3. Acceptance testing is also known as. Grey box testing. Alpha Testing. Beta testing. Answer: d. Explanation: Acceptance testing is a test conducted to determine if the requirements of a specification or contract are met and is done by users.""      ""width"": ""1024"" }                         78                  4. Which of the following is non-functional testing?Black box testing Performance testing Unit testing None of the mentioned Answer: b Explanation: Performance testing is in general testing performed to determine how a system performs in  terms of responsiveness and stability under a particular workload. 5. Beta testing is done at User’s end Developer’s end Answer: a Explanation: In beta testing the user evaluates the product and gives his feedback. 6. SPICE stands for Software Process Improvement and Compatibility Determination Software Process Improvement and Control Determination Software Process Improvement and Capability Determination Answer: c Explanation: SPICE stands for Software Process Improvement and Control Determination.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/78/4.+Which+of+the+following+is+non-functional+testing.jpg""      ""name"": ""4. Which of the following is non-functional testing""      ""description"": ""Black box testing. Performance testing. Unit testing. None of the mentioned. Answer: b. Explanation: Performance testing is in general testing performed to determine how a system performs in terms of responsiveness and stability under a particular workload. 5. Beta testing is done at. User’s end. Developer’s end. Answer: a. Explanation: In beta testing the user evaluates the product and gives his feedback. 6. SPICE stands for. Software Process Improvement and Compatibility Determination. Software Process Improvement and Control Determination. Software Process Improvement and Capability Determination. Answer: c. Explanation: SPICE stands for Software Process Improvement and Control Determination.""      ""width"": ""1024"" }                         79                  7. Unit testing is done by Users Developers Customers Answer: b Explanation: Unit testing is a method by which individual units of source code  sets of one or more computer program modules together with  associated control data  usage procedures  and operating procedures are tested to determine if they are fit for use. 8. Behavioral testing is White box testing Black box testing Grey box testing Explanation: Black-box testing is a method of software testing that examines the functionality of an application without peering into its internal  structures or workings. 9. Which of the following is black box testing Basic path testing Boundary value analysis Code path analysis None of the mentioned Explanation: Boundary value analysis is a software testing technique in which tests are designed to include representatives of boundary values. 10. Which of the following is not used in measuring the size of the software KLOC Function Points Size of module Answer: c Explanation: KLOC and function points both can be used as size measurement for measuring the size of the software.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/79/7.+Unit+testing+is+done+by+Users.+Developers.+Customers.+Answer%3A+b..jpg""      ""name"": ""7. Unit testing is done by Users. Developers. Customers. Answer: b.""      ""description"": ""Explanation: Unit testing is a method by which individual units of source code  sets of one or more computer program modules together with associated control data  usage procedures  and operating procedures are tested to determine if they are fit for use. 8. Behavioral testing is. White box testing. Black box testing. Grey box testing. Explanation: Black-box testing is a method of software testing that examines the functionality of an application without peering into its internal structures or workings. 9. Which of the following is black box testing. Basic path testing. Boundary value analysis. Code path analysis. None of the mentioned. Explanation: Boundary value analysis is a software testing technique in which tests are designed to include representatives of boundary values. 10. Which of the following is not used in measuring the size of the software. KLOC. Function Points. Size of module. Answer: c. Explanation: KLOC and function points both can be used as size measurement for measuring the size of the software.""      ""width"": ""1024"" }                         80                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/80/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         81                  Unified Modelling LanguageSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/81/Unified+Modelling+Language.jpg""      ""name"": ""Unified Modelling Language""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         82                  1. Object oriented analysis and design can be handled by the one who knows UML.True False Answer: b Explanation: The Unified Modeling Language includes a set of graphic notation techniques to create visual models of  object-oriented software-intensive systems. 2. At Conceptual level Class diagrams should include operations only attributes only both (a) and (b) None of the mentioned Explanation: In software engineering  a class diagram in the Unified Modeling Language (UML) is a type of static structure diagram that describes the structure of a system by showing the system’s classes  their attributes  operations  and the relationships among objects. 3. Select the statement true for activity diagrams. They can be used to discover parallel activities They are used to depict workflow for a particular business activity Activity diagram do not tell who does what and are difficult to trace back to object models All of the mentioned Answer: d Explanation: Activity diagrams are graphical representations of workflows of step wise activities and actions with support  for choice  iteration and concurrency.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/82/1.+Object+oriented+analysis+and+design+can+be+handled+by+the+one+who+knows+UML..jpg""      ""name"": ""1. Object oriented analysis and design can be handled by the one who knows UML.""      ""description"": ""True. False. Answer: b. Explanation: The Unified Modeling Language includes a set of graphic notation techniques to create visual models of object-oriented software-intensive systems. 2. At Conceptual level Class diagrams should include. operations only. attributes only. both (a) and (b) None of the mentioned. Explanation: In software engineering  a class diagram in the Unified Modeling Language (UML) is a type of static structure diagram that describes the structure of a system by showing the system’s classes  their attributes  operations  and the relationships among objects. 3. Select the statement true for activity diagrams. They can be used to discover parallel activities. They are used to depict workflow for a particular business activity. Activity diagram do not tell who does what and are difficult to trace back to object models. All of the mentioned. Answer: d. Explanation: Activity diagrams are graphical representations of workflows of step wise activities and actions with support for choice  iteration and concurrency.""      ""width"": ""1024"" }                         83                  4. Constraints can be represented in UML by{text} [text] c) constraint d) None of the mentioned Answer: a Explanation: Constraints are represented by {text string}. 5. What is an object? An object is an instance of a class. An object includes encapsulation of data An object is not an instance of a class Explanation: An object is an instance of a class. 6. What is an abstract class? A class that has direct instances  but whose descendants may have direct instances. A class that has direct instances  but whose descendants may not have direct instances. A class that has no direct instances  but whose descendants may have direct instances. Answer: c Explanation: An abstract type is a type in a nominative type system which cannot be instantiated directly. 7. Which of the following are the valid relationships in Use Case Diagrams Generalization Include Extend All of the mentioned Answer: d Explanation: Generalization  include  extend all of these are valid relationships in use case diagrams.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/83/4.+Constraints+can+be+represented+in+UML+by.jpg""      ""name"": ""4. Constraints can be represented in UML by""      ""description"": ""{text} [text] c) constraint. d) None of the mentioned. Answer: a. Explanation: Constraints are represented by {text string}. 5. What is an object An object is an instance of a class. An object includes encapsulation of data. An object is not an instance of a class. Explanation: An object is an instance of a class. 6. What is an abstract class A class that has direct instances  but whose descendants may have direct instances. A class that has direct instances  but whose descendants may not have direct instances. A class that has no direct instances  but whose descendants may have direct instances. Answer: c. Explanation: An abstract type is a type in a nominative type system which cannot be instantiated directly. 7. Which of the following are the valid relationships in Use Case Diagrams. Generalization. Include. Extend. All of the mentioned. Answer: d. Explanation: Generalization  include  extend all of these are valid relationships in use case diagrams.""      ""width"": ""1024"" }                         84                  8. Which of the following statement(s) is true about interaction diagrams?a) Interaction diagrams are at their best when they deal with one main design flow and not multiple variants that can happen. b) Interaction diagrams are good at designing part or all of one use case’s functionality across multiple objects. Interaction diagrams allow the analyst to show iteration and conditional execution for messaging between objects. All of these Answer: d Explanation: Interaction diagram is used to describe some type of interactions among the different elements in the model. So  this interaction is a part of dynamic behaviour of the system. 9. UML interfaces are used to: specify required services for types of objects. program in Java  but not in C++ or Smalltalk. define executable logic to reuse across classes. define an API for all classes. Answer: a Explanation: An interface is like a template design for a class that contains no data or implementation; only definitions for  methods  properties etc. 10. Referring to the attached diagram  the arrow indicates: Navigability Dependency Association Refers to Explanation: The arrows describe the ways you can navigate.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/84/8.+Which+of+the+following+statement%28s%29+is+true+about+interaction+diagrams.jpg""      ""name"": ""8. Which of the following statement(s) is true about interaction diagrams""      ""description"": ""a) Interaction diagrams are at their best when they deal with one main design flow and not multiple variants that can happen. b) Interaction diagrams are good at designing part or all of one use case’s functionality across multiple objects. Interaction diagrams allow the analyst to show iteration and conditional execution for messaging between objects. All of these. Answer: d. Explanation: Interaction diagram is used to describe some type of interactions among the different elements in the model. So this interaction is a part of dynamic behaviour of the system. 9. UML interfaces are used to: specify required services for types of objects. program in Java  but not in C++ or Smalltalk. define executable logic to reuse across classes. define an API for all classes. Answer: a. Explanation: An interface is like a template design for a class that contains no data or implementation; only definitions for methods  properties etc. 10. Referring to the attached diagram  the arrow indicates: Navigability. Dependency. Association. Refers to. Explanation: The arrows describe the ways you can navigate.""      ""width"": ""1024"" }                         85                  Modularity in Software DesignSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/85/Modularity+in+Software+Design.jpg""      ""name"": ""Modularity in Software Design""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         86                  1. Java packages and Fortran subroutine are examples ofFunctions Modules Classes Sub procedures Answer:b Explanation: A modular system consist of well defined manageable units with well defined interfaces among the units. 2. Which of the property of software modularity is incorrect with respect to benefits software modularity? Modules are robust. Module can use other modules Modules Can be separately compiled and stored in a library. Modules are mostly dependent. Answer:d Explanation: Modularity cannot bring benefits unless the modules are autonomous or independent. 3.  	is a measure of the degree of interdependence between modules. Cohesion Coupling None of the mentioned Explanation: Coupling or dependency is the degree to which each program module relies on each one of the other  modules.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/86/1.+Java+packages+and+Fortran+subroutine+are+examples+of.jpg""      ""name"": ""1. Java packages and Fortran subroutine are examples of""      ""description"": ""Functions. Modules. Classes. Sub procedures. Answer:b. Explanation: A modular system consist of well defined manageable units with well defined interfaces among the units. 2. Which of the property of software modularity is incorrect with respect to benefits software modularity Modules are robust. Module can use other modules. Modules Can be separately compiled and stored in a library. Modules are mostly dependent. Answer:d. Explanation: Modularity cannot bring benefits unless the modules are autonomous or independent. 3. is a measure of the degree of interdependence between modules. Cohesion. Coupling. None of the mentioned. Explanation: Coupling or dependency is the degree to which each program module relies on each one of the other modules.""      ""width"": ""1024"" }                         87                  4. Which of the following is the best type of module coupling?Control Coupling Stamp Coupling Data Coupling Content Coupling Answer:c Explanation: The dependency between module A and B is said to be data coupled if their dependency is  based on the fact they communicate by only passing of data. 5. Which of the following is the worst type of module coupling? External Coupling Explanation: Content coupling occurs when module A changes data of module B or when control is passed from one module to the middle of another.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/87/4.+Which+of+the+following+is+the+best+type+of+module+coupling.jpg""      ""name"": ""4. Which of the following is the best type of module coupling""      ""description"": ""Control Coupling. Stamp Coupling. Data Coupling. Content Coupling. Answer:c. Explanation: The dependency between module A and B is said to be data coupled if their dependency is based on the fact they communicate by only passing of data. 5. Which of the following is the worst type of module coupling External Coupling. Explanation: Content coupling occurs when module A changes data of module B or when control is passed from one module to the middle of another.""      ""width"": ""1024"" }                         88                  6. Which of the following is the worst type of module cohesion?Logical Cohesion Temporal Cohesion Functional Cohesion Coincidental Cohesion Answer:d Explanation: Coincidental cohesion exists in modules that contain instructions that have little or no relationship to one  another. 7. Which of the following is the best type of module cohesion? Sequential Cohesion Answer:a Explanation: Functional Cohesion is a type of cohesion in which the tasks performed by a software module all  contribute to the performance of a single function. 8. A software engineer must design the modules with the goal of high cohesion and low coupling. True False Explanation: If the software is not properly modularized  a host of seemingly trivial enhancement or changes will result  into death of the project.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/88/6.+Which+of+the+following+is+the+worst+type+of+module+cohesion.jpg""      ""name"": ""6. Which of the following is the worst type of module cohesion""      ""description"": ""Logical Cohesion. Temporal Cohesion. Functional Cohesion. Coincidental Cohesion. Answer:d. Explanation: Coincidental cohesion exists in modules that contain instructions that have little or no relationship to one another. 7. Which of the following is the best type of module cohesion Sequential Cohesion. Answer:a. Explanation: Functional Cohesion is a type of cohesion in which the tasks performed by a software module all contribute to the performance of a single function. 8. A software engineer must design the modules with the goal of high cohesion and low coupling. True. False. Explanation: If the software is not properly modularized  a host of seemingly trivial enhancement or changes will result into death of the project.""      ""width"": ""1024"" }                         89                  9. In what type of coupling  the complete data structure is passed from one module to another?Control Coupling Stamp Coupling External Coupling Content Coupling Answer:b Explanation: The answer is self explanatory. 10. If all tasks must be executed in the same time-span  what type of cohesion is being exhibited? Functional Cohesion Temporal Cohesion Sequential Cohesion Explanation: A Module exhibits temporal cohesion when it contains tasks that are related by the fact that all tasks  must be executed in the same time-span.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/89/9.+In+what+type+of+coupling%2C+the+complete+data+structure+is+passed+from+one+module+to+another.jpg""      ""name"": ""9. In what type of coupling  the complete data structure is passed from one module to another""      ""description"": ""Control Coupling. Stamp Coupling. External Coupling. Content Coupling. Answer:b. Explanation: The answer is self explanatory. 10. If all tasks must be executed in the same time-span  what type of cohesion is being exhibited Functional Cohesion. Temporal Cohesion. Sequential Cohesion. Explanation: A Module exhibits temporal cohesion when it contains tasks that are related by the fact that all tasks must be executed in the same time-span.""      ""width"": ""1024"" }                         90                  Software Evolution Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/90/Software+Evolution+Source+%26+Courtsey%3A.jpg""      ""name"": ""Software Evolution Source &amp;amp; Courtsey:""      ""description"": ""Software Evolution Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         91                  1. The two dimensions of spiral model arediagonal  angular radial  perpendicular radial  angular diagonal  perpendicular Answer:c Explanation: The radial dimension depicts the cumulative costs and the angular dimension depicts the progress made in  completing each cycle. Each loop of the spiral model represents a phase. 2. The Incremental Model is combination of elements of Build & FIX Model & Waterfall Model Linear Model & RAD Model Linear Model & Prototyping Model Waterfall Model & RAD Model Explanation: Each linear sequence produces a deliverable “increment” of the software system  particularly needed in case of quick delivery of a limited functionality system. 3. Model preferred to create client/server applications is WINWIN Spiral Model Spiral Model Concurrent Model Incremental Model Explanation: In case of client/server applications  the concurrent process model specifies activities in two dimensions: a system  dimension and a component dimension. Hence Concurrency is achieved by these two activities occurring simultaneously and can  be modeled using the state-oriented approach.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/91/1.+The+two+dimensions+of+spiral+model+are.jpg""      ""name"": ""1. The two dimensions of spiral model are""      ""description"": ""diagonal  angular. radial  perpendicular. radial  angular. diagonal  perpendicular. Answer:c. Explanation: The radial dimension depicts the cumulative costs and the angular dimension depicts the progress made in completing each cycle. Each loop of the spiral model represents a phase. 2. The Incremental Model is combination of elements of. Build &amp;amp; FIX Model &amp;amp; Waterfall Model. Linear Model &amp;amp; RAD Model. Linear Model &amp;amp; Prototyping Model. Waterfall Model &amp;amp; RAD Model. Explanation: Each linear sequence produces a deliverable increment of the software system  particularly needed in case of quick delivery of a limited functionality system. 3. Model preferred to create client/server applications is. WINWIN Spiral Model. Spiral Model. Concurrent Model. Incremental Model. Explanation: In case of client/server applications  the concurrent process model specifies activities in two dimensions: a system dimension and a component dimension. Hence Concurrency is achieved by these two activities occurring simultaneously and can be modeled using the state-oriented approach.""      ""width"": ""1024"" }                         92                  4. Identify the correct statement with respect to Evolutionary development:Evolutionary development usually has two flavors; exploratory development  and throw-away prototyping. Very large projects are usually done using evolutionary development based approach. It facilitates easy project management  through the high volume of documentation it generates. Sometimes the construction of a throw-away prototype is not followed by a re- implementation of the software system  using a more structured approach. Answer:a Explanation: Evolutionary development usually has two flavors; exploratory development  and throw-away prototyping. 5.Spiral model was developed by Victor Bisili Berry Boehm Bev Littlewood Roger Pressman Answer:b Explanation: Berry Boehm in 1986 in his Article “A spiral model of software development and enhancement”. 6. Software evolution does not comprises: Development activities Negotiating with client Maintenance activities Re-engineering activities Explanation: Software evolution refers to the study and management of the process of making changes to software over  time. Thus it comprises rest three options.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/92/4.+Identify+the+correct+statement+with+respect+to+Evolutionary+development%3A.jpg""      ""name"": ""4. Identify the correct statement with respect to Evolutionary development:""      ""description"": ""Evolutionary development usually has two flavors; exploratory development  and throw-away prototyping. Very large projects are usually done using evolutionary development based approach. It facilitates easy project management  through the high volume of documentation it generates. Sometimes the construction of a throw-away prototype is not followed by a re- implementation of the software system using a more structured approach. Answer:a. Explanation: Evolutionary development usually has two flavors; exploratory development  and throw-away prototyping. 5.Spiral model was developed by. Victor Bisili. Berry Boehm. Bev Littlewood. Roger Pressman. Answer:b. Explanation: Berry Boehm in 1986 in his Article A spiral model of software development and enhancement . 6. Software evolution does not comprises: Development activities. Negotiating with client. Maintenance activities. Re-engineering activities. Explanation: Software evolution refers to the study and management of the process of making changes to software over time. Thus it comprises rest three options.""      ""width"": ""1024"" }                         93                  7. Processes for evolving a software product depend on:Type of software to be maintained. Development processes used. Skills and experience of the people involved. All the mentioned Answer:d Explanation: Processes used for software evolution depend on all these factors. 8. Which technique is applied to ensure the continued evolution of legacy systems ? Forward engineering Reverse Engineering Reengineering. b and c Explanation: Processes used for software evolution depend rely on these two techniques. 9. Program modularization and Source code translation are the activities of_ 	_. Answer:c Explanation: Reengineering is the examination and alteration of a subject system to reconstitute it in a new form and the  subsequent implementation of the new form.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/93/7.+Processes+for+evolving+a+software+product+depend+on%3A.jpg""      ""name"": ""7. Processes for evolving a software product depend on:""      ""description"": ""Type of software to be maintained. Development processes used. Skills and experience of the people involved. All the mentioned. Answer:d. Explanation: Processes used for software evolution depend on all these factors. 8. Which technique is applied to ensure the continued evolution of legacy systems Forward engineering. Reverse Engineering. Reengineering. b and c. Explanation: Processes used for software evolution depend rely on these two techniques. 9. Program modularization and Source code translation are the activities of_ _. Answer:c. Explanation: Reengineering is the examination and alteration of a subject system to reconstitute it in a new form and the subsequent implementation of the new form.""      ""width"": ""1024"" }                         94                  10. Reverse engineering is the last activity in a reengineering project.True False Answer:b Explanation: Reverse engineering is often the initial activity in a reengineering project. 11. The cost of re-engineering is often significantly less than the costs of developing new software. Answer:a Explanation: There is a high risk in new software development. There may be development problems   staffing problems and specification problems  thereby increasing the cost.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/94/10.+Reverse+engineering+is+the+last+activity+in+a+reengineering+project..jpg""      ""name"": ""10. Reverse engineering is the last activity in a reengineering project.""      ""description"": ""True. False. Answer:b. Explanation: Reverse engineering is often the initial activity in a reengineering project. 11. The cost of re-engineering is often significantly less than the costs of developing new software. Answer:a. Explanation: There is a high risk in new software development. There may be development problems  staffing problems and specification problems  thereby increasing the cost.""      ""width"": ""1024"" }                         95                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/95/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         96                  Function Oriented Software DesignSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/96/Function+Oriented+Software+Design.jpg""      ""name"": ""Function Oriented Software Design""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         97                  1. Choose the option that does not define Function Oriented Software Design.It consists of module definitions Modules represent data abstraction Modules support functional abstraction Answer:b Explanation: Option b defines an Object Oriented Design. 2. Which of the following is a complementary approach to function-oriented approach ? Object oriented analysis Object oriented design Structured approach Both a and b Answer:d Explanation: The answer is self explanatory. 3. Function-oriented design techniques starts with functional requirements specified in SDD SRS None of the mentioned  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/97/1.+Choose+the+option+that+does+not+define+Function+Oriented+Software+Design..jpg""      ""name"": ""1. Choose the option that does not define Function Oriented Software Design.""      ""description"": ""It consists of module definitions. Modules represent data abstraction. Modules support functional abstraction. Answer:b. Explanation: Option b defines an Object Oriented Design. 2. Which of the following is a complementary approach to function-oriented approach Object oriented analysis. Object oriented design. Structured approach. Both a and b. Answer:d. Explanation: The answer is self explanatory. 3. Function-oriented design techniques starts with functional requirements specified in. SDD. SRS. None of the mentioned.""      ""width"": ""1024"" }                         98                  4. Structured Analysis is based on the principles ofTop-down decomposition approach Divide and conquer principle Graphical representation of results using DFDs All of the mentioned Answer:d Explanation: The answer is self explanatory. 5. Which of the following is/are true with respect to functions ? a) A function such as “search-book” is represented using a circle. Functions represent some activity Function symbol is known as a process symbol or a bubble in DFD Explanation: All the options are correct with respect to Function Oriented Software Design. 6. Which of the following is not a use of a CASE tool ? Support structured analysis and design (SA/SD) Maintains the data dictionary Checks whether DFDs are balanced or not It complies with the available system. Explanation: It takes long time to establish the system in order to comply with the available system.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/98/4.+Structured+Analysis+is+based+on+the+principles+of.jpg""      ""name"": ""4. Structured Analysis is based on the principles of""      ""description"": ""Top-down decomposition approach. Divide and conquer principle. Graphical representation of results using DFDs. All of the mentioned. Answer:d. Explanation: The answer is self explanatory. 5. Which of the following is/are true with respect to functions a) A function such as search-book is represented using a circle. Functions represent some activity. Function symbol is known as a process symbol or a bubble in DFD. Explanation: All the options are correct with respect to Function Oriented Software Design. 6. Which of the following is not a use of a CASE tool Support structured analysis and design (SA/SD) Maintains the data dictionary. Checks whether DFDs are balanced or not. It complies with the available system. Explanation: It takes long time to establish the system in order to comply with the available system.""      ""width"": ""1024"" }                         99                  7. What DFD notation is represented by the Rectangle?Transform Data Store Function None of the mentioned Answer:b Explanation: The answer is self explanatory. 8. Structural decomposition is concerned with function calls. True False Answer:a Explanation: Structural decomposition is concerned with developing a model of the design which shows the dynamic structure. 9. A function-oriented design focuses on the entities in the system rather than the data processing activities. Explanation: It is an object oriented design whichfocus on entities. 10. In DFDs  user interactions with the system is denoted by Circle Arrow Rectangle Triangle  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/99/7.+What+DFD+notation+is+represented+by+the+Rectangle.jpg""      ""name"": ""7. What DFD notation is represented by the Rectangle""      ""description"": ""Transform. Data Store. Function. None of the mentioned. Answer:b. Explanation: The answer is self explanatory. 8. Structural decomposition is concerned with function calls. True. False. Answer:a. Explanation: Structural decomposition is concerned with developing a model of the design which shows the dynamic structure. 9. A function-oriented design focuses on the entities in the system rather than the data processing activities. Explanation: It is an object oriented design whichfocus on entities. 10. In DFDs  user interactions with the system is denoted by. Circle. Arrow. Rectangle. Triangle.""      ""width"": ""1024"" }                         100                  Dependability and Security AssuranceSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/100/Dependability+and+Security+Assurance.jpg""      ""name"": ""Dependability and Security Assurance""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         101                  1. Static Analysis involves executing a program.True False Answer:b Explanation: Static analysis techniques are system verification techniques that don’t involve executing a program. 2. Which of the following is a technique covered in Static Analysis ? Formal verification Model checking Automated program analysis All of the mentioned Answer:d Explanation: The answer is self explanatory. 3. Select the disadvantage of using Formal methods Concurrent systems can be analysed to discover race conditions that might lead to deadlock. Producing a mathematical specification requires a detailed analysis of the requirements They require the use of specialised notations that cannot be understood by domain experts Answer:c Explanation: Formal methods are the ultimate static verification technique that may be used at different  stages in the development process.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/101/1.+Static+Analysis+involves+executing+a+program..jpg""      ""name"": ""1. Static Analysis involves executing a program.""      ""description"": ""True. False. Answer:b. Explanation: Static analysis techniques are system verification techniques that don’t involve executing a program. 2. Which of the following is a technique covered in Static Analysis Formal verification. Model checking. Automated program analysis. All of the mentioned. Answer:d. Explanation: The answer is self explanatory. 3. Select the disadvantage of using Formal methods. Concurrent systems can be analysed to discover race conditions that might lead to deadlock. Producing a mathematical specification requires a detailed analysis of the requirements. They require the use of specialised notations that cannot be understood by domain experts. Answer:c. Explanation: Formal methods are the ultimate static verification technique that may be used at different stages in the development process.""      ""width"": ""1024"" }                         102                  4. Which of the following is incorrect with respect to Model Checking?Model checking is particularly valuable for verifying concurrent systems Model checking is computationally very inexpensive The model checker explores all possible paths through the model Answer:b Explanation: Model checking is very expensive.It is only practical to use it in the verification of small to medium sized critical systems. 5. Choose the fault class in which the following automated static analysis check would fall:”Variables declared but never used”. Control Faults Data Faults Input/Output Faults Interface faults Explanation: The answer is self explanatory. 6. Choose the fault class in which the following automated static analysis check would fall: “Unreachable code”. Answer:a  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/102/4.+Which+of+the+following+is+incorrect+with+respect+to+Model+Checking.jpg""      ""name"": ""4. Which of the following is incorrect with respect to Model Checking""      ""description"": ""Model checking is particularly valuable for verifying concurrent systems. Model checking is computationally very inexpensive. The model checker explores all possible paths through the model. Answer:b. Explanation: Model checking is very expensive.It is only practical to use it in the verification of small to medium sized critical systems. 5. Choose the fault class in which the following automated static analysis check would fall: Variables declared but never used . Control Faults. Data Faults. Input/Output Faults. Interface faults. Explanation: The answer is self explanatory. 6. Choose the fault class in which the following automated static analysis check would fall: Unreachable code . Answer:a.""      ""width"": ""1024"" }                         103                  7. Choose the fault class in which the following automated static analysis check would fall:”Non-usage of the results of functions”. Storage management faults Data Faults Input/Output Faults Interface faults Answer:d Explanation: The answer is self explanatory. 8. Static analysis is now routinely used in the development of many safety and security critical systems. True False Answer:a Explanation: The static analyzer can discover areas of vulnerability such as buffer overflows or unchecked inputs. 9. Which level of Static Analysis allows specific rules that apply to a program to be checked ? Characteristic error checking User-defined error checking Assertion checking Answer:b Explanation: Users of a programming language define error patterns  thus extending the types of error that can be detected. 10. Choose the fault class in which the following automated static analysis check would fall:”Pointer Arithmetic”.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/103/7.+Choose+the+fault+class+in+which+the+following+automated+static+analysis+check+would+fall%3A+Non-usage+of+the+results+of+functions+..jpg""      ""name"": ""7. Choose the fault class in which the following automated static analysis check would fall: Non-usage of the results of functions .""      ""description"": ""Storage management faults. Data Faults. Input/Output Faults. Interface faults. Answer:d. Explanation: The answer is self explanatory. 8. Static analysis is now routinely used in the development of many safety and security critical systems. True. False. Answer:a. Explanation: The static analyzer can discover areas of vulnerability such as buffer overflows or unchecked inputs. 9. Which level of Static Analysis allows specific rules that apply to a program to be checked Characteristic error checking. User-defined error checking. Assertion checking. Answer:b. Explanation: Users of a programming language define error patterns  thus extending the types of error that can be detected. 10. Choose the fault class in which the following automated static analysis check would fall: Pointer Arithmetic .""      ""width"": ""1024"" }                         104                  Security Engineering Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/104/Security+Engineering+Source+%26+Courtsey%3A.jpg""      ""name"": ""Security Engineering Source &amp;amp; Courtsey:""      ""description"": ""Security Engineering Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         105                  1. Which of the following is a layer of protection for Security ?Platform-level protection Application-level protection Record-level protection All of the mentioned Answer:d Explanation: The answer is self explanatory. 2. Security engineering is only concerned with maintenance of systems such that they can resist malicious attacks. True False Answer:b Explanation: Security engineering is concerned with maintenance as well as development of such systems. 3. What are security controls ? Controls that are intended to ensure that attacks are unsuccessful. Controls that are intended to detect and repel attacks. Controls that are intended to support recovery from problems. Explanation: All the options define a security control property.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/105/1.+Which+of+the+following+is+a+layer+of+protection+for+Security.jpg""      ""name"": ""1. Which of the following is a layer of protection for Security""      ""description"": ""Platform-level protection. Application-level protection. Record-level protection. All of the mentioned. Answer:d. Explanation: The answer is self explanatory. 2. Security engineering is only concerned with maintenance of systems such that they can resist malicious attacks. True. False. Answer:b. Explanation: Security engineering is concerned with maintenance as well as development of such systems. 3. What are security controls Controls that are intended to ensure that attacks are unsuccessful. Controls that are intended to detect and repel attacks. Controls that are intended to support recovery from problems. Explanation: All the options define a security control property.""      ""width"": ""1024"" }                         106                  4. Controls that are intended to repel attacks is analogous to4. Controls that are intended to repel attacks is analogous to  	in dependability engineering. Fault avoidance Fault tolerance Fault detection None of the mentioned Answer:b Explanation: Here the system is designed so that faults in the delivered software do not result in system failure. 5. Controls that are intended to ensure that attacks are unsuccessful is analogous to  	in dependability engineering. Fault Recovery Answer:a Explanation: In Fault avoidance the system is developed in such a way that human error is avoided and thus  system faults are minimised. 6. What is Life cycle risk assessment ? Risk assessment after the system has been deployed Risk assessment while the system is being developed Both a and b Answer:c Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/106/4.+Controls+that+are+intended+to+repel+attacks+is+analogous+to.jpg""      ""name"": ""4. Controls that are intended to repel attacks is analogous to""      ""description"": ""4. Controls that are intended to repel attacks is analogous to in dependability engineering. Fault avoidance. Fault tolerance. Fault detection. None of the mentioned. Answer:b. Explanation: Here the system is designed so that faults in the delivered software do not result in system failure. 5. Controls that are intended to ensure that attacks are unsuccessful is analogous to in dependability engineering. Fault Recovery. Answer:a. Explanation: In Fault avoidance the system is developed in such a way that human error is avoided and thus system faults are minimised. 6. What is Life cycle risk assessment Risk assessment after the system has been deployed. Risk assessment while the system is being developed. Both a and b. Answer:c. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         107                  7. A system resource that has a value and has to be protected is known asAsset Control Vulnerability None of the mentioned Answer:a Explanation: The answer is self explanatory. 8. An impersonation of an authorised user is an example of a security threat. True False Answer:b Explanation: It is a security attack. 9. The records of each patient that is receiving or has received treatment resembles which security concept ? Threat Explanation: Asset is a system resource that has a value and has to be protected. 10. Circumstances that have potential to cause loss or harm is known as Attack  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/107/7.+A+system+resource+that+has+a+value+and+has+to+be+protected+is+known+as.jpg""      ""name"": ""7. A system resource that has a value and has to be protected is known as""      ""description"": ""Asset. Control. Vulnerability. None of the mentioned. Answer:a. Explanation: The answer is self explanatory. 8. An impersonation of an authorised user is an example of a security threat. True. False. Answer:b. Explanation: It is a security attack. 9. The records of each patient that is receiving or has received treatment resembles which security concept Threat. Explanation: Asset is a system resource that has a value and has to be protected. 10. Circumstances that have potential to cause loss or harm is known as. Attack.""      ""width"": ""1024"" }                         108                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/108/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         109                  Dependability EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/109/Dependability+Engineering.jpg""      ""name"": ""Dependability Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         110                  1. Which of the following examples does not involve dependability engineering ?Medical Systems Power Systems Library Management Telecommunications Answer:c Explanation: Software customers expect all software to be dependable. However  for non-critical applications such as  certain management systems  they may be willing to accept some system failures. 2. What is the term for development process organised such that faults in the system are detected and repaired before delivery to the customer ? Fault Avoidance Fault detection Fault tolerance None of the mentioned Answer:a Explanation: In Fault Avoidance  the system is developed in such a way that human error is avoided and thus system faults  are minimised. 3. What is the term for a system that is designed such that the faults in the delivered software do not result in system failure ? Explanation: The answer is self-explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/110/1.+Which+of+the+following+examples+does+not+involve+dependability+engineering.jpg""      ""name"": ""1. Which of the following examples does not involve dependability engineering""      ""description"": ""Medical Systems. Power Systems. Library Management. Telecommunications. Answer:c. Explanation: Software customers expect all software to be dependable. However  for non-critical applications such as certain management systems  they may be willing to accept some system failures. 2. What is the term for development process organised such that faults in the system are detected and repaired before delivery to the. customer Fault Avoidance. Fault detection. Fault tolerance. None of the mentioned. Answer:a. Explanation: In Fault Avoidance  the system is developed in such a way that human error is avoided and thus system faults are minimised. 3. What is the term for a system that is designed such that the faults in the delivered software do not result in system failure Explanation: The answer is self-explanatory.""      ""width"": ""1024"" }                         111                  4. Which process characteristic with respect to Dependability Engineering is mentioned by the statement: “The process should be understandable by people apart from process participants” ? Diverse Documentable Auditable Answer:c Explanation: It means that process standards are being followed and make suggestions for process improvement. 5. Which of the following is not a Protection system ? System to stop a train if it passes a red light System to indicate not returning of the library book System to shut down a reactor if temperature/pressure are too high Answer:b Explanation: A Protection system is a specialized system that is associated with some other control system  which can take emergency action if a  failure occurs. 6. The use of a well-defined  repeatable process is essential if faults in a system are to be minimized. True False Answer:a Explanation: The answer is self explanatory. 7. Which of the following is a Strategy to achieve Software diversity ? Different programming languages Different design methods and tools Explicit specification of different algorithms All of the mentioned Answer:d Explanation: Diversity means to provide the same functionality in different ways so that critical components of a dependable system will not fail  in the same way.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/111/4.+Which+process+characteristic+with+respect+to+Dependability+Engineering+is+mentioned+by+the+statement%3A+The+process+should+be+understandable+by+people+apart+from+process+participants.jpg""      ""name"": ""4. Which process characteristic with respect to Dependability Engineering is mentioned by the statement: The process should be understandable by people apart from process participants""      ""description"": ""Diverse. Documentable. Auditable. Answer:c. Explanation: It means that process standards are being followed and make suggestions for process improvement. 5. Which of the following is not a Protection system System to stop a train if it passes a red light. System to indicate not returning of the library book. System to shut down a reactor if temperature/pressure are too high. Answer:b. Explanation: A Protection system is a specialized system that is associated with some other control system  which can take emergency action if a failure occurs. 6. The use of a well-defined  repeatable process is essential if faults in a system are to be minimized. True. False. Answer:a. Explanation: The answer is self explanatory. 7. Which of the following is a Strategy to achieve Software diversity Different programming languages. Different design methods and tools. Explicit specification of different algorithms. All of the mentioned. Answer:d. Explanation: Diversity means to provide the same functionality in different ways so that critical components of a dependable system will not fail in the same way.""      ""width"": ""1024"" }                         112                  8. Exception handling is a mechanism to provide some fault avoidance.True False Answer:b Explanation: Exception handling is a mechanism to provide some fault tolerance. 9. Which of the following is a bad practice of Dependable programming? Limit the visibility of information in a program Check array bounds Check all inputs for validity None of the mentioned Answer:d Explanation: All the options are good practices to achieve Dependability Engineering. 10. What is a Range check? Check that the input does not exceed some maximum size e.g. 40 characters for a name Check that the input falls within a known range Use information about the input to check if it is reasonable rather than an extreme value Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/112/8.+Exception+handling+is+a+mechanism+to+provide+some+fault+avoidance..jpg""      ""name"": ""8. Exception handling is a mechanism to provide some fault avoidance.""      ""description"": ""True. False. Answer:b. Explanation: Exception handling is a mechanism to provide some fault tolerance. 9. Which of the following is a bad practice of Dependable programming Limit the visibility of information in a program. Check array bounds. Check all inputs for validity. None of the mentioned. Answer:d. Explanation: All the options are good practices to achieve Dependability Engineering. 10. What is a Range check Check that the input does not exceed some maximum size e.g. 40 characters for a name. Check that the input falls within a known range. Use information about the input to check if it is reasonable rather than an extreme value. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         113                  Software CertificationSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/113/Software+Certification.jpg""      ""name"": ""Software Certification""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         114                  1. Which of the following is a field related to certification ?Person Process Product All of the mentioned Answer:d Explanation: During software certification all given options are targeted. 2. Which of the following is a software process certification ? JAVA Certified IBM Certified ISO-9000 Microsoft Certified Answer:c Explanation: The answer is self explanatory. 3. Which standard is followed in aviation industry ? CTRADO-172B RTCADO-178B RTRADO-178B CTCADO-178B Answer:b Explanation: RTCADO-178B is a popular aviation standard that has become a defacto standard.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/114/1.+Which+of+the+following+is+a+field+related+to+certification.jpg""      ""name"": ""1. Which of the following is a field related to certification""      ""description"": ""Person. Process. Product. All of the mentioned. Answer:d. Explanation: During software certification all given options are targeted. 2. Which of the following is a software process certification JAVA Certified. IBM Certified. ISO Microsoft Certified. Answer:c. Explanation: The answer is self explanatory. 3. Which standard is followed in aviation industry CTRADO-172B. RTCADO-178B. RTRADO-178B. CTCADO-178B. Answer:b. Explanation: RTCADO-178B is a popular aviation standard that has become a defacto standard.""      ""width"": ""1024"" }                         115                  4. How many levels  does the DO-178B certification targeted by RTCADO-178B has ?two three four five Answer:d Explanation: The levels are A  B  C  D  E. 5. Third Party Certification for software standards is based on Ul 1998  Second Edition UT 1998  Second Edition Ul 1992  Second Edition Ul 1996  Second Edition Answer:a Explanation: The answer is self explanatory. 6. What are the goals to gain Laboratory Accreditation ? Increase availability of testing services through third-party laboratories Increase availability of testing market to encourage development of software testing industry Reduce cost by increasing supply of testing services All of the mentioned Explanation: The goal is to promote development of competitive market  hence option d.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/115/4.+How+many+levels%2C+does+the+DO-178B+certification+targeted+by+RTCADO-178B+has.jpg""      ""name"": ""4. How many levels  does the DO-178B certification targeted by RTCADO-178B has""      ""description"": ""two. three. four. five. Answer:d. Explanation: The levels are A  B  C  D  E. 5. Third Party Certification for software standards is based on. Ul 1998  Second Edition. UT 1998  Second Edition. Ul 1992  Second Edition. Ul 1996  Second Edition. Answer:a. Explanation: The answer is self explanatory. 6. What are the goals to gain Laboratory Accreditation Increase availability of testing services through third-party laboratories. Increase availability of testing market to encourage development of software testing industry. Reduce cost by increasing supply of testing services. All of the mentioned. Explanation: The goal is to promote development of competitive market  hence option d.""      ""width"": ""1024"" }                         116                  7. National Voluntary Laboratory Accreditation Program approve accreditation inEnvironmental standards Computers and electronics Product testing All of the mentioned Answer:d Explanation: National Voluntary Laboratory Accreditation Program Works with other national metro-logy institutes  to establish criteria for mutual recognition of test results. 8. CSTE stands for Certified Software Technology Certified Software Tester Certified Software Trainee Answer:b Explanation: The answer is self explanatory. 10. Which of the following companies provide certifications for their own products? CISCO ORACLE Microsoft  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/116/7.+National+Voluntary+Laboratory+Accreditation+Program+approve+accreditation+in.jpg""      ""name"": ""7. National Voluntary Laboratory Accreditation Program approve accreditation in""      ""description"": ""Environmental standards. Computers and electronics. Product testing. All of the mentioned. Answer:d. Explanation: National Voluntary Laboratory Accreditation Program Works with other national metro-logy institutes to establish criteria for mutual recognition of test results. 8. CSTE stands for. Certified Software Technology. Certified Software Tester. Certified Software Trainee. Answer:b. Explanation: The answer is self explanatory. 10. Which of the following companies provide certifications for their own products CISCO. ORACLE. Microsoft.""      ""width"": ""1024"" }                         117                  Service Oriented ArchitectureSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/117/Service+Oriented+Architecture.jpg""      ""name"": ""Service Oriented Architecture""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         118                  1. Service Oriented Architecture (SOA) isStrongly Coupled Loosely Coupled Strongly Cohesive Loosely Cohesive Answer:b Explanation: SOA is the architectural style that supports loosely coupled services to enable business flexibility. 2. Which of the following is an essential principle of an architecture? Consistency Reliability Scalability All of the mentioned Answer:d Explanation: Architecture implies a consistent and coherent design approach. 3. Arrange the following activities in order to build a SOA. Virtualization through mediation. Track services with registries. Govern  secure and manage the services. Design for interoperability through the adoption of standards. i  ii  iii  iv iii  ii  i  iv ii  iii  i  iv ii  iii  iv  i Answer:c Explanation: The order mentioned is appropriate to build a SOA  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/118/1.+Service+Oriented+Architecture+%28SOA%29+is.jpg""      ""name"": ""1. Service Oriented Architecture (SOA) is""      ""description"": ""Strongly Coupled. Loosely Coupled. Strongly Cohesive. Loosely Cohesive. Answer:b. Explanation: SOA is the architectural style that supports loosely coupled services to enable business flexibility. 2. Which of the following is an essential principle of an architecture Consistency. Reliability. Scalability. All of the mentioned. Answer:d. Explanation: Architecture implies a consistent and coherent design approach. 3. Arrange the following activities in order to build a SOA. Virtualization through mediation. Track services with registries. Govern  secure and manage the services. Design for interoperability through the adoption of standards. i  ii  iii  iv. iii  ii  i  iv. ii  iii  i  iv. ii  iii  iv  i. Answer:c. Explanation: The order mentioned is appropriate to build a SOA.""      ""width"": ""1024"" }                         119                  4. How is SOA different from OO Architecture ?Strong coupling among objects Communications are prescriptive rather than being descriptive Data is separated from a service or behavior Data and methods are integrated into a single object Answer:c Explanation: A service-oriented architecture is essentially a collection of services which communicate with each other. 5. Which architecture will be built on top of a SOA ? The Application Architecture The Service Architecture The Component Architecture None of the mentioned Answer:a Explanation: The answer is self explanatory. 6. Which of the following utilities is not a part of Application Service Layer ? Policy implementation QoS Security Verify invoice Answer:d Explanation: It is a part of Business service layer.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/119/4.+How+is+SOA+different+from+OO+Architecture.jpg""      ""name"": ""4. How is SOA different from OO Architecture""      ""description"": ""Strong coupling among objects. Communications are prescriptive rather than being descriptive. Data is separated from a service or behavior. Data and methods are integrated into a single object. Answer:c. Explanation: A service-oriented architecture is essentially a collection of services which communicate with each other. 5. Which architecture will be built on top of a SOA The Application Architecture. The Service Architecture. The Component Architecture. None of the mentioned. Answer:a. Explanation: The answer is self explanatory. 6. Which of the following utilities is not a part of Application Service Layer Policy implementation. QoS. Security. Verify invoice. Answer:d. Explanation: It is a part of Business service layer.""      ""width"": ""1024"" }                         120                  7. Which of the following utilities is not a part of Business Service Layer ?Task centric service Wrapper Services Get account info Entity centric service Answer:b Explanation: It is a part of Application service layer. 8. We can build Service Oriented Architecture (SOA) using Object Oriented (OO) language True False Answer:a Explanation: In SOA  the design methodology is associated  not an OO programming language. In fact we can do OO based  architecture using non OO languages. Likewise we can build SOA using OO language. 9. Which architecture describes the various elements that support the implementation of services. The Application Architecture The Service Architecture The Component Architecture Answer:c Explanation: The answer is self explanatory. 10. Web Services is not a realization of SOA ? Explanation: Web services is one realization of the SOA.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/120/7.+Which+of+the+following+utilities+is+not+a+part+of+Business+Service+Layer.jpg""      ""name"": ""7. Which of the following utilities is not a part of Business Service Layer""      ""description"": ""Task centric service. Wrapper Services. Get account info. Entity centric service. Answer:b. Explanation: It is a part of Application service layer. 8. We can build Service Oriented Architecture (SOA) using Object Oriented (OO) language. True. False. Answer:a. Explanation: In SOA  the design methodology is associated  not an OO programming language. In fact we can do OO based architecture using non OO languages. Likewise we can build SOA using OO language. 9. Which architecture describes the various elements that support the implementation of services. The Application Architecture. The Service Architecture. The Component Architecture. Answer:c. Explanation: The answer is self explanatory. 10. Web Services is not a realization of SOA Explanation: Web services is one realization of the SOA.""      ""width"": ""1024"" }                         121                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/121/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         122                  Object Oriented Software Design – 1Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/122/Object+Oriented+Software+Design+%E2%80%93+1.jpg""      ""name"": ""Object Oriented Software Design – 1""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         123                  1. Choose the incorrect statement in terms of Objects.a) Objects are abstractions of real-world. b) Objects can’t manage themselves. c) Objects encapsulate state and representation information. Answer:b Explanation: Objects are independent. 2. What encapsulates both data and data manipulation functions ? Object Class Super Class Sub Class Answer:a Explanation: The answer is self explanatory. 3. Which of the following is a mechanism that allows several objects in an class hierarchy to have different  methods with the same name? Aggregation Polymorphism Inheritance Explanation: In polymorphism instances of each subclass will be free to respond to messages by calling their  own version of the method.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/123/1.+Choose+the+incorrect+statement+in+terms+of+Objects..jpg""      ""name"": ""1. Choose the incorrect statement in terms of Objects.""      ""description"": ""a) Objects are abstractions of real-world. b) Objects can’t manage themselves. c) Objects encapsulate state and representation information. Answer:b. Explanation: Objects are independent. 2. What encapsulates both data and data manipulation functions Object. Class. Super Class. Sub Class. Answer:a. Explanation: The answer is self explanatory. 3. Which of the following is a mechanism that allows several objects in an class hierarchy to have different methods with the same name Aggregation. Polymorphism. Inheritance. Explanation: In polymorphism instances of each subclass will be free to respond to messages by calling their own version of the method.""      ""width"": ""1024"" }                         124                  4. Inherited object classes are self-contained.True False Answer:b Explanation: Inherited object classes are not self-contained. They cannot be understood without reference to their super-classes. 5. Which of the following points related to Object-oriented development (OOD) is true? OOA is concerned with developing an object model of the application domain OOD is concerned with developing an object-oriented system model to implement requirements. Both a and b None of the mentioned Answer:c Explanation: The answer is in support with the OOD. 6. How is generalization implemented in Object Oriented programming languages? Inheritance Polymorphism Encapsulation Abstract Classes Answer:a Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/124/4.+Inherited+object+classes+are+self-contained..jpg""      ""name"": ""4. Inherited object classes are self-contained.""      ""description"": ""True. False. Answer:b. Explanation: Inherited object classes are not self-contained. They cannot be understood without reference to their super-classes. 5. Which of the following points related to Object-oriented development (OOD) is true OOA is concerned with developing an object model of the application domain. OOD is concerned with developing an object-oriented system model to implement requirements. Both a and b. None of the mentioned. Answer:c. Explanation: The answer is in support with the OOD. 6. How is generalization implemented in Object Oriented programming languages Inheritance. Polymorphism. Encapsulation. Abstract Classes. Answer:a. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         125                  7. Which of the following is a disadvantage of OOD ?Easier maintenance. Objects may be understood as stand-alone entities. Objects are potentially reusable components. None of the mentioned Answer: d Explanation: All the options define the characteristics of OOD. 8. Which of the following describes”Is-a-Relationship” ? Aggregation Inheritance Dependency Answer: b Explanation: The answer is self explanatory. 9. Object that collects data on request rather than autonomously is known as Active Object Passive Object Multiple instance Explanation: A passive object holds data  but does not initiate control. 10. Objects are executed sequentially in Parallel Both a and b Answer: c Explanation: Objects may be distributed and may execute  sequentially or in parallel.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/125/7.+Which+of+the+following+is+a+disadvantage+of+OOD.jpg""      ""name"": ""7. Which of the following is a disadvantage of OOD""      ""description"": ""Easier maintenance. Objects may be. understood as stand-alone entities. Objects are potentially reusable components. None of the mentioned. Answer: d. Explanation: All the options define the characteristics of OOD. 8. Which of the following describes Is-a-Relationship Aggregation. Inheritance. Dependency. Answer: b. Explanation: The answer is self explanatory. 9. Object that collects data on request rather than autonomously is known as. Active Object. Passive Object. Multiple instance. Explanation: A passive object holds data  but does not initiate control. 10. Objects are executed. sequentially. in Parallel. Both a and b. Answer: c. Explanation: Objects may be distributed and may execute sequentially or in parallel.""      ""width"": ""1024"" }                         126                  Function Oriented Design using Structured Analysis Structured DesignSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/126/Function+Oriented+Design+using+Structured+Analysis+Structured+Design.jpg""      ""name"": ""Function Oriented Design using Structured Analysis Structured Design""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         127                  1. SA/SD features are obtained from which of the methodologies?Constantine and Yourdon’s methodology DeMarco and Yourdon’s methodology Gane and Sarson’s methodology d) All of the mentioned Answer:d Explanation: The answer is self explanatory. 2. Which of the following is not an activity of Structured Analysis (SA) ? Functional decomposition Transformation of a textual problem description into a graphic model All the functions represented in the DFD are mapped to a module structure Answer:c Explanation: The module structure is the software architecture. 3. To arrive at a form which is suitable for implementation in some programming language is the purpose of Structured Analysis (SA) Structured Design (SD) Detailed Design (DD) None of the mentioned Answer:b  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/127/1.+SA%2FSD+features+are+obtained+from+which+of+the+methodologies.jpg""      ""name"": ""1. SA/SD features are obtained from which of the methodologies""      ""description"": ""Constantine and Yourdon’s methodology. DeMarco and Yourdon’s methodology. Gane and Sarson’s methodology. d) All of the mentioned. Answer:d. Explanation: The answer is self explanatory. 2. Which of the following is not an activity of Structured Analysis (SA) Functional decomposition. Transformation of a textual problem description into a graphic model. All the functions represented in the DFD are mapped to a module structure. Answer:c. Explanation: The module structure is the software architecture. 3. To arrive at a form which is suitable for implementation in some programming language is the purpose of. Structured Analysis (SA) Structured Design (SD) Detailed Design (DD) None of the mentioned. Answer:b.""      ""width"": ""1024"" }                         128                  4. The results of structured analysis can be easily understood by ordinary customers.True False Answer:a Explanation: The results of structured analysis directly represents customer’s perception of the problem and uses customer’s terminology for naming different functions and data. 5. Structured Analysis is based on the principle of Bottom-Up Approach. Answer:b Explanation: Structured Analysis follows uses decomposition approach. 6. The context diagram is also known as Level-0 DFD Level-1 DFD Level-2 DFD Explanation: Context diagram captures the various entities external to the system interacting with it and data flow occurring  between the system and the external entities. 7. A directed arc or line in DFD represents Data Store Data Process Data Flow Answer:c Explanation: It resembles data flow in the direction of the arrow.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/128/4.+The+results+of+structured+analysis+can+be+easily+understood+by+ordinary+customers..jpg""      ""name"": ""4. The results of structured analysis can be easily understood by ordinary customers.""      ""description"": ""True. False. Answer:a. Explanation: The results of structured analysis directly represents customer’s perception of the problem and uses customer’s terminology for naming different functions and data. 5. Structured Analysis is based on the principle of Bottom-Up Approach. Answer:b. Explanation: Structured Analysis follows uses decomposition approach. 6. The context diagram is also known as. Level-0 DFD. Level-1 DFD. Level-2 DFD. Explanation: Context diagram captures the various entities external to the system interacting with it and data flow occurring between the system and the external entities. 7. A directed arc or line in DFD represents. Data Store. Data Process. Data Flow. Answer:c. Explanation: It resembles data flow in the direction of the arrow.""      ""width"": ""1024"" }                         129                  8. A DFD is always accompanied by a data dictionary.True False Answer:a Explanation: A data dictionary lists all data items appearing in a DFD including definition and data names. 9. Which of the following is a function of CASE Tool? Supporting Structured analysis and design (SA/SD). Maintaining the data dictionary  Checking whether DFDs are balanced or not Al of the mentioned Explanation: The answer is self explanatory. 10. Data Store Symbol in DFD represents a Physical file Data Structure Logical file All of the mentioned Answer:d Explanation: A logical file can be a data structure or a physical file on disk.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/129/8.+A+DFD+is+always+accompanied+by+a+data+dictionary..jpg""      ""name"": ""8. A DFD is always accompanied by a data dictionary.""      ""description"": ""True. False. Answer:a. Explanation: A data dictionary lists all data items appearing in a DFD including definition and data names. 9. Which of the following is a function of CASE Tool Supporting Structured analysis and design (SA/SD). Maintaining the data dictionary  Checking whether DFDs are balanced or not. Al of the mentioned. Explanation: The answer is self explanatory. 10. Data Store Symbol in DFD represents a. Physical file. Data Structure. Logical file. All of the mentioned. Answer:d. Explanation: A logical file can be a data structure or a physical file on disk.""      ""width"": ""1024"" }                         130                  Testing Tools Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/130/Testing+Tools+Source+%26+Courtsey%3A.jpg""      ""name"": ""Testing Tools Source &amp;amp; Courtsey:""      ""description"": ""Testing Tools Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         131                  1. Standard Enforcer is a Static Testing Tool Dynamic Testing Answer:a Explanation: Static Testing tools are those that perform analysis of the the program without executing them at all. 2. Many applications using static analysis find % NCSS. NCSS stands for Non-Code Source Statement Non Comment Source Sentence Non-Comment Source Statement Answer:c Explanation: The answer is self explanatory. 3. Which testing tool does a simple job of enforcing standards in a uniform way of many programs? Static Analyzer Code Inspector Standard Enforcer Both b & c Answer:d Explanation: A standard enforcer is just like a code inspector  except that the rules are generally simpler.  Standard enforcer looks at only single statements while the static analyzer looks at whole programs.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/131/1.+Standard+Enforcer+is+a+Static+Testing+Tool.+Dynamic+Testing.+Answer%3Aa..jpg""      ""name"": ""1. Standard Enforcer is a Static Testing Tool. Dynamic Testing. Answer:a.""      ""description"": ""Explanation: Static Testing tools are those that perform analysis of the the program without executing them at all. 2. Many applications using static analysis find % NCSS. NCSS stands for. Non-Code Source Statement. Non Comment Source Sentence. Non-Comment Source Statement. Answer:c. Explanation: The answer is self explanatory. 3. Which testing tool does a simple job of enforcing standards in a uniform way of many programs Static Analyzer. Code Inspector. Standard Enforcer. Both b &amp;amp; c. Answer:d. Explanation: A standard enforcer is just like a code inspector  except that the rules are generally simpler. Standard enforcer looks at only single statements while the static analyzer looks at whole programs.""      ""width"": ""1024"" }                         132                  4. Software Testing with real data in real environment is known asalpha testing beta testing regression testing None of the mentioned Answer:b Explanation: Beta testing is the last stage of testing  and normally can involve sending the product to beta test sites  outside the company for real-world exposure or offering the product for a free trial download over the Internet. 5. Which of the following testing tools examine program systematically & automatically ? Code Inspector Static Analyzer Standard Enforcer Coverage Analyzer Explanation: A static analyzer operates from a pre-computed database o descriptive information derived from the source  text of the program. 6. Which testing tool is responsible for documenting programs ? Test/File Generator Test Harness System Test Archiving Systems Answer:c Explanation: The answer is self-explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/132/4.+Software+Testing+with+real+data+in+real+environment+is+known+as.jpg""      ""name"": ""4. Software Testing with real data in real environment is known as""      ""description"": ""alpha testing. beta testing. regression testing. None of the mentioned. Answer:b. Explanation: Beta testing is the last stage of testing  and normally can involve sending the product to beta test sites outside the company for real-world exposure or offering the product for a free trial download over the Internet. 5. Which of the following testing tools examine program systematically &amp;amp; automatically Code Inspector. Static Analyzer. Standard Enforcer. Coverage Analyzer. Explanation: A static analyzer operates from a pre-computed database o descriptive information derived from the source text of the program. 6. Which testing tool is responsible for documenting programs Test/File Generator. Test Harness System. Test Archiving Systems. Answer:c. Explanation: The answer is self-explanatory.""      ""width"": ""1024"" }                         133                  False 7. Beta Testing is done by Developers Testers UsersAll of the mentioned Answer:c Explanation: The answer is self explanatory. 8. Standard enforcer tool looks at the whole program. True False 9. Debugging Program is a program which runs concurrently with the program under test & provide commands to examine memory & registers stop execution at a particular point search for references for particular variables  constant and registers Answer:d Explanation: Debugging is a methodical process of finding and reducing the number of bugs  or defects  in a computer program or a  piece of electronic hardware  thus making it behave as expected. 10. Execution Verifier is a dynamic tool that is also known as Test File Generator Coverage Analyzer Output Comparator Test Harness System Answer:b  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/133/False+7.+Beta+Testing+is+done+by+Developers+Testers+Users.jpg""      ""name"": ""False 7. Beta Testing is done by Developers Testers Users""      ""description"": ""All of the mentioned. Answer:c. Explanation: The answer is self explanatory. 8. Standard enforcer tool looks at the whole program. True. False. 9. Debugging Program is a program which runs concurrently with the program under test &amp;amp; provide commands to. examine memory &amp;amp; registers. stop execution at a particular point. search for references for particular variables  constant and registers. Answer:d. Explanation: Debugging is a methodical process of finding and reducing the number of bugs  or defects  in a computer program or a piece of electronic hardware  thus making it behave as expected. 10. Execution Verifier is a dynamic tool that is also known as. Test File Generator. Coverage Analyzer. Output Comparator. Test Harness System. Answer:b.""      ""width"": ""1024"" }                         134                  Metrics Analysis Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/134/Metrics+Analysis+Source+%26+Courtsey%3A.jpg""      ""name"": ""Metrics Analysis Source &amp;amp; Courtsey:""      ""description"": ""Metrics Analysis Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         135                  1. Which of the following is not a metric for design model?Interface design metrics Component-level metrics Architectural metrics Complexity metrics Answer:d Explanation: Complexity metrics measure the logical complexity of source code. 2. Statement and branch coverage metrics are part of Analysis Model Testing Design Model Source Code Answer:b Explanation: These metrics lead to the design of test cases that provide program coverage. 3. Function Points in software engineering was first proposed by Booch Boehm Albrecht Jacobson Answer:c Explanation: First proposed by Albrecht in 1979  hundreds of books and papers have been written on functions points since then.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/135/1.+Which+of+the+following+is+not+a+metric+for+design+model.jpg""      ""name"": ""1. Which of the following is not a metric for design model""      ""description"": ""Interface design metrics. Component-level metrics. Architectural metrics. Complexity metrics. Answer:d. Explanation: Complexity metrics measure the logical complexity of source code. 2. Statement and branch coverage metrics are part of. Analysis Model. Testing. Design Model. Source Code. Answer:b. Explanation: These metrics lead to the design of test cases that provide program coverage. 3. Function Points in software engineering was first proposed by. Booch. Boehm. Albrecht. Jacobson. Answer:c. Explanation: First proposed by Albrecht in 1979  hundreds of books and papers have been written on functions points since then.""      ""width"": ""1024"" }                         136                  4. How many Information Domain Values are used for Function Point Computation?three four five six Answer:c Explanation: The five values are: External Inputs  External Outputs  External Inquiries  Internal Logical Files and  External Interface Files. 5. Function Point Computation is given by the formula FP = [count total * 0.65] * sum(Fi) FP = count total * [ * sum(Fi)] c) FP = count total * [ ] * sum(Fi) d) FP = [count total * ] * sum(Fi) Answer:b Explanation: Option b is the correct formula for Function Point Computation. 6. Architectural Design Metrics are  	in nature. Black Box White Box Gray Box Green Box Answer:a Explanation: They are “black box” in that they do not require any knowledge of the inner workings of a particular software component.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/136/4.+How+many+Information+Domain+Values+are+used+for+Function+Point+Computation.jpg""      ""name"": ""4. How many Information Domain Values are used for Function Point Computation""      ""description"": ""three. four. five. six. Answer:c. Explanation: The five values are: External Inputs  External Outputs  External Inquiries  Internal Logical Files and External Interface Files. 5. Function Point Computation is given by the formula. FP = [count total * 0.65] * sum(Fi) FP = count total * [ * sum(Fi)] c) FP = count total * [ ] * sum(Fi) d) FP = [count total * ] * sum(Fi) Answer:b. Explanation: Option b is the correct formula for Function Point Computation. 6. Architectural Design Metrics are in nature. Black Box. White Box. Gray Box. Green Box. Answer:a. Explanation: They are black box in that they do not require any knowledge of the inner workings of a particular software component.""      ""width"": ""1024"" }                         137                  7. Structural complexity of a module i is given as S(i) = f. f (i)7. Structural complexity of a module i is given as S(i) = f*f (i). What does f symbolizes here? “fan check-out” of module i “fan check-in” of module i “fan in” of module i “fan out” of module I Answer:d Explanation: Fan out is number of modules directly invoked by module i. 8. SMI stands for Software Mature Indicator Software Maturity Index Software Mature Index Software Maturity Indicator Answer:b Explanation: The answer is self explanatory. 9. As the SMI approaches 1.0  the software product starts becoming unstable True False Explanation: As the SMI approaches 1.0  the software product begins to stabilize.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/137/7.+Structural+complexity+of+a+module+i+is+given+as+S%28i%29+%3D+f.+f+%28i%29.jpg""      ""name"": ""7. Structural complexity of a module i is given as S(i) = f. f (i)""      ""description"": ""7. Structural complexity of a module i is given as S(i) = f*f (i). What does f symbolizes here fan check-out of module i. fan check-in of module i. fan in of module i. fan out of module I. Answer:d. Explanation: Fan out is number of modules directly invoked by module i. 8. SMI stands for. Software Mature Indicator. Software Maturity Index. Software Mature Index. Software Maturity Indicator. Answer:b. Explanation: The answer is self explanatory. 9. As the SMI approaches 1.0  the software product starts becoming unstable. True. False. Explanation: As the SMI approaches 1.0  the software product begins to stabilize.""      ""width"": ""1024"" }                         138                  10. SMI = [Mt – (Fa + Fc + Fd)]/Mt. Here Mt is the number of modulesin the current release in the current release that have been changed from the preceding release that were deleted in the current release Answer:a Explanation: The answer is self explanatory. 11. The amount of time that the software is available for use is known as Reliability Usability Efficiency Functionality 12. Usability in metric analysis is defined as the degree to which the software stated needs. is easy to use. makes optimal use of system resources. Answer:b  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/138/10.+SMI+%3D+%5BMt+%E2%80%93+%28Fa+%2B+Fc+%2B+Fd%29%5D%2FMt.+Here+Mt+is+the+number+of+modules.jpg""      ""name"": ""10. SMI = [Mt – (Fa + Fc + Fd)]/Mt. Here Mt is the number of modules""      ""description"": ""in the current release. in the current release that have been changed. from the preceding release that were deleted in the current release. Answer:a. Explanation: The answer is self explanatory. 11. The amount of time that the software is available for use is known as. Reliability. Usability. Efficiency. Functionality. 12. Usability in metric analysis is defined as the degree to which the software. stated needs. is easy to use. makes optimal use of system resources. Answer:b.""      ""width"": ""1024"" }                         139                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/139/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         140                  Fault Tolerance Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/140/Fault+Tolerance+Source+%26+Courtsey%3A.jpg""      ""name"": ""Fault Tolerance Source &amp;amp; Courtsey:""      ""description"": ""Fault Tolerance Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         141                  1. What type of fault remains in the system for some period and then disappears?Permanent Transient Intermittent Answer:b Explanation: For example many faults in communication systems are transient in nature. 2. Which of the following approaches are used to achieve reliable systems? Fault prevention Fault removal Fault tolerance All of the mentioned Answer:d Explanation: All the options lead to formation of a reliable system. 3. A system maintaining its integrity while accepting a temporary halt in its operation is said to be in a state of Full Fault Tolerance Graceful Degradation Fail Soft Fail Safe Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/141/1.+What+type+of+fault+remains+in+the+system+for+some+period+and+then+disappears.jpg""      ""name"": ""1. What type of fault remains in the system for some period and then disappears""      ""description"": ""Permanent. Transient. Intermittent. Answer:b. Explanation: For example many faults in communication systems are transient in nature. 2. Which of the following approaches are used to achieve reliable systems Fault prevention. Fault removal. Fault tolerance. All of the mentioned. Answer:d. Explanation: All the options lead to formation of a reliable system. 3. A system maintaining its integrity while accepting a temporary halt in its operation is said to be in a state of. Full Fault Tolerance. Graceful Degradation. Fail Soft. Fail Safe. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         142                  4. Which of the following Error Detection checks is not a part of Application detection?Hardware checks Timing checks Reversal checks Coding checks Answer:a Explanation: Hardware is a part of environment detection check. 5. Exception handling is a type of forward error recovery mechanism backward error recovery mechanism Explanation: Exception handling is a forward error recovery mechanism  as there is no roll back to a  previous state; instead control is passed to the handler so that recovery procedures can be initiated. 6. Non-occurrence of improper alteration of information is known as Available Dependability Confidential Dependability Maintainable Dependability Integral Dependability Answer:d Explanation: Integrity is to keep the original content safe from alteration.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/142/4.+Which+of+the+following+Error+Detection+checks+is+not+a+part+of+Application+detection.jpg""      ""name"": ""4. Which of the following Error Detection checks is not a part of Application detection""      ""description"": ""Hardware checks. Timing checks. Reversal checks. Coding checks. Answer:a. Explanation: Hardware is a part of environment detection check. 5. Exception handling is a type of. forward error recovery mechanism. backward error recovery mechanism. Explanation: Exception handling is a forward error recovery mechanism  as there is no roll back to a previous state; instead control is passed to the handler so that recovery procedures can be initiated. 6. Non-occurrence of improper alteration of information is known as. Available Dependability. Confidential Dependability. Maintainable Dependability. Integral Dependability. Answer:d. Explanation: Integrity is to keep the original content safe from alteration.""      ""width"": ""1024"" }                         143                  7. In N-version programming which is the independent generation of N  the value of N isgreater than 1 less than 1 greater than 2 less than 2 Answer:c Explanation: N-version programming (NVP)  also known as multiversion programming or  multiple-version dissimilar software  is a method or process in software engineering  where multiple functionally equivalent programs are independently generated from the  same initial specifications. 8. In Log-based fault tolerance  logs of undetermined events are saved and replayed on failure. True False Answer:a Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/143/7.+In+N-version+programming+which+is+the+independent+generation+of+N%2C+the+value+of+N+is.jpg""      ""name"": ""7. In N-version programming which is the independent generation of N  the value of N is""      ""description"": ""greater than 1. less than 1. greater than 2. less than 2. Answer:c. Explanation: N-version programming (NVP)  also known as multiversion programming or multiple-version dissimilar software  is a method or process in software engineering where multiple functionally equivalent programs are independently generated from the same initial specifications. 8. In Log-based fault tolerance  logs of undetermined events are saved and replayed on failure. True. False. Answer:a. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         144                  9. All fault-tolerant techniques rely onIntegrity Dependability Redundancy Answer:c Explanation: All fault-tolerant techniques rely on extra elements introduced into the system to  detect & recover from faults. 10. It is imperative for a communicating processes to reach consistent recovery points to avoid the  	 effect  with backward error recovery mechanism. Static Dynamic Domino Whirlpool Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/144/9.+All+fault-tolerant+techniques+rely+on.jpg""      ""name"": ""9. All fault-tolerant techniques rely on""      ""description"": ""Integrity. Dependability. Redundancy. Answer:c. Explanation: All fault-tolerant techniques rely on extra elements introduced into the system to detect &amp;amp; recover from faults. 10. It is imperative for a communicating processes to reach consistent recovery points to avoid the effect  with backward error recovery mechanism. Static. Dynamic. Domino. Whirlpool. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         145                  Metrics for Quality ControlSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/145/Metrics+for+Quality+Control.jpg""      ""name"": ""Metrics for Quality Control""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         146                  1. Size and Complexity are a part ofProduct Metrics Process Metrics Project Metrics Answer:a Explanation: Product Metrics describe the characteristics of product. 2. Cost and schedule are a part of Answer:c Explanation: Project Metrics describe the project characteristics and execution. 3. Number of errors found per person hours expended is an example of a measurement measure metric Explanation: Metric is a quantitative measure of the degree to which a system  component  or process possesses a given attribute.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/146/1.+Size+and+Complexity+are+a+part+of.jpg""      ""name"": ""1. Size and Complexity are a part of""      ""description"": ""Product Metrics. Process Metrics. Project Metrics. Answer:a. Explanation: Product Metrics describe the characteristics of product. 2. Cost and schedule are a part of. Answer:c. Explanation: Project Metrics describe the project characteristics and execution. 3. Number of errors found per person hours expended is an example of a. measurement. measure. metric. Explanation: Metric is a quantitative measure of the degree to which a system  component  or process possesses a given attribute.""      ""width"": ""1024"" }                         147                  4. Which of the following is not categorized under Product Operation of McCall’s Software Quality Factors? Flexibility Reliability Usability Integrity Answer:a Explanation: Flexibility is a part of Product revision as per McCall’s Software Quality Factors. 5. The arc-to-node ratio is given as r = a/n. What does ‘a’ represent in the ratio? maximum number of nodes at any level longest path from the root to a leaf number of modules lines of control Answer:d Explanation: ‘a’ represents the arcs or the lines of control. 6. Which of the following is not categorized under Component-Level Design Metrics? Complexity Metrics Cohesion Metrics Morphology Metrics Coupling Metrics Answer:c Explanation: Morphology metrics are a part of High level design metrics. 7. Percentage of modules that were inspected is a part of Product Metrics Process Metrics c) Project Metrics Answer:b Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/147/4.+Which+of+the+following+is+not+categorized+under+Product+Operation+of+McCall%E2%80%99s+Software+Quality+Factors.jpg""      ""name"": ""4. Which of the following is not categorized under Product Operation of McCall’s Software Quality Factors""      ""description"": ""Flexibility. Reliability. Usability. Integrity. Answer:a. Explanation: Flexibility is a part of Product revision as per McCall’s Software Quality Factors. 5. The arc-to-node ratio is given as r = a/n. What does ‘a’ represent in the ratio maximum number of nodes at any level. longest path from the root to a leaf. number of modules. lines of control. Answer:d. Explanation: ‘a’ represents the arcs or the lines of control. 6. Which of the following is not categorized under Component-Level Design Metrics Complexity Metrics. Cohesion Metrics. Morphology Metrics. Coupling Metrics. Answer:c. Explanation: Morphology metrics are a part of High level design metrics. 7. Percentage of modules that were inspected is a part of. Product Metrics. Process Metrics. c) Project Metrics. Answer:b. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         148                  8. Metric is the act of obtaining a measure.True False Answer:b Explanation: Measurement is the act of obtaining a measure. 9. MTTC falls the the category of Correctness: integrity maintainability Answer:c Explanation: Mean time to change (MTTC) is the time it takes to analyze the change request  design an  appropriate modification  implement the change  test it  and distribute the change to all users. 10. Identify the correct option with reference to Software Quality Metrics. Integrity = [Sigma(1 – threat)] * (1 – security) Integrity = [1 – Sigma(threat)] * (1 – security) Integrity = [1 – threat * Sigma(1 – security)] d) Integrity = Sigma[1 – threat * (1 – security)] Answer:d Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/148/8.+Metric+is+the+act+of+obtaining+a+measure..jpg""      ""name"": ""8. Metric is the act of obtaining a measure.""      ""description"": ""True. False. Answer:b. Explanation: Measurement is the act of obtaining a measure. 9. MTTC falls the the category of. Correctness: integrity. maintainability. Answer:c. Explanation: Mean time to change (MTTC) is the time it takes to analyze the change request  design an appropriate modification  implement the change  test it  and distribute the change to all users. 10. Identify the correct option with reference to Software Quality Metrics. Integrity = [Sigma(1 – threat)] * (1 – security) Integrity = [1 – Sigma(threat)] * (1 – security) Integrity = [1 – threat * Sigma(1 – security)] d) Integrity = Sigma[1 – threat * (1 – security)] Answer:d. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         149                  Object Oriented Software Design – 2Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/149/Object+Oriented+Software+Design+%E2%80%93+2.jpg""      ""name"": ""Object Oriented Software Design – 2""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         150                  1. How many layers are present in the OO design pyramid?three four five Answer:b Explanation: The four layers are: Subsystem layer  class and object layer  message layer and  responsibilities layer 2. Which of the following early OOD methods incorporates both a “micro development process” and a “macro development process.” ? Booch method Rumbaugh method Wirfs-Brock method Coad and Yourdon method Answer:a Explanation: The macro development process includes the architectural planning and micro  developments process defines rules that govern the use of operations and attributes and the  domain-specific policies for memory management  error handling  and other infrastructure functions.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/150/1.+How+many+layers+are+present+in+the+OO+design+pyramid.jpg""      ""name"": ""1. How many layers are present in the OO design pyramid""      ""description"": ""three. four. five. Answer:b. Explanation: The four layers are: Subsystem layer  class and object layer  message layer and responsibilities layer. 2. Which of the following early OOD methods incorporates both a micro development process and a macro development process. Booch method. Rumbaugh method. Wirfs-Brock method. Coad and Yourdon method. Answer:a. Explanation: The macro development process includes the architectural planning and micro developments process defines rules that govern the use of operations and attributes and the domain-specific policies for memory management  error handling  and other infrastructure functions.""      ""width"": ""1024"" }                         151                  3. Grady Booch  James Rumbaugh  and Ivar Jacobson combined the best features of their individual object-oriented analysis into a new method for object oriented design known as HTML XML UML SGML Answer:c Explanation: The Unified Modeling Language (UML) has become widely used throughout the industry as the standard approach to OOD. 4. A design description of an object is known as a class instance object case both a and b Answer:d Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/151/3.+Grady+Booch%2C+James+Rumbaugh%2C+and+Ivar+Jacobson+combined+the+best+features+of+their+individual+object-oriented+analysis+into+a+new+method+for+object+oriented+design+known+as.jpg""      ""name"": ""3. Grady Booch  James Rumbaugh  and Ivar Jacobson combined the best features of their individual object-oriented analysis into a new method for object oriented design known as""      ""description"": ""HTML. XML. UML. SGML. Answer:c. Explanation: The Unified Modeling Language (UML) has become. widely used throughout the industry as the standard approach to OOD. 4. A design description of an object is known as a class. instance. object. case. both a and b. Answer:d. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         152                  5. Which of the following is conceptually similar to objects?PACKAGE PROC PRIVATE Answer:a Explanation: A package is a namespace that organizes a set of related classes and interfaces. 6. A design description in OOD includes Protocol Description Implementation Description Type Description both a and b Answer:d Explanation: The answer is self explanatory. 7. Which of the following is not an operation as per OOD algorithms and data structures? operations that manipulate data in some way operations that perform a computation operations that check for syntax errors operations that monitor an object for the occurrence of a controlling event. Answer: c Explanation: Option c is incorrect as it is concerned with the programming language used  so it will be handled  by the compiler.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/152/5.+Which+of+the+following+is+conceptually+similar+to+objects.jpg""      ""name"": ""5. Which of the following is conceptually similar to objects""      ""description"": ""PACKAGE. PROC. PRIVATE. Answer:a. Explanation: A package is a namespace that organizes a set of related classes and interfaces. 6. A design description in OOD includes. Protocol Description. Implementation Description. Type Description. both a and b. Answer:d. Explanation: The answer is self explanatory. 7. Which of the following is not an operation as per OOD algorithms and data structures operations that manipulate data in some way. operations that perform a computation. operations that check for syntax errors. operations that monitor an object for the occurrence of a controlling event. Answer: c. Explanation: Option c is incorrect as it is concerned with the programming language used  so it will be handled by the compiler.""      ""width"": ""1024"" }                         153                  8. Throughout the OOD process  a software engineer should look for every opportunity for creating new design process. True False Answer:b Explanation: A software engineer should look for every opportunity to reuse existing  design patterns whenever they meet the needs of the design rather than creating new  ones.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/153/8.+Throughout+the+OOD+process%2C+a+software+engineer+should+look+for+every+opportunity+for+creating+new+design+process..jpg""      ""name"": ""8. Throughout the OOD process  a software engineer should look for every opportunity for creating new design process.""      ""description"": ""True. False. Answer:b. Explanation: A software engineer should look for every opportunity to reuse existing design patterns whenever they meet the needs of the design rather than creating new ones.""      ""width"": ""1024"" }                         154                  Web Engineering Project MetricsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/154/Web+Engineering+Project+Metrics.jpg""      ""name"": ""Web Engineering Project Metrics""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         155                  1. The user has no control over the contents of a static web page.True False Answer:a Explanation: Static web pages are just for information purposes. 2. Which metric gives the idea about the contents on a web page ? Word Token Word Count Word Size Word Length Answer:b Explanation: The word count metric gives the total number of words on a web page. 3. How is the complexity of a web page related to link count ? Directly Indirectly No relation Explanation: If link count is more  complexity will be more. 4. It is expected to have less number of connections for a good web application. Explanation: More the link count  more the complexity and the web page dependence factor will increase.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/155/1.+The+user+has+no+control+over+the+contents+of+a+static+web+page..jpg""      ""name"": ""1. The user has no control over the contents of a static web page.""      ""description"": ""True. False. Answer:a. Explanation: Static web pages are just for information purposes. 2. Which metric gives the idea about the contents on a web page Word Token. Word Count. Word Size. Word Length. Answer:b. Explanation: The word count metric gives the total number of words on a web page. 3. How is the complexity of a web page related to link count Directly. Indirectly. No relation. Explanation: If link count is more  complexity will be more. 4. It is expected to have less number of connections for a good web application. Explanation: More the link count  more the complexity and the web page dependence factor will increase.""      ""width"": ""1024"" }                         156                  5. Number of dynamic web pages provides an idea about_5. Number of dynamic web pages provides an idea about_ 	for a web page that is to be built. size complexity effort All of the mentioned Answer:d Explanation: The answer is self explanatory. 6. Which of the following web engineering metric measures the extent of relatedness between two or more web pages ? Number of Static Content Objects Number of Dynamic Content Objects Web Page Similarity Number of Internal Page Links Answer:c 7. Which of the following is not a classification of the web engineering metric  Web Page Similarity ? Content based Link based Usage based Traffic based Explanation: Similarity between two web pages is not judged upon its traffic activity.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/156/5.+Number+of+dynamic+web+pages+provides+an+idea+about_.jpg""      ""name"": ""5. Number of dynamic web pages provides an idea about_""      ""description"": ""5. Number of dynamic web pages provides an idea about_ for a web page that is to be built. size. complexity. effort. All of the mentioned. Answer:d. Explanation: The answer is self explanatory. 6. Which of the following web engineering metric measures the extent of relatedness between two or more web pages Number of Static Content Objects. Number of Dynamic Content Objects. Web Page Similarity. Number of Internal Page Links. Answer:c. 7. Which of the following is not a classification of the web engineering metric  Web Page Similarity Content based. Link based. Usage based. Traffic based. Explanation: Similarity between two web pages is not judged upon its traffic activity.""      ""width"": ""1024"" }                         157                  8. The static content objects are dependent on the actions of the user.True False Answer:b Explanation: Dynamic Objects are user dependent 9. Link based measures rely on  	structure of a web graph to obtain related pages. Embedded Hyperlink Dynamic Explanation: Only option b answers the blank  rest are not in accordance to the question. 10. Which of the following is not a web engineering project metric ? Number of Static Content Objects Number of Dynamic Content Objects Number of Inherited Objects Word Count Answer:c Explanation: There is no such metric as an inherited object’s count.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/157/8.+The+static+content+objects+are+dependent+on+the+actions+of+the+user..jpg""      ""name"": ""8. The static content objects are dependent on the actions of the user.""      ""description"": ""True. False. Answer:b. Explanation: Dynamic Objects are user dependent. 9. Link based measures rely on structure of a web graph to obtain related pages. Embedded. Hyperlink. Dynamic. Explanation: Only option b answers the blank  rest are not in accordance to the question. 10. Which of the following is not a web engineering project metric Number of Static Content Objects. Number of Dynamic Content Objects. Number of Inherited Objects. Word Count. Answer:c. Explanation: There is no such metric as an inherited object’s count.""      ""width"": ""1024"" }                         158                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/158/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         159                  Software Control Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/159/Software+Control+Source+%26+Courtsey%3A.jpg""      ""name"": ""Software Control Source &amp;amp; Courtsey:""      ""description"": ""Software Control Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         160                  1. SCM stands for Software Control Management Software Configuration Management Software Concept Management None of the above Answer:b Explanation:In software engineering  software configuration management (SCM) is the task of tracking and  controlling changes in the software  part of the larger cross-discipline field of configuration management. 2. When code is made available to others  it goes in a/an hard drive access-controlled library servers access control Explanation:The answer is self explanatory. 3. Which of the following is not a main phase in Configuration Management (CM) Process? CM Planning Executing the CM process CM audits None of the mentioned Answer:d Explanation:All are main phases of CM.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/160/1.+SCM+stands+for+Software+Control+Management.+Software+Configuration+Management.+Software+Concept+Management..jpg""      ""name"": ""1. SCM stands for Software Control Management. Software Configuration Management. Software Concept Management.""      ""description"": ""None of the above. Answer:b. Explanation:In software engineering  software configuration management (SCM) is the task of tracking and controlling changes in the software  part of the larger cross-discipline field of configuration management. 2. When code is made available to others  it goes in a/an. hard drive. access-controlled library. servers. access control. Explanation:The answer is self explanatory. 3. Which of the following is not a main phase in Configuration Management (CM) Process CM Planning. Executing the CM process. CM audits. None of the mentioned. Answer:d. Explanation:All are main phases of CM.""      ""width"": ""1024"" }                         161                  4. CM is about managing the different items in the product  and changes in them.True False Answer:a Explanation:The answer is self explanatory. 5. What allows different projects to use the same source files at the same time? Version Control Access control CM Process Version Control and Access control Explanation:It allows software engineers to continue development along a branch even when a line of development is frozen. 6. Which of the following is not a change management process? Log the changes Estimate impact on effort and schedule Review impact with stakeholders None of the mentioned Answer:d Explanation:All are required for a change. 7. Configuration management (CM) is needed to deliver product to the client  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/161/4.+CM+is+about+managing+the+different+items+in+the+product%2C+and+changes+in+them..jpg""      ""name"": ""4. CM is about managing the different items in the product  and changes in them.""      ""description"": ""True. False. Answer:a. Explanation:The answer is self explanatory. 5. What allows different projects to use the same source files at the same time Version Control. Access control. CM Process. Version Control and Access control. Explanation:It allows software engineers to continue development along a branch even when a line of development is frozen. 6. Which of the following is not a change management process Log the changes. Estimate impact on effort and schedule. Review impact with stakeholders. None of the mentioned. Answer:d. Explanation:All are required for a change. 7. Configuration management (CM) is needed to deliver product to the client.""      ""width"": ""1024"" }                         162                  8. What is one or more software configuration items that have been formally reviewed and agreed upon and serve as a basis for further development? Baseline Cumulative changes CM Change Control Answer:a Explanation:In configuration management  a “baseline” is an agreed-to description of the attributes of a product  at a  point in time  which serves as a basis for defining change. 9. How are baselines verified? By reviews By inspections By testing of code All of the above Answer:c Explanation:Testing verifies the agreed-to description. 10. Which of the following is a example of Configuration Items ? SCM procedures Source code Software design descriptions All of the mentioned Answer:d Explanation:All are covered in CM.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/162/8.+What+is+one+or+more+software+configuration+items+that+have+been+formally+reviewed+and+agreed+upon+and+serve+as+a+basis+for+further+development.jpg""      ""name"": ""8. What is one or more software configuration items that have been formally reviewed and agreed upon and serve as a basis for further development""      ""description"": ""Baseline. Cumulative changes. CM. Change Control. Answer:a. Explanation:In configuration management  a baseline is an agreed-to description of the attributes of a product  at a point in time  which serves as a basis for defining change. 9. How are baselines verified By reviews. By inspections. By testing of code. All of the above. Answer:c. Explanation:Testing verifies the agreed-to description. 10. Which of the following is a example of Configuration Items SCM procedures. Source code. Software design descriptions. All of the mentioned. Answer:d. Explanation:All are covered in CM.""      ""width"": ""1024"" }                         163                  11. SCM controls only the products of the development process.True False Answer:a Explanation:The answer is self explanatory. 12. CCB stands for Change Control Board Change Control Baseline Cumulative Changes in Baseline None of the mentioned 13. What information is required to process a change to a baseline? Reasons for making the changes A description of the proposed changes List of other items affected by the changes All of the mentioned Answer:d Explanation:A baseline is an agreed-to description of the product  changes require multiple reasons.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/163/11.+SCM+controls+only+the+products+of+the+development+process..jpg""      ""name"": ""11. SCM controls only the products of the development process.""      ""description"": ""True. False. Answer:a. Explanation:The answer is self explanatory. 12. CCB stands for. Change Control Board. Change Control Baseline. Cumulative Changes in Baseline. None of the mentioned. 13. What information is required to process a change to a baseline Reasons for making the changes. A description of the proposed changes. List of other items affected by the changes. All of the mentioned. Answer:d. Explanation:A baseline is an agreed-to description of the product  changes require multiple reasons.""      ""width"": ""1024"" }                         164                  Decomposition Techniques in SoftwareProject Planning Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/164/Decomposition+Techniques+in+Software.jpg""      ""name"": ""Decomposition Techniques in Software""      ""description"": ""Project Planning. Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         165                  1. Why is decomposition technique required?Software project estimation is a form of problem solving Developing a cost and effort estimate for a software project is too complex All of the mentioned None of the mentioned Answer:c Explanation:For these reasons  we decompose the problem  re-characterizing it as a set of smaller problems. 2. Cost and effort estimation of a software uses only one forms of decomposition  either decomposition of the  problem or decomposition of the process. True False Answer:b Explanation:Estimation uses one or both forms of partitioning. 3. If a Direct approach to software project sizing is taken  size can be measured in LOC FP LOC and FP Answer:a Explanation:LOC or Line of Code is a direct measure to estiom ate project size.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/165/1.+Why+is+decomposition+technique+required.jpg""      ""name"": ""1. Why is decomposition technique required""      ""description"": ""Software project estimation is a form of problem solving. Developing a cost and effort estimate for a software project is too complex. All of the mentioned. None of the mentioned. Answer:c. Explanation:For these reasons  we decompose the problem  re-characterizing it as a set of smaller problems. 2. Cost and effort estimation of a software uses only one forms of decomposition  either decomposition of the problem or decomposition of the process. True. False. Answer:b. Explanation:Estimation uses one or both forms of partitioning. 3. If a Direct approach to software project sizing is taken  size can be measured in. LOC. FP. LOC and FP. Answer:a. Explanation:LOC or Line of Code is a direct measure to estiom ate project size.""      ""width"": ""1024"" }                         166                  4. Which software project sizing approach develop estimates of the information domain characteristics? Function point sizing Change sizing Standard component sizing Fuzzy logic sizing Answer:a Explanation:The answer is self explanatory. 5. The expected value for the estimation variable (size)  S  can be computed as a weighted average of the  optimistic(Sopt)  most likely (Sm)  and pessimistic (Spess) estimates given as EV = (Sopt + 4Sm + Spess)/4 EV = (Sopt + 4Sm + Spess)/6 EV = (Sopt + 2Sm + Spess)/6 EV = (Sopt + 2Sm + Spess)/4 Answer:b Explanation: This assumes that there is a very small probability that the actual size result will fall outside the optimistic  or pessimistic values. 6. How many forms exists of Barry Boehm’s COCOMO Model? Two Three Four No form exists Explanation: The three forms include the basic  intermediate and advanced COCOMO model.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/166/4.+Which+software+project+sizing+approach+develop+estimates+of+the+information+domain+characteristics.jpg""      ""name"": ""4. Which software project sizing approach develop estimates of the information domain characteristics""      ""description"": ""Function point sizing. Change sizing. Standard component sizing. Fuzzy logic sizing. Answer:a. Explanation:The answer is self explanatory. 5. The expected value for the estimation variable (size)  S  can be computed as a weighted average of the optimistic(Sopt)  most likely (Sm)  and pessimistic (Spess) estimates given as. EV = (Sopt + 4Sm + Spess)/4. EV = (Sopt + 4Sm + Spess)/6. EV = (Sopt + 2Sm + Spess)/6. EV = (Sopt + 2Sm + Spess)/4. Answer:b. Explanation: This assumes that there is a very small probability that the actual size result will fall outside the optimistic or pessimistic values. 6. How many forms exists of Barry Boehm’s COCOMO Model Two. Three. Four. No form exists. Explanation: The three forms include the basic  intermediate and advanced COCOMO model.""      ""width"": ""1024"" }                         167                  7. Who suggested the four different approaches to the sizing problem?Putnam Myers Boehm Putnam and Myers Answer:d Explanation:The answer is self explanatory. 8. In many cases  it is often more cost effective to acquire  rather than develop  computer software. True False Answer:a Explanation:Mangers are faced with a make-buy decision in such situations. 9. A make-buy decision is based on whether a) The software may be purchased off-the-shelf b) “Full-experience” or “Partial-experience” software components should be used Customer-built software should be developed All of the mentioned 10. Which of the following is not one of the five information domain characteristics of Function Point (FP) decomposition? External inputs External outputs External process External inquiries Answer:c Explanation: External inputs  external outputs  external inquiries  internal logical files  external interface files are the five domains.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/167/7.+Who+suggested+the+four+different+approaches+to+the+sizing+problem.jpg""      ""name"": ""7. Who suggested the four different approaches to the sizing problem""      ""description"": ""Putnam. Myers. Boehm. Putnam and Myers. Answer:d. Explanation:The answer is self explanatory. 8. In many cases  it is often more cost effective to acquire  rather than develop  computer software. True. False. Answer:a. Explanation:Mangers are faced with a make-buy decision in such situations. 9. A make-buy decision is based on whether. a) The software may be purchased off-the-shelf. b) Full-experience or Partial-experience software components should be used. Customer-built software should be developed. All of the mentioned. 10. Which of the following is not one of the five information domain characteristics of Function Point (FP) decomposition External inputs. External outputs. External process. External inquiries. Answer:c. Explanation: External inputs  external outputs  external inquiries  internal logical files  external interface files are the five domains.""      ""width"": ""1024"" }                         168                  11. The project planner must reconcile the estimates based on decomposition techniques to produce a single estimate of effort. True False Answer:b Explanation:The planner must determine the cause of divergence and then reconcile the estimates. 12. Programming language experience is a part of which factor of COCOMO cost drivers? Personnel Factor Product Factor Platform Factor Project Factor Answer:a Explanation:The answer is self explanatory. 13. If an Indirect approach is taken  then the sizing approach is represented as LOC FP Fuzzy Logic LOC and FP Explanation:A function point (FP) is a unit of measurement to express the amount of business functionality an  information system provides to a user.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/168/11.+The+project+planner+must+reconcile+the+estimates+based+on+decomposition+techniques+to+produce+a+single+estimate+of+effort..jpg""      ""name"": ""11. The project planner must reconcile the estimates based on decomposition techniques to produce a single estimate of effort.""      ""description"": ""True. False. Answer:b. Explanation:The planner must determine the cause of divergence and then reconcile the estimates. 12. Programming language experience is a part of which factor of COCOMO cost drivers Personnel Factor. Product Factor. Platform Factor. Project Factor. Answer:a. Explanation:The answer is self explanatory. 13. If an Indirect approach is taken  then the sizing approach is represented as. LOC. FP. Fuzzy Logic. LOC and FP. Explanation:A function point (FP) is a unit of measurement to express the amount of business functionality an information system provides to a user.""      ""width"": ""1024"" }                         169                  Test Case Design Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/169/Test+Case+Design+Source+%26+Courtsey%3A.jpg""      ""name"": ""Test Case Design Source &amp;amp; Courtsey:""      ""description"": ""Test Case Design Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         170                  1. What do you understand by V&V in software testing?Verified Version Version Validation Verification and Validation Version Verification Answer:c Explanation:V&V generally refers to any activity that attempts to ensure that the software will function as required. 2. In static test techniques  behavioral and performance properties of the program are observed. True False Answer:b Explanation:Static Analysis Techniques are based solely on the (manual or automated) examination of project  documentation of software models and code. 3. Which granularity level of testing checks the behavior of module cooperation? Unit Testing Integration Testing Acceptance Testing Regression Testing Explanation:Integration testing is the phase in software testing in which individual software modules are combined  and tested as a group.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/170/1.+What+do+you+understand+by+V%26V+in+software+testing.jpg""      ""name"": ""1. What do you understand by V&amp;amp;V in software testing""      ""description"": ""Verified Version. Version Validation. Verification and Validation. Version Verification. Answer:c. Explanation:V&amp;amp;V generally refers to any activity that attempts to ensure that the software will function as required. 2. In static test techniques  behavioral and performance properties of the program are observed. True. False. Answer:b. Explanation:Static Analysis Techniques are based solely on the (manual or automated) examination of project documentation of software models and code. 3. Which granularity level of testing checks the behavior of module cooperation Unit Testing. Integration Testing. Acceptance Testing. Regression Testing. Explanation:Integration testing is the phase in software testing in which individual software modules are combined and tested as a group.""      ""width"": ""1024"" }                         171                  4. Which test refers to the retesting of a unit  integration and system after modification  in order to ascertain that the change has not introduced new faults? Regression Test Smoke Test Alpha Test Beta Test Answer:a Explanation:Regression test seeks to uncover new software bugs in existing functional and non-functional areas of a  system after changes have been made to them. 5. Which of the following is a black box testing strategy? All Statements Coverage Control Structure Coverage Cause-Effect Graphs All Paths Coverage Answer:c Explanation:Rest are test strategies of white box testing. 6. A set of inputs  execution preconditions and expected outcomes is known as a Test plan Test case Test document Test Suite Answer:b Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/171/4.+Which+test+refers+to+the+retesting+of+a+unit%2C+integration+and+system+after+modification%2C+in+order+to+ascertain+that+the+change+has+not+introduced+new+faults.jpg""      ""name"": ""4. Which test refers to the retesting of a unit  integration and system after modification  in order to ascertain that the change has not introduced new faults""      ""description"": ""Regression Test. Smoke Test. Alpha Test. Beta Test. Answer:a. Explanation:Regression test seeks to uncover new software bugs in existing functional and non-functional areas of a system after changes have been made to them. 5. Which of the following is a black box testing strategy All Statements Coverage. Control Structure Coverage. Cause-Effect Graphs. All Paths Coverage. Answer:c. Explanation:Rest are test strategies of white box testing. 6. A set of inputs  execution preconditions and expected outcomes is known as a. Test plan. Test case. Test document. Test Suite. Answer:b. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         172                  7. In which test design each input is tested at both ends of its valid range and just outside its valid range? Boundary value testing Equivalence class partitioning Boundary value testing AND Equivalence class partitioning Decision tables Answer:a Explanation:Boundary value analysis is a software testing technique in which tests are designed to include  representatives of boundary values. 8. A white box test scales up well at different granularity levels of testing. True False Answer:b Explanation:A white box test is mostly applicable at unit and integration testing level. 9. When does the testing process stops? When resources (time and budget) are over When some coverage is reached When quality criterion is reached Testing never ends. Answer:c Explanation:As software testing is an exhaustive process  when the quality assurance is established and the  product is ready to be delivered  testing is stopped.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/172/7.+In+which+test+design+each+input+is+tested+at+both+ends+of+its+valid+range+and+just+outside+its+valid+range.jpg""      ""name"": ""7. In which test design each input is tested at both ends of its valid range and just outside its valid range""      ""description"": ""Boundary value testing. Equivalence class partitioning. Boundary value testing AND Equivalence class partitioning. Decision tables. Answer:a. Explanation:Boundary value analysis is a software testing technique in which tests are designed to include representatives of boundary values. 8. A white box test scales up well at different granularity levels of testing. True. False. Answer:b. Explanation:A white box test is mostly applicable at unit and integration testing level. 9. When does the testing process stops When resources (time and budget) are over. When some coverage is reached. When quality criterion is reached. Testing never ends. Answer:c. Explanation:As software testing is an exhaustive process  when the quality assurance is established and the product is ready to be delivered  testing is stopped.""      ""width"": ""1024"" }                         173                  10. Which of the following is not a part of a test design document?Test Plan Test Design Specification Test Case Specification Test Log Answer:d Explanation:Test log is a part of testing result document. 11. Specifying a set of test cases or test paths for each item to be tested at that level is known as Test case generation Test case design ALL of the mentioned None of the mentioned Answer:c Explanation:The answer is self explanatory. 12. Acceptance & system test planning are a part of architectural design. True False Answer:b Explanation:They are a part of requirements engineering  while integration & unit test planning come under architectural design. 13. PRD stands for Product Requirement Document Project Requirement Document Product Restrictions Document Answer:a Explanation:A product requirements document (PRD) is a document written by a company that defines a product they are making  or the  requirements for one or more new features for an existing product.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/173/10.+Which+of+the+following+is+not+a+part+of+a+test+design+document.jpg""      ""name"": ""10. Which of the following is not a part of a test design document""      ""description"": ""Test Plan. Test Design Specification. Test Case Specification. Test Log. Answer:d. Explanation:Test log is a part of testing result document. 11. Specifying a set of test cases or test paths for each item to be tested at that level is known as. Test case generation. Test case design. ALL of the mentioned. None of the mentioned. Answer:c. Explanation:The answer is self explanatory. 12. Acceptance &amp;amp; system test planning are a part of architectural design. True. False. Answer:b. Explanation:They are a part of requirements engineering  while integration &amp;amp; unit test planning come under architectural design. 13. PRD stands for. Product Requirement Document. Project Requirement Document. Product Restrictions Document. Answer:a. Explanation:A product requirements document (PRD) is a document written by a company that defines a product they are making  or the requirements for one or more new features for an existing product.""      ""width"": ""1024"" }                         174                  Software Design PatternSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/174/Software+Design+Pattern.jpg""      ""name"": ""Software Design Pattern""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         175                  1. Which mechanism is applied to use a design pattern in an OO system?Inheritance Composition All of the mentioned None of the mentioned Answer:c Explanation:Using inheritance  an existing design pattern becomes a template for a new subclass.Composition  is a concept that leads to aggregate objects. 2. Design patterns does not follow the concept of software reuse. True False Answer:b Explanation:Design patterns allow the designer to create the system architecture by integrating reusable components. 3. The use of design patterns for the development of object-oriented software has important implications for component-based software engineering reusability in general Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/175/1.+Which+mechanism+is+applied+to+use+a+design+pattern+in+an+OO+system.jpg""      ""name"": ""1. Which mechanism is applied to use a design pattern in an OO system""      ""description"": ""Inheritance. Composition. All of the mentioned. None of the mentioned. Answer:c. Explanation:Using inheritance  an existing design pattern becomes a template for a new subclass.Composition is a concept that leads to aggregate objects. 2. Design patterns does not follow the concept of software reuse. True. False. Answer:b. Explanation:Design patterns allow the designer to create the system architecture by integrating reusable components. 3. The use of design patterns for the development of object-oriented software has important implications for. component-based software engineering. reusability in general. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         176                  4. Which of the following is a design pattern?Behavioral Structural Abstract Factory All of the mentioned Answer:d Explanation:All the options are design patterns so option d. 5. You want to minimize development cost by reusing methods? Which design pattern would you choose? Adapter Pattern Singleton Pattern Delegation pattern Immutable Pattern Answer:c Explanation:The delegation pattern is a design pattern in OOP where an object  instead of performing one of its stated  tasks  delegates that task to an associated helper object. 6. You want to avoid multiple inheritance. Which design pattern would you choose? Abstraction-Occurrence Pattern Player-Role Pattern General Hierarchy Pattern Answer:b Explanation:The answer is self-explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/176/4.+Which+of+the+following+is+a+design+pattern.jpg""      ""name"": ""4. Which of the following is a design pattern""      ""description"": ""Behavioral. Structural. Abstract Factory. All of the mentioned. Answer:d. Explanation:All the options are design patterns so option d. 5. You want to minimize development cost by reusing methods Which design pattern would you choose Adapter Pattern. Singleton Pattern. Delegation pattern. Immutable Pattern. Answer:c. Explanation:The delegation pattern is a design pattern in OOP where an object  instead of performing one of its stated tasks  delegates that task to an associated helper object. 6. You want to avoid multiple inheritance. Which design pattern would you choose Abstraction-Occurrence Pattern. Player-Role Pattern. General Hierarchy Pattern. Answer:b. Explanation:The answer is self-explanatory.""      ""width"": ""1024"" }                         177                  7. The recurring aspects of designs are called designpatterns documents structures methods Answer:a Explanation:A pattern is the outline of a reusable solution to a general problem encountered in a particular context. 8. Design pattern is a solution to a problem that occurs repeatedly in a variety of contexts. True False Explanation:Each design pattern has a name and use of each pattern has consequences. 9. Which pattern prevents one from creating more than one instance of a variable? Factory Method Singleton Observer None of the mentioned Answer:b Explanation:In singleton pattern  the class itself is made responsible for keeping track of its instance.Thus it  ensures that no more than one instance is created.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/177/7.+The+recurring+aspects+of+designs+are+called+design.jpg""      ""name"": ""7. The recurring aspects of designs are called design""      ""description"": ""patterns. documents. structures. methods. Answer:a. Explanation:A pattern is the outline of a reusable solution to a general problem encountered in a particular context. 8. Design pattern is a solution to a problem that occurs repeatedly in a variety of contexts. True. False. Explanation:Each design pattern has a name and use of each pattern has consequences. 9. Which pattern prevents one from creating more than one instance of a variable Factory Method. Singleton. Observer. None of the mentioned. Answer:b. Explanation:In singleton pattern  the class itself is made responsible for keeping track of its instance.Thus it ensures that no more than one instance is created.""      ""width"": ""1024"" }                         178                  10. Facade pattern promotes weak coupling between subsystem and its clients.True False Answer:a Explanation:It is one of the patterns’s benefit.The facade pattern shields clients from subsystem classes and reduces the number of objects  that clients deal with. 11. Which design pattern defines one-to-many dependency among objects? Singleton pattern Facade Pattern Observer pattern Factory method pattern Answer:c Explanation:Observer pattern defines one-to-many dependency among objects so that when one object changes its state  all its dependents are notified. 12. Facade pattern couples a subsystem from its clients. Answer:b Explanation:A facade can be a single entry point to each subsystem level. It decouples the subsystem. 13. In factory method pattern  the framework must instantiate classes but it only knows about the abstract classes  which it cannot initiate. How  would one solve this problem? encapsulating the knowledge of which document subclass to is to be created and moving this knowledge out of the framework instantiating the application specific documents without knowing their class All of the mentioned Answer:d Explanation:Following all the options in order will solve the factory method problem.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/178/10.+Facade+pattern+promotes+weak+coupling+between+subsystem+and+its+clients..jpg""      ""name"": ""10. Facade pattern promotes weak coupling between subsystem and its clients.""      ""description"": ""True. False. Answer:a. Explanation:It is one of the patterns’s benefit.The facade pattern shields clients from subsystem classes and reduces the number of objects that clients deal with. 11. Which design pattern defines one-to-many dependency among objects Singleton pattern. Facade Pattern. Observer pattern. Factory method pattern. Answer:c. Explanation:Observer pattern defines one-to-many dependency among objects so that when one object changes its state  all its dependents are notified. 12. Facade pattern couples a subsystem from its clients. Answer:b. Explanation:A facade can be a single entry point to each subsystem level. It decouples the subsystem. 13. In factory method pattern  the framework must instantiate classes but it only knows about the abstract classes  which it cannot initiate. How would one solve this problem encapsulating the knowledge of which document subclass to is to be created and. moving this knowledge out of the framework. instantiating the application specific documents without knowing their class. All of the mentioned. Answer:d. Explanation:Following all the options in order will solve the factory method problem.""      ""width"": ""1024"" }                         179                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/179/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         180                  Software Monitoring Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/180/Software+Monitoring+Source+%26+Courtsey%3A.jpg""      ""name"": ""Software Monitoring Source &amp;amp; Courtsey:""      ""description"": ""Software Monitoring Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         181                  1. Why is software difficult to build ?Controlled changes Lack of reuseability Lack of monitoring All of the mentioned Answer:c Explanation:Monitoring is a key aspect which requires much attention for a succesful build. 2. Which of the following is not a conflict in software development team? Simultaneous updates Shared and common code Versions Graphics issues Answer:d Explanation:These are part of design  which can be handled by the design team. 3. Which of the following lasts for the duration of the project and covers the development process? Monitoring all key parameters like cost  schedule  risks Taking corrective actions when needed Providing information on the development process in terms of metrics Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/181/1.+Why+is+software+difficult+to+build.jpg""      ""name"": ""1. Why is software difficult to build""      ""description"": ""Controlled changes. Lack of reuseability. Lack of monitoring. All of the mentioned. Answer:c. Explanation:Monitoring is a key aspect which requires much attention for a succesful build. 2. Which of the following is not a conflict in software development team Simultaneous updates. Shared and common code. Versions. Graphics issues. Answer:d. Explanation:These are part of design  which can be handled by the design team. 3. Which of the following lasts for the duration of the project and covers the development process Monitoring all key parameters like cost  schedule  risks. Taking corrective actions when needed. Providing information on the development process in terms of metrics. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         182                  4. Which of the following is not a typical environment in communication facilitation ?Multiple teams Multiple user groups Multiple fests Multiple locations Answer:c Explanation:The answer is not related to the question. 5. Which of the following is a software process ? Analysis and design Configuration and management Business modeling All of the mentioned Answer:d Explanation:The answer is self explanatory. 6. Which of the following is not included in Issues Meetings? Issues gathered the day before Regular schedule of meeting Discussion with business Attendance Explanation:Discussion with business is planning in QA Meetings.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/182/4.+Which+of+the+following+is+not+a+typical+environment+in+communication+facilitation.jpg""      ""name"": ""4. Which of the following is not a typical environment in communication facilitation""      ""description"": ""Multiple teams. Multiple user groups. Multiple fests. Multiple locations. Answer:c. Explanation:The answer is not related to the question. 5. Which of the following is a software process Analysis and design. Configuration and management. Business modeling. All of the mentioned. Answer:d. Explanation:The answer is self explanatory. 6. Which of the following is not included in Issues Meetings Issues gathered the day before. Regular schedule of meeting. Discussion with business. Attendance. Explanation:Discussion with business is planning in QA Meetings.""      ""width"": ""1024"" }                         183                  7. Which of the following is not a part of Software Configuration Management Basics?Identification Version Auditing and Reviewing Status Accounting Answer:b Explanation:The answer is self explanatory. 8. What is a collection of software elements treated as a unit for the purposes of SCM? Software Configuration Item Baseline Configuration Configuration Control Board Answer:a Explanation:Software Configuration Item is a collection of software elements treated as a unit for the purposes of SCM. 9. What is one or more software configuration items that have been formally reviewed and agreed upon and serve as a  basis for further development? Software All of the above Explanation:Baseline – One or more software configuration items that have been formally reviewed and agreed upon  and serve as a basis for further development.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/183/7.+Which+of+the+following+is+not+a+part+of+Software+Configuration+Management+Basics.jpg""      ""name"": ""7. Which of the following is not a part of Software Configuration Management Basics""      ""description"": ""Identification. Version. Auditing and Reviewing. Status Accounting. Answer:b. Explanation:The answer is self explanatory. 8. What is a collection of software elements treated as a unit for the purposes of SCM Software Configuration Item. Baseline. Configuration. Configuration Control Board. Answer:a. Explanation:Software Configuration Item is a collection of software elements treated as a unit for the purposes of SCM. 9. What is one or more software configuration items that have been formally reviewed and agreed upon and serve as a basis for further development Software. All of the above. Explanation:Baseline – One or more software configuration items that have been formally reviewed and agreed upon and serve as a basis for further development.""      ""width"": ""1024"" }                         184                  10. What is validating the completeness of a product?Identification Software Auditing and Reviewing Status Accounting .Answer:c Explanation: Auditing and Reviewing is validating the completeness of a product and that SCM procedures are being followed 11. What is group with the responsibility for reviewing and approving changes to baselines? Software Configuration Item Baseline Configuration Configuration Control Board Answer:d Explanation:Configuration Control Board (CCB) is the group with the responsibility for reviewing and approving changes to baselines. 12. In many settings PM is a center of communication hub True False Answer:a Explanation:The answer is self explanatory. 13. What is a specific instance of a baseline or configuration item? Version Answer:c Explanation:Even the smallest development projects should utilize some sort of version and baseline control tool.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/184/10.+What+is+validating+the+completeness+of+a+product.jpg""      ""name"": ""10. What is validating the completeness of a product""      ""description"": ""Identification. Software. Auditing and Reviewing. Status Accounting. .Answer:c. Explanation: Auditing and Reviewing is validating the completeness of a product and that SCM procedures are being followed. 11. What is group with the responsibility for reviewing and approving changes to baselines Software Configuration Item. Baseline. Configuration. Configuration Control Board. Answer:d. Explanation:Configuration Control Board (CCB) is the group with the responsibility for reviewing and approving changes to baselines. 12. In many settings PM is a center of communication hub. True. False. Answer:a. Explanation:The answer is self explanatory. 13. What is a specific instance of a baseline or configuration item Version. Answer:c. Explanation:Even the smallest development projects should utilize some sort of version and baseline control tool.""      ""width"": ""1024"" }                         185                  Software Risks and IdentificationSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/185/Software+Risks+and+Identification.jpg""      ""name"": ""Software Risks and Identification""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         186                  1. What all has to be identified as per risk identification?Threats Vulnerabilities Consequences All of the mentioned Answer:d Explanation:Risk identification states what could cause a potential loss. 2. Which one is not a risk management activity? Risk assessment Risk generation Risk control None of the mentioned Answer:b Explanation:Risk management activities would never want a new risk to be generated. 3. What is the product of the probability of incurring a loss due to the risk and the potential magnitude of that loss? Risk exposure Risk prioritization Risk analysis Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/186/1.+What+all+has+to+be+identified+as+per+risk+identification.jpg""      ""name"": ""1. What all has to be identified as per risk identification""      ""description"": ""Threats. Vulnerabilities. Consequences. All of the mentioned. Answer:d. Explanation:Risk identification states what could cause a potential loss. 2. Which one is not a risk management activity Risk assessment. Risk generation. Risk control. None of the mentioned. Answer:b. Explanation:Risk management activities would never want a new risk to be generated. 3. What is the product of the probability of incurring a loss due to the risk and the potential magnitude of that loss Risk exposure. Risk prioritization. Risk analysis. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         187                  4. What threatens the quality and timeliness of the software to be produced?Known risks Business risks Project risks Technical risks Answer:d Explanation:Technical risks identify potential design  implementation  interface  verification  and maintenance problems. 5. What threatens the viability of the software to be built? Answer:b Explanation:Business risks often jeopardize the project or the product. 6. Which of the following is not a business risk? building an excellent product or system that no one really wants losing the support of senior management due to a change in focus or change in people lack of documented requirements or software scope losing budgetary or personnel commitment Answer:c Explanation:This is not considered as a business risk.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/187/4.+What+threatens+the+quality+and+timeliness+of+the+software+to+be+produced.jpg""      ""name"": ""4. What threatens the quality and timeliness of the software to be produced""      ""description"": ""Known risks. Business risks. Project risks. Technical risks. Answer:d. Explanation:Technical risks identify potential design  implementation  interface  verification  and maintenance problems. 5. What threatens the viability of the software to be built Answer:b. Explanation:Business risks often jeopardize the project or the product. 6. Which of the following is not a business risk building an excellent product or system that no one really wants. losing the support of senior management due to a change in focus or change in people. lack of documented requirements or software scope. losing budgetary or personnel commitment. Answer:c. Explanation:This is not considered as a business risk.""      ""width"": ""1024"" }                         188                  7. Which of the following is a systematic attempt to specify threats to the project plan?Risk identification Performance risk Support risk Risk projection Answer:d Explanation:By identifying known and predictable risks  the project manager takes a first  step toward avoiding them when possible and controlling them when necessary. 8. Which risks are associated with the overall size of the software to be built or modified? Business impact risks Process definition risks Product size risks Development environment risks Answer:c Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/188/7.+Which+of+the+following+is+a+systematic+attempt+to+specify+threats+to+the+project+plan.jpg""      ""name"": ""7. Which of the following is a systematic attempt to specify threats to the project plan""      ""description"": ""Risk identification. Performance risk. Support risk. Risk projection. Answer:d. Explanation:By identifying known and predictable risks  the project manager takes a first step toward avoiding them when possible and controlling them when necessary. 8. Which risks are associated with the overall size of the software to be built or modified Business impact risks. Process definition risks. Product size risks. Development environment risks. Answer:c. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         189                  9. Which risks are associated with constraints imposed by management or the marketplace?Business impact risks Process definition risks Product size risks Development environment risks Answer:a Explanation:The answer is self explanatory. 10. Which of the following term is best defined by the statement:”the degree of uncertainty  that the product will meet its requirements and be fit for its intended use.”? Performance risk Cost risk Support risk Schedule risk  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/189/9.+Which+risks+are+associated+with+constraints+imposed+by+management+or+the+marketplace.jpg""      ""name"": ""9. Which risks are associated with constraints imposed by management or the marketplace""      ""description"": ""Business impact risks. Process definition risks. Product size risks. Development environment risks. Answer:a. Explanation:The answer is self explanatory. 10. Which of the following term is best defined by the statement: the degree of uncertainty that the product will meet its requirements and be fit for its intended use. Performance risk. Cost risk. Support risk. Schedule risk.""      ""width"": ""1024"" }                         190                  Software Reuse Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/190/Software+Reuse+Source+%26+Courtsey%3A.jpg""      ""name"": ""Software Reuse Source &amp;amp; Courtsey:""      ""description"": ""Software Reuse Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         191                  1. Reuse-based software engineering is a software engineering strategy where the development process is geared to  reusing existing software. True False Answer:a Explanation:The answer is self explanatory. 2. The open source movement has meant that there is a huge reusable code base available at free of cost low cost high cost short period of time Answer:b Explanation:The open source movement has meant that there is a huge reusable code base available at low cost. This  may be in the form of program libraries or entire applications. 3. Consider the example and categorize it accordingly  “A pattern-matching system developed as part of a text-processing system may be reused in a database management system”. Application system reuse Component reuse Object and function reuse None of the mentioned Explanation:Components of an application  ranging in size from subsystems to single objects  may be reused.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/191/1.+Reuse-based+software+engineering+is+a+software+engineering+strategy+where+the+development+process+is+geared+to+reusing+existing+software..jpg""      ""name"": ""1. Reuse-based software engineering is a software engineering strategy where the development process is geared to reusing existing software.""      ""description"": ""True. False. Answer:a. Explanation:The answer is self explanatory. 2. The open source movement has meant that there is a huge reusable code base available at. free of cost. low cost. high cost. short period of time. Answer:b. Explanation:The open source movement has meant that there is a huge reusable code base available at low cost. This may be in the form of program libraries or entire applications. 3. Consider the example and categorize it accordingly  A pattern-matching system developed as part of a text-processing system may. be reused in a database management system . Application system reuse. Component reuse. Object and function reuse. None of the mentioned. Explanation:Components of an application  ranging in size from subsystems to single objects  may be reused.""      ""width"": ""1024"" }                         192                  4. COTS stands for Commercial Off-The-Shelf systems Commercial Off-The-Shelf states Commercial Off-The-System state None of the mentioned Answer:a Explanation:The answer is self explanatory. 5. COTS product reuse means Class and function libraries that implement commonly used abstractions are available for reuse. Shared components are woven into an application at different places when the program is compiled. Large-scale systems that encapsulate generic business functionality and rules are configured for an organization. Systems are developed by configuring and integrating existing application systems. Answer:d 6. .NET are specific to which platform? Java Mac-OS Microsoft LINUX Answer:c Explanation:NET Framework (pronounced dot net) is a software framework developed by Microsoft that runs primarily on  Microsoft Windows.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/192/4.+COTS+stands+for+Commercial+Off-The-Shelf+systems.+Commercial+Off-The-Shelf+states.+Commercial+Off-The-System+state..jpg""      ""name"": ""4. COTS stands for Commercial Off-The-Shelf systems. Commercial Off-The-Shelf states. Commercial Off-The-System state.""      ""description"": ""None of the mentioned. Answer:a. Explanation:The answer is self explanatory. 5. COTS product reuse means. Class and function libraries that implement commonly used abstractions are available for reuse. Shared components are woven into an application at different places when the program is compiled. Large-scale systems that encapsulate generic business functionality and rules are configured for an organization. Systems are developed by configuring and integrating existing application systems. Answer:d. 6. .NET are specific to which platform Java. Mac-OS. Microsoft. LINUX. Answer:c. Explanation:NET Framework (pronounced dot net) is a software framework developed by Microsoft that runs primarily on Microsoft Windows.""      ""width"": ""1024"" }                         193                  7. Which of the following is a generic structure that is extended to create a more specific subsystem or application? Software reuse Object-oriented programming language Framework None of the mentioned Answer:c Explanation:Frameworks are implemented as a collection of concrete and abstract object classes in an object-oriented  programming language. 8. “An ordering system may be adapted to cope with a centralized ordering process in one company and a distributed process in another.” Which category the example belong to? Process specialization Platform specialization Environment specialization Functional specialization Answer:a Explanation:In process specialization  the system is adapted to cope with specific business processes. 9. What are generic application systems that may be designed to support a particular business type  activity  or sometimes a  complete enterprise? COTS-solution systems COTS-integrated systems ERP systems Both COTS-solution and COTS-integrated systems Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/193/7.+Which+of+the+following+is+a+generic+structure+that+is+extended+to+create+a+more+specific+subsystem+or+application.jpg""      ""name"": ""7. Which of the following is a generic structure that is extended to create a more specific subsystem or application""      ""description"": ""Software reuse. Object-oriented programming language. Framework. None of the mentioned. Answer:c. Explanation:Frameworks are implemented as a collection of concrete and abstract object classes in an object-oriented programming language. 8. An ordering system may be adapted to cope with a centralized ordering process in one company and a distributed process in. another. Which category the example belong to Process specialization. Platform specialization. Environment specialization. Functional specialization. Answer:a. Explanation:In process specialization  the system is adapted to cope with specific business processes. 9. What are generic application systems that may be designed to support a particular business type  activity  or sometimes a complete enterprise COTS-solution systems. COTS-integrated systems. ERP systems. Both COTS-solution and COTS-integrated systems. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         194                  10. Which of the following is not an advantages of software reuse?lower costs faster software development high effectiveness lower risks Answer:c Explanation:Effectiveness depends on how one reuses the existing product. 11. ERP stands for Effective Reuse Planning Enterprise Resource Planning Effective Research Planning None of the mentioned Answer:b Explanation:Enterprise Resource Planning systems are examples of large-scale COTS reuse. 12. Which framework class include standards and classes that support component communication and information  exchange? System infrastructure frameworks Middleware integration frameworks Enterprise application frameworks MVC Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/194/10.+Which+of+the+following+is+not+an+advantages+of+software+reuse.jpg""      ""name"": ""10. Which of the following is not an advantages of software reuse""      ""description"": ""lower costs. faster software development. high effectiveness. lower risks. Answer:c. Explanation:Effectiveness depends on how one reuses the existing product. 11. ERP stands for. Effective Reuse Planning. Enterprise Resource Planning. Effective Research Planning. None of the mentioned. Answer:b. Explanation:Enterprise Resource Planning systems are examples of large-scale COTS reuse. 12. Which framework class include standards and classes that support component communication and information exchange System infrastructure frameworks. Middleware integration frameworks. Enterprise application frameworks. MVC. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         195                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/195/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         196                  Software Testing StrategiesSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/196/Software+Testing+Strategies.jpg""      ""name"": ""Software Testing Strategies""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         197                  1. Software Debugging is a set of activities that can be planned in advance and conducted systematically. True False Answer:b Explanation:Software Testing is a set of such activities. 2. Which of the following is not a software testing generic characteristics? Different testing techniques are appropriate at different points in time Testing is conducted by the developer of the software or an independent test group Testing and debugging are different activities  but debugging must be accommodated in any testing strategy None of the mentioned Answer:a Explanation:The answer is self explanatory. 3. ITG stands for instantaneous test group integration testing group individual testing group independent test group Answer:d Explanation:The role of an independent test group (ITG) is to remove the inherent problems associated with letting the builder test the thing that has been built.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/197/1.+Software+Debugging+is+a+set+of+activities+that+can+be+planned+in+advance+and+conducted+systematically..jpg""      ""name"": ""1. Software Debugging is a set of activities that can be planned in advance and conducted systematically.""      ""description"": ""True. False. Answer:b. Explanation:Software Testing is a set of such activities. 2. Which of the following is not a software testing generic characteristics Different testing techniques are appropriate at different points in time. Testing is conducted by the developer of the software or an independent test group. Testing and debugging are different activities  but debugging must be accommodated in any testing strategy. None of the mentioned. Answer:a. Explanation:The answer is self explanatory. 3. ITG stands for. instantaneous test group. integration testing group. individual testing group. independent test group. Answer:d. Explanation:The role of an independent test group (ITG) is to remove the inherent problems associated with letting the builder test the thing that has been built.""      ""width"": ""1024"" }                         198                  4. By collecting  	during software testing  it is possible to develop meaningful guidelines to halt the testing process. Failure intensity Testing time Metrics All of the mentioned Answer:c Explanation:It answers questions like: “When are we done with testing?”. 5. Which of the following issues must be addressed if a successful software testing strategy is to be implemented? a) Use effective formal technical reviews as a filter prior to testing b) Develop a testing plan that emphasizes “rapid cycle testing.” State testing objectives explicitly Answer:d Explanation:All the mentioned options are carried out for the purpose. 6. Test cases should uncover errors like Nonexistent loop termination Comparison of different data types Incorrect logical operators or precedence Answer:a Explanation:Test cases should uncover errors such as all the explained options and much more.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/198/4.+By+collecting+during+software+testing%2C+it+is+possible+to+develop+meaningful+guidelines+to+halt+the+testing+process..jpg""      ""name"": ""4. By collecting during software testing  it is possible to develop meaningful guidelines to halt the testing process.""      ""description"": ""Failure intensity. Testing time. Metrics. All of the mentioned. Answer:c. Explanation:It answers questions like: When are we done with testing . 5. Which of the following issues must be addressed if a successful software testing strategy is to be implemented a) Use effective formal technical reviews as a filter prior to testing. b) Develop a testing plan that emphasizes rapid cycle testing. State testing objectives explicitly. Answer:d. Explanation:All the mentioned options are carried out for the purpose. 6. Test cases should uncover errors like. Nonexistent loop termination. Comparison of different data types. Incorrect logical operators or precedence. Answer:a. Explanation:Test cases should uncover errors such as all the explained options and much more.""      ""width"": ""1024"" }                         199                  7. Which of the following errors should not be tested when error handling is evaluated?Error description is unintelligible Error noted does not correspond to error encountered Error condition causes system intervention prior to error handling d) Error description provide enough information to assist in the location of the cause of the error Answer:a Explanation:Actually  error description does not provide enough information to assist in the location of the cause of the error. 8. What is normally considered as an adjunct to the coding step Integration testing Unit testing Completion of Testing Regression Testing Answer:b Explanation:After source level code has been developed  reviewed  and verified for correspondence to component level  design  unit test case design begins. 9. Which of the following is not regression test case? A representative sample of tests that will exercise all software functions Additional tests that focus on software functions that are likely to be affected by the change Tests that focus on the software components that have been changed Low-level components are combined into clusters that perform a specific software sub-function Answer:d Explanation:Regression testing may be conducted manually  by re-executing a subset of all test cases or using automated  capture or playback tools  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/199/7.+Which+of+the+following+errors+should+not+be+tested+when+error+handling+is+evaluated.jpg""      ""name"": ""7. Which of the following errors should not be tested when error handling is evaluated""      ""description"": ""Error description is unintelligible. Error noted does not correspond to error encountered. Error condition causes system intervention prior to error handling. d) Error description provide enough information to assist in the location of the cause of the error. Answer:a. Explanation:Actually  error description does not provide enough information to assist in the location of the cause of the error. 8. What is normally considered as an adjunct to the coding step. Integration testing. Unit testing. Completion of Testing. Regression Testing. Answer:b. Explanation:After source level code has been developed  reviewed  and verified for correspondence to component level design  unit test case design begins. 9. Which of the following is not regression test case A representative sample of tests that will exercise all software functions. Additional tests that focus on software functions that are likely to be affected by the change. Tests that focus on the software components that have been changed. Low-level components are combined into clusters that perform a specific software sub-function. Answer:d. Explanation:Regression testing may be conducted manually  by re-executing a subset of all test cases or using automated capture or playback tools.""      ""width"": ""1024"" }                         200                  10. Which testing is an integration testing approach that is commonly used when “shrink-wrapped” software products are being developed? Regression Testing Integration testing Smoke testing Validation testing Answer:c Explanation:Smoke testing is designed as a pacing mechanism for time-critical projects  allowing the software team to  assess its project on a frequent basis. 11. In which testing level the focus is on customer usage? Alpha Testing Beta Testing Validation Testing Both Alpha and Beta Answer:d Explanation:Alpha testing is done at developer’s end while beta testing is done at user’s end. 12. Validation refers to the set of tasks that ensure that software correctly implements a specific function. True False Answer:b Explanation:Its verification  while validation refers to a different set of tasks that ensure that the software that has been  built is traceable to customer requirements.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/200/10.+Which+testing+is+an+integration+testing+approach+that+is+commonly+used+when+shrink-wrapped+software+products+are.jpg""      ""name"": ""10. Which testing is an integration testing approach that is commonly used when shrink-wrapped software products are""      ""description"": ""being developed Regression Testing. Integration testing. Smoke testing. Validation testing. Answer:c. Explanation:Smoke testing is designed as a pacing mechanism for time-critical projects  allowing the software team to assess its project on a frequent basis. 11. In which testing level the focus is on customer usage Alpha Testing. Beta Testing. Validation Testing. Both Alpha and Beta. Answer:d. Explanation:Alpha testing is done at developer’s end while beta testing is done at user’s end. 12. Validation refers to the set of tasks that ensure that software correctly implements a specific function. True. False. Answer:b. Explanation:Its verification  while validation refers to a different set of tasks that ensure that the software that has been built is traceable to customer requirements.""      ""width"": ""1024"" }                         201                  Size and Cost Estimation of SoftwareSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/201/Size+and+Cost+Estimation+of+Software.jpg""      ""name"": ""Size and Cost Estimation of Software""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         202                  1. Which of the following are parameters involved in computing the total cost of a software development project? Hardware and software costs Effort costs Travel and training costs All of the mentioned Answer:d Explanation:All these are accounted for in estimating a software’s development cost. 2. Which of the following costs is not part of the total effort cost? Costs of networking and communications Costs of providing heating and lighting office space Costs of lunch time food Costs of support staff Answer:c Explanation:This is a incurred by the employees. 3. What is related to the overall functionality of the delivered software? Function-related metrics Product-related metrics Size-related metrics None of the mentioned Answer:a Explanation:Productivity is expressed in terms of the amount of useful functionality produced in some given time.  Function points and object points are the best-known metrics of this type.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/202/1.+Which+of+the+following+are+parameters+involved+in+computing+the+total+cost+of+a+software+development+project.jpg""      ""name"": ""1. Which of the following are parameters involved in computing the total cost of a software development project""      ""description"": ""Hardware and software costs. Effort costs. Travel and training costs. All of the mentioned. Answer:d. Explanation:All these are accounted for in estimating a software’s development cost. 2. Which of the following costs is not part of the total effort cost Costs of networking and communications. Costs of providing heating and lighting office space. Costs of lunch time food. Costs of support staff. Answer:c. Explanation:This is a incurred by the employees. 3. What is related to the overall functionality of the delivered software Function-related metrics. Product-related metrics. Size-related metrics. None of the mentioned. Answer:a. Explanation:Productivity is expressed in terms of the amount of useful functionality produced in some given time. Function points and object points are the best-known metrics of this type.""      ""width"": ""1024"" }                         203                  4. A  	is developed using historical cost information that relates some software metric to the project cost. Algorithmic cost modelling Expert judgement Estimation by analogy d) Parkinson’s Law Answer:a Explanation:The model uses a basic regression formula with parameters that are derived from historical project data  and current as well as future project characteristics. 5. It is often difficult to estimate size at an early stage in a project when only a specification is available True False Explanation:Function-point and object-point estimates are easier to produce than estimates of code size but are often still inaccurate. 6. Which technique is applicable when other projects in the same analogy application domain have been completed? Answer:c Explanation:The cost of a new project is estimated by analogy with these completed projects.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/203/4.+A+is+developed+using+historical+cost+information+that+relates+some+software+metric+to+the+project+cost..jpg""      ""name"": ""4. A is developed using historical cost information that relates some software metric to the project cost.""      ""description"": ""Algorithmic cost modelling. Expert judgement. Estimation by analogy. d) Parkinson’s Law. Answer:a. Explanation:The model uses a basic regression formula with parameters that are derived from historical project data and current as well as future project characteristics. 5. It is often difficult to estimate size at an early stage in a project when only a specification is available. True. False. Explanation:Function-point and object-point estimates are easier to produce than estimates of code size but are often still inaccurate. 6. Which technique is applicable when other projects in the same analogy application domain have been completed Answer:c. Explanation:The cost of a new project is estimated by analogy with these completed projects.""      ""width"": ""1024"" }                         204                  7. Which model assumes that systems are created from reusable components  scripting or database programming? An application-composition model A post-architecture model A reuse model An early design model Answer:a Explanation:It is designed to make estimates of prototype development. 8. Which of the following states that work expands to fill the time available. CASE tools Pricing to win c) Parkinson’s Law d) Expert judgement Answer:c Explanation:The cost is determined by available resources rather than by objective assessment. If the software has to be  delivered in 12 months and 5 people are available  the effort required is estimated to be 60 person-months. 9. Which model is used during early stages of the system design after the requirements have been established? Answer:d Explanation:Estimates are based on function points  which are then converted to number of lines of source code. The  formula follows the standard form discussed above with a simplified set of seven multipliers.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/204/7.+Which+model+assumes+that+systems+are+created+from+reusable+components%2C+scripting+or+database+programming.jpg""      ""name"": ""7. Which model assumes that systems are created from reusable components  scripting or database programming""      ""description"": ""An application-composition model. A post-architecture model. A reuse model. An early design model. Answer:a. Explanation:It is designed to make estimates of prototype development. 8. Which of the following states that work expands to fill the time available. CASE tools. Pricing to win. c) Parkinson’s Law. d) Expert judgement. Answer:c. Explanation:The cost is determined by available resources rather than by objective assessment. If the software has to be delivered in 12 months and 5 people are available  the effort required is estimated to be 60 person-months. 9. Which model is used during early stages of the system design after the requirements have been established Answer:d. Explanation:Estimates are based on function points  which are then converted to number of lines of source code. The formula follows the standard form discussed above with a simplified set of seven multipliers.""      ""width"": ""1024"" }                         205                  10. Which model is used to compute the effort required to integrate reusable components or program code that is automatically generated by design or program translation tools? An application-composition model A post-architecture model A reuse model An early design model Answer:c Explanation:The answer is self explanatory. 11. The COCOMO model takes into account different approaches to software  development  reuse  etc. True False Answer:b Explanation:Its the COCOMO-2 model. COCOMO 2 incorporates a range of sub- models that produce increasingly detailed software estimates.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/205/10.+Which+model+is+used+to+compute+the+effort+required+to+integrate+reusable+components+or+program+code+that+is+automatically+generated+by+design+or+program+translation+tools.jpg""      ""name"": ""10. Which model is used to compute the effort required to integrate reusable components or program code that is automatically generated by design or program translation tools""      ""description"": ""An application-composition model. A post-architecture model. A reuse model. An early design model. Answer:c. Explanation:The answer is self explanatory. 11. The COCOMO model takes into account different approaches to software development  reuse  etc. True. False. Answer:b. Explanation:Its the COCOMO-2 model. COCOMO 2 incorporates a range of sub- models that produce increasingly detailed software estimates.""      ""width"": ""1024"" }                         206                  Project Scheduling and TrackingSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/206/Project+Scheduling+and+Tracking.jpg""      ""name"": ""Project Scheduling and Tracking""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         207                  1. Which of the following is the reason that software is delivered late?Changing customer requirements that are not reflected in schedule changes Technical difficulties that could not have been foreseen in advance Human difficulties that could not have been foreseen in advance All of the mentioned Answer:d Explanation:The answer is self explanatory. 2. Which of the following is an activity that distributes estimated effort across the planned project duration by  allocating the effort to specific software engineering tasks? Software Macroscopic schedule Software Project scheduling Software Detailed schedule None of the mentioned Answer:b 3. Every task that is scheduled should be assigned to a specific team member is termed as Compartmentalization Defined milestones Defined responsibilities Defined outcomes Answer:c Explanation:These responsibilities are domain specific.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/207/1.+Which+of+the+following+is+the+reason+that+software+is+delivered+late.jpg""      ""name"": ""1. Which of the following is the reason that software is delivered late""      ""description"": ""Changing customer requirements that are not reflected in schedule changes. Technical difficulties that could not have been foreseen in advance. Human difficulties that could not have been foreseen in advance. All of the mentioned. Answer:d. Explanation:The answer is self explanatory. 2. Which of the following is an activity that distributes estimated effort across the planned project duration by allocating the effort to specific software engineering tasks Software Macroscopic schedule. Software Project scheduling. Software Detailed schedule. None of the mentioned. Answer:b. 3. Every task that is scheduled should be assigned to a specific team member is termed as. Compartmentalization. Defined milestones. Defined responsibilities. Defined outcomes. Answer:c. Explanation:These responsibilities are domain specific.""      ""width"": ""1024"" }                         208                  4. What is a collection of software engineering work tasks  milestones  and deliverables that must be accomplished to complete a particular project? Task set Degree of milestone Adaptation criteria All of the mentioned Answer:a Explanation:The answer is self explanatory. 5. Ensuring that no more than the allocated number of people are allocated at any given time in Software Scheduling is known as Time Allocation Effort Validation Defined Milestone Effort Distribution Answer:b 6. What is used to determine the recommended degree of rigor with which the software process should be applied on a project? Degree of Rigor Task Set Both degree of Rigor and adaptation criteria Explanation:Four different degrees of rigor are: casual  structured  strict  and quick reaction.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/208/4.+What+is+a+collection+of+software+engineering+work+tasks%2C+milestones%2C+and+deliverables+that+must+be+accomplished+to+complete+a+particular+project.jpg""      ""name"": ""4. What is a collection of software engineering work tasks  milestones  and deliverables that must be accomplished to complete a particular project""      ""description"": ""Task set. Degree of milestone. Adaptation criteria. All of the mentioned. Answer:a. Explanation:The answer is self explanatory. 5. Ensuring that no more than the allocated number of people are allocated at any given time in Software Scheduling is known as. Time Allocation. Effort Validation. Defined Milestone. Effort Distribution. Answer:b. 6. What is used to determine the recommended degree of rigor with which the software process should be applied on a project Degree of Rigor. Task Set. Both degree of Rigor and adaptation criteria. Explanation:Four different degrees of rigor are: casual  structured  strict  and quick reaction.""      ""width"": ""1024"" }                         209                  7. What evaluates the risk associated with the technology to be implemented as part of project scope? Concept scoping Preliminary concept planning Technology risk assessment Customer reaction to the concept Answer:b Explanation:The answer is self explanatory. 8. Which of the following is not an adaptation criteria for software projects? Size of the project Customers Complaints Project staff Mission criticality Explanation:These can vary from client to client. 9. Which of the following is a project scheduling method that can be applied to software development? PERT CPM CMM both PERT and CPM Answer:d Explanation:Program evaluation and review technique (PERT) and critical path method (CPM) are two project  scheduling methods that can be applied to software development.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/209/7.+What+evaluates+the+risk+associated+with+the+technology+to+be+implemented+as+part+of+project+scope.jpg""      ""name"": ""7. What evaluates the risk associated with the technology to be implemented as part of project scope""      ""description"": ""Concept scoping. Preliminary concept planning. Technology risk assessment. Customer reaction to the concept. Answer:b. Explanation:The answer is self explanatory. 8. Which of the following is not an adaptation criteria for software projects Size of the project. Customers Complaints. Project staff. Mission criticality. Explanation:These can vary from client to client. 9. Which of the following is a project scheduling method that can be applied to software development PERT. CPM. CMM. both PERT and CPM. Answer:d. Explanation:Program evaluation and review technique (PERT) and critical path method (CPM) are two project scheduling methods that can be applied to software development.""      ""width"": ""1024"" }                         210                  10. A technique for performing quantitative analysis of progress is known asBCWS EVA BAC CBSE Answer:b Explanation:The earned value system provides a common value scale for every task  regardless of the type of work being performed. The total hours to do the whole project are estimated  and every task is given an earned value based on its estimated percentage of the total. What is the recommended distribution of effort for a project?  a) b) c) d) Answer:a Explanation:A recommended distribution of effort across the software process is 40% (analysis and design)  20% (coding)  and  40% (testing). A project usually has a timeline chart which was developed by Henry Gantt Barry Boehm Ivar Jacabson None of the mentioned Explanation:Timeline chart  also called a Gantt chart was invented by Henry Gantt  an industrial engineer in 1917.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/210/10.+A+technique+for+performing+quantitative+analysis+of+progress+is+known+as.jpg""      ""name"": ""10. A technique for performing quantitative analysis of progress is known as""      ""description"": ""BCWS. EVA. BAC. CBSE. Answer:b. Explanation:The earned value system provides a common value scale for every task  regardless of the type of work being performed. The total hours to do the whole project are estimated  and every task is given an earned value based on its estimated percentage of the total. What is the recommended distribution of effort for a project a) b) c) d) Answer:a. Explanation:A recommended distribution of effort across the software process is 40% (analysis and design)  20% (coding)  and 40% (testing). A project usually has a timeline chart which was developed by. Henry Gantt. Barry Boehm. Ivar Jacabson. None of the mentioned. Explanation:Timeline chart  also called a Gantt chart was invented by Henry Gantt  an industrial engineer in""      ""width"": ""1024"" }                         211                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/211/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         212                  Reverse Engineering Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/212/Reverse+Engineering+Source+%26+Courtsey%3A.jpg""      ""name"": ""Reverse Engineering Source &amp;amp; Courtsey:""      ""description"": ""Reverse Engineering Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         213                  1. In reverse engineering process  what refers to the sophistication of the design information that can be extracted from  the source code? interactivity completeness abstraction level direction level Answer:c Explanation:The answer is self explanatory. 2. In reverse engineering  what refers to the level of detail that is provided at an abstraction level? directionality Answer:b 3. The core of reverse engineering is an activity called restructure code extract abstractions Explanation:The engineer must evaluate the old program and extract a meaningful specification of the processing that is  performed  the user interface that is applied  and the program data structures or database that is used.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/213/1.+In+reverse+engineering+process%2C+what+refers+to+the+sophistication+of+the+design+information+that+can+be+extracted+from+the+source+code.jpg""      ""name"": ""1. In reverse engineering process  what refers to the sophistication of the design information that can be extracted from the source code""      ""description"": ""interactivity. completeness. abstraction level. direction level. Answer:c. Explanation:The answer is self explanatory. 2. In reverse engineering  what refers to the level of detail that is provided at an abstraction level directionality. Answer:b. 3. The core of reverse engineering is an activity called. restructure code. extract abstractions. Explanation:The engineer must evaluate the old program and extract a meaningful specification of the processing that is performed  the user interface that is applied  and the program data structures or database that is used.""      ""width"": ""1024"" }                         214                  4. What have become de rigueur for computer-based products and systems of every type?GUIs candidate keys object model All of the mentioned Answer:a Explanation:Therefore  the redevelopment of user interfaces has become one of the most common types of re-engineering  activity. But before a user interface can be rebuilt  reverse engineering should occur. 5. Forward engineering is also known as extract abstractions renovation reclamation both renovation and reclamation Answer:d Explanation:Forward engineering  also called renovation or reclamation   not only recovers design information from  existing software  but uses this information to alter or reconstitute the existing system in an effort to improve its overall  quality. 6. Reverse engineering is the process of deriving the system design and specification from its GUI Database Source code Answer:c Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/214/4.+What+have+become+de+rigueur+for+computer-based+products+and+systems+of+every+type.jpg""      ""name"": ""4. What have become de rigueur for computer-based products and systems of every type""      ""description"": ""GUIs. candidate keys. object model. All of the mentioned. Answer:a. Explanation:Therefore  the redevelopment of user interfaces has become one of the most common types of re-engineering activity. But before a user interface can be rebuilt  reverse engineering should occur. 5. Forward engineering is also known as. extract abstractions. renovation. reclamation. both renovation and reclamation. Answer:d. Explanation:Forward engineering  also called renovation or reclamation   not only recovers design information from existing software  but uses this information to alter or reconstitute the existing system in an effort to improve its overall quality. 6. Reverse engineering is the process of deriving the system design and specification from its. GUI. Database. Source code. Answer:c. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         215                  7. Reverse engineering techniques for internal program data focus on the definition of classes of objects. True False Answer:a Explanation:This is accomplished by examining the program code with the intent of grouping related program variables. 8. Which of the following steps may not be used to define the existing data model as a precursor to re-engineering a new  database model: Build an initial object model Determine candidate keys Refine the tentative classes Discover user interfaces Answer:d Explanation:Once information defined in the preceding steps is known  a series of transformations can be applied to  map the old database structure into a new database structure. 9. Much of the information necessary to create a behavioral model can be obtained by observing the external manifestation of the existing candidate keys interface database structure none of the above Answer:b Explanation:The GUI or the interface provides the base for the behavioral model.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/215/7.+Reverse+engineering+techniques+for+internal+program+data+focus+on+the+definition+of+classes+of+objects..jpg""      ""name"": ""7. Reverse engineering techniques for internal program data focus on the definition of classes of objects.""      ""description"": ""True. False. Answer:a. Explanation:This is accomplished by examining the program code with the intent of grouping related program variables. 8. Which of the following steps may not be used to define the existing data model as a precursor to re-engineering a new database model: Build an initial object model. Determine candidate keys. Refine the tentative classes. Discover user interfaces. Answer:d. Explanation:Once information defined in the preceding steps is known  a series of transformations can be applied to map the old database structure into a new database structure. 9. Much of the information necessary to create a behavioral model can be obtained by observing the external manifestation of the existing. candidate keys. interface. database structure. none of the above. Answer:b. Explanation:The GUI or the interface provides the base for the behavioral model.""      ""width"": ""1024"" }                         216                  10. Extracting data items and objects  to get information on data flow  and to understand the existing data structures that have been implemented is sometimes called data analysis directionality data extraction client applications Answer:a Explanation:The answer is self explanatory. 11. Reverse engineering and Re-engineering are equivalent processes of software engineering. True False Answer:b Explanation: Re engineering is a process of analysis and change whereby a system is modified by first reverse engineering and then  forward engineering. 12. Transformation of a system from one representational form to another is known as Re-factoring Restructuring Forward engineering Both a and b Answer:d 13. Which of the following is not an objective of reverse engineering? to reduce maintenance effort to cope with complexity to avoid side effects to assist migration to a CASE environment Explanation:Reverse engineering helps us to detect side effects rather than avoiding them.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/216/10.+Extracting+data+items+and+objects%2C+to+get+information+on+data+flow%2C+and+to+understand+the+existing+data+structures+that+have+been+implemented+is+sometimes+called.jpg""      ""name"": ""10. Extracting data items and objects  to get information on data flow  and to understand the existing data structures that have been implemented is sometimes called""      ""description"": ""data analysis. directionality. data extraction. client applications. Answer:a. Explanation:The answer is self explanatory. 11. Reverse engineering and Re-engineering are equivalent processes of software engineering. True. False. Answer:b. Explanation: Re engineering is a process of analysis and change whereby a system is modified by first reverse engineering and then forward engineering. 12. Transformation of a system from one representational form to another is known as. Re-factoring. Restructuring. Forward engineering. Both a and b. Answer:d. 13. Which of the following is not an objective of reverse engineering to reduce maintenance effort. to cope with complexity. to avoid side effects. to assist migration to a CASE environment. Explanation:Reverse engineering helps us to detect side effects rather than avoiding them.""      ""width"": ""1024"" }                         217                  Software Re-engineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/217/Software+Re-engineering.jpg""      ""name"": ""Software Re-engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         218                  Explanation:Except option a all other are module types.1. What are the problems with re-structuring? Loss of comments Loss of documentation Heavy computational demands All of the mentioned Answer:b Explanation:Restructuring doesn’t help with poor modularisation where related components are dispersed throughout the code. 2. Which of the following is not a module type? Object modules Hardware modules Functional modules Process support modules Answer:a Explanation:Except option a all other are module types. 3. Reverse engineering of data focuses on Internal data structures Database structures ALL of the mentioned None of the mentioned Answer:c Explanation: .  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/218/Explanation%3AExcept+option+a+all+other+are+module+types..jpg""      ""name"": ""Explanation:Except option a all other are module types.""      ""description"": ""1. What are the problems with re-structuring Loss of comments. Loss of documentation. Heavy computational demands. All of the mentioned. Answer:b. Explanation:Restructuring doesn’t help with poor modularisation where related components are dispersed throughout the code. 2. Which of the following is not a module type Object modules. Hardware modules. Functional modules. Process support modules. Answer:a. Explanation:Except option a all other are module types. 3. Reverse engineering of data focuses on. Internal data structures. Database structures. ALL of the mentioned. None of the mentioned. Answer:c Explanation: .""      ""width"": ""1024"" }                         219                  4. Forward engineering is not necessary if an existing software product is producing the correct output. True False Answer:b Explanation:Forward engineering refers to taking a high-level model and using it to build a more complex lower-level implementation. 5. Which of the following is not an example of a business process? designing a new product hiring an employee purchasing services testing software Answer:d Explanation:It is a part of development phase. 6. Which of the following is a data problem? hardware problem record organisation problems heavy computational demands loss of comments Explanation:Records representing the same entity may be organised differently in different programs.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/219/4.+Forward+engineering+is+not+necessary+if+an+existing+software+product+is+producing+the+correct+output..jpg""      ""name"": ""4. Forward engineering is not necessary if an existing software product is producing the correct output.""      ""description"": ""True. False. Answer:b. Explanation:Forward engineering refers to taking a high-level model and using it to build a more complex lower-level implementation. 5. Which of the following is not an example of a business process designing a new product. hiring an employee. purchasing services. testing software. Answer:d. Explanation:It is a part of development phase. 6. Which of the following is a data problem hardware problem. record organisation problems. heavy computational demands. loss of comments. Explanation:Records representing the same entity may be organised differently in different programs.""      ""width"": ""1024"" }                         220                  7. When does one decides to re-engineer a product?when tools to support restructuring are disabled when system crashes frequently when hardware or software support becomes obsolete subsystems of a larger system require few maintenance Answer:c Explanation:Re-engineering involves putting in the effort to make the system easier to maintain. 8. Which of the following is not a business goal of re-engineering ? Cost reduction Time reduction Maintainability None of the mentioned Answer:d Explanation:No such goal is mentioned which is not a business goal  so option d is correct here. 9. Which of these benefits can be achieved when software is restructured? Higher quality programs Reduced maintenance effort Software easier to test All of the mentioned Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/220/7.+When+does+one+decides+to+re-engineer+a+product.jpg""      ""name"": ""7. When does one decides to re-engineer a product""      ""description"": ""when tools to support restructuring are disabled. when system crashes frequently. when hardware or software support becomes obsolete. subsystems of a larger system require few maintenance. Answer:c. Explanation:Re-engineering involves putting in the effort to make the system easier to maintain. 8. Which of the following is not a business goal of re-engineering Cost reduction. Time reduction. Maintainability. None of the mentioned. Answer:d. Explanation:No such goal is mentioned which is not a business goal  so option d is correct here. 9. Which of these benefits can be achieved when software is restructured Higher quality programs. Reduced maintenance effort. Software easier to test. All of the mentioned. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         221                  10. Data re-engineering may be part of the process of migrating from a file-based system to a DBMS-based system or changing from one DBMS to another. True False Answer:a Explanation:Data re-engineering involves analyzing and reorganizing the data structures in a program. 11. BPR stands for Business process re-engineering Business product re-engineering Business process requirements Explanation:The answer is self explanatory. 12. Source code translation is a part of which re-engineering technique? Data re-engineering Re-factoring Restructuring None of the mentioned Answer:c Explanation:Restructuring involves automatic conversion from unstructured to structured code.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/221/10.+Data+re-engineering+may+be+part+of+the+process+of+migrating+from+a+file-based+system+to+a+DBMS-based+system+or+changing+from+one+DBMS+to+another..jpg""      ""name"": ""10. Data re-engineering may be part of the process of migrating from a file-based system to a DBMS-based system or changing from one DBMS to another.""      ""description"": ""True. False. Answer:a. Explanation:Data re-engineering involves analyzing and reorganizing the data structures in a program. 11. BPR stands for. Business process re-engineering. Business product re-engineering. Business process requirements. Explanation:The answer is self explanatory. 12. Source code translation is a part of which re-engineering technique Data re-engineering. Re-factoring. Restructuring. None of the mentioned. Answer:c. Explanation:Restructuring involves automatic conversion from unstructured to structured code.""      ""width"": ""1024"" }                         222                  Process Improvement Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/222/Process+Improvement+Source+%26+Courtsey%3A.jpg""      ""name"": ""Process Improvement Source &amp;amp; Courtsey:""      ""description"": ""Process Improvement Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         223                  1. “Robustness” answers which of the following description?CASE tools be used to support the process activities Process errors are avoided or trapped before they result in product errors Defined process is acceptable and usable by the engineers responsible for producing the software Process continues in spite of unexpected problems Answer:d Explanation:The answer is self explanatory. 2. Process improvement is the set of activities  methods  and transformations that developers use to develop  and maintain information systems. True False Answer:b Explanation:The definition is of a system development process. 3. “Understandability” answers which of the following description? The extent to which the process is explicitly defined Defined process is acceptable and usable by the engineers responsible for producing the software product Answer:a  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/223/1.+Robustness+answers+which+of+the+following+description.jpg""      ""name"": ""1. Robustness answers which of the following description""      ""description"": ""CASE tools be used to support the process activities. Process errors are avoided or trapped before they result in product errors. Defined process is acceptable and usable by the engineers responsible for producing the software. Process continues in spite of unexpected problems. Answer:d. Explanation:The answer is self explanatory. 2. Process improvement is the set of activities  methods  and transformations that developers use to develop and maintain information systems. True. False. Answer:b. Explanation:The definition is of a system development process. 3. Understandability answers which of the following description The extent to which the process is explicitly defined. Defined process is acceptable and usable by the engineers responsible for producing the software product. Answer:a.""      ""width"": ""1024"" }                         224                  4. How many stages are there in process improvement?three four five six Answer:a Explanation:Process measurement  analysis and change are the three stages. 5. In which stage of process improvement bottlenecks and weaknesses are identified? Process measurement Process analysis Process change None of the mentioned Answer:b Explanation:In Process analysis the current process is assessed and bottlenecks and weaknesses are identified. 6. Prototypes and 4GL business systems are categorized under which process? Informal Managed Methodical Supported Explanation:Here the development team chose their own way of working.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/224/4.+How+many+stages+are+there+in+process+improvement.jpg""      ""name"": ""4. How many stages are there in process improvement""      ""description"": ""three. four. five. six. Answer:a. Explanation:Process measurement  analysis and change are the three stages. 5. In which stage of process improvement bottlenecks and weaknesses are identified Process measurement. Process analysis. Process change. None of the mentioned. Answer:b. Explanation:In Process analysis the current process is assessed and bottlenecks and weaknesses are identified. 6. Prototypes and 4GL business systems are categorized under which process Informal. Managed. Methodical. Supported. Explanation:Here the development team chose their own way of working.""      ""width"": ""1024"" }                         225                  7. The documentation of a process which records the tasks  the roles and the entities used is calledProcess metric Process analysis Process modelling None of the mentioned Answer:c Explanation:Process models may be presented from different perspectives. 8. It is always best to start process analysis with a new test model. True False Answer:b Explanation:It is always best to start process analysis with an existing model. People then may extend and change this. 9. What is a tangible output of an activity that is predicted in a project plan? Deliverable Activity Condition Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/225/7.+The+documentation+of+a+process+which+records+the+tasks%2C+the+roles+and+the+entities+used+is+called.jpg""      ""name"": ""7. The documentation of a process which records the tasks  the roles and the entities used is called""      ""description"": ""Process metric. Process analysis. Process modelling. None of the mentioned. Answer:c. Explanation:Process models may be presented from different perspectives. 8. It is always best to start process analysis with a new test model. True. False. Answer:b. Explanation:It is always best to start process analysis with an existing model. People then may extend and change this. 9. What is a tangible output of an activity that is predicted in a project plan Deliverable. Activity. Condition. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         226                  10. What is often undefined and is left to the ingenuity of the project managers and engineers?Role Exception Activity Process Answer:b Explanation:Exceptions are often undefined and it is left to the ingenuity of the project managers and engineers to handle the exception. 11. Which of the following is not a part of process change? Introducing new practices  methods or processes Introducing new team members to existing project Introducing or removing deliverable Introducing new roles or responsibilities Explanation:Adding more developers aid to process completion rather than changing it. 12. The Capability Maturity Model (CMM) is a continuous model. True False Explanation:The CMM is discrete rather than continuous. 13. The CMMI assessment is based on a x-point scale. What is the value of x? 2 4 6 Answer:d Explanation:Not performed  performed  managed  defined  quantitatively managed  and optimizing are the six points.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/226/10.+What+is+often+undefined+and+is+left+to+the+ingenuity+of+the+project+managers+and+engineers.jpg""      ""name"": ""10. What is often undefined and is left to the ingenuity of the project managers and engineers""      ""description"": ""Role. Exception. Activity. Process. Answer:b. Explanation:Exceptions are often undefined and it is left to the ingenuity of the project managers and engineers to handle the exception. 11. Which of the following is not a part of process change Introducing new practices  methods or processes. Introducing new team members to existing project. Introducing or removing deliverable. Introducing new roles or responsibilities. Explanation:Adding more developers aid to process completion rather than changing it. 12. The Capability Maturity Model (CMM) is a continuous model. True. False. Explanation:The CMM is discrete rather than continuous. 13. The CMMI assessment is based on a x-point scale. What is the value of x Answer:d. Explanation:Not performed  performed  managed  defined  quantitatively managed  and optimizing are the six points.""      ""width"": ""1024"" }                         227                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/227/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         228                  Using CASE Tools Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/228/Using+CASE+Tools+Source+%26+Courtsey%3A.jpg""      ""name"": ""Using CASE Tools Source &amp;amp; Courtsey:""      ""description"": ""Using CASE Tools Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         229                  1. CASE stands for Cost Aided Software Engineering Computer Aided Software Engineering Control Aided Software Engineering None of the mentioned Answer:b Explanation:CASE tools purpose is to make the work of software development and maintenance easier and more reliable. 2. CASE tools are used only during the software testing phase. True False Explanation:CASE tools support the developer when performing one or more phases of the software life cycle  and/or support software maintenance. 3. Which of the following is not a type of CASE tool? Lower Classic Real Middle Answer:d Explanation:Lower and Upper CASE tools support analysis and design.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/229/1.+CASE+stands+for+Cost+Aided+Software+Engineering.+Computer+Aided+Software+Engineering.+Control+Aided+Software+Engineering..jpg""      ""name"": ""1. CASE stands for Cost Aided Software Engineering. Computer Aided Software Engineering. Control Aided Software Engineering.""      ""description"": ""None of the mentioned. Answer:b. Explanation:CASE tools purpose is to make the work of software development and maintenance easier and more reliable. 2. CASE tools are used only during the software testing phase. True. False. Explanation:CASE tools support the developer when performing one or more phases of the software life cycle and/or support software maintenance. 3. Which of the following is not a type of CASE tool Lower. Classic. Real. Middle. Answer:d. Explanation:Lower and Upper CASE tools support analysis and design.""      ""width"": ""1024"" }                         230                  4. What stores all changes and info related to the project from development through maintenance in CASE tools? Database Repository Registers None of the mentioned Answer:b Explanation:The main component of real CASE tools is the repository which stores all changes. 5. What kind of support is provided by the Repository Query CASE tool? Editing text and diagrams Display of parts of the design texts Cross referencing queries and requirements tracing Display of parts of the design texts AND Cross referencing queries and requirements tracing Answer:d Explanation:The answer is self explanatory. 6. What kind of support is provided by the Code Generation CASE tool? Transformation of design records into application software Compiling  interpreting or applying interactive debugging code Transformation of design records into application software AND Compiling  interpreting or applying interactive debugging code Explanation:Code Generation tool aids in transformation of design records into prototypes or application software  compatible with a given software development language.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/230/4.+What+stores+all+changes+and+info+related+to+the+project+from+development+through+maintenance+in+CASE+tools.jpg""      ""name"": ""4. What stores all changes and info related to the project from development through maintenance in CASE tools""      ""description"": ""Database. Repository. Registers. None of the mentioned. Answer:b. Explanation:The main component of real CASE tools is the repository which stores all changes. 5. What kind of support is provided by the Repository Query CASE tool Editing text and diagrams. Display of parts of the design texts. Cross referencing queries and requirements tracing. Display of parts of the design texts AND Cross referencing queries and requirements tracing. Answer:d. Explanation:The answer is self explanatory. 6. What kind of support is provided by the Code Generation CASE tool Transformation of design records into application software. Compiling  interpreting or applying interactive debugging code. Transformation of design records into application software AND Compiling  interpreting or applying interactive debugging code. Explanation:Code Generation tool aids in transformation of design records into prototypes or application software compatible with a given software development language.""      ""width"": ""1024"" }                         231                  7. Logical design errors can be resolved using both classic and real CASE tools.True False Answer:b Explanation:Classic CASE tools include interactive debuggers and compilers which do not serve the required purpose. 8. CASE-generated updated documentation enables easier and more reliable identification of software failure causes. Answer:a Explanation:The answer is self explanatory. 9. What kind of support is provided by the Code Editing CASE tool? Management of design documents and software code versions Transformation of design records into application software Compiling  interpreting or applying interactive debugging code None of the mentioned Answer:c Explanation:Code editing tool serves the purpose of compiling  interpreting or applying interactive debugging code specific coding  language or development tool. 10. Use of the repository assures automated coding and documentation of corrections. Explanation:Use of the repository assures consistency of new applications and improvements with existing software systems.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/231/7.+Logical+design+errors+can+be+resolved+using+both+classic+and+real+CASE+tools..jpg""      ""name"": ""7. Logical design errors can be resolved using both classic and real CASE tools.""      ""description"": ""True. False. Answer:b. Explanation:Classic CASE tools include interactive debuggers and compilers which do not serve the required purpose. 8. CASE-generated updated documentation enables easier and more reliable identification of software failure causes. Answer:a. Explanation:The answer is self explanatory. 9. What kind of support is provided by the Code Editing CASE tool Management of design documents and software code versions. Transformation of design records into application software. Compiling  interpreting or applying interactive debugging code. None of the mentioned. Answer:c. Explanation:Code editing tool serves the purpose of compiling  interpreting or applying interactive debugging code specific coding language or development tool. 10. Use of the repository assures automated coding and documentation of corrections. Explanation:Use of the repository assures consistency of new applications and improvements with existing software systems.""      ""width"": ""1024"" }                         232                  11. Which of the following is a drawback of using CASE tool?Standardization of notations and diagrams Communication between development team member Costs associated with the use of the tool Reduction of time and effort Answer:c Explanation:Using CASE tools is an expensive approach. 12. An upper CASE tool is also referred to as a back end CASE. True False Answer:b Explanation:An upper CASE tool (front end CASE) provides support for the early stages in the systems  development life cycle such as requirements analysis and design. 13. CASE tools are mainly used while developing which of the following methodologies? RAD JAD OO Approach All of the mentioned Answer:d Explanation:CASE tools are used in various stages of the Software Development Life Cycle.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/232/11.+Which+of+the+following+is+a+drawback+of+using+CASE+tool.jpg""      ""name"": ""11. Which of the following is a drawback of using CASE tool""      ""description"": ""Standardization of notations and diagrams. Communication between development team member. Costs associated with the use of the tool. Reduction of time and effort. Answer:c. Explanation:Using CASE tools is an expensive approach. 12. An upper CASE tool is also referred to as a back end CASE. True. False. Answer:b. Explanation:An upper CASE tool (front end CASE) provides support for the early stages in the systems development life cycle such as requirements analysis and design. 13. CASE tools are mainly used while developing which of the following methodologies RAD. JAD. OO Approach. All of the mentioned. Answer:d. Explanation:CASE tools are used in various stages of the Software Development Life Cycle.""      ""width"": ""1024"" }                         233                  Web Engineering Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/233/Web+Engineering+Source+%26+Courtsey%3A.jpg""      ""name"": ""Web Engineering Source &amp;amp; Courtsey:""      ""description"": ""Web Engineering Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         234                  1. Which web app attribute is defined by the statement:”A large number of users may access the WebApp at one time”? Unpredictable load Performance Concurrency Network intensiveness Answer:c Explanation:The answer is self explanatory. 2. Which web app attribute is defined by the statement:”The quality and aesthetic nature of content remains an important  determinant of the quality of a WebApp”? Availability Data driven Content sensitive Continuous evolution 3. If the user queries a collection of large databases and extracts information from the webapp  the webapp is categorized under Service oriented app Database access app Portal app Data warehousing app Answer:d Explanation:The Data Warehouse is a stable  read-only database that combines information from separate systems into  one  easy-to- access location.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/234/1.+Which+web+app+attribute+is+defined+by+the+statement%3A+A+large+number+of+users+may+access+the+WebApp+at+one+time.jpg""      ""name"": ""1. Which web app attribute is defined by the statement: A large number of users may access the WebApp at one time""      ""description"": ""Unpredictable load. Performance. Concurrency. Network intensiveness. Answer:c. Explanation:The answer is self explanatory. 2. Which web app attribute is defined by the statement: The quality and aesthetic nature of content remains an important determinant of the quality of a WebApp Availability. Data driven. Content sensitive. Continuous evolution. 3. If the user queries a collection of large databases and extracts information from the webapp  the webapp is categorized under. Service oriented app. Database access app. Portal app. Data warehousing app. Answer:d. Explanation:The Data Warehouse is a stable  read-only database that combines information from separate systems into one  easy-to- access location.""      ""width"": ""1024"" }                         235                  4. Which process model should be used in virtually all situations of web engineering?Incremental Model Waterfall Model Spiral Model None of the mentioned Answer:a Explanation:The web enginering proces must accommodate incremental delivery  frequent changes and short timeline. 5. Which analysis is a part of Analysis model of the web engineering process framework? Content Analysis Interaction Analysis Functional Analysis All of the mentioned Answer:d Explanation:Analysis model establishes a basis for design which requires all the mentioned options. 6. Web development and software development are one and the same thing. True False Answer:b Explanation:They are different due to the nature and distinct requirements of Web-based systems.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/235/4.+Which+process+model+should+be+used+in+virtually+all+situations+of+web+engineering.jpg""      ""name"": ""4. Which process model should be used in virtually all situations of web engineering""      ""description"": ""Incremental Model. Waterfall Model. Spiral Model. None of the mentioned. Answer:a. Explanation:The web enginering proces must accommodate incremental delivery  frequent changes and short timeline. 5. Which analysis is a part of Analysis model of the web engineering process framework Content Analysis. Interaction Analysis. Functional Analysis. All of the mentioned. Answer:d. Explanation:Analysis model establishes a basis for design which requires all the mentioned options. 6. Web development and software development are one and the same thing. True. False. Answer:b. Explanation:They are different due to the nature and distinct requirements of Web-based systems.""      ""width"": ""1024"" }                         236                  7. Web-based systems are often document-oriented containing static or dynamic content.True False Answer:a Explanation:In web-based systems  more emphasis is on “look and feel” of the product. 8. Web-based systems apply the same levels of formal planning and testing used in software development. Answer:b Explanation:Web-based systems are typically constrained to a short development time making it difficult to apply the same levels of formal  planning and testing used in software development. 9. Which of the following statements are incorrect with reference to web-based systems? Web-based systems should be unscalable must be able to cope with uncertain  random heavy demands on services must be secure are subject to assorted legal  social  and ethical scrutiny Explanation:Web-based systems should be scalable. 10. What category of web-based system would you assign to electronic shopping? Informational Interactive Transaction-oriented Workflow-oriented Answer:c Explanation:It involves usage of transaction management of database systems.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/236/7.+Web-based+systems+are+often+document-oriented+containing+static+or+dynamic+content..jpg""      ""name"": ""7. Web-based systems are often document-oriented containing static or dynamic content.""      ""description"": ""True. False. Answer:a. Explanation:In web-based systems  more emphasis is on look and feel of the product. 8. Web-based systems apply the same levels of formal planning and testing used in software development. Answer:b. Explanation:Web-based systems are typically constrained to a short development time making it difficult to apply the same levels of formal planning and testing used in software development. 9. Which of the following statements are incorrect with reference to web-based systems Web-based systems. should be unscalable. must be able to cope with uncertain  random heavy demands on services. must be secure. are subject to assorted legal  social  and ethical scrutiny. Explanation:Web-based systems should be scalable. 10. What category of web-based system would you assign to electronic shopping Informational. Interactive. Transaction-oriented. Workflow-oriented. Answer:c. Explanation:It involves usage of transaction management of database systems.""      ""width"": ""1024"" }                         237                  11. What category of web-based system would you assign to discussion groups?Collaborative work Online communities Web portals Workflow-oriented Answer:b Explanation:The answer is self explanatory. 12. W3C stands for World Wide Web Consortium World Wide Web Collaboration World Wide Web Community None of the mentioned Answer:a Explanation:W3C is an international consortium where member organizations  a full-time staff  and the public work  together to develop web standards. 13. Which of the following is a risk associated with using hypertext in web applications? loss of sense of locality and direction cognitive overload for users All of the mentioned Answer:c Explanation:Hypertexts and links may divert the users attention from the main content.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/237/11.+What+category+of+web-based+system+would+you+assign+to+discussion+groups.jpg""      ""name"": ""11. What category of web-based system would you assign to discussion groups""      ""description"": ""Collaborative work. Online communities. Web portals. Workflow-oriented. Answer:b. Explanation:The answer is self explanatory. 12. W3C stands for. World Wide Web Consortium. World Wide Web Collaboration. World Wide Web Community. None of the mentioned. Answer:a. Explanation:W3C is an international consortium where member organizations  a full-time staff  and the public work together to develop web standards. 13. Which of the following is a risk associated with using hypertext in web applications loss of sense of locality and direction. cognitive overload for users. All of the mentioned. Answer:c. Explanation:Hypertexts and links may divert the users attention from the main content.""      ""width"": ""1024"" }                         238                  Quality Management Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/238/Quality+Management+Source+%26+Courtsey%3A.jpg""      ""name"": ""Quality Management Source &amp;amp; Courtsey:""      ""description"": ""Quality Management Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         239                  1. Quality Management in software engineering is also known asSQA SQM SQI SQA and SQM Answer:a Explanation:Quality Management is also called software quality assurance (SQA) which serves as an umbrella activity  that is applied throughout the software process. 2. Quality also can be looked at in terms of user satisfaction which includes A compliant product Good quality output Delivery within budget and schedule All of the mentioned Answer:d Explanation:This focuses on how well the implementation follows the design and how well the resulting system meets its requirements. 3. Inspections and testing are what kinds of Quality Costs? Prevention Internal Failure External Failure Appraisal Explanation:Inspections  equipment calibration  maintenance and testing appraisal costs is quality management.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/239/1.+Quality+Management+in+software+engineering+is+also+known+as.jpg""      ""name"": ""1. Quality Management in software engineering is also known as""      ""description"": ""SQA. SQM. SQI. SQA and SQM. Answer:a. Explanation:Quality Management is also called software quality assurance (SQA) which serves as an umbrella activity that is applied throughout the software process. 2. Quality also can be looked at in terms of user satisfaction which includes. A compliant product. Good quality output. Delivery within budget and schedule. All of the mentioned. Answer:d. Explanation:This focuses on how well the implementation follows the design and how well the resulting system meets its requirements. 3. Inspections and testing are what kinds of Quality Costs Prevention. Internal Failure. External Failure. Appraisal. Explanation:Inspections  equipment calibration  maintenance and testing appraisal costs is quality management.""      ""width"": ""1024"" }                         240                  4. According to Pareto’s principle  x% of defects can be traced to y% of all causes. What are the values of x and y? a) 60  40 b) 70  30 c) 80  20 d) No such principle exists Answer:c Explanation:The Pareto principle (also known as the 80–20 rule) states that  for many events  roughly 80% of the effects come  from 20% of the causes. 5. What is Six Sigma? a) It is the most widely used strategy for statistical quality assurance The “Six Sigma” refers to six standard deviations It is the most widely used strategy for statistical quality assurance AND The “Six Sigma” refers to six standard deviations d) A Formal Technical Review(FTR) guideline for quality walkthrough or inspection Explanation:The Six Sigma uses data and statistical analysis to measure and improve a company’s operational performance. 6. Which of the following is not a core step of Six Sigma? Define Control Measure Analyse Answer:b Explanation:It is an additional step added for existing processes and can be done in parallel.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/240/4.+According+to+Pareto%E2%80%99s+principle%2C+x%25+of+defects+can+be+traced+to+y%25+of+all+causes.+What+are+the+values+of+x+and+y+a%29+60%2C+40.jpg""      ""name"": ""4. According to Pareto’s principle  x% of defects can be traced to y% of all causes. What are the values of x and y a) 60  40""      ""description"": ""b) 70  30. c) 80  20. d) No such principle exists. Answer:c. Explanation:The Pareto principle (also known as the 80–20 rule) states that  for many events  roughly 80% of the effects come from 20% of the causes. 5. What is Six Sigma a) It is the most widely used strategy for statistical quality assurance. The Six Sigma refers to six standard deviations. It is the most widely used strategy for statistical quality assurance AND The Six Sigma refers to six standard deviations. d) A Formal Technical Review(FTR) guideline for quality walkthrough or inspection. Explanation:The Six Sigma uses data and statistical analysis to measure and improve a company’s operational performance. 6. Which of the following is not a core step of Six Sigma Define. Control. Measure. Analyse. Answer:b. Explanation:It is an additional step added for existing processes and can be done in parallel.""      ""width"": ""1024"" }                         241                  7. Non-conformance to software requirements is known asSoftware availability Software reliability Software failure None of the mentioned Answer:c Explanation:Given a set of valid requirements  all software failures can be traced to design or implementation problems. 8. Software safety is equivalent to software reliability. True False Answer:b Explanation:Software reliability uses statistical analysis to determine the likelihood that a software failure will occur; however  the failure  may not necessarily result in a hazard or mishap. 9. Misinterpretation of customer communication is a sample of possible cause defects. Answer:a Explanation:Translation gap between the client and the developer often leads to software defects. 10. What kind of quality cost is incurred when an error is detected in a product prior to shipment? Prevention Internal Failure External Failure Appraisal Explanation:This includes rework  repair  and failure mode analysis.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/241/7.+Non-conformance+to+software+requirements+is+known+as.jpg""      ""name"": ""7. Non-conformance to software requirements is known as""      ""description"": ""Software availability. Software reliability. Software failure. None of the mentioned. Answer:c. Explanation:Given a set of valid requirements  all software failures can be traced to design or implementation problems. 8. Software safety is equivalent to software reliability. True. False. Answer:b. Explanation:Software reliability uses statistical analysis to determine the likelihood that a software failure will occur; however  the failure may not necessarily result in a hazard or mishap. 9. Misinterpretation of customer communication is a sample of possible cause defects. Answer:a. Explanation:Translation gap between the client and the developer often leads to software defects. 10. What kind of quality cost is incurred when an error is detected in a product prior to shipment Prevention. Internal Failure. External Failure. Appraisal. Explanation:This includes rework  repair  and failure mode analysis.""      ""width"": ""1024"" }                         242                  11. The degree to which the design specifications are followed during manufacturing is known asQuality of design Quality of conformance Quality of testing None of the mentioned Answer:b Explanation:This focuses on how well the implementation follows the design and how well the resulting system meets its requirements. 12. Quality of design encompasses requirements and specifications of the system. True False Answer:a Explanation:The characteristic that designers specify for an item are cover in quality of design. 13. According to ISO 9001  inspection and testing comes under which management responsibility? Process control Document control Control of non-conforming products Servicing Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/242/11.+The+degree+to+which+the+design+specifications+are+followed+during+manufacturing+is+known+as.jpg""      ""name"": ""11. The degree to which the design specifications are followed during manufacturing is known as""      ""description"": ""Quality of design. Quality of conformance. Quality of testing. None of the mentioned. Answer:b. Explanation:This focuses on how well the implementation follows the design and how well the resulting system meets its requirements. 12. Quality of design encompasses requirements and specifications of the system. True. False. Answer:a. Explanation:The characteristic that designers specify for an item are cover in quality of design. 13. According to ISO 9001  inspection and testing comes under which management responsibility Process control. Document control. Control of non-conforming products. Servicing. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         243                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/243/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         244                  Building Blocks of UML Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/244/Building+Blocks+of+UML+Source+%26+Courtsey%3A.jpg""      ""name"": ""Building Blocks of UML Source &amp;amp; Courtsey:""      ""description"": ""Building Blocks of UML Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         245                  1. Which of the following is a building block of UML?Things Relationships Diagrams All of the mentioned Answer:d Explanation:All are the building blocks of UML which are further sub-categorized. 2. Classes and interfaces are a part of Structural things Behavioral things Grouping things Annotational things Answer:a Explanation:Structural things are mostly static parts of a model  representing elements that are either conceptual or  physical. 3.What is a collection of operations that specify a service of a class or component? Use Case Actor Interface Relationship Answer:c Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/245/1.+Which+of+the+following+is+a+building+block+of+UML.jpg""      ""name"": ""1. Which of the following is a building block of UML""      ""description"": ""Things. Relationships. Diagrams. All of the mentioned. Answer:d. Explanation:All are the building blocks of UML which are further sub-categorized. 2. Classes and interfaces are a part of. Structural things. Behavioral things. Grouping things. Annotational things. Answer:a. Explanation:Structural things are mostly static parts of a model  representing elements that are either conceptual or physical. 3.What is a collection of operations that specify a service of a class or component Use Case. Actor. Interface. Relationship. Answer:c. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         246                  4. What is a physical element that exists at run time in UML?A node An interface An activity None of the mentioned Answer:a Explanation:A node represents a computational resource. 5. What can be requested from any object of the class to affect behavior? object attribute operation instance Answer:c Explanation:An operation is the implementation of a service that can be requested from any object of the class to affect behavior. 6. Which things are dynamic parts of UML models? Structural things Behavioral things Grouping things Annotational things Answer:b Explanation:These are the verbs of a model  representing behavior over time and space.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/246/4.+What+is+a+physical+element+that+exists+at+run+time+in+UML.jpg""      ""name"": ""4. What is a physical element that exists at run time in UML""      ""description"": ""A node. An interface. An activity. None of the mentioned. Answer:a. Explanation:A node represents a computational resource. 5. What can be requested from any object of the class to affect behavior object. attribute. operation. instance. Answer:c. Explanation:An operation is the implementation of a service that can be requested from any object of the class to affect behavior. 6. Which things are dynamic parts of UML models Structural things. Behavioral things. Grouping things. Annotational things. Answer:b. Explanation:These are the verbs of a model  representing behavior over time and space.""      ""width"": ""1024"" }                         247                  7. Which diagram in UML emphasizes the time-ordering of messages?Activity Sequence Collaboration Class Answer:b Explanation:This diagram is a model describing how groups of objects collaborate in some behavior over time. 8. Object diagram captures the behavior of a single use case. True False Explanation:Sequence Diagram is responsible for this. 9. If you are working on real-time process control applications or systems that involve concurrent processing  you would use a Activity diagram Sequence diagram Statechart diagram Object diagram Answer:c Explanation:A statechart diagram shows a state machine  consisting of states  transitions  events  and activities.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/247/7.+Which+diagram+in+UML+emphasizes+the+time-ordering+of+messages.jpg""      ""name"": ""7. Which diagram in UML emphasizes the time-ordering of messages""      ""description"": ""Activity. Sequence. Collaboration. Class. Answer:b. Explanation:This diagram is a model describing how groups of objects collaborate in some behavior over time. 8. Object diagram captures the behavior of a single use case. True. False. Explanation:Sequence Diagram is responsible for this. 9. If you are working on real-time process control applications or systems that involve concurrent processing  you would use a. Activity diagram. Sequence diagram. Statechart diagram. Object diagram. Answer:c. Explanation:A statechart diagram shows a state machine  consisting of states  transitions  events  and activities.""      ""width"": ""1024"" }                         248                  10. Which diagram shows the configuration of run-time processing elements?Deployment diagram Component diagram Node diagram ER-diagram Answer:a Explanation:A Deployment diagram shows the configuration of run-time processing elements and the software components   processes  and objects. 11. Which things in UML are the explanatory parts of UML models? Structural things Behavioral things Grouping things Annotational things Answer:d Explanation:It include a note which is simply a symbol for rendering constraints and comments attached to an element or a  collection of elements. 12. Which of the following term is best defined by the statement:”a structural relationship that specifies that objects of one thing are connected to objects of another”? Association Aggregation Realization Generalization Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/248/10.+Which+diagram+shows+the+configuration+of+run-time+processing+elements.jpg""      ""name"": ""10. Which diagram shows the configuration of run-time processing elements""      ""description"": ""Deployment diagram. Component diagram. Node diagram. ER-diagram. Answer:a. Explanation:A Deployment diagram shows the configuration of run-time processing elements and the software components  processes  and objects. 11. Which things in UML are the explanatory parts of UML models Structural things. Behavioral things. Grouping things. Annotational things. Answer:d. Explanation:It include a note which is simply a symbol for rendering constraints and comments attached to an element or a collection of elements. 12. Which of the following term is best defined by the statement: a structural relationship that specifies that objects of one thing are. connected to objects of another Association. Aggregation. Realization. Generalization. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         249                  13. What refers to the value associated with a specific attribute of an object and to any actions or side? Object State Interface None of the mentioned Answer:b Explanation:In a state chart diagram  effects occur when the attribute’s value changes.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/249/13.+What+refers+to+the+value+associated+with+a+specific+attribute+of+an+object+and+to+any+actions+or+side.jpg""      ""name"": ""13. What refers to the value associated with a specific attribute of an object and to any actions or side""      ""description"": ""Object. State. Interface. None of the mentioned. Answer:b. Explanation:In a state chart diagram  effects occur when the attribute’s value changes.""      ""width"": ""1024"" }                         250                  Managing Software Projects – 1Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/250/Managing+Software+Projects+%E2%80%93+1.jpg""      ""name"": ""Managing Software Projects – 1""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         251                  1. Project management involves the planning  monitoring  and control of the people  process  and events that occur as  software evolves from a preliminary concept to an operational implementation. True False Answer:a Explanation:The answer is self explanatory. 2. Which of the following is not an effective software project management focus? people product popularity process Answer:c Explanation:Effective software project management focuses on the four P’s: people  product  process  and project. 3. PM-CMM stands for people management capability maturity model process management capability maturity model product management capability maturity model project management capability maturity model Explanation:The people management maturity model defines the following key practice areas for software people:  recruiting  selection  performance management  training  compensation  career development  organization and work  design  and team/culture development.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/251/1.+Project+management+involves+the+planning%2C+monitoring%2C+and+control+of+the+people%2C+process%2C+and+events+that+occur+as+software+evolves+from+a+preliminary+concept+to+an+operational+implementation..jpg""      ""name"": ""1. Project management involves the planning  monitoring  and control of the people  process  and events that occur as software evolves from a preliminary concept to an operational implementation.""      ""description"": ""True. False. Answer:a. Explanation:The answer is self explanatory. 2. Which of the following is not an effective software project management focus people. product. popularity. process. Answer:c. Explanation:Effective software project management focuses on the four P’s: people  product  process  and project. 3. PM-CMM stands for. people management capability maturity model. process management capability maturity model. product management capability maturity model. project management capability maturity model. Explanation:The people management maturity model defines the following key practice areas for software people: recruiting  selection  performance management  training  compensation  career development  organization and work design  and team/culture development.""      ""width"": ""1024"" }                         252                  4. Which of the following is not a project manager’s activity?project control project management project planning project design Answer:d Explanation:The design part of any project management is done by the project team. 5. A software  	provides the framework from which a comprehensive plan for software development can be established. people product process Answer:c Explanation:A small number of framework activities are applicable to all software projects  regardless of their size or complexity. 6. Who defines the business issues that often have significant influence on the project? Practitioners Project managers Senior managers Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/252/4.+Which+of+the+following+is+not+a+project+manager%E2%80%99s+activity.jpg""      ""name"": ""4. Which of the following is not a project manager’s activity""      ""description"": ""project control. project management. project planning. project design. Answer:d. Explanation:The design part of any project management is done by the project team. 5. A software provides the framework from which a comprehensive plan for software development can be established. people. product. process. Answer:c. Explanation:A small number of framework activities are applicable to all software projects  regardless of their size or complexity. 6. Who defines the business issues that often have significant influence on the project Practitioners. Project managers. Senior managers. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         253                  7. Who delivers the technical skills that are necessary to engineer a product or an application?Practitioners Project managers Senior managers None of the mentioned Answer:a Explanation:None. 8. Which of the following paradigm attempts to structure a team in a manner that achieves some of the controls associated with the closed paradigm but also much of the innovation that occurs when using the random paradigm? asynchronous paradigm open paradigm closed paradigm synchronous paradigm Answer:b Explanation:Open paradigm team structures are well suited to the solution of complex problems but may not perform as  efficiently as other teams. 9. Which of the following is a people-intensive activity? Problem solving Organization Motivation Project management Answer:d Explanation:For this reason  competent practitioners often make poor team leaders.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/253/7.+Who+delivers+the+technical+skills+that+are+necessary+to+engineer+a+product+or+an+application.jpg""      ""name"": ""7. Who delivers the technical skills that are necessary to engineer a product or an application""      ""description"": ""Practitioners. Project managers. Senior managers. None of the mentioned. Answer:a Explanation:None. 8. Which of the following paradigm attempts to structure a team in a manner that achieves some of the controls associated with the closed paradigm but also much of the innovation that occurs when using the random paradigm asynchronous paradigm. open paradigm. closed paradigm. synchronous paradigm. Answer:b. Explanation:Open paradigm team structures are well suited to the solution of complex problems but may not perform as efficiently as other teams. 9. Which of the following is a people-intensive activity Problem solving. Organization. Motivation. Project management. Answer:d. Explanation:For this reason  competent practitioners often make poor team leaders.""      ""width"": ""1024"" }                         254                  10. Which paradigm structures a team loosely and depends on individual initiative of the team members? random paradigm open paradigm closed paradigm synchronous paradigm Answer:d Explanation:The answer is self explanatory. 11. Which of the following is not an approach to software cost estimation? Empirical Heuristic Analytical Critical Explanation:Critical is no such standard approach of cost estimation.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/254/10.+Which+paradigm+structures+a+team+loosely+and+depends+on+individual+initiative+of+the+team+members.jpg""      ""name"": ""10. Which paradigm structures a team loosely and depends on individual initiative of the team members""      ""description"": ""random paradigm. open paradigm. closed paradigm. synchronous paradigm. Answer:d. Explanation:The answer is self explanatory. 11. Which of the following is not an approach to software cost estimation Empirical. Heuristic. Analytical. Critical. Explanation:Critical is no such standard approach of cost estimation.""      ""width"": ""1024"" }                         255                  Software Reliability ModelsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/255/Software+Reliability+Models.jpg""      ""name"": ""Software Reliability Models""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         256                  1. Which one is not a software quality model?ISO 9000 McCall model Boehm model ISO 9126 Answer:a Explanation:ISO 9000 is software certification. 2. How many levels are present in CMM? three four five six Answer:c Explanation:The five levels are: initial  repeatable  defined  managed  optimizing. 3. Which level of CMM is for process management? Initial Repeatable Defined Optimizing Answer:d Explanation:It is a characteristic of processes at this level that the focus is on continually improving process  performance through both incremental and innovative technological changes/improvements.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/256/1.+Which+one+is+not+a+software+quality+model.jpg""      ""name"": ""1. Which one is not a software quality model""      ""description"": ""ISO McCall model. Boehm model. ISO Answer:a. Explanation:ISO 9000 is software certification. 2. How many levels are present in CMM three. four. five. six. Answer:c. Explanation:The five levels are: initial  repeatable  defined  managed  optimizing. 3. Which level of CMM is for process management Initial. Repeatable. Defined. Optimizing. Answer:d. Explanation:It is a characteristic of processes at this level that the focus is on continually improving process performance through both incremental and innovative technological changes/improvements.""      ""width"": ""1024"" }                         257                  4. In ISO 9126  time behavior and resource utilization are a part ofmaintainability portability efficiency usability Answer:c Explanation:A set of attributes that bear on the relationship between the level of performance of the software  and the amount of resources used  under stated conditions. 5. Which of the following is not a Probabilistic Model? Error seeding NHPP Input domain d) Halstead’s software metric Answer:d Explanation:Halstead’s software metric is a deterministic model. 6. Software reliability is defined with respect to time bugs failures quality Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/257/4.+In+ISO+9126%2C+time+behavior+and+resource+utilization+are+a+part+of.jpg""      ""name"": ""4. In ISO 9126  time behavior and resource utilization are a part of""      ""description"": ""maintainability. portability. efficiency. usability. Answer:c. Explanation:A set of attributes that bear on the relationship between the level of performance of the software and the amount of resources used  under stated conditions. 5. Which of the following is not a Probabilistic Model Error seeding. NHPP. Input domain. d) Halstead’s software metric. Answer:d. Explanation:Halstead’s software metric is a deterministic model. 6. Software reliability is defined with respect to. time. bugs. failures. quality. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         258                  7. Failure In Time (FIT) is another way of reportingMTTR MTTF MTSF MTBF Answer:d Explanation:FIT reports the number of expected failures per one billion hours of operation for a device. This  term is used particularly by the semiconductor industry but is also used by component manufacturers. 8. MTTF stands for Minimum time to failure Mean time to failure Maximum time to failure None of the mentioned Answer:b Explanation:The answer is self explanatory. 9. Mean Time To Repair (MTTR) is the time needed to repair a failed hardware module. True False Answer:a Explanation:In an operational system  repair generally means replacing a failed hardware part. Thus  hardware  MTTR could be viewed as mean time to replace a failed hardware module.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/258/7.+Failure+In+Time+%28FIT%29+is+another+way+of+reporting.jpg""      ""name"": ""7. Failure In Time (FIT) is another way of reporting""      ""description"": ""MTTR. MTTF. MTSF. MTBF. Answer:d. Explanation:FIT reports the number of expected failures per one billion hours of operation for a device. This term is used particularly by the semiconductor industry but is also used by component manufacturers. 8. MTTF stands for. Minimum time to failure. Mean time to failure. Maximum time to failure. None of the mentioned. Answer:b. Explanation:The answer is self explanatory. 9. Mean Time To Repair (MTTR) is the time needed to repair a failed hardware module. True. False. Answer:a. Explanation:In an operational system  repair generally means replacing a failed hardware part. Thus  hardware MTTR could be viewed as mean time to replace a failed hardware module.""      ""width"": ""1024"" }                         259                  10. IMC Networks is a leading10. IMC Networks is a leading  	certified manufacturer of optical networking and LAN/WAN connectivity solutions for enterprise  telecommunications and service provider applications. Telco Systems D-Link Arista Networks ISO 9001 Answer:a Explanation:Founded in 1988  with over one million products installed worldwide  IMC  Networks offers a wide range of fiber media and mode converters for a variety of  applications.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/259/10.+IMC+Networks+is+a+leading.jpg""      ""name"": ""10. IMC Networks is a leading""      ""description"": ""10. IMC Networks is a leading certified manufacturer of optical networking and LAN/WAN connectivity solutions for enterprise  telecommunications and service provider applications. Telco Systems. D-Link. Arista Networks. ISO Answer:a. Explanation:Founded in 1988  with over one million products installed worldwide  IMC Networks offers a wide range of fiber media and mode converters for a variety of applications.""      ""width"": ""1024"" }                         260                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/260/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         261                  Application ArchitecturesSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/261/Application+Architectures.jpg""      ""name"": ""Application Architectures""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         262                  1. Which of the following examples is/are models of application architectures?a means of assessing components for reuse a design checklist a vocabulary for talking about types of applications All of the mentioned Answer:d Explanation:Application architectures encapsulate the principal characteristics of a class of systems. 2. ERP stands for Enterprise Research Planning Enterprise Resource Planning Enterprise Resource Package Enterprise Research Package Answer:b Explanation:The answer is self explanatory. 3. Which of the following type describes application architectures? Transaction processing applications Language processing systems Client management systems Transaction processing applications and Language processing systems Explanation:Transaction processing applications are database-centered applications that process user requests for information and update the information in a database  while language processing systems are systems in which the user’s intentions are expressed in a formal language.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/262/1.+Which+of+the+following+examples+is%2Fare+models+of+application+architectures.jpg""      ""name"": ""1. Which of the following examples is/are models of application architectures""      ""description"": ""a means of assessing components for reuse. a design checklist. a vocabulary for talking about types of applications. All of the mentioned. Answer:d. Explanation:Application architectures encapsulate the principal characteristics of a class of systems. 2. ERP stands for. Enterprise Research Planning. Enterprise Resource Planning. Enterprise Resource Package. Enterprise Research Package. Answer:b. Explanation:The answer is self explanatory. 3. Which of the following type describes application architectures Transaction processing applications. Language processing systems. Client management systems. Transaction processing applications and Language processing systems. Explanation:Transaction processing applications are database-centered applications that process user requests for information and update the information in a database  while language processing systems are systems in which the user’s intentions are expressed in a formal language.""      ""width"": ""1024"" }                         263                  4. All the operations in a transaction need to be completed before the database changes are made  	_.functional available to the users permanent None of the mentioned Answer:b Explanation:This ensures that failure of operations within the transaction does not lead to inconsistencies in the database. 5. Systems that involve interaction with a shared database can be considered as. software-based transaction-based server-based client-based Explanation:Such systems with a shared database are also referred to as transaction based information systems. 6. What translates a natural or an artificial language into another representation of that language and  for programming  languages also execute the resulting code? ERP systems Transaction-based information systems Language processing systems Answer:c Explanation:In software engineering  compilers translate an artificial programming language into machine code.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/263/4.+All+the+operations+in+a+transaction+need+to+be+completed+before+the+database+changes+are+made+_..jpg""      ""name"": ""4. All the operations in a transaction need to be completed before the database changes are made _.""      ""description"": ""functional. available to the users. permanent. None of the mentioned. Answer:b. Explanation:This ensures that failure of operations within the transaction does not lead to inconsistencies in the database. 5. Systems that involve interaction with a shared database can be considered as. software-based. transaction-based. server-based. client-based. Explanation:Such systems with a shared database are also referred to as transaction based information systems. 6. What translates a natural or an artificial language into another representation of that language and  for programming languages also execute the resulting code ERP systems. Transaction-based information systems. Language processing systems. Answer:c. Explanation:In software engineering  compilers translate an artificial programming language into machine code.""      ""width"": ""1024"" }                         264                  7. Properties of a system such as performance and security are independent of the architecture used.True False Answer:b Explanation:Properties such as performance  security  and availability are influenced by the architecture used. 8. Which of the following is/are commonly used architectural pattern(s)? Model-View-Controller Layered Architecture Client–server All of the mentioned Answer:d Explanation:Commonly used architectural patterns include Model-View-Controller  Layered Architecture   Repository  Client–server  and Pipe and Filter. 9. A language-processing systems may translate an XML data description into a machine code an alternative XML representation machine code and alternative XML representation a software module Answer:c Explanation:Such is the property and function of language processing system.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/264/7.+Properties+of+a+system+such+as+performance+and+security+are+independent+of+the+architecture+used..jpg""      ""name"": ""7. Properties of a system such as performance and security are independent of the architecture used.""      ""description"": ""True. False. Answer:b. Explanation:Properties such as performance  security  and availability are influenced by the architecture used. 8. Which of the following is/are commonly used architectural pattern(s) Model-View-Controller. Layered Architecture. Client–server. All of the mentioned. Answer:d. Explanation:Commonly used architectural patterns include Model-View-Controller  Layered Architecture  Repository  Client–server  and Pipe and Filter. 9. A language-processing systems may translate an XML data description into. a machine code. an alternative XML representation. machine code and alternative XML representation. a software module. Answer:c. Explanation:Such is the property and function of language processing system.""      ""width"": ""1024"" }                         265                  10. Transaction processing systems may be organized as a10. Transaction processing systems may be organized as a  	architecture with system components responsible for input  processing  and output. Repository Client–server Model-View-Controller Pipe and Filter Answer:d Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/265/10.+Transaction+processing+systems+may+be+organized+as+a.jpg""      ""name"": ""10. Transaction processing systems may be organized as a""      ""description"": ""10. Transaction processing systems may be organized as a architecture with system components responsible for input  processing  and output. Repository. Client–server. Model-View-Controller. Pipe and Filter. Answer:d. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         266                  Architectural PatternsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/266/Architectural+Patterns.jpg""      ""name"": ""Architectural Patterns""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         267                  1. Which of these following sensor is a useful as part of a burglar alarm system for commercial buildings? Movement detector Door sensor Window sensor All of the mentioned Answer:d Explanation:A burglar alarm system for commercial buildings include movement detectors in individual rooms  door sensors that  detect corridor doors opening  and window sensors on ground-floor windows that can detect when a window has been opened. 2. Which of the following is not real-time architectural patterns that are commonly used? Asynchronous communication Observe and React Environmental Control Process Pipeline Answer:a Explanation:These patterns can be combined and you will often see more than one of them in a single system. 3. A monitoring system examines its environment through operating system communication set of sensors none of these Answer:c Explanation:If some exceptional event or sensor state is detected by the system  the monitoring system takes some action. Often  this involves raising an alarm to draw an operator’s attention to the event.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/267/1.+Which+of+these+following+sensor+is+a+useful+as+part+of+a+burglar+alarm+system+for+commercial+buildings.jpg""      ""name"": ""1. Which of these following sensor is a useful as part of a burglar alarm system for commercial buildings""      ""description"": ""Movement detector. Door sensor. Window sensor. All of the mentioned. Answer:d. Explanation:A burglar alarm system for commercial buildings include movement detectors in individual rooms  door sensors that detect corridor doors opening  and window sensors on ground-floor windows that can detect when a window has been opened. 2. Which of the following is not real-time architectural patterns that are commonly used Asynchronous communication. Observe and React. Environmental Control. Process Pipeline. Answer:a. Explanation:These patterns can be combined and you will often see more than one of them in a single system. 3. A monitoring system examines its environment through. operating system. communication. set of sensors. none of these. Answer:c. Explanation:If some exceptional event or sensor state is detected by the system  the monitoring system takes some action. Often  this involves raising an alarm to draw an operator’s attention to the event.""      ""width"": ""1024"" }                         268                  4. Which of the following is applicable on software radio?Environmental Control Process Pipeline Distributed system None of the mentioned Answer:b Explanation:A software radio accepts incoming packets of digital data representing the radio transmission and  transforms these into a sound signal that people can listen to. 5. An example of a system that may use a process pipeline is a high-speed data distributing system data acquisition system data collector system none of the mentioned Explanation:Data acquisition systems collect data from sensors for subsequent processing and analysis. 6. Monitoring systems are an important class of embedded real-time systems. True False Answer:a Explanation:A monitoring system examines its environment through a set of sensors and  usually  displays the state  of the environment in some way.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/268/4.+Which+of+the+following+is+applicable+on+software+radio.jpg""      ""name"": ""4. Which of the following is applicable on software radio""      ""description"": ""Environmental Control. Process Pipeline. Distributed system. None of the mentioned. Answer:b. Explanation:A software radio accepts incoming packets of digital data representing the radio transmission and transforms these into a sound signal that people can listen to. 5. An example of a system that may use a process pipeline is a high-speed. data distributing system. data acquisition system. data collector system. none of the mentioned. Explanation:Data acquisition systems collect data from sensors for subsequent processing and analysis. 6. Monitoring systems are an important class of embedded real-time systems. True. False. Answer:a. Explanation:A monitoring system examines its environment through a set of sensors and  usually  displays the state of the environment in some way.""      ""width"": ""1024"" }                         269                  7. Which of the following is an example of a controller for a car braking system?Observe and React Process Pipeline Environmental Control Answer:d Explanation:An anti-skid braking system in a car monitors the car’s wheels and brake system. 8. ETL stands for Data Extraction Transformation & Loading Data Execution Transformation & Loading Extraction Transformation & Loading Execution Transformation & Loading Answer:a Explanation:The answer is self explanatory. 9. Control systems may make use of the Environmental Control pattern  which is a general control pattern that includes  	  processes. sensor actuator pipeline both sensor and actuator Explanation:Such patterns are quite common in Environmental Control Systems.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/269/7.+Which+of+the+following+is+an+example+of+a+controller+for+a+car+braking+system.jpg""      ""name"": ""7. Which of the following is an example of a controller for a car braking system""      ""description"": ""Observe and React. Process Pipeline. Environmental Control. Answer:d. Explanation:An anti-skid braking system in a car monitors the car’s wheels and brake system. 8. ETL stands for. Data Extraction Transformation &amp;amp; Loading. Data Execution Transformation &amp;amp; Loading. Extraction Transformation &amp;amp; Loading. Execution Transformation &amp;amp; Loading. Answer:a. Explanation:The answer is self explanatory. 9. Control systems may make use of the Environmental Control pattern  which is a general control pattern that includes processes. sensor. actuator. pipeline. both sensor and actuator. Explanation:Such patterns are quite common in Environmental Control Systems.""      ""width"": ""1024"" }                         270                  10.  	can be associated with a separate processor or core  so that the processing steps can be carried out in parallel. Process Pipeline Environmental Control Observe and React none of the mentioned Answer:a Explanation:The Process Pipeline pattern makes this rapid processing possible by breaking  down the required data processing into a sequence of separate transformations  with each  transformation carried out by an independent process.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/270/10.+can+be+associated+with+a+separate+processor+or+core%2C+so+that+the+processing+steps+can+be+carried+out+in+parallel..jpg""      ""name"": ""10. can be associated with a separate processor or core  so that the processing steps can be carried out in parallel.""      ""description"": ""Process Pipeline. Environmental Control. Observe and React. none of the mentioned. Answer:a. Explanation:The Process Pipeline pattern makes this rapid processing possible by breaking down the required data processing into a sequence of separate transformations  with each transformation carried out by an independent process.""      ""width"": ""1024"" }                         271                  Aspect Oriented Software EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/271/Aspect+Oriented+Software+Engineering.jpg""      ""name"": ""Aspect Oriented Software Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         272                  1. Which of the following diagrams can help spot points cuts?Class diagram Object diagram Sequence diagram ER diagram Answer:b Explanation:In AOSE  sequence diagrams can help spot where pointcuts need to be set. 2. Which of the following is represented as an aspect that requests a login name and password? Class Object User authentication All of the mentioned Answer:c Explanation:User authentication may be represented as an aspect that requests a login name and password. This can be  automatically woven into the program wherever authentication is required. 3. Research and development in aspect-orientation has primarily focused on software re-engineering artificial programming aspect-oriented programming Explanation:Aspect-oriented programming languages such as AspectJ have been developed that extend object-oriented  programming to include aspects.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/272/1.+Which+of+the+following+diagrams+can+help+spot+points+cuts.jpg""      ""name"": ""1. Which of the following diagrams can help spot points cuts""      ""description"": ""Class diagram. Object diagram. Sequence diagram. ER diagram. Answer:b. Explanation:In AOSE  sequence diagrams can help spot where pointcuts need to be set. 2. Which of the following is represented as an aspect that requests a login name and password Class. Object. User authentication. All of the mentioned. Answer:c. Explanation:User authentication may be represented as an aspect that requests a login name and password. This can be automatically woven into the program wherever authentication is required. 3. Research and development in aspect-orientation has primarily focused on. software re-engineering. artificial programming. aspect-oriented programming. Explanation:Aspect-oriented programming languages such as AspectJ have been developed that extend object-oriented programming to include aspects.""      ""width"": ""1024"" }                         273                  4. Which of the following is a key principle of software design and implementation?Separation of concerns Writing aspects Finding code complexity None of the mentioned Answer:a Explanation:The separation of concerns is a key principle of software design and implementation. It means that you should organize  your software so that each element in the program (class  method  procedure  etc.) does one thing and one thing only. 5. Which of the following is not a type of stakeholder concern? Functional concerns Quality of service concerns Policy concern Non-functional concern Explanation:The core concerns of a system are those functional concerns that relate to its primary purpose. 6. Which of the following concerns best suits the following statement:”Internet banking system includes new customer requirements   account Requirements  customer management requirements  security requirements  recovery requirements etc.” ? System concerns Cross-cutting concerns Answer:d Explanation:Cross-cutting concerns  which is based on an example of an Internet banking system. This system has requirements  relating to new customers such as credit checking and address verification.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/273/4.+Which+of+the+following+is+a+key+principle+of+software+design+and+implementation.jpg""      ""name"": ""4. Which of the following is a key principle of software design and implementation""      ""description"": ""Separation of concerns. Writing aspects. Finding code complexity. None of the mentioned. Answer:a. Explanation:The separation of concerns is a key principle of software design and implementation. It means that you should organize your software so that each element in the program (class  method  procedure  etc.) does one thing and one thing only. 5. Which of the following is not a type of stakeholder concern Functional concerns. Quality of service concerns. Policy concern. Non-functional concern. Explanation:The core concerns of a system are those functional concerns that relate to its primary purpose. 6. Which of the following concerns best suits the following statement: Internet banking system includes new customer requirements  account Requirements  customer management requirements  security requirements  recovery requirements etc. System concerns. Cross-cutting concerns. Answer:d. Explanation:Cross-cutting concerns  which is based on an example of an Internet banking system. This system has requirements relating to new customers such as credit checking and address verification.""      ""width"": ""1024"" }                         274                  7. Which of the following is core concern in medical record management system?maintaining records of patients diagnose and treatments consultations All of the mentioned Answer:a Explanation:The answer is self explanatory. 8. An event in an executing program where the advice associated with an aspect may be executed is known as aspect join point join point model pointcut Answer:b 9. The incorporation of advice code at the specified join points by an aspect weaver is called”. weaving Answer:e  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/274/7.+Which+of+the+following+is+core+concern+in+medical+record+management+system.jpg""      ""name"": ""7. Which of the following is core concern in medical record management system""      ""description"": ""maintaining records of patients. diagnose and treatments. consultations. All of the mentioned. Answer:a. Explanation:The answer is self explanatory. 8. An event in an executing program where the advice associated with an aspect may be executed is known as. aspect. join point. join point model. pointcut. Answer:b. 9. The incorporation of advice code at the specified join points by an aspect weaver is called . weaving. Answer:e.""      ""width"": ""1024"" }                         275                  10. Which of the following is needed by Maintenance staff?a specific type of equipment maintenance record for each and every equipment item Check in/check out equipment for maintenance All of the mentioned Answer:d Explanation:All the options are essential for effective maintenance. 11. An aspect is only static. True False Explanation:An aspect is a class-like structure to encapsulate cross-cut concerns that can be static or dynamic.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/275/10.+Which+of+the+following+is+needed+by+Maintenance+staff.jpg""      ""name"": ""10. Which of the following is needed by Maintenance staff""      ""description"": ""a specific type of equipment. maintenance record for each and every equipment item. Check in/check out equipment for maintenance. All of the mentioned. Answer:d. Explanation:All the options are essential for effective maintenance. 11. An aspect is only static. True. False. Explanation:An aspect is a class-like structure to encapsulate cross-cut concerns that can be static or dynamic.""      ""width"": ""1024"" }                         276                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/276/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         277                  Cleanroom Software EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/277/Cleanroom+Software+Engineering.jpg""      ""name"": ""Cleanroom Software Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         278                  1. Who was first to proposed the Cleanroom philosophy in software engineering ?Mills Dyer Linger All of the Mentioned Answer:d Explanation:The Cleanroom philosophy was first proposed for software engineering by Mills  Dyer  and Linger during the 1980s. 2. How does Cleanroom software engineering differs from the conventional and object-oriented views ? It makes explicit use of statistical quality control. It verifies design specification using a mathematically based proof of correctness. It relies heavily on statistical use testing to uncover high-impact errors. All of the mentioned Explanation:The answer is self explanatory. 3. Cleanroom software engineering complies with the operational analysis principles by using a method called known as box structure specification referential transparency degenerative error correction None of the mentioned Answer:a Explanation:Box structures are descriptions of functions that exhibit properties essential for effective system specification and design.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/278/1.+Who+was+first+to+proposed+the+Cleanroom+philosophy+in+software+engineering.jpg""      ""name"": ""1. Who was first to proposed the Cleanroom philosophy in software engineering""      ""description"": ""Mills. Dyer. Linger. All of the Mentioned. Answer:d. Explanation:The Cleanroom philosophy was first proposed for software engineering by Mills  Dyer  and Linger during the 1980s. 2. How does Cleanroom software engineering differs from the conventional and object-oriented views It makes explicit use of statistical quality control. It verifies design specification using a mathematically based proof of correctness. It relies heavily on statistical use testing to uncover high-impact errors. All of the mentioned. Explanation:The answer is self explanatory. 3. Cleanroom software engineering complies with the operational analysis principles by using a method called known as. box structure specification. referential transparency. degenerative error correction. None of the mentioned. Answer:a. Explanation:Box structures are descriptions of functions that exhibit properties essential for effective system specification and design.""      ""width"": ""1024"" }                         279                  4. What encapsulates state data and services in a manner that is analogous to objects?State box Clean box White box Black box Answer:a Explanation:In this specification view  inputs to the state box (stimuli) and outputs (responses) are represented. 5. MTTF stands for mean-time-to-function mean-time-to-failure manufacture-time-to-function None of the mentioned Answer:b Explanation:The answer is self explanatory. 6. The transition functions that are implied by the state box are defined in Yellow box Clear box Explanation:Stated simply  a clear box contains the procedural design for the state box.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/279/4.+What+encapsulates+state+data+and+services+in+a+manner+that+is+analogous+to+objects.jpg""      ""name"": ""4. What encapsulates state data and services in a manner that is analogous to objects""      ""description"": ""State box. Clean box. White box. Black box. Answer:a. Explanation:In this specification view  inputs to the state box (stimuli) and outputs (responses) are represented. 5. MTTF stands for. mean-time-to-function. mean-time-to-failure. manufacture-time-to-function. None of the mentioned. Answer:b. Explanation:The answer is self explanatory. 6. The transition functions that are implied by the state box are defined in. Yellow box. Clear box. Explanation:Stated simply  a clear box contains the procedural design for the state box.""      ""width"": ""1024"" }                         280                  7. Which of the following is not included in the certification approach?Creation of usage scenarios Specific usage file Generation of test cases from the servers end. Reliability Answer:c Explanation:This is a part of testing phase and can be as exhaustive as possible. 8. The  	specifies the behavior of a system or a part of a system. Yellow box Clear box White box Black box Answer:d Explanation:The system (or part) responds to specific stimuli (events) by applying a set of transition rules that map  the stimulus into a response. 9. Which of the following is required for Certification for cleanroom software engineering? Sampling model Component model Certification model All of the mentioned  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/280/7.+Which+of+the+following+is+not+included+in+the+certification+approach.jpg""      ""name"": ""7. Which of the following is not included in the certification approach""      ""description"": ""Creation of usage scenarios. Specific usage file. Generation of test cases from the servers end. Reliability. Answer:c. Explanation:This is a part of testing phase and can be as exhaustive as possible. 8. The specifies the behavior of a system or a part of a system. Yellow box. Clear box. White box. Black box. Answer:d. Explanation:The system (or part) responds to specific stimuli (events) by applying a set of transition rules that map the stimulus into a response. 9. Which of the following is required for Certification for cleanroom software engineering Sampling model. Component model. Certification model. All of the mentioned.""      ""width"": ""1024"" }                         281                  10. The philosophy of Cleanroom SE focuses on defect removal rather than defect avaoidance.True False Answer:b Explanation: The philosophy focuses on defect avoidance rather than defect removal. 11. Which of the following Cleanroom process teams develops set of statistical test to exercise software after development? Specification team Development team Certification team  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/281/10.+The+philosophy+of+Cleanroom+SE+focuses+on+defect+removal+rather+than+defect+avaoidance..jpg""      ""name"": ""10. The philosophy of Cleanroom SE focuses on defect removal rather than defect avaoidance.""      ""description"": ""True. False. Answer:b. Explanation: The philosophy focuses on defect avoidance rather than defect removal. 11. Which of the following Cleanroom process teams develops set of statistical test to exercise software after development Specification team. Development team. Certification team.""      ""width"": ""1024"" }                         282                  Component Based Software EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/282/Component+Based+Software+Engineering.jpg""      ""name"": ""Component Based Software Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         283                  1. A software element conforms to a standard component model and can be independently deployed and composed  without modification according to a composition standard. True False Answer:a Explanation:This definition is essentially based on standards so that a software unit that conforms to these standards is a  component. 2.Which of the following is a feature of CBSE? It increases quality CBSE shortens delivery time CBSE increases productivity All of the mentioned Answer:d Explanation:CBSE increases quality  especially evolvability and maintainability. Other options are also favor CBSE. 3. Which of the following term is best define by the statement:”For a component to be composable  all external  interactions must take place through publicly defined interfaces”? Standardized Independent Composable Documented Answer:c Explanation:The answer is self eexplanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/283/1.+A+software+element+conforms+to+a+standard+component+model+and+can+be+independently+deployed+and+composed+without+modification+according+to+a+composition+standard..jpg""      ""name"": ""1. A software element conforms to a standard component model and can be independently deployed and composed without modification according to a composition standard.""      ""description"": ""True. False. Answer:a. Explanation:This definition is essentially based on standards so that a software unit that conforms to these standards is a component. 2.Which of the following is a feature of CBSE It increases quality. CBSE shortens delivery time. CBSE increases productivity. All of the mentioned. Answer:d. Explanation:CBSE increases quality  especially evolvability and maintainability. Other options are also favor CBSE. 3. Which of the following term is best define by the statement: For a component to be composable  all external interactions must take place through publicly defined interfaces Standardized. Independent. Composable. Documented. Answer:c. Explanation:The answer is self eexplanatory.""      ""width"": ""1024"" }                         284                  4. A component model defines standards forproperties methods mechanisms All of the mentioned Answer:d Explanation:A component model defines standards for properties individual components must satisfy and methods and  mechanisms for composing components. 5. Which of the following is not an example of component technology? EJB COM+ .NET None of the mentioned Explanation:All the options supports the implementation  assembly  deployment  execution of components. 6. Which of the following term is best defined by the statement:”The operations on each side of the interface have the  same name but their parameter types or the number of parameters are different.”? Parameter incompatibility Operation incompleteness Operation incompatibility Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/284/4.+A+component+model+defines+standards+for.jpg""      ""name"": ""4. A component model defines standards for""      ""description"": ""properties. methods. mechanisms. All of the mentioned. Answer:d. Explanation:A component model defines standards for properties individual components must satisfy and methods and mechanisms for composing components. 5. Which of the following is not an example of component technology EJB. COM+ .NET. None of the mentioned. Explanation:All the options supports the implementation  assembly  deployment  execution of components. 6. Which of the following term is best defined by the statement: The operations on each side of the interface have the same name but their parameter types or the number of parameters are different. Parameter incompatibility. Operation incompleteness. Operation incompatibility. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         285                  7. Which of the following term is best defined by the statement: “The names of the operations in the ‘provides’ and ‘requires’ interfaces are different.”? Parameter incompatibility Operation incompleteness Operation incompatibility None of the above Answer:c Explanation:The answer is self explanatory. 8. A defines a set of standards for components  including interface standards  usage standards  and deployment standards. Component-based software engineering Component composition Component model Component interfaces Explanation:The implementation of the component model provides a set of common services that may be used by all components. 9. When composing reusable components that have not been written for your application  you may need to write adaptors or ‘glue code’ to reconcile the different  	. Component modules  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/285/7.+Which+of+the+following+term+is+best+defined+by+the+statement%3A+The+names+of+the+operations+in+the+%E2%80%98provides%E2%80%99+and+%E2%80%98requires%E2%80%99+interfaces+are+different..jpg""      ""name"": ""7. Which of the following term is best defined by the statement: The names of the operations in the ‘provides’ and ‘requires’ interfaces are different.""      ""description"": ""Parameter incompatibility. Operation incompleteness. Operation incompatibility. None of the above. Answer:c. Explanation:The answer is self explanatory. 8. A defines a set of standards for components  including interface standards  usage standards  and deployment standards. Component-based software engineering. Component composition. Component model. Component interfaces. Explanation:The implementation of the component model provides a set of common services that may be used by all components. 9. When composing reusable components that have not been written for your application  you may need to write adaptors or ‘glue code’ to reconcile the different . Component modules.""      ""width"": ""1024"" }                         286                  10. 	is a reuse-based approach to defining  implementing  and composing loosely coupled independent components into systems. Component-based software engineering Component composition Component model Component interfaces Answer:d Explanation:Component Interfaces are PeopleSoft’s way of exposing the business logic developed into Components for consumption by other areas of the system.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/286/10.+is+a+reuse-based+approach+to+defining%2C+implementing%2C+and+composing+loosely+coupled+independent+components+into+systems..jpg""      ""name"": ""10. is a reuse-based approach to defining  implementing  and composing loosely coupled independent components into systems.""      ""description"": ""Component-based software engineering. Component composition. Component model. Component interfaces. Answer:d. Explanation:Component Interfaces are PeopleSoft’s way of exposing the business logic developed into Components for consumption by other areas of the system.""      ""width"": ""1024"" }                         287                  Computer Aided Software EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/287/Computer+Aided+Software+Engineering.jpg""      ""name"": ""Computer Aided Software Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         288                  1. Which of the following is software engineer’s primary characteristics?A collection of useful tools that will help in every step of building a product An organized layout that enables tools to be found quickly and used efficiently A skilled artisan who understands how to use the tools in an effective manner All of the mentioned Answer:d Explanation:The answer is self explanatory. 2. Database management software serves as a foundation for the establishment of a CASE database (repository) that we call project database system database analysis and design tools prototyping tools Answer:a Explanation:Given the emphasis on configuration objects  database management tools for CASE are evolving from relational  database management systems to object oriented database management systems. 3. What enables a software engineer to define screen layout rapidly for interactive applications? Analysis and design tools Tool kit Screen painters PRO/SIM tools Answer:c Explanation:More sophisticated CASE prototyping tools enable the creation of a data design  coupled with both screen  and report layouts.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/288/1.+Which+of+the+following+is+software+engineer%E2%80%99s+primary+characteristics.jpg""      ""name"": ""1. Which of the following is software engineer’s primary characteristics""      ""description"": ""A collection of useful tools that will help in every step of building a product. An organized layout that enables tools to be found quickly and used efficiently. A skilled artisan who understands how to use the tools in an effective manner. All of the mentioned. Answer:d. Explanation:The answer is self explanatory. 2. Database management software serves as a foundation for the establishment of a CASE database (repository) that we call. project database. system database. analysis and design tools. prototyping tools. Answer:a. Explanation:Given the emphasis on configuration objects  database management tools for CASE are evolving from relational database management systems to object oriented database management systems. 3. What enables a software engineer to define screen layout rapidly for interactive applications Analysis and design tools. Tool kit. Screen painters. PRO/SIM tools. Answer:c. Explanation:More sophisticated CASE prototyping tools enable the creation of a data design  coupled with both screen and report layouts.""      ""width"": ""1024"" }                         289                  4.  	tools assist in the planning  development  and control in CASE.Dynamic measurement Data acquisition Test management Cross-functional tools Answer:c Explanation:The answer is self explanatory. 5. Which tools cross the bounds of the preceding categories? Simulation 6. Which environment demands specialized testing tools that exercise the graphical user interface and the network  communications requirements for client and server? Dynamic analysis Client/Server Re-engineering Answer:b Explanation:A client/server architecture is GUI based.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/289/4.+tools+assist+in+the+planning%2C+development%2C+and+control+in+CASE..jpg""      ""name"": ""4. tools assist in the planning  development  and control in CASE.""      ""description"": ""Dynamic measurement. Data acquisition. Test management. Cross-functional tools. Answer:c. Explanation:The answer is self explanatory. 5. Which tools cross the bounds of the preceding categories Simulation. 6. Which environment demands specialized testing tools that exercise the graphical user interface and the network communications requirements for client and server Dynamic analysis. Client/Server. Re-engineering. Answer:b. Explanation:A client/server architecture is GUI based.""      ""width"": ""1024"" }                         290                  7. Which tools are used to modify on-line database systems?Reverse engineering specification tools Code restructuring and analysis tools Test management tools On-line system re-engineering tools Answer:d Explanation:For example these tools convert IDMS or DB2 files into entity-relationship format. 8. Which is the definition of objects in the database that leads directly to a standard approach for the creation of  software engineering documents. Document standardization Data integrity Information sharing Data/data integration Answer:a Explanation:The answer is self explanatory. 9. Which of the following term is best defined by the statement: “CASE tools and the target applications are isolated  from physical storage so they are not affected when the hardware configuration is changed.”? Non-redundant data storage Data independence Data dependence. Adhoc data queries and reports Answer:b  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/290/7.+Which+tools+are+used+to+modify+on-line+database+systems.jpg""      ""name"": ""7. Which tools are used to modify on-line database systems""      ""description"": ""Reverse engineering specification tools. Code restructuring and analysis tools. Test management tools. On-line system re-engineering tools. Answer:d. Explanation:For example these tools convert IDMS or DB2 files into entity-relationship format. 8. Which is the definition of objects in the database that leads directly to a standard approach for the creation of software engineering documents. Document standardization. Data integrity. Information sharing. Data/data integration. Answer:a. Explanation:The answer is self explanatory. 9. Which of the following term is best defined by the statement: CASE tools and the target applications are isolated from physical storage so they are not affected when the hardware configuration is changed. Non-redundant data storage. Data independence. Data dependence. Adhoc data queries and reports. Answer:b.""      ""width"": ""1024"" }                         291                  10. Which of the following term is best define by the statement:”Each object is stored only once  but is accessible by all CASE tools that need it.”? Non-redundant data storage Data independence Transaction control. Adhoc data queries and reports Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/291/10.+Which+of+the+following+term+is+best+define+by+the+statement%3A+Each+object+is+stored+only+once%2C+but+is+accessible+by+all+CASE+tools+that+need+it..jpg""      ""name"": ""10. Which of the following term is best define by the statement: Each object is stored only once  but is accessible by all CASE tools that need it.""      ""description"": ""Non-redundant data storage. Data independence. Transaction control. Adhoc data queries and reports. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         292                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/292/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         293                  ISO 9001 and CMM Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/293/ISO+9001+and+CMM+Source+%26+Courtsey%3A.jpg""      ""name"": ""ISO 9001 and CMM Source &amp;amp; Courtsey:""      ""description"": ""ISO 9001 and CMM Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         294                  1. CMM stands for Capability Management Module Conservative Maturity Model Capability Maturity Module Capability Maturity Model Answer:d Explanation:The Capability Maturity Model for Software describes the principles and practices underlying software process maturity and is intended to help software organizations improve the maturity of their software processes in terms of an evolutionary path from adhoc  chaotic processes to mature  disciplined software processes. 2. The ISO 9000 series of standards is a program that can be used for external quality assurance purposes. True False Answer:b Explanation:The ISO 9000 series of standards is a set of documents. 3. According to ISO 9001  the causes of nonconforming product should be deleted eliminated identified eliminated and identified Explanation: ISO 9001 requires that the causes of nonconforming product to be identified. Potential causes of  nonconforming product are eliminated.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/294/1.+CMM+stands+for+Capability+Management+Module.+Conservative+Maturity+Model.+Capability+Maturity+Module..jpg""      ""name"": ""1. CMM stands for Capability Management Module. Conservative Maturity Model. Capability Maturity Module.""      ""description"": ""Capability Maturity Model. Answer:d. Explanation:The Capability Maturity Model for Software describes the principles and practices underlying software process maturity and is intended to help software organizations improve the maturity of their software processes in terms of an evolutionary path from adhoc  chaotic processes to mature  disciplined software processes. 2. The ISO 9000 series of standards is a program that can be used for external quality assurance purposes. True. False. Answer:b. Explanation:The ISO 9000 series of standards is a set of documents. 3. According to ISO 9001  the causes of nonconforming product should be. deleted. eliminated. identified. eliminated and identified. Explanation: ISO 9001 requires that the causes of nonconforming product to be identified. Potential causes of nonconforming product are eliminated.""      ""width"": ""1024"" }                         295                  4. .CO poliy in CMM means The leadership practices in Commitment to Perform The organizational structure (groups) practices in Ability to Perform The policy practices in Commitment to Perform The planning practices in Commitment to Perform Answer:c Explanation: CMM have certain policy practices covered under .CO policy. 5. ISO 9001 is not concerned with  	of quality records. collection maintenance verification dis-positioning Explanation:The practices defining the quality records to be maintained in the CMM are distributed throughout the key  process areas in the various Activities Performed practices. 6. Which of the following is not a maturity level in CMM? Design Repeatable Managed Optimizing Explanation:The CMM is organized into five maturity levels as namely: Initial  Repeatable  Defined  Managed and Optimizing.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/295/4.+.CO+poliy+in+CMM+means+The+leadership+practices+in+Commitment+to+Perform.+The+organizational+structure+%28groups%29+practices+in+Ability+to+Perform..jpg""      ""name"": ""4. .CO poliy in CMM means The leadership practices in Commitment to Perform. The organizational structure (groups) practices in Ability to Perform.""      ""description"": ""The policy practices in Commitment to Perform. The planning practices in Commitment to Perform. Answer:c. Explanation: CMM have certain policy practices covered under .CO policy. 5. ISO 9001 is not concerned with of quality records. collection. maintenance. verification. dis-positioning. Explanation:The practices defining the quality records to be maintained in the CMM are distributed throughout the key process areas in the various Activities Performed practices. 6. Which of the following is not a maturity level in CMM Design. Repeatable. Managed. Optimizing. Explanation:The CMM is organized into five maturity levels as namely: Initial  Repeatable  Defined  Managed and Optimizing.""      ""width"": ""1024"" }                         296                  7. In CMM  the life cycle activities of requirements analysis  design  code  and test are described in Software Product Engineering Software Quality Assurance Software Subcontract Management Software Quality Management Answer:a Explanation:In CMM planning these activities is described in Software Project Planning  however the life cycle activities of  requirements analysis  design  code  and test are described in Software Product Engineering. 8. Which of the following requires design control measures  such as holding and recording design reviews and qualification tests? CMM ISO c) ISO d) None of the mentioned Answer:c Explanation:ISO states that the supplier should carry out reviews to ensure the requirements are met and design  methods are correctly carried out. 9. The CMM emphasizes continuous process improvement the need to record information the need to accept quality system both a and b Answer:d Explanation: CMM emphasizes the need to record information for later use in the process and for improvement of the process.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/296/7.+In+CMM%2C+the+life+cycle+activities+of+requirements+analysis%2C+design%2C+code%2C+and+test+are+described+in.jpg""      ""name"": ""7. In CMM  the life cycle activities of requirements analysis  design  code  and test are described in""      ""description"": ""Software Product Engineering. Software Quality Assurance. Software Subcontract Management. Software Quality Management. Answer:a. Explanation:In CMM planning these activities is described in Software Project Planning  however the life cycle activities of requirements analysis  design  code  and test are described in Software Product Engineering. 8. Which of the following requires design control measures  such as holding and recording design reviews and qualification tests CMM. ISO 9001 c) ISO d) None of the mentioned. Answer:c. Explanation:ISO states that the supplier should carry out reviews to ensure the requirements are met and design methods are correctly carried out. 9. The CMM emphasizes. continuous process improvement. the need to record information. the need to accept quality system. both a and b. Answer:d. Explanation: CMM emphasizes the need to record information for later use in the process and for improvement of the process.""      ""width"": ""1024"" }                         297                  10.  	states that  where appropriate  adequate statistical techniques are identified and used to verify the acceptability of process capability and product characteristics. a) ISO 9001 b) ISO CMM All of the mentioned Answer:a Explanation: ISO 9001 states that  where  appropriate adequate statistical techniques are  identified and used to verify the acceptability of process capability and product  characteristics.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/297/10.+states+that%2C+where+appropriate%2C+adequate+statistical+techniques+are+identified+and+used+to+verify+the+acceptability+of+process+capability+and+product+characteristics..jpg""      ""name"": ""10. states that  where appropriate  adequate statistical techniques are identified and used to verify the acceptability of process capability and product characteristics.""      ""description"": ""a) ISO b) ISO CMM. All of the mentioned. Answer:a. Explanation: ISO 9001 states that  where  appropriate adequate statistical techniques are identified and used to verify the acceptability of process capability and product characteristics.""      ""width"": ""1024"" }                         298                  Analysis Modelling Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/298/Analysis+Modelling+Source+%26+Courtsey%3A.jpg""      ""name"": ""Analysis Modelling Source &amp;amp; Courtsey:""      ""description"": ""Analysis Modelling Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         299                  1. Which of the following is not the primary objectives in the analysis model?describing the customer complaints establishing a basis for the creation of a software design defining a set of requirements that can be validated once the software is built None of the mentioned Answer:d Explanation:All the options are covered in analysis model. 2. A description of each function presented in the DFD is contained in a  	. data flow process specification control specification data store Answer:b Explanation:The answer is self explanatory. 3. Which diagram indicates the behaviour of the system as a consequence of external events? data flow diagram state transition diagram control specification diagram workflow diagram Explanation:The state transition diagram represents the various modes of behavior (called states) of the system and  the manner in which transitions are made from state to state.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/299/1.+Which+of+the+following+is+not+the+primary+objectives+in+the+analysis+model.jpg""      ""name"": ""1. Which of the following is not the primary objectives in the analysis model""      ""description"": ""describing the customer complaints. establishing a basis for the creation of a software design. defining a set of requirements that can be validated once the software is built. None of the mentioned. Answer:d. Explanation:All the options are covered in analysis model. 2. A description of each function presented in the DFD is contained in a . data flow. process specification. control specification. data store. Answer:b. Explanation:The answer is self explanatory. 3. Which diagram indicates the behaviour of the system as a consequence of external events data flow diagram. state transition diagram. control specification diagram. workflow diagram. Explanation:The state transition diagram represents the various modes of behavior (called states) of the system and the manner in which transitions are made from state to state.""      ""width"": ""1024"" }                         300                  4. A data model contains data object attributes relationships All of the mentioned Answer:d Explanation: The data model consists of three interrelated pieces of information: the data object  the attributes that describe the data object  and the relationships that connect data objects to one another. 5.  	defines the properties of a data object and take on one of the three different characteristics. data object and attributes Answer:b Explanation:They can be used to name an instance of the data object  describe the instance  or make reference to another  instance in another table. 6. The  	of a relationship is 0 if there is no explicit need for the relationship to occur or the relationship is optional. modality cardinality entity structured analysis Answer:a Explanation:The modality is 1 if an occurrence of the relationship is mandatory  else 0 for optional relationship.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/300/4.+A+data+model+contains+data+object.+attributes.+relationships.+All+of+the+mentioned.+Answer%3Ad..jpg""      ""name"": ""4. A data model contains data object. attributes. relationships. All of the mentioned. Answer:d.""      ""description"": ""Explanation: The data model consists of three interrelated pieces of information: the data object  the attributes that describe the data object  and the relationships that connect data objects to one another. 5. defines the properties of a data object and take on one of the three different characteristics. data object and attributes. Answer:b. Explanation:They can be used to name an instance of the data object  describe the instance  or make reference to another instance in another table. 6. The of a relationship is 0 if there is no explicit need for the relationship to occur or the relationship is optional. modality. cardinality. entity. structured analysis. Answer:a. Explanation:The modality is 1 if an occurrence of the relationship is mandatory  else 0 for optional relationship.""      ""width"": ""1024"" }                         301                  7. A  	is a graphical representation that depicts information flow and the transforms that are applied as data moves from input to output. data flow diagram state transition diagram control specification workflow diagram Answer:b Explanation:The basic form of a data flow diagram  also known as a data flow graph or a bubble chart. 8. A data condition occurs whenever a data is passed to an input element followed by a processing element and the  result in control output. True False Answer:a Explanation:Standard flow of condition check. 9. The  	enables the software engineer to develop models of the information domain and functional domain  at the same time activity diagram Explanation:As the DFD is refined into greater levels of detail  the analyst performs an implicit functional decomposition  of the system  thereby accomplishing the fourth operational analysis principle for function.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/301/7.+A+is+a+graphical+representation+that+depicts+information+flow+and+the+transforms+that+are+applied+as+data+moves+from+input+to+output..jpg""      ""name"": ""7. A is a graphical representation that depicts information flow and the transforms that are applied as data moves from input to output.""      ""description"": ""data flow diagram. state transition diagram. control specification. workflow diagram. Answer:b. Explanation:The basic form of a data flow diagram  also known as a data flow graph or a bubble chart. 8. A data condition occurs whenever a data is passed to an input element followed by a processing element and the result in control output. True. False. Answer:a. Explanation:Standard flow of condition check. 9. The enables the software engineer to develop models of the information domain and functional domain at the same time. activity diagram. Explanation:As the DFD is refined into greater levels of detail  the analyst performs an implicit functional decomposition of the system  thereby accomplishing the fourth operational analysis principle for function.""      ""width"": ""1024"" }                         302                  10. The  	contains a state transition diagram that is a sequential specification of behavior.data flow diagram state transition diagram control specification workflow diagram Answer:c Explanation:The control specification(CSPEC) describes the behavior of the  system  but it gives us no information about the inner working of the processes that  are activated as a result of this behavior.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/302/10.+The+contains+a+state+transition+diagram+that+is+a+sequential+specification+of+behavior..jpg""      ""name"": ""10. The contains a state transition diagram that is a sequential specification of behavior.""      ""description"": ""data flow diagram. state transition diagram. control specification. workflow diagram. Answer:c. Explanation:The control specification(CSPEC) describes the behavior of the system  but it gives us no information about the inner working of the processes that are activated as a result of this behavior.""      ""width"": ""1024"" }                         303                  Application Frameworks in Software ReuseSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/303/Application+Frameworks+in+Software+Reuse.jpg""      ""name"": ""Application Frameworks in Software Reuse""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         304                  1.Which of the following is not a benefit of software reuse?Standards compliance Increased Reliability Reduced Process risk Maintaining a component library Answer:c Explanation:There can be thousands of components in a frameworks whose maintenance is quite difficult. 2.In which of the following language the frameworks will not work? C# Ruby PHP Java Explanation:Frameworks available in all of the commonly used object-oriented programming languages. 3. Which frameworks support the development of system infrastructures such as communications  user interfaces  and compilers? Middleware integration frameworks System infrastructure framework Enterprise application frameworks Web application frameworks Answer:b Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/304/1.Which+of+the+following+is+not+a+benefit+of+software+reuse.jpg""      ""name"": ""1.Which of the following is not a benefit of software reuse""      ""description"": ""Standards compliance. Increased Reliability. Reduced Process risk. Maintaining a component library. Answer:c. Explanation:There can be thousands of components in a frameworks whose maintenance is quite difficult. 2.In which of the following language the frameworks will not work C# Ruby. PHP. Java. Explanation:Frameworks available in all of the commonly used object-oriented programming languages. 3. Which frameworks support the development of system infrastructures such as communications  user interfaces  and compilers Middleware integration frameworks. System infrastructure framework. Enterprise application frameworks. Web application frameworks. Answer:b. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         305                  4. The MVC pattern was originally proposed in the 1980s as an approach toWeb application frameworks Middleware integration frameworks GUI design Answer:d Explanation:The MVC pattern was originally proposed in the 1980s as an approach to GUI design that allowed for  multiple presentations of an object and separate styles of interaction with each of these presentations. 5. MVC framework includes Observer pattern Strategy pattern Composite pattern All of the mentioned Explanation:MVC framework includes the Observer pattern  the Strategy pattern  the Composite pattern  and a number of others. 6. Which category the following statement belongs ”Classes to create and manage sessions are usually part of a WAF”? Session management Security User interaction Database support Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/305/4.+The+MVC+pattern+was+originally+proposed+in+the+1980s+as+an+approach+to.jpg""      ""name"": ""4. The MVC pattern was originally proposed in the 1980s as an approach to""      ""description"": ""Web application frameworks. Middleware integration frameworks. GUI design. Answer:d. Explanation:The MVC pattern was originally proposed in the 1980s as an approach to GUI design that allowed for multiple presentations of an object and separate styles of interaction with each of these presentations. 5. MVC framework includes. Observer pattern. Strategy pattern. Composite pattern. All of the mentioned. Explanation:MVC framework includes the Observer pattern  the Strategy pattern  the Composite pattern  and a number of others. 6. Which category the following statement belongs  Classes to create and manage sessions are usually part of a WAF Session management. Security. User interaction. Database support. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         306                  7. Which framework’s applications are difficult to deal with?MVC pattern Web application frameworks Debugging framework None of the mentioned Answer:c Explanation:Debugging framework based applications is difficult because you may not understand how the framework  methods interact. This is a general problem with reusable software. 8. Which category the following statement belongs ”Frameworks don’t usually include a database but rather assume that a separate database such as MySQl”? Session management Security User interaction Database support Answer:d Explanation:The answer is self explanatory. 9. Which option supports the statement:”Most web frameworks now provide AJAX support”? Session Management  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/306/7.+Which+framework%E2%80%99s+applications+are+difficult+to+deal+with.jpg""      ""name"": ""7. Which framework’s applications are difficult to deal with""      ""description"": ""MVC pattern. Web application frameworks. Debugging framework. None of the mentioned. Answer:c. Explanation:Debugging framework based applications is difficult because you may not understand how the framework methods interact. This is a general problem with reusable software. 8. Which category the following statement belongs  Frameworks don’t usually include a database but rather assume that a separate. database such as MySQl Session management. Security. User interaction. Database support. Answer:d. Explanation:The answer is self explanatory. 9. Which option supports the statement: Most web frameworks now provide AJAX support Session Management.""      ""width"": ""1024"" }                         307                  10. Frameworks are an effective approach to reuse  but are10. Frameworks are an effective approach to reuse  but are  	to introduce into software development processes. difficult expensive unreliable difficult and expensive Answer:d Explanation:Frameworks can be difficult and expensive to evaluate available frameworks to choose the most appropriate one.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/307/10.+Frameworks+are+an+effective+approach+to+reuse%2C+but+are.jpg""      ""name"": ""10. Frameworks are an effective approach to reuse  but are""      ""description"": ""10. Frameworks are an effective approach to reuse  but are to introduce into software development processes. difficult. expensive. unreliable. difficult and expensive. Answer:d. Explanation:Frameworks can be difficult and expensive to evaluate available frameworks to choose the most appropriate one.""      ""width"": ""1024"" }                         308                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/308/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         309                  Client Server Software EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/309/Client+Server+Software+Engineering.jpg""      ""name"": ""Client Server Software Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         310                  1. The  	is connected to servers (typically powerful workstations or PCs) that play a dual role.database software Hardware None of the mentioned Answer:d Explanation:A root system  sometimes a mainframe  serves as the repository for corporate data plays a dual role. 2. Which of the following term is best defined by the statement:”The client sends structured query language (SQL) requests to the server which are transmitted as messages across the net”? File servers Database servers Client servers Answer:b Explanation:SQL is a database language. 3. Which subsystem implements the requirements defined by the application? UI DBMS Application subsystem Answer:c Explanation:This subsystem implements the requirements defined by the application within the context of the domain in which  the application operates.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/310/1.+The+is+connected+to+servers+%28typically+powerful+workstations+or+PCs%29+that+play+a+dual+role..jpg""      ""name"": ""1. The is connected to servers (typically powerful workstations or PCs) that play a dual role.""      ""description"": ""database. software. Hardware. None of the mentioned. Answer:d. Explanation:A root system  sometimes a mainframe  serves as the repository for corporate data plays a dual role. 2. Which of the following term is best defined by the statement: The client sends structured query language (SQL) requests to the. server which are transmitted as messages across the net File servers. Database servers. Client servers. Answer:b. Explanation:SQL is a database language. 3. Which subsystem implements the requirements defined by the application UI. DBMS. Application subsystem. Answer:c. Explanation:This subsystem implements the requirements defined by the application within the context of the domain in which the application operates.""      ""width"": ""1024"" }                         311                  4. Which test do you infer from the following statement: “The coordination and data management functions of the server are tested.”? Server tests Application function tests Transaction tests Network communication tests Answer:a Explanation:The answer is self explanatory. 5. Which of the following presentation is explained in the following statement:”An extension of the distributed presentation approach  primary database and application logic remain on the server  and data sent by the server is used by the client to prepare the user presentation.”? Local Presentation Distributed presentation Remote presentation Answer:c 6. “A client is assigned all user presentation tasks and the processes associated with data entry”.Which option supports the client’s situation? Distributed logic Explanation:The server is assigned database management tasks  the processes for client queries  and enterprise-wide applications.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/311/4.+Which+test+do+you+infer+from+the+following+statement%3A+The+coordination+and+data+management+functions+of+the+server+are+tested..jpg""      ""name"": ""4. Which test do you infer from the following statement: The coordination and data management functions of the server are tested.""      ""description"": ""Server tests. Application function tests. Transaction tests. Network communication tests. Answer:a. Explanation:The answer is self explanatory. 5. Which of the following presentation is explained in the following statement: An extension of the distributed presentation approach  primary database and application logic remain on the server  and data sent by the server is used by the client to prepare the user presentation. Local Presentation. Distributed presentation. Remote presentation. Answer:c. 6. A client is assigned all user presentation tasks and the processes associated with data entry .Which option supports the client’s. situation Distributed logic. Explanation:The server is assigned database management tasks  the processes for client queries  and enterprise-wide applications.""      ""width"": ""1024"" }                         312                  7. What is used to pass SQL requests and associated data from one component to another?Client/server SQL interaction Remote procedure calls SQL Injection All of the above Answer:a Explanation:This mechanism is limited to relational database management system (RDBMS) applications. 8. When a client application invokes a method contained within an object elsewhere in the system  CORBA uses dynamic invocation to obtain pertinent information about the desired method from the interface repository create a data structure with parameters to be passed to the object create a request for the object All of the mentioned Answer:d Explanation:The request is then passed to the ORB core—an implementation-specific part of the network operating  system that manages requests  and the request is fulfilled. 9. Which of the following services is not provided by an object? Activating & Deactivating Objects Security features Files implementing the entities identified within the ERD Registering object implementation Answer:c Explanation:An ERD is not a part of UML.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/312/7.+What+is+used+to+pass+SQL+requests+and+associated+data+from+one+component+to+another.jpg""      ""name"": ""7. What is used to pass SQL requests and associated data from one component to another""      ""description"": ""Client/server SQL interaction. Remote procedure calls. SQL Injection. All of the above. Answer:a. Explanation:This mechanism is limited to relational database management system (RDBMS) applications. 8. When a client application invokes a method contained within an object elsewhere in the system  CORBA uses dynamic invocation to. obtain pertinent information about the desired method from the interface repository. create a data structure with parameters to be passed to the object. create a request for the object. All of the mentioned. Answer:d. Explanation:The request is then passed to the ORB core—an implementation-specific part of the network operating system that manages requests  and the request is fulfilled. 9. Which of the following services is not provided by an object Activating &amp;amp; Deactivating Objects. Security features. Files implementing the entities identified within the ERD. Registering object implementation. Answer:c. Explanation:An ERD is not a part of UML.""      ""width"": ""1024"" }                         313                  10. Which of the following term is best defined by the statement:”When one object invokes another independent object  a message is passed between the two objects.”? Control couple Application object Data couple Database object Answer:c Explanation:The answer is self explanatory. 11. CORBA stands for Common Object Request Build Architecture Common Object Request Broker Architecture Common Object Request Break Architecture Answer:b  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/313/10.+Which+of+the+following+term+is+best+defined+by+the+statement%3A+When+one+object+invokes+another+independent+object%2C+a+message+is.jpg""      ""name"": ""10. Which of the following term is best defined by the statement: When one object invokes another independent object  a message is""      ""description"": ""passed between the two objects. Control couple. Application object. Data couple. Database object. Answer:c. Explanation:The answer is self explanatory. 11. CORBA stands for. Common Object Request Build Architecture. Common Object Request Broker Architecture. Common Object Request Break Architecture. Answer:b.""      ""width"": ""1024"" }                         314                  Architectural Design Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/314/Architectural+Design+Source+%26+Courtsey%3A.jpg""      ""name"": ""Architectural Design Source &amp;amp; Courtsey:""      ""description"": ""Architectural Design Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         315                  1. Architectural design is a creative process satisfying only functional-requirements of a system.True False Answer:b Explanation:In architectural design you design a system organization satisfying the functional and non- functional requirements of a system. 2. A  	view shows the system hardware and how software components are distributed across the processors in the system. physical logical process Answer:a Explanation:A physical view is implemented by system engineers implementing the system hardware. 3. The UML was designed for describing  	. object-oriented systems architectural design SRS Both object-oriented systems and Architectural design Answer:d Explanation:The UML was designed for describing object-oriented systems and  at the architectural design  stage  you often want to describe systems at a higher level of abstraction.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/315/1.+Architectural+design+is+a+creative+process+satisfying+only+functional-requirements+of+a+system..jpg""      ""name"": ""1. Architectural design is a creative process satisfying only functional-requirements of a system.""      ""description"": ""True. False. Answer:b. Explanation:In architectural design you design a system organization satisfying the functional and non- functional requirements of a system. 2. A view shows the system hardware and how software components are distributed across the processors in the system. physical. logical. process. Answer:a. Explanation:A physical view is implemented by system engineers implementing the system hardware. 3. The UML was designed for describing . object-oriented systems. architectural design. SRS. Both object-oriented systems and Architectural design. Answer:d. Explanation:The UML was designed for describing object-oriented systems and  at the architectural design stage  you often want to describe systems at a higher level of abstraction.""      ""width"": ""1024"" }                         316                  4. Which of the following view shows that the system is composed of interacting processes at run time? physical development logical process Answer:d Explanation:This view is useful for making judgments about non-functional system characteristics such as performance and availability. 5. Which of the following is an architectural conflict? Using large-grain components improves performance but reduces maintainability Introducing redundant data improves availability but makes security more difficult Localizing safety-related features usually means more communication so degraded performance All of the mentioned Explanation:High availability architecture can be affected by several design factors that are required to be maintained to  ensure that no single points of failure exist in such design. 6. Which of the following is not included in Architectural design decisions? type of application distribution of the system architectural styles testing the system Explanation: Architectural design decisions include decisions on the type of application  the distribution of the system  the  architectural styles to be used  and the ways in which the architecture should be documented and evaluated.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/316/4.+Which+of+the+following+view+shows+that+the+system+is+composed+of+interacting+processes+at+run+time.jpg""      ""name"": ""4. Which of the following view shows that the system is composed of interacting processes at run time""      ""description"": ""physical. development. logical. process. Answer:d. Explanation:This view is useful for making judgments about non-functional system characteristics such as performance and availability. 5. Which of the following is an architectural conflict Using large-grain components improves performance but reduces maintainability. Introducing redundant data improves availability but makes security more difficult. Localizing safety-related features usually means more communication so degraded performance. All of the mentioned. Explanation:High availability architecture can be affected by several design factors that are required to be maintained to ensure that no single points of failure exist in such design. 6. Which of the following is not included in Architectural design decisions type of application. distribution of the system. architectural styles. testing the system. Explanation: Architectural design decisions include decisions on the type of application  the distribution of the system  the architectural styles to be used  and the ways in which the architecture should be documented and evaluated.""      ""width"": ""1024"" }                         317                  7. Architecture once established can be applied to other products as well.True False Answer:b Explanation:Systems in the same domain often have similar architectures that reflect domain concepts. 8. Which of the following pattern is the basis of interaction management in many web-based systems? architecture repository pattern model-view-controller different operating system Answer:c Explanation:Model-View-Controller pattern is the basis of interaction management in many web-based systems. 9. What describes how a set of interacting components can share data? architecture pattern None of the mentioned Explanation:The majority of systems that use large amounts of data are organized around a shared database or repository.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/317/7.+Architecture+once+established+can+be+applied+to+other+products+as+well..jpg""      ""name"": ""7. Architecture once established can be applied to other products as well.""      ""description"": ""True. False. Answer:b. Explanation:Systems in the same domain often have similar architectures that reflect domain concepts. 8. Which of the following pattern is the basis of interaction management in many web-based systems architecture. repository pattern. model-view-controller. different operating system. Answer:c. Explanation:Model-View-Controller pattern is the basis of interaction management in many web-based systems. 9. What describes how a set of interacting components can share data architecture pattern. None of the mentioned. Explanation:The majority of systems that use large amounts of data are organized around a shared database or repository.""      ""width"": ""1024"" }                         318                  10. Which view in architectural design shows the key abstractions in the system as objects or object classes? physical development logical process Answer:c Explanation:It is possible to relate the system requirements to entities in a logical view. 11. Which of the following is a type of Architectural Model? Static structural model Dynamic process model Distribution model All of the mentioned Answer:d Explanation:All these models reflects the basic strategy that is used to structure a system.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/318/10.+Which+view+in+architectural+design+shows+the+key+abstractions+in+the+system+as+objects+or+object+classes.jpg""      ""name"": ""10. Which view in architectural design shows the key abstractions in the system as objects or object classes""      ""description"": ""physical. development. logical. process. Answer:c. Explanation:It is possible to relate the system requirements to entities in a logical view. 11. Which of the following is a type of Architectural Model Static structural model. Dynamic process model. Distribution model. All of the mentioned. Answer:d. Explanation:All these models reflects the basic strategy that is used to structure a system.""      ""width"": ""1024"" }                         319                  Component Level DesignSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/319/Component+Level+Design.jpg""      ""name"": ""Component Level Design""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         320                  1. Which of the following is not a construct?sequence condition repetition selection Answer:d Explanation: Sequence implements processing steps that are essential in the specification of any algorithm. Condition  provides the facility for selected processing based on some logical occurrence  and repetition allows for looping. 2.Which of the following steps is applied to develop a decision table? List all actions that can be associated with a specific procedure List all conditions during execution of the procedure. Define rules by indicating what action(s) occurs for a set of conditions. All of the mentioned Explanation: A decision table includes action stub and a condition stub with a set of rules. 3.  	is a pidgin(simplified version of a language that develops as a means of communication between two or more  groups that do not have a language in common) program design language structured English pseudocode Explanation:The difference between PDL and a real programming language lies in the use of narrative text embedded  directly within PDL statements.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/320/1.+Which+of+the+following+is+not+a+construct.jpg""      ""name"": ""1. Which of the following is not a construct""      ""description"": ""sequence. condition. repetition. selection. Answer:d. Explanation: Sequence implements processing steps that are essential in the specification of any algorithm. Condition provides the facility for selected processing based on some logical occurrence  and repetition allows for looping. 2.Which of the following steps is applied to develop a decision table List all actions that can be associated with a specific procedure. List all conditions during execution of the procedure. Define rules by indicating what action(s) occurs for a set of conditions. All of the mentioned. Explanation: A decision table includes action stub and a condition stub with a set of rules. 3. is a pidgin(simplified version of a language that develops as a means of communication between two or more groups that do not have a language in common) program design language. structured English. pseudocode. Explanation:The difference between PDL and a real programming language lies in the use of narrative text embedded directly within PDL statements.""      ""width"": ""1024"" }                         321                  4. Which of the following term is best defined by the statement:”The ability to represent local and global data is an essential element of component-level design.”? Data representation Logic verification c) “Code-to” ability d) Automatic processing Answer:a Explanation:The answer is self explanatory. 5. A software component Implements some functionality Has explicit dependencies through provides and required interfaces Communicates through its interfaces only All of the mentioned Answer:d Explanation:All the options identify with features of a software component. 6. Which diagram evolved from a desire to develop a procedural design representation that would not allow violation of the  structured constructs? State transition diagram Box diagram ER diagram None of the mentioned Answer:b Explanation:None.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/321/4.+Which+of+the+following+term+is+best+defined+by+the+statement%3A+The+ability+to+represent+local+and+global+data+is+an+essential+element+of+component-level+design..jpg""      ""name"": ""4. Which of the following term is best defined by the statement: The ability to represent local and global data is an essential element of component-level design.""      ""description"": ""Data representation. Logic verification. c) Code-to ability. d) Automatic processing. Answer:a. Explanation:The answer is self explanatory. 5. A software component. Implements some functionality. Has explicit dependencies through provides and required interfaces. Communicates through its interfaces only. All of the mentioned. Answer:d. Explanation:All the options identify with features of a software component. 6. Which diagram evolved from a desire to develop a procedural design representation that would not allow violation of the structured constructs State transition diagram. Box diagram. ER diagram. None of the mentioned. Answer:b Explanation:None.""      ""width"": ""1024"" }                         322                  7. A  	executes the loop task first  then tests a condition and repeats the task until the condition fails. repeat until condition do while tests if then-else Answer:a Explanation:The answer is self explanatory. 8. Which of the following is not a characteristics of box diagram? functional domain arbitrary transfer of control is impossible recursion is easy to represent providing a notation that translates actions and conditions Answer:d Explanation:This functionality is covered by UML diagrams. 9. The 	is represented as two processing boxes connected by an line (arrow) of control. Repetition Sequence Condition None of the above Answer:b  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/322/7.+A+executes+the+loop+task+first%2C+then+tests+a+condition+and+repeats+the+task+until+the+condition+fails..jpg""      ""name"": ""7. A executes the loop task first  then tests a condition and repeats the task until the condition fails.""      ""description"": ""repeat until. condition. do while tests. if then-else. Answer:a. Explanation:The answer is self explanatory. 8. Which of the following is not a characteristics of box diagram functional domain. arbitrary transfer of control is impossible. recursion is easy to represent. providing a notation that translates actions and conditions. Answer:d. Explanation:This functionality is covered by UML diagrams. 9. The is represented as two processing boxes connected by an line (arrow) of control. Repetition. Sequence. Condition. None of the above. Answer:b.""      ""width"": ""1024"" }                         323                  10. Which of the following term is best defined by the statement “Notation that can be input directly into a computer-based development system offers significant benefits.”? Machine readability Maintainability Structure enforcement Overall simplicity Answer:a Explanation:Readability is processing input.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/323/10.+Which+of+the+following+term+is+best+defined+by+the+statement+Notation+that+can+be+input+directly+into+a+computer-based+development.jpg""      ""name"": ""10. Which of the following term is best defined by the statement Notation that can be input directly into a computer-based development""      ""description"": ""system offers significant benefits. Machine readability. Maintainability. Structure enforcement. Overall simplicity. Answer:a. Explanation:Readability is processing input.""      ""width"": ""1024"" }                         324                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/324/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         325                  Debugging Techniques and ApproachesSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/325/Debugging+Techniques+and+Approaches.jpg""      ""name"": ""Debugging Techniques and Approaches""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         326                  1. What is testing process’ first goal?Bug prevention Testing Execution Analyses Answer:a Explanation:Its better to prevent a bug rather than putting time in its testing and removal. 2. Software mistakes during coding are known as errors failures bugs defects Answer:c Explanation:A software bug is an error  flaw  failure  or fault in a computer program or system that causes it to produce  an incorrect or unexpected result. 3. Name an evaluation technique to assess the quality of test cases. Mutation analysis Validation Verification Performance analysis Explanation:Mutation analysis is used to design new software tests and evaluate the quality of existing software tests.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/326/1.+What+is+testing+process%E2%80%99+first+goal.jpg""      ""name"": ""1. What is testing process’ first goal""      ""description"": ""Bug prevention. Testing. Execution. Analyses. Answer:a. Explanation:Its better to prevent a bug rather than putting time in its testing and removal. 2. Software mistakes during coding are known as. errors. failures. bugs. defects. Answer:c. Explanation:A software bug is an error  flaw  failure  or fault in a computer program or system that causes it to produce an incorrect or unexpected result. 3. Name an evaluation technique to assess the quality of test cases. Mutation analysis. Validation. Verification. Performance analysis. Explanation:Mutation analysis is used to design new software tests and evaluate the quality of existing software tests.""      ""width"": ""1024"" }                         327                  4. Test should be conducted for every possibledata case variable All of the mentioned Answer:d Explanation:It increases the scope for code inspection. 5. Which of the following is not a part of bug report? Test case Output Software Version LOC Explanation:Line of code(LOC) is immaterial during testing  as it is an exhaustive process. 6. Which of the following is not a part of Execution Flow during debugging? Step Over Step Into Step Up Step Out Answer:c Explanation:Step Into executes code  Step Out continues execution until bound value and Step Over is to execute  code without stopping.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/327/4.+Test+should+be+conducted+for+every+possible.jpg""      ""name"": ""4. Test should be conducted for every possible""      ""description"": ""data. case. variable. All of the mentioned. Answer:d. Explanation:It increases the scope for code inspection. 5. Which of the following is not a part of bug report Test case. Output. Software Version. LOC. Explanation:Line of code(LOC) is immaterial during testing  as it is an exhaustive process. 6. Which of the following is not a part of Execution Flow during debugging Step Over. Step Into. Step Up. Step Out. Answer:c. Explanation:Step Into executes code  Step Out continues execution until bound value and Step Over is to execute code without stopping.""      ""width"": ""1024"" }                         328                  7. Cyclomatic Complexity method comes under which testing method.Yellow box White box Gray box Black box Answer:b Explanation:Cyclomatic Complexity tells us about the number of indepoendent paths in a program which is covered in white box testing. 8. Which is a black box testing technique appropriate to all levels of testing? Acceptance testing Regression testing Equivalence partitioning Quality assurance Answer:c Explanation:Equivalence partitioning is a software testing technique that divides the input data of a software unit into  partitions of equivalent data from which test cases can be derived. 9. Which of the following is the way of ensuring that the tests are actually testing code? Control structure testing Complex path testing Code coverage Quality assurance of software Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/328/7.+Cyclomatic+Complexity+method+comes+under+which+testing+method..jpg""      ""name"": ""7. Cyclomatic Complexity method comes under which testing method.""      ""description"": ""Yellow box. White box. Gray box. Black box. Answer:b. Explanation:Cyclomatic Complexity tells us about the number of indepoendent paths in a program which is covered in white box testing. 8. Which is a black box testing technique appropriate to all levels of testing Acceptance testing. Regression testing. Equivalence partitioning. Quality assurance. Answer:c. Explanation:Equivalence partitioning is a software testing technique that divides the input data of a software unit into partitions of equivalent data from which test cases can be derived. 9. Which of the following is the way of ensuring that the tests are actually testing code Control structure testing. Complex path testing. Code coverage. Quality assurance of software. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         329                  10. Effective testing will reduce  	cost.maintenance design coding documentation Answer:a Explanation:Remaining options are a part of development process. 11. Which of the following is a common pointwer problem? Data sharing errors Accessing data elements of the wrong type Attempting to use memory areas after freeing them All of the mentioned Answer:d Explanation:These are the common errors programmers make while coding.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/329/10.+Effective+testing+will+reduce+cost..jpg""      ""name"": ""10. Effective testing will reduce cost.""      ""description"": ""maintenance. design. coding. documentation. Answer:a. Explanation:Remaining options are a part of development process. 11. Which of the following is a common pointwer problem Data sharing errors. Accessing data elements of the wrong type. Attempting to use memory areas after freeing them. All of the mentioned. Answer:d. Explanation:These are the common errors programmers make while coding.""      ""width"": ""1024"" }                         330                  Distributed Software EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/330/Distributed+Software+Engineering.jpg""      ""name"": ""Distributed Software Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         331                  1. Which of the following term is best defined by the statement “In a distributed system  several processes may  operate at the same time on separate computers on the network.”? Concurrency Openness Resource sharing Fault tolerance Answer:a Explanation:The answer is self explanatory. 2.Which of the following is not a dimension of scalability? Size Distribution Manageability Interception Answer:d Explanation:Interception is a communication conception. 3. A distributed system must defend itself against Modification Interruption Fabrication All of the mentioned  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/331/1.+Which+of+the+following+term+is+best+defined+by+the+statement+In+a+distributed+system%2C+several+processes+may+operate+at+the+same+time+on+separate+computers+on+the+network..jpg""      ""name"": ""1. Which of the following term is best defined by the statement In a distributed system  several processes may operate at the same time on separate computers on the network.""      ""description"": ""Concurrency. Openness. Resource sharing. Fault tolerance. Answer:a. Explanation:The answer is self explanatory. 2.Which of the following is not a dimension of scalability Size. Distribution. Manageability. Interception. Answer:d. Explanation:Interception is a communication conception. 3. A distributed system must defend itself against. Modification. Interruption. Fabrication. All of the mentioned.""      ""width"": ""1024"" }                         332                  4. QoS stands for Quality of security Quality of system Quality of service None of the mentioned Answer:c Explanation:QoS is particularly critical when the system is dealing with time-critical data such as sound or video streams. 5. In Java _ 	are comparable with  though not identical to  RPCs. Remote Method Invocations Operating System Client–server computing None of the above Answer:a Explanation:The RMI framework handles the invocation of remote methods in a Java program. 6.  	depend on there being a clear separation between the presentation of information and the computations that  create and process that information. Master-slave architectures Client–server systems Two-tier client–server architecture Both Master-slave architectures AND Client–server systems Answer:b Explanation:One should design the architecture of distributed client–server systems so that they are structured into  several logical layers  with clear interfaces between these layers.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/332/4.+QoS+stands+for+Quality+of+security.+Quality+of+system.+Quality+of+service.+None+of+the+mentioned..jpg""      ""name"": ""4. QoS stands for Quality of security. Quality of system. Quality of service. None of the mentioned.""      ""description"": ""Answer:c. Explanation:QoS is particularly critical when the system is dealing with time-critical data such as sound or video streams. 5. In Java _ are comparable with  though not identical to  RPCs. Remote Method Invocations. Operating System. Client–server computing. None of the above. Answer:a. Explanation:The RMI framework handles the invocation of remote methods in a Java program. 6. depend on there being a clear separation between the presentation of information and the computations that create and process that information. Master-slave architectures. Client–server systems. Two-tier client–server architecture. Both Master-slave architectures AND Client–server systems. Answer:b. Explanation:One should design the architecture of distributed client–server systems so that they are structured into several logical layers  with clear interfaces between these layers.""      ""width"": ""1024"" }                         333                  7. Which architecture is used when there is a high volume of transactions to be processed by the server? Multi-tier client–server architecture Master-slave architecture Distributed component architecture Peer-to-peer architecture Answer:a Explanation:Multi-tier systems may be used when applications need to access and use data from different databases. 8. Which architecture are reliant on middle-ware? Answer:c Explanation:It allows the system designer to delay decisions on where and how services should be provided. 9.  	is a way of providing functionality on a remote server with client access through a web browser. SaaS SOA Configurability both SaaS and Configurability Explanation:The server maintains the user’s data and state during an interaction session.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/333/7.+Which+architecture+is+used+when+there+is+a+high+volume+of+transactions+to+be+processed+by+the+server.jpg""      ""name"": ""7. Which architecture is used when there is a high volume of transactions to be processed by the server""      ""description"": ""Multi-tier client–server architecture. Master-slave architecture. Distributed component architecture. Peer-to-peer architecture. Answer:a. Explanation:Multi-tier systems may be used when applications need to access and use data from different databases. 8. Which architecture are reliant on middle-ware Answer:c. Explanation:It allows the system designer to delay decisions on where and how services should be provided. 9. is a way of providing functionality on a remote server with client access through a web browser. SaaS. SOA. Configurability. both SaaS and Configurability. Explanation:The server maintains the user’s data and state during an interaction session.""      ""width"": ""1024"" }                         334                  10. Which architecture decentralized architectures in which there are no distinguished clients and servers? Multi-tier client–server architecture Master-slave architecture Distributed component architecture Peer-to-peer architecture Answer:d Explanation:Peer-to-peer (p2p) systems are decentralized systems in which computations may  be carried out by any node on the network.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/334/10.+Which+architecture+decentralized+architectures+in+which+there+are+no+distinguished+clients+and+servers.jpg""      ""name"": ""10. Which architecture decentralized architectures in which there are no distinguished clients and servers""      ""description"": ""Multi-tier client–server architecture. Master-slave architecture. Distributed component architecture. Peer-to-peer architecture. Answer:d. Explanation:Peer-to-peer (p2p) systems are decentralized systems in which computations may be carried out by any node on the network.""      ""width"": ""1024"" }                         335                  Embedded Software Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/335/Embedded+Software+Source+%26+Courtsey%3A.jpg""      ""name"": ""Embedded Software Source &amp;amp; Courtsey:""      ""description"": ""Embedded Software Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         336                  1. Which of the following is a category of a stimuli?Periodic stimuli Software stimuli Hardware stimuli Management stimuli Answer:a Explanation: Periodic stimuli occur at predictable time intervals. For example  the system may examine a sensor  every 50 milliseconds and take action depending on that sensor value. 2. Which of the following activities may be included in a real-time software design process? Platform selection Timing analysis Process design All of the mentioned Answer:d Explanation: All these can be implemented. 3. Which of the following is not a real-time architectural pattern Observe and React Environmental Control Embedded System Process Pipeline Answer:c Explanation:Embedded systems’ patterns are process-oriented rather than object- or component-oriented .  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/336/1.+Which+of+the+following+is+a+category+of+a+stimuli.jpg""      ""name"": ""1. Which of the following is a category of a stimuli""      ""description"": ""Periodic stimuli. Software stimuli. Hardware stimuli. Management stimuli. Answer:a. Explanation: Periodic stimuli occur at predictable time intervals. For example  the system may examine a sensor every 50 milliseconds and take action depending on that sensor value. 2. Which of the following activities may be included in a real-time software design process Platform selection. Timing analysis. Process design. All of the mentioned. Answer:d. Explanation: All these can be implemented. 3. Which of the following is not a real-time architectural pattern. Observe and React. Environmental Control. Embedded System. Process Pipeline. Answer:c. Explanation:Embedded systems’ patterns are process-oriented rather than object- or component-oriented .""      ""width"": ""1024"" }                         337                  4. RTOS stands for real-life operating system real-time operating system real-time operating software real-life operating software Answer:b Explanation:Embedded applications are built on top of a real-time operating system (RTOS). 5. The times by which stimuli must be processed and some response produced by the system is known as Compile time Frequency Deadlines Execution time Answer:c Explanation:If the system does not meet a deadline then  it results in a system failure; in a soft real-time system  it  results in degraded system service. 6. The switch to backup power must be completed within a deadline of 50 ms 55 ms 70 ms 100 ms Answer:a Explanation:The time required to power failure stimuli is 50 millisecond.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/337/4.+RTOS+stands+for+real-life+operating+system.+real-time+operating+system.+real-time+operating+software..jpg""      ""name"": ""4. RTOS stands for real-life operating system. real-time operating system. real-time operating software.""      ""description"": ""real-life operating software. Answer:b. Explanation:Embedded applications are built on top of a real-time operating system (RTOS). 5. The times by which stimuli must be processed and some response produced by the system is known as. Compile time. Frequency. Deadlines. Execution time. Answer:c. Explanation:If the system does not meet a deadline then  it results in a system failure; in a soft real-time system  it results in degraded system service. 6. The switch to backup power must be completed within a deadline of. 50 ms. 55 ms. 70 ms. 100 ms. Answer:a. Explanation:The time required to power failure stimuli is 50 millisecond.""      ""width"": ""1024"" }                         338                  7. An example of a system that may use a process pipeline is a  	_.High-speed data acquisition system Failure of a power supply in an embedded system Both High-speed data acquisition system AND Failure of a power supply in an embedded system None of the mentioned Answer:a Explanation:Data acquisition systems collect data from sensors for subsequent processing and analysis. These systems are used in situations where the sensors are collecting a lot of data from the system’s environment and it isn’t possible or necessary to process that data in real time. 8. Periodic occur irregularly and unpredictably and are usually signaled using the computer’s interrupt mechanism. True False Answer:b Explanation: This is the case for Aperiodic stimuli 9. If you detect power failure by monitoring a voltage level  you have to make more than one observation to detect  that the voltage is dropping. Explanation:If you run the process 250 times per second  this means that it runs every 4 ms and you may require up  to two periods to detect the voltage drop.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/338/7.+An+example+of+a+system+that+may+use+a+process+pipeline+is+a+_..jpg""      ""name"": ""7. An example of a system that may use a process pipeline is a _.""      ""description"": ""High-speed data acquisition system. Failure of a power supply in an embedded system. Both High-speed data acquisition system AND Failure of a power supply in an embedded system. None of the mentioned. Answer:a. Explanation:Data acquisition systems collect data from sensors for subsequent processing and analysis. These systems are used in situations where the sensors are collecting a lot of data from the system’s environment and it isn’t possible or necessary to process that data in real time. 8. Periodic occur irregularly and unpredictably and are usually signaled using the computer’s interrupt mechanism. True. False. Answer:b. Explanation: This is the case for Aperiodic stimuli. 9. If you detect power failure by monitoring a voltage level  you have to make more than one observation to detect that the voltage is dropping. Explanation:If you run the process 250 times per second  this means that it runs every 4 ms and you may require up to two periods to detect the voltage drop.""      ""width"": ""1024"" }                         339                  10. The average execution time of the power monitor process should be less than1ms 10ms 100ms none of the above Answer:a Explanation:General embedded software property.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/339/10.+The+average+execution+time+of+the+power+monitor+process+should+be+less+than.jpg""      ""name"": ""10. The average execution time of the power monitor process should be less than""      ""description"": ""1ms. 10ms. 100ms. none of the above. Answer:a. Explanation:General embedded software property.""      ""width"": ""1024"" }                         340                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/340/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         341                  Emperical Estimation ModelsSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/341/Emperical+Estimation+Models.jpg""      ""name"": ""Emperical Estimation Models""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         342                  1. Which of the following uses empirically derived formulas to predict effort as a function of LOC or FP? FP-Based Estimation Process-Based Estimation COCOMO Both FP-Based Estimation and COCOMO Answer:d Explanation:Function points and COCOMO are used to evaluate effort. 2. The empirical data that support most estimation models are derived from a vast sample of projects. True False Answer:b Explanation:The emperical data is derived from a limited sample of projects. For this reason  no estimation  model is appropriate for all classes of software and in all development environments. 3. COCOMO stands for Constructive cost model Comprehensive cost model Constructive cost estimation model Complete cost estimation model Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/342/1.+Which+of+the+following+uses+empirically+derived+formulas+to+predict+effort+as+a+function+of+LOC+or+FP.jpg""      ""name"": ""1. Which of the following uses empirically derived formulas to predict effort as a function of LOC or FP""      ""description"": ""FP-Based Estimation. Process-Based Estimation. COCOMO. Both FP-Based Estimation and COCOMO. Answer:d. Explanation:Function points and COCOMO are used to evaluate effort. 2. The empirical data that support most estimation models are derived from a vast sample of projects. True. False. Answer:b. Explanation:The emperical data is derived from a limited sample of projects. For this reason  no estimation model is appropriate for all classes of software and in all development environments. 3. COCOMO stands for. Constructive cost model. Comprehensive cost model. Constructive cost estimation model. Complete cost estimation model. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         343                  4. Which version of COCOMO states that once requirements have been stabilized  the basic software architecture has been established? Early design stage model Post-architecture-stage model Application composition model Answer:a Explanation:The answer is self explanatory. 5. Which model was used during the early stages of software engineering  when prototyping of user interfaces   consideration of software and system interaction  assessment of performance  and evaluation of technology maturity  were paramount. Answer:c Explanation:None. 6. Which one is not a size measure for software product? a) LOC b) Halstead’s program length Function Count Cyclomatic Complexity Answer:d Explanation:It is the part of white box testing.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/343/4.+Which+version+of+COCOMO+states+that+once+requirements+have+been+stabilized%2C+the+basic+software+architecture+has+been+established.jpg""      ""name"": ""4. Which version of COCOMO states that once requirements have been stabilized  the basic software architecture has been established""      ""description"": ""Early design stage model. Post-architecture-stage model. Application composition model. Answer:a. Explanation:The answer is self explanatory. 5. Which model was used during the early stages of software engineering  when prototyping of user interfaces  consideration of software and system interaction  assessment of performance  and evaluation of technology maturity were paramount. Answer:c Explanation:None. 6. Which one is not a size measure for software product a) LOC. b) Halstead’s program length. Function Count. Cyclomatic Complexity. Answer:d. Explanation:It is the part of white box testing.""      ""width"": ""1024"" }                         344                  7.COCOMO was developed initially byB.Beizer Rajiv Gupta B.W.Bohem Gregg Rothermal Answer:c Explanation:Barry Boehm introduced a hierarchy of software estimation models bearing the name COCOMO  for  COnstructive COst MOdel. 8. Estimation of size for a project is dependent on Cost Time Schedule None of the mentioned Answer:d Explanation:Estimation depends on factors such as Fucntion points and LOC. 9. COCOMO-II was developed at University of Texas University of Southern California MIT IIT-Kanpur Answer:b Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/344/7.COCOMO+was+developed+initially+by.jpg""      ""name"": ""7.COCOMO was developed initially by""      ""description"": ""B.Beizer. Rajiv Gupta. B.W.Bohem. Gregg Rothermal. Answer:c. Explanation:Barry Boehm introduced a hierarchy of software estimation models bearing the name COCOMO  for COnstructive COst MOdel. 8. Estimation of size for a project is dependent on. Cost. Time. Schedule. None of the mentioned. Answer:d. Explanation:Estimation depends on factors such as Fucntion points and LOC. 9. COCOMO-II was developed at. University of Texas. University of Southern California. MIT. IIT-Kanpur. Answer:b. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         345                  10. Which one is not a stage of COCOMO-II?Early design estimation model Application Composition estimation model Comprehensive cost estimation model Post architecture estimation model Answer:a Explanation:It was a part of COCOMO.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/345/10.+Which+one+is+not+a+stage+of+COCOMO-II.jpg""      ""name"": ""10. Which one is not a stage of COCOMO-II""      ""description"": ""Early design estimation model. Application Composition estimation model. Comprehensive cost estimation model. Post architecture estimation model. Answer:a. Explanation:It was a part of COCOMO.""      ""width"": ""1024"" }                         346                  Managing Software Projects – 2Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/346/Managing+Software+Projects+%E2%80%93+2.jpg""      ""name"": ""Managing Software Projects – 2""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         347                  1. Which paradigm relies on the natural compartmentalization of a problem and organizes team members to work  on pieces of the problem with little active communication among themselves? random paradigm open paradigm closed paradigm synchronous paradigm Answer:c Explanation:The answer is self explanatory. 2. Who interacts with the software once it is released for production use? End-users Client Project (technical) managers Senior managers Answer:a Explanation:A product is always built to satisfy an end-user. 3. Which of the following is not an effective project manager trait? Problem solving Managerial identity Influence and team building None of the mentioned Answer:d Explanation:All are key traits of an effective project manager.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/347/1.+Which+paradigm+relies+on+the+natural+compartmentalization+of+a+problem+and+organizes+team+members+to+work+on+pieces+of+the+problem+with+little+active+communication+among+themselves.jpg""      ""name"": ""1. Which paradigm relies on the natural compartmentalization of a problem and organizes team members to work on pieces of the problem with little active communication among themselves""      ""description"": ""random paradigm. open paradigm. closed paradigm. synchronous paradigm. Answer:c. Explanation:The answer is self explanatory. 2. Who interacts with the software once it is released for production use End-users. Client. Project (technical) managers. Senior managers. Answer:a. Explanation:A product is always built to satisfy an end-user. 3. Which of the following is not an effective project manager trait Problem solving. Managerial identity. Influence and team building. None of the mentioned. Answer:d. Explanation:All are key traits of an effective project manager.""      ""width"": ""1024"" }                         348                  4. Which type of software engineering team has a defined leader who coordinates specific tasks and secondary leaders that have responsibility for sub tasks? Controlled decentralized (CD) Democratic decentralized (DD) Controlled centralized (CC) None of the mentioned Answer:a Explanation:Problem solving remains a group activity  but implementation of solutions is partitioned among subgroups by  the team leader. 5. Commitments to unrealistic time and resource estimates may result in project delay poor quality work project failure All of the mentioned Answer:d Explanation:The answer is self explanatory. 6. Which software engineering team has no permanent leader? Controlled Centralized (CC) None of the above Answer:b Explanation:Here Communication among team members is horizontal.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/348/4.+Which+type+of+software+engineering+team+has+a+defined+leader+who+coordinates+specific+tasks+and+secondary+leaders+that+have+responsibility+for+sub+tasks.jpg""      ""name"": ""4. Which type of software engineering team has a defined leader who coordinates specific tasks and secondary leaders that have responsibility for sub tasks""      ""description"": ""Controlled decentralized (CD) Democratic decentralized (DD) Controlled centralized (CC) None of the mentioned. Answer:a. Explanation:Problem solving remains a group activity  but implementation of solutions is partitioned among subgroups by the team leader. 5. Commitments to unrealistic time and resource estimates may result in. project delay. poor quality work. project failure. All of the mentioned. Answer:d. Explanation:The answer is self explanatory. 6. Which software engineering team has no permanent leader Controlled Centralized (CC) None of the above. Answer:b. Explanation:Here Communication among team members is horizontal.""      ""width"": ""1024"" }                         349                  7. Which of the following is not a project factor that should be considered when planning the structure of software engineering teams? The difficulty of the problem to be solved High frustration caused by personal  business  or technological factors that causes friction among team members The degree of sociability required for the project The rigidity of the delivery date Answer:c Explanation:Development is irrelevant of social quotient. 8. Which of the following is a collection of project coordination technique? Formal approaches Formal  interpersonal procedures Informal  interpersonal procedures All of the mentioned Answer:d Explanation:The answer is self explanatory. 9. Which activity sits at the core of software requirements analysis? Problem decomposition Partitioning Problem elaboration Explanation:During the scoping activity decomposition is applied in two major areas: the functionality that must be  delivered and the process that will be used to deliver it.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/349/7.+Which+of+the+following+is+not+a+project+factor+that+should+be+considered+when+planning+the+structure+of+software+engineering+teams.jpg""      ""name"": ""7. Which of the following is not a project factor that should be considered when planning the structure of software engineering teams""      ""description"": ""The difficulty of the problem to be solved. High frustration caused by personal  business  or technological factors that causes friction among team members. The degree of sociability required for the project. The rigidity of the delivery date. Answer:c. Explanation:Development is irrelevant of social quotient. 8. Which of the following is a collection of project coordination technique Formal approaches. Formal  interpersonal procedures. Informal  interpersonal procedures. All of the mentioned. Answer:d. Explanation:The answer is self explanatory. 9. Which activity sits at the core of software requirements analysis Problem decomposition. Partitioning. Problem elaboration. Explanation:During the scoping activity decomposition is applied in two major areas: the functionality that must be delivered and the process that will be used to deliver it.""      ""width"": ""1024"" }                         350                  10. Which of the following is not a sign that indicates that an information systems project is in jeopardy? a) Software people don’t understand their customer’s needs. Changes are managed poorly. Sponsorship is gained. Users are resistant. Answer:c Explanation:Other options are contradictory of the question. 11. SPMP stands for Software Project Manager’s Plan Software Project Management Plan Software Product Management Plan d) Software Product Manager’s Plan Answer:b Explanation:After planning is complete  documenting of the plans is done in a Software Project Management Plan(SPMP) document.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/350/10.+Which+of+the+following+is+not+a+sign+that+indicates+that+an+information+systems+project+is+in+jeopardy.jpg""      ""name"": ""10. Which of the following is not a sign that indicates that an information systems project is in jeopardy""      ""description"": ""a) Software people don’t understand their customer’s needs. Changes are managed poorly. Sponsorship is gained. Users are resistant. Answer:c. Explanation:Other options are contradictory of the question. 11. SPMP stands for. Software Project Manager’s Plan. Software Project Management Plan. Software Product Management Plan. d) Software Product Manager’s Plan. Answer:b. Explanation:After planning is complete  documenting of the plans is done in a Software Project Management Plan(SPMP) document.""      ""width"": ""1024"" }                         351                  Formal Methods of Software EngineeringSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/351/Formal+Methods+of+Software+Engineering.jpg""      ""name"": ""Formal Methods of Software Engineering""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         352                  1. Which of the following option is not provided by formal methods?providing frameworks verifying systems provide investors both providing frameworks and verifying systems Answer:d Explanation:A method is formal if it has a sound mathematical basis  typically given by a formal specification language. 2.  	are statements that can be interpreted in a number of ways. Contradictions Ambiguities Vagueness Comments Answer:a Explanation:As the name indicates  these statements may be interpreted differently as per user. 3. What defines the circumstances in which a particular operation is valid? Post-condition None of the mentioned Explanation:A precondition defines the circumstances in which a particular operation is valid.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/352/1.+Which+of+the+following+option+is+not+provided+by+formal+methods.jpg""      ""name"": ""1. Which of the following option is not provided by formal methods""      ""description"": ""providing frameworks. verifying systems. provide investors. both providing frameworks and verifying systems. Answer:d. Explanation:A method is formal if it has a sound mathematical basis  typically given by a formal specification language. 2. are statements that can be interpreted in a number of ways. Contradictions. Ambiguities. Vagueness. Comments. Answer:a. Explanation:As the name indicates  these statements may be interpreted differently as per user. 3. What defines the circumstances in which a particular operation is valid Post-condition. None of the mentioned. Explanation:A precondition defines the circumstances in which a particular operation is valid.""      ""width"": ""1024"" }                         353                  4. Which of the following is a way of making a statement about the elements of a set that is true for every member of the set? Set Sequence Universal quantification both Set and Sequence Answer:c Explanation:The answer is self explanatory. 5. Which of the following occurs often due to the bulkiness of a system specification document? Contradictions Ambiguities Vagueness Incompleteness Explanation:Achieving a high level of precision consistently is an almost impossible task. 6. The  	of a formal specification language is often based on a syntax that is derived from standard set theory  notation and predicate calculus. semantic domain syntactic domain sequence set Answer:b Explanation:The answer is self explanatory  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/353/4.+Which+of+the+following+is+a+way+of+making+a+statement+about+the+elements+of+a+set+that+is+true+for+every+member+of+the+set.jpg""      ""name"": ""4. Which of the following is a way of making a statement about the elements of a set that is true for every member of the set""      ""description"": ""Set. Sequence. Universal quantification. both Set and Sequence. Answer:c. Explanation:The answer is self explanatory. 5. Which of the following occurs often due to the bulkiness of a system specification document Contradictions. Ambiguities. Vagueness. Incompleteness. Explanation:Achieving a high level of precision consistently is an almost impossible task. 6. The of a formal specification language is often based on a syntax that is derived from standard set theory notation and predicate calculus. semantic domain. syntactic domain. sequence. set. Answer:b. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         354                  7. Which of the following provides a concise  unambiguous  and consistent method for documenting system requirements? CMM ISO-9001 CASE tools Formal methods Answer:d Explanation:Formal methods provide a concise  unambiguous  and consistent method for documenting system requirements. 8. The  	of a specification language indicates how the language represents system requirements. semantic domain syntactic domain sequence set Answer:a Explanation:For example  a programming language has a set of formal semantics that enables the software developer to  specify algorithms that transform input to output. 9. Which of the following is essential for success  when formal methods are used for the first time? Expert training Consulting Pre-requisite knowledge Both Expert training and Consulting All of the mentioned Explanation:The answer is self-explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/354/7.+Which+of+the+following+provides+a+concise%2C+unambiguous%2C+and+consistent+method+for+documenting+system+requirements.jpg""      ""name"": ""7. Which of the following provides a concise  unambiguous  and consistent method for documenting system requirements""      ""description"": ""CMM. ISO CASE tools. Formal methods. Answer:d. Explanation:Formal methods provide a concise  unambiguous  and consistent method for documenting system requirements. 8. The of a specification language indicates how the language represents system requirements. semantic domain. syntactic domain. sequence. set. Answer:a. Explanation:For example  a programming language has a set of formal semantics that enables the software developer to specify algorithms that transform input to output. 9. Which of the following is essential for success  when formal methods are used for the first time Expert training. Consulting. Pre-requisite knowledge. Both Expert training and Consulting. All of the mentioned. Explanation:The answer is self-explanatory.""      ""width"": ""1024"" }                         355                  10. It is generally not necessary to apply formal methods to every aspect of a major system.True False Answer:a Explanation:Those components that are safety critical are first choices  followed by components whose failure cannot be tolerated.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/355/10.+It+is+generally+not+necessary+to+apply+formal+methods+to+every+aspect+of+a+major+system..jpg""      ""name"": ""10. It is generally not necessary to apply formal methods to every aspect of a major system.""      ""description"": ""True. False. Answer:a. Explanation:Those components that are safety critical are first choices  followed by components whose failure cannot be tolerated.""      ""width"": ""1024"" }                         356                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/356/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         357                  Object Oriented TestingSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/357/Object+Oriented+Testing.jpg""      ""name"": ""Object Oriented Testing""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         358                  1. The architecture of object-oriented software results in a series of layered subsystems that encapsulate collaborating  classes. True False Answer:a Explanation:It is necessary to test an OO system at a variety of different levels in an effort to uncover errors that may occur  as classes collaborate with one another and subsystems communicate across architectural layers. 2.The construction of object-oriented software begins with the creation of design model analysis model code levels both design and analysis model Answer:d Explanation:It is due to the evolutionary nature of the OO software engineering paradigm  these models begin as relatively informal representations of system requirements and evolve into detailed models of classes  class connections and relationships  system design and allocation  and object design. 3. Which testing integrates the set of classes required to respond to one input or event for the system? cluster testing thread-based testing use-based testing none of the mentioned Answer:b Explanation:Each thread is integrated and tested individually. Regression testing is applied to ensure that no side effects occur.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/358/1.+The+architecture+of+object-oriented+software+results+in+a+series+of+layered+subsystems+that+encapsulate+collaborating+classes..jpg""      ""name"": ""1. The architecture of object-oriented software results in a series of layered subsystems that encapsulate collaborating classes.""      ""description"": ""True. False. Answer:a. Explanation:It is necessary to test an OO system at a variety of different levels in an effort to uncover errors that may occur as classes collaborate with one another and subsystems communicate across architectural layers. 2.The construction of object-oriented software begins with the creation of. design model. analysis model. code levels. both design and analysis model. Answer:d. Explanation:It is due to the evolutionary nature of the OO software engineering paradigm  these models begin as relatively informal representations of system requirements and evolve into detailed models of classes  class connections and relationships  system design and allocation  and object design. 3. Which testing integrates the set of classes required to respond to one input or event for the system cluster testing. thread-based testing. use-based testing. none of the mentioned. Answer:b. Explanation:Each thread is integrated and tested individually. Regression testing is applied to ensure that no side effects occur.""      ""width"": ""1024"" }                         359                  4. Which of the following is one of the steps in the integration testing of OO software?cluster testing thread-based testing use-based testing none of the above Answer:a Explanation:Here  a cluster of collaborating classes is exercised by designing test cases that attempt to uncover errors in  the collaborations. 5.  	methods can be used to drive validations tests Yellow-box testing Black-box testing White-box testing All of the mentioned Answer:b Explanation:Black-box testing methods are as appropriate for OO systems as they are for systems developed using  conventional software engineering methods. 6. Which of the following is a part of testing OO code? Validation tests Integration tests Class tests System tests Answer:c Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/359/4.+Which+of+the+following+is+one+of+the+steps+in+the+integration+testing+of+OO+software.jpg""      ""name"": ""4. Which of the following is one of the steps in the integration testing of OO software""      ""description"": ""cluster testing. thread-based testing. use-based testing. none of the above. Answer:a. Explanation:Here  a cluster of collaborating classes is exercised by designing test cases that attempt to uncover errors in the collaborations. 5. methods can be used to drive validations tests. Yellow-box testing. Black-box testing. White-box testing. All of the mentioned. Answer:b. Explanation:Black-box testing methods are as appropriate for OO systems as they are for systems developed using conventional software engineering methods. 6. Which of the following is a part of testing OO code Validation tests. Integration tests. Class tests. System tests. Answer:c. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         360                  7. The object of  	within an OO system is to design tests that have a high likelihood of uncovering plausible bugs. Fault-based testing Integration testing Use-based testing Scenario-based testing Answer:a Explanation:The object of fault-based testing within an OO system is to design tests that have a high likelihood of uncovering  plausible faults. 8. What refers to the externally observable structure of an OO program? Deep structure Surface structure Core structure All of the above Answer:b Explanation:Surface structure refers to the externally observable structure of an OO program which is immediately obvious to an  end- user. 9.  	categorizes class operations based on the generic function that each performs Category-based partitioning Attribute-based partitioning State-based partitioning None of the mentioned Explanation:For example  operations in the account class can be categorized in initialization operations (open  setup)   computational operations (deposit withdraw) etc.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/360/7.+The+object+of+within+an+OO+system+is+to+design+tests+that+have+a+high+likelihood+of+uncovering+plausible+bugs..jpg""      ""name"": ""7. The object of within an OO system is to design tests that have a high likelihood of uncovering plausible bugs.""      ""description"": ""Fault-based testing. Integration testing. Use-based testing. Scenario-based testing. Answer:a. Explanation:The object of fault-based testing within an OO system is to design tests that have a high likelihood of uncovering plausible faults. 8. What refers to the externally observable structure of an OO program Deep structure. Surface structure. Core structure. All of the above. Answer:b. Explanation:Surface structure refers to the externally observable structure of an OO program which is immediately obvious to an end- user. 9. categorizes class operations based on the generic function that each performs. Category-based partitioning. Attribute-based partitioning. State-based partitioning. None of the mentioned. Explanation:For example  operations in the account class can be categorized in initialization operations (open  setup)  computational operations (deposit withdraw) etc.""      ""width"": ""1024"" }                         361                  10. Which of the following is black-box oriented and can be accomplished by applying the same black-box methods discussed for conventional software? Conventional testing OO system validation testing Test case design Both Conventional testing and OO system validation testing Answer:d Explanation:The answer is self explanatory. 11. In which of the following testing strategies  a smallest testable unit is the encapsulated class or object? Unit testing Integration testing System testing None of the mentioned Answer:a 12. Which of the following testing types is not a part of system testing? Recovery testing Stress testing Random testing Explanation:It is a testing method at class level.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/361/10.+Which+of+the+following+is+black-box+oriented+and+can+be+accomplished+by+applying+the+same+black-box+methods+discussed+for+conventional+software.jpg""      ""name"": ""10. Which of the following is black-box oriented and can be accomplished by applying the same black-box methods discussed for conventional software""      ""description"": ""Conventional testing. OO system validation testing. Test case design. Both Conventional testing and OO system validation testing. Answer:d. Explanation:The answer is self explanatory. 11. In which of the following testing strategies  a smallest testable unit is the encapsulated class or object Unit testing. Integration testing. System testing. None of the mentioned. Answer:a. 12. Which of the following testing types is not a part of system testing Recovery testing. Stress testing. Random testing. Explanation:It is a testing method at class level.""      ""width"": ""1024"" }                         362                  Object Oriented Design using UMLSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/362/Object+Oriented+Design+using+UML.jpg""      ""name"": ""Object Oriented Design using UML""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         363                  1. Which of the following is not needed to develop a system design from concept to detailed object-oriented design? Designing system architecture Developing design models Specifying interfaces Developing a debugging system Answer:d Explanation:The debugging system is a part of testing phase. 2. Which of the following is a dynamic model that shows how the system interacts with its environment as it is used? system context model interaction model environmental model both system context and interaction Answer:b Explanation:The answer is self explanatory. 3. Which of the following is a structural model that demonstrates the other systems in the environment of the system being developed? Answer:a Explanation:The context model of a system may be represented using associations. Associations simply show that there  are some relationships between the entities involved in the association.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/363/1.+Which+of+the+following+is+not+needed+to+develop+a+system+design+from+concept+to+detailed+object-oriented+design.jpg""      ""name"": ""1. Which of the following is not needed to develop a system design from concept to detailed object-oriented design""      ""description"": ""Designing system architecture. Developing design models. Specifying interfaces. Developing a debugging system. Answer:d. Explanation:The debugging system is a part of testing phase. 2. Which of the following is a dynamic model that shows how the system interacts with its environment as it is used system context model. interaction model. environmental model. both system context and interaction. Answer:b. Explanation:The answer is self explanatory. 3. Which of the following is a structural model that demonstrates the other systems in the environment of the system being developed Answer:a. Explanation:The context model of a system may be represented using associations. Associations simply show that there are some relationships between the entities involved in the association.""      ""width"": ""1024"" }                         364                  4. Which of the following come under system control?Reconfigure Shutdown Powersave All of the mentioned Answer:d Explanation: Functionalities are governed by the system. 5. We use  	where various parts of system use are identified and analyzed in turn. tangible entities scenario-based analysis design-based analysis None of the mentioned Answer:b Explanation:Use a scenario-based analysis where various scenarios of system use are identified and analyzed in turn. 6. Which model describes the static structure of the system using object classes and their relationships? Sequence model Subsystem model Dynamic model Structural model Explanation:Important relationships that may be documented at this stage are generalization (inheritance)  relationships  uses/used-by relationships  and composition relationships.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/364/4.+Which+of+the+following+come+under+system+control.jpg""      ""name"": ""4. Which of the following come under system control""      ""description"": ""Reconfigure. Shutdown. Powersave. All of the mentioned. Answer:d. Explanation: Functionalities are governed by the system. 5. We use where various parts of system use are identified and analyzed in turn. tangible entities. scenario-based analysis. design-based analysis. None of the mentioned. Answer:b. Explanation:Use a scenario-based analysis where various scenarios of system use are identified and analyzed in turn. 6. Which model describes the static structure of the system using object classes and their relationships Sequence model. Subsystem model. Dynamic model. Structural model. Explanation:Important relationships that may be documented at this stage are generalization (inheritance) relationships  uses/used-by relationships  and composition relationships.""      ""width"": ""1024"" }                         365                  7. Which model shows the flow of object interactions?Sequence model Subsystem model Dynamic model Both Sequence and Dynamic model Answer:a Explanation.Sequence model are represented using a UML sequence or a collaboration diagram and are dynamic models. 8. If the system state is Shutdown then it can respond to which of the following message? restart() reconfigure() powerSave() All of the mentioned Answer:d Explanation:A restart() message causes a transition to normal operation. Both the powerSave() and reconfigure() messages  cause a transition to a state in which the system reconfigures itself. 9. Which message is received so that the system moves to the Testing state  then the Transmitting state  before returning to the Running state? signalStatus() remoteControl() reportStatus() Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/365/7.+Which+model+shows+the+flow+of+object+interactions.jpg""      ""name"": ""7. Which model shows the flow of object interactions""      ""description"": ""Sequence model. Subsystem model. Dynamic model. Both Sequence and Dynamic model. Answer:a. Explanation.Sequence model are represented using a UML sequence or a collaboration diagram and are dynamic models. 8. If the system state is Shutdown then it can respond to which of the following message restart() reconfigure() powerSave() All of the mentioned. Answer:d. Explanation:A restart() message causes a transition to normal operation. Both the powerSave() and reconfigure() messages cause a transition to a state in which the system reconfigures itself. 9. Which message is received so that the system moves to the Testing state  then the Transmitting state  before returning to the. Running state signalStatus() remoteControl() reportStatus() Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         366                  10. Open source development involves making the source code of a system publicly available.True False Answer:a Explanation:This means that many people can propose changes and improvements to the software.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/366/10.+Open+source+development+involves+making+the+source+code+of+a+system+publicly+available..jpg""      ""name"": ""10. Open source development involves making the source code of a system publicly available.""      ""description"": ""True. False. Answer:a. Explanation:This means that many people can propose changes and improvements to the software.""      ""width"": ""1024"" }                         367                  Project Management Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/367/Project+Management+Source+%26+Courtsey%3A.jpg""      ""name"": ""Project Management Source &amp;amp; Courtsey:""      ""description"": ""Project Management Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         368                  1. Which of the following is not project management goal?Keeping overall costs within budget. Delivering the software to the customer at the agreed time. Maintaining a happy and well-functioning development team. Avoiding costumer complaints. Answer:d Explanation:Projects need to be managed because professional software engineering is always subject to  organizational budget and schedule constraints. 2. Project managers have to assess the risks that may affect a project. True False Answer:b Explanation:Risk management involves anticipating risks that might affect the project schedule or the quality  of the software being developed  and then taking action to avoid these risks. 3. Which of the following is not considered as a risk in project management? Specification delays Product competition Testing Staff turnover Answer:c Explanation:Testing is a part of project  thus it can’t be categorized as risk.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/368/1.+Which+of+the+following+is+not+project+management+goal.jpg""      ""name"": ""1. Which of the following is not project management goal""      ""description"": ""Keeping overall costs within budget. Delivering the software to the customer at the agreed time. Maintaining a happy and well-functioning development team. Avoiding costumer complaints. Answer:d. Explanation:Projects need to be managed because professional software engineering is always subject to organizational budget and schedule constraints. 2. Project managers have to assess the risks that may affect a project. True. False. Answer:b. Explanation:Risk management involves anticipating risks that might affect the project schedule or the quality of the software being developed  and then taking action to avoid these risks. 3. Which of the following is not considered as a risk in project management Specification delays. Product competition. Testing. Staff turnover. Answer:c. Explanation:Testing is a part of project  thus it can’t be categorized as risk.""      ""width"": ""1024"" }                         369                  4. The process each manager follows during the life of a project is known asProject Management Manager life cycle Project Management Life Cycle All of the mentioned Answer:c Explanation:A proven methodical life cycle is necessary to repeatedly implement and manage projects successfully. 5. A 66.6% risk is considered as very low low moderate high very high Answer:d Explanation:The probability of the risk might be assessed as very low (<10%)  low (10–25%)  moderate (25–50%)  high (50– 75%)  or very high (>75%). 6. Which of the following is/are main parameters that you should use when computing the costs of a software development project? travel and training costs hardware and software costs effort costs (the costs of paying software engineers and managers) Explanation:Estimation involves working out how much effort is required to complete each activity and  from this  calculating the  total cost of activities.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/369/4.+The+process+each+manager+follows+during+the+life+of+a+project+is+known+as.jpg""      ""name"": ""4. The process each manager follows during the life of a project is known as""      ""description"": ""Project Management. Manager life cycle. Project Management Life Cycle. All of the mentioned. Answer:c. Explanation:A proven methodical life cycle is necessary to repeatedly implement and manage projects successfully. 5. A 66.6% risk is considered as. very low. low. moderate. high. very high. Answer:d. Explanation:The probability of the risk might be assessed as very low (&amp;lt;10%)  low (10–25%)  moderate (25–50%)  high (50– 75%)  or very high (&amp;gt;75%). 6. Which of the following is/are main parameters that you should use when computing the costs of a software development project travel and training costs. hardware and software costs. effort costs (the costs of paying software engineers and managers) Explanation:Estimation involves working out how much effort is required to complete each activity and  from this  calculating the total cost of activities.""      ""width"": ""1024"" }                         370                  7. Quality planning is the process of developing a quality plan forteam project customers project manager Answer:b Explanation: The quality plan should set out the desired software qualities and describe how these are to be assessed. 8. Which of the following is incorrect activity for the configuration management of a software system? Internship management Change management Version management System management Answer:a Explanation:Configuration management policies and processes define how to record and process proposed system changes  how to decide what system components to change  how to manage different versions of the system and its components  and how to distribute changes to customers. 9. Identify the sub-process of process improvement Process introduction Process analysis De-processification Process distribution Explanation:The current process is assessed  and process weaknesses and bottlenecks are identified.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/370/7.+Quality+planning+is+the+process+of+developing+a+quality+plan+for.jpg""      ""name"": ""7. Quality planning is the process of developing a quality plan for""      ""description"": ""team. project. customers. project manager. Answer:b. Explanation: The quality plan should set out the desired software qualities and describe how these are to be assessed. 8. Which of the following is incorrect activity for the configuration management of a software system Internship management. Change management. Version management. System management. Answer:a. Explanation:Configuration management policies and processes define how to record and process proposed system changes  how to decide what system components to change  how to manage different versions of the system and its components  and how to distribute changes to customers. 9. Identify the sub-process of process improvement. Process introduction. Process analysis. De-processification. Process distribution. Explanation:The current process is assessed  and process weaknesses and bottlenecks are identified.""      ""width"": ""1024"" }                         371                  10. An independent relationship must exist between the attribute that can be measured and the external quality attribute. True False Answer:b Explanation:The value of the quality attribute must be related  in some way  to the value of the attribute than can be measured.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/371/10.+An+independent+relationship+must+exist+between+the+attribute+that+can+be+measured+and+the+external+quality+attribute..jpg""      ""name"": ""10. An independent relationship must exist between the attribute that can be measured and the external quality attribute.""      ""description"": ""True. False. Answer:b. Explanation:The value of the quality attribute must be related  in some way  to the value of the attribute than can be measured.""      ""width"": ""1024"" }                         372                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/372/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         373                  Project Planning Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/373/Project+Planning+Source+%26+Courtsey%3A.jpg""      ""name"": ""Project Planning Source &amp;amp; Courtsey:""      ""description"": ""Project Planning Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         374                  1. Which of the following is an important factor that can affect the accuracy and efficacy of estimates? Project size Planning process Project complexity Degree of structural uncertainty Answer:a Explanation:As size increases  the inter-dependency among various elements of the software grows rapidly. 2. What describes the data and control to be processed? Software scope External hardware Answer:b Explanation:Functions described in the statement of scope are evaluated and in some cases refined to provide more detail prior to  the beginning of estimation. 3. A number of independent investigators have developed a team-oriented approach to requirements gathering that can be applied to establish the scope of a project called JAD CLASS FAST None of the mentioned Answer:c Explanation:Facilitated application specification techniques (FAST)  this approach encourages the creation of a joint team of customers and developers who work together to identify the problem  propose elements  of the solution  negotiate different approaches  and specify a preliminary set of requirements.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/374/1.+Which+of+the+following+is+an+important+factor+that+can+affect+the+accuracy+and+efficacy+of+estimates.jpg""      ""name"": ""1. Which of the following is an important factor that can affect the accuracy and efficacy of estimates""      ""description"": ""Project size. Planning process. Project complexity. Degree of structural uncertainty. Answer:a. Explanation:As size increases  the inter-dependency among various elements of the software grows rapidly. 2. What describes the data and control to be processed Software scope. External hardware. Answer:b. Explanation:Functions described in the statement of scope are evaluated and in some cases refined to provide more detail prior to the beginning of estimation. 3. A number of independent investigators have developed a team-oriented approach to requirements gathering that can be applied to establish the scope of a project called. JAD. CLASS. FAST. None of the mentioned. Answer:c. Explanation:Facilitated application specification techniques (FAST)  this approach encourages the creation of a joint team of customers and developers who work together to identify the problem  propose elements of the solution  negotiate different approaches  and specify a preliminary set of requirements.""      ""width"": ""1024"" }                         375                  4. CLSS stands for conveyor line sorting system conveyor line sorting software conveyor line sorting speed conveyor line sorting specification Answer:a Explanation:The conveyor line sorting system (CLSS) sorts boxes moving along a conveyor line. Each box is identified  by a bar code that contains a part number and is sorted into one of six bins at the end of the line. 5. The project planner examines the statement of scope and extracts all important software functions which is known as Association Decomposition Planning process All of the mentioned Answer:b Explanation:The answer is self explanatory 6. The environment that supports the software project is called CLSS SEE FAST CBSE Explanation:Software engineering environment (SEE)  incorporates hardware and software.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/375/4.+CLSS+stands+for+conveyor+line+sorting+system.+conveyor+line+sorting+software.+conveyor+line+sorting+speed..jpg""      ""name"": ""4. CLSS stands for conveyor line sorting system. conveyor line sorting software. conveyor line sorting speed.""      ""description"": ""conveyor line sorting specification. Answer:a. Explanation:The conveyor line sorting system (CLSS) sorts boxes moving along a conveyor line. Each box is identified by a bar code that contains a part number and is sorted into one of six bins at the end of the line. 5. The project planner examines the statement of scope and extracts all important software functions which is known as. Association. Decomposition. Planning process. All of the mentioned. Answer:b. Explanation:The answer is self explanatory. 6. The environment that supports the software project is called. CLSS. SEE. FAST. CBSE. Explanation:Software engineering environment (SEE)  incorporates hardware and software.""      ""width"": ""1024"" }                         376                  7. Which of the following is not an option to achieve reliable cost and effort estimate?Base estimates on similar projects that have already been completed Use one or more empirical models for software cost and effort estimation Use relatively simple decomposition techniques to generate project cost and effort estimates. The ability to translate the size estimate into human effort  calendar time  and dollars. Answer:d Explanation:The answer is self explanatory. 8. What can be used to complement decomposition techniques and offer a potentially valuable estimation approach in their own right? Automated estimation tools Empirical estimation models Decomposition techniques Both Automated estimation tools and Empirical estimation models Answer:b Explanation:An estimation model for computer software uses empirically derived formulas to predict effort as a function of LOC or FP. 9. Which of the following is not achieved by an automated estimation tools? Predicting staffing levels Predicting software cost Predicting software schedules Predicting clients demands Explanation:Demands can vary from client to client.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/376/7.+Which+of+the+following+is+not+an+option+to+achieve+reliable+cost+and+effort+estimate.jpg""      ""name"": ""7. Which of the following is not an option to achieve reliable cost and effort estimate""      ""description"": ""Base estimates on similar projects that have already been completed. Use one or more empirical models for software cost and effort estimation. Use relatively simple decomposition techniques to generate project cost and effort estimates. The ability to translate the size estimate into human effort  calendar time  and dollars. Answer:d. Explanation:The answer is self explanatory. 8. What can be used to complement decomposition techniques and offer a potentially valuable estimation approach in their own right Automated estimation tools. Empirical estimation models. Decomposition techniques. Both Automated estimation tools and Empirical estimation models. Answer:b. Explanation:An estimation model for computer software uses empirically derived formulas to predict effort as a function of LOC or FP. 9. Which of the following is not achieved by an automated estimation tools Predicting staffing levels. Predicting software cost. Predicting software schedules. Predicting clients demands. Explanation:Demands can vary from client to client.""      ""width"": ""1024"" }                         377                  10. Software project estimation can never be an exact science  but a combination of good  historical data and systematic techniques can improve estimation accuracy. True False Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/377/10.+Software+project+estimation+can+never+be+an+exact+science%2C+but+a+combination+of+good+historical+data+and+systematic+techniques+can+improve+estimation+accuracy..jpg""      ""name"": ""10. Software project estimation can never be an exact science  but a combination of good historical data and systematic techniques can improve estimation accuracy.""      ""description"": ""True. False. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         378                  Software Configuration Management – 1Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/378/Software+Configuration+Management+%E2%80%93+1.jpg""      ""name"": ""Software Configuration Management – 1""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         379                  1. Which of the following categories is part of the output of software process?computer programs documents that describe the computer programs data All of the mentioned Answer:d Explanation:The answer is self explanatory. 2. Which is a software configuration management concept that helps us to control change without seriously impeding  justifiable change? Baselines Source code Data model None of the mentioned Answer:a Explanation:A baseline is analogous to the kitchen doors in the restaurant. Before a software configuration item becomes a  baseline  change may be made quickly and informally. 3. Software Configuration Management can be administered in several ways. These include A single software configuration management team for the whole organization A separate configuration management team for each project Software Configuration Management distributed among the project members  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/379/1.+Which+of+the+following+categories+is+part+of+the+output+of+software+process.jpg""      ""name"": ""1. Which of the following categories is part of the output of software process""      ""description"": ""computer programs. documents that describe the computer programs. data. All of the mentioned. Answer:d. Explanation:The answer is self explanatory. 2. Which is a software configuration management concept that helps us to control change without seriously impeding justifiable change Baselines. Source code. Data model. None of the mentioned. Answer:a. Explanation:A baseline is analogous to the kitchen doors in the restaurant. Before a software configuration item becomes a baseline  change may be made quickly and informally. 3. Software Configuration Management can be administered in several ways. These include. A single software configuration management team for the whole organization. A separate configuration management team for each project. Software Configuration Management distributed among the project members.""      ""width"": ""1024"" }                         380                  4. What combines procedures and tools to manage different versions of configuration objects that are created during the software process? Change control Version control SCIs None of the mentioned Answer:b Explanation:Configuration management allows a user to specify alternative configurations of the software system through the  selection of appropriate versions. 5. What complements the formal technical review by assessing a configuration object for characteristics that are generally not considered during review? Software configuration audit Software configuration management Baseline Answer:a Explanation:The answer is self explanatory. 6. Which of the following is the process of assembling program components  data  and libraries  and then compiling and linking  these to create an executable system? System building Release management Change management Version management  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/380/4.+What+combines+procedures+and+tools+to+manage+different+versions+of+configuration+objects+that+are+created+during+the+software+process.jpg""      ""name"": ""4. What combines procedures and tools to manage different versions of configuration objects that are created during the software process""      ""description"": ""Change control. Version control. SCIs. None of the mentioned. Answer:b. Explanation:Configuration management allows a user to specify alternative configurations of the software system through the selection of appropriate versions. 5. What complements the formal technical review by assessing a configuration object for characteristics that are generally not considered during review Software configuration audit. Software configuration management. Baseline. Answer:a. Explanation:The answer is self explanatory. 6. Which of the following is the process of assembling program components  data  and libraries  and then compiling and linking these to create an executable system System building. Release management. Change management. Version management.""      ""width"": ""1024"" }                         381                  7. Which of the following option is not tracked by configuration management tools?Tracking of change proposals Storing versions of system components Tracking the releases of system versions to customers None of the mentioned Answer:d Explanation:All the options are tracked. 8. Which of the following is not a Software Configuration Management Activity? Configuration item identification Risk management Release management Branch management Answer:b Explanation:Risk management is an entirely different domain. 9. The definition and use of configuration management standards is essential for quality certification in ISO 9000 CMM CMMI All of the mentioned Explanation:It is defined in all the mentioned options.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/381/7.+Which+of+the+following+option+is+not+tracked+by+configuration+management+tools.jpg""      ""name"": ""7. Which of the following option is not tracked by configuration management tools""      ""description"": ""Tracking of change proposals. Storing versions of system components. Tracking the releases of system versions to customers. None of the mentioned. Answer:d. Explanation:All the options are tracked. 8. Which of the following is not a Software Configuration Management Activity Configuration item identification. Risk management. Release management. Branch management. Answer:b. Explanation:Risk management is an entirely different domain. 9. The definition and use of configuration management standards is essential for quality certification in. ISO CMM. CMMI. All of the mentioned. Explanation:It is defined in all the mentioned options.""      ""width"": ""1024"" }                         382                  10. What involves preparing software for external release and keeping track of the system versions that have been released for customer use? System building Release management Change management Version management Answer:b Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/382/10.+What+involves+preparing+software+for+external+release+and+keeping+track+of+the+system+versions+that+have+been+released+for+customer+use.jpg""      ""name"": ""10. What involves preparing software for external release and keeping track of the system versions that have been released for customer use""      ""description"": ""System building. Release management. Change management. Version management. Answer:b. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         383                  Software Quality AssuranceSource & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/383/Software+Quality+Assurance.jpg""      ""name"": ""Software Quality Assurance""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         384                  1. Which of the following is not included in failure costs?rework repair failure mode analysis none of the mentioned Answer:d Explanation:Failure costs are those that would disappear if no defects appeared before shipping a product to customers. 2. Which requirements are the foundation from which quality is measured? Hardware Software Programmers None of the mentioned Answer:b Explanation:Lack of conformance to requirements is lack of quality. 3. Which of the following is not a SQA plan for a project? evaluations to be performed amount of technical work audits and reviews to be performed documents to be produced by the SQA group Explanation:All other options support a SQA plan.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/384/1.+Which+of+the+following+is+not+included+in+failure+costs.jpg""      ""name"": ""1. Which of the following is not included in failure costs""      ""description"": ""rework. repair. failure mode analysis. none of the mentioned. Answer:d. Explanation:Failure costs are those that would disappear if no defects appeared before shipping a product to customers. 2. Which requirements are the foundation from which quality is measured Hardware. Software. Programmers. None of the mentioned. Answer:b. Explanation:Lack of conformance to requirements is lack of quality. 3. Which of the following is not a SQA plan for a project evaluations to be performed. amount of technical work. audits and reviews to be performed. documents to be produced by the SQA group. Explanation:All other options support a SQA plan.""      ""width"": ""1024"" }                         385                  4. Degree to which design specifications are followed in manufacturing the product is calledQuality Control Quality of conformance Quality Assurance None of the mentioned Answer:b Explanation:The answer is self explanatory. 5. Which of the following is not included in External failure costs? testing help line support warranty work complaint resolution Answer:a Explanation:External failure costs are associated with defects found after the product has been shipped to the customer. 6. Which of the following is not an appraisal cost in SQA? inter-process inspection maintenance quality planning Answer:c Explanation:It is associated prevention cost.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/385/4.+Degree+to+which+design+specifications+are+followed+in+manufacturing+the+product+is+called.jpg""      ""name"": ""4. Degree to which design specifications are followed in manufacturing the product is called""      ""description"": ""Quality Control. Quality of conformance. Quality Assurance. None of the mentioned. Answer:b. Explanation:The answer is self explanatory. 5. Which of the following is not included in External failure costs testing. help line support. warranty work. complaint resolution. Answer:a. Explanation:External failure costs are associated with defects found after the product has been shipped to the customer. 6. Which of the following is not an appraisal cost in SQA inter-process inspection. maintenance. quality planning. Answer:c. Explanation:It is associated prevention cost.""      ""width"": ""1024"" }                         386                  7. Who identifies  documents  and verifies that corrections have been made to the software?Project manager Project team SQA group All of the mentioned Answer:c Explanation:The answer is self explanatory. 8. The primary objective of formal technical reviews is to find  	during the process so that they do not become defects  after release of the software. errors equivalent faults failure cause None of the mentioned Answer:a Explanation:Errors lead to faults 9. What is not included in prevention costs? quality planning formal technical reviews test equipment equipment calibration and maintenance Answer:d Explanation:The cost of quality includes all costs incurred in the pursuit of quality or in performing quality-related activities.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/386/7.+Who+identifies%2C+documents%2C+and+verifies+that+corrections+have+been+made+to+the+software.jpg""      ""name"": ""7. Who identifies  documents  and verifies that corrections have been made to the software""      ""description"": ""Project manager. Project team. SQA group. All of the mentioned. Answer:c. Explanation:The answer is self explanatory. 8. The primary objective of formal technical reviews is to find during the process so that they do not become defects after release of the software. errors. equivalent faults. failure cause. None of the mentioned. Answer:a. Explanation:Errors lead to faults. 9. What is not included in prevention costs quality planning. formal technical reviews. test equipment. equipment calibration and maintenance. Answer:d. Explanation:The cost of quality includes all costs incurred in the pursuit of quality or in performing quality-related activities.""      ""width"": ""1024"" }                         387                  10. Software quality assurance consists of the auditing and reporting functions of management.True False Answer:a Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/387/10.+Software+quality+assurance+consists+of+the+auditing+and+reporting+functions+of+management..jpg""      ""name"": ""10. Software quality assurance consists of the auditing and reporting functions of management.""      ""description"": ""True. False. Answer:a. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         388                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/388/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         389                  Software Configuration Management – 2Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/389/Software+Configuration+Management+%E2%80%93+2.jpg""      ""name"": ""Software Configuration Management – 2""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         390                  1. Which of the following process ensures that versions of systems and components are recorded and maintained? Codeline Configuration control Version Workspace Answer:b Explanation:In configuration control changes are managed and all versions of components are identified and stored for the lifetime. 2. Which of the following process is concerned with analyzing the costs and benefits of proposed changes? Change management Version management System building Release management Answer:a Explanation:It involves approving those changes that are worthwhile  and tracking which components in the system have  been changed. 3. Which of the following is not a Version management feature? Version and release identification Build script generation Project support Change history recording Explanation:All other options are a part of version management.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/390/1.+Which+of+the+following+process+ensures+that+versions+of+systems+and+components+are+recorded+and+maintained.jpg""      ""name"": ""1. Which of the following process ensures that versions of systems and components are recorded and maintained""      ""description"": ""Codeline. Configuration control. Version. Workspace. Answer:b. Explanation:In configuration control changes are managed and all versions of components are identified and stored for the lifetime. 2. Which of the following process is concerned with analyzing the costs and benefits of proposed changes Change management. Version management. System building. Release management. Answer:a. Explanation:It involves approving those changes that are worthwhile  and tracking which components in the system have been changed. 3. Which of the following is not a Version management feature Version and release identification. Build script generation. Project support. Change history recording. Explanation:All other options are a part of version management.""      ""width"": ""1024"" }                         391                  4. Which method recommends that very frequent system builds should be carried out with automated testing to discover software problems? Agile method Parallel compilation method Large systems method All of the mentioned Answer:a Explanation:In keeping with the agile methods notion of making many small changes  continuous integration involves rebuilding  the mainline frequently  after small source code changes have been made. 5. Which of the following is not a build system feature? Minimal recompilation Documentation generation Storage management Reporting Answer:c Explanation:To reduce the storage space required by multiple versions of components that differ only slightly  version management  systems usually provide storage management facilities. 6. Which of the following is a collection of component versions that make up a system? Version Codeline Baseline None of the above Explanation:Baselines are controlled  which means that the versions of the components making up the system cannot be changed.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/391/4.+Which+method+recommends+that+very+frequent+system+builds+should+be+carried+out+with+automated+testing+to+discover+software+problems.jpg""      ""name"": ""4. Which method recommends that very frequent system builds should be carried out with automated testing to discover software problems""      ""description"": ""Agile method. Parallel compilation method. Large systems method. All of the mentioned. Answer:a. Explanation:In keeping with the agile methods notion of making many small changes  continuous integration involves rebuilding the mainline frequently  after small source code changes have been made. 5. Which of the following is not a build system feature Minimal recompilation. Documentation generation. Storage management. Reporting. Answer:c. Explanation:To reduce the storage space required by multiple versions of components that differ only slightly  version management systems usually provide storage management facilities. 6. Which of the following is a collection of component versions that make up a system Version. Codeline. Baseline. None of the above. Explanation:Baselines are controlled  which means that the versions of the components making up the system cannot be changed.""      ""width"": ""1024"" }                         392                  7. Which of the following is a configuration item?Design specification Source code Test specification Log information All of the mentioned Answer:e Explanation:A configuration item is an approved and accepted deliverable  changes have to be made through formal procedure. 8. Which of the following is a part of system release? electronic and paper documentation describing the system packaging and associated publicity that have been designed for that release an installation program that is used to help install the system on target hardware all of the mentioned Answer:d Explanation:Release creation is the process of creating the collection of files and documentation that includes all of the  components of the system release. 9. A sequence of baselines representing different versions of a system is known as System building Mainline Software Configuration Item(SCI) None of the above Answer:b Explanation:The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/392/7.+Which+of+the+following+is+a+configuration+item.jpg""      ""name"": ""7. Which of the following is a configuration item""      ""description"": ""Design specification. Source code. Test specification. Log information. All of the mentioned. Answer:e. Explanation:A configuration item is an approved and accepted deliverable  changes have to be made through formal procedure. 8. Which of the following is a part of system release electronic and paper documentation describing the system. packaging and associated publicity that have been designed for that release. an installation program that is used to help install the system on target hardware. all of the mentioned. Answer:d. Explanation:Release creation is the process of creating the collection of files and documentation that includes all of the components of the system release. 9. A sequence of baselines representing different versions of a system is known as. System building. Mainline. Software Configuration Item(SCI) None of the above. Answer:b. Explanation:The answer is self explanatory.""      ""width"": ""1024"" }                         393                  10. Which of the following term is best defined by the statement “The creation of a new codeline from a version in an existing codeline”? Branching Merging Codeline Mainline Answer:a Explanation:The code may then be developed independently.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/393/10.+Which+of+the+following+term+is+best+defined+by+the+statement+The+creation+of+a+new+codeline+from+a+version+in+an+existing+codeline.jpg""      ""name"": ""10. Which of the following term is best defined by the statement The creation of a new codeline from a version in an existing codeline""      ""description"": ""Branching. Merging. Codeline. Mainline. Answer:a. Explanation:The code may then be developed independently.""      ""width"": ""1024"" }                         394                  Software Maintenance – 1Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/394/Software+Maintenance+%E2%80%93+1.jpg""      ""name"": ""Software Maintenance – 1""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         395                  1. Software Maintenance includesError corrections Enhancements of capabilities Deletion of obsolete capabilities All of the mentioned Answer:d Explanation: The answer is self explanatory. 2. Maintenance is classified into how many categories ? two three four five Answer:c Explanation: Adaptive  corrective  perfective and preventive are the four types of software maintenance. 3. The modification of the software to match changes in the ever changing environment  falls under which category  of software maintenance? Corrective Adaptive Perfective Preventive Answer:b  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/395/1.+Software+Maintenance+includes.jpg""      ""name"": ""1. Software Maintenance includes""      ""description"": ""Error corrections. Enhancements of capabilities. Deletion of obsolete capabilities. All of the mentioned. Answer:d. Explanation: The answer is self explanatory. 2. Maintenance is classified into how many categories two. three. four. five. Answer:c. Explanation: Adaptive  corrective  perfective and preventive are the four types of software maintenance. 3. The modification of the software to match changes in the ever changing environment  falls under which category of software maintenance Corrective. Adaptive. Perfective. Preventive. Answer:b.""      ""width"": ""1024"" }                         396                  4. How many phases are there in Taute Maintenance Model?six seven eight nine Answer:c Explanation: The answer is self explanatory. 5. What type of software testing is generally used in Software Maintenance? Regression Testing System Testing Integration Testing Unit Testing Answer:a Explanation: All other options are known as levels of software testing which further have types of software testing. 6. Regression testing is a very expensive activity. True False Explanation: As regression testing is performed many times over the life of the software product  it becomes a costly affair.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/396/4.+How+many+phases+are+there+in+Taute+Maintenance+Model.jpg""      ""name"": ""4. How many phases are there in Taute Maintenance Model""      ""description"": ""six. seven. eight. nine. Answer:c. Explanation: The answer is self explanatory. 5. What type of software testing is generally used in Software Maintenance Regression Testing. System Testing. Integration Testing. Unit Testing. Answer:a. Explanation: All other options are known as levels of software testing which further have types of software testing. 6. Regression testing is a very expensive activity. True. False. Explanation: As regression testing is performed many times over the life of the software product  it becomes a costly affair.""      ""width"": ""1024"" }                         397                  7. Selective retest techniques may be more economical than the “retest-all”technique.How many selective retest techniques are there? two three four five Answer:b Explanation: The three categories include: Coverage  Minimization and Safe techniques. 8. Which selective retest technique selects every test case that causes a modified program to produce a different output than  its original version? Coverage Minimization Safe Answer:c Explanation: Safe techniques do not focus on coverage criteria  instead they select every test case that cause a modified  program to produce different output than its original version. 9.  	measures the ability of a regression test selection technique to handle realistic applications. Efficiency Precision Generality Inclusiveness Explanation: Generality measures the ability of a technique to handle realistic and diverse language constructs   arbitrarily complex modifications  and realistic testing applications.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/397/7.+Selective+retest+techniques+may+be+more+economical+than+the+retest-all+technique.How+many+selective+retest+techniques+are+there.jpg""      ""name"": ""7. Selective retest techniques may be more economical than the retest-all technique.How many selective retest techniques are there""      ""description"": ""two. three. four. five. Answer:b. Explanation: The three categories include: Coverage  Minimization and Safe techniques. 8. Which selective retest technique selects every test case that causes a modified program to produce a different output than its original version Coverage. Minimization. Safe. Answer:c. Explanation: Safe techniques do not focus on coverage criteria  instead they select every test case that cause a modified program to produce different output than its original version. 9. measures the ability of a regression test selection technique to handle realistic applications. Efficiency. Precision. Generality. Inclusiveness. Explanation: Generality measures the ability of a technique to handle realistic and diverse language constructs  arbitrarily complex modifications  and realistic testing applications.""      ""width"": ""1024"" }                         398                  10. Which regression test selection technique exposes faults caused by modifications?Efficiency Precision Generality Inclusiveness Answer:d Explanation: Inclusiveness measures the extent to which a technique chooses test  cases that will cause the modified program to produce different output than the original  program  and thereby expose faults caused by modifications.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/398/10.+Which+regression+test+selection+technique+exposes+faults+caused+by+modifications.jpg""      ""name"": ""10. Which regression test selection technique exposes faults caused by modifications""      ""description"": ""Efficiency. Precision. Generality. Inclusiveness. Answer:d. Explanation: Inclusiveness measures the extent to which a technique chooses test cases that will cause the modified program to produce different output than the original program  and thereby expose faults caused by modifications.""      ""width"": ""1024"" }                         399                  Software Maintenance – 2Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/399/Software+Maintenance+%E2%80%93+2.jpg""      ""name"": ""Software Maintenance – 2""      ""description"": ""Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         400                  1. The process of generating analysis and design documents is known asSoftware engineering Software re-engineering Reverse engineering Re-engineering Answer:c Explanation: Reverse engineering is the process followed in order to find difficult  unknown and hidden information  about a software system. 2. What is a software patch? Required or Critical Fix Emergency Fix Daily or routine Fix None of the mentioned Answer:b Explanation: A software patch is an emergency fix which is worked upon the obsolete version whenever a vulnerability is encountered. 3. Which one of the following is not a maintenance model? Waterfall model Reuse-oriented model Iterative enhancement model Quick fix model Answer:a Explanation: Waterfall model is a software development model.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/400/1.+The+process+of+generating+analysis+and+design+documents+is+known+as.jpg""      ""name"": ""1. The process of generating analysis and design documents is known as""      ""description"": ""Software engineering. Software re-engineering. Reverse engineering. Re-engineering. Answer:c. Explanation: Reverse engineering is the process followed in order to find difficult  unknown and hidden information about a software system. 2. What is a software patch Required or Critical Fix. Emergency Fix. Daily or routine Fix. None of the mentioned. Answer:b. Explanation: A software patch is an emergency fix which is worked upon the obsolete version whenever a vulnerability is encountered. 3. Which one of the following is not a maintenance model Waterfall model. Reuse-oriented model. Iterative enhancement model. Quick fix model. Answer:a. Explanation: Waterfall model is a software development model.""      ""width"": ""1024"" }                         401                  4. What does ACT stands for in In Boehm model for software maintenance?Actual change track Annual change track Annual change traffic Actual change traffic Answer:c Explanation: The answer is self explanatory. 5. Choose the suitable options with respect to regression testing. It helps in development of software It helps in maintenance of software both a and b none of the mentioned Explanation: Regression testing preserves the quality and reliability of software and ensures the software’s continued operation. 6. What are legacy systems? new systems old systems under-developed systems Answer:b Explanation: Legacy systems are the existing systems which may require some modification or maintenance.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/401/4.+What+does+ACT+stands+for+in+In+Boehm+model+for+software+maintenance.jpg""      ""name"": ""4. What does ACT stands for in In Boehm model for software maintenance""      ""description"": ""Actual change track. Annual change track. Annual change traffic. Actual change traffic. Answer:c. Explanation: The answer is self explanatory. 5. Choose the suitable options with respect to regression testing. It helps in development of software. It helps in maintenance of software. both a and b. none of the mentioned. Explanation: Regression testing preserves the quality and reliability of software and ensures the software’s continued operation. 6. What are legacy systems new systems. old systems. under-developed systems. Answer:b. Explanation: Legacy systems are the existing systems which may require some modification or maintenance.""      ""width"": ""1024"" }                         402                  7. Which of the following manuals is not a user documentation?a) Beginner’s Guide Installation guide Reference Guide SRS Answer:d Explanation: SRS provides information on exact requirements of system as agreed between user and developers. 8. Which of the following manuals is a user documentation? SRS -Software Requirement Specification SDD -Software Design Document System Overview Answer:c Explanation: System overview provides general description of the system’s functions. 9. The process of transforming a model into source code is known as Forward engineering Reverse engineering Re-engineering Reconstructing Answer:a Explanation: The answer is self explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/402/7.+Which+of+the+following+manuals+is+not+a+user+documentation.jpg""      ""name"": ""7. Which of the following manuals is not a user documentation""      ""description"": ""a) Beginner’s Guide. Installation guide. Reference Guide. SRS. Answer:d. Explanation: SRS provides information on exact requirements of system as agreed between user and developers. 8. Which of the following manuals is a user documentation SRS -Software Requirement Specification. SDD -Software Design Document. System Overview. Answer:c. Explanation: System overview provides general description of the system’s functions. 9. The process of transforming a model into source code is known as. Forward engineering. Reverse engineering. Re-engineering. Reconstructing. Answer:a. Explanation: The answer is self explanatory.""      ""width"": ""1024"" }                         403                  10. How many stages are there in Iterative-enhancement model used during software maintenance?two three four five Answer:b Explanation: The stages include: analysis of existing system  characterize proposed  modifications  redesign and implement current version.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/403/10.+How+many+stages+are+there+in+Iterative-enhancement+model+used+during+software+maintenance.jpg""      ""name"": ""10. How many stages are there in Iterative-enhancement model used during software maintenance""      ""description"": ""two. three. four. five. Answer:b. Explanation: The stages include: analysis of existing system  characterize proposed modifications  redesign and implement current version.""      ""width"": ""1024"" }                         404                  Thanks… Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/404/Thanks%E2%80%A6+Source+%26+Courtsey%3A.jpg""      ""name"": ""Thanks… Source &amp;amp; Courtsey:""      ""description"": ""Thanks… Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         405                  System Modelling – 2 Source & Courtsey:  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/405/System+Modelling+%E2%80%93+2+Source+%26+Courtsey%3A.jpg""      ""name"": ""System Modelling – 2 Source &amp;amp; Courtsey:""      ""description"": ""System Modelling – 2 Source &amp;amp; Courtsey:""      ""width"": ""1024"" }                         406                  1. Which of the following diagram is not supported by UML considering Data-driven modeling ?Activity Data Flow Diagram (DFD) State Chart Component Answer:b Explanation: DFDs focus on system functions and do not recognize system objects. 2.  	allows us to infer that different members of classes have some common characteristics. Realization Aggregation Generalization dependency Answer:c Explanation: Generalization is an everyday technique that we use to manage complexity.This means that common  information will be maintained in one place only. 3. One creates Behavioral models of a system when you are discussing and designing the system architecture. True False Explanation: Structural models of software display the organization of a system in terms of the components that make  up that system and their relationships.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/406/1.+Which+of+the+following+diagram+is+not+supported+by+UML+considering+Data-driven+modeling.jpg""      ""name"": ""1. Which of the following diagram is not supported by UML considering Data-driven modeling""      ""description"": ""Activity. Data Flow Diagram (DFD) State Chart. Component. Answer:b. Explanation: DFDs focus on system functions and do not recognize system objects. 2. allows us to infer that different members of classes have some common characteristics. Realization. Aggregation. Generalization. dependency. Answer:c. Explanation: Generalization is an everyday technique that we use to manage complexity.This means that common information will be maintained in one place only. 3. One creates Behavioral models of a system when you are discussing and designing the system architecture. True. False. Explanation: Structural models of software display the organization of a system in terms of the components that make up that system and their relationships.""      ""width"": ""1024"" }                         407                  4.  	&  	diagrams of UML represent Interaction modeling.Use Case  Sequence Class  Object Activity  State Chart Answer:a Explanation: Use case modeling is mostly used to model interactions between a system and external actors.Sequence  diagrams are used to model interactions between system components  although external agents may also be included. 5. Which level of Entity Relationship Diagram (ERD) models all entities and relationships ? Level 1 Level 2 Level 3 Answer:b Explanation: Level 1 ERD models all data objects (entities) and their “connections” to one another while Level 3  ERD models all entities  relationships  and the attributes that provide further depth. Thus option b is correct. 6.  	classes are used to create the interface that the user sees and interacts with as the software is used. Controller Entity Boundary Business Answer:c Explanation: The answer is self-explanatory.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/407/4.+%26+diagrams+of+UML+represent+Interaction+modeling..jpg""      ""name"": ""4. &amp;amp; diagrams of UML represent Interaction modeling.""      ""description"": ""Use Case  Sequence. Class  Object. Activity  State Chart. Answer:a. Explanation: Use case modeling is mostly used to model interactions between a system and external actors.Sequence diagrams are used to model interactions between system components  although external agents may also be included. 5. Which level of Entity Relationship Diagram (ERD) models all entities and relationships Level 1. Level 2. Level 3. Answer:b. Explanation: Level 1 ERD models all data objects (entities) and their connections to one another while Level 3 ERD models all entities  relationships  and the attributes that provide further depth. Thus option b is correct. 6. classes are used to create the interface that the user sees and interacts with as the software is used. Controller. Entity. Boundary. Business. Answer:c. Explanation: The answer is self-explanatory.""      ""width"": ""1024"" }                         408                  7. Which of the following statement is incorrect regarding the Class-responsibility-collaborator (CRC) modeling? All use-case scenarios (and corresponding use-case diagrams) are organized into categories in CRC modelling The review leader reads the use-case deliberately. Only developers in the review (of the CRC model) are given a subset of the CRC model index cards Answer:c Explanation: All participants in the review (of the CRC model) are given a subset of the CRC model index cards. 8. A data object can encapsulates processes and operation as well. True False Answer:b Explanation: A data object encapsulates data only. There is no reference within a data object to operations that  act on the data.  {     ""@context"": ""http://schema.org""      ""@type"": ""ImageObject""      ""contentUrl"": ""https://slideplayer.com/slide/13147265/79/images/408/7.+Which+of+the+following+statement+is+incorrect+regarding+the+Class-responsibility-collaborator+%28CRC%29+modeling.jpg""      ""name"": ""7. Which of the following statement is incorrect regarding the Class-responsibility-collaborator (CRC) modeling""      ""description"": ""All use-case scenarios (and corresponding use-case diagrams) are organized into. categories in CRC modelling. The review leader reads the use-case deliberately. Only developers in the review (of the CRC model) are given a subset of the CRC model index cards. Answer:c. Explanation: All participants in the review (of the CRC model) are given a subset of the CRC model index cards. 8. A data object can encapsulates processes and operation as well. True. False. Answer:b. Explanation: A data object encapsulates data only. There is no reference within a data object to operations that act on the data.""      ""width"": ""1024"" }  Ch:8 Design Concepts S.W Design should have following quality attribute: Functionality Usability Reliability Performance Supportability (extensibility Prescriptive Process modelsSOFTWARE TESTING. INTRODUCTION  Software Testing is the process of executing a program or system with the intent of finding errors.  It involves any.The System and Software Development Process Instructor: Dr. Hany H. Ammar Dept. of Computer Science and Electrical Engineering  WVU.Lecture # 2 : Process ModelsSoftware Process Models10 Software Engineering Foundations of Computer Science ã Cengage Learning.Chapter 2 – Software ProcessesCh 3 System Development Environment1 Prescriptive Process Models. 2 Prescriptive Models Prescriptive process models advocate an orderly approach to software engineering Prescriptive process.Alternate Software Development MethodologiesChapter 1 Principles of Programming and Software Engineering.Testing an individual module1 Software Requirements Specification Lecture 14.Course Instructor: Aisha AzeemSoftware Process and Product MetricsSoftware Life Cycle ModelIntroduction to Computer Technology Similar presentations                                    © 2019 SlidePlayer.com Inc. All rights reserved.",facilitated application specification technique, 'Personal computer',https://slideplayer.com/slide/13147265/,'light system'
Do you want to read the rest of this conference paper?You can request the full-text of this conference paper directly from the authors on ResearchGate.,life cycle model, 'Personal computer',https://www.researchgate.net/publication/271456695_Software_engineering_is_software_engineering,'light system'
We use cookies to offer you a better experience  personalize content  tailor advertising  provide social media features  and better understand the use of our services.To learn more or modify/prevent the use of cookies  see our Cookie Policy and Privacy Policy.Do you want to read the rest of this conference paper?You can request the full-text of this conference paper directly from the authors on ResearchGate.,object oriented requirement analysis, 'Personal computer',https://www.researchgate.net/publication/221115251_A_CSP_View_on_UML-RT_structure_diagrams,'light system'
Loading PreviewSorry  preview is currently unavailable. You can download the paper by clicking the button above.Enter the email address you signed up with and we'll email you a reset link.,operational feasibility, 'Personal computer',https://www.academia.edu/7334897/PROPOSAL_ON_AUTOMATIC_ROOM_LIGHT_AND_FAN_CONTROL_SYSTEMS,'light system'
Loading PreviewSorry  preview is currently unavailable. You can download the paper by clicking the button above.Enter the email address you signed up with and we'll email you a reset link.,public domain software, 'Personal computer',http://www.fftw.org/fftw-paper.ps.gz,'light system'
Don't have an account? Sign upBy clicking Join now  you agree to the LinkedIn User Agreement  Privacy Policy  and Cookie Policy.Already have an account? Sign in,quality assurance ( sqa ), 'Personal computer',https://pk.linkedin.com/in/farhan-waseem,'light system'
Loading PreviewSorry  preview is currently unavailable. You can download the paper by clicking the button above.Enter the email address you signed up with and we'll email you a reset link.,capability maturity model ( cmm ), 'Personal computer',https://www.academia.edu/30989571/Schach_s_object_oriented_software_engineering_7ed_mgh,'previous computer'
"Profile 2. The Alto and   the StarProfile Author: Terry WinogradIn 1970  the Xerox Corporation established   the Palo Alto Research Center (PARC)  to invent the future of   the electronic office. In PARC's first decade  a stream of innovations   emerged that set the stage for today's computer industry. Among   other technologies  laser printing  local-area networking  and   desktop publishing software were first developed at PARC. Many   of the prominent companies in the computing industry  such as   3COM  Adobe  and Apple Computer were started or were heavily   influenced by PARC graduates.PARC's most notable innovation was the personal computer    which grew out of earlier concepts by Alan Kay for what he called   a reactive engine and a Dynabook . The progenitor   of the modern personal computer  the Alto  was developed in 1972   by Kay's Learning Research Group (LRG) and a number of researchers   in PARC's Computer Systems Laboratory (CSL)  under the direction   of Robert Taylor. Just as the Model-T contained the fundamental   elements of a modern automobile  the Alto included the central   elements of today's personal computer: a bitmapped graphic display    which enabled it to display text in multiple fonts  combined   with graphics; a mouse as a pointing device; removable magnetic   storage; and an operating system designed for a single user who   alternates among multiple applications. Although the Alto's cost   at the time was high (at standard industry markup  it would have   sold for more than $75 000)  the PARC strategy was to act as   though the Alto was a personal computer—to put one on every   desk and to see what people would do with it.The result of this bold strategy was a proliferation of experimental   software for writing  drawing  communicating  teaching  and computing   in many domains. The Smalltalk language and programming environment    developed by Kay's LRG  pioneered uses of the graphic interface.   Other software developed in CSL included the Bravo text editor    which developed many of the sophisticated features of today's   word processors and was the predecessor of Microsoft Word; Draw   and Markup  the ancestors of MacDraw and MacPaint  and the many   drawing programs that later followed their lead; and programs   that made it possible for personal-computer users to make use   of networked facilities for file storage and laser printing.The Xerox Star was born out of PARC's creative ferment  designing   an integrated system that would bring PARC's new hardware and   software ideas into a commercially viable product for use in   office environments. The Star drew on the ideas that had been   developed  and went further in integrating them and in designing   for a class of users who were far less technically knowledgeable   than the engineers who had been both the creators and the prime   users of many PARC systems (one of PARC's favorite mottoes was   ""Build what you use  use what you build."") As David   Liddle describes in Chapter 2  the Star designers were challenged   to make the personal computer usable for a community that did   not have previous computer experience.From today's perspective  the Star screen (Figure 2.4) looks   rather unremarkable  and perhaps a bit clumsy in its graphic   design—a boxy model-T when compared to the highly styled   look of today's Taurus or Jaguar. What is notable from a historical   perspective  of course  is how much the Star does look like current   screens and how little it looks like the character-based and   vector-drawing screens that preceded it.Figure 2.3 [in the book  not the exact one here] The   Star (Viewpoint) screen image The Star pioneered the   now-familiar constellation of icons  moveable scrollable windows    and intermixed text and graphic images. The widely used graphic   user interfaces (GUIs) of today are all variants of this original   design. (Source: Reprinted by permission from Jeff Johnson et   al. Xerox Star  a retrospective. IEEE Computer 22:9 (September    1989)  p. 13.)The visible mechanisms on the Star display were backed up   with a set of design principles that grew out of a user-oriented   design methodology and by a great deal of empirical testing    as described by Liddle in Chapter 2. Several principles were   central to the Star design:1. Direct manipulation. The core concept that distinguished     Star (and other Alto programs) from the conventional computer     interfaces of their time was the use of a bitmapped screen to     present the user with direct visual representations of objects.     In the Star'sdesktop metaphor  documents  printers  folders      collections of folders (file drawers and cabinets)  in and out     boxes  and other familiar office objects were depicted on the     screen. To print a document  for example  the user could point     (using the mouse) to the icon for the document and the icon for     the printer  while using a key on the keyboard to indicate a     Copy operation.     2.WYSIWYG (what you see is what you get). In previously     available programs for producing sophisticated graphical output—such     as drawings or page layout with multiple fonts—the user     created and edited a representation that looked like a programming     language  and then compiled the resulting program into a visible     form. Alto programs pioneered a new style that Star unified      in which the user works directly with the desired form  through     direct manipulation. The user makes changes by operating on a     direct representation of what will appear on the printed page.     As shown in Figure 2.3  the Star user could intermix text  tables      graphs  drawings  and mathematical formulas. In fact  most of     the popular microcomputer applications of today have not yet     reached the degree of integration that Star offered more than     a decade ago.     3. Consistency of commands. Because all Star applications     were developed in a unified way by a single development group      it was possible to adhere to a coherent and consistent design     language (see Chapter 4 for a discussion of design languages).     The Star keyboard embodied a set of generic commands  which     were used in a consistent way across all applications: Move      Copy  Delete  Open  Show Properties  and Same (copy     properties). Evoking one of these commands produced the same     behavior whether the object being moved or copied  for example      was a word of text  a drawing element  or a folder of documents.     Through the use of property sheets (Figure 2.1)  the user could     manipulate the aspects that were specific to each element  such     as the font of a text character  or the brush width of a painted     line. The Open command was the basis for applying a technique     of progressive disclosure—showing the user only the     relevant information for a task at hand  and then providing a     way to reveal more possibilities as they were needed.   In addition to these three key concepts  many specific design   features made the Star unique  including its attention to the   communicative aspects of graphic design  its integration of an   end-user scripting language (CUSP)  and its underlying mechanisms   for internationalization—from the very beginning  Star versions   were developed in several languages  including non-European languages   with large character sets  non–left-to-right orthography    and so on.Some of the aspects that led to the Star's design quality   may have also hampered its commercial success—in particular   Xerox's dependence on development groups within a single company   to produce all the applications software. But the result was   one that supports Liddle's assertion that ""In some aspects    I still think that Star was a great advance over its successors.""Suggested ReadingsDavid Canfield Smith  Charles Irby  Ralph Kimball  Bill Verplank    Eric Harlslem. Designing the STAR user interface.Byte   7:4 (April  1982)  242–282.William Bewley  Teresa Roberts  David Schroit  and William   Verplank. Human factors testing in the design of Xerox’s   8010 ""Star"" office workstation. Proceedings of CHI'83    New York: ACM  1983  72–77.David Liddle  Design of the Conceptual   Model  in Bringing Design to Software  Addison-Wesley    1996  17-31.Bruce Damer's Personal Histories of the Desktop User Interface:   A Retrospective of the Xerox Alto  Star 8010 System and Elixir   Desktop: http://www.damer.com/pictures/elixir/products/star.htmlLawrence Miller and Jeff Johnson  The Xerox Star: An Influential   User Interface Design  in Rudsill  Lewis  Polson  and. McKay    (eds.) Human-computer Interface Design: Success Stories  Emerging   Methods  and Real-world Context.(1996). 70-100. Bill Verplank  Graphic challenges in designing object-oriented   user interfaces  in Martin Helander (ed.)  Handbook of Human-Computer   Interaction  Elsevier  1988 (First edition)  365-376. Video: Xerox Star Interface: An Overview [Xerox]  SIGGRAPH   Video Review Issue 56 - CHI '90 Techincal Video Program Video: The Final Demonstration of the Xerox 'Star' Computer    1981. Xerox PARC  June 17  1998 (2 tapes  TRT 1:59:00 + 21:30).",design language, 'Personal computer',https://hci.stanford.edu/publications/bds/2p-star.html,'previous computer'
,earliest start time, 'Personal computer',https://www.scribd.com/document/283025495/Connect-Plus-Test-Centre-Administration-Guide,'previous computer'
 SIGN IN   SIGN UP Share:Powered by ,evolutionary prototyping, 'Personal computer',http://doi.org/10.1145/69586.358137,'previous computer'
  2 083          Views       2           Favorites        For print-disabled users                   Uploaded by                                         Rana Adnan                                      on February 3  2016 ,execution time, 'Personal computer',https://archive.org/stream/ComputerOrganizationAndDesign3rdEdition/-computer%2Borganization%2Band%2Bdesign%2B3rd%2Bedition_djvu.txt,'previous computer'
"An Object-Oriented Approach to Writing Computational Electromagnetics CodesNASA Technical Reports Server (NTRS)Zimmerman  Martin; Mallasch  Paul G.1996-01-01Presently  most computer software development in the Computational Electromagnetics (CEM) community employs the structured programming paradigm  particularly using the Fortran language. Other segments of the software community began switching to an Object-Oriented Programming (OOP) paradigm in recent years to help ease design and development of highly complex codes. This paper examines design of a time-domain numerical analysis CEM code using the OOP paradigm  comparing OOP code and structured programming code in terms of software maintenance  portability  flexibility  and speed.An Object-oriented Computer Code for Aircraft Engine Weight EstimationNASA Technical Reports Server (NTRS)Tong  Michael T.; Naylor  Bret A.2008-01-01Reliable engine-weight estimation at the conceptual design stage is critical to the development of new aircraft engines. It helps to identify the best engine concept amongst several candidates. At NASA Glenn (GRC)  the Weight Analysis of Turbine Engines (WATE) computer code  originally developed by Boeing Aircraft  has been used to estimate the engine weight of various conceptual engine designs. The code  written in FORTRAN  was originally developed for NASA in 1979. Since then  substantial improvements have been made to the code to improve the weight calculations for most of the engine components. Most recently  to improve the maintainability and extensibility of WATE  the FORTRAN code has been converted into an object-oriented version. The conversion was done within the NASA s NPSS (Numerical Propulsion System Simulation) framework. This enables WATE to interact seamlessly with the thermodynamic cycle model which provides component flow data such as airflows  temperatures  and pressures  etc. that are required for sizing the components and weight calculations. The tighter integration between the NPSS and WATE would greatly enhance system-level analysis and optimization capabilities. It also would facilitate the enhancement of the WATE code for next-generation aircraft and space propulsion systems. In this paper  the architecture of the object-oriented WATE code (or WATE++) is described. Both the FORTRAN and object-oriented versions of the code are employed to compute the dimensions and weight of a 300- passenger aircraft engine (GE90 class). Both versions of the code produce essentially identical results as should be the case. Keywords: NASA  aircraft engine  weight  object-orientedAn Object-Oriented Computer Code for Aircraft Engine Weight EstimationNASA Technical Reports Server (NTRS)Tong  Michael T.; Naylor  Bret A.2009-01-01Reliable engine-weight estimation at the conceptual design stage is critical to the development of new aircraft engines. It helps to identify the best engine concept amongst several candidates. At NASA Glenn Research Center (GRC)  the Weight Analysis of Turbine Engines (WATE) computer code  originally developed by Boeing Aircraft  has been used to estimate the engine weight of various conceptual engine designs. The code  written in FORTRAN  was originally developed for NASA in 1979. Since then  substantial improvements have been made to the code to improve the weight calculations for most of the engine components. Most recently  to improve the maintainability and extensibility of WATE  the FORTRAN code has been converted into an object-oriented version. The conversion was done within the NASA's NPSS (Numerical Propulsion System Simulation) framework. This enables WATE to interact seamlessly with the thermodynamic cycle model which provides component flow data such as airflows  temperatures  and pressures  etc.  that are required for sizing the components and weight calculations. The tighter integration between the NPSS and WATE would greatly enhance system-level analysis and optimization capabilities. It also would facilitate the enhancement of the WATE code for next-generation aircraft and space propulsion systems. In this paper  the architecture of the object-oriented WATE code (or WATE++) is described. Both the FORTRAN and object-oriented versions of the code are employed to compute the dimensions and weight of a 300-passenger aircraft engine (GE90 class). Both versions of the code produce essentially identical results as should be the case.Object-oriented numerical computing C++NASA Technical Reports Server (NTRS)Vanrosendale  John1994-01-01An object oriented language is one allowing users to create a set of related types and then intermix and manipulate values of these related types. This paper discusses object oriented numerical computing using C++.Object-oriented Tools for Distributed ComputingNASA Technical Reports Server (NTRS)Adler  Richard M.1993-01-01Distributed computing systems are proliferating  owing to the availability of powerful  affordable microcomputers and inexpensive communication networks. A critical problem in developing such systems is getting application programs to interact with one another across a computer network. Remote interprogram connectivity is particularly challenging across heterogeneous environments  where applications run on different kinds of computers and operating systems. NetWorks! (trademark) is an innovative software product that provides an object-oriented messaging solution to these problems. This paper describes the design and functionality of NetWorks! and illustrates how it is being used to build complex distributed applications for NASA and in the commercial sector.Object-oriented code SUR for plasma kinetic simulationSciTech ConnectLevchenko  V.D.; Sigov  Y.S.1995-12-31We have developed a self-consistent simulation code based on object-oriented model of plasma (OOMP) for solving the Vlasov/Poisson (V/P)  Vlasov/Maxwell (V/M)  Bhatnagar-Gross-Krook (BGK) as well as Fokker-Planck (FP) kinetic equations. The application of an object-oriented approach (OOA) to simulation of plasmas and plasma-like media by means of splitting methods permits to uniformly describe and solve the wide circle of plasma kinetics problems  including those being very complicated: many-dimensional  relativistic  with regard for collisions  specific boundary conditions etc. This paper gives the brief description of possibilities of the SUR code  as a concrete realization of OOMP.Generic  Type-Safe and Object Oriented Computer Algebra SoftwareNASA Astrophysics Data System (ADS)Kredel  Heinz; Jolly  RaphaelAdvances in computer science  in particular object oriented programming  and software engineering have had little practical impact on computer algebra systems in the last 30 years. The software design of existing systems is still dominated by ad-hoc memory management  weakly typed algorithm libraries and proprietary domain specific interactive expression interpreters. We discuss a modular approach to computer algebra software: usage of state-of-the-art memory management and run-time systems (e.g. JVM) usage of strongly typed  generic  object oriented programming languages (e.g. Java) and usage of general purpose  dynamic interactive expression interpreters (e.g. Python) To illustrate the workability of this approach  we have implemented and studied computer algebra systems in Java and Scala. In this paper we report on the current state of this work by presenting new examples.Simulating complex intracellular processes using object-oriented computational modelling.PubMedJohnson  Colin G; Goldman  Jacki P; Gullick  William J2004-11-01The aim of this paper is to give an overview of computer modelling and simulation in cellular biology  in particular as applied to complex biochemical processes within the cell. This is illustrated by the use of the techniques of object-oriented modelling  where the computer is used to construct abstractions of objects in the domain being modelled  and these objects then interact within the computer to simulate the system and allow emergent properties to be observed. The paper also discusses the role of computer simulation in understanding complexity in biological systems  and the kinds of information which can be obtained about biology via simulation.Meanline Analysis of Turbines with Choked Flow in the Object-Oriented Turbomachinery Analysis CodeNASA Technical Reports Server (NTRS)Hendricks  Eric S.2016-01-01The prediction of turbomachinery performance characteristics is an important part of the conceptual aircraft engine design process. During this phase  the designer must examine the effects of a large number of turbomachinery design parameters to determine their impact on overall engine performance and weight. The lack of detailed design information available in this phase necessitates the use of simpler meanline and streamline methods to determine the turbomachinery geometry characteristics and provide performance estimates prior to more detailed CFD (Computational Fluid Dynamics) analyses. While a number of analysis codes have been developed for this purpose  most are written in outdated software languages and may be difficult or impossible to apply to new  unconventional designs. The Object-Oriented Turbomachinery Analysis Code (OTAC) is currently being developed at NASA Glenn Research Center to provide a flexible meanline and streamline analysis capability in a modern object-oriented language. During the development and validation of OTAC  a limitation was identified in the code's ability to analyze and converge turbines as the flow approached choking. This paper describes a series of changes which can be made to typical OTAC turbine meanline models to enable the assessment of choked flow up to limit load conditions. Results produced with this revised model setup are provided in the form of turbine performance maps and are compared to published maps.OSIRIS - an object-oriented parallel 3D PIC code for modeling laser and particle beam-plasma interactionNASA Astrophysics Data System (ADS)Hemker  Roy1999-11-01The advances in computational speed make it now possible to do full 3D PIC simulations of laser plasma and beam plasma interactions  but at the same time the increased complexity of these problems makes it necessary to apply modern approaches like object oriented programming to the development of simulation codes. We report here on our progress in developing an object oriented parallel 3D PIC code using Fortran 90. In its current state the code contains algorithms for 1D  2D  and 3D simulations in cartesian coordinates and for 2D cylindrically-symmetric geometry. For all of these algorithms the code allows for a moving simulation window and arbitrary domain decomposition for any number of dimensions. Recent 3D simulation results on the propagation of intense laser and electron beams through plasmas will be presented.Meanline Analysis of Turbines with Choked Flow in the Object-Oriented Turbomachinery Analysis CodeNASA Technical Reports Server (NTRS)Hendricks  Eric S.2016-01-01The Object-Oriented Turbomachinery Analysis Code (OTAC) is a new meanline/streamline turbomachinery modeling tool being developed at NASA GRC. During the development process  a limitation of the code was discovered in relation to the analysis of choked flow in axial turbines. This paper describes the relevant physics for choked flow as well as the changes made to OTAC to enable analysis in this flow regime.An Object-Oriented Network-Centric Software Architecture for Physical ComputingNASA Astrophysics Data System (ADS)Palmer  Richard1997-08-01Recent developments in object-oriented computer languages and infrastructure such as the Internet  Web browsers  and the like provide an opportunity to define a more productive computational environment for scientific programming that is based more closely on the underlying mathematics describing physics than traditional programming languages such as FORTRAN or C++. In this talk I describe an object-oriented software architecture for representing physical problems that includes classes for such common mathematical objects as geometry  boundary conditions  partial differential and integral equations  discretization and numerical solution methods  etc. In practice  a scientific program written using this architecture looks remarkably like the mathematics used to understand the problem  is typically an order of magnitude smaller than traditional FORTRAN or C++ codes  and hence easier to understand  debug  describe  etc. All objects in this architecture are ``network-enabled '' which means that components of a software solution to a physical problem can be transparently loaded from anywhere on the Internet or other global network. The architecture is expressed as an ``API '' or application programmers interface specification  with reference embeddings in Java  Python  and C++. A C++ class library for an early version of this API has been implemented for machines ranging from PC's to the IBM SP2  meaning that phidentical codes run on all architectures.Design of an Object-Oriented Turbomachinery Analysis Code: Initial ResultsNASA Technical Reports Server (NTRS)Jones  Scott2015-01-01Performance prediction of turbomachines is a significant part of aircraft propulsion design. In the conceptual design stage  there is an important need to quantify compressor and turbine aerodynamic performance and develop initial geometry parameters at the 2-D level prior to more extensive Computational Fluid Dynamics (CFD) analyses. The Object-oriented Turbomachinery Analysis Code (OTAC) is being developed to perform 2-D meridional flowthrough analysis of turbomachines using an implicit formulation of the governing equations to solve for the conditions at the exit of each blade row. OTAC is designed to perform meanline or streamline calculations; for streamline analyses simple radial equilibrium is used as a governing equation to solve for spanwise property variations. While the goal for OTAC is to allow simulation of physical effects and architectural features unavailable in other existing codes  it must first prove capable of performing calculations for conventional turbomachines.OTAC is being developed using the interpreted language features available in the Numerical Propulsion System Simulation (NPSS) code described by Claus et al (1991). Using the NPSS framework came with several distinct advantages  including access to the pre-existing NPSS thermodynamic property packages and the NPSS Newton-Raphson solver. The remaining objects necessary for OTAC were written in the NPSS framework interpreted language. These new objects form the core of OTAC and are the BladeRow  BladeSegment  TransitionSection  Expander  Reducer  and OTACstart Elements. The BladeRow and BladeSegment consumed the initial bulk of the development effort and required determining the equations applicable to flow through turbomachinery blade rows given specific assumptions about the nature of that flow. Once these objects were completed  OTAC was tested and found to agree with existing solutions from other codes; these tests included various meanline and streamline comparisons of axialDesign of an Object-Oriented Turbomachinery Analysis Code: Initial ResultsNASA Technical Reports Server (NTRS)Jones  Scott M.2015-01-01Performance prediction of turbomachines is a significant part of aircraft propulsion design. In the conceptual design stage  there is an important need to quantify compressor and turbine aerodynamic performance and develop initial geometry parameters at the 2-D level prior to more extensive Computational Fluid Dynamics (CFD) analyses. The Object-oriented Turbomachinery Analysis Code (OTAC) is being developed to perform 2-D meridional flowthrough analysis of turbomachines using an implicit formulation of the governing equations to solve for the conditions at the exit of each blade row. OTAC is designed to perform meanline or streamline calculations; for streamline analyses simple radial equilibrium is used as a governing equation to solve for spanwise property variations. While the goal for OTAC is to allow simulation of physical effects and architectural features unavailable in other existing codes  it must first prove capable of performing calculations for conventional turbomachines. OTAC is being developed using the interpreted language features available in the Numerical Propulsion System Simulation (NPSS) code described by Claus et al (1991). Using the NPSS framework came with several distinct advantages  including access to the pre-existing NPSS thermodynamic property packages and the NPSS Newton-Raphson solver. The remaining objects necessary for OTAC were written in the NPSS framework interpreted language. These new objects form the core of OTAC and are the BladeRow  BladeSegment  TransitionSection  Expander  Reducer  and OTACstart Elements. The BladeRow and BladeSegment consumed the initial bulk of the development effort and required determining the equations applicable to flow through turbomachinery blade rows given specific assumptions about the nature of that flow. Once these objects were completed  OTAC was tested and found to agree with existing solutions from other codes; these tests included various meanline and streamline comparisons of axialAdvanced Computing Technologies for Rocket Engine Propulsion Systems: Object-Oriented Design with C++NASA Technical Reports Server (NTRS)Bekele  Gete2002-01-01This document explores the use of advanced computer technologies with an emphasis on object-oriented design to be applied in the development of software for a rocket engine to improve vehicle safety and reliability. The primary focus is on phase one of this project  the smart start sequence module. The objectives are: 1) To use current sound software engineering practices  object-orientation; 2) To improve on software development time  maintenance  execution and management; 3) To provide an alternate design choice for control  implementation  and performance.Method for Statically Checking an Object-oriented Computer Program ModuleNASA Technical Reports Server (NTRS)Bierhoff  Kevin M. (Inventor); Aldrich  Jonathan (Inventor)2012-01-01A method for statically checking an object-oriented computer program module includes the step of identifying objects within a computer program module  at least one of the objects having a plurality of references thereto  possibly from multiple clients. A discipline of permissions is imposed on the objects identified within the computer program module. The permissions enable tracking  from among a discrete set of changeable states  a subset of states each object might be in. A determination is made regarding whether the imposed permissions are violated by a potential reference to any of the identified objects. The results of the determination are output to a user.An object-oriented computational model to study cardiopulmonary hemodynamic interactions in humans.PubMedNgo  Chuong; Dahlmanns  Stephan; Vollmer  Thomas; Misgeld  Berno; Leonhardt  Steffen2018-06-01This work introduces an object-oriented computational model to study cardiopulmonary interactions in humans. Modeling was performed in object-oriented programing language Matlab Simscape  where model components are connected with each other through physical connections. Constitutive and phenomenological equations of model elements are implemented based on their non-linear pressure-volume or pressure-flow relationship. The model includes more than 30 physiological compartments  which belong either to the cardiovascular or respiratory system. The model considers non-linear behaviors of veins  pulmonary capillaries  collapsible airways  alveoli  and the chest wall. Model parameters were derisved based on literature values. Model validation was performed by comparing simulation results with clinical and animal data reported in literature. The model is able to provide quantitative values of alveolar  pleural  interstitial  aortic and ventricular pressures  as well as heart and lung volumes during spontaneous breathing and mechanical ventilation. Results of baseline simulation demonstrate the consistency of the assigned parameters. Simulation results during mechanical ventilation with PEEP trials can be directly compared with animal and clinical data given in literature. Object-oriented programming languages can be used to model interconnected systems including model non-linearities. The model provides a useful tool to investigate cardiopulmonary activity during spontaneous breathing and mechanical ventilation. Copyright Â© 2018 Elsevier B.V. All rights reserved.Development of an Object-Oriented Turbomachinery Analysis Code within the NPSS FrameworkNASA Technical Reports Server (NTRS)Jones  Scott M.2014-01-01During the preliminary or conceptual design phase of an aircraft engine  the turbomachinery designer has a need to estimate the effects of a large number of design parameters such as flow size  stage count  blade count  radial position  etc. on the weight and efficiency of a turbomachine. Computer codes are invariably used to perform this task however  such codes are often very old  written in outdated languages with arcane input files  and rarely adaptable to new architectures or unconventional layouts. Given the need to perform these kinds of preliminary design trades  a modern 2-D turbomachinery design and analysis code has been written using the Numerical Propulsion System Simulation (NPSS) framework. This paper discusses the development of the governing equations and the structure of the primary objects used in OTAC.Object-oriented analysis and design: a methodology for modeling the computer-based patient record.PubMedEgyhazy  C J; Eyestone  S M; Martino  J; Hodgson  C L1998-08-01The article highlights the importance of an object-oriented analysis and design (OOAD) methodology for the computer-based patient record (CPR) in the military environment. Many OOAD methodologies do not adequately scale up  allow for efficient reuse of their products  or accommodate legacy systems. A methodology that addresses these issues is formulated and used to demonstrate its applicability in a large-scale health care service system. During a period of 6 months  a team of object modelers and domain experts formulated an OOAD methodology tailored to the Department of Defense Military Health System and used it to produce components of an object model for simple order processing. This methodology and the lessons learned during its implementation are described. This approach is necessary to achieve broad interoperability among heterogeneous automated information systems.Teaching computer interfacing with virtual instruments in an object-oriented language.PubMed CentralGulotta  M1995-01-01LabVIEW is a graphic object-oriented computer language developed to facilitate hardware/software communication. LabVIEW is a complete computer language that can be used like Basic  FORTRAN  or C. In LabVIEW one creates virtual instruments that aesthetically look like real instruments but are controlled by sophisticated computer programs. There are several levels of data acquisition VIs that make it easy to control data flow  and many signal processing and analysis algorithms come with the software as premade VIs. In the classroom  the similarity between virtual and real instruments helps students understand how information is passed between the computer and attached instruments. The software may be used in the absence of hardware so that students can work at home as well as in the classroom. This article demonstrates how LabVIEW can be used to control data flow between computers and instruments  points out important features for signal processing and analysis  and shows how virtual instruments may be used in place of physical instrumentation. Applications of LabVIEW to the teaching laboratory are also discussed  and a plausible course outline is given. PMID:8580361Teaching computer interfacing with virtual instruments in an object-oriented language.PubMedGulotta  M1995-11-01LabVIEW is a graphic object-oriented computer language developed to facilitate hardware/software communication. LabVIEW is a complete computer language that can be used like Basic  FORTRAN  or C. In LabVIEW one creates virtual instruments that aesthetically look like real instruments but are controlled by sophisticated computer programs. There are several levels of data acquisition VIs that make it easy to control data flow  and many signal processing and analysis algorithms come with the software as premade VIs. In the classroom  the similarity between virtual and real instruments helps students understand how information is passed between the computer and attached instruments. The software may be used in the absence of hardware so that students can work at home as well as in the classroom. This article demonstrates how LabVIEW can be used to control data flow between computers and instruments  points out important features for signal processing and analysis  and shows how virtual instruments may be used in place of physical instrumentation. Applications of LabVIEW to the teaching laboratory are also discussed  and a plausible course outline is given.An object oriented code for simulating supersymmetric Yang-Mills theoriesNASA Astrophysics Data System (ADS)Catterall  Simon; Joseph  Anosh2012-06-01We present SUSY_LATTICE - a C++ program that can be used to simulate certain classes of supersymmetric Yang-Mills (SYM) theories  including the well known N=4 SYM in four dimensions  on a flat Euclidean space-time lattice. Discretization of SYM theories is an old problem in lattice field theory. It has resisted solution until recently when new ideas drawn from orbifold constructions and topological field theories have been brought to bear on the question. The result has been the creation of a new class of lattice gauge theories in which the lattice action is invariant under one or more supersymmetries. The resultant theories are local  free of doublers and also possess exact gauge-invariance. In principle they form the basis for a truly non-perturbative definition of the continuum SYM theories. In the continuum limit they reproduce versions of the SYM theories formulated in terms of twisted fields  which on a flat space-time is just a change of the field variables. In this paper  we briefly review these ideas and then go on to provide the details of the C++ code. We sketch the design of the code  with particular emphasis being placed on SYM theories with N=(2 2) in two dimensions and N=4 in three and four dimensions  making one-to-one comparisons between the essential components of the SYM theories and their corresponding counterparts appearing in the simulation code. The code may be used to compute several quantities associated with the SYM theories such as the Polyakov loop  mean energy  and the width of the scalar eigenvalue distributions. Program summaryProgram title: SUSY_LATTICE Catalogue identifier: AELS_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AELS_v1_0.html Program obtainable from: CPC Program Library  Queen's University  Belfast  N. Ireland Licensing provisions: Standard CPC license  http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program  including test data  etc.: 9315 No. of bytes in distributed programDevelopment of a Dynamically Configurable  Object-Oriented Framework for Distributed  Multi-modal Computational Aerospace Systems SimulationNASA Technical Reports Server (NTRS)Afjeh  Abdollah A.; Reed  John A.2003-01-01The following reports are presented on this project:A first year progress report on: Development of a Dynamically Configurable Object-Oriented Framework for Distributed  Multi-modal Computational Aerospace Systems Simulation; A second year progress report on: Development of a Dynamically Configurable  Object-Oriented Framework for Distributed  Multi-modal Computational Aerospace Systems Simulation; An Extensible  Interchangeable and Sharable Database Model for Improving Multidisciplinary Aircraft Design; Interactive  Secure Web-enabled Aircraft Engine Simulation Using XML Databinding Integration; and Improving the Aircraft Design Process Using Web-based Modeling and Simulation.Automated Source-Code-Based Testing of Object-Oriented SoftwareNASA Astrophysics Data System (ADS)Gerlich  Ralf; Gerlich  Rainer; Dietrich  Carsten2014-08-01With the advent of languages such as C++ and Java in mission- and safety-critical space on-board software  new challenges for testing and specifically automated testing arise. In this paper we discuss some of these challenges  consequences and solutions based on an experiment in automated source- code-based testing for C++.High Performance Object-Oriented Scientific Programming in Fortran 90NASA Technical Reports Server (NTRS)Norton  Charles D.; Decyk  Viktor K.; Szymanski  Boleslaw K.1997-01-01We illustrate how Fortran 90 supports object-oriented concepts by example of plasma particle computations on the IBM SP. Our experience shows that Fortran 90 and object-oriented methodology give high performance while providing a bridge from Fortran 77 legacy codes to modern programming principles. All of our object-oriented Fortran 90 codes execute more quickly thatn the equeivalent C++ versions  yet the abstraction modelling capabilities used for scentific programming are comparably powereful.PyCOOL â€” A Cosmological Object-Oriented Lattice code written in PythonNASA Astrophysics Data System (ADS)Sainio  J.2012-04-01There are a number of different phenomena in the early universe that have to be studied numerically with lattice simulations. This paper presents a graphics processing unit (GPU) accelerated Python program called PyCOOL that solves the evolution of scalar fields in a lattice with very precise symplectic integrators. The program has been written with the intention to hit a sweet spot of speed  accuracy and user friendliness. This has been achieved by using the Python language with the PyCUDA interface to make a program that is easy to adapt to different scalar field models. In this paper we derive the symplectic dynamics that govern the evolution of the system and then present the implementation of the program in Python and PyCUDA. The functionality of the program is tested in a chaotic inflation preheating model  a single field oscillon case and in a supersymmetric curvaton model which leads to Q-ball production. We have also compared the performance of a consumer graphics card to a professional Tesla compute card in these simulations. We find that the program is not only accurate but also very fast. To further increase the usefulness of the program we have equipped it with numerous post-processing functions that provide useful information about the cosmological model. These include various spectra and statistics of the fields. The program can be additionally used to calculate the generated curvature perturbation. The program is publicly available under GNU General Public License at https://github.com/jtksai/PyCOOL. Some additional information can be found from http://www.physics.utu.fi/tiedostot/theory/particlecosmology/pycool/.Distributed Object Oriented ProgrammingDTIC Science & Technology1990-02-01of the object oriented model of computation. Therefore  object oriented programming can provide the programmer with good conceptual tools to divide his...LABOR SALES-COMMISSION). The symbol + refers to the addition function and takes any number of numeric arguments. The third subtype of list forms is the...2) ’(:SEND-DONE) (SEWF (AREF OBJECT-i1-MESSAGES-SENT 2) ’(PROGN (FORMAT T ""-s methd completely executed instr-ptr -s-V NAME %INSTR-PTR%) (INCFLegacy systems: managing evolution through integration in a distributed and object-oriented computing environment.PubMedLemaitre  D; Sauquet  D; Fofol  I; Tanguy  L; Jean  F C; Degoulet  P1995-01-01Legacy systems are crucial for organizations since they support key functionalities. But they become obsolete with aging and the apparition of new techniques. Managing their evolution is a key issue in software engineering. This paper presents a strategy that has been developed at Broussais University Hospital in Paris to make a legacy system devoted to the management of health care units evolve towards a new up-to-date software. A two-phase evolution pathway is described. The first phase consists in separating the interface from the data storage and application control and in using a communication channel between the individualized components. The second phase proposes to use an object-oriented DBMS in place of the homegrown system. An application example for the management of hypertensive patients is described.Legacy systems: managing evolution through integration in a distributed and object-oriented computing environment.PubMed CentralLemaitre  D.; Sauquet  D.; Fofol  I.; Tanguy  L.; Jean  F. C.; Degoulet  P.1995-01-01Legacy systems are crucial for organizations since they support key functionalities. But they become obsolete with aging and the apparition of new techniques. Managing their evolution is a key issue in software engineering. This paper presents a strategy that has been developed at Broussais University Hospital in Paris to make a legacy system devoted to the management of health care units evolve towards a new up-to-date software. A two-phase evolution pathway is described. The first phase consists in separating the interface from the data storage and application control and in using a communication channel between the individualized components. The second phase proposes to use an object-oriented DBMS in place of the homegrown system. An application example for the management of hypertensive patients is described. PMID:8563252Development of a Dynamically Configurable Object-Oriented Framework for Distributed  Multi-modal Computational Aerospace Systems SimulationNASA Technical Reports Server (NTRS)Afjeh  Abdollah A.; Reed  John A.2003-01-01This research is aimed at developing a neiv and advanced simulation framework that will significantly improve the overall efficiency of aerospace systems design and development. This objective will be accomplished through an innovative integration of object-oriented and Web-based technologies ivith both new and proven simulation methodologies. The basic approach involves Ihree major areas of research: Aerospace system and component representation using a hierarchical object-oriented component model which enables the use of multimodels and enforces component interoperability. Collaborative software environment that streamlines the process of developing  sharing and integrating aerospace design and analysis models. . Development of a distributed infrastructure which enables Web-based exchange of models to simplify the collaborative design process  and to support computationally intensive aerospace design and analysis processes. Research for the first year dealt with the design of the basic architecture and supporting infrastructure  an initial implementation of that design  and a demonstration of its application to an example aircraft engine system simulation.An Object-Oriented Approach to the Development of Computer-Assisted Instructional Material Using HypertextDTIC Science & Technology1988-12-01reading on computers for more than 10 or 15 minutes . If it takes any longer I would rather have a piece of paper in front of me. It did provide an outline...advisor  Capt. David Umphress. I thank Dave also for the moral support he provided by agreeing to advise this thesis  and by providing timely...2.17 information using... text  graphics  video   music  voice  and animation"" (Williams  1987:109; Conklin  1987a:32). Even so  HyperCard has been veryObject-oriented productivity metricsNASA Technical Reports Server (NTRS)Connell  John L.; Eller  Nancy1992-01-01Software productivity metrics are useful for sizing and costing proposed software and for measuring development productivity. Estimating and measuring source lines of code (SLOC) has proven to be a bad idea because it encourages writing more lines of code and using lower level languages. Function Point Analysis is an improved software metric system  but it is not compatible with newer rapid prototyping and object-oriented approaches to software development. A process is presented here for counting object-oriented effort points  based on a preliminary object-oriented analysis. It is proposed that this approach is compatible with object-oriented analysis  design  programming  and rapid prototyping. Statistics gathered on actual projects are presented to validate the approach.PRELIMINARY COUPLING OF THE MONTE CARLO CODE OPENMC AND THE MULTIPHYSICS OBJECT-ORIENTED SIMULATION ENVIRONMENT (MOOSE) FOR ANALYZING DOPPLER FEEDBACK IN MONTE CARLO SIMULATIONSSciTech ConnectMatthew Ellis; Derek Gaston; Benoit ForgetIn recent years the use of Monte Carlo methods for modeling reactors has become feasible due to the increasing availability of massively parallel computer systems. One of the primary challenges yet to be fully resolved  however  is the efficient and accurate inclusion of multiphysics feedback in Monte Carlo simulations. The research in this paper presents a preliminary coupling of the open source Monte Carlo code OpenMC with the open source Multiphysics Object-Oriented Simulation Environment (MOOSE). The coupling of OpenMC and MOOSE will be used to investigate efficient and accurate numerical methods needed to include multiphysics feedback in Monte Carlo codes.moreÂ Â» An investigation into the sensitivity of Doppler feedback to fuel temperature approximations using a two dimensional 17x17 PWR fuel assembly is presented in this paper. The results show a functioning multiphysics coupling between OpenMC and MOOSE. The coupling utilizes Functional Expansion Tallies to accurately and efficiently transfer pin power distributions tallied in OpenMC to unstructured finite element meshes used in MOOSE. The two dimensional PWR fuel assembly case also demonstrates that for a simplified model the pin-by-pin doppler feedback can be adequately replicated by scaling a representative pin based on pin relative powers.Â«Â lessObject-oriented Technology for Compressor SimulationNASA Technical Reports Server (NTRS)Drummond  C. K.; Follen  G. J.; Cannon  M. R.1994-01-01An object-oriented basis for interdisciplinary compressor simulation can  in principle  overcome several barriers associated with the traditional structured (procedural) development approach. This paper presents the results of a research effort with the objective to explore the repercussions on design  analysis  and implementation of a compressor model in an object oriented (OO) language  and to examine the ability of the OO system design to accommodate computational fluid dynamics (CFD) code for compressor performance prediction. Three fundamental results are that: (1) the selection of the object oriented language is not the central issue; enhanced (interdisciplinary) analysis capability derives from a broader focus on object-oriented technology; (2) object-oriented designs will produce more effective and reusable computer programs when the technology is applied to issues involving complex system inter-relationships (more so than when addressing the complex physics of an isolated discipline); and (3) the concept of disposable prototypes is effective for exploratory research programs  but this requires organizations to have a commensurate long-term perspective. This work also suggests that interdisciplinary simulation can be effectively accomplished (over several levels of fidelity) with a mixed language treatment (i.e.  FORTRAN-C++)  reinforcing the notion the OO technology implementation into simulations is a 'journey' in which the syntax can  by design  continuously evolve.OFF  Open source Finite volume Fluid dynamics code: A free  high-order solver based on parallel  modular  object-oriented Fortran APINASA Astrophysics Data System (ADS)Zaghi  S.2014-07-01OFF  an open source (free software) code for performing fluid dynamics simulations  is presented. The aim of OFF is to solve  numerically  the unsteady (and steady) compressible Navier-Stokes equations of fluid dynamics by means of finite volume techniques: the research background is mainly focused on high-order (WENO) schemes for multi-fluids  multi-phase flows over complex geometries. To this purpose a highly modular  object-oriented application program interface (API) has been developed. In particular  the concepts of data encapsulation and inheritance available within Fortran language (from standard 2003) have been stressed in order to represent each fluid dynamics ""entity"" (e.g. the conservative variables of a finite volume  its geometry  etcâ€¦) by a single object so that a large variety of computational libraries can be easily (and efficiently) developed upon these objects. The main features of OFF can be summarized as follows: Programming LanguageOFF is written in standard (compliant) Fortran 2003; its design is highly modular in order to enhance simplicity of use and maintenance without compromising the efficiency; Parallel Frameworks Supported the development of OFF has been also targeted to maximize the computational efficiency: the code is designed to run on shared-memory multi-cores workstations and distributed-memory clusters of shared-memory nodes (supercomputers); the code's parallelization is based on Open Multiprocessing (OpenMP) and Message Passing Interface (MPI) paradigms; Usability  Maintenance and Enhancement in order to improve the usability  maintenance and enhancement of the code also the documentation has been carefully taken into account; the documentation is built upon comprehensive comments placed directly into the source files (no external documentation files needed): these comments are parsed by means of doxygen free software producing high quality html and latex documentation pages; the distributed versioning system referred as gitGeneral object-oriented software developmentNASA Technical Reports Server (NTRS)Seidewitz  Edwin V.; Stark  Mike1986-01-01Object-oriented design techniques are gaining increasing popularity for use with the Ada programming language. A general approach to object-oriented design which synthesizes the principles of previous object-oriented methods into the overall software life-cycle  providing transitions from specification to design and from design to code. It therefore provides the basis for a general object-oriented development methodology.Object Oriented Learning ObjectsERIC Educational Resources Information CenterMorris  Ed2005-01-01We apply the object oriented software engineering (OOSE) design methodology for software objects (SOs) to learning objects (LOs). OOSE extends and refines design principles for authoring dynamic reusable LOs. Our learning object class (LOC) is a template from which individualised LOs can be dynamically created for  or by  students. The propertiesâ€¦Application of an object-oriented programming paradigm in three-dimensional computer modeling of mechanically active gastrointestinal tissues.PubMedRashev  P Z; Mintchev  M P; Bowes  K L2000-09-01The aim of this study was to develop a novel three-dimensional (3-D) object-oriented modeling approach incorporating knowledge of the anatomy  electrophysiology  and mechanics of externally stimulated excitable gastrointestinal (GI) tissues and emphasizing the ""stimulus-response"" principle of extracting the modeling parameters. The modeling method used clusters of class hierarchies representing GI tissues from three perspectives: 1) anatomical; 2) electrophysiological; and 3) mechanical. We elaborated on the first four phases of the object-oriented system development life-cycle: 1) analysis; 2) design; 3) implementation; and 4) testing. Generalized cylinders were used for the implementation of 3-D tissue objects modeling the cecum  the descending colon  and the colonic circular smooth muscle tissue. The model was tested using external neural electrical tissue excitation of the descending colon with virtual implanted electrodes and the stimulating current density distributions over the modeled surfaces were calculated. Finally  the tissue deformations invoked by electrical stimulation were estimated and represented by a mesh-surface visualization technique.Object-oriented design for accelerator controlSciTech ConnectStok  P.D.V. van der; Berk  F. van den; Deckers  R.1994-02-01An object-oriented design for the distributed computer control system of the accelerator ring EUTERPE is presented. Because of the experimental nature of the ring  flexibility is of the utmost importance. The object-oriented principles have contributed considerably to the flexibility of the design incorporating multiple views  multi-level access and distributed surveillance.Object-oriented design and programming in medical decision support.PubMedHeathfield  H; Armstrong  J; Kirkham  N1991-12-01The concept of object-oriented design and programming has recently received a great deal of attention from the software engineering community. This paper highlights the realisable benefits of using the object-oriented approach in the design and development of clinical decision support systems. These systems seek to build a computational model of some problem domain and therefore tend to be exploratory in nature. Conventional procedural design techniques do not support either the process of model building or rapid prototyping. The central concepts of the object-oriented paradigm are introduced  namely encapsulation  inheritance and polymorphism  and their use illustrated in a case study  taken from the domain of breast histopathology. In particular  the dual roles of inheritance in object-oriented programming are examined  i.e.  inheritance as a conceptual modelling tool and inheritance as a code reuse mechanism. It is argued that the use of the former is not entirely intuitive and may be difficult to incorporate into the design process. However  inheritance as a means of optimising code reuse offers substantial technical benefits.Object-oriented design and implementation of CFDLab: a computer-assisted learning tool for fluid dynamics using dual reciprocity boundary element methodologyNASA Astrophysics Data System (ADS)Friedrich  J.1999-08-01As lecturers  our main concern and goal is to develop more attractive and efficient ways of communicating up-to-date scientific knowledge to our students and facilitate an in-depth understanding of physical phenomena. Computer-based instruction is very promising to help both teachers and learners in their difficult task  which involves complex cognitive psychological processes. This complexity is reflected in high demands on the design and implementation methods used to create computer-assisted learning (CAL) programs. Due to their concepts  flexibility  maintainability and extended library resources  object-oriented modeling techniques are very suitable to produce this type of pedagogical tool. Computational fluid dynamics (CFD) enjoys not only a growing importance in today's research  but is also very powerful for teaching and learning fluid dynamics. For this purpose  an educational PC program for university level called 'CFDLab 1.1' for Windowsâ„¢ was developed with an interactive graphical user interface (GUI) for multitasking and point-and-click operations. It uses the dual reciprocity boundary element method as a versatile numerical scheme  allowing to handle a variety of relevant governing equations in two dimensions on personal computers due to its simple pre- and postprocessing including 2D Laplace  Poisson  diffusion  transient convection-diffusion.Object-Oriented Programming in High Schools the Turing Way.ERIC Educational Resources Information CenterHolt  Richard C.This paper proposes an approach to introducing object-oriented concepts to high school computer science students using the Object-Oriented Turing (OOT) language. Students can learn about basic object-oriented (OO) principles such as classes and inheritance by using and expanding a collection of classes that draw pictures like circles and happyâ€¦Multiphysics Object Oriented Simulation EnvironmentSciTech ConnectThe Multiphysics Object Oriented Simulation Environment (MOOSE) software library developed at Idaho National Laboratory is a tool. MOOSE  like other tools  doesn't actually complete a task. Instead  MOOSE seeks to reduce the effort required to create engineering simulation applications. MOOSE itself is a software library: a blank canvas upon which you write equations and then MOOSE can help you solve them. MOOSE is comparable to a spreadsheet application. A spreadsheet  by itself  doesn't do anything. Only once equations are entered into it will a spreadsheet application compute anything. Such is the same for MOOSE. An engineer or scientist can utilizemoreÂ Â» the equation solvers within MOOSE to solve equations related to their area of study. For instance  a geomechanical scientist can input equations related to water flow in underground reservoirs and MOOSE can solve those equations to give the scientist an idea of how water could move over time. An engineer might input equations related to the forces in steel beams in order to understand the load bearing capacity of a bridge. Because MOOSE is a blank canvas it can be useful in many scientific and engineering pursuits.Â«Â lessObject-oriented biomedical system modelling--the language.PubMedHakman  M; Groth  T1999-11-01The paper describes a new object-oriented biomedical continuous system modelling language (OOBSML). It is fully object-oriented and supports model inheritance  encapsulation  and model component instantiation and behaviour polymorphism. Besides the traditional differential and algebraic equation expressions the language includes also formal expressions for documenting models and defining model quantity types and quantity units. It supports explicit definition of model input-  output- and state quantities  model components and component connections. The OOBSML model compiler produces self-contained  independent  executable model components that can be instantiated and used within other OOBSML models and/or stored within model and model component libraries. In this way complex models can be structured as multilevel  multi-component model hierarchies. Technically the model components produced by the OOBSML compiler are executable computer code objects based on distributed object and object request broker technology. This paper includes both the language tutorial and the formal language syntax and semantic description.An object oriented extension to CLIPSNASA Technical Reports Server (NTRS)Sobkowicz  Clifford1990-01-01A presentation of software sub-system developed to augment C Language Production Systems (CLIPS) with facilities for object oriented Knowledge representation. Functions are provided to define classes  instantiate objects  access attributes  and assert object related facts. This extension is implemented via the CLIPS user function interface and does not require modification of any CLIPS code. It does rely on internal CLIPS functions for memory management and symbol representation.Pedagogical Issues in Object Orientation.ERIC Educational Resources Information CenterNerur  Sridhar; Ramanujan  Sam; Kesh  Someswar2002-01-01Discusses the need for people with object-oriented (OO) skills  explains benefits of OO in software development  and addresses some of the difficulties in teaching OO. Topics include the evolution of programming languages; differences between OO and traditional approaches; differences from data modeling; and Unified Modeling Language (UML) andâ€¦An Ada Object Oriented Missile Flight SimulationDTIC Science & Technology1991-09-01identify by block number) This thesis uses the Ada programming language in the design and development of an air-to-air missile flight simulation with...object oriented techniques and sound software engineering principles. The simulation is designed to be more understandable  modifiable  efficient and...Department of Computer Science ii ABSTRACT This thesis uses the Ada programming language in the design and development of an air-to-air missile flightObject Oriented Modeling and DesignNASA Technical Reports Server (NTRS)Shaykhian  Gholam Ali2007-01-01The Object Oriented Modeling and Design seminar is intended for software professionals and students  it covers the concepts and a language-independent graphical notation that can be used to analyze problem requirements  and design a solution to the problem. The seminar discusses the three kinds of object-oriented models class  state  and interaction. The class model represents the static structure of a system  the state model describes the aspects of a system that change over time as well as control behavior and the interaction model describes how objects collaborate to achieve overall results. Existing knowledge of object oriented programming may benefit the learning of modeling and good design. Specific expectations are: Create a class model  Read  recognize  and describe a class model  Describe association and link  Show abstract classes used with multiple inheritance  Explain metadata  reification and constraints  Group classes into a package  Read  recognize  and describe a state model  Explain states and transitions  Read  recognize  and describe interaction model  Explain Use cases and use case relationships  Show concurrency in activity diagram  Object interactions in sequence diagram.An Exploration and Analysis of the Relationships among Object Oriented Programming  Hypermedia  and Hypertalk.ERIC Educational Resources Information CenterMilet  Lynn K.; Harvey  Francis A.Hypermedia and object oriented programming systems (OOPs) represent examples of ""open"" computer environments that allow the user access to parts of the code or operating system. Both systems share fundamental intellectual concepts (objects  messages  methods  classes  and inheritance)  so that an understanding of hypermedia can help inâ€¦Exploring the controls of soil biogeochemistry in a restored coastal wetland using object-oriented computer simulations of uptake kinetics and thermodynamic optimization in batch reactorsNASA Astrophysics Data System (ADS)Payn  R. A.; Helton  A. M.; Poole  G.; Izurieta  C.; Bernhardt  E. S.; Burgin  A. J.2012-12-01Many hypotheses have been proposed to predict patterns of biogeochemical redox reactions based on the availability of electron donors and acceptors and the thermodynamic theory of chemistry. Our objective was to develop a computer model that would allow us to test various alternatives of these hypotheses against data gathered from soil slurry batch reactors  experimental soil perfusion cores  and in situ soil profile observations from the restored Timberlake Wetland in coastal North Carolina  USA. Software requirements to meet this objective included the ability to rapidly develop and compare different hypothetical formulations of kinetic and thermodynamic theory  and the ability to easily change the list of potential biogeochemical reactions used in the optimization scheme. For future work  we also required an object pattern that could easily be coupled with an existing soil hydrologic model. These requirements were met using Network Exchange Objects (NEO)  our recently developed object-oriented distributed modeling framework that facilitates simulations of multiple interacting currencies moving through network-based systems. An initial implementation of the object pattern was developed in NEO based on maximizing growth of the microbial community from available dissolved organic carbon. We then used this implementation to build a modeling system for comparing results across multiple simulated batch reactors with varied initial solute concentrations  varied biogeochemical parameters  or varied optimization schemes. Among heterotrophic aerobic and anaerobic reactions  we have found that this model reasonably predicts the use of terminal electron acceptors in simulated batch reactors  where reactions with higher energy yields occur before reactions with lower energy yields. However  among the aerobic reactions  we have also found this model predicts dominance of chemoautotrophs (e.g.  nitrifiers) when their electron donor (e.g.  ammonium) is abundant  despite theObject-oriented Persistent HomologyPubMed CentralWang  Bao; Wei  Guo-Wei2015-01-01Persistent homology provides a new approach for the topological simplification of big data via measuring the life time of intrinsic topological features in a filtration process and has found its success in scientific and engineering applications. However  such a success is essentially limited to qualitative data classification and analysis. Indeed  persistent homology has rarely been employed for quantitative modeling and prediction. Additionally  the present persistent homology is a passive tool  rather than a proactive technique  for classification and analysis. In this work  we outline a general protocol to construct object-oriented persistent homology methods. By means of differential geometry theory of surfaces  we construct an objective functional  namely  a surface free energy defined on the data of interest. The minimization of the objective functional leads to a Laplace-Beltrami operator which generates a multiscale representation of the initial data and offers an objective oriented filtration process. The resulting differential geometry based object-oriented persistent homology is able to preserve desirable geometric features in the evolutionary filtration and enhances the corresponding topological persistence. The cubical complex based homology algorithm is employed in the present work to be compatible with the Cartesian representation of the Laplace-Beltrami flow. The proposed Laplace-Beltrami flow based persistent homology method is extensively validated. The consistence between Laplace-Beltrami flow based filtration and Euclidean distance based filtration is confirmed on the Vietoris-Rips complex for a large amount of numerical tests. The convergence and reliability of the present Laplace-Beltrami flow based cubical complex filtration approach are analyzed over various spatial and temporal mesh sizes. The Laplace-Beltrami flow based persistent homology approach is utilized to study the intrinsic topology of proteins and fullerene molecules. Based on aRisk-Based Object Oriented TestingNASA Technical Reports Server (NTRS)Rosenberg  Linda H.; Stapko  Ruth; Gallo  Albert2000-01-01Software testing is a well-defined phase of the software development life cycle. Functional (""black box"") testing and structural (""white box"") testing are two methods of test case design commonly used by software developers. A lesser known testing method is risk-based testing  which takes into account the probability of failure of a portion of code as determined by its complexity. For object oriented programs  a methodology is proposed for identification of risk-prone classes. Risk-based testing is a highly effective testing technique that can be used to find and fix the most important problems as quickly as possible.The STAGS computer codeNASA Technical Reports Server (NTRS)Almroth  B. O.; Brogan  F. A.1978-01-01Basic information about the computer code STAGS (Structural Analysis of General Shells) is presented to describe to potential users the scope of the code and the solution procedures that are incorporated. Primarily  STAGS is intended for analysis of shell structures  although it has been extended to more complex shell configurations through the inclusion of springs and beam elements. The formulation is based on a variational approach in combination with local two dimensional power series representations of the displacement components. The computer code includes options for analysis of linear or nonlinear static stress  stability  vibrations  and transient response. Material as well as geometric nonlinearities are included. A few examples of applications of the code are presented for further illustration of its scope.Gas turbine system simulation: An object-oriented approachNASA Technical Reports Server (NTRS)Drummond  Colin K.; Follen  Gregory J.; Putt  Charles W.1993-01-01A prototype gas turbine engine simulation has been developed that offers a generalized framework for the simulation of engines subject to steady-state and transient operating conditions. The prototype is in preliminary form  but it successfully demonstrates the viability of an object-oriented approach for generalized simulation applications. Although object oriented programming languages are-relative to FORTRAN-somewhat austere  it is proposed that gas turbine simulations of an interdisciplinary nature will benefit significantly in terms of code reliability  maintainability  and manageability. This report elucidates specific gas turbine simulation obstacles that an object-oriented framework can overcome and describes the opportunity for interdisciplinary simulation that the approach offers.An object oriented generic controller using CLIPSNASA Technical Reports Server (NTRS)Nivens  Cody R.1990-01-01In today's applications  the need for the division of code and data has focused on the growth of object oriented programming. This philosophy gives software engineers greater control over the environment of an application. Yet the use of object oriented design does not exclude the need for greater understanding by the application of what the controller is doing. Such understanding is only possible by using expert systems. Providing a controller that is capable of controlling an object by using rule-based expertise would expedite the use of both object oriented design and expert knowledge of the dynamic of an environment in modern controllers. This project presents a model of a controller that uses the CLIPS expert system and objects in C++ to create a generic controller. The polymorphic abilities of C++ allow for the design of a generic component stored in individual data files. Accompanying the component is a set of rules written in CLIPS which provide the following: the control of individual components  the input of sensory data from components and the ability to find the status of a given component. Along with the data describing the application  a set of inference rules written in CLIPS allows the application to make use of sensory facts and status and control abilities. As a demonstration of this ability  the control of the environment of a house is provided. This demonstration includes the data files describing the rooms and their contents as far as devices  windows and doors. The rules used for the home consist of the flow of people in the house and the control of devices by the home owner.Etomica: an object-oriented framework for molecular simulation.PubMedSchultz  Andrew J; Kofke  David A2015-03-30We describe the design of an object-oriented library of software components that are suitable for constructing simulations of systems of interacting particles. The emphasis of the discussion is on the general design of the components and how they interact  and less on details of the programming interface or its implementation. Example code is provided as an aid to understanding object-oriented programming structures and to demonstrate how the framework is applied. Â© 2015 Wiley Periodicals  Inc.Object-Oriented Implementation of the NAS Parallel Benchmarks using Charm++NASA Technical Reports Server (NTRS)Krishnan  Sanjeev; Bhandarkar  Milind; Kale  Laxmikant V.1996-01-01This report describes experiences with implementing the NAS Computational Fluid Dynamics benchmarks using a parallel object-oriented language  Charm++. Our main objective in implementing the NAS CFD kernel benchmarks was to develop a code that could be used to easily experiment with different domain decomposition strategies and dynamic load balancing. We also wished to leverage the object-orientation provided by the Charm++ parallel object-oriented language  to develop reusable abstractions that would simplify the process of developing parallel applications. We first describe the Charm++ parallel programming model and the parallel object array abstraction  then go into detail about each of the Scalar Pentadiagonal (SP) and Lower/Upper Triangular (LU) benchmarks  along with performance results. Finally we conclude with an evaluation of the methodology used.Reeds computer codeNASA Technical Reports Server (NTRS)Bjork  C.1981-01-01The REEDS (rocket exhaust effluent diffusion single layer) computer code is used for the estimation of certain rocket exhaust effluent concentrations and dosages and their distributions near the Earth's surface following a rocket launch event. Output from REEDS is used in producing near real time air quality and environmental assessments of the effects of certain potentially harmful effluents  namely HCl  Al2O3  CO  and NO.Object oriented studies into artificial space debrisNASA Technical Reports Server (NTRS)Adamson  J. M.; Marshall  G.1988-01-01A prototype simulation is being developed under contract to the Royal Aerospace Establishment (RAE)  Farnborough  England  to assist in the discrimination of artificial space objects/debris. The methodology undertaken has been to link Object Oriented programming  intelligent knowledge based system (IKBS) techniques and advanced computer technology with numeric analysis to provide a graphical  symbolic simulation. The objective is to provide an additional layer of understanding on top of conventional classification methods. Use is being made of object and rule based knowledge representation  multiple reasoning  truth maintenance and uncertainty. Software tools being used include Knowledge Engineering Environment (KEE) and SymTactics for knowledge representation. Hooks are being developed within the SymTactics framework to incorporate mathematical models describing orbital motion and fragmentation. Penetration and structural analysis can also be incorporated. SymTactics is an Object Oriented discrete event simulation tool built as a domain specific extension to the KEE environment. The tool provides facilities for building  debugging and monitoring dynamic (military) simulations.MELCOR computer code manualsSciTech ConnectSummers  R.M.; Cole  R.K. Jr.; Smith  R.C.1995-03-01MELCOR is a fully integrated  engineering-level computer code that models the progression of severe accidents in light water reactor nuclear power plants. MELCOR is being developed at Sandia National Laboratories for the U.S. Nuclear Regulatory Commission as a second-generation plant risk assessment tool and the successor to the Source Term Code Package. A broad spectrum of severe accident phenomena in both boiling and pressurized water reactors is treated in MELCOR in a unified framework. These include: thermal-hydraulic response in the reactor coolant system  reactor cavity  containment  and confinement buildings; core heatup  degradation  and relocation; core-concrete attack; hydrogen production  transport  andmoreÂ Â» combustion; fission product release and transport; and the impact of engineered safety features on thermal-hydraulic and radionuclide behavior. Current uses of MELCOR include estimation of severe accident source terms and their sensitivities and uncertainties in a variety of applications. This publication of the MELCOR computer code manuals corresponds to MELCOR 1.8.3  released to users in August  1994. Volume 1 contains a primer that describes MELCOR`s phenomenological scope  organization (by package)  and documentation. The remainder of Volume 1 contains the MELCOR Users Guides  which provide the input instructions and guidelines for each package. Volume 2 contains the MELCOR Reference Manuals  which describe the phenomenological models that have been implemented in each package.Â«Â lessAn Object Oriented Extensible Architecture for Affordable Aerospace Propulsion SystemsNASA Technical Reports Server (NTRS)Follen  Gregory J.; Lytle  John K. (Technical Monitor)2002-01-01Driven by a need to explore and develop propulsion systems that exceeded current computing capabilities  NASA Glenn embarked on a novel strategy leading to the development of an architecture that enables propulsion simulations never thought possible before. Full engine 3 Dimensional Computational Fluid Dynamic propulsion system simulations were deemed impossible due to the impracticality of the hardware and software computing systems required. However  with a software paradigm shift and an embracing of parallel and distributed processing  an architecture was designed to meet the needs of future propulsion system modeling. The author suggests that the architecture designed at the NASA Glenn Research Center for propulsion system modeling has potential for impacting the direction of development of affordable weapons systems currently under consideration by the Applied Vehicle Technology Panel (AVT). This paper discusses the salient features of the NPSS Architecture including its interface layer  object layer  implementation for accessing legacy codes  numerical zooming infrastructure and its computing layer. The computing layer focuses on the use and deployment of these propulsion simulations on parallel and distributed computing platforms which has been the focus of NASA Ames. Additional features of the object oriented architecture that support MultiDisciplinary (MD) Coupling  computer aided design (CAD) access and MD coupling objects will be discussed. Included will be a discussion of the successes  challenges and benefits of implementing this architecture.Mentat: An object-oriented macro data flow systemNASA Technical Reports Server (NTRS)Grimshaw  Andrew S.; Liu  Jane W. S.1988-01-01Mentat  an object-oriented macro data flow system designed to facilitate parallelism in distributed systems  is presented. The macro data flow model is a model of computation similar to the data flow model with two principal differences: the computational complexity of the actors is much greater than in traditional data flow systems  and there are persistent actors that maintain state information between executions. Mentat is a system that combines the object-oriented programming paradigm and the macro data flow model of computation. Mentat programs use a dynamic structure called a future list to represent the future of computations.Parallelization of an Object-Oriented Unstructured Aeroacoustics SolverNASA Technical Reports Server (NTRS)Baggag  Abdelkader; Atkins  Harold; Oezturan  Can; Keyes  David1999-01-01A computational aeroacoustics code based on the discontinuous Galerkin method is ported to several parallel platforms using MPI. The discontinuous Galerkin method is a compact high-order method that retains its accuracy and robustness on non-smooth unstructured meshes. In its semi-discrete form  the discontinuous Galerkin method can be combined with explicit time marching methods making it well suited to time accurate computations. The compact nature of the discontinuous Galerkin method also makes it well suited for distributed memory parallel platforms. The original serial code was written using an object-oriented approach and was previously optimized for cache-based machines. The port to parallel platforms was achieved simply by treating partition boundaries as a type of boundary condition. Code modifications were minimal because boundary conditions were abstractions in the original program. Scalability results are presented for the SCI Origin  IBM SP2  and clusters of SGI and Sun workstations. Slightly superlinear speedup is achieved on a fixed-size problem on the Origin  due to cache effects.Object-oriented millisecond timers for the PC.PubMedHamm  J P2001-11-01Object-oriented programming provides a useful structure for designing reusable code. Accurate millisecond timing is essential for many areas of research. With this in mind  this paper provides a Turbo Pascal unit containing an object-oriented millisecond timer. This approach allows for multiple timers to be running independently. The timers may also be set at different levels of temporal precision  such as 10(-3) (milliseconds) or 10(-5) sec. The object also is able to store the time of a flagged event for later examination without interrupting the ongoing timing operation.Development of a Dynamically Configurable  Object-Oriented Framework for Distributed  Multi-modal Computational Aerospace Systems Simulation: Second Year Progress ReportNASA Technical Reports Server (NTRS)Afjeh  Abdollah A.; Reed  John A.2003-01-01Mesh generation has long been recognized as a bottleneck in the CFD process. While much research on automating the volume mesh generation process have been relatively successful these methods rely on appropriate initial surface triangulation to work properly. Surface discretization has been one of the least automated steps in computational simulation due to its dependence on implicitly defined CAD surfaces and curves. Differences in CAD peometry engines manifest themselves in discrepancies in their interpretation of the same entities. This lack of ""good"" geometry causes significant problems for mesh generators  requiring users to ""repair"" the CAD geometry before mesh generation. The problem is exacerbated when CAD geometry is translated to other forms (e.g.  IGES )which do not include important topological and construction information in addition to entity geometry. One technique to avoid these problems is to access the CAD geometry directly from the mesh generating software  rather than through files. By accessing the geometry model (not a discretized version) in its native environment  t h s a proach avoids translation to a format which can deplete the model of topological information. Our approach to enable models developed in the Denali software environment to directly access CAD geometry and functions is through an Application Programming Interface (API) known as CAPRI. CAPRI provides a layer of indirection through which CAD-specific data may be accessed by an application program using CAD-system neutral C and FORTRAN language function calls. CAPRI supports a general set of CAD operations such as truth testing  geometry construction and entity queries.An outline of object-oriented philosophy.PubMedHarman  Graham2013-01-01This article summarises the principles of object-oriented philosophy and explains its similarities with  and differences from  the outlook of the natural sciences. Like science  the object-oriented position avoids the notion (quite common in philosophy) that the human-world relation is the ground of all others  such that scientific statements about the world would only be statements about the world as it is for humans. But unlike science  object-oriented metaphysics treats artificial  social  and fictional entities in the same way as natural ones  and also holds that the world can only be known allusively rather than directly.Three Object-Oriented enhancement for EPICSNASA Astrophysics Data System (ADS)Osberg  E. A.; Dohan  D. A.; Richter  R.; Biggs  R.; Chillara  K.; Wade  D.; Bossom  J.1994-12-01In line with our group's intention of producing software using  where possible  Object-Oriented methodologies and techniques in the development of RF control systems  we have undertaken three projects to enhance the EPICS software environment. Two of the projects involve interfaces to EPICs Channel Access from Object-Oriented languages. The third is an enhancement to the EPICS State Notation Language to better support the Shlaer-Mellor Object-Oriented Analysis and Design Methodology. This paper discusses the motivation  approaches  results and future directions of these three projects.Object-oriented models of cognitive processing.PubMedMather  G2001-05-01Information-processing models of vision and cognition are inspired by procedural programming languages. Models that emphasize object-based representations are closely related to object-oriented programming languages. The concepts underlying object-oriented languages provide a theoretical framework for cognitive processing that differs markedly from that offered by procedural languages. This framework is well-suited to a system designed to deal flexibly with discrete objects and unpredictable events in the world.Industrial Computer CodesNASA Technical Reports Server (NTRS)Shapiro  Wilbur1996-01-01This is an overview of new and updated industrial codes for seal design and testing. GCYLT (gas cylindrical seals -- turbulent)  SPIRALI (spiral-groove seals -- incompressible)  KTK (knife to knife) Labyrinth Seal Code  and DYSEAL (dynamic seal analysis) are covered. CGYLT uses G-factors for Poiseuille and Couette turbulence coefficients. SPIRALI is updated to include turbulence and inertia  but maintains the narrow groove theory. KTK labyrinth seal code handles straight or stepped seals. And DYSEAL provides dynamics for the seal geometry.Object oriented development of engineering software using CLIPSNASA Technical Reports Server (NTRS)Yoon  C. John1991-01-01Engineering applications involve numeric complexity and manipulations of a large amount of data. Traditionally  numeric computation has been the concern in developing an engineering software. As engineering application software became larger and more complex  management of resources such as data  rather than the numeric complexity  has become the major software design problem. Object oriented design and implementation methodologies can improve the reliability  flexibility  and maintainability of the resulting software; however  some tasks are better solved with the traditional procedural paradigm. The C Language Integrated Production System (CLIPS)  with deffunction and defgeneric constructs  supports the procedural paradigm. The natural blending of object oriented and procedural paradigms has been cited as the reason for the popularity of the C++ language. The CLIPS Object Oriented Language's (COOL) object oriented features are more versatile than C++'s. A software design methodology based on object oriented and procedural approaches appropriate for engineering software  and to be implemented in CLIPS was outlined. A method for sensor placement for Space Station Freedom is being implemented in COOL as a sample problem.Contour-based object orientation estimationNASA Astrophysics Data System (ADS)Alpatov  Boris; Babayan  Pavel2016-04-01Real-time object orientation estimation is an actual problem of computer vision nowadays. In this paper we propose an approach to estimate an orientation of objects lacking axial symmetry. Proposed algorithm is intended to estimate orientation of a specific known 3D object  so 3D model is required for learning. The proposed orientation estimation algorithm consists of 2 stages: learning and estimation. Learning stage is devoted to the exploring of studied object. Using 3D model we can gather set of training images by capturing 3D model from viewpoints evenly distributed on a sphere. Sphere points distribution is made by the geosphere principle. It minimizes the training image set. Gathered training image set is used for calculating descriptors  which will be used in the estimation stage of the algorithm. The estimation stage is focusing on matching process between an observed image descriptor and the training image descriptors. The experimental research was performed using a set of images of Airbus A380. The proposed orientation estimation algorithm showed good accuracy (mean error value less than 6Â°) in all case studies. The real-time performance of the algorithm was also demonstrated.Partitioning an object-oriented terminology schema.PubMedGu  H; Perl  Y; Halper  M; Geller  J; Kuo  F; Cimino  J J2001-07-01Controlled medical terminologies are increasingly becoming strategic components of various healthcare enterprises. However  the typical medical terminology can be difficult to exploit due to its extensive size and high density. The schema of a medical terminology offered by an object-oriented representation is a valuable tool in providing an abstract view of the terminology  enhancing comprehensibility and making it more usable. However  schemas themselves can be large and unwieldy. We present a methodology for partitioning a medical terminology schema into manageably sized fragments that promote increased comprehension. Our methodology has a refinement process for the subclass hierarchy of the terminology schema. The methodology is carried out by a medical domain expert in conjunction with a computer. The expert is guided by a set of three modeling rules  which guarantee that the resulting partitioned schema consists of a forest of trees. This makes it easier to understand and consequently use the medical terminology. The application of our methodology to the schema of the Medical Entities Dictionary (MED) is presented.Towards a general object-oriented software development methodologyNASA Technical Reports Server (NTRS)Seidewitz  ED; Stark  Mike1986-01-01Object diagrams were used to design a 5000 statement team training exercise and to design the entire dynamics simulator. The object diagrams are also being used to design another 50 000 statement Ada system and a personal computer based system that will be written in Modula II. The design methodology evolves out of these experiences as well as the limitations of other methods that were studied. Object diagrams  abstraction analysis  and associated principles provide a unified framework which encompasses concepts from Yourdin  Booch  and Cherry. This general object-oriented approach handles high level system design  possibly with concurrency  through object-oriented decomposition down to a completely functional level. How object-oriented concepts can be used in other phases of the software life-cycle  such as specification and testing is being studied concurrently.Object-Oriented Algorithm For Evaluation Of Fault TreesNASA Technical Reports Server (NTRS)Patterson-Hine  F. A.; Koen  B. V.1992-01-01Algorithm for direct evaluation of fault trees incorporates techniques of object-oriented programming. Reduces number of calls needed to solve trees with repeated events. Provides significantly improved software environment for such computations as quantitative analyses of safety and reliability of complicated systems of equipment (e.g.  spacecraft or factories).Object-Oriented Multi-Disciplinary Design  Analysis  and Optimization ToolNASA Technical Reports Server (NTRS)Pak  Chan-gi2011-01-01An Object-Oriented Optimization (O3) tool was developed that leverages existing tools and practices  and allows the easy integration and adoption of new state-of-the-art software. At the heart of the O3 tool is the Central Executive Module (CEM)  which can integrate disparate software packages in a cross platform network environment so as to quickly perform optimization and design tasks in a cohesive  streamlined manner. This object-oriented framework can integrate the analysis codes for multiple disciplines instead of relying on one code to perform the analysis for all disciplines. The CEM was written in FORTRAN and the script commands for each performance index were submitted through the use of the FORTRAN Call System command. In this CEM  the user chooses an optimization methodology  defines objective and constraint functions from performance indices  and provides starting and side constraints for continuous as well as discrete design variables. The structural analysis modules such as computations of the structural weight  stress  deflection  buckling  and flutter and divergence speeds have been developed and incorporated into the O3 tool to build an object-oriented Multidisciplinary Design  Analysis  and Optimization (MDAO) tool.Object-oriented programming for the biosciences.PubMedWiechert  W; Joksch  B; Wittig  R; Hartbrich  A; HÃ¶ner  T; MÃ¶llney  M1995-10-01The development of software systems for the biosciences is always closely connected to experimental practice. Programs must be able to handle the inherent complexity and heterogeneous structure of biological systems in combination with the measuring equipment. Moreover  a high degree of flexibility is required to treat rapidly changing experimental conditions. Object-oriented methodology seems to be well suited for this purpose. It enables an evolutionary approach to software development that still maintains a high degree of modularity. This paper presents experience with object-oriented technology gathered during several years of programming in the fields of bioprocess development and metabolic engineering. It concentrates on the aspects of experimental support  data analysis  interaction and visualization. Several examples are presented and discussed in the general context of the experimental cycle of knowledge acquisition  thus pointing out the benefits and problems of object-oriented technology in the specific application field of the biosciences. Finally  some strategies for future development are described.Preliminary Development of an Object-Oriented Optimization ToolNASA Technical Reports Server (NTRS)Pak  Chan-gi2011-01-01The National Aeronautics and Space Administration Dryden Flight Research Center has developed a FORTRAN-based object-oriented optimization (O3) tool that leverages existing tools and practices and allows easy integration and adoption of new state-of-the-art software. The object-oriented framework can integrate the analysis codes for multiple disciplines  as opposed to relying on one code to perform analysis for all disciplines. Optimization can thus take place within each discipline module  or in a loop between the central executive module and the discipline modules  or both. Six sample optimization problems are presented. The first four sample problems are based on simple mathematical equations; the fifth and sixth problems consider a three-bar truss  which is a classical example in structural synthesis. Instructions for preparing input data for the O3 tool are presented.What is ""Object-Oriented Programming""?NASA Astrophysics Data System (ADS)Stroustrup  Bjarne""Object-Oriented Programming"" and ""Data Abstraction"" have become very common terms. Unfortunately  few people agree on what they mean. I will offer informal definitions that appear to make sense in the context of languages like Ada  C++  Modula-2  Simula67  and Smalltalk. The general idea is to equate ""support for data abstraction"" with the ability to define and use new types and equate ""support for object-oriented programming"" with the ability to express type hierarchies. Features necessary to support these programming styles in a general purpose programming language will be discussed. The presentation centers around C++ but is not limited to facilities provided by that language.An Object Oriented Analysis Method for Ada and Embedded SystemsDTIC Science & Technology1989-12-01expansion of the paradligm from the coding anld desiningactivities into the earlier activity of reurmnsalyi.Ts hpl  begins by discussing the application of...response time: 0.1 seconds.I Step le: Identify Known Restrictions on the Software.I "" The cruise control system object code must fit within 16K of mem- orv...application of object-oriented techniques to the coding and desigll phases of the life cycle  as well as various approaches to requirements analysis. 3Adding intelligent services to an object oriented systemNASA Technical Reports Server (NTRS)Robideaux  Bret R.; Metzler  Theodore A.1994-01-01As today's software becomes increasingly complex  the need grows for intelligence of one sort or another to becomes part of the application  often an intelligence that does not readily fit the paradigm of one's software development. There are many methods of developing software  but at this time  the most promising is the object oriented (OO) method. This method involves an analysis to abstract the problem into separate 'objects' that are unique in the data that describe them and the behavior that they exhibit  and eventually to convert this analysis into computer code using a programming language that was designed (or retrofitted) for OO implementation. This paper discusses the creation of three different applications that are analyzed  designed  and programmed using the Shlaer/Mellor method of OO development and C++ as the programming language. All three  however  require the use of an expert system to provide an intelligence that C++ (or any other 'traditional' language) is not directly suited to supply. The flexibility of CLIPS permitted us to make modifications to it that allow seamless integration with any of our applications that require an expert system. We illustrate this integration with the following applications: (1) an after action review (AAR) station that assists a reviewer in watching a simulated tank battle and developing an AAR to critique the performance of the participants in the battle; (2) an embedded training system and over-the-shoulder coach for howitzer crewmen; and (3) a system to identify various chemical compounds from their infrared absorption spectra.Computer algorithm for coding gainNASA Technical Reports Server (NTRS)Dodd  E. E.1974-01-01Development of a computer algorithm for coding gain for use in an automated communications link design system. Using an empirical formula which defines coding gain as used in space communications engineering  an algorithm is constructed on the basis of available performance data for nonsystematic convolutional encoding with soft-decision (eight-level) Viterbi decoding.Multiphysics Object-Oriented Simulation Environment (MOOSE)ScienceCinemaNone2017-12-09Nuclear reactor operators can expand safety margins with more precise information about how materials behave inside operating reactors. INL's new simulation platform makes such studies easier & more informative by letting researchers ""plug-n-play"" their mathematical models  skipping years of computer code development.Teaching Quality Object-Oriented ProgrammingERIC Educational Resources Information CenterFeldman  Yishai A.2005-01-01Computer science students need to learn how to write high-quality software. An important methodology for achieving quality is design-by-contract  in which code is developed together with its specification  which is given as class invariants and method pre- and postconditions. This paper describes practical experience in teaching design-by-contractâ€¦GUI and Object Oriented Programming in COBOL.ERIC Educational Resources Information CenterLorents  Alden C.Various schools are struggling with the introduction of Object Oriented (OO) programming concepts and GUI (graphical user interfaces) within the traditional COBOL sequence. OO programming has been introduced in some of the curricula with languages such as C++  Smalltalk  and Java. Introducing OO programming into a typical COBOL sequence presentsâ€¦Object-oriented fault tree models applied to system diagnosisNASA Technical Reports Server (NTRS)Iverson  David L.; Patterson-Hine  F. A.1990-01-01When a diagnosis system is used in a dynamic environment  such as the distributed computer system planned for use on Space Station Freedom  it must execute quickly and its knowledge base must be easily updated. Representing system knowledge as object-oriented augmented fault trees provides both features. The diagnosis system described here is based on the failure cause identification process of the diagnostic system described by Narayanan and Viswanadham. Their system has been enhanced in this implementation by replacing the knowledge base of if-then rules with an object-oriented fault tree representation. This allows the system to perform its task much faster and facilitates dynamic updating of the knowledge base in a changing diagnosis environment. Accessing the information contained in the objects is more efficient than performing a lookup operation on an indexed rule base. Additionally  the object-oriented fault trees can be easily updated to represent current system status. This paper describes the fault tree representation  the diagnosis algorithm extensions  and an example application of this system. Comparisons are made between the object-oriented fault tree knowledge structure solution and one implementation of a rule-based solution. Plans for future work on this system are also discussed.Representing metabolic pathway information: an object-oriented approach.PubMedEllis  L B; Speedie  S M; McLeish  R1998-01-01The University of Minnesota Biocatalysis/Biodegradation Database (UM-BBD) is a website providing information and dynamic links for microbial metabolic pathways  enzyme reactions  and their substrates and products. The Compound  Organism  Reaction and Enzyme (CORE) object-oriented database management system was developed to contain and serve this information. CORE was developed using Java  an object-oriented programming language  and PSE persistent object classes from Object Design  Inc. CORE dynamically generates descriptive web pages for reactions  compounds and enzymes  and reconstructs ad hoc pathway maps starting from any UM-BBD reaction. CORE code is available from the authors upon request. CORE is accessible through the UM-BBD at: http://www. labmed.umn.edu/umbbd/index.html.Asynchronous Data Retrieval from an Object-Oriented DatabaseNASA Astrophysics Data System (ADS)Gilbert  Jonathan P.; Bic  LubomirWe present an object-oriented semantic database model which  similar to other object-oriented systems  combines the virtues of four concepts: the functional data model  a property inheritance hierarchy  abstract data types and message-driven computation. The main emphasis is on the last of these four concepts. We describe generic procedures that permit queries to be processed in a purely message-driven manner. A database is represented as a network of nodes and directed arcs  in which each node is a logical processing element  capable of communicating with other nodes by exchanging messages. This eliminates the need for shared memory and for centralized control during query processing. Hence  the model is suitable for implementation on a multiprocessor computer architecture  consisting of large numbers of loosely coupled processing elements.An Object-Oriented Software Reuse ToolDTIC Science & Technology1989-04-01Square Cambridge  MA 02139 I. CONTROLLING OFFICE NAME ANO ADDRESS 12. REPORT DATIE Advanced Research Projects Agency April 1989 1400 Wilson Blvd. IS...Office of Naval Research UNCLASSIFIED Information Systems Arlington  VA 22217 1s . DECLASSIFICATION/DOWNGRAOINGSCHEDUL.E 6. O:STRIILJTION STATEMENT (of...DISTRIBUTION: Defense Technical Information Center Computer Sciences Division ONR  Code 1133 Navy Center for Applied Research in ArtificialConsidering Object Oriented Technology in Aviation ApplicationsNASA Technical Reports Server (NTRS)Hayhurst  Kelly J.; Holloway  C. Michael2003-01-01Few developers of commercial aviation software products are using object-oriented technology (OOT)  despite its popularity in some other industries. Safety concerns about using OOT in critical applications  uncertainty about how to comply with regulatory requirements  and basic conservatism within the aviation community have been factors behind this caution. The Federal Aviation Administration (FAA) and the National Aeronautics and Space Administration (NASA) have sponsored research to investigate and workshops to discuss safety and certification concerns about OOT and to develop recommendations for safe use. Two Object Oriented Technology in Aviation (OOTiA) workshops have been held and numerous issues and comments about the effect of OOT features and languages have been collected. This paper gives a high level overview of the OOTiA project  and discusses selected specific results from the March 2003 workshop. In particular  results in the form of questions to consider before making the decision to use OOT are presented.Reuse Metrics for Object Oriented SoftwareNASA Technical Reports Server (NTRS)Bieman  James M.1998-01-01One way to increase the quality of software products and the productivity of software development is to reuse existing software components when building new software systems. In order to monitor improvements in reuse  the level of reuse must be measured. In this NASA supported project we (1) derived a suite of metrics which quantify reuse attributes for object oriented  object based  and procedural software  (2) designed prototype tools to take these measurements in Ada  C++  Java  and C software  (3) evaluated the reuse in available software  (4) analyzed the relationship between coupling  cohesion  inheritance  and reuse  (5) collected object oriented software systems for our empirical analyses  and (6) developed quantitative criteria and methods for restructuring software to improve reusability.Leveraging object-oriented development at AmesNASA Technical Reports Server (NTRS)Wenneson  Greg; Connell  John1994-01-01This paper presents lessons learned by the Software Engineering Process Group (SEPG) from results of supporting two projects at NASA Ames using an Object Oriented Rapid Prototyping (OORP) approach supported by a full featured visual development environment. Supplemental lessons learned from a large project in progress and a requirements definition are also incorporated. The paper demonstrates how productivity gains can be made by leveraging the developer with a rich development environment  correct and early requirements definition using rapid prototyping  and earlier and better effort estimation and software sizing through object-oriented methods and metrics. Although the individual elements of OO methods  RP approach and OO metrics had been used on other separate projects  the reported projects were the first integrated usage supported by a rich development environment. Overall the approach used was twice as productive (measured by hours per OO Unit) as a C++ development.Introducing Object-Oriented Concepts into GSINASA Technical Reports Server (NTRS)Guo  Jing; Todling  Ricardo2017-01-01Enhancements are now being made to the Gridpoint Statistical Interpolation (GSI) data assimilation system to expand its capabilities. This effort opens the way for broadening the scope of GSI's applications by using some standard object-oriented features in Fortran  and represents a starting point for the so-called GSI refactoring  as a part of the Joint Effort for Data-assimilationI ntegration (JEDI) project of JCSDA.Computer-Access-Code MatricesNASA Technical Reports Server (NTRS)Collins  Earl R.  Jr.1990-01-01Authorized users respond to changing challenges with changing passwords. Scheme for controlling access to computers defeats eavesdroppers and ""hackers"". Based on password system of challenge and password or sign  challenge  and countersign correlated with random alphanumeric codes in matrices of two or more dimensions. Codes stored on floppy disk or plug-in card and changed frequently. For even higher security  matrices of four or more dimensions used  just as cubes compounded into hypercubes in concurrent processing.An object-oriented approach to nested data parallelismNASA Technical Reports Server (NTRS)Sheffler  Thomas J.; Chatterjee  Siddhartha1994-01-01This paper describes an implementation technique for integrating nested data parallelism into an object-oriented language. Data-parallel programming employs sets of data called 'collections' and expresses parallelism as operations performed over the elements of a collection. When the elements of a collection are also collections  then there is the possibility for 'nested data parallelism.' Few current programming languages support nested data parallelism however. In an object-oriented framework  a collection is a single object. Its type defines the parallel operations that may be applied to it. Our goal is to design and build an object-oriented data-parallel programming environment supporting nested data parallelism. Our initial approach is built upon three fundamental additions to C++. We add new parallel base types by implementing them as classes  and add a new parallel collection type called a 'vector' that is implemented as a template. Only one new language feature is introduced: the 'foreach' construct  which is the basis for exploiting elementwise parallelism over collections. The strength of the method lies in the compilation strategy  which translates nested data-parallel C++ into ordinary C++. Extracting the potential parallelism in nested 'foreach' constructs is called 'flattening' nested parallelism. We show how to flatten 'foreach' constructs using a simple program transformation. Our prototype system produces vector code which has been successfully run on workstations  a CM-2  and a CM-5.PSYCHE: An Object-Oriented Approach to Simulating Medical EducationPubMed CentralMullen  Jamie A.1990-01-01Traditional approaches to computer-assisted instruction (CAI) do not provide realistic simulations of medical education  in part because they do not utilize heterogeneous knowledge bases for their source of domain knowledge. PSYCHE  a CAI program designed to teach hypothetico-deductive psychiatric decision-making to medical students  uses an object-oriented implementation of an intelligent tutoring system (ITS) to model the student  domain expert  and tutor. It models the transactions between the participants in complex transaction chains  and uses heterogeneous knowledge bases to represent both domain and procedural knowledge in clinical medicine. This object-oriented approach is a flexible and dynamic approach to modeling  and represents a potentially valuable tool for the investigation of medical education and decision-making.Developing Formal Object-oriented Requirements Specifications: A Model  Tool and Technique.ERIC Educational Resources Information CenterJackson  Robert B.; And Others1995-01-01Presents a formal object-oriented specification model (OSS) for computer software system development that is supported by a tool that automatically generates a prototype from an object-oriented analysis model (OSA) instance  lets the user examine the prototype  and permits the user to refine the OSA model instance to generate a requirementsâ€¦Aspects on Teaching/Learning with Object Oriented Programming for Entry Level Courses of Engineering.ERIC Educational Resources Information Centerde Oliveira  Clara Amelia; Conte  Marcos Fernando; Riso  Bernardo GoncalvesThis work presents a proposal for Teaching/Learning  on Object Oriented Programming for Entry Level Courses of Engineering and Computer Science  on University. The philosophy of Object Oriented Programming comes as a new pattern of solution for problems  where flexibility and reusability appears over the simple data structure and sequentialâ€¦Faunus: An object oriented framework for molecular simulationPubMed CentralLund  Mikael; Trulsson  Martin; Persson  BjÃ¶rn2008-01-01Background We present a C++ class library for Monte Carlo simulation of molecular systems  including proteins in solution. The design is generic and highly modular  enabling multiple developers to easily implement additional features. The statistical mechanical methods are documented by extensive use of code comments that â€“ subsequently â€“ are collected to automatically build a web-based manual. Results We show how an object oriented design can be used to create an intuitively appealing coding framework for molecular simulation. This is exemplified in a minimalistic C++ program that can calculate protein protonation states. We further discuss performance issues related to high level coding abstraction. Conclusion C++ and the Standard Template Library (STL) provide a high-performance platform for generic molecular modeling. Automatic generation of code documentation from inline comments has proven particularly useful in that no separate manual needs to be maintained. PMID:18241331Microgravity computing codes. User's guideNASA Astrophysics Data System (ADS)1982-01-01Codes used in microgravity experiments to compute fluid parameters and to obtain data graphically are introduced. The computer programs are stored on two diskettes  compatible with the floppy disk drives of the Apple 2. Two versions of both disks are available (DOS-2 and DOS-3). The codes are written in BASIC and are structured as interactive programs. Interaction takes place through the keyboard of any Apple 2-48K standard system with single floppy disk drive. The programs are protected against wrong commands given by the operator. The programs are described step by step in the same order as the instructions displayed on the monitor. Most of these instructions are shown  with samples of computation and of graphics.Computer access security code systemNASA Technical Reports Server (NTRS)Collins  Earl R.  Jr. (Inventor)1990-01-01A security code system for controlling access to computer and computer-controlled entry situations comprises a plurality of subsets of alpha-numeric characters disposed in random order in matrices of at least two dimensions forming theoretical rectangles  cubes  etc.  such that when access is desired  at least one pair of previously unused character subsets not found in the same row or column of the matrix is chosen at random and transmitted by the computer. The proper response to gain access is transmittal of subsets which complete the rectangle  and/or a parallelepiped whose opposite corners were defined by first groups of code. Once used  subsets are not used again to absolutely defeat unauthorized access by eavesdropping  and the like.Knowledge-based simulation using object-oriented programmingNASA Technical Reports Server (NTRS)Sidoran  Karen M.1993-01-01Simulations have become a powerful mechanism for understanding and modeling complex phenomena. Their results have had substantial impact on a broad range of decisions in the military  government  and industry. Because of this  new techniques are continually being explored and developed to make them even more useful  understandable  extendable  and efficient. One such area of research is the application of the knowledge-based methods of artificial intelligence (AI) to the computer simulation field. The goal of knowledge-based simulation is to facilitate building simulations of greatly increased power and comprehensibility by making use of deeper knowledge about the behavior of the simulated world. One technique for representing and manipulating knowledge that has been enhanced by the AI community is object-oriented programming. Using this technique  the entities of a discrete-event simulation can be viewed as objects in an object-oriented formulation. Knowledge can be factual (i.e.  attributes of an entity) or behavioral (i.e.  how the entity is to behave in certain circumstances). Rome Laboratory's Advanced Simulation Environment (RASE) was developed as a research vehicle to provide an enhanced simulation development environment for building more intelligent  interactive  flexible  and realistic simulations. This capability will support current and future battle management research and provide a test of the object-oriented paradigm for use in large scale military applications.A Taxonomy of Object-Oriented Measures Modeling the Object-Oriented SpaceNASA Technical Reports Server (NTRS)Neal  Ralph D.; Weistroffer  H. Roland; Coppins  Richard J.1997-01-01In order to control the quality of software and the software development process  it is important to understand the measurement of software. A first step toward a better comprehension of software measurement is the categorization of software measures by some meaningful taxonomy. The most worthwhile taxonomy would capture the fundamental nature of the object-oriented (O-O) space. The principal characteristics of object-oriented software offer a starting point for such a categorization of measures. This paper introduces a taxonomy of measures based upon fourteen characteristics of object-oriented software gathered from the literature. This taxonomy allows us to easily see gaps or redundancies in the existing O-O measures. The taxonomy also clearly differentiates among taxa so that there is no ambiguity as to the taxon to which a measure belongs. The taxonomy has been populated with measures taken from the literature.A Taxonomy of Object-Oriented Measures Modeling the Object Oriented SpaceNASA Technical Reports Server (NTRS)Neal  Ralph D.; Weistroffer  H. Roland; Coppins  Richard J.1997-01-01In order to control the quality of software and the software development process  it is important to understand the measurement of software. A first step toward a better comprehension of software measurement is the categorization of software measures by some meaningful taxonomy. The most worthwhile taxonomy would capture the fundamental nature of the object-oriented (O-O) space. The principal characteristics of object-oriented software offer a starting point for such a categorization of measures. This paper introduces a taxonomy of measures based upon fourteen characteristics of object-oriented software gathered from the literature. This taxonomy allows us to easily see gaps or redundancies in the existing O-O measures. The taxonomy also clearly differentiates among taxa so that there is no ambiguity as to the taxon to which a measure belongs. The taxonomy has been populated with measures taken from the literature.Object-Oriented Simulation of EW Systems.DTIC Science & Technology1987-12-01elix.- r’UATO. SY - ~ ow W ."" --N I -SEL’ TD DEEICESESEC ETBLISKM - 1Eol~P7 TEST National Defense Deec ationale OBJECT-ORIENTED SIMULATION OF EW...C C- _ _ _4- 0 E (4. I o 0 ~1 . __ _ L c 0 0 i EnE- L-C( 1*c 0~~ N1 Ld 0- E  U  E 0 cu a 0* L L L C:c0 Yc 0 c aja  it) oO -.zz - VV1V 41-4- ia. ca...will retain a simultaneous capability to simulate signal processing at the pulse level. 10 ?1( N 0 .0O Ldk rW% o N1 0 4’-V - 54 - "" As discussedObject-oriented model-driven controlNASA Technical Reports Server (NTRS)Drysdale  A.; Mcroberts  M.; Sager  J.; Wheeler  R.1994-01-01A monitoring and control subsystem architecture has been developed that capitalizes on the use of modeldriven monitoring and predictive control  knowledge-based data representation  and artificial reasoning in an operator support mode. We have developed an object-oriented model of a Controlled Ecological Life Support System (CELSS). The model based on the NASA Kennedy Space Center CELSS breadboard data  tracks carbon  hydrogen  and oxygen  carbodioxide  and water. It estimates and tracks resorce-related parameters such as mass  energy  and manpower measurements such as growing area required for balance. We are developing an interface with the breadboard systems that is compatible with artificial reasoning. Initial work is being done on use of expert systems and user interface development. This paper presents an approach to defining universally applicable CELSS monitor and control issues  and implementing appropriate monitor and control capability for a particular instance: the KSC CELSS Breadboard Facility.Reengineering legacy software to object-oriented systemsNASA Technical Reports Server (NTRS)Pitman  C.; Braley  D.; Fridge  E.; Plumb  A.; Izygon  M.; Mears  B.1994-01-01NASA has a legacy of complex software systems that are becoming increasingly expensive to maintain. Reengineering is one approach to modemizing these systems. Object-oriented technology  other modem software engineering principles  and automated tools can be used to reengineer the systems and will help to keep maintenance costs of the modemized systems down. The Software Technology Branch at the NASA/Johnson Space Center has been developing and testing reengineering methods and tools for several years. The Software Technology Branch is currently providing training and consulting support to several large reengineering projects at JSC  including the Reusable Objects Software Environment (ROSE) project  which is reengineering the flight analysis and design system (over 2 million lines of FORTRAN code) into object-oriented C++. Many important lessons have been learned during the past years; one of these is that the design must never be allowed to diverge from the code during maintenance and enhancement. Future work on open  integrated environments to support reengineering is being actively planned.An Object-oriented Taxonomy of Medical Data PresentationsPubMed CentralStarren  Justin; Johnson  Stephen B.2000-01-01A variety of methods have been proposed for presenting medical data visually on computers. Discussion of and comparison among these methods have been hindered by a lack of consistent terminology. A taxonomy of medical data presentations based on object-oriented user interface principles is presented. Presentations are divided into five major classesâ€”list  table  graph  icon  and generated text. These are subdivided into eight subclasses with simple inheritance and four subclasses with multiple inheritance. The various subclasses are reviewed and examples are provided. Issues critical to the development and evaluation of presentations are also discussed. PMID:10641959Computation of the Genetic CodeNASA Astrophysics Data System (ADS)Kozlov  Nicolay N.; Kozlova  Olga N.2018-03-01One of the problems in the development of mathematical theory of the genetic code (summary is presented in [1]  the detailed -to [2]) is the problem of the calculation of the genetic code. Similar problems in the world is unknown and could be delivered only in the 21st century. One approach to solving this problem is devoted to this work. For the first time provides a detailed description of the method of calculation of the genetic code  the idea of which was first published earlier [3])  and the choice of one of the most important sets for the calculation was based on an article [4]. Such a set of amino acid corresponds to a complete set of representations of the plurality of overlapping triple gene belonging to the same DNA strand. A separate issue was the initial point  triggering an iterative search process all codes submitted by the initial data. Mathematical analysis has shown that the said set contains some ambiguities  which have been founded because of our proposed compressed representation of the set. As a result  the developed method of calculation was limited to the two main stages of research  where the first stage only the of the area were used in the calculations. The proposed approach will significantly reduce the amount of computations at each step in this complex discrete structure.Object-oriented requirements analysis: A quick tourNASA Technical Reports Server (NTRS)Berard  Edward V.1990-01-01Of all the approaches to software development  an object-oriented approach appears to be both the most beneficial and the most popular. The description of the object-oriented approach is presented in the form of the view graphs.Object-oriented approach for gas turbine engine simulationNASA Technical Reports Server (NTRS)Curlett  Brian P.; Felder  James L.1995-01-01An object-oriented gas turbine engine simulation program was developed. This program is a prototype for a more complete  commercial grade engine performance program now being proposed as part of the Numerical Propulsion System Simulator (NPSS). This report discusses architectural issues of this complex software system and the lessons learned from developing the prototype code. The prototype code is a fully functional  general purpose engine simulation program  however  only the component models necessary to model a transient compressor test rig have been written. The production system will be capable of steady state and transient modeling of almost any turbine engine configuration. Chief among the architectural considerations for this code was the framework in which the various software modules will interact. These modules include the equation solver  simulation code  data model  event handler  and user interface. Also documented in this report is the component based design of the simulation module and the inter-component communication paradigm. Object class hierarchies for some of the code modules are given.Top-level modeling of an als system utilizing object-oriented techniquesNASA Astrophysics Data System (ADS)Rodriguez  L. F.; Kang  S.; Ting  K. C.The possible configuration of an Advanced Life Support (ALS) System capable of supporting human life for long-term space missions continues to evolve as researchers investigate potential technologies and configurations. To facilitate the decision process the development of acceptable  flexible  and dynamic mathematical computer modeling tools capable of system level analysis is desirable. Object-oriented techniques have been adopted to develop a dynamic top-level model of an ALS system.This approach has several advantages; among these  object-oriented abstractions of systems are inherently modular in architecture. Thus  models can initially be somewhat simplistic  while allowing for adjustments and improvements. In addition  by coding the model in Java  the model can be implemented via the World Wide Web  greatly encouraging the utilization of the model. Systems analysis is further enabled with the utilization of a readily available backend database containing information supporting the model. The subsystem models of the ALS system model include Crew  Biomass Production  Waste Processing and Resource Recovery  Food Processing and Nutrition  and the Interconnecting Space. Each subsystem model and an overall model have been developed. Presented here is the procedure utilized to develop the modeling tool  the vision of the modeling tool  and the current focus for each of the subsystem models.Object-oriented technologies in a multi-mission data systemNASA Technical Reports Server (NTRS)Murphy  Susan C.; Miller  Kevin J.; Louie  John J.1993-01-01The Operations Engineering Laboratory (OEL) at JPL is developing new technologies that can provide more efficient and productive ways of doing business in flight operations. Over the past three years  we have worked closely with the Multi-Mission Control Team to develop automation tools  providing technology transfer into operations and resulting in substantial cost savings and error reduction. The OEL development philosophy is characterized by object-oriented design  extensive reusability of code  and an iterative development model with active participation of the end users. Through our work  the benefits of object-oriented design became apparent for use in mission control data systems. Object-oriented technologies and how they can be used in a mission control center to improve efficiency and productivity are explained. The current research and development efforts in the JPL Operations Engineering Laboratory are also discussed to architect and prototype a new paradigm for mission control operations based on object-oriented concepts.Design of object-oriented distributed simulation classesNASA Technical Reports Server (NTRS)Schoeffler  James D. (Principal Investigator)1995-01-01Distributed simulation of aircraft engines as part of a computer aided design package is being developed by NASA Lewis Research Center for the aircraft industry. The project is called NPSS  an acronym for 'Numerical Propulsion Simulation System'. NPSS is a flexible object-oriented simulation of aircraft engines requiring high computing speed. It is desirable to run the simulation on a distributed computer system with multiple processors executing portions of the simulation in parallel. The purpose of this research was to investigate object-oriented structures such that individual objects could be distributed. The set of classes used in the simulation must be designed to facilitate parallel computation. Since the portions of the simulation carried out in parallel are not independent of one another  there is the need for communication among the parallel executing processors which in turn implies need for their synchronization. Communication and synchronization can lead to decreased throughput as parallel processors wait for data or synchronization signals from other processors. As a result of this research  the following have been accomplished. The design and implementation of a set of simulation classes which result in a distributed simulation control program have been completed. The design is based upon MIT 'Actor' model of a concurrent object and uses 'connectors' to structure dynamic connections between simulation components. Connectors may be dynamically created according to the distribution of objects among machines at execution time without any programming changes. Measurements of the basic performance have been carried out with the result that communication overhead of the distributed design is swamped by the computation time of modules unless modules have very short execution times per iteration or time step. An analytical performance model based upon queuing network theory has been designed and implemented. Its application to realistic configurations hasDesign of Object-Oriented Distributed Simulation ClassesNASA Technical Reports Server (NTRS)Schoeffler  James D.1995-01-01Distributed simulation of aircraft engines as part of a computer aided design package being developed by NASA Lewis Research Center for the aircraft industry. The project is called NPSS  an acronym for ""Numerical Propulsion Simulation System"". NPSS is a flexible object-oriented simulation of aircraft engines requiring high computing speed. It is desirable to run the simulation on a distributed computer system with multiple processors executing portions of the simulation in parallel. The purpose of this research was to investigate object-oriented structures such that individual objects could be distributed. The set of classes used in the simulation must be designed to facilitate parallel computation. Since the portions of the simulation carried out in parallel are not independent of one another  there is the need for communication among the parallel executing processors which in turn implies need for their synchronization. Communication and synchronization can lead to decreased throughput as parallel processors wait for data or synchronization signals from other processors. As a result of this research  the following have been accomplished. The design and implementation of a set of simulation classes which result in a distributed simulation control program have been completed. The design is based upon MIT ""Actor"" model of a concurrent object and uses ""connectors"" to structure dynamic connections between simulation components. Connectors may be dynamically created according to the distribution of objects among machines at execution time without any programming changes. Measurements of the basic performance have been carried out with the result that communication overhead of the distributed design is swamped by the computation time of modules unless modules have very short execution times per iteration or time step. An analytical performance model based upon queuing network theory has been designed and implemented. Its application to realistic configurations has notObject-Oriented MDAO Tool with Aeroservoelastic Model Tuning CapabilityNASA Technical Reports Server (NTRS)Pak  Chan-gi; Li  Wesley; Lung  Shun-fat2008-01-01An object-oriented multi-disciplinary analysis and optimization (MDAO) tool has been developed at the NASA Dryden Flight Research Center to automate the design and analysis process and leverage existing commercial as well as in-house codes to enable true multidisciplinary optimization in the preliminary design stage of subsonic  transonic  supersonic and hypersonic aircraft. Once the structural analysis discipline is finalized and integrated completely into the MDAO process  other disciplines such as aerodynamics and flight controls will be integrated as well. Simple and efficient model tuning capabilities based on optimization problem are successfully integrated with the MDAO tool. More synchronized all phases of experimental testing (ground and flight)  analytical model updating  high-fidelity simulations for model validation  and integrated design may result in reduction of uncertainties in the aeroservoelastic model and increase the flight safety.An object oriented fully 3D tomography visual toolkit.PubMedAgostinelli  S; Paoli  G2001-04-01In this paper we present a modern object oriented component object model (COMM) C + + toolkit dedicated to fully 3D cone-beam tomography. The toolkit allows the display and visual manipulation of analytical phantoms  projection sets and volumetric data through a standard Windows graphical user interface. Data input/output is performed using proprietary file formats but import/export of industry standard file formats  including raw binary  Windows bitmap and AVI  ACR/NEMA DICOMM 3 and NCSA HDF is available. At the time of writing built-in implemented data manipulators include a basic phantom ray-tracer and a Matrox Genesis frame grabbing facility. A COMM plug-in interface is provided for user-defined custom backprojector algorithms: a simple Feldkamp ActiveX control  including source code  is provided as an example; our fast Feldkamp plug-in is also available.HackaMol: An Object-Oriented Modern Perl Library for Molecular Hacking on Multiple ScalesDOE PAGESRiccardi  Demian M.; Parks  Jerry M.; Johs  Alexander; ...2015-03-20HackaMol is an open source  object-oriented toolkit written in Modern Perl that organizes atoms within molecules and provides chemically intuitive attributes and methods. The library consists of two components: HackaMol  the core that contains classes for storing and manipulating molecular information  and HackaMol::X  the extensions that use the core. We tested the core; it is well-documented and easy to install across computational platforms. Our goal for the extensions is to provide a more flexible space for researchers to develop and share new methods. In this application note  we provide a description of the core classes and two extensions: HackaMol::X::Calculator  anmoreÂ Â» abstract calculator that uses code references to generalize interfaces with external programs  and HackaMol::X::Vina  a structured class that provides an interface with the AutoDock Vina docking program.Â«Â lessHackaMol: An Object-Oriented Modern Perl Library for Molecular Hacking on Multiple Scales.PubMedRiccardi  Demian; Parks  Jerry M; Johs  Alexander; Smith  Jeremy C2015-04-27HackaMol is an open source  object-oriented toolkit written in Modern Perl that organizes atoms within molecules and provides chemically intuitive attributes and methods. The library consists of two components: HackaMol  the core that contains classes for storing and manipulating molecular information  and HackaMol::X  the extensions that use the core. The core is well-tested  well-documented  and easy to install across computational platforms. The goal of the extensions is to provide a more flexible space for researchers to develop and share new methods. In this application note  we provide a description of the core classes and two extensions: HackaMol::X::Calculator  an abstract calculator that uses code references to generalize interfaces with external programs  and HackaMol::X::Vina  a structured class that provides an interface with the AutoDock Vina docking program.GENASIS Mathematics : Object-oriented manifolds  operations  and solvers for large-scale physics simulationsNASA Astrophysics Data System (ADS)Cardall  Christian Y.; Budiardja  Reuben D.2018-01-01The large-scale computer simulation of a system of physical fields governed by partial differential equations requires some means of approximating the mathematical limit of continuity. For example  conservation laws are often treated with a 'finite-volume' approach in which space is partitioned into a large number of small 'cells ' with fluxes through cell faces providing an intuitive discretization modeled on the mathematical definition of the divergence operator. Here we describe and make available Fortran 2003 classes furnishing extensible object-oriented implementations of simple meshes and the evolution of generic conserved currents thereon  along with individual 'unit test' programs and larger example problems demonstrating their use. These classes inaugurate the Mathematics division of our developing astrophysics simulation code GENASIS (Gen eral A strophysical Si mulation S ystem)  which will be expanded over time to include additional meshing options  mathematical operations  solver types  and solver variations appropriate for many multiphysics applications.HackaMol: An Object-Oriented Modern Perl Library for Molecular Hacking on Multiple ScalesSciTech ConnectRiccardi  Demian M.; Parks  Jerry M.; Johs  AlexanderHackaMol is an open source  object-oriented toolkit written in Modern Perl that organizes atoms within molecules and provides chemically intuitive attributes and methods. The library consists of two components: HackaMol  the core that contains classes for storing and manipulating molecular information  and HackaMol::X  the extensions that use the core. We tested the core; it is well-documented and easy to install across computational platforms. Our goal for the extensions is to provide a more flexible space for researchers to develop and share new methods. In this application note  we provide a description of the core classes and two extensions: HackaMol::X::Calculator  anmoreÂ Â» abstract calculator that uses code references to generalize interfaces with external programs  and HackaMol::X::Vina  a structured class that provides an interface with the AutoDock Vina docking program.Â«Â lessSISSY: An example of a multi-threaded  networked  object-oriented databased applicationSciTech ConnectScipioni  B.; Liu  D.; Song  T.1993-05-01The Systems Integration Support SYstem (SISSY) is presented and its capabilities and techniques are discussed. It is fully automated data collection and analysis system supporting the SSCL`s systems analysis activities as they relate to the Physics Detector and Simulation Facility (PDSF). SISSY itself is a paradigm of effective computing on the PDSF. It uses home-grown code (C++)  network programming (RPC  SNMP)  relational (SYBASE) and object-oriented (ObjectStore) DBMSs  UNIX operating system services (IRIX threads  cron  system utilities  shells scripts  etc.)  and third party software applications (NetCentral Station  Wingz  DataLink) all of which act together as a single application to monitor andmoreÂ Â» analyze the PDSF.Â«Â lessAn Object-Oriented Collection of Minimum Degree Algorithms: Design  Implementation  and ExperiencesNASA Technical Reports Server (NTRS)Kumfert  Gary; Pothen  Alex1999-01-01The multiple minimum degree (MMD) algorithm and its variants have enjoyed 20+ years of research and progress in generating fill-reducing orderings for sparse  symmetric positive definite matrices. Although conceptually simple  efficient implementations of these algorithms are deceptively complex and highly specialized. In this case study  we present an object-oriented library that implements several recent minimum degree-like algorithms. We discuss how object-oriented design forces us to decompose these algorithms in a different manner than earlier codes and demonstrate how this impacts the flexibility and efficiency of our C++ implementation. We compare the performance of our code against other implementations in C or Fortran.Object-oriented knowledge representation for expert systemsNASA Technical Reports Server (NTRS)Scott  Stephen L.1991-01-01Object oriented techniques have generated considerable interest in the Artificial Intelligence (AI) community in recent years. This paper discusses an approach for representing expert system knowledge using classes  objects  and message passing. The implementation is in version 4.3 of NASA's C Language Integrated Production System (CLIPS)  an expert system tool that does not provide direct support for object oriented design. The method uses programmer imposed conventions and keywords to structure facts  and rules to provide object oriented capabilities.The Assignment of Scale to Object-Oriented Software MeasuresNASA Technical Reports Server (NTRS)Neal  Ralph D.; Weistroffer  H. Roland; Coppins  Richard J.1997-01-01In order to improve productivity (and quality)  measurement of specific aspects of software has become imperative. As object oriented programming languages have become more widely used  metrics designed specifically for object-oriented software are required. Recently a large number of new metrics for object- oriented software has appeared in the literature. Unfortunately  many of these proposed metrics have not been validated to measure what they purport to measure. In this paper fifty (50) of these metrics are analyzed.StrateGene: object-oriented programming in molecular biology.PubMedCarhart  R E; Cash  H D; Moore  J F1988-03-01This paper describes some of the ways that object-oriented programming methodologies have been used to represent and manipulate biological information in a working application. When running on a Xerox 1100 series computer  StrateGene functions as a genetic engineering workstation for the management of information about cloning experiments. It represents biological molecules  enzymes  fragments  and methods as classes  subclasses  and members in a hierarchy of objects. These objects may have various attributes  which themselves can be defined and classified. The attributes and their values can be passed from the classes of objects down to the subclasses and members. The user can modify the objects and their attributes while using them. New knowledge and changes to the system can be incorporated relatively easily. The operations on the biological objects are associated with the objects themselves. This makes it easier to invoke them correctly and allows generic operations to be customized for the particular object.Coding Without Your Crystal Ball: Unanticipated Object-Oriented ReuseDTIC Science & Technology2009-12-01Abstract In many ways  existing languages place unrealistic expectations on library and framework designers  allowing some varieties of client reuse only...if it is explicitlyâ€” sometimes manuallyâ€”supported. Instead  we should aim for the ideal: a language design that reduces the amount of prognostication...that is required on the part of the original designers. In particular  I show that languages can and should support a combination of structural andTransforming Aggregate Object-Oriented Formal Specifications to CodeDTIC Science & Technology1999-03-01integration issues associated with a formal-based software transformation system  such as the source specification  the problem space architecture   design architecture ... design transforms  and target software transforms. Software is critical in today’s Air Force  yet its specification  design  and developmentAn object-oriented description method of EPMM processNASA Astrophysics Data System (ADS)Jiang  Zuo; Yang  Fan2017-06-01In order to use the object-oriented mature tools and language in software process model  make the software process model more accord with the industrial standard  itâ€™s necessary to study the object-oriented modelling of software process. Based on the formal process definition in EPMM  considering the characteristics that Petri net is mainly formal modelling tool and combining the Petri net modelling with the object-oriented modelling idea  this paper provides this implementation method to convert EPMM based on Petri net into object models based on object-oriented description.A survey of commercial object-oriented database management systemsNASA Technical Reports Server (NTRS)Atkins  John1992-01-01The object-oriented data model is the culmination of over thirty years of database research. Initially  database research focused on the need to provide information in a consistent and efficient manner to the business community. Early data models such as the hierarchical model and the network model met the goal of consistent and efficient access to data and were substantial improvements over simple file mechanisms for storing and accessing data. However  these models required highly skilled programmers to provide access to the data. Consequently  in the early 70's E.F. Codd  an IBM research computer scientists  proposed a new data model based on the simple mathematical notion of the relation. This model is known as the Relational Model. In the relational model  data is represented in flat tables (or relations) which have no physical or internal links between them. The simplicity of this model fostered the development of powerful but relatively simple query languages that now made data directly accessible to the general database user. Except for large  multi-user database systems  a database professional was in general no longer necessary. Database professionals found that traditional data in the form of character data  dates  and numeric data were easily represented and managed via the relational model. Commercial relational database management systems proliferated and performance of relational databases improved dramatically. However  there was a growing community of potential database users whose needs were not met by the relational model. These users needed to store data with data types not available in the relational model and who required a far richer modelling environment than that provided by the relational model. Indeed  the complexity of the objects to be represented in the model mandated a new approach to database technology. The Object-Oriented Model was the result.Teaching Adaptability of Object-Oriented Programming Language CurriculumERIC Educational Resources Information CenterZhu  Xiao-dong2012-01-01The evolution of object-oriented programming languages includes update of their own versions  update of development environments  and reform of new languages upon old languages. In this paper  the evolution analysis of object-oriented programming languages is presented in term of the characters and development. The notion of adaptive teaching uponâ€¦Computer Code Aids Design Of WingsNASA Technical Reports Server (NTRS)Carlson  Harry W.; Darden  Christine M.1993-01-01AERO2S computer code developed to aid design engineers in selection and evaluation of aerodynamically efficient wing/canard and wing/horizontal-tail configurations that includes simple hinged-flap systems. Code rapidly estimates longitudinal aerodynamic characteristics of conceptual airplane lifting-surface arrangements. Developed in FORTRAN V on CDC 6000 computer system  and ported to MS-DOS environment.Volume accumulator design analysis computer codesNASA Technical Reports Server (NTRS)Whitaker  W. D.; Shimazaki  T. T.1973-01-01The computer codes  VANEP and VANES  were written and used to aid in the design and performance calculation of the volume accumulator units (VAU) for the 5-kwe reactor thermoelectric system. VANEP computes the VAU design which meets the primary coolant loop VAU volume and pressure performance requirements. VANES computes the performance of the VAU design  determined from the VANEP code  at the conditions of the secondary coolant loop. The codes can also compute the performance characteristics of the VAU's under conditions of possible modes of failure which still permit continued system operation.electromagnetics  eddy current  computer codesSciTech ConnectGartling  DavidTORO Version 4 is designed for finite element analysis of steady  transient and time-harmonic  multi-dimensional  quasi-static problems in electromagnetics. The code allows simulation of electrostatic fields  steady current flows  magnetostatics and eddy current problems in plane or axisymmetric  two-dimensional geometries. TORO is easily coupled to heat conduction and solid mechanics codes to allow multi-physics simulations to be performed.A Learning Research Informed Design and Evaluation of a Web-Enhanced Object Oriented Programming SeminarERIC Educational Resources Information CenterGeorgantaki  Stavroula C.; Retalis  Symeon D.2007-01-01""Object-Oriented Programming"" subject is included in the ACM Curriculum Guidelines for Undergraduate and Graduate Degree Programs in Computer Science as well as in Curriculum for K-12 Computer Science. In a few research studies learning problems and difficulties have been recorded  and therefore  specific pedagogical guidelines andâ€¦Implementation of an object oriented track reconstruction model into multiple LHC experiments*NASA Astrophysics Data System (ADS)Gaines  Irwin; Gonzalez  Saul; Qian  Sijin2001-10-01An Object Oriented (OO) model (Gaines et al.  1996; 1997; Gaines and Qian  1998; 1999) for track reconstruction by the Kalman filtering method has been designed for high energy physics experiments at high luminosity hadron colliders. The model has been coded in the C++ programming language and has been successfully implemented into the OO computing environments of both the CMS (1994) and ATLAS (1994) experiments at the future Large Hadron Collider (LHC) at CERN. We shall report: how the OO model was adapted  with largely the same code  to different scenarios and serves the different reconstruction aims in different experiments (i.e. the level-2 trigger software for ATLAS and the offline software for CMS); how the OO model has been incorporated into different OO environments with a similar integration structure (demonstrating the ease of re-use of OO program); what are the OO model's performance  including execution time  memory usage  track finding efficiency and ghost rate  etc.; and additional physics performance based on use of the OO tracking model. We shall also mention the experience and lessons learned from the implementation of the OO model into the general OO software framework of the experiments. In summary  our practice shows that the OO technology really makes the software development and the integration issues straightforward and convenient; this may be particularly beneficial for the general non-computer-professional physicists.Network Coding for Function ComputationERIC Educational Resources Information CenterAppuswamy  Rathinakumar2011-01-01In this dissertation  the following ""network computing problem"" is considered. Source nodes in a directed acyclic network generate independent messages and a single receiver node computes a target function f of the messages. The objective is to maximize the average number of times f can be computed per network usage  i.e.  the ""computingâ€¦Object-oriented programming with mixins in AdaNASA Technical Reports Server (NTRS)Seidewitz  ED1992-01-01Recently  I wrote a paper discussing the lack of 'true' object-oriented programming language features in Ada 83  why one might desire them in Ada  and how they might be added in Ada 9X. The approach I took in this paper was to build the new object-oriented features of Ada 9X as much as possible on the basic constructs and philosophy of Ada 83. The object-oriented features proposed for Ada 9X  while different in detail  are based on the same kind of approach. Further consideration of this approach led me on a long reflection on the nature of object-oriented programming and its application to Ada. The results of this reflection  presented in this paper  show how a fairly natural object-oriented style can indeed be developed even in Ada 83. The exercise of developing this style is useful for at least three reasons: (1) it provides a useful style for programming object-oriented applications in Ada 83 until new features become available with Ada 9X; (2) it demystifies many of the mechanisms that seem to be 'magic' in most object-oriented programming languages by making them explicit; and (3) it points out areas that are and are not in need of change in Ada 83 to make object-oriented programming more natural in Ada 9X. In the next four sections I will address in turn the issues of object-oriented classes  mixins  self-reference and supertyping. The presentation is through a sequence of examples. This results in some overlap with that paper  but all the examples in the present paper are written entirely in Ada 83. I will return to considerations for Ada 9X in the last section of the paper.Superimposed Code Theoretic Analysis of DNA Codes and DNA ComputingDTIC Science & Technology2008-01-01complements of one another and the DNA duplex formed is a Watson - Crick (WC) duplex. However  there are many instances when the formation of non-WC...that the userâ€™s requirements for probe selection are met based on the Watson - Crick probe locality within a target. The second type  called...AFRL-RI-RS-TR-2007-288 Final Technical Report January 2008 SUPERIMPOSED CODE THEORETIC ANALYSIS OF DNA CODES AND DNA COMPUTINGA Validation of Object-Oriented Design MetricsNASA Technical Reports Server (NTRS)Basili  Victor R.; Briand  Lionel; Melo  Walcelio L.1995-01-01This paper presents the results of a study conducted at the University of Maryland in which we experimentally investigated the suite of Object-Oriented (00) design metrics introduced by [Chidamber and Kemerer  1994]. In order to do this  we assessed these metrics as predictors of fault-prone classes. This study is complementary to [Lieand Henry  1993] where the same suite of metrics had been used to assess frequencies of maintenance changes to classes. To perform our validation accurately  we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model  a well-known 00 analysis/design method and the C++ programming language. Based on experimental results  the advantages and drawbacks of these 00 metrics are discussed and suggestions for improvement are provided. Several of Chidamber and Kemerer's 00 metrics appear to be adequate to predict class fault-proneness during the early phases of the life-cycle. We also showed that they are  on our data set  better predictors than ""traditional"" code metrics  which can only be collected at a later phase of the software development processes.ODIN-object-oriented development interface for NMR.PubMedJochimsen  Thies H; von Mengershausen  Michael2004-09-01A cross-platform development environment for nuclear magnetic resonance (NMR) experiments is presented. It allows rapid prototyping of new pulse sequences and provides a common programming interface for different system types. With this object-oriented interface implemented in C++  the programmer is capable of writing applications to control an experiment that can be executed on different measurement devices  even from different manufacturers  without the need to modify the source code. Due to the clear design of the software  new pulse sequences can be created  tested  and executed within a short time. To post-process the acquired data  an interface to well-known numerical libraries is part of the framework. This allows a transparent integration of the data processing instructions into the measurement module. The software focuses mainly on NMR imaging  but can also be used with limitations for spectroscopic experiments. To demonstrate the capabilities of the framework  results of the same experiment  carried out on two NMR imaging systems from different manufacturers are shown and compared with the results of a simulation.VLTI auxiliary telescopes: a full object-oriented approachNASA Astrophysics Data System (ADS)Chiozzi  Gianluca; Duhoux  Philippe; Karban  Robert2000-06-01The Very Large Telescope (VLT) Telescope Control Software (TCS) is a portable system. It is now in use or will be used in a whole family of ESO telescopes VLT Unit Telescopes  VLTI Auxiliary Telescopes  NTT  La Silla 3.6  VLT Survey Telescope and Astronomical Site Monitors in Paranal and La Silla). Although it has been developed making extensive usage of Object Oriented (OO) methodologies  the overall development process chosen at the beginning of the project used traditional methods. In order to warranty a longer lifetime to the system (improving documentation and maintainability) and to prepare for future projects  we have introduced a full OO process. We have taken as a basis the United Software Development Process with the Unified Modeling Language (UML) and we have adapted the process to our specific needs. This paper describes how the process has been applied to the VLTI Auxiliary Telescopes Control Software (ATCS). The ATCS is based on the portable VLT TCS  but some subsystems are new or have specific characteristics. The complete process has been applied to the new subsystems  while reused code has been integrated in the UML models. We have used the ATCS on one side to tune the process and train the team members and on the other side to provide a UML and WWW based documentation for the portable VLT TCS.Initiating Formal Requirements Specifications with Object-Oriented ModelsNASA Technical Reports Server (NTRS)Ampo  Yoko; Lutz  Robyn R.1994-01-01This paper reports results of an investigation into the suitability of object-oriented models as an initial step in developing formal specifications. The requirements for two critical system-level software modules were used as target applications. It was found that creating object-oriented diagrams prior to formally specifying the requirements enhanced the accuracy of the initial formal specifications and reduced the effort required to produce them. However  the formal specifications incorporated some information not found in the object-oriented diagrams  such as higher-level strategy or goals of the software.A diagnosis system using object-oriented fault tree modelsNASA Technical Reports Server (NTRS)Iverson  David L.; Patterson-Hine  F. A.1990-01-01Spaceborne computing systems must provide reliable  continuous operation for extended periods. Due to weight  power  and volume constraints  these systems must manage resources very effectively. A fault diagnosis algorithm is described which enables fast and flexible diagnoses in the dynamic distributed computing environments planned for future space missions. The algorithm uses a knowledge base that is easily changed and updated to reflect current system status. Augmented fault trees represented in an object-oriented form provide deep system knowledge that is easy to access and revise as a system changes. Given such a fault tree  a set of failure events that have occurred  and a set of failure events that have not occurred  this diagnosis system uses forward and backward chaining to propagate causal and temporal information about other failure events in the system being diagnosed. Once the system has established temporal and causal constraints  it reasons backward from heuristically selected failure events to find a set of basic failure events which are a likely cause of the occurrence of the top failure event in the fault tree. The diagnosis system has been implemented in common LISP using Flavors.Computer Code for Nanostructure SimulationNASA Technical Reports Server (NTRS)Filikhin  Igor; Vlahovic  Branislav2009-01-01Due to their small size  nanostructures can have stress and thermal gradients that are larger than any macroscopic analogue. These gradients can lead to specific regions that are susceptible to failure via processes such as plastic deformation by dislocation emission  chemical debonding  and interfacial alloying. A program has been developed that rigorously simulates and predicts optoelectronic properties of nanostructures of virtually any geometrical complexity and material composition. It can be used in simulations of energy level structure  wave functions  density of states of spatially configured phonon-coupled electrons  excitons in quantum dots  quantum rings  quantum ring complexes  and more. The code can be used to calculate stress distributions and thermal transport properties for a variety of nanostructures and interfaces  transport and scattering at nanoscale interfaces and surfaces under various stress states  and alloy compositional gradients. The code allows users to perform modeling of charge transport processes through quantum-dot (QD) arrays as functions of inter-dot distance  array order versus disorder  QD orientation  shape  size  and chemical composition for applications in photovoltaics and physical properties of QD-based biochemical sensors. The code can be used to study the hot exciton formation/relation dynamics in arrays of QDs of different shapes and sizes at different temperatures. It also can be used to understand the relation among the deposition parameters and inherent stresses  strain deformation  heat flow  and failure of nanostructures.Prototyping Visual Database Interface by Object-Oriented LanguageDTIC Science & Technology1988-06-01approach is to use object-oriented programming. Object-oriented languages are characterized by three criteria [Ref. 4:p. 1.2.1]: - encapsulation of...made it a sub-class of our DMWindow.Cls  which is discussed later in this chapter. This extension to the application had to be intergrated with our... abnormal behaviors similar to Korth’s discussion of pitfalls in relational database designing. Even extensions like GEM [Ref. 8] that are powerful andSIMOGEN - An Object-Oriented Language for SimulationDTIC Science & Technology1989-03-01program generator must also be written in the same prcgramming languaje . In this case  the C language was chosen  for the following main reasons...3)  March 88. 4. PRESTO: A System for Object-Oriented Parallel Programing B N Bershad  E D Lazowska & H M Levy Software Practice and Experience  Vol...U.S. Depare nt of Defence ANSI/ML-STD 1815A. 7. Object-oriented Development Grady Booch Transactions on Software Engineering   February 86. 8. ACloud Computing for Complex Performance Codes.SciTech ConnectAppel  Gordon John; Hadgu  Teklu; Klein  Brandon ThorinThis report describes the use of cloud computing services for running complex public domain performance assessment problems. The work consisted of two phases: Phase 1 was to demonstrate complex codes  on several differently configured servers  could run and compute trivial small scale problems in a commercial cloud infrastructure. Phase 2 focused on proving non-trivial large scale problems could be computed in the commercial cloud environment. The cloud computing effort was successfully applied using codes of interest to the geohydrology and nuclear waste disposal modeling community.Quantity  Revisited: An Object-Oriented Reusable ClassNASA Technical Reports Server (NTRS)Funston  Monica Gayle; Gerstle  Walter; Panthaki  Malcolm1998-01-01""Quantity""  a prototype implementation of an object-oriented class  was developed for two reasons: to help engineers and scientists manipulate the many types of quantities encountered during routine analysis  and to create a reusable software component to for large domain-specific applications. From being used as a stand-alone application to being incorporated into an existing computational mechanics toolkit  ""Quantity"" appears to be a useful and powerful object. ""Quantity"" has been designed to maintain the full engineering meaning of values with respect to units and coordinate systems. A value is a scalar  vector  tensor  or matrix  each of which is composed of Value Components  each of which may be an integer  floating point number  fuzzy number  etc.  and its associated physical unit. Operations such as coordinate transformation and arithmetic operations are handled by member functions of ""Quantity"". The prototype has successfully tested such characteristics as maintaining a numeric value  an associated unit  and an annotation. In this paper we further explore the design of ""Quantity""  with particular attention to coordinate systems.Development of an object-oriented finite element program: application to metal-forming and impact simulationsNASA Astrophysics Data System (ADS)Pantale  O.; Caperaa  S.; Rakotomalala  R.2004-07-01During the last 50 years  the development of better numerical methods and more powerful computers has been a major enterprise for the scientific community. In the same time  the finite element method has become a widely used tool for researchers and engineers. Recent advances in computational software have made possible to solve more physical and complex problems such as coupled problems  nonlinearities  high strain and high-strain rate problems. In this field  an accurate analysis of large deformation inelastic problems occurring in metal-forming or impact simulations is extremely important as a consequence of high amount of plastic flow. In this presentation  the object-oriented implementation  using the C++ language  of an explicit finite element code called DynELA is presented. The object-oriented programming (OOP) leads to better-structured codes for the finite element method and facilitates the development  the maintainability and the expandability of such codes. The most significant advantage of OOP is in the modeling of complex physical systems such as deformation processing where the overall complex problem is partitioned in individual sub-problems based on physical  mathematical or geometric reasoning. We first focus on the advantages of OOP for the development of scientific programs. Specific aspects of OOP  such as the inheritance mechanism  the operators overload procedure or the use of template classes are detailed. Then we present the approach used for the development of our finite element code through the presentation of the kinematics  conservative and constitutive laws and their respective implementation in C++. Finally  the efficiency and accuracy of our finite element program are investigated using a number of benchmark tests relative to metal forming and impact simulations.An Object-Oriented Architecture for a Web-Based CAI System.ERIC Educational Resources Information CenterNakabayashi  Kiyoshi; Hoshide  Takahide; Seshimo  Hitoshi; Fukuhara  YoshimiThis paper describes the design and implementation of an object-oriented World Wide Web-based CAI (Computer-Assisted Instruction) system. The goal of the design is to provide a flexible CAI/ITS (Intelligent Tutoring System) framework with full extendibility and reusability  as well as to exploit Web-based software technologies such as JAVA  ASP (aâ€¦An Achievement Degree Analysis Approach to Identifying Learning Problems in Object-Oriented ProgrammingERIC Educational Resources Information CenterAllinjawi  Arwa A.; Al-Nuaim  Hana A.; Krause  Paul2014-01-01Students often face difficulties while learning object-oriented programming (OOP) concepts. Many papers have presented various assessment methods for diagnosing learning problems to improve the teaching of programming in computer science (CS) higher education. The research presented in this article illustrates that although max-min composition isâ€¦Cognitive characteristics of learning Java  an object-oriented programming languageNASA Astrophysics Data System (ADS)White  Garry LynnIndustry and Academia are moving from procedural programming languages (e.g.  COBOL) to object-oriented programming languages  such as Java for the Internet. Past studies in the cognitive aspects of programming have focused primarily on procedural programming languages. Some of the languages used have been Pascal  C  Basic  FORTAN  and COBOL. Object-oriented programming (OOP) represents a new paradigm for computing. Industry is finding that programmers are having difficulty shifting to this new programming paradigm. This instruction in OOP is currently starting in colleges and universities across the country. What are the cognitive aspects for this new OOP language Java? When is a student developmentally ready to handle the cognitive characteristics of the OOP language Java? Which cognitive teaching style is best for this OOP language Java? Questions such as the aforementioned are the focus of this research Such research is needed to improve understanding of the learning process and identify students' difficulties with OOP methods. This can enhance academic teaching and industry training (Scholtz  1993; Sheetz  1997; Rosson  1990). Cognitive development as measured by the Propositional Logic Test  cognitive style as measured by the Hemispheric Mode Indicator  and physical hemispheric dominance as measured by a self-report survey were obtained from thirty-six university students studying Java programming. Findings reveal that physical hemispheric dominance is unrelated to cognitive and programming language variables. However  both procedural and object oriented programming require Piaget's formal operation cognitive level as indicated by the Propositional Logic Test. This is consistent with prior research A new finding is that object oriented programming also requires formal operation cognitive level. Another new finding is that object oriented programming appears to be unrelated to hemispheric cognitive style as indicated by the Hemispheric Mode Indicator (HMIAn object-oriented  coprocessor-accelerated model for ice sheet simulationsNASA Astrophysics Data System (ADS)Seddik  H.; Greve  R.2013-12-01Recently  numerous models capable of modeling the thermo-dynamics of ice sheets have been developed within the ice sheet modeling community. Their capabilities have been characterized by a wide range of features with different numerical methods (finite difference or finite element)  different implementations of the ice flow mechanics (shallow-ice  higher-order  full Stokes) and different treatments for the basal and coastal areas (basal hydrology  basal sliding  ice shelves). Shallow-ice models (SICOPOLIS  IcIES  PISM  etc) have been widely used for modeling whole ice sheets (Greenland and Antarctica) due to the relatively low computational cost of the shallow-ice approximation but higher order (ISSM  AIF) and full Stokes (Elmer/Ice) models have been recently used to model the Greenland ice sheet. The advance in processor speed and the decrease in cost for accessing large amount of memory and storage have undoubtedly been the driving force in the commoditization of models with higher capabilities  and the popularity of Elmer/Ice (http://elmerice.elmerfem.com) with an active user base is a notable representation of this trend. Elmer/Ice is a full Stokes model built on top of the multi-physics package Elmer (http://www.csc.fi/english/pages/elmer) which provides the full machinery for the complex finite element procedure and is fully parallel (mesh partitioning with OpenMPI communication). Elmer is mainly written in Fortran 90 and targets essentially traditional processors as the code base was not initially written to run on modern coprocessors (yet adding support for the recently introduced x86 based coprocessors is possible). Furthermore  a truly modular and object-oriented implementation is required for quick adaptation to fast evolving capabilities in hardware (Fortran 2003 provides an object-oriented programming model while not being clean and requiring a tricky refactoring of Elmer code). In this work  the object-oriented  coprocessor-accelerated finite elementAutomatic code generation in SPARK: Applications of computer algebra and compiler-compilersSciTech ConnectNataf  J.M.; Winkelmann  F.We show how computer algebra and compiler-compilers are used for automatic code generation in the Simulation Problem Analysis and Research Kernel (SPARK)  an object oriented environment for modeling complex physical systems that can be described by differential-algebraic equations. After a brief overview of SPARK  we describe the use of computer algebra in SPARK's symbolic interface  which generates solution code for equations that are entered in symbolic form. We also describe how the Lex/Yacc compiler-compiler is used to achieve important extensions to the SPARK simulation language  including parametrized macro objects and steady-state resetting of a dynamic simulation. The application of thesemoreÂ Â» methods to solving the partial differential equations for two-dimensional heat flow is illustrated.Â«Â lessAutomatic code generation in SPARK: Applications of computer algebra and compiler-compilersSciTech ConnectNataf  J.M.; Winkelmann  F.We show how computer algebra and compiler-compilers are used for automatic code generation in the Simulation Problem Analysis and Research Kernel (SPARK)  an object oriented environment for modeling complex physical systems that can be described by differential-algebraic equations. After a brief overview of SPARK  we describe the use of computer algebra in SPARK`s symbolic interface  which generates solution code for equations that are entered in symbolic form. We also describe how the Lex/Yacc compiler-compiler is used to achieve important extensions to the SPARK simulation language  including parametrized macro objects and steady-state resetting of a dynamic simulation. The application of thesemoreÂ Â» methods to solving the partial differential equations for two-dimensional heat flow is illustrated.Â«Â lessAn object-oriented  technology-adaptive information modelNASA Technical Reports Server (NTRS)Anyiwo  Joshua C.1995-01-01The primary objective was to develop a computer information system for effectively presenting NASA's technologies to American industries  for appropriate commercialization. To this end a comprehensive information management model  applicable to a wide variety of situations  and immune to computer software/hardware technological gyrations  was developed. The model consists of four main elements: a DATA_STORE  a data PRODUCER/UPDATER_CLIENT and a data PRESENTATION_CLIENT  anchored to a central object-oriented SERVER engine. This server engine facilitates exchanges among the other model elements and safeguards the integrity of the DATA_STORE element. It is designed to support new technologies  as they become available  such as Object Linking and Embedding (OLE)  on-demand audio-video data streaming with compression (such as is required for video conferencing)  Worldwide Web (WWW) and other information services and browsing  fax-back data requests  presentation of information on CD-ROM  and regular in-house database management  regardless of the data model in place. The four components of this information model interact through a system of intelligent message agents which are customized to specific information exchange needs. This model is at the leading edge of modern information management models. It is independent of technological changes and can be implemented in a variety of ways to meet the specific needs of any communications situation. This summer a partial implementation of the model has been achieved. The structure of the DATA_STORE has been fully specified and successfully tested using Microsoft's FoxPro 2.6 database management system. Data PRODUCER/UPDATER and PRESENTATION architectures have been developed and also successfully implemented in FoxPro; and work has started on a full implementation of the SERVER engine. The model has also been successfully applied to a CD-ROM presentation of NASA's technologies in support of Langley Research Center's TAGQuantum computing with Majorana fermion codesNASA Astrophysics Data System (ADS)Litinski  Daniel; von Oppen  Felix2018-05-01We establish a unified framework for Majorana-based fault-tolerant quantum computation with Majorana surface codes and Majorana color codes. All logical Clifford gates are implemented with zero-time overhead. This is done by introducing a protocol for Pauli product measurements with tetrons and hexons which only requires local 4-Majorana parity measurements. An analogous protocol is used in the fault-tolerant setting  where tetrons and hexons are replaced by Majorana surface code patches  and parity measurements are replaced by lattice surgery  still only requiring local few-Majorana parity measurements. To this end  we discuss twist defects in Majorana fermion surface codes and adapt the technique of twist-based lattice surgery to fermionic codes. Moreover  we propose a family of codes that we refer to as Majorana color codes  which are obtained by concatenating Majorana surface codes with small Majorana fermion codes. Majorana surface and color codes can be used to decrease the space overhead and stabilizer weight compared to their bosonic counterparts.Towards a general object-oriented software development methodologyNASA Technical Reports Server (NTRS)Seidewitz  ED; Stark  Mike1986-01-01An object is an abstract software model of a problem domain entity. Objects are packages of both data and operations of that data (Goldberg 83  Booch 83). The Ada (tm) package construct is representative of this general notion of an object. Object-oriented design is the technique of using objects as the basic unit of modularity in systems design. The Software Engineering Laboratory at the Goddard Space Flight Center is currently involved in a pilot program to develop a flight dynamics simulator in Ada (approximately 40 000 statements) using object-oriented methods. Several authors have applied object-oriented concepts to Ada (e.g.  Booch 83  Cherry 85). It was found that these methodologies are limited. As a result a more general approach was synthesized with allows a designer to apply powerful object-oriented principles to a wide range of applications and at all stages of design. An overview is provided of this approach. Further  how object-oriented design fits into the overall software life-cycle is considered.Humanoid Robotics: Real-Time Object Oriented ProgrammingNASA Technical Reports Server (NTRS)Newton  Jason E.2005-01-01Programming of robots in today's world is often done in a procedural oriented fashion  where object oriented programming is not incorporated. In order to keep a robust architecture allowing for easy expansion of capabilities and a truly modular design  object oriented programming is required. However  concepts in object oriented programming are not typically applied to a real time environment. The Fujitsu HOAP-2 is the test bed for the development of a humanoid robot framework abstracting control of the robot into simple logical commands in a real time robotic system while allowing full access to all sensory data. In addition to interfacing between the motor and sensory systems  this paper discusses the software which operates multiple independently developed control systems simultaneously and the safety measures which keep the humanoid from damaging itself and its environment while running these systems. The use of this software decreases development time and costs and allows changes to be made while keeping results safe and predictable.An Improved Suite of Object Oriented Software MeasuresNASA Technical Reports Server (NTRS)Neal  Ralph D.; Weistroffer  H. Roland; Coppins  Richard J.1997-01-01In the pursuit of ever increasing productivity  the need to be able to measure specific aspects of software is generally agreed upon. As object oriented programming languages are becoming more and more widely used  metrics specifically designed for object oriented software are required. In recent years there has been an explosion of new  object oriented software metrics proposed in the literature. Unfortunately  many or most of these proposed metrics have not been validated to measure what they claim to measure. In fact  an analysis of many of these metrics shows that they do not satisfy basic properties of measurement theory  and thus their application has to be suspect. In this paper ten improved metrics are proposed and are validated using measurement theory.C++  objected-oriented programming  and astronomical data modelsNASA Technical Reports Server (NTRS)Farris  A.1992-01-01Contemporary astronomy is characterized by increasingly complex instruments and observational techniques  higher data collection rates  and large data archives  placing severe stress on software analysis systems. The object-oriented paradigm represents a significant new approach to software design and implementation that holds great promise for dealing with this increased complexity. The basic concepts of this approach will be characterized in contrast to more traditional procedure-oriented approaches. The fundamental features of objected-oriented programming will be discussed from a C++ programming language perspective  using examples familiar to astronomers. This discussion will focus on objects  classes and their relevance to the data type system; the principle of information hiding; and the use of inheritance to implement generalization/specialization relationships. Drawing on the object-oriented approach  features of a new database model to support astronomical data analysis will be presented.Extension of an Object-Oriented Optimization Tool: User's Reference ManualNASA Technical Reports Server (NTRS)Pak  Chan-Gi; Truong  Samson S.2015-01-01The National Aeronautics and Space Administration Armstrong Flight Research Center has developed a cost-effective and flexible object-oriented optimization (O (sup 3)) tool that leverages existing tools and practices and allows easy integration and adoption of new state-of-the-art software. This object-oriented framework can integrate the analysis codes for multiple disciplines  as opposed to relying on one code to perform analysis for all disciplines. Optimization can thus take place within each discipline module  or in a loop between the O (sup 3) tool and the discipline modules  or both. Six different sample mathematical problems are presented to demonstrate the performance of the O (sup 3) tool. Instructions for preparing input data for the O (sup 3) tool are detailed in this user's manual.Object-oriented structures supporting remote sensing databasesNASA Technical Reports Server (NTRS)Wichmann  Keith; Cromp  Robert F.1995-01-01Object-oriented databases show promise for modeling the complex interrelationships pervasive in scientific domains. To examine the utility of this approach  we have developed an Intelligent Information Fusion System based on this technology  and applied it to the problem of managing an active repository of remotely-sensed satellite scenes. The design and implementation of the system is compared and contrasted with conventional relational database techniques  followed by a presentation of the underlying object-oriented data structures used to enable fast indexing into the data holdings.Parameterized hardware description as object oriented hardware model implementationNASA Astrophysics Data System (ADS)Drabik  Pawel K.2010-09-01The paper introduces novel model for design  visualization and management of complex  highly adaptive hardware systems. The model settles component oriented environment for both hardware modules and software application. It is developed on parameterized hardware description research. Establishment of stable link between hardware and software  as a purpose of designed and realized work  is presented. Novel programming framework model for the environment  named Graphic-Functional-Components is presented. The purpose of the paper is to present object oriented hardware modeling with mentioned features. Possible model implementation in FPGA chips and its management by object oriented software in Java is described.Object-Oriented Design for Sparse Direct SolversNASA Technical Reports Server (NTRS)Dobrian  Florin; Kumfert  Gary; Pothen  Alex1999-01-01We discuss the object-oriented design of a software package for solving sparse  symmetric systems of equations (positive definite and indefinite) by direct methods. At the highest layers  we decouple data structure classes from algorithmic classes for flexibility. We describe the important structural and algorithmic classes in our design  and discuss the trade-offs we made for high performance. The kernels at the lower layers were optimized by hand. Our results show no performance loss from our object-oriented design  while providing flexibility  case of use  and extensibility over solvers using procedural design.Large project experiences with object-oriented methods and reuseNASA Technical Reports Server (NTRS)Wessale  William; Reifer  Donald J.; Weller  David1992-01-01The SSVTF (Space Station Verification and Training Facility) project is completing the Preliminary Design Review of a large software development using object-oriented methods and systematic reuse. An incremental developmental lifecycle was tailored to provide early feedback and guidance on methods and products  with repeated attention to reuse. Object oriented methods were formally taught and supported by realistic examples. Reuse was readily accepted and planned by the developers. Schedule and budget issues were handled by agreements and work sharing arranged by the developers.High-Performance Java Codes for Computational Fluid DynamicsNASA Technical Reports Server (NTRS)Riley  Christopher; Chatterjee  Siddhartha; Biswas  Rupak; Biegel  Bryan (Technical Monitor)2001-01-01The computational science community is reluctant to write large-scale computationally -intensive applications in Java due to concerns over Java's poor performance  despite the claimed software engineering advantages of its object-oriented features. Naive Java implementations of numerical algorithms can perform poorly compared to corresponding Fortran or C implementations. To achieve high performance  Java applications must be designed with good performance as a primary goal. This paper presents the object-oriented design and implementation of two real-world applications from the field of Computational Fluid Dynamics (CFD): a finite-volume fluid flow solver (LAURA  from NASA Langley Research Center)  and an unstructured mesh adaptation algorithm (2D_TAG  from NASA Ames Research Center). This work builds on our previous experience with the design of high-performance numerical libraries in Java. We examine the performance of the applications using the currently available Java infrastructure and show that the Java version of the flow solver LAURA performs almost within a factor of 2 of the original procedural version. Our Java version of the mesh adaptation algorithm 2D_TAG performs within a factor of 1.5 of its original procedural version on certain platforms. Our results demonstrate that object-oriented software design principles are not necessarily inimical to high performance.MCViNE- An object oriented Monte Carlo neutron ray tracing simulation packageDOE PAGESLin  J. Y. Y.; Smith  Hillary L.; Granroth  Garrett E.; ...2015-11-28MCViNE (Monte-Carlo VIrtual Neutron Experiment) is an open-source Monte Carlo (MC) neutron ray-tracing software for performing computer modeling and simulations that mirror real neutron scattering experiments. We exploited the close similarity between how instrument components are designed and operated and how such components can be modeled in software. For example we used object oriented programming concepts for representing neutron scatterers and detector systems  and recursive algorithms for implementing multiple scattering. Combining these features together in MCViNE allows one to handle sophisticated neutron scattering problems in modern instruments  including  for example  neutron detection by complex detector systems  and single and multiplemoreÂ Â» scattering events in a variety of samples and sample environments. In addition  MCViNE can use simulation components from linear-chain-based MC ray tracing packages which facilitates porting instrument models from those codes. Furthermore it allows for components written solely in Python  which expedites prototyping of new components. These developments have enabled detailed simulations of neutron scattering experiments  with non-trivial samples  for time-of-flight inelastic instruments at the Spallation Neutron Source. Examples of such simulations for powder and single-crystal samples with various scattering kernels  including kernels for phonon and magnon scattering  are presented. As a result  with simulations that closely reproduce experimental results  scattering mechanisms can be turned on and off to determine how they contribute to the measured scattering intensities  improving our understanding of the underlying physics.Â«Â lessDevelopment of probabilistic multimedia multipathway computer codes.SciTech ConnectYu  C.; LePoire  D.; Gnanapragasam  E.2002-01-01The deterministic multimedia dose/risk assessment codes RESRAD and RESRAD-BUILD have been widely used for many years for evaluation of sites contaminated with residual radioactive materials. The RESRAD code applies to the cleanup of sites (soils) and the RESRAD-BUILD code applies to the cleanup of buildings and structures. This work describes the procedure used to enhance the deterministic RESRAD and RESRAD-BUILD codes for probabilistic dose analysis. A six-step procedure was used in developing default parameter distributions and the probabilistic analysis modules. These six steps include (1) listing and categorizing parameters; (2) ranking parameters; (3) developing parameter distributions; (4) testing parameter distributionsmoreÂ Â» for probabilistic analysis; (5) developing probabilistic software modules; and (6) testing probabilistic modules and integrated codes. The procedures used can be applied to the development of other multimedia probabilistic codes. The probabilistic versions of RESRAD and RESRAD-BUILD codes provide tools for studying the uncertainty in dose assessment caused by uncertain input parameters. The parameter distribution data collected in this work can also be applied to other multimedia assessment tasks and multimedia computer codes.Â«Â lessNew coding technique for computer generated holograms.NASA Technical Reports Server (NTRS)Haskell  R. E.; Culver  B. C.1972-01-01A coding technique is developed for recording computer generated holograms on a computer controlled CRT in which each resolution cell contains two beam spots of equal size and equal intensity. This provides a binary hologram in which only the position of the two dots is varied from cell to cell. The amplitude associated with each resolution cell is controlled by selectively diffracting unwanted light into a higher diffraction order. The recording of the holograms is fast and simple.People vs. Object Orientation in Preschool Boys and Girls.ERIC Educational Resources Information CenterJennings  Kay D.This study was undertaken to explore the cultural stereotype that boys are more object-oriented and girls are more people-oriented. A total of 38 white  middle class  preschool children were observed during their free play hour at nursery school when a variety of people and objects were freely available to them. Each child was observed with a timeâ€¦Strategies for Teaching Object-Oriented Concepts with JavaERIC Educational Resources Information CenterSicilia  Miguel-Angel2006-01-01A considerable amount of experiences in teaching object-oriented concepts using the Java language have been reported to date  some of which describe language pitfalls and concrete learning difficulties. In this paper  a number of additional issues that have been experienced as difficult for students to master  along with approaches intended toâ€¦Clinical Views: Object-Oriented Views for Clinical DatabasesPubMed CentralPortoni  Luisa; Combi  Carlo; Pinciroli  Francesco1998-01-01We present here a prototype of a clinical information system for the archiving and the management of multimedia and temporally-oriented clinical data related to PTCA patients. The system is based on an object-oriented DBMS and supports multiple views and view schemas on patients' data. Remote data access is supported too.Object-Oriented Scientific Programming with Fortran 90NASA Technical Reports Server (NTRS)Norton  C.1998-01-01Fortran 90 is a modern language that introduces many important new features beneficial for scientific programming. We discuss our experiences in plasma particle simulation and unstructured adaptive mesh refinement on supercomputers  illustrating the features of Fortran 90 that support the object-oriented methodology.Object-oriented fault tree evaluation program for quantitative analysesNASA Technical Reports Server (NTRS)Patterson-Hine  F. A.; Koen  B. V.1988-01-01Object-oriented programming can be combined with fault free techniques to give a significantly improved environment for evaluating the safety and reliability of large complex systems for space missions. Deep knowledge about system components and interactions  available from reliability studies and other sources  can be described using objects that make up a knowledge base. This knowledge base can be interrogated throughout the design process  during system testing  and during operation  and can be easily modified to reflect design changes in order to maintain a consistent information source. An object-oriented environment for reliability assessment has been developed on a Texas Instrument (TI) Explorer LISP workstation. The program  which directly evaluates system fault trees  utilizes the object-oriented extension to LISP called Flavors that is available on the Explorer. The object representation of a fault tree facilitates the storage and retrieval of information associated with each event in the tree  including tree structural information and intermediate results obtained during the tree reduction process. Reliability data associated with each basic event are stored in the fault tree objects. The object-oriented environment on the Explorer also includes a graphical tree editor which was modified to display and edit the fault trees.Experiences Building an Object-Oriented System in C++NASA Technical Reports Server (NTRS)Madany  Peter W.; Campbell  Roy H.; Kougiouris  Panagiotis1991-01-01This paper describes tools that we built to support the construction of an object-oriented operating system in C++. The tools provide the automatic deletion of unwanted objects  first-class classes  dynamically loadable classes  and class-oriented debugging. As a consequence of our experience building Choices  we advocate these features as useful  simplifying and unifying many aspects of system programming.Quick Prototyping of Educational Software: An Object-Oriented Approach.ERIC Educational Resources Information CenterWong  Simon C-H1994-01-01Introduces and demonstrates a quick-prototyping model for educational software development that can be used by teachers developing their own courseware using an object-oriented programming system. Development of a courseware package called ""The Match-Maker"" is explained as an example that uses HyperCard for quick prototyping. (Containsâ€¦How Reuse Influences Productivity in Object-Oriented SystemsNASA Technical Reports Server (NTRS)Basili  Victor R.; Briand  Lionel C.; Melo  Walcelio L.1997-01-01Although reuse is assumed to be especially valuable in building high quality software as well as in Object Oriented (OO) development  limited empirical evidence connects reuse with productivity and quality gains. The author's eight system study begins to define such benefits in an OO framework  most notably in terms of reduce defect density and rework as well as in increased productivity.Enhancement of the CAVE computer codeNASA Astrophysics Data System (ADS)Rathjen  K. A.; Burk  H. O.1983-12-01The computer code CAVE (Conduction Analysis via Eigenvalues) is a convenient and efficient computer code for predicting two dimensional temperature histories within thermal protection systems for hypersonic vehicles. The capabilities of CAVE were enhanced by incorporation of the following features into the code: real gas effects in the aerodynamic heating predictions  geometry and aerodynamic heating package for analyses of cone shaped bodies  input option to change from laminar to turbulent heating predictions on leading edges  modification to account for reduction in adiabatic wall temperature with increase in leading sweep  geometry package for two dimensional scramjet engine sidewall  with an option for heat transfer to external and internal surfaces  print out modification to provide tables of select temperatures for plotting and storage  and modifications to the radiation calculation procedure to eliminate temperature oscillations induced by high heating rates. These new features are described.Thermoelectric pump performance analysis computer codeNASA Technical Reports Server (NTRS)Johnson  J. L.1973-01-01A computer program is presented that was used to analyze and design dual-throat electromagnetic dc conduction pumps for the 5-kwe ZrH reactor thermoelectric system. In addition to a listing of the code and corresponding identification of symbols  the bases for this analytical model are provided.Error-correcting codes in computer arithmetic.NASA Technical Reports Server (NTRS)Massey  J. L.; Garcia  O. N.1972-01-01Summary of the most important results so far obtained in the theory of coding for the correction and detection of errors in computer arithmetic. Attempts to satisfy the stringent reliability demands upon the arithmetic unit are considered  and special attention is given to attempts to incorporate redundancy into the numbers themselves which are being processed so that erroneous results can be detected and corrected.Modeling the Object-Oriented Space Through Validated MeasuresNASA Technical Reports Server (NTRS)Neal  Ralph D.1996-01-01In order to truly understand software and the software development process  software measurement must be better understood. A beginning step toward a better understanding of software measurement is the categorization of the measurements by some meaningful taxonomy. The most meaningful taxonomy would capture the basic nature of the subject oriented (O-O) space. The interesting characteristics of object oriented software offer a starting point for such a categorization of measures. A taxonomy has been developed based on fourteen characteristics of object-oriented software gathered from the literature This taxonomy allows us to easily see gaps and redundancies in the O-O measures. The taxonomy also clearly differentiates among taxa so that there is no ambiguity as to the taxon to which a measure belongs. The taxonomy has been populated with thirty-two measures that have been validated in the narrow sense of Fenton  using measurement theory with Zuse's augmentation.Object-oriented software design in semiautomatic building extractionNASA Astrophysics Data System (ADS)Guelch  Eberhard; Mueller  Hardo1997-08-01Developing a system for semiautomatic building acquisition is a complex process  that requires constant integration and updating of software modules and user interfaces. To facilitate these processes we apply an object-oriented design not only for the data but also for the software involved. We use the unified modeling language (UML) to describe the object-oriented modeling of the system in different levels of detail. We can distinguish between use cases from the users point of view  that represent a sequence of actions  yielding in an observable result and the use cases for the programmers  who can use the system as a class library to integrate the acquisition modules in their own software. The structure of the system is based on the model-view-controller (MVC) design pattern. An example from the integration of automated texture extraction for the visualization of results demonstrate the feasibility of this approach.Expert reasoning within an object-oriented frameworkSciTech ConnectBohn  S.J.; Pennock  K.A.1991-10-01A large number of contaminated waste sites across the United States await site remediation efforts. These sites can be physically complex  composed of multiple  possibly interacting  contaminants distributed throughout one or more media. The Remedial Action Assessment System (RAAS) is being designed and developed to support decisions concerning the selection of remediation alternatives. The goal of this system is to broaden the consideration of remediation alternatives  while reducing the time and cost of making these considerations. The Remedial Action Assessment System was designed and constructed using object-oriented techniques. It is a hybrid system which uses a combination of quantitative andmoreÂ Â» qualitative reasoning to consider and suggest remediation alternatives. the reasoning process that drives this application is centered around an object-oriented organization of remediation technology information. This paper briefly describes the waste remediation problem and then discusses the information structure and organization RAAS utilizes to address it. 4 refs.  4 figs.Â«Â lessA Decision-Based Methodology for Object Oriented-DesignDTIC Science & Technology1988-12-16willing to take the time to meet together weekly for mutual encouragement and prayer . Their friendship  uncompromising standards  and lifestyle were...assume the validity of the object-oriented and software engineering principles involved  and define and proto- type a generic  language independent...mean- ingful labels for variables  abstraction requires the ability to define new types that relieve the programmer from having to know or mess withObjects as closures - Abstract semantics of object oriented languagesNASA Technical Reports Server (NTRS)Reddy  Uday S.1988-01-01The denotational semantics of object-oriented languages is discussed using the concept of closure widely used in (semi) functional programming to encapsulate side effects. It is shown that this denotational framework is adequate to explain classes  instantiation  and inheritance in the style of Simula as well as SMALLTALK-80. This framework is then compared with that of Kamin (1988)  in his recent denotational definition of SMALLTALK-80  and the implications of the differences between the two approaches are discussed.Objects as closures: Abstract semantics of object oriented languagesNASA Technical Reports Server (NTRS)Reddy  Uday S.1989-01-01We discuss denotational semantics of object-oriented languages  using the concept of closure widely used in (semi) functional programming to encapsulate side effects. It is shown that this denotational framework is adequate to explain classes  instantiation  and inheritance in the style of Simula as well as SMALLTALK-80. This framework is then compared with that of Kamin  in his recent denotational definition of SMALLTALK-80  and the implications of the differences between the two approaches are discussed.Yes! An object-oriented compiler compiler (YOOCC)SciTech ConnectAvotins  J.; Mingins  C.; Schmidt  H.1995-12-31Grammar-based processor generation is one of the most widely studied areas in language processor construction. However  there have been very few approaches to date that reconcile object-oriented principles  processor generation  and an object-oriented language. Pertinent here also. is that currently to develop a processor using the Eiffel Parse libraries requires far too much time to be expended on tasks that can be automated. For these reasons  we have developed YOOCC (Yes! an Object-Oriented Compiler Compiler)  which produces a processor framework from a grammar using an enhanced version of the Eiffel Parse libraries  incorporating the ideas hypothesized by Meyer  and GrapemoreÂ Â» and Walden  as well as many others. Various essential changes have been made to the Eiffel Parse libraries. Examples are presented to illustrate the development of a processor using YOOCC  and it is concluded that the Eiffel Parse libraries are now not only an intelligent  but also a productive option for processor construction.Â«Â lessEMEN2: An Object Oriented Database and Electronic Lab NotebookPubMed CentralRees  Ian; Langley  Ed; Chiu  Wah; Ludtke  Steven J.2013-01-01Transmission electron microscopy and associated methods such as single particle analysis  2-D crystallography  helical reconstruction and tomography  are highly data-intensive experimental sciences  which also have substantial variability in experimental technique. Object-oriented databases present an attractive alternative to traditional relational databases for situations where the experiments themselves are continually evolving. We present EMEN2  an easy to use object-oriented database with a highly flexible infrastructure originally targeted for transmission electron microscopy and tomography  which has been extended to be adaptable for use in virtually any experimental science. It is a pure object-oriented database designed for easy adoption in diverse laboratory environments  and does not require professional database administration. It includes a full featured  dynamic web interface in addition to APIs for programmatic access. EMEN2 installations currently support roughly 800 scientists worldwide with over 1/2 million experimental records and over 20 TB of experimental data. The software is freely available with complete source. PMID:23360752An integrated radiation physics computer code system.NASA Technical Reports Server (NTRS)Steyn  J. J.; Harris  D. W.1972-01-01An integrated computer code system for the semi-automatic and rapid analysis of experimental and analytic problems in gamma photon and fast neutron radiation physics is presented. Such problems as the design of optimum radiation shields and radioisotope power source configurations may be studied. The system codes allow for the unfolding of complex neutron and gamma photon experimental spectra. Monte Carlo and analytic techniques are used for the theoretical prediction of radiation transport. The system includes a multichannel pulse-height analyzer scintillation and semiconductor spectrometer coupled to an on-line digital computer with appropriate peripheral equipment. The system is geometry generalized as well as self-contained with respect to material nuclear cross sections and the determination of the spectrometer response functions. Input data may be either analytic or experimental.TAIR: A transonic airfoil analysis computer codeNASA Technical Reports Server (NTRS)Dougherty  F. C.; Holst  T. L.; Grundy  K. L.; Thomas  S. D.1981-01-01The operation of the TAIR (Transonic AIRfoil) computer code  which uses a fast  fully implicit algorithm to solve the conservative full-potential equation for transonic flow fields about arbitrary airfoils  is described on two levels of sophistication: simplified operation and detailed operation. The program organization and theory are elaborated to simplify modification of TAIR for new applications. Examples with input and output are given for a wide range of cases  including incompressible  subcritical compressible  and transonic calculations.Computing Challenges in Coded Mask ImagingNASA Technical Reports Server (NTRS)Skinner  Gerald2009-01-01This slide presaentation reviews the complications and challenges in developing computer systems for Coded Mask Imaging telescopes. The coded mask technique is used when there is no other way to create the telescope  (i.e.  when there are wide fields of view  high energies for focusing or low energies for the Compton/Tracker Techniques and very good angular resolution.) The coded mask telescope is described  and the mask is reviewed. The coded Masks for the INTErnational Gamma-Ray Astrophysics Laboratory (INTEGRAL) instruments are shown  and a chart showing the types of position sensitive detectors used for the coded mask telescopes is also reviewed. Slides describe the mechanism of recovering an image from the masked pattern. The correlation with the mask pattern is described. The Matrix approach is reviewed  and other approaches to image reconstruction are described. Included in the presentation is a review of the Energetic X-ray Imaging Survey Telescope (EXIST) / High Energy Telescope (HET)  with information about the mission  the operation of the telescope  comparison of the EXIST/HET with the SWIFT/BAT and details of the design of the EXIST/HET.Hanford meteorological station computer codes: Volume 9  The quality assurance computer codesSciTech ConnectBurk  K.W.; Andrews  G.L.1989-02-01The Hanford Meteorological Station (HMS) was established in 1944 on the Hanford Site to collect and archive meteorological data and provide weather forecasts and related services for Hanford Site approximately 1/2 mile east of the 200 West Area and is operated by PNL for the US Department of Energy. Meteorological data are collected from various sensors and equipment located on and off the Hanford Site. These data are stored in data bases on the Digital Equipment Corporation (DEC) VAX 11/750 at the HMS (hereafter referred to as the HMS computer). Files from those data bases are routinely transferred to themoreÂ Â» Emergency Management System (EMS) computer at the Unified Dose Assessment Center (UDAC). To ensure the quality and integrity of the HMS data  a set of Quality Assurance (QA) computer codes has been written. The codes will be routinely used by the HMS system manager or the data base custodian. The QA codes provide detailed output files that will be used in correcting erroneous data. The following sections in this volume describe the implementation and operation of QA computer codes. The appendices contain detailed descriptions  flow charts  and source code listings of each computer code. 2 refs.Â«Â lessObject Oriented Programming Systems (OOPS) and frame representations: An investigation of programming paradigmsNASA Technical Reports Server (NTRS)Auty  David1988-01-01The project was initiated to research Object Oriented Programming Systems (OOPS) and frame representation systems  their significance and applicability  and their implementation in or relationship to Ada. Object orientated is currently a very popular conceptual adjective. Object oriented programming  in particular  is promoted as a particularly productive approach to programming; an approach which maximizes opportunities for code reuse and lends itself to the definition of convenient and well-developed units. Such units are thus expected to be usable in a variety of situations  beyond the typical highly specific unit development of other approaches. Frame represenation systems share a common heritage and similar conceptual foundations. Together they represent a quickly emerging alternative approach to programming. The approach is to first define the terms  starting with relevant concepts and using these to put bounds on what is meant by OOPS and Frames. From this the possibilities were pursued to merge OOPS with Ada which will further elucidate the significant characteristics which make up this programming approach. Finally  some of the merits and demerits of OOPS were briefly considered as a way of addressing the applicability of OOPS to various programming tasks.Object-oriented Approach to High-level Network Monitoring and ManagementNASA Technical Reports Server (NTRS)Mukkamala  Ravi2000-01-01An absolute prerequisite for the management of large investigating methods to build high-level monitoring computer networks is the ability to measure their systems that are built on top of existing monitoring performance. Unless we monitor a system  we cannot tools. Due to the heterogeneous nature of the hope to manage and control its performance. In this underlying systems at NASA Langley Research Center  paper  we describe a network monitoring system that we use an object-oriented approach for the design  we are currently designing and implementing. Keeping  first  we use UML (Unified Modeling Language) to in mind the complexity of the task and the required model users' requirements. Second  we identify the flexibility for future changes  we use an object-oriented existing capabilities of the underlying monitoring design methodology. The system is built using the system. Third  we try to map the former with the latter. APIs offered by the HP OpenView system.The Use of Object-Oriented Analysis Methods in Surety AnalysisSciTech ConnectCraft  Richard L.; Funkhouser  Donald R.; Wyss  Gregory D.1999-05-01Object-oriented analysis methods have been used in the computer science arena for a number of years to model the behavior of computer-based systems. This report documents how such methods can be applied to surety analysis. By embodying the causality and behavior of a system in a common object-oriented analysis model  surety analysts can make the assumptions that underlie their models explicit and thus better communicate with system designers. Furthermore  given minor extensions to traditional object-oriented analysis methods  it is possible to automatically derive a wide variety of traditional risk and reliability analysis methods from a single common object model. AutomaticmoreÂ Â» model extraction helps ensure consistency among analyses and enables the surety analyst to examine a system from a wider variety of viewpoints in a shorter period of time. Thus it provides a deeper understanding of a system's behaviors and surety requirements. This report documents the underlying philosophy behind the common object model representation  the methods by which such common object models can be constructed  and the rules required to interrogate the common object model for derivation of traditional risk and reliability analysis models. The methodology is demonstrated in an extensive example problem.Â«Â lessDevelopment and application of computational aerothermodynamics flowfield computer codesNASA Technical Reports Server (NTRS)Venkatapathy  Ethiraj1994-01-01Research was performed in the area of computational modeling and application of hypersonic  high-enthalpy  thermo-chemical nonequilibrium flow (Aerothermodynamics) problems. A number of computational fluid dynamic (CFD) codes were developed and applied to simulate high altitude rocket-plume  the Aeroassist Flight Experiment (AFE)  hypersonic base flow for planetary probes  the single expansion ramp model (SERN) connected with the National Aerospace Plane  hypersonic drag devices  hypersonic ramp flows  ballistic range models  shock tunnel facility nozzles  transient and steady flows in the shock tunnel facility  arc-jet flows  thermochemical nonequilibrium flows around simple and complex bodies  axisymmetric ionized flows of interest to re-entry  unsteady shock induced combustion phenomena  high enthalpy pulsed facility simulations  and unsteady shock boundary layer interactions in shock tunnels. Computational modeling involved developing appropriate numerical schemes for the flows on interest and developing  applying  and validating appropriate thermochemical processes. As part of improving the accuracy of the numerical predictions  adaptive grid algorithms were explored  and a user-friendly  self-adaptive code (SAGE) was developed. Aerothermodynamic flows of interest included energy transfer due to strong radiation  and a significant level of effort was spent in developing computational codes for calculating radiation and radiation modeling. In addition  computational tools were developed and applied to predict the radiative heat flux and spectra that reach the model surface.Enhancing Interactivity and Productivity through Object-Oriented Authoring: An Instructional Designer's Perspective.ERIC Educational Resources Information CenterChapman  Bryan L.1994-01-01Discusses the effect of object-oriented programming on the evolution of authoring systems. Topics include the definition of an object; examples of object-oriented authoring interfaces; what object-orientation means to an instructional developer; how object orientation increases productivity and enhances interactivity; and the future of coursewareâ€¦Comparison of transect sampling and object-oriented image classification methods of urbanizing catchmentsNASA Astrophysics Data System (ADS)Yang  Y.; Tenenbaum  D. E.2009-12-01The process of urbanization has major effects on both human and natural systems. In order to monitor these changes and better understand how urban ecological systems work  urban spatial structure and the variation needs to be first quantified at a fine scale. Because the land-use and land-cover (LULC) in urbanizing areas is highly heterogeneous  the classification of urbanizing environments is the most challenging field in remote sensing. Although a pixel-based method is a common way to do classification  the results are not good enough for many research objectives which require more accurate classification data in fine scales. Transect sampling and object-oriented classification methods are more appropriate for urbanizing areas. Tenenbaum used a transect sampling method using a computer-based facility within a widely available commercial GIS in the Glyndon Catchment and the Upper Baismans Run Catchment  Baltimore  Maryland. It was a two-tiered classification system  including a primary level (which includes 7 classes) and a secondary level (which includes 37 categories). The statistical information of LULC was collected. W. Zhou applied an object-oriented method at the parcel level in Gwynnâ€™s Falls Watershed which includes the two previously mentioned catchments and six classes were extracted. The two urbanizing catchments are located in greater Baltimore  Maryland and drain into Chesapeake Bay. In this research  the two different methods are compared for 6 classes (woody  herbaceous  water  ground  pavement and structure). The comparison method uses the segments in the transect method to extract LULC information from the results of the object-oriented method. Classification results were compared in order to evaluate the difference between the two methods. The overall proportions of LULC classes from the two studies show that there is overestimation of structures in the object-oriented method. For the other five classes  the results from the two methods areAn Object-Oriented Python Implementation of an Intermediate-Level Atmospheric ModelNASA Astrophysics Data System (ADS)Lin  J. W.2008-12-01The Neelin-Zeng Quasi-equilibrium Tropical Circulation Model (QTCM1) is a Fortran-based intermediate-level atmospheric model that includes simplified treatments of several physical processes  including a GCM-like convective scheme and a land-surface scheme with representations of different surface types  evaporation  and soil moisture. This model has been used in studies of the Madden-Julian oscillation  ENSO  and vegetation-atmosphere interaction effects on climate. Through the assumption of convective quasi-equilibrium in the troposphere  the QTCM1 is able to include full nonlinearity  resolve baroclinic disturbances  and generate a reasonable climatology  all at low computational cost. One year of simulation on a PC at 5.625 Ã— 3.75 degree longitude-latitude resolution takes under three minutes of wall-clock time. The Python package qtcm implements the QTCM1 in a mixed-language environment that retains the speed of compiled Fortran while providing the benefits of Python's object-oriented framework and robust suite of utilities and datatypes. We describe key programming constructs used to create this modeling environment: the decomposition of model runs into Python objects  providing methods so visualization tools are attached to model runs  and the use of Python's mutable datatypes (lists and dictionaries) to implement the ""run list"" entity  which enables total runtime control of subroutine execution order and content. The result is an interactive modeling environment where the traditional sequence of ""hypothesis â†’ modeling â†’ visualization and analysis"" is opened up and made nonlinear and flexible. In this environment  science tasks such as parameter-space exploration and testing alternative parameterizations can be easily automated  without the need for multiple versions of the model code interacting with a bevy of makefiles and shell scripts. The environment also simplifies interfacing of the atmospheric model to other models (e.g.  hydrologic modelsDeploying Object Oriented Data Technology to the Planetary Data SystemNASA Technical Reports Server (NTRS)Kelly  S.; Crichton  D.; Hughes  J. S.2003-01-01How do you provide more than 350 scientists and researchers access to data from every instrument in Odyssey when the data is curated across half a dozen institutions and in different formats and is too big to mail on a CD-ROM anymore? The Planetary Data System (PDS) faced this exact question. The solution was to use a metadata-based middleware framework developed by the Object Oriented Data Technology task at NASA s Jet Propulsion Laboratory. Using OODT  PDS provided - for the first time ever - data from all mission instruments through a single system immediately upon data delivery.IDL Object Oriented Software for Hinode/XRT Image AnalysisNASA Astrophysics Data System (ADS)Higgins  P. A.; Gallagher  P. T.2008-09-01We have developed a set of object oriented IDL routines that enable users to search  download and analyse images from the X-Ray Telescope (XRT) on-board Hinode. In this paper  we give specific examples of how the object can be used and how multi-instrument data analysis can be performed. The XRT object is a highly versatile and powerful IDL object  which will prove to be a useful tool for solar researchers. This software utilizes the generic Framework object available within the GEN branch of SolarSoft.An object-oriented software for fate and exposure assessments.PubMedScheil  S; Baumgarten  G; Reiter  B; Schwartz  S; Wagner  J O; Trapp  S; Matthies  M1995-07-01The model system CemoS(1) (Chemical Exposure Model System) was developed for the exposure prediction of hazardous chemicals released to the environment. Eight different models were implemented involving chemicals fate simulation in air  water  soil and plants after continuous or single emissions from point and diffuse sources. Scenario studies are supported by a substance and an environmental data base. All input data are checked on their plausibility. Substance and environmental process estimation functions facilitate generic model calculations. CemoS is implemented in a modular structure using object-oriented programming.Spiking network simulation code for petascale computers.PubMedKunkel  Susanne; Schmidt  Maximilian; Eppler  Jochen M; Plesser  Hans E; Masumoto  Gen; Igarashi  Jun; Ishii  Shin; Fukai  Tomoki; Morrison  Abigail; Diesmann  Markus; Helias  Moritz2014-01-01Brain-scale networks exhibit a breathtaking heterogeneity in the dynamical properties and parameters of their constituents. At cellular resolution  the entities of theory are neurons and synapses and over the past decade researchers have learned to manage the heterogeneity of neurons and synapses with efficient data structures. Already early parallel simulation codes stored synapses in a distributed fashion such that a synapse solely consumes memory on the compute node harboring the target neuron. As petaflop computers with some 100 000 nodes become increasingly available for neuroscience  new challenges arise for neuronal network simulation software: Each neuron contacts on the order of 10 000 other neurons and thus has targets only on a fraction of all compute nodes; furthermore  for any given source neuron  at most a single synapse is typically created on any compute node. From the viewpoint of an individual compute node  the heterogeneity in the synaptic target lists thus collapses along two dimensions: the dimension of the types of synapses and the dimension of the number of synapses of a given type. Here we present a data structure taking advantage of this double collapse using metaprogramming techniques. After introducing the relevant scaling scenario for brain-scale simulations  we quantitatively discuss the performance on two supercomputers. We show that the novel architecture scales to the largest petascale supercomputers available today.Spiking network simulation code for petascale computersPubMed CentralKunkel  Susanne; Schmidt  Maximilian; Eppler  Jochen M.; Plesser  Hans E.; Masumoto  Gen; Igarashi  Jun; Ishii  Shin; Fukai  Tomoki; Morrison  Abigail; Diesmann  Markus; Helias  Moritz2014-01-01Brain-scale networks exhibit a breathtaking heterogeneity in the dynamical properties and parameters of their constituents. At cellular resolution  the entities of theory are neurons and synapses and over the past decade researchers have learned to manage the heterogeneity of neurons and synapses with efficient data structures. Already early parallel simulation codes stored synapses in a distributed fashion such that a synapse solely consumes memory on the compute node harboring the target neuron. As petaflop computers with some 100 000 nodes become increasingly available for neuroscience  new challenges arise for neuronal network simulation software: Each neuron contacts on the order of 10 000 other neurons and thus has targets only on a fraction of all compute nodes; furthermore  for any given source neuron  at most a single synapse is typically created on any compute node. From the viewpoint of an individual compute node  the heterogeneity in the synaptic target lists thus collapses along two dimensions: the dimension of the types of synapses and the dimension of the number of synapses of a given type. Here we present a data structure taking advantage of this double collapse using metaprogramming techniques. After introducing the relevant scaling scenario for brain-scale simulations  we quantitatively discuss the performance on two supercomputers. We show that the novel architecture scales to the largest petascale supercomputers available today. PMID:25346682Analog system for computing sparse codesDOEpatentsRozell  Christopher John; Johnson  Don Herrick; Baraniuk  Richard Gordon; Olshausen  Bruno A.; Ortman  Robert Lowell2010-08-24A parallel dynamical system for computing sparse representations of data  i.e.  where the data can be fully represented in terms of a small number of non-zero code elements  and for reconstructing compressively sensed images. The system is based on the principles of thresholding and local competition that solves a family of sparse approximation problems corresponding to various sparsity metrics. The system utilizes Locally Competitive Algorithms (LCAs)  nodes in a population continually compete with neighboring units using (usually one-way) lateral inhibition to calculate coefficients representing an input in an over complete dictionary.An object-oriented framework for medical image registration  fusion  and visualization.PubMedZhu  Yang-Ming; Cochoff  Steven M2006-06-01An object-oriented framework for image registration  fusion  and visualization was developed based on the classic model-view-controller paradigm. The framework employs many design patterns to facilitate legacy code reuse  manage software complexity  and enhance the maintainability and portability of the framework. Three sample applications built a-top of this framework are illustrated to show the effectiveness of this framework: the first one is for volume image grouping and re-sampling  the second one is for 2D registration and fusion  and the last one is for visualization of single images as well as registered volume images.Simple proteomics data analysis in the object-oriented PowerShell.PubMedMohammed  Yassene; Palmblad  Magnus2013-01-01Scripting languages such as Perl and Python are appreciated for solving simple  everyday tasks in bioinformatics. A more recent  object-oriented command shell and scripting language  Windows PowerShell  has many attractive features: an object-oriented interactive command line  fluent navigation and manipulation of XML files  ability to consume Web services from the command line  consistent syntax and grammar  rich regular expressions  and advanced output formatting. The key difference between classical command shells and scripting languages  such as bash  and object-oriented ones  such as PowerShell  is that in the latter the result of a command is a structured object with inherited properties and methods rather than a simple stream of characters. Conveniently  PowerShell is included in all new releases of Microsoft Windows and therefore already installed on most computers in classrooms and teaching labs. In this chapter we demonstrate how PowerShell in particular allows easy interaction with mass spectrometry data in XML formats  connection to Web services for tools such as BLAST  and presentation of results as formatted text or graphics. These features make PowerShell much more than ""yet another scripting language.""Cellular automata with object-oriented features for parallel molecular network modeling.PubMedZhu  Hao; Wu  Yinghui; Huang  Sui; Sun  Yan; Dhar  Pawan2005-06-01Cellular automata are an important modeling paradigm for studying the dynamics of large  parallel systems composed of multiple  interacting components. However  to model biological systems  cellular automata need to be extended beyond the large-scale parallelism and intensive communication in order to capture two fundamental properties characteristic of complex biological systems: hierarchy and heterogeneity. This paper proposes extensions to a cellular automata language  Cellang  to meet this purpose. The extended language  with object-oriented features  can be used to describe the structure and activity of parallel molecular networks within cells. Capabilities of this new programming language include object structure to define molecular programs within a cell  floating-point data type and mathematical functions to perform quantitative computation  message passing capability to describe molecular interactions  as well as new operators  statements  and built-in functions. We discuss relevant programming issues of these features  including the object-oriented description of molecular interactions with molecule encapsulation  message passing  and the description of heterogeneity and anisotropy at the cell and molecule levels. By enabling the integration of modeling at the molecular level with system behavior at cell  tissue  organ  or even organism levels  the program will help improve our understanding of how complex and dynamic biological activities are generated and controlled by parallel functioning of molecular networks. Index Terms-Cellular automata  modeling  molecular network  object-oriented.Using object-oriented analysis techniques to support system testingNASA Astrophysics Data System (ADS)Zucconi  Lin1990-03-01Testing of real-time control systems can be greatly facilitated by use of object-oriented and structured analysis modeling techniques. This report describes a project where behavior  process and information models built for a real-time control system were used to augment and aid traditional system testing. The modeling techniques used were an adaptation of the Ward/Mellor method for real-time systems analysis and design (Ward85) for object-oriented development. The models were used to simulate system behavior by means of hand execution of the behavior or state model and the associated process (data and control flow) and information (data) models. The information model  which uses an extended entity-relationship modeling technique  is used to identify application domain objects and their attributes (instance variables). The behavioral model uses state-transition diagrams to describe the state-dependent behavior of the object. The process model uses a transformation schema to describe the operations performed on or by the object. Together  these models provide a means of analyzing and specifying a system in terms of the static and dynamic properties of the objects which it manipulates. The various models were used to simultaneously capture knowledge about both the objects in the application domain and the system implementation. Models were constructed  verified against the software as-built and validated through informal reviews with the developer. These models were then hand-executed.An object-oriented data reduction system in FortranNASA Technical Reports Server (NTRS)Bailey  J.1992-01-01A data reduction system for the AAO two-degree field project is being developed using an object-oriented approach. Rather than use an object-oriented language (such as C++) the system is written in Fortran and makes extensive use of existing subroutine libraries provided by the UK Starlink project. Objects are created using the extensible N-dimensional Data Format (NDF) which itself is based on the Hierarchical Data System (HDS). The software consists of a class library  with each class corresponding to a Fortran subroutine with a standard calling sequence. The methods of the classes provide operations on NDF objects at a similar level of functionality to the applications of conventional data reduction systems. However  because they are provided as callable subroutines  they can be used as building blocks for more specialist applications. The class library is not dependent on a particular software environment thought it can be used effectively in ADAM applications. It can also be used from standalone Fortran programs. It is intended to develop a graphical user interface for use with the class library to form the 2dF data reduction system.OOM - OBJECT ORIENTATION MANIPULATOR  VERSION 6.1NASA Technical Reports Server (NTRS)Goza  S. P.1994-01-01The Object Orientation Manipulator (OOM) is an application program for creating  rendering  and recording three-dimensional computer-generated still and animated images. This is done using geometrically defined 3D models  cameras  and light sources  referred to collectively as animation elements. OOM does not provide the tools necessary to construct 3D models; instead  it imports binary format model files generated by the Solid Surface Modeler (SSM). Model files stored in other formats must be converted to the SSM binary format before they can be used in OOM. SSM is available as MSC-21914 or as part of the SSM/OOM bundle  COS-10047. Among OOM's features are collision detection (with visual and audio feedback)  the capability to define and manipulate hierarchical relationships between animation elements  stereographic display  and ray-traced rendering. OOM uses Euler angle transformations for calculating the results of translation and rotation operations. OOM provides an interactive environment for the manipulation and animation of models  cameras  and light sources. Models are the basic entity upon which OOM operates and are therefore considered the primary animation elements. Cameras and light sources are considered secondary animation elements. A camera  in OOM  is simply a location within the three-space environment from which the contents of the environment are observed. OOM supports the creation and full animation of cameras. Light sources can be defined  positioned and linked to models  but they cannot be animated independently. OOM can simultaneously accommodate as many animation elements as the host computer's memory permits. Once the required animation elements are present  the user may position them  orient them  and define any initial relationships between them. Once the initial relationships are defined  the user can display individual still views for rendering and output  or define motion for the animation elements by using the Interp Animation EditorAn Object-Oriented Graphical User Interface for a Reusable Rocket Engine Intelligent Control SystemNASA Technical Reports Server (NTRS)Litt  Jonathan S.; Musgrave  Jeffrey L.; Guo  Ten-Huei; Paxson  Daniel E.; Wong  Edmond; Saus  Joseph R.; Merrill  Walter C.1994-01-01An intelligent control system for reusable rocket engines under development at NASA Lewis Research Center requires a graphical user interface to allow observation of the closed-loop system in operation. The simulation testbed consists of a real-time engine simulation computer  a controls computer  and several auxiliary computers for diagnostics and coordination. The system is set up so that the simulation computer could be replaced by the real engine and the change would be transparent to the control system. Because of the hard real-time requirement of the control computer  putting a graphical user interface on it was not an option. Thus  a separate computer used strictly for the graphical user interface was warranted. An object-oriented LISP-based graphical user interface has been developed on a Texas Instruments Explorer 2+ to indicate the condition of the engine to the observer through plots  animation  interactive graphics  and text.Development of probabilistic internal dosimetry computer codeNASA Astrophysics Data System (ADS)Noh  Siwan; Kwon  Tae-Eun; Lee  Jai-Ki2017-02-01Internal radiation dose assessment involves biokinetic models  the corresponding parameters  measured data  and many assumptions. Every component considered in the internal dose assessment has its own uncertainty  which is propagated in the intake activity and internal dose estimates. For research or scientific purposes  and for retrospective dose reconstruction for accident scenarios occurring in workplaces having a large quantity of unsealed radionuclides  such as nuclear power plants  nuclear fuel cycle facilities  and facilities in which nuclear medicine is practiced  a quantitative uncertainty assessment of the internal dose is often required. However  no calculation tools or computer codes that incorporate all the relevant processes and their corresponding uncertainties  i.e.  from the measured data to the committed dose  are available. Thus  the objective of the present study is to develop an integrated probabilistic internal-dose-assessment computer code. First  the uncertainty components in internal dosimetry are identified  and quantitative uncertainty data are collected. Then  an uncertainty database is established for each component. In order to propagate these uncertainties in an internal dose assessment  a probabilistic internal-dose-assessment system that employs the Bayesian and Monte Carlo methods. Based on the developed system  we developed a probabilistic internal-dose-assessment code by using MATLAB so as to estimate the dose distributions from the measured data with uncertainty. Using the developed code  we calculated the internal dose distribution and statistical values ( e.g. the 2.5th  5th  median  95th  and 97.5th percentiles) for three sample scenarios. On the basis of the distributions  we performed a sensitivity analysis to determine the influence of each component on the resulting dose in order to identify the major component of the uncertainty in a bioassay. The results of this study can be applied to various situations. In cases ofTAIR- TRANSONIC AIRFOIL ANALYSIS COMPUTER CODENASA Technical Reports Server (NTRS)Dougherty  F. C.1994-01-01The Transonic Airfoil analysis computer code  TAIR  was developed to employ a fast  fully implicit algorithm to solve the conservative full-potential equation for the steady transonic flow field about an arbitrary airfoil immersed in a subsonic free stream. The full-potential formulation is considered exact under the assumptions of irrotational  isentropic  and inviscid flow. These assumptions are valid for a wide range of practical transonic flows typical of modern aircraft cruise conditions. The primary features of TAIR include: a new fully implicit iteration scheme which is typically many times faster than classical successive line overrelaxation algorithms; a new  reliable artifical density spatial differencing scheme treating the conservative form of the full-potential equation; and a numerical mapping procedure capable of generating curvilinear  body-fitted finite-difference grids about arbitrary airfoil geometries. Three aspects emphasized during the development of the TAIR code were reliability  simplicity  and speed. The reliability of TAIR comes from two sources: the new algorithm employed and the implementation of effective convergence monitoring logic. TAIR achieves ease of use by employing a ""default mode"" that greatly simplifies code operation  especially by inexperienced users  and many useful options including: several airfoil-geometry input options  flexible user controls over program output  and a multiple solution capability. The speed of the TAIR code is attributed to the new algorithm and the manner in which it has been implemented. Input to the TAIR program consists of airfoil coordinates  aerodynamic and flow-field convergence parameters  and geometric and grid convergence parameters. The airfoil coordinates for many airfoil shapes can be generated in TAIR from just a few input parameters. Most of the other input parameters have default values which allow the user to run an analysis in the default mode by specifing only a few input parametersAn Object-Oriented Serial DSMC Simulation PackageNASA Astrophysics Data System (ADS)Liu  Hongli; Cai  Chunpei2011-05-01A newly developed three-dimensional direct simulation Monte Carlo (DSMC) simulation package  named GRASP (""Generalized Rarefied gAs Simulation Package"")  is reported in this paper. This package utilizes the concept of simulation engine  many C++ features and software design patterns. The package has an open architecture which can benefit further development and maintenance of the code. In order to reduce the engineering time for three-dimensional models  a hybrid grid scheme  combined with a flexible data structure compiled by C++ language  are implemented in this package. This scheme utilizes a local data structure based on the computational cell to achieve high performance on workstation processors. This data structure allows the DSMC algorithm to be very efficiently parallelized with domain decomposition and it provides much flexibility in terms of grid types. This package can utilize traditional structured  unstructured or hybrid grids within the framework of a single code to model arbitrarily complex geometries and to simulate rarefied gas flows. Benchmark test cases indicate that this package has satisfactory accuracy for complex rarefied gas flows.40 CFR 194.23 - Models and computer codes.Code of Federal Regulations  2013 CFR2013-07-01... 40 Protection of Environment 26 2013-07-01 2013-07-01 false Models and computer codes. 194.23... General Requirements Â§ 194.23 Models and computer codes. (a) Any compliance application shall include: (1... obtain stable solutions; (iv) Computer models accurately implement the numerical models; i.e.  computer...40 CFR 194.23 - Models and computer codes.Code of Federal Regulations  2012 CFR2012-07-01... 40 Protection of Environment 26 2012-07-01 2011-07-01 true Models and computer codes. 194.23... General Requirements Â§ 194.23 Models and computer codes. (a) Any compliance application shall include: (1... obtain stable solutions; (iv) Computer models accurately implement the numerical models; i.e.  computer...40 CFR 194.23 - Models and computer codes.Code of Federal Regulations  2014 CFR2014-07-01... 40 Protection of Environment 25 2014-07-01 2014-07-01 false Models and computer codes. 194.23... General Requirements Â§ 194.23 Models and computer codes. (a) Any compliance application shall include: (1... obtain stable solutions; (iv) Computer models accurately implement the numerical models; i.e.  computer...40 CFR 194.23 - Models and computer codes.Code of Federal Regulations  2010 CFR2010-07-01... 40 Protection of Environment 24 2010-07-01 2010-07-01 false Models and computer codes. 194.23... General Requirements Â§ 194.23 Models and computer codes. (a) Any compliance application shall include: (1... obtain stable solutions; (iv) Computer models accurately implement the numerical models; i.e.  computer...40 CFR 194.23 - Models and computer codes.Code of Federal Regulations  2011 CFR2011-07-01... 40 Protection of Environment 25 2011-07-01 2011-07-01 false Models and computer codes. 194.23... General Requirements Â§ 194.23 Models and computer codes. (a) Any compliance application shall include: (1... obtain stable solutions; (iv) Computer models accurately implement the numerical models; i.e.  computer...Strategies for teaching object-oriented concepts with JavaNASA Astrophysics Data System (ADS)Sicilia  Miguel-Ãngel2006-03-01A considerable amount of experiences in teaching object-oriented concepts using the Java language have been reported to date  some of which describe language pitfalls and concrete learning difficulties. In this paper  a number of additional issues that have been experienced as difficult for students to master  along with approaches intended to overcome them  are addressed. Concretely  practical issues regarding associations  interfaces  genericity and exceptions are described. These issues suggest that more emphasis is required on presenting Java programs as derivations of conceptual models  in order to guarantee that a thorough design of the object structure actually precedes implementation issues. In addition  common student misunderstandings about the uses of interfaces and exceptions point to the necessity of introducing both specific design philosophies and also a clear distinction between design-for-reuse and more specific implementation issues.Object-oriented design of medical imaging software.PubMedLigier  Y; Ratib  O; Logean  M; Girard  C; Perrier  R; Scherrer  J R1994-01-01A special software package for interactive display and manipulation of medical images was developed at the University Hospital of Geneva  as part of a hospital wide Picture Archiving and Communication System (PACS). This software package  called Osiris  was especially designed to be easily usable and adaptable to the needs of noncomputer-oriented physicians. The Osiris software has been developed to allow the visualization of medical images obtained from any imaging modality. It provides generic manipulation tools  processing tools  and analysis tools more specific to clinical applications. This software  based on an object-oriented paradigm  is portable and extensible. Osiris is available on two different operating systems: the Unix X-11/OSF-Motif based workstations  and the Macintosh family.Object-oriented parsing of biological databases with Python.PubMedRamu  C; GemÃ¼nd  C; Gibson  T J2000-07-01While database activities in the biological area are increasing rapidly  rather little is done in the area of parsing them in a simple and object-oriented way. We present here an elegant  simple yet powerful way of parsing biological flat-file databases. We have taken EMBL  SWISSPROT and GENBANK as examples. EMBL and SWISS-PROT do not differ much in the format structure. GENBANK has a very different format structure than EMBL and SWISS-PROT. Extracting the desired fields in an entry (for example a sub-sequence with an associated feature) for later analysis is a constant need in the biological sequence-analysis community: this is illustrated with tools to make new splice-site databases. The interface to the parser is abstract in the sense that the access to all the databases is independent from their different formats  since parsing instructions are hidden.Building a genome database using an object-oriented approach.PubMedBarbasiewicz  Anna; Liu  Lin; Lang  B Franz; Burger  Gertraud2002-01-01GOBASE is a relational database that integrates data associated with mitochondria and chloroplasts. The most important data in GOBASE  i. e.  molecular sequences and taxonomic information  are obtained from the public sequence data repository at the National Center for Biotechnology Information (NCBI)  and are validated by our experts. Maintaining a curated genomic database comes with a towering labor cost  due to the shear volume of available genomic sequences and the plethora of annotation errors and omissions in records retrieved from public repositories. Here we describe our approach to increase automation of the database population process  thereby reducing manual intervention. As a first step  we used Unified Modeling Language (UML) to construct a list of potential errors. Each case was evaluated independently  and an expert solution was devised  and represented as a diagram. Subsequently  the UML diagrams were used as templates for writing object-oriented automation programs in the Java programming language.Large scale database scrubbing using object oriented software components.PubMedHerting  R L; Barnes  M R1998-01-01Now that case managers  quality improvement teams  and researchers use medical databases extensively  the ability to share and disseminate such databases while maintaining patient confidentiality is paramount. A process called scrubbing addresses this problem by removing personally identifying information while keeping the integrity of the medical information intact. Scrubbing entire databases  containing multiple tables  requires that the implicit relationships between data elements in different tables of the database be maintained. To address this issue we developed DBScrub  a Java program that interfaces with any JDBC compliant database and scrubs the database while maintaining the implicit relationships within it. DBScrub uses a small number of highly configurable object-oriented software components to carry out the scrubbing. We describe the structure of these software components and how they maintain the implicit relationships within the database.An object-oriented mobile health system with usability features.PubMedEscarfullet  Krystle; Moore  Cantera; Tucker  Shari; Wei  June2012-01-01Mobile health (m-health) comprises the concept of utilising mobile devices to carry out the task of viewing electronic medical records  reserving medical appointments with a patient's medical provider and electronically refilling prescriptions. This paper aims at developing a m-health system to improve usability from a user's perspective. Specifically  it first developed a m-health model by logically linking characteristics of the m-health system together based on information flows. Then  the system requirements were collected by using a developed questionnaire. These requirements were structured and further in-depth analysis was conducted by using an object-oriented approach based on unified modelling language  such as use-case  sequence and analysis class diagrams. This research will be beneficial to decision makers and developers in the mobile healthcare industry.SCOS 2: An object oriented software development approachNASA Technical Reports Server (NTRS)Symonds  Martin; Lynenskjold  Steen; Mueller  Christian1994-01-01The Spacecraft Control and Operations System 2 (SCOS 2)  is intended to provide the generic mission control system infrastructure for future ESA missions. It represents a bold step forward in order to take advantage of state-of-the-art technology and current practices in the area of software engineering. Key features include: (1) use of object oriented analysis and design techniques; (2) use of UNIX  C++ and a distributed architecture as the enabling implementation technology; (3) goal of re-use for development  maintenance and mission specific software implementation; and (4) introduction of the concept of a spacecraft control model. This paper touches upon some of the traditional beliefs surrounding Object Oriented development and describes their relevance to SCOS 2. It gives rationale for why particular approaches were adopted and others not  and describes the impact of these decisions. The development approach followed is discussed  highlighting the evolutionary nature of the overall process and the iterative nature of the various tasks carried out. The emphasis of this paper is on the process of the development with the following being covered: (1) the three phases of the SCOS 2 project - prototyping & analysis  design & implementation and configuration / delivery of mission specific systems; (2) the close cooperation and continual interaction with the users during the development; (3) the management approach - the split between client staff  industry and some of the required project management activities; (4) the lifecycle adopted being an enhancement of the ESA PSS-05 standard with SCOS 2 specific activities and approaches defined; and (5) an examination of some of the difficulties encountered and the solutions adopted. Finally  the lessons learned from the SCOS 2 experience are highlighted  identifying those issues to be used as feedback into future developments of this nature. This paper does not intend to describe the finished product and its operationEX6AFS: A data acquisition system for high-speed dispersive EXAFS measurements implemented using object-oriented programming techniquesNASA Astrophysics Data System (ADS)Jennings  Guy; Lee  Peter L.1995-02-01In this paper we describe the design and implementation of a computerized data-acquisition system for high-speed energy-dispersive EXAFS experiments on the X6A beamline at the National Synchrotron Light Source. The acquisition system drives the stepper motors used to move the components of the experimental setup and controls the readout of the EXAFS spectra. The system runs on a Macintosh IIfx computer and is written entirely in the object-oriented language C++. Large segments of the system are implemented by means of commercial class libraries  specifically the MacApp application framework from Apple  the Rogue Wave class library  and the Hierarchical Data Format datafile format library from the National Center for Supercomputing Applications. This reduces the amount of code that must be written and enhances reliability. The system makes use of several advanced features of C++: Multiple inheritance allows the code to be decomposed into independent software components and the use of exception handling allows the system to be much more reliable in the event of unexpected errors. Object-oriented techniques allow the program to be extended easily as new requirements develop. All sections of the program related to a particular concept are located in a small set of source files. The program will also be used as a prototype for future software development plans for the Basic Energy Science Synchrotron Radiation Center Collaborative Access Team beamlines being designed and built at the Advanced Photon Source.ICAN Computer Code Adapted for Building MaterialsNASA Technical Reports Server (NTRS)Murthy  Pappu L. N.1997-01-01The NASA Lewis Research Center has been involved in developing composite micromechanics and macromechanics theories over the last three decades. These activities have resulted in several composite mechanics theories and structural analysis codes whose applications range from material behavior design and analysis to structural component response. One of these computer codes  the Integrated Composite Analyzer (ICAN)  is designed primarily to address issues related to designing polymer matrix composites and predicting their properties - including hygral  thermal  and mechanical load effects. Recently  under a cost-sharing cooperative agreement with a Fortune 500 corporation  Master Builders Inc.  ICAN was adapted to analyze building materials. The high costs and technical difficulties involved with the fabrication of continuous-fiber-reinforced composites sometimes limit their use. Particulate-reinforced composites can be thought of as a viable alternative. They are as easily processed to near-net shape as monolithic materials  yet have the improved stiffness  strength  and fracture toughness that is characteristic of continuous-fiber-reinforced composites. For example  particlereinforced metal-matrix composites show great potential for a variety of automotive applications  such as disk brake rotors  connecting rods  cylinder liners  and other hightemperature applications. Building materials  such as concrete  can be thought of as one of the oldest materials in this category of multiphase  particle-reinforced materials. The adaptation of ICAN to analyze particle-reinforced composite materials involved the development of new micromechanics-based theories. A derivative of the ICAN code  ICAN/PART  was developed and delivered to Master Builders Inc. as a part of the cooperative activity.A surface code quantum computer in siliconPubMed CentralHill  Charles D.; Peretz  Eldad; Hile  Samuel J.; House  Matthew G.; Fuechsle  Martin; Rogge  Sven; Simmons  Michelle Y.; Hollenberg  Lloyd C. L.2015-01-01The exceptionally long quantum coherence times of phosphorus donor nuclear spin qubits in silicon  coupled with the proven scalability of silicon-based nano-electronics  make them attractive candidates for large-scale quantum computing. However  the high threshold of topological quantum error correction can only be captured in a two-dimensional array of qubits operating synchronously and in parallelâ€”posing formidable fabrication and control challenges. We present an architecture that addresses these problems through a novel shared-control paradigm that is particularly suited to the natural uniformity of the phosphorus donor nuclear spin qubit states and electronic confinement. The architecture comprises a two-dimensional lattice of donor qubits sandwiched between two vertically separated control layers forming a mutually perpendicular crisscross gate array. Shared-control lines facilitate loading/unloading of single electrons to specific donors  thereby activating multiple qubits in parallel across the array on which the required operations for surface code quantum error correction are carried out by global spin control. The complexities of independent qubit control  wave function engineering  and ad hoc quantum interconnects are explicitly avoided. With many of the basic elements of fabrication and control based on demonstrated techniques and with simulated quantum operation below the surface code error threshold  the architecture represents a new pathway for large-scale quantum information processing in silicon and potentially in other qubit systems where uniformity can be exploited. PMID:26601310A surface code quantum computer in silicon.PubMedHill  Charles D; Peretz  Eldad; Hile  Samuel J; House  Matthew G; Fuechsle  Martin; Rogge  Sven; Simmons  Michelle Y; Hollenberg  Lloyd C L2015-10-01The exceptionally long quantum coherence times of phosphorus donor nuclear spin qubits in silicon  coupled with the proven scalability of silicon-based nano-electronics  make them attractive candidates for large-scale quantum computing. However  the high threshold of topological quantum error correction can only be captured in a two-dimensional array of qubits operating synchronously and in parallel-posing formidable fabrication and control challenges. We present an architecture that addresses these problems through a novel shared-control paradigm that is particularly suited to the natural uniformity of the phosphorus donor nuclear spin qubit states and electronic confinement. The architecture comprises a two-dimensional lattice of donor qubits sandwiched between two vertically separated control layers forming a mutually perpendicular crisscross gate array. Shared-control lines facilitate loading/unloading of single electrons to specific donors  thereby activating multiple qubits in parallel across the array on which the required operations for surface code quantum error correction are carried out by global spin control. The complexities of independent qubit control  wave function engineering  and ad hoc quantum interconnects are explicitly avoided. With many of the basic elements of fabrication and control based on demonstrated techniques and with simulated quantum operation below the surface code error threshold  the architecture represents a new pathway for large-scale quantum information processing in silicon and potentially in other qubit systems where uniformity can be exploited.Object oriented fault diagnosis system for space shuttle main engine redlinesNASA Technical Reports Server (NTRS)Rogers  John S.; Mohapatra  Saroj Kumar1990-01-01A great deal of attention has recently been given to Artificial Intelligence research in the area of computer aided diagnostics. Due to the dynamic and complex nature of space shuttle red-line parameters  a research effort is under way to develop a real time diagnostic tool that will employ historical and engineering rulebases as well as a sensor validity checking. The capability of AI software development tools (KEE and G2) will be explored by applying object oriented programming techniques in accomplishing the diagnostic evaluation.Code for Multiblock CFD and Heat-Transfer ComputationsNASA Technical Reports Server (NTRS)Fabian  John C.; Heidmann  James D.; Lucci  Barbara L.; Ameri  Ali A.; Rigby  David L.; Steinthorsson  Erlendur2006-01-01The NASA Glenn Research Center General Multi-Block Navier-Stokes Convective Heat Transfer Code  Glenn-HT  has been used extensively to predict heat transfer and fluid flow for a variety of steady gas turbine engine problems. Recently  the Glenn-HT code has been completely rewritten in Fortran 90/95  a more object-oriented language that allows programmers to create code that is more modular and makes more efficient use of data structures. The new implementation takes full advantage of the capabilities of the Fortran 90/95 programming language. As a result  the Glenn-HT code now provides dynamic memory allocation  modular design  and unsteady flow capability. This allows for the heat-transfer analysis of a full turbine stage. The code has been demonstrated for an unsteady inflow condition  and gridding efforts have been initiated for a full turbine stage unsteady calculation. This analysis will be the first to simultaneously include the effects of rotation  blade interaction  film cooling  and tip clearance with recessed tip on turbine heat transfer and cooling performance. Future plans call for the application of the new Glenn-HT code to a range of gas turbine engine problems of current interest to the heat-transfer community. The new unsteady flow capability will allow researchers to predict the effect of unsteady flow phenomena upon the convective heat transfer of turbine blades and vanes. Work will also continue on the development of conjugate heat-transfer capability in the code  where simultaneous solution of convective and conductive heat-transfer domains is accomplished. Finally  advanced turbulence and fluid flow models and automatic gridding techniques are being developed that will be applied to the Glenn-HT code and solution process.Theoretical Value Belief  Cognitive Ability  and Personality as Predictors of Student Performance in Object-Oriented Programming EnvironmentsERIC Educational Resources Information CenterHall  Dianne J.; Cegielski  Casey G.; Wade  James N.2006-01-01The research described in this article reports the results of a study designed to evaluate the relationship among object-oriented (OO) computer programming task performance and a student's (1) theoretical value belief  (2) cognitive ability  and (3) personality. The results of this study do not support the assertion that cognitive ability is aâ€¦A Cognitive Model of How Interactive Multimedia Authoring Facilitates Conceptual Understanding of Object-Oriented Programming in NovicesERIC Educational Resources Information CenterYuen  Timothy; Liu  Min2011-01-01This paper presents a cognitive model of how interactive multimedia authoring (IMA) affect novices' cognition in object-oriented programming. This model was generated through an empirical study of first year computer science students at the university level being engaged in interactive multimedia authoring of a role-playing game. Clinicalâ€¦PWL 1.0 Personal WaveLab: an object-oriented workbench for seismogram analysis on Windows systemsNASA Astrophysics Data System (ADS)Bono  Andrea; Badiali  Lucio2005-02-01Personal WaveLab 1.0 wants to be the starting point for an ex novo development of seismic time-series analysis procedures for Windows-based personal computers. Our objective is two-fold. Firstly  being itself a stand-alone application  it allows to do ""basic"" digital or digitised seismic waveform analysis. Secondly  thanks to its architectural characteristics it can be the basis for the development of more complex and power featured applications. An expanded version of PWL  called SisPick!  is currently in use at the Istituto Nazionale di Geofisica e Vulcanologia (Italian Institute of Geophysics and Volcanology) for real-time monitoring with purposes of Civil Protection. This means that about 90 users tested the application for more than 1 year  making its features more robust and efficient. SisPick! was also employed in the United Nations Nyragongo Project  in Congo  and during the Stromboli emergency in summer of 2002. The main appeals of the application package are: ease of use  object-oriented design  good computational speed  minimal need of disk space and the complete absence of third-party developed components (including ActiveX). Windows environment spares the user scripting or complex interaction with the system. The system is in constant development to answer the needs and suggestions of its users. Microsoft Visual Basic 6 source code  installation package  test data sets and documentation are available at no cost.Dakota  a multilevel parallel object-oriented framework for design optimization  parameter estimation  uncertainty quantification  and sensitivity analysis :SciTech ConnectAdams  Brian M.; Ebeida  Mohamed Salah; Eldred  Michael S.The Dakota (Design Analysis Kit for Optimization and Terascale Applications) toolkit provides a exible and extensible interface between simulation codes and iterative analysis methods. Dakota contains algorithms for optimization with gradient and nongradient-based methods; uncertainty quanti cation with sampling  reliability  and stochastic expansion methods; parameter estimation with nonlinear least squares methods; and sensitivity/variance analysis with design of experiments and parameter study methods. These capabilities may be used on their own or as components within advanced strategies such as surrogate-based optimization  mixed integer nonlinear programming  or optimization under uncertainty. By employing object-oriented design to implement abstractions of the key components requiredmoreÂ Â» for iterative systems analyses  the Dakota toolkit provides a exible and extensible problem-solving environment for design and performance analysis of computational models on high performance computers. This report serves as a user's manual for the Dakota software and provides capability overviews and procedures for software execution  as well as a variety of example studies.Â«Â lessPractical experience with graphical user interfaces and object-oriented design in the clinical laboratory.PubMedWells  I G; Cartwright  R Y; Farnan  L P1993-12-15The computing strategy in our laboratories evolved from research in Artificial Intelligence  and is based on powerful software tools running on high performance desktop computers with a graphical user interface. This allows most tasks to be regarded as design problems rather than implementation projects  and both rapid prototyping and an object-oriented approach to be employed during the in-house development and enhancement of the laboratory information systems. The practical application of this strategy is discussed  with particular reference to the system designer  the laboratory user and the laboratory customer. Routine operation covers five departments  and the systems are stable  flexible and well accepted by the users. Client-server computing  currently undergoing final trials  is seen as the key to further development  and this approach to Pathology computing has considerable potential for the future.User Instructions for the Systems Assessment Capability  Rev. 1  Computer Codes Volume 3: Utility CodesSciTech ConnectEslinger  Paul W.; Aaberg  Rosanne L.; Lopresti  Charles A.2004-09-14This document contains detailed user instructions for a suite of utility codes developed for Rev. 1 of the Systems Assessment Capability. The suite of computer codes for Rev. 1 of Systems Assessment Capability performs many functions.VIMOS Instrument Control Software Design: an Object Oriented ApproachNASA Astrophysics Data System (ADS)Brau-NoguÃ©  Sylvie; Lucuix  Christian2002-12-01The Franco-Italian VIMOS instrument is a VIsible imaging Multi-Object Spectrograph with outstanding multiplex capabilities  allowing to take spectra of more than 800 objects simultaneously  or integral field spectroscopy mode in a 54x54 arcsec area. VIMOS is being installed at the Nasmyth focus of the third Unit Telescope of the European Southern Observatory Very Large Telescope (VLT) at Mount Paranal in Chile. This paper will describe the analysis  the design and the implementation of the VIMOS Instrument Control System  using UML notation. Our Control group followed an Object Oriented software process while keeping in mind the ESO VLT standard control concepts. At ESO VLT a complete software library is available. Rather than applying waterfall lifecycle  ICS project used iterative development  a lifecycle consisting of several iterations. Each iteration consisted in : capture and evaluate the requirements  visual modeling for analysis and design  implementation  test  and deployment. Depending of the project phases  iterations focused more or less on specific activity. The result is an object model (the design model)  including use-case realizations. An implementation view and a deployment view complement this product. An extract of VIMOS ICS UML model will be presented and some implementation  integration and test issues will be discussed.Object-oriented data model of the municipal transportationNASA Astrophysics Data System (ADS)Pan  Yuqing; Sheng  Yehua; Zhang  Guiying2008-10-01The transportation problem is always one of main questions each big city all over the world faces. Managing the municipal transportation using GIS is becoming the important trend. And the data model is the transportation information system foundation. The organization and storage of the data must consider well in the system design. The data model not only needs to meet the demand that the transportation navigates  but also needs to achieve the good visual effects  also can carry on the management and the maintenance to the traffic information. According to the object-oriented theory and the method  the road is divided into segment  intersection. This paper analyzed the driveway  marking  sign and other transportation facilities and the relationship with the segment  intersection and constructed the municipal transportation data model which is adequate to the demand of vehicles navigation  visual and management. The paper also schemes the the all kinds of transportation data. The practice proves that this data model can satisfy the application demands of traffic management system.RF control at SSCL â€” an object oriented design approachNASA Astrophysics Data System (ADS)Dohan  D. A.; Osberg  E.; Biggs  R.; Bossom  J.; Chillara  K.; Richter  R.; Wade  D.1994-12-01The Superconducting Super Collider (SSC) in Texas  the construction of which was stopped in 1994  would have represented a major challenge in accelerator research and development. This paper addresses the issues encountered in the parallel design and construction of the control systems for the RF equipment for the five accelerators comprising the SSC. An extensive analysis of the components of the RF control systems has been undertaken  based upon the Schlaer-Mellor object-oriented analysis and design (OOA/OOD) methodology. The RF subsystem components such as amplifiers  tubes  power supplies  PID loops  etc. were analyzed to produce OOA information  behavior and process models. Using these models  OOD was iteratively applied to develop a generic RF control system design. This paper describes the results of this analysis and the development of 'bridges' between the analysis objects  and the EPICS-based software and underlying VME-based hardware architectures. The application of this approach to several of the SSCL RF control systems is discussed.Field Model: An Object-Oriented Data Model for FieldsNASA Technical Reports Server (NTRS)Moran  Patrick J.2001-01-01We present an extensible  object-oriented data model designed for field data entitled Field Model (FM). FM objects can represent a wide variety of fields  including fields of arbitrary dimension and node type. FM can also handle time-series data. FM achieves generality through carefully selected topological primitives and through an implementation that leverages the potential of templated C++. FM supports fields where the nodes values are paired with any cell type. Thus FM can represent data where the field nodes are paired with the vertices (""vertex-centered"" data)  fields where the nodes are paired with the D-dimensional cells in R(sup D) (often called ""cell-centered"" data)  as well as fields where nodes are paired with edges or other cell types. FM is designed to effectively handle very large data sets; in particular FM employs a demand-driven evaluation strategy that works especially well with large field data. Finally  the interfaces developed for FM have the potential to effectively abstract field data based on adaptive meshes. We present initial results with a triangular adaptive grid in R(sup 2) and discuss how the same design abstractions would work equally well with other adaptive-grid variations  including meshes in R(sup 3).An object-oriented class library for medical software development.PubMedO'Kane  K C; McColligan  E E1996-12-01The objective of this research is the development of a Medical Object Library (MOL) consisting of reusable  inheritable  portable  extendable C++ classes that facilitate rapid development of medical software at reduced cost and increased functionality. The result of this research is a library of class objects that range in function from string and hierarchical file handling entities to high level  procedural agents that perform increasingly complex  integrated tasks. A system built upon these classes is compatible with any other system similarly constructed with respect to data definitions  semantics  data organization and storage. As new objects are built  they can be added to the class library for subsequent use. The MOL is a toolkit of software objects intended to support a common file access methodology  a unified medical record structure  consistent message processing  standard graphical display facilities and uniform data collection procedures. This work emphasizes the relationship that potentially exists between the structure of a hierarchical medical record and procedural language components by means of a hierarchical class library and tree structured file access facility. In doing so  it attempts to establish interest in and demonstrate the practicality of the hierarchical medical record model in the modern context of object oriented programming.Framework for Development of Object-Oriented SoftwareNASA Technical Reports Server (NTRS)Perez-Poveda  Gus; Ciavarella  Tony; Nieten  Dan2004-01-01The Real-Time Control (RTC) Application Framework is a high-level software framework written in C++ that supports the rapid design and implementation of object-oriented application programs. This framework provides built-in functionality that solves common software development problems within distributed client-server  multi-threaded  and embedded programming environments. When using the RTC Framework to develop software for a specific domain  designers and implementers can focus entirely on the details of the domain-specific software rather than on creating custom solutions  utilities  and frameworks for the complexities of the programming environment. The RTC Framework was originally developed as part of a Space Shuttle Launch Processing System (LPS) replacement project called Checkout and Launch Control System (CLCS). As a result of the framework s development  CLCS software development time was reduced by 66 percent. The framework is generic enough for developing applications outside of the launch-processing system domain. Other applicable high-level domains include command and control systems and simulation/ training systems.About turn: how object orientation affects categorisation and mental rotation.PubMedMilivojevic  Branka; Hamm  Jeff P; Corballis  Michael C2011-11-01High-density ERPs evoked by rotated alphanumeric characters were examined to determine how neural processing is affected by stimulus orientation during letter/digit classifications and during mirror/normal discriminations. The former task typically produces response times that are unaffected by stimulus orientation while the latter is thought to require mental rotation. Sensitivity to orientation was first observed around 100-140 ms and this effect was attributed to differences in low-level features between vertical and oblique orientations. Subsequently  character misorientation amplified the N170  a neural marker of object classification  between 160 and 220 ms. Top-down processing is reflected in the ERPs beginning at 280-320 ms and this time range may reflect binding of ventral and dorsal stream information. In the case of mirror-normal discrimination these top-down processes can lead to mental rotation between 340 and 700 ms. Therefore  although neural processing reflects object orientation  these effects do not translate into increases in reaction-times or impaired accuracy for categorisation  and precede those that do in the mental-rotation task. Copyright Ã‚Â© 2011 Elsevier Ltd. All rights reserved.An Object-Oriented Approach for Analyzing CALIPSO's Profile ObservationsNASA Astrophysics Data System (ADS)Trepte  C. R.2016-12-01The CALIPSO satellite mission is a pioneering international partnership between NASA and the French Space Agency  CNES. Since launch on 28 April 2006  CALIPSO has been acquiring near-continuous lidar profile observations of clouds and aerosols in the Earth's atmosphere. Many studies have profitably used these observations to advance our understanding of climate  weather and air quality. For the most part  however  these studies have considered CALIPSO profile measurements independent from one another and have not related each to neighboring or family observations within a cloud element or aerosol feature. In this presentation we describe an alternative approach that groups measurements into objects visually identified from CALIPSO browse images. The approach makes use of the Visualization of CALIPSO (VOCAL) software tool that enables a user to outline a region of interest and save coordinates into a database. The selected features or objects can then be analyzed to explore spatial correlations over the feature's domain and construct bulk statistical properties for each structure. This presentation will show examples that examine cirrus and dust layers and will describe how this object-oriented approach can provide added insight into physical processes beyond conventional statistical treatments. It will further show results with combined measurements from other A-Train sensors to highlight advantages of viewing features in this manner.Adapting current Arden Syntax knowledge for an object oriented event monitor.PubMedChoi  Jeeyae; Lussier  Yves A; MendoÃ§a  Eneida A2003-01-01Arden Syntax for Medical Logic Module (MLM)1 was designed for writing and sharing task-specific health knowledge in 1989. Several researchers have developed frameworks to improve the sharability and adaptability of Arden Syntax MLMs  an issue known as ""curly braces"" problem. Karadimas et al proposed an Arden Syntax MLM-based decision support system that uses an object oriented model and the dynamic linking features of the Java platform.2 Peleg et al proposed creating a Guideline Expression Language (GEL) based on Arden Syntax's logic grammar.3 The New York Presbyterian Hospital (NYPH) has a collection of about 200 MLMs. In a process of adapting the current MLMs for an object-oriented event monitor  we identified two problems that may influence the ""curly braces"" one: (1) the query expressions within the curly braces of Arden Syntax used in our institution are cryptic to the physicians  institutional dependent and written ineffectively (unpublished results)  and (2) the events are coded individually within a curly braces  resulting sometimes in a large number of events - up to 200.An Object-Oriented Finite Element Framework for Multiphysics Phase Field SimulationsSciTech ConnectMichael R Tonks; Derek R Gaston; Paul C Millett2012-01-01The phase field approach is a powerful and popular method for modeling microstructure evolution. In this work  advanced numerical tools are used to create a phase field framework that facilitates rapid model development. This framework  called MARMOT  is based on Idaho National Laboratory's finite element Multiphysics Object-Oriented Simulation Environment. In MARMOT  the system of phase field partial differential equations (PDEs) are solved simultaneously with PDEs describing additional physics  such as solid mechanics and heat conduction  using the Jacobian-Free Newton Krylov Method. An object-oriented architecture is created by taking advantage of commonalities in phase fields models to facilitate development of newmoreÂ Â» models with very little written code. In addition  MARMOT provides access to mesh and time step adaptivity  reducing the cost for performing simulations with large disparities in both spatial and temporal scales. In this work  phase separation simulations are used to show the numerical performance of MARMOT. Deformation-induced grain growth and void growth simulations are included to demonstrate the muliphysics capability.Â«Â lessThe Implementation of Satellite Attitude Control System Software Using Object Oriented DesignNASA Technical Reports Server (NTRS)Reid  W. Mark; Hansell  William; Phillips  Tom; Anderson  Mark O.; Drury  Derek1998-01-01NASA established the Small Explorer (SNMX) program in 1988 to provide frequent opportunities for highly focused and relatively inexpensive space science missions. The SMEX program has produced five satellites  three of which have been successfully launched. The remaining two spacecraft are scheduled for launch within the coming year. NASA has recently developed a prototype for the next generation Small Explorer spacecraft (SMEX-Lite). This paper describes the object-oriented design (OOD) of the SMEX-Lite Attitude Control System (ACS) software. The SMEX-Lite ACS is three-axis controlled and is capable of performing sub-arc-minute pointing. This paper first describes high level requirements governing the SMEX-Lite ACS software architecture. Next  the context in which the software resides is explained. The paper describes the principles of encapsulation  inheritance  and polymorphism with respect to the implementation of an ACS software system. This paper will also discuss the design of several ACS software components. Specifically  object-oriented designs are presented for sensor data processing  attitude determination  attitude control  and failure detection. Finally  this paper will address the establishment of the ACS Foundation Class (AFC) Library. The AFC is a large software repository  requiring a minimal amount of code modifications to produce ACS software for future projects.The Visual Representation of 3D Object Orientation in Parietal CortexPubMed CentralCowan  Noah J.; Angelaki  Dora E.2013-01-01An accurate representation of three-dimensional (3D) object orientation is essential for interacting with the environment. Where and how the brain visually encodes 3D object orientation remains unknown  but prior studies suggest the caudal intraparietal area (CIP) may be involved. Here  we develop rigorous analytical methods for quantifying 3D orientation tuning curves  and use these tools to the study the neural coding of surface orientation. Specifically  we show that single neurons in area CIP of the rhesus macaque jointly encode the slant and tilt of a planar surface  and that across the population  the distribution of preferred slant-tilts is not statistically different from uniform. This suggests that all slant-tilt combinations are equally represented in area CIP. Furthermore  some CIP neurons are found to also represent the third rotational degree of freedom that determines the orientation of the image pattern on the planar surface. Together  the present results suggest that CIP is a critical neural locus for the encoding of all three rotational degrees of freedom specifying an object's 3D spatial orientation. PMID:24305830Visualization: a tool for enhancing students' concept images of basic object-oriented conceptsNASA Astrophysics Data System (ADS)Cetin  Ibrahim2013-03-01The purpose of this study was twofold: to investigate students' concept images about class  object  and their relationship and to help them enhance their learning of these notions with a visualization tool. Fifty-six second-year university students participated in the study. To investigate his/her concept images  the researcher developed a survey including open-ended questions  which was administered to the participants. Follow-up interviews with 12 randomly selected students were conducted to explore their answers to the survey in depth. The results of the first part of the research were utilized to construct visualization scenarios. The students used these scenarios to develop animations using Flash software. The study found that most of the students experienced difficulties in learning object-oriented notions. Overdependence on code-writing practice and examples and incorrectly learned analogies were determined to be the sources of their difficulties. Moreover  visualization was found to be a promising approach in facilitating students' concept images of basic object-oriented notions. The results of this study have implications for researchers and practitioners when designing programming instruction.Frequent Statement and Dereference Elimination for Imperative and Object-Oriented Distributed ProgramsPubMed CentralEl-Zawawy  Mohamed A.2014-01-01This paper introduces new approaches for the analysis of frequent statement and dereference elimination for imperative and object-oriented distributed programs running on parallel machines equipped with hierarchical memories. The paper uses languages whose address spaces are globally partitioned. Distributed programs allow defining data layout and threads writing to and reading from other thread memories. Three type systems (for imperative distributed programs) are the tools of the proposed techniques. The first type system defines for every program point a set of calculated (ready) statements and memory accesses. The second type system uses an enriched version of types of the first type system and determines which of the ready statements and memory accesses are used later in the program. The third type system uses the information gather so far to eliminate unnecessary statement computations and memory accesses (the analysis of frequent statement and dereference elimination). Extensions to these type systems are also presented to cover object-oriented distributed programs. Two advantages of our work over related work are the following. The hierarchical style of concurrent parallel computers is similar to the memory model used in this paper. In our approach  each analysis result is assigned a type derivation (serves as a correctness proof). PMID:24892098Description and status update on GELLO: a proposed standardized object-oriented expression language for clinical decision support.PubMedSordo  Margarita; Boxwala  Aziz A; Ogunyemi  Omolola; Greenes  Robert A2004-01-01A major obstacle to sharing computable clinical knowledge is the lack of a common language for specifying expressions and criteria. Such a language could be used to specify decision criteria  formulae  and constraints on data and action. Al-though the Arden Syntax addresses this problem for clinical rules  its generalization to HL7's object-oriented data model is limited. The GELLO Expression language is an object-oriented language used for expressing logical conditions and computations in the GLIF3 (GuideLine Interchange Format  v. 3) guideline modeling language. It has been further developed under the auspices of the HL7 Clinical Decision Support Technical Committee  as a proposed HL7 standard.  GELLO is based on the Object Constraint Language (OCL)  because it is vendor-independent  object-oriented  and side-effect-free. GELLO expects an object-oriented data model. Although choice of model is arbitrary  standardization is facilitated by ensuring that the data model is compatible with the HL7 Reference Information Model (RIM).Analyzing and designing object-oriented missile simulations with concurrencyNASA Astrophysics Data System (ADS)Randorf  Jeffrey Allen2000-11-01A software object model for the six degree-of-freedom missile modeling domain is presented. As a precursor  a domain analysis of the missile modeling domain was started  based on the Feature-Oriented Domain Analysis (FODA) technique described by the Software Engineering Institute (SEI). It was subsequently determined the FODA methodology is functionally equivalent to the Object Modeling Technique. The analysis used legacy software documentation and code from the ENDOSIM  KDEC  and TFrames 6-DOF modeling tools  including other technical literature. The SEI Object Connection Architecture (OCA) was the template for designing the object model. Three variants of the OCA were considered---a reference structure  a recursive structure  and a reference structure with augmentation for flight vehicle modeling. The reference OCA design option was chosen for maintaining simplicity while not compromising the expressive power of the OMT model. The missile architecture was then analyzed for potential areas of concurrent computing. It was shown how protected objects could be used for data passing between OCA object managers  allowing concurrent access without changing the OCA reference design intent or structure. The implementation language was the 1995 release of Ada. OCA software components were shown how to be expressed as Ada child packages. While acceleration of several low level and other high operations level are possible on proper hardware  there was a 33% degradation of 4th order Runge-Kutta integrator performance of two simultaneous ordinary differential equations using Ada tasking on a single processor machine. The Defense Department's High Level Architecture was introduced and explained in context with the OCA. It was shown the HLA and OCA were not mutually exclusive architectures  but complimentary. HLA was shown as an interoperability solution  with the OCA as an architectural vehicle for software reuse. Further directions for implementing a 6-DOF missile modelingHandling Emergency Management in [an] Object Oriented Modeling EnvironmentNASA Technical Reports Server (NTRS)Tokgoz  Berna Eren; Cakir  Volkan; Gheorghe  Adrian V.2010-01-01It has been understood that protection of a nation from extreme disasters is a challenging task. Impacts of extreme disasters on a nation's critical infrastructures  economy and society could be devastating. A protection plan itself would not be sufficient when a disaster strikes. Hence  there is a need for a holistic approach to establish more resilient infrastructures to withstand extreme disasters. A resilient infrastructure can be defined as a system or facility that is able to withstand damage  but if affected  can be readily and cost-effectively restored. The key issue to establish resilient infrastructures is to incorporate existing protection plans with comprehensive preparedness actions to respond  recover and restore as quickly as possible  and to minimize extreme disaster impacts. Although national organizations will respond to a disaster  extreme disasters need to be handled mostly by local emergency management departments. Since emergency management departments have to deal with complex systems  they have to have a manageable plan and efficient organizational structures to coordinate all these systems. A strong organizational structure is the key in responding fast before and during disasters  and recovering quickly after disasters. In this study  the entire emergency management is viewed as an enterprise and modelled through enterprise management approach. Managing an enterprise or a large complex system is a very challenging task. It is critical for an enterprise to respond to challenges in a timely manner with quick decision making. This study addresses the problem of handling emergency management at regional level in an object oriented modelling environment developed by use of TopEase software. Emergency Operation Plan of the City of Hampton  Virginia  has been incorporated into TopEase for analysis. The methodology used in this study has been supported by a case study on critical infrastructure resiliency in Hampton Roads.Object-Oriented Image Clustering Method Using UAS Photogrammetric ImageryNASA Astrophysics Data System (ADS)Lin  Y.; Larson  A.; Schultz-Fellenz  E. S.; Sussman  A. J.; Swanson  E.; Coppersmith  R.2016-12-01Unmanned Aerial Systems (UAS) have been used widely as an imaging modality to obtain remotely sensed multi-band surface imagery  and are growing in popularity due to their efficiency  ease of use  and affordability. Los Alamos National Laboratory (LANL) has employed the use of UAS for geologic site characterization and change detection studies at a variety of field sites. The deployed UAS equipped with a standard visible band camera to collect imagery datasets. Based on the imagery collected  we use deep sparse algorithmic processing to detect and discriminate subtle topographic features created or impacted by subsurface activities. In this work  we develop an object-oriented remote sensing imagery clustering method for land cover classification. To improve the clustering and segmentation accuracy  instead of using conventional pixel-based clustering methods  we integrate the spatial information from neighboring regions to create super-pixels to avoid salt-and-pepper noise and subsequent over-segmentation. To further improve robustness of our clustering method  we also incorporate a custom digital elevation model (DEM) dataset generated using a structure-from-motion (SfM) algorithm together with the red  green  and blue (RGB) band data for clustering. In particular  we first employ an agglomerative clustering to create an initial segmentation map  from where every object is treated as a single (new) pixel. Based on the new pixels obtained  we generate new features to implement another level of clustering. We employ our clustering method to the RGB+DEM datasets collected at the field site. Through binary clustering and multi-object clustering tests  we verify that our method can accurately separate vegetation from non-vegetation regions  and are also able to differentiate object features on the surface.Object-oriented microcomputer software for earthquake seismologySciTech ConnectKroeger  G.C.1993-02-01A suite of graphically interactive applications for the retrieval  editing and modeling of earthquake seismograms have been developed using object-orientation programming methodology and the C++ language. Retriever is an application which allows the user to search for  browse  and extract seismic data from CD-ROMs produced by the National Earthquake Information Center (NEIC). The user can restrict the date  size  location and depth of desired earthquakes and extract selected data into a variety of common seismic file formats. Reformer is an application that allows the user to edit seismic data and data headers  and perform a variety of signal processing operationsmoreÂ Â» on that data. Synthesizer is a program for the generation and analysis of teleseismic P and SH synthetic seismograms. The program provides graphical manipulation of source parameters  crustal structures and seismograms  as well as near real-time response in generating synthetics for arbitrary flat-layered crustal structures. All three applications use class libraries developed for implementing geologic and seismic objects and views. Standard seismogram view objects and objects that encapsulate the reading and writing of different seismic data file formats are shared by all three applications. The focal mechanism views in Synthesizer are based on a generic stereonet view object. Interaction with the native graphical user interface is encapsulated in a class library in order to simplify the porting of the software to different operating systems and application programming interfaces. The software was developed on the Apple Macintosh and is being ported to UNIX/X-Window platforms.Â«Â lessThe first object oriented monitor for intravenous anesthesia.PubMedCantraine  F R; Coussaert  E J2000-01-01To describe the design and implementation of ""INFUSION TOOLBOX "" a software tool to control and monitor multiple intravenous drug infusions simultaneously using pharmacokinetic and pharmacodynamic principles. INFUSION TOOLBOX has been designed to present a graphical interface. Object Oriented design was used and the software was implemented using Smalltalk  to run on a PC. Basic tools are available to manage patient  drugs  pumps and reports. These tools are the PatientPanel  the DrugPanel  the PumpPanel and the HistoryPanel. The screen is built dynamically. The panels may be collapsed or closed to avoid a crowded display. We also built control panels such as the Target ControlPanel which calculates the best infusion sequence to bring the drug concentration in the plasma compartment to a preset value. Before drug delivery  the user enters the patient's data  selects a drug  enters its dilution factor and chooses a pharmacokinetic model. The calculated plasma concentration is continually displayed and updated. The anesthetist may ask for the history of the delivery to obtain a graphic report or to add events to the logbook. A panel targeting the effect is used when a pharmacodynamic model is known. Data files for drugs  pumps and surgery are upgradable. By creating a resizeable ControlPanel we enable the anesthetist to display the information he wishes  when he wishes it. The available panels are diverse enough to meet the anesthetist needs; they may be adapted to the drug used  pumps used and surgery. It is the anesthetist who builds dynamically its different control screens. By adopting an evolutionary solution model we have achieved considerable success in building our drug delivery monitor. In addition we have gained valuable insight into the anesthesia information domain that will allow us to further enhance and expand the system.Object-oriented classification of drumlins from digital elevation modelsNASA Astrophysics Data System (ADS)Saha  KakoliDrumlins are common elements of glaciated landscapes which are easily identified by their distinct morphometric characteristics including shape  length/width ratio  elongation ratio  and uniform direction. To date  most researchers have mapped drumlins by tracing contours on maps  or through on-screen digitization directly on top of hillshaded digital elevation models (DEMs). This paper seeks to utilize the unique morphometric characteristics of drumlins and investigates automated extraction of the landforms as objects from DEMs by Definiens Developer software (V.7)  using the 30 m United States Geological Survey National Elevation Dataset DEM as input. The Chautauqua drumlin field in Pennsylvania and upstate New York  USA was chosen as a study area. As the study area is huge (approximately covers 2500 sq.km. of area)  small test areas were selected for initial testing of the method. Individual polygons representing the drumlins were extracted from the elevation data set by automated recognition  using Definiens' Multiresolution Segmentation tool  followed by rule-based classification. Subsequently parameters such as length  width and length-width ratio  perimeter and area were measured automatically. To test the accuracy of the method  a second base map was produced by manual on-screen digitization of drumlins from topographic maps and the same morphometric parameters were extracted from the mapped landforms using Definiens Developer. Statistical comparison showed a high agreement between the two methods confirming that object-oriented classification for extraction of drumlins can be used for mapping these landforms. The proposed method represents an attempt to solve the problem by providing a generalized rule-set for mass extraction of drumlins. To check that the automated extraction process was next applied to a larger area. Results showed that the proposed method is as successful for the bigger area as it was for the smaller test areas.GenASiS Basics: Object-oriented utilitarian functionality for large-scale physics simulationsDOE PAGESCardall  Christian Y.; Budiardja  Reuben D.2015-06-11Aside from numerical algorithms and problem setup  large-scale physics simulations on distributed-memory supercomputers require more basic utilitarian functionality  such as physical units and constants; display to the screen or standard output device; message passing; I/O to disk; and runtime parameter management and usage statistics. Here we describe and make available Fortran 2003 classes furnishing extensible object-oriented implementations of this sort of rudimentary functionality  along with individual `unit test' programs and larger example problems demonstrating their use. Lastly  these classes compose the Basics division of our developing astrophysics simulation code GenASiS (General Astrophysical Simulation System)  but their fundamental nature makes themmoreÂ Â» useful for physics simulations in many fields.Â«Â lessAn object-oriented programming system for the integration of internet-based bioinformatics resources.PubMedBeveridge  Allan2006-01-01The Internet consists of a vast inhomogeneous reservoir of data. Developing software that can integrate a wide variety of different data sources is a major challenge that must be addressed for the realisation of the full potential of the Internet as a scientific research tool. This article presents a semi-automated object-oriented programming system for integrating web-based resources. We demonstrate that the current Internet standards (HTML  CGI [common gateway interface]  Java  etc.) can be exploited to develop a data retrieval system that scans existing web interfaces and then uses a set of rules to generate new Java code that can automatically retrieve data from the Web. The validity of the software has been demonstrated by testing it on several biological databases. We also examine the current limitations of the Internet and discuss the need for the development of universal standards for web-based data.Convergence acceleration of the Proteus computer code with multigrid methodsNASA Technical Reports Server (NTRS)Demuren  A. O.; Ibraheem  S. O.1992-01-01Presented here is the first part of a study to implement convergence acceleration techniques based on the multigrid concept in the Proteus computer code. A review is given of previous studies on the implementation of multigrid methods in computer codes for compressible flow analysis. Also presented is a detailed stability analysis of upwind and central-difference based numerical schemes for solving the Euler and Navier-Stokes equations. Results are given of a convergence study of the Proteus code on computational grids of different sizes. The results presented here form the foundation for the implementation of multigrid methods in the Proteus code.Liquid rocket combustor computer code developmentNASA Technical Reports Server (NTRS)Liang  P. Y.1985-01-01The Advanced Rocket Injector/Combustor Code (ARICC) that has been developed to model the complete chemical/fluid/thermal processes occurring inside rocket combustion chambers are highlighted. The code  derived from the CONCHAS-SPRAY code originally developed at Los Alamos National Laboratory incorporates powerful features such as the ability to model complex injector combustion chamber geometries  Lagrangian tracking of droplets  full chemical equilibrium and kinetic reactions for multiple species  a fractional volume of fluid (VOF) description of liquid jet injection in addition to the gaseous phase fluid dynamics  and turbulent mass  energy  and momentum transport. Atomization and droplet dynamic models from earlier generation codes are transplated into the present code. Currently  ARICC is specialized for liquid oxygen/hydrogen propellants  although other fuel/oxidizer pairs can be easily substituted.Proceduracy: Computer Code Writing in the Continuum of LiteracyERIC Educational Resources Information CenterVee  Annette2010-01-01This dissertation looks at computer programming through the lens of literacy studies  building from the concept of code as a written text with expressive and rhetorical power. I focus on the intersecting technological and social factors of computer code writing as a literacy--a practice I call ""proceduracy"". Like literacy  proceduracy is a humanâ€¦Object-Oriented/Data-Oriented Design of a Direct Simulation Monte Carlo AlgorithmNASA Technical Reports Server (NTRS)Liechty  Derek S.2014-01-01Over the past decade  there has been much progress towards improved phenomenological modeling and algorithmic updates for the direct simulation Monte Carlo (DSMC) method  which provides a probabilistic physical simulation of gas Rows. These improvements have largely been based on the work of the originator of the DSMC method  Graeme Bird. Of primary importance are improved chemistry  internal energy  and physics modeling and a reduction in time to solution. These allow for an expanded range of possible solutions In altitude and velocity space. NASA's current production code  the DSMC Analysis Code (DAC)  is well-established and based on Bird's 1994 algorithms written in Fortran 77 and has proven difficult to upgrade. A new DSMC code is being developed in the C++ programming language using object-oriented and data-oriented design paradigms to facilitate the inclusion of the recent improvements and future development activities. The development efforts on the new code  the Multiphysics Algorithm with Particles (MAP)  are described  and performance comparisons are made with DAC.An object-oriented approach to data display and storage: 3 years experience  25 000 cases.PubMedSainsbury  D A1993-11-01Object-oriented programming techniques were used to develop computer based data display and storage systems. These have been operating in the 8 anaesthetising areas of the Adelaide Children's Hospital for 3 years. The analogue and serial outputs from an array of patient monitors are connected to IBM compatible PC-XT computers. The information is displayed on a colour screen as wave-form and trend graphs and digital format in 'real time'. The trend data is printed simultaneously on a dot matrix printer. This data is also stored for 24 hours on 'hard' disk. The major benefit has been the provision of a single visual focus for all monitored variables. The automatic logging of data has been invaluable in the analysis of critical incidents. The systems were made possible by recent  rapid improvements in computer hardware and software. This paper traces the development of the program and demonstrates the advantages of object-oriented programming techniques.Implementing Relational Operations in an Object-Oriented DatabaseDTIC Science & Technology1992-03-01computer aided software engineering (CASE) and computer aided design (CAD) tools. There has been some research done in the area of combining...35 2. Prograph Database Engine .................................................................. 38 III. W HY A N R/O...in most business applications where the bulk of data being stored and manipulated is simply textual or numeric data that can be stored and manipulatedNASA TSRV essential flight control system requirements via object oriented analysisNASA Technical Reports Server (NTRS)Duffy  Keith S.; Hoza  Bradley J.1992-01-01The objective was to analyze the baseline flight control system of the Transport Systems Research Vehicle (TSRV) and to develop a system specification that offers high visibility of the essential system requirements in order to facilitate the future development of alternate  more advanced software architectures. The flight control system is defined to be the baseline software for the TSRV research flight deck  including all navigation  guidance  and control functions  and primary pilot displays. The Object Oriented Analysis (OOA) methodology developed is used to develop a system requirement definition. The scope of the requirements definition contained herein is limited to a portion of the Flight Management/Flight Control computer functionality. The development of a partial system requirements definition is documented  and includes a discussion of the tasks required to increase the scope of the requirements definition and recommendations for follow-on research.A high-level object-oriented model for representing relationships in an electronic medical record.PubMed CentralDolin  R. H.1994-01-01The importance of electronic medical records to improve the quality and cost-effectiveness of medical care continues to be realized. This growing importance has spawned efforts at defining the structure and content of medical data  which is heterogeneous  highly inter-related  and complex. Computer-assisted data modeling tools have greatly facilitated the process of representing medical data  however the complex inter-relationships of medical information can result in data models that are large and cumbersome to manipulate and view. This report presents a high-level object-oriented model for representing the relationships between objects or entities that might exist in an electronic medical record. By defining the relationship between objects at a high level and providing for inheritance  this model enables relating any medical entity to any other medical entity  even though the relationships were not directly specified or known during data model design. PMID:7949981Using features of Arden Syntax with object-oriented medical data models for guideline modeling.PubMedPeleg  M; Ogunyemi  O; Tu  S; Boxwala  A A; Zeng  Q; Greenes  R A; Shortliffe  E H2001-01-01Computer-interpretable guidelines (CIGs) can deliver patient-specific decision support at the point of care. CIGs base their recommendations on eligibility and decision criteria that relate medical concepts to patient data. CIG models use expression languages for specifying these criteria  and define models for medical data to which the expressions can refer. In developing version 3 of the GuideLine Interchange Format (GLIF3)  we used existing standards as the medical data model and expression language. We investigated the object-oriented HL7 Reference Information Model (RIM) as a default data model. We developed an expression language  called GEL  based on Arden Syntax's logic grammar. Together with other GLIF constructs  GEL reconciles incompatibilities between the data models of Arden Syntax and the HL7 RIM. These incompatibilities include Arden's lack of support for complex data types and time intervals  and the mismatch between Arden's single primary time and multiple time attributes of the HL7 RIM.Talking about Code: Integrating Pedagogical Code Reviews into Early Computing CoursesERIC Educational Resources Information CenterHundhausen  Christopher D.; Agrawal  Anukrati; Agarwal  Pawan2013-01-01Given the increasing importance of soft skills in the computing profession  there is good reason to provide students withmore opportunities to learn and practice those skills in undergraduate computing courses. Toward that end  we have developed an active learning approach for computing education called the ""Pedagogical Code Review""â€¦Code 672 observational science branch computer networksNASA Technical Reports Server (NTRS)Hancock  D. W.; Shirk  H. G.1988-01-01In general  networking increases productivity due to the speed of transmission  easy access to remote computers  ability to share files  and increased availability of peripherals. Two different networks within the Observational Science Branch are described in detail.Computer code for charge-exchange plasma propagationNASA Technical Reports Server (NTRS)Robinson  R. S.; Kaufman  H. R.1981-01-01The propagation of the charge-exchange plasma from an electrostatic ion thruster is crucial in determining the interaction of that plasma with the associated spacecraft. A model that describes this plasma and its propagation is described  together with a computer code based on this model. The structure and calling sequence of the code  named PLASIM  is described. An explanation of the program's input and output is included  together with samples of both. The code is written in ASNI Standard FORTRAN.PLASIM: A computer code for simulating charge exchange plasma propagationNASA Technical Reports Server (NTRS)Robinson  R. S.; Deininger  W. D.; Winder  D. R.; Kaufman  H. R.1982-01-01The propagation of the charge exchange plasma for an electrostatic ion thruster is crucial in determining the interaction of that plasma with the associated spacecraft. A model that describes this plasma and its propagation is described  together with a computer code based on this model. The structure and calling sequence of the code  named PLASIM  is described. An explanation of the program's input and output is included  together with samples of both. The code is written in ANSI Standard FORTRAN.An Object Oriented Extensible Architecture for Affordable Aerospace Propulsion SystemsNASA Technical Reports Server (NTRS)Follen  Gregory J.2003-01-01Driven by a need to explore and develop propulsion systems that exceeded current computing capabilities  NASA Glenn embarked on a novel strategy leading to the development of an architecture that enables propulsion simulations never thought possible before. Full engine 3 Dimensional Computational Fluid Dynamic propulsion system simulations were deemed impossible due to the impracticality of the hardware and software computing systems required. However  with a software paradigm shift and an embracing of parallel and distributed processing  an architecture was designed to meet the needs of future propulsion system modeling. The author suggests that the architecture designed at the NASA Glenn Research Center for propulsion system modeling has potential for impacting the direction of development of affordable weapons systems currently under consideration by the Applied Vehicle Technology Panel (AVT).Computer Code for Transportation Network Design and AnalysisDOT National Transportation Integrated Search1977-01-01This document describes the results of research into the application of the mathematical programming technique of decomposition to practical transportation network problems. A computer code called Catnap (for Control Analysis Transportation Network A...Computer-assisted coding and clinical documentation: first things first.PubMedTully  Melinda; Carmichael  Angela2012-10-01Computer-assisted coding tools have the potential to drive improvements in seven areas: Transparency of coding. Productivity (generally by 20 to 25 percent for inpatient claims). Accuracy (by improving specificity of documentation). Cost containment (by reducing overtime expenses  audit fees  and denials). Compliance. Efficiency. Consistency.Nonuniform code concatenation for universal fault-tolerant quantum computingNASA Astrophysics Data System (ADS)Nikahd  Eesa; Sedighi  Mehdi; Saheb Zamani  Morteza2017-09-01Using transversal gates is a straightforward and efficient technique for fault-tolerant quantum computing. Since transversal gates alone cannot be computationally universal  they must be combined with other approaches such as magic state distillation  code switching  or code concatenation to achieve universality. In this paper we propose an alternative approach for universal fault-tolerant quantum computing  mainly based on the code concatenation approach proposed in [T. Jochym-O'Connor and R. Laflamme  Phys. Rev. Lett. 112  010505 (2014)  10.1103/PhysRevLett.112.010505]  but in a nonuniform fashion. The proposed approach is described based on nonuniform concatenation of the 7-qubit Steane code with the 15-qubit Reed-Muller code  as well as the 5-qubit code with the 15-qubit Reed-Muller code  which lead to two 49-qubit and 47-qubit codes  respectively. These codes can correct any arbitrary single physical error with the ability to perform a universal set of fault-tolerant gates  without using magic state distillation.APC: A New Code for Atmospheric Polarization ComputationsNASA Technical Reports Server (NTRS)Korkin  Sergey V.; Lyapustin  Alexei I.; Rozanov  Vladimir V.2014-01-01A new polarized radiative transfer code Atmospheric Polarization Computations (APC) is described. The code is based on separation of the diffuse light field into anisotropic and smooth (regular) parts. The anisotropic part is computed analytically. The smooth regular part is computed numerically using the discrete ordinates method. Vertical stratification of the atmosphere  common types of bidirectional surface reflection and scattering by spherical particles or spheroids are included. A particular consideration is given to computation of the bidirectional polarization distribution function (BPDF) of the waved ocean surface.Los Alamos radiation transport code system on desktop computing platformsSciTech ConnectBriesmeister  J.F.; Brinkley  F.W.; Clark  B.A.The Los Alamos Radiation Transport Code System (LARTCS) consists of state-of-the-art Monte Carlo and discrete ordinates transport codes and data libraries. These codes were originally developed many years ago and have undergone continual improvement. With a large initial effort and continued vigilance  the codes are easily portable from one type of hardware to another. The performance of scientific work-stations (SWS) has evolved to the point that such platforms can be used routinely to perform sophisticated radiation transport calculations. As the personal computer (PC) performance approaches that of the SWS  the hardware options for desk-top radiation transport calculations expands considerably. ThemoreÂ Â» current status of the radiation transport codes within the LARTCS is described: MCNP  SABRINA  LAHET  ONEDANT  TWODANT  TWOHEX  and ONELD. Specifically  the authors discuss hardware systems on which the codes run and present code performance comparisons for various machines.Â«Â lessTowards an Object-Oriented Model for the Design and Development of Learning ObjectsERIC Educational Resources Information CenterChrysostomou  Chrysostomos; Papadopoulos  George2008-01-01This work introduces the concept of an Object-Oriented Learning Object (OOLO) that is developed in a manner similar to the one that software objects are developed through Object-Oriented Software Engineering (OO SWE) techniques. In order to make the application of the OOLO feasible and efficient  an OOLO model needs to be developed based onâ€¦Advanced software development workstation: Object-oriented methodologies and applications for flight planning and mission operationsNASA Technical Reports Server (NTRS)Izygon  Michel1993-01-01The work accomplished during the past nine months in order to help three different organizations involved in Flight Planning and in Mission Operations systems  to transition to Object-Oriented Technology  by adopting one of the currently most widely used Object-Oriented analysis and Design Methodology is summarized.Postural and Object-Oriented Experiences Advance Early Reaching  Object Exploration  and Means-End BehaviorERIC Educational Resources Information CenterLobo  Michele A.; Galloway  James C.2008-01-01The effects of 3 weeks of social (control)  postural  or object-oriented experiences on 9- to 21-week-old infants' (N = 42) reaching  exploration  and means-end behaviors were assessed. Coders recorded object contacts  mouthing  fingering  attention  and affect from video. Postural and object-oriented experiences advanced reaching  hapticâ€¦Object-Oriented Dynamic Bayesian Network-Templates for Modelling Mechatronic SystemsDTIC Science & Technology2002-05-04daimlerchrysler.com Abstract are widespread. For modelling mechanical systems The object-oriented paradigma is a new but proven technol- ADAMS [31 or...hardware (sub-)systems. On the Software side thermal flow or hydraulics  see Figure 1. It also contains a the object-oriented paradigma is by now (atNASA Lewis Stirling engine computer code evaluationNASA Technical Reports Server (NTRS)Sullivan  Timothy J.1989-01-01In support of the U.S. Department of Energy's Stirling Engine Highway Vehicle Systems program  the NASA Lewis Stirling engine performance code was evaluated by comparing code predictions without engine-specific calibration factors to GPU-3  P-40  and RE-1000 Stirling engine test data. The error in predicting power output was -11 percent for the P-40 and 12 percent for the Re-1000 at design conditions and 16 percent for the GPU-3 at near-design conditions (2000 rpm engine speed versus 3000 rpm at design). The efficiency and heat input predictions showed better agreement with engine test data than did the power predictions. Concerning all data points  the error in predicting the GPU-3 brake power was significantly larger than for the other engines and was mainly a result of inaccuracy in predicting the pressure phase angle. Analysis into this pressure phase angle prediction error suggested that improvements to the cylinder hysteresis loss model could have a significant effect on overall Stirling engine performance predictions.A Survey of Object Oriented Languages in Programming Environments.DTIC Science & Technology1987-06-01subset of natural languages might be more effective   and make the human-computer interface more friendly. 19 .. .. . . -.. -  ""  . o...and complexty of Ada. He meant that the language contained too many features that made it complicated to use effectively . Much of the complexity comes...by sending messages to a class instance. A small subset of the methods in Smalltalk-80 are not expressed in the !-’ Smalhalk-80 programming languagePerformance Analysis of Distributed Object-Oriented ApplicationsNASA Technical Reports Server (NTRS)Schoeffler  James D.1998-01-01The purpose of this research was to evaluate the efficiency of a distributed simulation architecture which creates individual modules which are made self-scheduling through the use of a message-based communication system used for requesting input data from another module which is the source of that data. To make the architecture as general as possible  the message-based communication architecture was implemented using standard remote object architectures (Common Object Request Broker Architecture (CORBA) and/or Distributed Component Object Model (DCOM)). A series of experiments were run in which different systems are distributed in a variety of ways across multiple computers and the performance evaluated. The experiments were duplicated in each case so that the overhead due to message communication and data transmission can be separated from the time required to actually perform the computational update of a module each iteration. The software used to distribute the modules across multiple computers was developed in the first year of the current grant and was modified considerably to add a message-based communication scheme supported by the DCOM distributed object architecture. The resulting performance was analyzed using a model created during the first year of this grant which predicts the overhead due to CORBA and DCOM remote procedure calls and includes the effects of data passed to and from the remote objects. A report covering the distributed simulation software and the results of the performance experiments has been submitted separately. The above report also discusses possible future work to apply the methodology to dynamically distribute the simulation modules so as to minimize overall computation time.Multitasking the code ARC3D. [for computational fluid dynamicsNASA Technical Reports Server (NTRS)Barton  John T.; Hsiung  Christopher C.1986-01-01The CRAY multitasking system was developed in order to utilize all four processors and sharply reduce the wall clock run time. This paper describes the techniques used to modify the computational fluid dynamics code ARC3D for this run and analyzes the achieved speedup. The ARC3D code solves either the Euler or thin-layer N-S equations using an implicit approximate factorization scheme. Results indicate that multitask processing can be used to achieve wall clock speedup factors of over three times  depending on the nature of the program code being used. Multitasking appears to be particularly advantageous for large-memory problems running on multiple CPU computers.An object oriented Python interface for atomistic simulationsNASA Astrophysics Data System (ADS)Hynninen  T.; Himanen  L.; Parkkinen  V.; Musso  T.; Corander  J.; Foster  A. S.2016-01-01Programmable simulation environments allow one to monitor and control calculations efficiently and automatically before  during  and after runtime. Environments directly accessible in a programming environment can be interfaced with powerful external analysis tools and extensions to enhance the functionality of the core program  and by incorporating a flexible object based structure  the environments make building and analysing computational setups intuitive. In this work  we present a classical atomistic force field with an interface written in Python language. The program is an extension for an existing object based atomistic simulation environment.Computer Code For Turbocompounded Adiabatic Diesel EngineNASA Technical Reports Server (NTRS)Assanis  D. N.; Heywood  J. B.1988-01-01Computer simulation developed to study advantages of increased exhaust enthalpy in adiabatic turbocompounded diesel engine. Subsytems of conceptual engine include compressor  reciprocator  turbocharger turbine  compounded turbine  ducting  and heat exchangers. Focus of simulation of total system is to define transfers of mass and energy  including release and transfer of heat and transfer of work in each subsystem  and relationship among subsystems. Written in FORTRAN IV.Computer vision cracks the leaf codePubMed CentralWilf  Peter; Zhang  Shengping; Chikkerur  Sharat; Little  Stefan A.; Wing  Scott L.; Serre  Thomas2016-01-01Understanding the extremely variable  complex shape and venation characters of angiosperm leaves is one of the most challenging problems in botany. Machine learning offers opportunities to analyze large numbers of specimens  to discover novel leaf features of angiosperm clades that may have phylogenetic significance  and to use those characters to classify unknowns. Previous computer vision approaches have primarily focused on leaf identification at the species level. It remains an open question whether learning and classification are possible among major evolutionary groups such as families and orders  which usually contain hundreds to thousands of species each and exhibit many times the foliar variation of individual species. Here  we tested whether a computer vision algorithm could use a database of 7 597 leaf images from 2 001 genera to learn features of botanical families and orders  then classify novel images. The images are of cleared leaves  specimens that are chemically bleached  then stained to reveal venation. Machine learning was used to learn a codebook of visual elements representing leaf shape and venation patterns. The resulting automated system learned to classify images into families and orders with a success rate many times greater than chance. Of direct botanical interest  the responses of diagnostic features can be visualized on leaf images as heat maps  which are likely to prompt recognition and evolutionary interpretation of a wealth of novel morphological characters. With assistance from computer vision  leaves are poised to make numerous new contributions to systematic and paleobotanical studies. PMID:26951664Development Of A Navier-Stokes Computer CodeNASA Technical Reports Server (NTRS)Yoon  Seokkwan; Kwak  Dochan1993-01-01Report discusses aspects of development of CENS3D computer code  solving three-dimensional Navier-Stokes equations of compressible  viscous  unsteady flow. Implements implicit finite-difference or finite-volume numerical-integration scheme  called ""lower-upper symmetric-Gauss-Seidel"" (LU-SGS)  offering potential for very low computer time per iteration and for fast convergence.An object-oriented software approach for a distributed human tracking motion systemNASA Astrophysics Data System (ADS)Micucci  Daniela L.2003-06-01Tracking is a composite job involving the co-operation of autonomous activities which exploit a complex information model and rely on a distributed architecture. Both information and activities must be classified and related in several dimensions: abstraction levels (what is modelled and how information is processed); topology (where the modelled entities are); time (when entities exist); strategy (why something happens); responsibilities (who is in charge of processing the information). A proper Object-Oriented analysis and design approach leads to a modular architecture where information about conceptual entities is modelled at each abstraction level via classes and intra-level associations  whereas inter-level associations between classes model the abstraction process. Both information and computation are partitioned according to level-specific topological models. They are also placed in a temporal framework modelled by suitable abstractions. Domain-specific strategies control the execution of the computations. Computational components perform both intra-level processing and intra-level information conversion. The paper overviews the phases of the analysis and design process  presents major concepts at each abstraction level  and shows how the resulting design turns into a modular  flexible and adaptive architecture. Finally  the paper sketches how the conceptual architecture can be deployed into a concrete distribute architecture by relying on an experimental framework.Semantic framework for mapping object-oriented model to semantic web languagesPubMed CentralJeÅ¾ek  Petr; MouÄek  Roman2015-01-01The article deals with and discusses two main approaches in building semantic structures for electrophysiological metadata. It is the use of conventional data structures  repositories  and programming languages on one hand and the use of formal representations of ontologies  known from knowledge representation  such as description logics or semantic web languages on the other hand. Although knowledge engineering offers languages supporting richer semantic means of expression and technological advanced approaches  conventional data structures and repositories are still popular among developers  administrators and users because of their simplicity  overall intelligibility  and lower demands on technical equipment. The choice of conventional data resources and repositories  however  raises the question of how and where to add semantics that cannot be naturally expressed using them. As one of the possible solutions  this semantics can be added into the structures of the programming language that accesses and processes the underlying data. To support this idea we introduced a software prototype that enables its users to add semantically richer expressions into a Java object-oriented code. This approach does not burden users with additional demands on programming environment since reflective Java annotations were used as an entry for these expressions. Moreover  additional semantics need not to be written by the programmer directly to the code  but it can be collected from non-programmers using a graphic user interface. The mapping that allows the transformation of the semantically enriched Java code into the Semantic Web language OWL was proposed and implemented in a library named the Semantic Framework. This approach was validated by the integration of the Semantic Framework in the EEG/ERP Portal and by the subsequent registration of the EEG/ERP Portal in the Neuroscience Information Framework. PMID:25762923Semantic framework for mapping object-oriented model to semantic web languages.PubMedJeÅ¾ek  Petr; MouÄek  Roman2015-01-01The article deals with and discusses two main approaches in building semantic structures for electrophysiological metadata. It is the use of conventional data structures  repositories  and programming languages on one hand and the use of formal representations of ontologies  known from knowledge representation  such as description logics or semantic web languages on the other hand. Although knowledge engineering offers languages supporting richer semantic means of expression and technological advanced approaches  conventional data structures and repositories are still popular among developers  administrators and users because of their simplicity  overall intelligibility  and lower demands on technical equipment. The choice of conventional data resources and repositories  however  raises the question of how and where to add semantics that cannot be naturally expressed using them. As one of the possible solutions  this semantics can be added into the structures of the programming language that accesses and processes the underlying data. To support this idea we introduced a software prototype that enables its users to add semantically richer expressions into a Java object-oriented code. This approach does not burden users with additional demands on programming environment since reflective Java annotations were used as an entry for these expressions. Moreover  additional semantics need not to be written by the programmer directly to the code  but it can be collected from non-programmers using a graphic user interface. The mapping that allows the transformation of the semantically enriched Java code into the Semantic Web language OWL was proposed and implemented in a library named the Semantic Framework. This approach was validated by the integration of the Semantic Framework in the EEG/ERP Portal and by the subsequent registration of the EEG/ERP Portal in the Neuroscience Information Framework.Computer codes developed and under development at LewisNASA Technical Reports Server (NTRS)Chamis  Christos C.1992-01-01The objective of this summary is to provide a brief description of: (1) codes developed or under development at LeRC; and (2) the development status of IPACS with some typical early results. The computer codes that have been developed and/or are under development at LeRC are listed in the accompanying charts. This list includes: (1) the code acronym; (2) select physics descriptors; (3) current enhancements; and (4) present (9/91) code status with respect to its availability and documentation. The computer codes list is grouped by related functions such as: (1) composite mechanics; (2) composite structures; (3) integrated and 3-D analysis; (4) structural tailoring; and (5) probabilistic structural analysis. These codes provide a broad computational simulation infrastructure (technology base-readiness) for assessing the structural integrity/durability/reliability of propulsion systems. These codes serve two other very important functions: they provide an effective means of technology transfer; and they constitute a depository of corporate memory.Analyzing Pulse-Code Modulation On A Small ComputerNASA Technical Reports Server (NTRS)Massey  David E.1988-01-01System for analysis pulse-code modulation (PCM) comprises personal computer  computer program  and peripheral interface adapter on circuit board that plugs into expansion bus of computer. Functions essentially as ""snapshot"" PCM decommutator  which accepts and stores thousands of frames of PCM data  sifts through them repeatedly to process according to routines specified by operator. Enables faster testing and involves less equipment than older testing systems.Space radiator simulation manual for computer codeNASA Technical Reports Server (NTRS)Black  W. Z.; Wulff  W.1972-01-01A computer program that simulates the performance of a space radiator is presented. The program basically consists of a rigorous analysis which analyzes a symmetrical fin panel and an approximate analysis that predicts system characteristics for cases of non-symmetrical operation. The rigorous analysis accounts for both transient and steady state performance including aerodynamic and radiant heating of the radiator system. The approximate analysis considers only steady state operation with no aerodynamic heating. A description of the radiator system and instructions to the user for program operation is included. The input required for the execution of all program options is described. Several examples of program output are contained in this section. Sample output includes the radiator performance during ascent  reentry and orbit.Image Engine: an object-oriented multimedia database for storing  retrieving and sharing medical images and text.PubMed CentralLowe  H. J.1993-01-01This paper describes Image Engine  an object-oriented  microcomputer-based  multimedia database designed to facilitate the storage and retrieval of digitized biomedical still images  video  and text using inexpensive desktop computers. The current prototype runs on Apple Macintosh computers and allows network database access via peer to peer file sharing protocols. Image Engine supports both free text and controlled vocabulary indexing of multimedia objects. The latter is implemented using the TView thesaurus model developed by the author. The current prototype of Image Engine uses the National Library of Medicine's Medical Subject Headings (MeSH) vocabulary (with UMLS Meta-1 extensions) as its indexing thesaurus. PMID:8130596A Validation of Object-Oriented Design Metrics as Quality IndicatorsNASA Technical Reports Server (NTRS)Basili  Victor R.; Briand  Lionel C.; Melo  Walcelio1997-01-01This paper presents the results of a study in which we empirically investigated the suits of object-oriented (00) design metrics introduced in another work. More specifically  our goal is to assess these metrics as predictors of fault-prone classes and  therefore  determine whether they can be used as early quality indicators. This study is complementary to the work described where the same suite of metrics had been used to assess frequencies of maintenance changes to classes. To perform our validation accurately  we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model  a well-known 00 analysis/design method and the C++ programming language. Based on empirical and quantitative analysis  the advantages and drawbacks of these 00 metrics are discussed. Several of Chidamber and Kamerer's 00 metrics appear to be useful to predict class fault-proneness during the early phases of the life-cycle. Also  on our data set  they are better predictors than 'traditional' code metrics  which can only be collected at a later phase of the software development processes.Organizing and Typing Persistent Objects Within an Object-Oriented FrameworkNASA Technical Reports Server (NTRS)Madany  Peter W.; Campbell  Roy H.1991-01-01Conventional operating systems provide little or no direct support for the services required for an efficient persistent object system implementation. We have built a persistent object scheme using a customization and extension of an object-oriented operating system called Choices. Choices includes a framework for the storage of persistent data that is suited to the construction of both conventional file system and persistent object system. In this paper we describe three areas in which persistent object support differs from file system support: storage organization  storage management  and typing. Persistent object systems must support various sizes of objects efficiently. Customizable containers  which are themselves persistent objects and can be nested  support a wide range of object sizes in Choices. Collections of persistent objects that are accessed as an aggregate and collections of light-weight persistent objects can be clustered in containers that are nested within containers for larger objects. Automated garbage collection schemes are added to storage management and have a major impact on persistent object applications. The Choices persistent object store provides extensible sets of persistent object types. The store contains not only the data for persistent objects but also the names of the classes to which they belong and the code for the operation of the classes. Besides presenting persistent object storage organization  storage management  and typing  this paper discusses how persistent objects are named and used within the Choices persistent data/file system framework.HiCAT Software Infrastructure: Safe hardware control with object oriented PythonNASA Astrophysics Data System (ADS)Moriarty  Christopher; Brooks  Keira; Soummer  Remi2018-01-01High contrast imaging for Complex Aperture Telescopes (HiCAT) is a testbed designed to demonstrate coronagraphy and wavefront control for segmented on-axis space telescopes such as envisioned for LUVOIR. To limit the air movements in the testbed room  software interfaces for several different hardware components were developed to completely automate operations. When developing software interfaces for many different pieces of hardware  unhandled errors are commonplace and can prevent the software from properly closing a hardware resource. Some fragile components (e.g. deformable mirrors) can be permanently damaged because of this. We present an object oriented Python-based infrastructure to safely automate hardware control and optical experiments. Specifically  conducting high-contrast imaging experiments while monitoring humidity and power status along with graceful shutdown processes even for unexpected errors. Python contains a construct called a â€œcontext managerâ€ that allows you define code to run when a resource is opened or closed. Context managers ensure that a resource is properly closed  even when unhandled errors occur. Harnessing the context manager design  we also use Pythonâ€™s multiprocessing library to monitor humidity and power status without interrupting the experiment. Upon detecting a safety problem  the master process sends an event to the child process that triggers the context managers to gracefully close any open resources. This infrastructure allows us to queue up several experiments and safely operate the testbed without a human in the loop.Bee++: An Object-Oriented  Agent-Based Simulator for Honey Bee ColoniesPubMed CentralBetti  Matthew; LeClair  Josh; Wahl  Lindi M.; Zamir  Mair2017-01-01We present a model and associated simulation package (www.beeplusplus.ca) to capture the natural dynamics of a honey bee colony in a spatially-explicit landscape  with temporally-variable  weather-dependent parameters. The simulation tracks bees of different ages and castes  food stores within the colony  pollen and nectar sources and the spatial position of individual foragers outside the hive. We track explicitly the intake of pesticides in individual bees and their ability to metabolize these toxins  such that the impact of sub-lethal doses of pesticides can be explored. Moreover  pathogen populations (in particular  Nosema apis  Nosema cerenae and Varroa mites) have been included in the model and may be introduced at any time or location. The ability to study interactions among pesticides  climate  biodiversity and pathogens in this predictive framework should prove useful to a wide range of researchers studying honey bee populations. To this end  the simulation package is written in open source  object-oriented code (C++) and can be easily modified by the user. Here  we demonstrate the use of the model by exploring the effects of sub-lethal pesticide exposure on the flight behaviour of foragers. PMID:28287445Representing object oriented specifications and designs with extended data flow notationsNASA Technical Reports Server (NTRS)Buser  Jon Franklin; Ward  Paul T.1988-01-01The issue of using extended data flow notations to document object oriented designs and specifications is discussed. Extended data flow notations  for the purposes here  refer to notations that are based on the rules of Yourdon/DeMarco data flow analysis. The extensions include additional notation for representing real-time systems as well as some proposed extensions specific to object oriented development. Some advantages of data flow notations are stated. How data flow diagrams are used to represent software objects are investigated. Some problem areas with regard to using data flow notations for object oriented development are noted. Some initial solutions to these problems are proposed.Guest Editor's introduction: Selected papers from the 4th USENIX Conference on Object-Oriented Technologies and SystemsNASA Astrophysics Data System (ADS)Sventek  Joe1998-12-01Hewlett-Packard Laboratories  1501 Page Mill Road  Palo Alto  CA 94304  USA Introduction The USENIX Conference on Object-Oriented Technologies and Systems (COOTS) is held annually in the late spring. The conference evolved from a set of C++ workshops that were held under the auspices of USENIX  the first of which met in 1989. Given the growing diverse interest in object-oriented technologies  the C++ focus of the workshop eventually became too narrow  with the result that the scope was widened in 1995 to include object-oriented technologies and systems. COOTS is intended to showcase advanced R&D efforts in object-oriented technologies and software systems. The conference emphasizes experimental research and experience gained by using object-oriented techniques and languages to build complex software systems that meet real-world needs. COOTS solicits papers in the following general areas: application of  and experiences with  object-oriented technologies in particular domains (e.g. financial  medical  telecommunication); the architecture and implementation of distributed object systems (e.g. CORBA  DCOM  RMI); object-oriented programming and specification languages; object-oriented design and analysis. The 4th meeting of COOTS was held 27 - 30 April 1998 at the El Dorado Hotel  Santa Fe  New Mexico  USA. Several tutorials were given. The technical program proper consisted of a single track of six sessions  with three paper presentations per session. A keynote address and a provocative panel session rounded out the technical program. The program committee reviewed 56 papers  selecting the best 18 for presentation in the technical sessions. While we solicit papers across the spectrum of applications of object-oriented technologies  this year there was a predominance of distributed  object-oriented papers. The accepted papers reflected this asymmetry  with 15 papers on distributed objects and 3 papers on object-oriented languages. The papers in this special issue areRecent applications of the transonic wing analysis computer code  TWINGNASA Technical Reports Server (NTRS)Subramanian  N. R.; Holst  T. L.; Thomas  S. D.1982-01-01An evaluation of the transonic-wing-analysis computer code TWING is given. TWING utilizes a fully implicit approximate factorization iteration scheme to solve the full potential equation in conservative form. A numerical elliptic-solver grid-generation scheme is used to generate the required finite-difference mesh. Several wing configurations were analyzed  and the limits of applicability of this code was evaluated. Comparisons of computed results were made with available experimental data. Results indicate that the code is robust  accurate (when significant viscous effects are not present)  and efficient. TWING generally produces solutions an order of magnitude faster than other conservative full potential codes using successive-line overrelaxation. The present method is applicable to a wide range of isolated wing configurations including high-aspect-ratio transport wings and low-aspect-ratio  high-sweep  fighter configurations.Holonomic surface codes for fault-tolerant quantum computationNASA Astrophysics Data System (ADS)Zhang  Jiang; Devitt  Simon J.; You  J. Q.; Nori  Franco2018-02-01Surface codes can protect quantum information stored in qubits from local errors as long as the per-operation error rate is below a certain threshold. Here we propose holonomic surface codes by harnessing the quantum holonomy of the system. In our scheme  the holonomic gates are built via auxiliary qubits rather than the auxiliary levels in multilevel systems used in conventional holonomic quantum computation. The key advantage of our approach is that the auxiliary qubits are in their ground state before and after each gate operation  so they are not involved in the operation cycles of surface codes. This provides an advantageous way to implement surface codes for fault-tolerant quantum computation.Reweighted mass center based object-oriented sparse subspace clustering for hyperspectral imagesNASA Astrophysics Data System (ADS)Zhai  Han; Zhang  Hongyan; Zhang  Liangpei; Li  Pingxiang2016-10-01Considering the inevitable obstacles faced by the pixel-based clustering methods  such as salt-and-pepper noise  high computational complexity  and the lack of spatial information  a reweighted mass center based object-oriented sparse subspace clustering (RMC-OOSSC) algorithm for hyperspectral images (HSIs) is proposed. First  the mean-shift segmentation method is utilized to oversegment the HSI to obtain meaningful objects. Second  a distance reweighted mass center learning model is presented to extract the representative and discriminative features for each object. Third  assuming that all the objects are sampled from a union of subspaces  it is natural to apply the SSC algorithm to the HSI. Faced with the high correlation among the hyperspectral objects  a weighting scheme is adopted to ensure that the highly correlated objects are preferred in the procedure of sparse representation  to reduce the representation errors. Two widely used hyperspectral datasets were utilized to test the performance of the proposed RMC-OOSSC algorithm  obtaining high clustering accuracies (overall accuracy) of 71.98% and 89.57%  respectively. The experimental results show that the proposed method clearly improves the clustering performance with respect to the other state-of-the-art clustering methods  and it significantly reduces the computational time.The Implementation of Satellite Control System Software Using Object Oriented DesignNASA Technical Reports Server (NTRS)Anderson  Mark O.; Reid  Mark; Drury  Derek; Hansell  William; Phillips  Tom1998-01-01NASA established the Small Explorer (SMEX) program in 1988 to provide frequent opportunities for highly focused and relatively inexpensive space science missions that can be launched into low earth orbit by small expendable vehicles. The development schedule for each SMEX spacecraft was three years from start to launch. The SMEX program has produced five satellites; Solar Anomalous and Magnetospheric Particle Explorer (SAMPEX)  Fast Auroral Snapshot Explorer (FAST)  Submillimeter Wave Astronomy Satellite (SWAS)  Transition Region and Coronal Explorer (TRACE) and Wide-Field Infrared Explorer (WIRE). SAMPEX and FAST are on-orbit  TRACE is scheduled to be launched in April of 1998  WIRE is scheduled to be launched in September of 1998  and SWAS is scheduled to be launched in January of 1999. In each of these missions  the Attitude Control System (ACS) software was written using a modular procedural design. Current program goals require complete spacecraft development within 18 months. This requirement has increased pressure to write reusable flight software. Object-Oriented Design (OOD) offers the constructs for developing an application that only needs modification for mission unique requirements. This paper describes the OOD that was used to develop the SMEX-Lite ACS software. The SMEX-Lite ACS is three-axis controlled  momentum stabilized  and is capable of performing sub-arc-minute pointing. The paper first describes the high level requirements which governed the architecture of the SMEX-Lite ACS software. Next  the context in which the software resides is explained. The paper describes the benefits of encapsulation  inheritance and polymorphism with respect to the implementation of an ACS software system. This paper will discuss the design of several software components that comprise the ACS software. Specifically  Object-Oriented designs are presented for sensor data processing  attitude control  attitude determination and failure detection. The paper addressesInstrumentation for Verification of Bomb Damage Repair Computer Code.DTIC Science & Technology1981-09-01record the data  a conventional 14-track FM analog tape recorder was retained. The unknown factors of signal duration  test duration  and signal ...Kirtland Air Force Base computer centers for more detailed analyses. In addition to the analog recorder  signal conditioning equipment and amplifiers were...necessary to allow high quality data to be recorded. An Interrange Instrumentation Group (IRIG) code generator/reader placed a coded signal on the tapeObject-Oriented Programming When Developing Software in Geology and GeophysicsNASA Astrophysics Data System (ADS)Ahmadulin  R. K.; Bakanovskaya  L. N.2017-01-01The paper reviews the role of object-oriented programming when developing software in geology and geophysics. Main stages have been identified at which it is worthwhile to apply principles of object-oriented programming when developing software in geology and geophysics. The research was based on a number of problems solved in Geology and Petroleum Production Institute. Distinctive features of these problems are given and areas of application of the object-oriented approach are identified. Developing applications in the sphere of geology and geophysics has shown that the process of creating such products is simplified due to the use of object-oriented programming  firstly when designing structures for data storage and graphical user interfaces.A uniform object-oriented solution to the eigenvalue problem for real symmetric and Hermitian matricesNASA Astrophysics Data System (ADS)Castro  MarÃ­a Eugenia; DÃ­az  Javier; MuÃ±oz-Caro  Camelia; NiÃ±o  Alfonso2011-09-01 and conquer  can be used to factorize the matrices in order to apply a parallel computing approach. However  it is still interesting to have a core procedure able to tackle the computation of eigenvalues and eigenvectors once the matrix has been factorized to pieces of enough small size. Several available software packages  such as LAPACK  tackled this problem under the traditional imperative programming paradigm. In order to ease the modelling of complex quantum mechanical models it could be interesting to apply an object-oriented approach to the treatment of the eigenproblem. This approach offers the advantage of a single  uniform treatment for the real symmetric and Hermitian cases. Solution method: To reach the above goals  we have developed a system of classes: SHMatrix. SHMatrix is composed by an abstract base class and two descendant classes  one for real symmetric matrices and the other for the Hermitian case. The object-oriented characteristics of inheritance and polymorphism allows handling both cases using a single reference of the base class. The basic computing strategy applied in SHMatrix allows computing subsets of eigenvalues and (optionally) eigenvectors. The tests performed show that SHMatrix is competitive  and more efficient for large matrices  than the equivalent routines of the LAPACK package. Running time: The examples included in the distribution take only a couple of seconds to run.Parallelization of Finite Element Analysis Codes Using Heterogeneous Distributed ComputingNASA Technical Reports Server (NTRS)Ozguner  Fusun1996-01-01Performance gains in computer design are quickly consumed as users seek to analyze larger problems to a higher degree of accuracy. Innovative computational methods  such as parallel and distributed computing  seek to multiply the power of existing hardware technology to satisfy the computational demands of large applications. In the early stages of this project  experiments were performed using two large  coarse-grained applications  CSTEM and METCAN. These applications were parallelized on an Intel iPSC/860 hypercube. It was found that the overall speedup was very low  due to large  inherently sequential code segments present in the applications. The overall execution time T(sub par)  of the application is dependent on these sequential segments. If these segments make up a significant fraction of the overall code  the application will have a poor speedup measure.Data management in an object-oriented distributed aircraft conceptual design environmentNASA Astrophysics Data System (ADS)Lu  ZhijieIn the competitive global market place  aerospace companies are forced to deliver the right products to the right market  with the right cost  and at the right time. However  the rapid development of technologies and new business opportunities  such as mergers  acquisitions  supply chain management  etc.  have dramatically increased the complexity of designing an aircraft. Therefore  the pressure to reduce design cycle time and cost is enormous. One way to solve such a dilemma is to develop and apply advanced engineering environments (AEEs)  which are distributed collaborative virtual design environments linking researchers  technologists  designers  etc.  together by incorporating application tools and advanced computational  communications  and networking facilities. Aircraft conceptual design  as the first design stage  provides major opportunity to compress design cycle time and is the cheapest place for making design changes. However  traditional aircraft conceptual design programs  which are monolithic programs  cannot provide satisfactory functionality to meet new design requirements due to the lack of domain flexibility and analysis scalability. Therefore  we are in need of the next generation aircraft conceptual design environment (NextADE). To build the NextADE  the framework and the data management problem are two major problems that need to be addressed at the forefront. Solving these two problems  particularly the data management problem  is the focus of this research. In this dissertation  in light of AEEs  a distributed object-oriented framework is firstly formulated and tested for the NextADE. In order to improve interoperability and simplify the integration of heterogeneous application tools  data management is one of the major problems that need to be tackled. To solve this problem  taking into account the characteristics of aircraft conceptual design data  a robust  extensible object-oriented data model is then proposed according to theUpgrades of Two Computer Codes for Analysis of TurbomachineryNASA Technical Reports Server (NTRS)Chima  Rodrick V.; Liou  Meng-Sing2005-01-01Major upgrades have been made in two of the programs reported in ""ive Computer Codes for Analysis of Turbomachinery"". The affected programs are: Swift -- a code for three-dimensional (3D) multiblock analysis; and TCGRID  which generates a 3D grid used with Swift. Originally utilizing only a central-differencing scheme for numerical solution  Swift was augmented by addition of two upwind schemes that give greater accuracy but take more computing time. Other improvements in Swift include addition of a shear-stress-transport turbulence model for better prediction of adverse pressure gradients  addition of an H-grid capability for flexibility in modeling flows in pumps and ducts  and modification to enable simultaneous modeling of hub and tip clearances. Improvements in TCGRID include modifications to enable generation of grids for more complicated flow paths and addition of an option to generate grids compatible with the ADPAC code used at NASA and in industry. For both codes  new test cases were developed and documentation was updated. Both codes were converted to Fortran 90  with dynamic memory allocation. Both codes were also modified for ease of use in both UNIX and Windows operating systems.Connecting Neural Coding to Number Cognition: A Computational AccountERIC Educational Resources Information CenterPrather  Richard W.2012-01-01The current study presents a series of computational simulations that demonstrate how the neural coding of numerical magnitude may influence number cognition and development. This includes behavioral phenomena cataloged in cognitive literature such as the development of numerical estimation and operational momentum. Though neural research hasâ€¦Plagiarism Detection Algorithm for Source Code in Computer Science EducationERIC Educational Resources Information CenterLiu  Xin; Xu  Chan; Ouyang  Boyu2015-01-01Nowadays  computer programming is getting more necessary in the course of program design in college education. However  the trick of plagiarizing plus a little modification exists among some students' home works. It's not easy for teachers to judge if there's plagiarizing in source code or not. Traditional detection algorithms cannot fit thisâ€¦General review of the MOSTAS computer code for wind turbinesNASA Technical Reports Server (NTRS)Dungundji  J.; Wendell  J. H.1981-01-01The MOSTAS computer code for wind turbine analysis is reviewed  and techniques and methods used in its analyses are described. Impressions of its strengths and weakness  and recommendations for its application  modification  and further development are made. Basic techniques used in wind turbine stability and response analyses for systems with constant and periodic coefficients are reviewed.Development and application of computational aerothermodynamics flowfield computer codesNASA Technical Reports Server (NTRS)Venkatapathy  Ethiraj1993-01-01Computations are presented for one-dimensional  strong shock waves that are typical of those that form in front of a reentering spacecraft. The fluid mechanics and thermochemistry are modeled using two different approaches. The first employs traditional continuum techniques in solving the Navier-Stokes equations. The second-approach employs a particle simulation technique (the direct simulation Monte Carlo method  DSMC). The thermochemical models employed in these two techniques are quite different. The present investigation presents an evaluation of thermochemical models for nitrogen under hypersonic flow conditions. Four separate cases are considered. The cases are governed  respectively  by the following: vibrational relaxation; weak dissociation; strong dissociation; and weak ionization. In near-continuum  hypersonic flow  the nonequilibrium thermochemical models employed in continuum and particle simulations produce nearly identical solutions. Further  the two approaches are evaluated successfully against available experimental data for weakly and strongly dissociating flows.Neptune: An astrophysical smooth particle hydrodynamics code for massively parallel computer architecturesNASA Astrophysics Data System (ADS)Sandalski  StouSmooth particle hydrodynamics is an efficient method for modeling the dynamics of fluids. It is commonly used to simulate astrophysical processes such as binary mergers. We present a newly developed GPU accelerated smooth particle hydrodynamics code for astrophysical simulations. The code is named neptune after the Roman god of water. It is written in OpenMP parallelized C++ and OpenCL and includes octree based hydrodynamic and gravitational acceleration. The design relies on object-oriented methodologies in order to provide a flexible and modular framework that can be easily extended and modified by the user. Several pre-built scenarios for simulating collisions of polytropes and black-hole accretion are provided. The code is released under the MIT Open Source license and publicly available at http://code.google.com/p/neptune-sph/.Dakota  a multilevel parallel object-oriented framework for design optimization  parameter estimation  uncertainty quantification  and sensitivity analysis version 6.0 theory manualSciTech ConnectAdams  Brian M.; Ebeida  Mohamed Salah; Eldred  Michael SThe Dakota (Design Analysis Kit for Optimization and Terascale Applications) toolkit provides a exible and extensible interface between simulation codes and iterative analysis methods. Dakota contains algorithms for optimization with gradient and nongradient-based methods; uncertainty quanti cation with sampling  reliability  and stochastic expansion methods; parameter estimation with nonlinear least squares methods; and sensitivity/variance analysis with design of experiments and parameter study methods. These capabilities may be used on their own or as components within advanced strategies such as surrogate-based optimization  mixed integer nonlinear programming  or optimization under uncertainty. By employing object-oriented design to implement abstractions of the key components requiredmoreÂ Â» for iterative systems analyses  the Dakota toolkit provides a exible and extensible problem-solving environment for design and performance analysis of computational models on high performance computers. This report serves as a theoretical manual for selected algorithms implemented within the Dakota software. It is not intended as a comprehensive theoretical treatment  since a number of existing texts cover general optimization theory  statistical analysis  and other introductory topics. Rather  this manual is intended to summarize a set of Dakota-related research publications in the areas of surrogate-based optimization  uncertainty quanti cation  and optimization under uncertainty that provide the foundation for many of Dakota's iterative analysis capabilities.Â«Â lessAdditional extensions to the NASCAP computer code  volume 3NASA Technical Reports Server (NTRS)Mandell  M. J.; Cooke  D. L.1981-01-01The ION computer code is designed to calculate charge exchange ion densities  electric potentials  plasma temperatures  and current densities external to a neutralized ion engine in R-Z geometry. The present version assumes the beam ion current and density to be known and specified  and the neutralizing electrons to originate from a hot-wire ring surrounding the beam orifice. The plasma is treated as being resistive  with an electron relaxation time comparable to the plasma frequency. Together with the thermal and electrical boundary conditions described below and other straightforward engine parameters  these assumptions suffice to determine the required quantities. The ION code  written in ASCII FORTRAN for UNIVAC 1100 series computers  is designed to be run interactively  although it can also be run in batch mode. The input is free-format  and the output is mainly graphical  using the machine-independent graphics developed for the NASCAP code. The executive routine calls the code's major subroutines in user-specified order  and the code allows great latitude for restart and parameter change.[An object-oriented remote sensing image segmentation approach based on edge detection].PubMedTan  Yu-Min; Huai  Jian-Zhu; Tang  Zhong-Shi2010-06-01Satellite sensor technology endorsed better discrimination of various landscape objects. Image segmentation approaches to extracting conceptual objects and patterns hence have been explored and a wide variety of such algorithms abound. To this end  in order to effectively utilize edge and topological information in high resolution remote sensing imagery  an object-oriented algorithm combining edge detection and region merging is proposed. Susan edge filter is firstly applied to the panchromatic band of Quickbird imagery with spatial resolution of 0.61 m to obtain the edge map. Thanks to the resulting edge map  a two-phrase region-based segmentation method operates on the fusion image from panchromatic and multispectral Quickbird images to get the final partition result. In the first phase  a quad tree grid consisting of squares with sides parallel to the image left and top borders agglomerates the square subsets recursively where the uniform measure is satisfied to derive image object primitives. Before the merger of the second phrase  the contextual and spatial information  (e. g.  neighbor relationship  boundary coding) of the resulting squares are retrieved efficiently by means of the quad tree structure. Then a region merging operation is performed with those primitives  during which the criterion for region merging integrates edge map and region-based features. This approach has been tested on the QuickBird images of some site in Sanxia area and the result is compared with those of ENVI Zoom Definiens. In addition  quantitative evaluation of the quality of segmentation results is also presented. Experiment results demonstrate stable convergence and efficiency.New Parallel computing framework for radiation transport codesSciTech ConnectKostin  M.A.; /Michigan State U.  NSCL; Mokhov  N.V.A new parallel computing framework has been developed to use with general-purpose radiation transport codes. The framework was implemented as a C++ module that uses MPI for message passing. The module is significantly independent of radiation transport codes it can be used with  and is connected to the codes by means of a number of interface functions. The framework was integrated with the MARS15 code  and an effort is under way to deploy it in PHITS. Besides the parallel computing functionality  the framework offers a checkpoint facility that allows restarting calculations with a saved checkpoint file. The checkpoint facility canmoreÂ Â» be used in single process calculations as well as in the parallel regime. Several checkpoint files can be merged into one thus combining results of several calculations. The framework also corrects some of the known problems with the scheduling and load balancing found in the original implementations of the parallel computing functionality in MARS15 and PHITS. The framework can be used efficiently on homogeneous systems and networks of workstations  where the interference from the other users is possible.Â«Â lessObject-oriented regression for building predictive models with high dimensional omics data from translational studies.PubMedZhao  Lue Ping; Bolouri  Hamid2016-04-01Maturing omics technologies enable researchers to generate high dimension omics data (HDOD) routinely in translational clinical studies. In the field of oncology  The Cancer Genome Atlas (TCGA) provided funding support to researchers to generate different types of omics data on a common set of biospecimens with accompanying clinical data and has made the data available for the research community to mine. One important application  and the focus of this manuscript  is to build predictive models for prognostic outcomes based on HDOD. To complement prevailing regression-based approaches  we propose to use an object-oriented regression (OOR) methodology to identify exemplars specified by HDOD patterns and to assess their associations with prognostic outcome. Through computing patient's similarities to these exemplars  the OOR-based predictive model produces a risk estimate using a patient's HDOD. The primary advantages of OOR are twofold: reducing the penalty of high dimensionality and retaining the interpretability to clinical practitioners. To illustrate its utility  we apply OOR to gene expression data from non-small cell lung cancer patients in TCGA and build a predictive model for prognostic survivorship among stage I patients  i.e.  we stratify these patients by their prognostic survival risks beyond histological classifications. Identification of these high-risk patients helps oncologists to develop effective treatment protocols and post-treatment disease management plans. Using the TCGA data  the total sample is divided into training and validation data sets. After building up a predictive model in the training set  we compute risk scores from the predictive model  and validate associations of risk scores with prognostic outcome in the validation data (P-value=0.015). Copyright Â© 2016 Elsevier Inc. All rights reserved.Object-Oriented Regression for Building Predictive Models with High Dimensional Omics Data from Translational StudiesPubMed CentralZhao  Lue Ping; Bolouri  Hamid2016-01-01Maturing omics technologies enable researchers to generate high dimension omics data (HDOD) routinely in translational clinical studies. In the field of oncology  The Cancer Genome Atlas (TCGA) provided funding support to researchers to generate different types of omics data on a common set of biospecimens with accompanying clinical data and to make the data available for the research community to mine. One important application  and the focus of this manuscript  is to build predictive models for prognostic outcomes based on HDOD. To complement prevailing regression-based approaches  we propose to use an object-oriented regression (OOR) methodology to identify exemplars specified by HDOD patterns and to assess their associations with prognostic outcome. Through computing patientâ€™s similarities to these exemplars  the OOR-based predictive model produces a risk estimate using a patientâ€™s HDOD. The primary advantages of OOR are twofold: reducing the penalty of high dimensionality and retaining the interpretability to clinical practitioners. To illustrate its utility  we apply OOR to gene expression data from non-small cell lung cancer patients in TCGA and build a predictive model for prognostic survivorship among stage I patients  i.e.  we stratify these patients by their prognostic survival risks beyond histological classifications. Identification of these high-risk patients helps oncologists to develop effective treatment protocols and post-treatment disease management plans. Using the TCGA data  the total sample is divided into training and validation data sets. After building up a predictive model in the training set  we compute risk scores from the predictive model  and validate associations of risk scores with prognostic outcome in the validation data (p=0.015). PMID:26972839The Nature of an Object-Oriented Program: How Do Practitioners Understand the Nature of What They Are Creating?ERIC Educational Resources Information CenterThompson  Errol; Kinshuk2011-01-01Object-oriented programming is seen as a difficult skill to master. There is considerable debate about the most appropriate way to introduce novice programmers to object-oriented concepts. Is it possible to uncover what the critical aspects or features are that enhance the learning of object-oriented programming? Practitioners have differingâ€¦Integration of object-oriented knowledge representation with the CLIPS rule based systemNASA Technical Reports Server (NTRS)Logie  David S.; Kamil  Hasan1990-01-01The paper describes a portion of the work aimed at developing an integrated  knowledge based environment for the development of engineering-oriented applications. An Object Representation Language (ORL) was implemented in C++ which is used to build and modify an object-oriented knowledge base. The ORL was designed in such a way so as to be easily integrated with other representation schemes that could effectively reason with the object base. Specifically  the integration of the ORL with the rule based system C Language Production Systems (CLIPS)  developed at the NASA Johnson Space Center  will be discussed. The object-oriented knowledge representation provides a natural means of representing problem data as a collection of related objects. Objects are comprised of descriptive properties and interrelationships. The object-oriented model promotes efficient handling of the problem data by allowing knowledge to be encapsulated in objects. Data is inherited through an object network via the relationship links. Together  the two schemes complement each other in that the object-oriented approach efficiently handles problem data while the rule based knowledge is used to simulate the reasoning process. Alone  the object based knowledge is little more than an object-oriented data storage scheme; however  the CLIPS inference engine adds the mechanism to directly and automatically reason with that knowledge. In this hybrid scheme  the expert system dynamically queries for data and can modify the object base with complete access to all the functionality of the ORL from rules.Integration of the Gene Ontology into an object-oriented architecturePubMed CentralShegogue  Daniel; Zheng  W Jim2005-01-01Background To standardize gene product descriptions  a formal vocabulary defined as the Gene Ontology (GO) has been developed. GO terms have been categorized into biological processes  molecular functions  and cellular components. However  there is no single representation that integrates all the terms into one cohesive model. Furthermore  GO definitions have little information explaining the underlying architecture that forms these terms  such as the dynamic and static events occurring in a process. In contrast  object-oriented models have been developed to show dynamic and static events. A portion of the TGF-beta signaling pathway  which is involved in numerous cellular events including cancer  differentiation and development  was used to demonstrate the feasibility of integrating the Gene Ontology into an object-oriented model. Results Using object-oriented models we have captured the static and dynamic events that occur during a representative GO process  ""transforming growth factor-beta (TGF-beta) receptor complex assembly"" (GO:0007181). Conclusion We demonstrate that the utility of GO terms can be enhanced by object-oriented technology  and that the GO terms can be integrated into an object-oriented model by serving as a basis for the generation of object functions and attributes. PMID:15885145Integration of the Gene Ontology into an object-oriented architecture.PubMedShegogue  Daniel; Zheng  W Jim2005-05-10To standardize gene product descriptions  a formal vocabulary defined as the Gene Ontology (GO) has been developed. GO terms have been categorized into biological processes  molecular functions  and cellular components. However  there is no single representation that integrates all the terms into one cohesive model. Furthermore  GO definitions have little information explaining the underlying architecture that forms these terms  such as the dynamic and static events occurring in a process. In contrast  object-oriented models have been developed to show dynamic and static events. A portion of the TGF-beta signaling pathway  which is involved in numerous cellular events including cancer  differentiation and development  was used to demonstrate the feasibility of integrating the Gene Ontology into an object-oriented model. Using object-oriented models we have captured the static and dynamic events that occur during a representative GO process  ""transforming growth factor-beta (TGF-beta) receptor complex assembly"" (GO:0007181). We demonstrate that the utility of GO terms can be enhanced by object-oriented technology  and that the GO terms can be integrated into an object-oriented model by serving as a basis for the generation of object functions and attributes.Object-oriented design tools for supramolecular devices and biomedical nanotechnology.PubMedLee  Stephen C; Bhalerao  Khaustaub; Ferrari  Mauro2004-05-01Nanotechnology provides multifunctional agents for in vivo use that increasingly blur the distinction between pharmaceuticals and medical devices. Realization of such therapeutic nanodevices requires multidisciplinary effort that is difficult for individual device developers to sustain  and identification of appropriate collaborations outside ones own field can itself be challenging. Further  as in vivo nanodevices become increasingly complex  their design will increasingly demand systems level thinking. System engineering tools such as object-oriented analysis  object-oriented design (OOA/D) and unified modeling language (UML) are applicable to nanodevices built from biological components  help logically manage the knowledge needed to design them  and help identify useful collaborative relationships for device designers. We demonstrate the utility of these systems engineering tools by reverse engineering an existing molecular device (the bacmid molecular cloning system) using them  and illustrate how object-oriented approaches identify fungible components (objects) in nanodevices in a way that facilitates design of families of related devices  rather than single inventions. We also explore the utility of object-oriented approaches for design of another class of therapeutic nanodevices  vaccines. While they are useful for design of current nanodevices  the power of systems design tools for biomedical nanotechnology will become increasingly apparent as the complexity and sophistication of in vivo nanosystems increases. The nested  hierarchical nature of object-oriented approaches allows treatment of devices as objects in higher-order structures  and so will facilitate concatenation of multiple devices into higher-order  higher-function nanosystems.War of Ontology Worlds: Mathematics  Computer Code  or Esperanto?PubMed CentralRzhetsky  Andrey; Evans  James A.2011-01-01The use of structured knowledge representationsâ€”ontologies and terminologiesâ€”has become standard in biomedicine. Definitions of ontologies vary widely  as do the values and philosophies that underlie them. In seeking to make these views explicit  we conducted and summarized interviews with a dozen leading ontologists. Their views clustered into three broad perspectives that we summarize as mathematics  computer code  and Esperanto. Ontology as mathematics puts the ultimate premium on rigor and logic  symmetry and consistency of representation across scientific subfields  and the inclusion of only established  non-contradictory knowledge. Ontology as computer code focuses on utility and cultivates diversity  fitting ontologies to their purpose. Like computer languages C++  Prolog  and HTML  the code perspective holds that diverse applications warrant custom designed ontologies. Ontology as Esperanto focuses on facilitating cross-disciplinary communication  knowledge cross-referencing  and computation across datasets from diverse communities. We show how these views align with classical divides in science and suggest how a synthesis of their concerns could strengthen the next generation of biomedical ontologies. PMID:21980276Convergence acceleration of the Proteus computer code with multigrid methodsNASA Technical Reports Server (NTRS)Demuren  A. O.; Ibraheem  S. O.1995-01-01This report presents the results of a study to implement convergence acceleration techniques based on the multigrid concept in the two-dimensional and three-dimensional versions of the Proteus computer code. The first section presents a review of the relevant literature on the implementation of the multigrid methods in computer codes for compressible flow analysis. The next two sections present detailed stability analysis of numerical schemes for solving the Euler and Navier-Stokes equations  based on conventional von Neumann analysis and the bi-grid analysis  respectively. The next section presents details of the computational method used in the Proteus computer code. Finally  the multigrid implementation and applications to several two-dimensional and three-dimensional test problems are presented. The results of the present study show that the multigrid method always leads to a reduction in the number of iterations (or time steps) required for convergence. However  there is an overhead associated with the use of multigrid acceleration. The overhead is higher in 2-D problems than in 3-D problems  thus overall multigrid savings in CPU time are in general better in the latter. Savings of about 40-50 percent are typical in 3-D problems  but they are about 20-30 percent in large 2-D problems. The present multigrid method is applicable to steady-state problems and is therefore ineffective in problems with inherently unstable solutions.War of ontology worlds: mathematics  computer code  or Esperanto?PubMedRzhetsky  Andrey; Evans  James A2011-09-01The use of structured knowledge representations-ontologies and terminologies-has become standard in biomedicine. Definitions of ontologies vary widely  as do the values and philosophies that underlie them. In seeking to make these views explicit  we conducted and summarized interviews with a dozen leading ontologists. Their views clustered into three broad perspectives that we summarize as mathematics  computer code  and Esperanto. Ontology as mathematics puts the ultimate premium on rigor and logic  symmetry and consistency of representation across scientific subfields  and the inclusion of only established  non-contradictory knowledge. Ontology as computer code focuses on utility and cultivates diversity  fitting ontologies to their purpose. Like computer languages C++  Prolog  and HTML  the code perspective holds that diverse applications warrant custom designed ontologies. Ontology as Esperanto focuses on facilitating cross-disciplinary communication  knowledge cross-referencing  and computation across datasets from diverse communities. We show how these views align with classical divides in science and suggest how a synthesis of their concerns could strengthen the next generation of biomedical ontologies.CFD and Neutron codes coupling on a computational platformNASA Astrophysics Data System (ADS)Cerroni  D.; Da ViÃ   R.; Manservisi  S.; Menghini  F.; Scardovelli  R.2017-01-01In this work we investigate the thermal-hydraulics behavior of a PWR nuclear reactor core  evaluating the power generation distribution taking into account the local temperature field. The temperature field  evaluated using a self-developed CFD module  is exchanged with a neutron code  DONJON-DRAGON  which updates the macroscopic cross sections and evaluates the new neutron flux. From the updated neutron flux the new peak factor is evaluated and the new temperature field is computed. The exchange of data between the two codes is obtained thanks to their inclusion into the computational platform SALOME  an open-source tools developed by the collaborative project NURESAFE. The numerical libraries MEDmem  included into the SALOME platform  are used in this work  for the projection of computational fields from one problem to another. The two problems are driven by a common supervisor that can access to the computational fields of both systems  in every time step  the temperature field  is extracted from the CFD problem and set into the neutron problem. After this iteration the new power peak factor is projected back into the CFD problem and the new time step can be computed. Several computational examples  where both neutron and thermal-hydraulics quantities are parametrized  are finally reported in this work.Additional extensions to the NASCAP computer code  volume 1NASA Technical Reports Server (NTRS)Mandell  M. J.; Katz  I.; Stannard  P. R.1981-01-01Extensions and revisions to a computer code that comprehensively analyzes problems of spacecraft charging (NASCAP) are documented. Using a fully three dimensional approach  it can accurately predict spacecraft potentials under a variety of conditions. Among the extensions are a multiple electron/ion gun test tank capability  and the ability to model anisotropic and time dependent space environments. Also documented are a greatly extended MATCHG program and the preliminary version of NASCAP/LEO. The interactive MATCHG code was developed into an extremely powerful tool for the study of material-environment interactions. The NASCAP/LEO  a three dimensional code to study current collection under conditions of high voltages and short Debye lengths  was distributed for preliminary testing.A three-dimensional spacecraft-charging computer codeNASA Technical Reports Server (NTRS)Rubin  A. G.; Katz  I.; Mandell  M.; Schnuelle  G.; Steen  P.; Parks  D.; Cassidy  J.; Roche  J.1980-01-01A computer code is described which simulates the interaction of the space environment with a satellite at geosynchronous altitude. Employing finite elements  a three-dimensional satellite model has been constructed with more than 1000 surface cells and 15 different surface materials. Free space around the satellite is modeled by nesting grids within grids. Applications of this NASA Spacecraft Charging Analyzer Program (NASCAP) code to the study of a satellite photosheath and the differential charging of the SCATHA (satellite charging at high altitudes) satellite in eclipse and in sunlight are discussed. In order to understand detector response when the satellite is charged  the code is used to trace the trajectories of particles reaching the SCATHA detectors. Particle trajectories from positive and negative emitters on SCATHA also are traced to determine the location of returning particles  to estimate the escaping flux  and to simulate active control of satellite potentials.Three-quarter views are subjectively good because object orientation is uncertain.PubMedNiimi  Ryosuke; Yokosawa  Kazuhiko2009-04-01Because the objects that surround us are three-dimensional  their appearance and our visual perception of them change depending on an object's orientation relative to a viewpoint. One of the most remarkable effects of object orientation is that viewers prefer three-quarter views over others  such as front and back  but the exact source of this preference has not been firmly established. We show that object orientation perception of the three-quarter view is relatively imprecise and that this impreciseness is related to preference for this view. Human vision is largely insensitive to variations among different three-quarter views (e.g.  45 degrees vs. 50 degrees ); therefore  the three-quarter view is perceived as if it corresponds to a wide range of orientations. In other words  it functions as the typical representation of the object.Direct evaluation of fault trees using object-oriented programming techniquesNASA Technical Reports Server (NTRS)Patterson-Hine  F. A.; Koen  B. V.1989-01-01Object-oriented programming techniques are used in an algorithm for the direct evaluation of fault trees. The algorithm combines a simple bottom-up procedure for trees without repeated events with a top-down recursive procedure for trees with repeated events. The object-oriented approach results in a dynamic modularization of the tree at each step in the reduction process. The algorithm reduces the number of recursive calls required to solve trees with repeated events and calculates intermediate results as well as the solution of the top event. The intermediate results can be reused if part of the tree is modified. An example is presented in which the results of the algorithm implemented with conventional techniques are compared to those of the object-oriented approach.An ECG storage and retrieval system embedded in client server HIS utilizing object-oriented DB.PubMedWang  C; Ohe  K; Sakurai  T; Nagase  T; Kaihara  S1996-02-01In the University of Tokyo Hospital  the improved client server HIS has been applied to clinical practice and physicians can order prescription  laboratory examination  ECG examination and radiographic examination  etc. directly by themselves and read results of these examinations  except medical signal waves  schema and image  on UNIX workstations. Recently  we designed and developed an ECG storage and retrieval system embedded in the client server HIS utilizing object-oriented database to take the first step in dealing with digitized signal  schema and image data and show waves  graphics  and images directly to physicians by the client server HIS. The system was developed based on object-oriented analysis and design  and implemented with object-oriented database management system (OODMS) and C++ programming language. In this paper  we describe the ECG data model  functions of the storage and retrieval system  features of user interface and the result of its implementation in the HIS.[Object-oriented remote sensing image classification in epidemiological studies of visceral leishmaniasis in urban areas].PubMedAlmeida  AndrÃ©a Sobral de; Werneck  Guilherme Loureiro; Resendes  Ana Paula da Costa2014-08-01This study explored the use of object-oriented classification of remote sensing imagery in epidemiological studies of visceral leishmaniasis (VL) in urban areas. To obtain temperature and environmental information  an object-oriented classification approach was applied to Landsat 5 TM scenes from the city of Teresina  PiauÃ­ State  Brazil. For 1993-1996  VL incidence rates correlated positively with census tracts covered by dense vegetation  grass/pasture  and bare soil and negatively with areas covered by water and densely populated areas. In 2001-2006  positive correlations were found with dense vegetation  grass/pasture  bare soil  and densely populated areas and negative correlations with occupied urban areas with some vegetation. Land surface temperature correlated negatively with VL incidence in both periods. Object-oriented classification can be useful to characterize landscape features associated with VL in urban areas and to help identify risk areas in order to prioritize interventions.Considerations of persistence and security in CHOICES  an object-oriented operating systemNASA Technical Reports Server (NTRS)Campbell  Roy H.; Madany  Peter W.1990-01-01The current design of the CHOICES persistent object implementation is summarized  and research in progress is outlined. CHOICES is implemented as an object-oriented system  and persistent objects appear to simplify and unify many functions of the system. It is demonstrated that persistent data can be accessed through an object-oriented file system model as efficiently as by an existing optimized commercial file system. The object-oriented file system can be specialized to provide an object store for persistent objects. The problems that arise in building an efficient persistent object scheme in a 32-bit virtual address space that only uses paging are described. Despite its limitations  the solution presented allows quite large numbers of objects to be active simultaneously  and permits sharing and efficient method calls.Development of non-linear finite element computer codeNASA Technical Reports Server (NTRS)Becker  E. B.; Miller  T.1985-01-01Recent work has shown that the use of separable symmetric functions of the principal stretches can adequately describe the response of certain propellant materials and  further  that a data reduction scheme gives a convenient way of obtaining the values of the functions from experimental data. Based on representation of the energy  a computational scheme was developed that allows finite element analysis of boundary value problems of arbitrary shape and loading. The computational procedure was implemental in a three-dimensional finite element code  TEXLESP-S  which is documented herein.The Applicability of Proposed Object-Oriented Metrics to Developer Feedback in Time to Impact DevelopmentNASA Technical Reports Server (NTRS)Neal  Ralph D.1996-01-01This paper looks closely at each of the software metrics generated by the McCabe object-Oriented Tool(TM) and its ability to convey timely information to developers. The metrics are examined for meaningfulness in terms of the scale assignable to the metric by the rules of measurement theory and the software dimension being measured. Recommendations are made as to the proper use of each metric and its ability to influence development at an early stage. The metrics of the McCabe Object-Oriented Tool(TM) set were selected because of the tool's use in a couple of NASA IV&V projects.Object-orientated DBMS techniques for time-oriented medical record.PubMedPinciroli  F; Combi  C; Pozzi  G1992-01-01In implementing time-orientated medical record (TOMR) management systems  use of a relational model played a big role. Many applications have been developed to extend query and data manipulation languages to temporal aspects of information. Our experience in developing TOMR revealed some deficiencies inside the relational model  such as: (a) abstract data type definition; (b) unified view of data  at a programming level; (c) management of temporal data; (d) management of signals and images. We identified some first topics to face by an object-orientated approach to database design. This paper describes the first steps in designing and implementing a TOMR by an object-orientated DBMS.Verification and benchmark testing of the NUFT computer codeNASA Astrophysics Data System (ADS)Lee  K. H.; Nitao  J. J.; Kulshrestha  A.1993-10-01This interim report presents results of work completed in the ongoing verification and benchmark testing of the NUFT (Nonisothermal Unsaturated-saturated Flow and Transport) computer code. NUFT is a suite of multiphase  multicomponent models for numerical solution of thermal and isothermal flow and transport in porous media  with application to subsurface contaminant transport problems. The code simulates the coupled transport of heat  fluids  and chemical components  including volatile organic compounds. Grid systems may be cartesian or cylindrical  with one-  two-  or fully three-dimensional configurations possible. In this initial phase of testing  the NUFT code was used to solve seven one-dimensional unsaturated flow and heat transfer problems. Three verification and four benchmarking problems were solved. In the verification testing  excellent agreement was observed between NUFT results and the analytical or quasianalytical solutions. In the benchmark testing  results of code intercomparison were very satisfactory. From these testing results  it is concluded that the NUFT code is ready for application to field and laboratory problems similar to those addressed here. Multidimensional problems  including those dealing with chemical transport  will be addressed in a subsequent report.Aquarius' Object-Oriented  Plug and Play Component-Based Flight SoftwareNASA Technical Reports Server (NTRS)Murray  Alexander; Shahabuddin  Mohammad2013-01-01The Aquarius mission involves a combined radiometer and radar instrument in low-Earth orbit  providing monthly global maps of Sea Surface Salinity. Operating successfully in orbit since June  2011  the spacecraft bus was furnished by the Argentine space agency  Comision Nacional de Actividades Espaciales (CONAE). The instrument  built jointly by NASA's Caltech/JPL and Goddard Space Flight Center  has been successfully producing expectation-exceeding data since it was powered on in August of 2011. In addition to the radiometer and scatterometer  the instrument contains an command & data-handling subsystem with a computer and flight software (FSW) that is responsible for managing the instrument  its operation  and its data. Aquarius' FSW is conceived and architected as a Component-based system  in which the running software consists of a set of Components  each playing a distinctive role in the subsystem  instantiated and connected together at runtime. Component architectures feature a well-defined set of interfaces between the Components  visible and analyzable at the architectural level (see [1]). As we will describe  this kind of an architecture offers significant advantages over more traditional FSW architectures  which often feature a monolithic runtime structure. Component-based software is enabled by Object-Oriented (OO) techniques and languages  the use of which again is not typical in space mission FSW. We will argue in this paper that the use of OO design methods and tools (especially the Unified Modeling Language)  as well as the judicious usage of C++  are very well suited to FSW applications  and we will present Aquarius FSW  describing our methods  processes  and design  as a successful case in point.Code manual for CONTAIN 2.0: A computer code for nuclear reactor containment analysisSciTech ConnectMurata  K.K.; Williams  D.C.; Griffith  R.O.1997-12-01The CONTAIN 2.0 computer code is an integrated analysis tool used for predicting the physical conditions  chemical compositions  and distributions of radiological materials inside a containment building following the release of material from the primary system in a light-water reactor accident. It can also predict the source term to the environment. CONTAIN 2.0 is intended to replace the earlier CONTAIN 1.12  which was released in 1991. The purpose of this Code Manual is to provide full documentation of the features and models in CONTAIN 2.0. Besides complete descriptions of the models  this Code Manual provides a complete description of themoreÂ Â» input and output from the code. CONTAIN 2.0 is a highly flexible and modular code that can run problems that are either quite simple or highly complex. An important aspect of CONTAIN is that the interactions among thermal-hydraulic phenomena  aerosol behavior  and fission product behavior are taken into account. The code includes atmospheric models for steam/air thermodynamics  intercell flows  condensation/evaporation on structures and aerosols  aerosol behavior  and gas combustion. It also includes models for reactor cavity phenomena such as core-concrete interactions and coolant pool boiling. Heat conduction in structures  fission product decay and transport  radioactive decay heating  and the thermal-hydraulic and fission product decontamination effects of engineered safety features are also modeled. To the extent possible  the best available models for severe accident phenomena have been incorporated into CONTAIN  but it is intrinsic to the nature of accident analysis that significant uncertainty exists regarding numerous phenomena. In those cases  sensitivity studies can be performed with CONTAIN by means of user-specified input parameters. Thus  the code can be viewed as a tool designed to assist the knowledge reactor safety analyst in evaluating the consequences of specific modeling assumptions.Â«Â lessA Software Designed For STP Data Plot and Analysis Based on Object-oriented MethodologyNASA Astrophysics Data System (ADS)Lina  L.; Murata  K.2006-12-01In the present study  we design a system that is named ""STARS (Solar-Terrestrial data Analysis and Reference System)"". The STARS provides a research environment that researchers can refer to and analyse a variety of data with single software. This software design is based on the OMT (Object Modeling Technique). The OMT is one of the object-oriented techniques  which has an advantage in maintenance improvement  reuse and long time development of a system. At the Center for Information Technology  Ehime University  after our designing of the STARS  we have already started implementing the STARS. The latest version of the STARS  the STARS5  was released in 2006. Any user can download the system from our WWW site (http:// www.infonet.cite.ehime-u.ac.jp/STARS). The present paper is mainly devoted to the design of a data analysis software system. Through our designing  we paid attention so that the design is flexible and applicable when other developers design software for the similar purpose. If our model is so particular only for our own purpose  it would be useless for other developers. Through our design of the domain object model  we carefully removed the parts  which depend on the system resources  e.g. hardware and software. We put the dependent parts into the application object model. In the present design  therefore  the domain object model and the utility object model are independent of computer resource. This helps anther developer to construct his/her own system based the present design. They simply modify their own application object models according to their system resource. This division of the design between dependent and independent part into three object models is one of the advantages in the OMT. If the design of software is completely done along with the OMT  implementation is rather simple and automatic: developers simply map their designs on our programs. If one creates ""ganother STARS"" with other programming language such as Java  the programmerIncorporating Manual and Autonomous Code GenerationNASA Technical Reports Server (NTRS)McComas  David1998-01-01Code can be generated manually or using code-generated software tools  but how do you interpret the two? This article looks at a design methodology that combines object-oriented design with autonomic code generation for attitude control flight software. Recent improvements in space flight computers are allowing software engineers to spend more time engineering the applications software. The application developed was the attitude control flight software for an astronomical satellite called the Microwave Anisotropy Probe (MAP). The MAP flight system is being designed  developed  and integrated at NASA's Goddard Space Flight Center. The MAP controls engineers are using Integrated Systems Inc.'s MATRIXx for their controls analysis. In addition to providing a graphical analysis for an environment  MATRIXx includes an autonomic code generation facility called AutoCode. This article examines the forces that shaped the final design and describes three highlights of the design process: (1) Defining the manual to autonomic code interface; (2) Applying object-oriented design to the manual flight code; (3) Implementing the object-oriented design in C.Mirror-Image Confusions: Implications for Representation and Processing of Object OrientationERIC Educational Resources Information CenterGregory  Emma; McCloskey  Michael2010-01-01Perceiving the orientation of objects is important for interacting with the world  yet little is known about the mental representation or processing of object orientation information. The tendency of humans and other species to confuse mirror images provides a potential clue. However  the appropriate characterization of this phenomenon is notâ€¦BlueJ Visual Debugger for Learning the Execution of Object-Oriented Programs?ERIC Educational Resources Information CenterBennedsen  Jens; Schulte  Carsten2010-01-01This article reports on an experiment undertaken in order to evaluate the effect of a program visualization tool for helping students to better understand the dynamics of object-oriented programs. The concrete tool used was BlueJ's debugger and object inspector. The study was done as a control-group experiment in an introductory programmingâ€¦An object-oriented forest landscape model and its representation of tree speciesTreesearchHong S. He; David J. Mladenoff; Joel Boeder1999-01-01LANDIS is a forest landscape model that simulates the interaction of large landscape processes and forest successional dynamics at tree species level. We discuss how object-oriented design (OOD) approaches such as modularity  abstraction and encapsulation are integrated into the design of LANDIS. We show that using OOD approaches  model decisions (olden as model...Analyzing the Quality of Students Interaction in a Distance Learning Object-Oriented Programming DisciplineERIC Educational Resources Information CenterCarvalho  Elizabeth SimÃ£o2015-01-01Teaching object-oriented programming to students in an in-classroom environment demands well-thought didactic and pedagogical strategies in order to guarantee a good level of apprenticeship. To teach it on a completely distance learning environment (e-learning) imposes possibly other strategies  besides those that the e-learning model of Openâ€¦Exploring the Synergies between the Object Oriented Paradigm and Mathematics: A Java Led ApproachERIC Educational Resources Information CenterConrad  Marc; French  Tim2004-01-01While the object oriented paradigm and its instantiation within programming languages such as Java has become a ubiquitous part of both the commercial and educational landscapes  its usage as a visualization technique within mathematics undergraduate programmes of study has perhaps been somewhat underestimated. By regarding the object orientedâ€¦The Object Oriented Approach in Systems Analysis and Design Texts: Consistency within the IS CurriculumERIC Educational Resources Information CenterWood  David F.; Kohun  Frederick G.; Laverty  Joseph Packy2010-01-01This paper reports on a study of systems analysis textbooks in terms of topics covered and academic background of the authors. It addresses the consistency within IS curricula with respect to the content of a systems analysis and design course using the object-oriented approach. The research questions addressed were 1: Is there a consistency amongâ€¦Microworlds for Learning Object-Oriented Programming: Considerations from Research to PracticeERIC Educational Resources Information CenterDjelil  Fahima; Albouy-Kissi  Adelaide; Albouy-Kissi  Benjamin; Sanchez  Eric; Lavest  Jean-Marc2016-01-01Object-Oriented paradigm is a common paradigm for introductory programming courses. However  many teachers find that transitioning to teaching this paradigm is a difficult task. To overcome this complexity  many experienced teachers use microworlds to give beginner students an intuitive and rapid understanding of fundamental abstract concepts ofâ€¦Holistic Approach to Learning and Teaching Introductory Object-Oriented ProgrammingERIC Educational Resources Information CenterThota  Neena; Whitfield  Richard2010-01-01This article describes a holistic approach to designing an introductory  object-oriented programming course. The design is grounded in constructivism and pedagogy of phenomenography. We use constructive alignment as the framework to align assessments  learning  and teaching with planned learning outcomes. We plan learning and teaching activities â€¦Enhancing Problem-Solving Capabilities Using Object-Oriented Programming LanguageERIC Educational Resources Information CenterUnuakhalu  Mike F.2009-01-01This study integrated object-oriented programming instruction with transfer training activities in everyday tasks  which might provide a mechanism that can be used for efficient problem solving. Specifically  a Visual BASIC embedded with everyday tasks group was compared to another group exposed to Visual BASIC instruction only. Subjects were 40â€¦The Action Event (Notes on the Development of Object-Oriented Actions II)ERIC Educational Resources Information CenterElkonin  B. D.2015-01-01The article critically rethinks and refashions conceptions of object-oriented actions. The author introduces the concept of an action event  which relies on the work of D. B. Elkonin. The essence of an action event lies in its transition to a new form of activity  that is  an action mediated by a pattern that is given to a child by an adult. Anâ€¦Visual Search for Object Orientation Can Be Modulated by Canonical OrientationERIC Educational Resources Information CenterBallaz  Cecile; Boutsen  Luc; Peyrin  Carole; Humphreys  Glyn W.; Marendaz  Christian2005-01-01The authors studied the influence of canonical orientation on visual search for object orientation. Displays consisted of pictures of animals whose axis of elongation was either vertical or tilted in their canonical orientation. Target orientation could be either congruent or incongruent with the object's canonical orientation. In Experiment 1 â€¦Diagram  a Learning Environment for Initiation to Object-Oriented Modeling with UML Class DiagramsERIC Educational Resources Information CenterPy  Dominique; Auxepaules  Ludovic; Alonso  Mathilde2013-01-01This paper presents Diagram  a learning environment for object-oriented modelling (OOM) with UML class diagrams. Diagram an open environment  in which the teacher can add new exercises without constraints on the vocabulary or the size of the diagram. The interface includes methodological help  encourages self-correcting and self-monitoring  andâ€¦Multi-User Domain Object Oriented (MOO) as a High School Procedure for Foreign Language Acquisition.ERIC Educational Resources Information CenterBacker  James A.Foreign language students experience added difficulty when they are isolated from native speakers and from the culture of the target language. It has been posited that MOO (Multi-User Domain Object Oriented) may help overcome the geographical isolation of these students. MOOs are Internet-based virtual worlds in which people from all over the realâ€¦Target-object integration  attention distribution  and object orientation interactively modulate object-based selection.PubMedAl-Janabi  Shahd; Greenberg  Adam S2016-10-01The representational basis of attentional selection can be object-based. Various studies have suggested  however  that object-based selection is less robust than spatial selection across experimental paradigms. We sought to examine the manner by which the following factors might explain this variation: Target-Object Integration (targets 'on' vs. part 'of' an object)  Attention Distribution (narrow vs. wide)  and Object Orientation (horizontal vs. vertical). In Experiment 1  participants discriminated between two targets presented 'on' an object in one session  or presented as a change 'of' an object in another session. There was no spatial cue-thus  attention was initially focused widely-and the objects were horizontal or vertical. We found evidence of object-based selection only when targets constituted a change 'of' an object. Additionally  object orientation modulated the sign of object-based selection: We observed a same-object advantage for horizontal objects  but a same-object cost for vertical objects. In Experiment 2  an informative cue preceded a single target presented 'on' an object or as a change 'of' an object (thus  attention was initially focused narrowly). Unlike in Experiment 1  we found evidence of object-based selection independent of target-object integration. We again found that the sign of selection was modulated by the objects' orientation. This result may reflect a meridian effect  which emerged due to anisotropies in the cortical representations when attention is oriented endogenously. Experiment 3 revealed that object orientation did not modulate object-based selection when attention was oriented exogenously. Our findings suggest that target-object integration  attention distribution  and object orientation modulate object-based selection  but only in combination.Integrating end-to-end threads of control into object-oriented analysis and designNASA Technical Reports Server (NTRS)Mccandlish  Janet E.; Macdonald  James R.; Graves  Sara J.1993-01-01Current object-oriented analysis and design methodologies fall short in their use of mechanisms for identifying threads of control for the system being developed. The scenarios which typically describe a system are more global than looking at the individual objects and representing their behavior. Unlike conventional methodologies that use data flow and process-dependency diagrams  object-oriented methodologies do not provide a model for representing these global threads end-to-end. Tracing through threads of control is key to ensuring that a system is complete and timing constraints are addressed. The existence of multiple threads of control in a system necessitates a partitioning of the system into processes. This paper describes the application and representation of end-to-end threads of control to the object-oriented analysis and design process using object-oriented constructs. The issue of representation is viewed as a grouping problem  that is  how to group classes/objects at a higher level of abstraction so that the system may be viewed as a whole with both classes/objects and their associated dynamic behavior. Existing object-oriented development methodology techniques are extended by adding design-level constructs termed logical composite classes and process composite classes. Logical composite classes are design-level classes which group classes/objects both logically and by thread of control information. Process composite classes further refine the logical composite class groupings by using process partitioning criteria to produce optimum concurrent execution results. The goal of these design-level constructs is to ultimately provide the basis for a mechanism that can support the creation of process composite classes in an automated way. Using an automated mechanism makes it easier to partition a system into concurrently executing elements that can be run in parallel on multiple processors.Majorana fermion surface code for universal quantum computationDOE PAGESVijay  Sagar; Hsieh  Timothy H.; Fu  Liang2015-12-10In this study  we introduce an exactly solvable model of interacting Majorana fermions realizing Z 2 topological order with a Z 2 fermion parity grading and lattice symmetries permuting the three fundamental anyon types. We propose a concrete physical realization by utilizing quantum phase slips in an array of Josephson-coupled mesoscopic topological superconductors  which can be implemented in a wide range of solid-state systems  including topological insulators  nanowires  or two-dimensional electron gases  proximitized by s-wave superconductors. Our model finds a natural application as a Majorana fermion surface code for universal quantum computation  with a single-step stabilizer measurement requiring no physicalmoreÂ Â» ancilla qubits  increased error tolerance  and simpler logical gates than a surface code with bosonic physical qubits. We thoroughly discuss protocols for stabilizer measurements  encoding and manipulating logical qubits  and gate implementations.Â«Â lessHeat pipe design handbook  part 2. [digital computer code specificationsNASA Technical Reports Server (NTRS)Skrabek  E. A.1972-01-01The utilization of a digital computer code for heat pipe analysis and design (HPAD) is described which calculates the steady state hydrodynamic heat transport capability of a heat pipe with a particular wick configuration  the working fluid being a function of wick cross-sectional area. Heat load  orientation  operating temperature  and heat pipe geometry are specified. Both one 'g' and zero 'g' environments are considered  and  at the user's option  the code will also perform a weight analysis and will calculate heat pipe temperature drops. The central porous slab  circumferential porous wick  arterial wick  annular wick  and axial rectangular grooves are the wick configurations which HPAD has the capability of analyzing. For Vol. 1  see N74-22569.Computer code for the prediction of nozzle admittanceNASA Technical Reports Server (NTRS)Nguyen  Thong V.1988-01-01A procedure which can accurately characterize injector designs for large thrust (0.5 to 1.5 million pounds)  high pressure (500 to 3000 psia) LOX/hydrocarbon engines is currently under development. In this procedure  a rectangular cross-sectional combustion chamber is to be used to simulate the lower traverse frequency modes of the large scale chamber. The chamber will be sized so that the first width mode of the rectangular chamber corresponds to the first tangential mode of the full-scale chamber. Test data to be obtained from the rectangular chamber will be used to assess the full scale engine stability. This requires the development of combustion stability models for rectangular chambers. As part of the combustion stability model development  a computer code  NOAD based on existing theory was developed to calculate the nozzle admittances for both rectangular and axisymmetric nozzles. This code is detailed.Code Verification of the HIGRAD Computational Fluid Dynamics SolverSciTech ConnectVan Buren  Kendra L.; Canfield  Jesse M.; Hemez  Francois M.2012-05-04The purpose of this report is to outline code and solution verification activities applied to HIGRAD  a Computational Fluid Dynamics (CFD) solver of the compressible Navier-Stokes equations developed at the Los Alamos National Laboratory  and used to simulate various phenomena such as the propagation of wildfires and atmospheric hydrodynamics. Code verification efforts  as described in this report  are an important first step to establish the credibility of numerical simulations. They provide evidence that the mathematical formulation is properly implemented without significant mistakes that would adversely impact the application of interest. Highly accurate analytical solutions are derived for four code verificationmoreÂ Â» test problems that exercise different aspects of the code. These test problems are referred to as: (i) the quiet start  (ii) the passive advection  (iii) the passive diffusion  and (iv) the piston-like problem. These problems are simulated using HIGRAD with different levels of mesh discretization and the numerical solutions are compared to their analytical counterparts. In addition  the rates of convergence are estimated to verify the numerical performance of the solver. The first three test problems produce numerical approximations as expected. The fourth test problem (piston-like) indicates the extent to which the code is able to simulate a 'mild' discontinuity  which is a condition that would typically be better handled by a Lagrangian formulation. The current investigation concludes that the numerical implementation of the solver performs as expected. The quality of solutions is sufficient to provide credible simulations of fluid flows around wind turbines. The main caveat associated to these findings is the low coverage provided by these four problems  and somewhat limited verification activities. A more comprehensive evaluation of HIGRAD may be beneficial for future studies.Â«Â lessAnalysis of the Length of Braille Texts in English Braille American Edition  the Nemeth Code  and Computer Braille Code versus the Unified English Braille CodeERIC Educational Resources Information CenterKnowlton  Marie; Wetzel  Robin2006-01-01This study compared the length of text in English Braille American Edition  the Nemeth code  and the computer braille code with the Unified English Braille Code (UEBC)--also known as Unified English Braille (UEB). The findings indicate that differences in the length of text are dependent on the type of material that is transcribed and the gradeâ€¦Improvements to the fastex flutter analysis computer codeNASA Technical Reports Server (NTRS)Taylor  Ronald F.1987-01-01Modifications to the FASTEX flutter analysis computer code (UDFASTEX) are described. The objectives were to increase the problem size capacity of FASTEX  reduce run times by modification of the modal interpolation procedure  and to add new user features. All modifications to the program are operable on the VAX 11/700 series computers under the VAX operating system. Interfaces were provided to aid in the inclusion of alternate aerodynamic and flutter eigenvalue calculations. Plots can be made of the flutter velocity  display and frequency data. A preliminary capability was also developed to plot contours of unsteady pressure amplitude and phase. The relevant equations of motion  modal interpolation procedures  and control system considerations are described and software developments are summarized. Additional information documenting input instructions  procedures  and details of the plate spline algorithm is found in the appendices.The nature of an object-oriented program: How do practitioners understand the nature of what they are creating?NASA Astrophysics Data System (ADS)Thompson  Errol; Kinshuk2011-09-01Object-oriented programming is seen as a difficult skill to master. There is considerable debate about the most appropriate way to introduce novice programmers to object-oriented concepts. Is it possible to uncover what the critical aspects or features are that enhance the learning of object-oriented programming? Practitioners have differing understandings of the nature of an object-oriented program. Uncovering these different ways of understanding leads to agreater understanding of the critical aspects and their relationship tothe structure of the program produced. A phenomenographic studywas conducted to uncover practitioner understandings of the nature of an object-oriented program. The study identified five levels of understanding and three dimensions of variation within these levels. These levels and dimensions of variation provide a framework for fostering conceptual change with respect to the nature of an object-oriented program.A flexible object-oriented software framework for developing complex multimedia simulations.SciTech ConnectSydelko  P. J.; Dolph  J. E.; Christiansen  J. H.Decision makers involved in brownfields redevelopment and long-term stewardship must consider environmental conditions  future-use potential  site ownership  area infrastructure  funding resources  cost recovery  regulations  risk and liability management  community relations  and expected return on investment in a comprehensive and integrated fashion to achieve desired results. Successful brownfields redevelopment requires the ability to assess the impacts of redevelopment options on multiple interrelated aspects of the ecosystem  both natural and societal. Computer-based tools  such as simulation models  databases  and geographical information systems (GISs) can be used to address brownfields planning and project execution. The transparent integration of these tools into a comprehensivemoreÂ Â» and dynamic decision support system would greatly enhance the brownfields assessment process. Such a system needs to be able to adapt to shifting and expanding analytical requirements and contexts. The Dynamic Information Architecture System (DIAS) is a flexible  extensible  object-oriented framework for developing and maintaining complex multidisciplinary simulations of a wide variety of application domains. The modeling domain of a specific DIAS-based simulation is determined by (1) software objects that represent the real-world entities that comprise the problem space (atmosphere  watershed  human)  and (2) simulation models and other data processing applications that express the dynamic behaviors of the domain entities. Models and applications used to express dynamic behaviors can be either internal or external to DIAS  including existing legacy models written in various languages (FORTRAN  C  etc.). The flexible design framework of DIAS makes the objects adjustable to the context of the problem without a great deal of recoding. The DIAS Spatial Data Set facility allows parameters to vary spatially depending on the simulation context according to any of a number of 1-DAutomatic pre-processing for an object-oriented distributed hydrological model using GRASS-GISNASA Astrophysics Data System (ADS)Sanzana  P.; Jankowfsky  S.; Branger  F.; Braud  I.; Vargas  X.; Hitschfeld  N.2012-04-01Landscapes are very heterogeneous  which impact the hydrological processes occurring in the catchments  especially in the modeling of peri-urban catchments. The Hydrological Response Units (HRUs)  resulting from the intersection of different maps  such as land use  soil types and geology  and flow networks  allow the representation of these elements in an explicit way  preserving natural and artificial contours of the different layers. These HRUs are used as model mesh in some distributed object-oriented hydrological models  allowing the application of a topological oriented approach. The connectivity between polygons and polylines provides a detailed representation of the water balance and overland flow in these distributed hydrological models  based on irregular hydro-landscape units. When computing fluxes between these HRUs  the geometrical parameters  such as the distance between the centroid of gravity of the HRUs and the river network  and the length of the perimeter  can impact the realism of the calculated overland  sub-surface and groundwater fluxes. Therefore  it is necessary to process the original model mesh in order to avoid these numerical problems. We present an automatic pre-processing implemented in the open source GRASS-GIS software  for which several Python scripts or some algorithms already available were used  such as the Triangle software. First  some scripts were developed to improve the topology of the various elements  such as snapping of the river network to the closest contours. When data are derived with remote sensing  such as vegetation areas  their perimeter has lots of right angles that were smoothed. Second  the algorithms more particularly address bad-shaped elements of the model mesh such as polygons with narrow shapes  marked irregular contours and/or the centroid outside of the polygons. To identify these elements we used shape descriptors. The convexity index was considered the best descriptor to identify them with a thresholdParFit: A Python-Based Object-Oriented Program for Fitting Molecular Mechanics Parameters to ab Initio Data.PubMedZahariev  Federico; De Silva  Nuwan; Gordon  Mark S; Windus  Theresa L; Dick-Perez  Marilu2017-03-27A newly created object-oriented program for automating the process of fitting molecular-mechanics parameters to ab initio data  termed ParFit  is presented. ParFit uses a hybrid of deterministic and stochastic genetic algorithms. ParFit can simultaneously handle several molecular-mechanics parameters in multiple molecules and can also apply symmetric and antisymmetric constraints on the optimized parameters. The simultaneous handling of several molecules enhances the transferability of the fitted parameters. ParFit is written in Python  uses a rich set of standard and nonstandard Python libraries  and can be run in parallel on multicore computer systems. As an example  a series of phosphine oxides  important for metal extraction chemistry  are parametrized using ParFit. ParFit is in an open source program available for free on GitHub ( https://github.com/fzahari/ParFit ).ParFit: A Python-Based Object-Oriented Program for Fitting Molecular Mechanics Parameters to ab Initio DataDOE PAGESZahariev  Federico; De Silva  Nuwan; Gordon  Mark S.; ...2017-02-23Here  a newly created object-oriented program for automating the process of fitting molecular-mechanics parameters to ab initio data  termed ParFit  is presented. ParFit uses a hybrid of deterministic and stochastic genetic algorithms. ParFit can simultaneously handle several molecular-mechanics parameters in multiple molecules and can also apply symmetric and antisymmetric constraints on the optimized parameters. The simultaneous handling of several molecules enhances the transferability of the fitted parameters. ParFit is written in Python  uses a rich set of standard and nonstandard Python libraries  and can be run in parallel on multicore computer systems. As an example  a series of phosphine oxides moreÂ Â» important for metal extraction chemistry  are parametrized using ParFit.Â«Â lessParFit: A Python-Based Object-Oriented Program for Fitting Molecular Mechanics Parameters to ab Initio DataSciTech ConnectZahariev  Federico; De Silva  Nuwan; Gordon  Mark S.Here  a newly created object-oriented program for automating the process of fitting molecular-mechanics parameters to ab initio data  termed ParFit  is presented. ParFit uses a hybrid of deterministic and stochastic genetic algorithms. ParFit can simultaneously handle several molecular-mechanics parameters in multiple molecules and can also apply symmetric and antisymmetric constraints on the optimized parameters. The simultaneous handling of several molecules enhances the transferability of the fitted parameters. ParFit is written in Python  uses a rich set of standard and nonstandard Python libraries  and can be run in parallel on multicore computer systems. As an example  a series of phosphine oxides moreÂ Â» important for metal extraction chemistry  are parametrized using ParFit.Â«Â lessParameters that affect parallel processing for computational electromagnetic simulation codes on high performance computing clustersNASA Astrophysics Data System (ADS)Moon  HongsikWhat is the impact of multicore and associated advanced technologies on computational software for science? Most researchers and students have multicore laptops or desktops for their research and they need computing power to run computational software packages. Computing power was initially derived from Central Processing Unit (CPU) clock speed. That changed when increases in clock speed became constrained by power requirements. Chip manufacturers turned to multicore CPU architectures and associated technological advancements to create the CPUs for the future. Most software applications benefited by the increased computing power the same way that increases in clock speed helped applications run faster. However  for Computational ElectroMagnetics (CEM) software developers  this change was not an obvious benefit - it appeared to be a detriment. Developers were challenged to find a way to correctly utilize the advancements in hardware so that their codes could benefit. The solution was parallelization and this dissertation details the investigation to address these challenges. Prior to multicore CPUs  advanced computer technologies were compared with the performance using benchmark software and the metric was FLoting-point Operations Per Seconds (FLOPS) which indicates system performance for scientific applications that make heavy use of floating-point calculations. Is FLOPS an effective metric for parallelized CEM simulation tools on new multicore system? Parallel CEM software needs to be benchmarked not only by FLOPS but also by the performance of other parameters related to type and utilization of the hardware  such as CPU  Random Access Memory (RAM)  hard disk  network  etc. The codes need to be optimized for more than just FLOPs and new parameters must be included in benchmarking. In this dissertation  the parallel CEM software named High Order Basis Based Integral Equation Solver (HOBBIES) is introduced. This code was developed to address the needs of theObject-oriented analysis and design of an ECG storage and retrieval system integrated with an HIS.PubMedWang  C; Ohe  K; Sakurai  T; Nagase  T; Kaihara  S1996-03-01For a hospital information system  object-oriented methodology plays an increasingly important role  especially for the management of digitized data  e.g.  the electrocardiogram  electroencephalogram  electromyogram  spirogram  X-ray  CT and histopathological images  which are not yet computerized in most hospitals. As a first step in an object-oriented approach to hospital information management and storing medical data in an object-oriented database  we connected electrocardiographs to a hospital network and established the integration of ECG storage and retrieval systems with a hospital information system. In this paper  the object-oriented analysis and design of the ECG storage and retrieval systems is reported.Development and application of the GIM code for the Cyber 203 computerNASA Technical Reports Server (NTRS)Stainaker  J. F.; Robinson  M. A.; Rawlinson  E. G.; Anderson  P. G.; Mayne  A. W.; Spradley  L. W.1982-01-01The GIM computer code for fluid dynamics research was developed. Enhancement of the computer code  implicit algorithm development  turbulence model implementation  chemistry model development  interactive input module coding and wing/body flowfield computation are described. The GIM quasi-parabolic code development was completed  and the code used to compute a number of example cases. Turbulence models  algebraic and differential equations  were added to the basic viscous code. An equilibrium reacting chemistry model and implicit finite difference scheme were also added. Development was completed on the interactive module for generating the input data for GIM. Solutions for inviscid hypersonic flow over a wing/body configuration are also presented.An assembly process model based on object-oriented hierarchical time Petri NetsNASA Astrophysics Data System (ADS)Wang  Jiapeng; Liu  Shaoli; Liu  Jianhua; Du  Zenghui2017-04-01In order to improve the versatility  accuracy and integrity of the assembly process model of complex products  an assembly process model based on object-oriented hierarchical time Petri Nets is presented. A complete assembly process information model including assembly resources  assembly inspection  time  structure and flexible parts is established  and this model describes the static and dynamic data involved in the assembly process. Through the analysis of three-dimensional assembly process information  the assembly information is hierarchically divided from the whole  the local to the details and the subnet model of different levels of object-oriented Petri Nets is established. The communication problem between Petri subnets is solved by using message database  and it reduces the complexity of system modeling effectively. Finally  the modeling process is presented  and a five layer Petri Nets model is established based on the hoisting process of the engine compartment of a wheeled armored vehicle.Advanced software development workstation. Comparison of two object-oriented development methodologiesNASA Technical Reports Server (NTRS)Izygon  Michel E.1992-01-01This report is an attempt to clarify some of the concerns raised about the OMT method  specifically that OMT is weaker than the Booch method in a few key areas. This interim report specifically addresses the following issues: (1) is OMT object-oriented or only data-driven?; (2) can OMT be used as a front-end to implementation in C++?; (3) the inheritance concept in OMT is in contradiction with the 'pure and real' inheritance concept found in object-oriented (OO) design; (4) low support for software life-cycle issues  for project and risk management; (5) uselessness of functional modeling for the ROSE project; and (6) problems with event-driven and simulation systems. The conclusion of this report is that both Booch's method and Rumbaugh's method are good OO methods  each with strengths and weaknesses in different areas of the development process.An application of object-oriented knowledge representation to engineering expert systemsNASA Technical Reports Server (NTRS)Logie  D. S.; Kamil  H.; Umaretiya  J. R.1990-01-01The paper describes an object-oriented knowledge representation and its application to engineering expert systems. The object-oriented approach promotes efficient handling of the problem data by allowing knowledge to be encapsulated in objects and organized by defining relationships between the objects. An Object Representation Language (ORL) was implemented as a tool for building and manipulating the object base. Rule-based knowledge representation is then used to simulate engineering design reasoning. Using a common object base  very large expert systems can be developed  comprised of small  individually processed  rule sets. The integration of these two schemes makes it easier to develop practical engineering expert systems. The general approach to applying this technology to the domain of the finite element analysis  design  and optimization of aerospace structures is discussed.VAS: A Vision Advisor System combining agents and object-oriented databasesNASA Technical Reports Server (NTRS)Eilbert  James L.; Lim  William; Mendelsohn  Jay; Braun  Ron; Yearwood  Michael1994-01-01A model-based approach to identifying and finding the orientation of non-overlapping parts on a tray has been developed. The part models contain both exact and fuzzy descriptions of part features  and are stored in an object-oriented database. Full identification of the parts involves several interacting tasks each of which is handled by a distinct agent. Using fuzzy information stored in the model allowed part features that were essentially at the noise level to be extracted and used for identification. This was done by focusing attention on the portion of the part where the feature must be found if the current hypothesis of the part ID is correct. In going from one set of parts to another the only thing that needs to be changed is the database of part models. This work is part of an effort in developing a Vision Advisor System (VAS) that combines agents and objected-oriented databases.Object-oriented Bayesian networks for paternity cases with allelic dependenciesPubMed CentralHepler  Amanda B.; Weir  Bruce S.2008-01-01This study extends the current use of Bayesian networks by incorporating the effects of allelic dependencies in paternity calculations. The use of object-oriented networks greatly simplify the process of building and interpreting forensic identification models  allowing researchers to solve new  more complex problems. We explore two paternity examples: the most common scenario where DNA evidence is available from the alleged father  the mother and the child; a more complex casewhere DNA is not available from the alleged father  but is available from the alleged fatherâ€™s brother. Object-oriented networks are built  using HUGIN  for each example which incorporate the effects of allelic dependence caused by evolutionary relatedness. PMID:19079769Object-oriented analysis and design of a health care management information system.PubMedKrol  M; Reich  D L1999-04-01We have created a prototype for a universal object-oriented model of a health care system compatible with the object-oriented approach used in version 3.0 of the HL7 standard for communication messages. A set of three models has been developed: (1) the Object Model describes the hierarchical structure of objects in a system--their identity  relationships  attributes  and operations; (2) the Dynamic Model represents the sequence of operations in time as a collection of state diagrams for object classes in the system; and (3) functional Diagram represents the transformation of data within a system by means of data flow diagrams. Within these models  we have defined major object classes of health care participants and their subclasses  associations  attributes and operators  states  and behavioral scenarios. We have also defined the major processes and subprocesses. The top-down design approach allows use  reuse  and cloning of standard components.The application of the unified modeling language in object-oriented analysis of healthcare information systems.PubMedAggarwal  Vinod2002-10-01This paper concerns itself with the beneficial effects of the Unified Modeling Language (UML)  a nonproprietary object modeling standard  in specifying  visualizing  constructing  documenting  and communicating the model of a healthcare information system from the user's perspective. The author outlines the process of object-oriented analysis (OOA) using the UML and illustrates this with healthcare examples to demonstrate the practicality of application of the UML by healthcare personnel to real-world information system problems. The UML will accelerate advanced uses of object-orientation such as reuse technology  resulting in significantly higher software productivity. The UML is also applicable in the context of a component paradigm that promises to enhance the capabilities of healthcare information systems and simplify their management and maintenance.An NAFP Project: Use of Object Oriented Methodologies and Design Patterns to Refactor Software DesignNASA Technical Reports Server (NTRS)Shaykhian  Gholam Ali; Baggs  Rhoda2007-01-01In the early problem-solution era of software programming  functional decompositions were mainly used to design and implement software solutions. In functional decompositions  functions and data are introduced as two separate entities during the design phase  and are followed as such in the implementation phase. Functional decompositions make use of refactoring through optimizing the algorithms  grouping similar functionalities into common reusable functions  and using abstract representations of data where possible; all these are done during the implementation phase. This paper advocates the usage of object-oriented methodologies and design patterns as the centerpieces of refactoring software solutions. Refactoring software is a method of changing software design while explicitly preserving its external functionalities. The combined usage of object-oriented methodologies and design patterns to refactor should also benefit the overall software life cycle cost with improved software.The Concert system - Compiler and runtime technology for efficient concurrent object-oriented programmingNASA Technical Reports Server (NTRS)Chien  Andrew A.; Karamcheti  Vijay; Plevyak  John; Sahrawat  Deepak1993-01-01Concurrent object-oriented languages  particularly fine-grained approaches  reduce the difficulty of large scale concurrent programming by providing modularity through encapsulation while exposing large degrees of concurrency. Despite these programmability advantages  such languages have historically suffered from poor efficiency. This paper describes the Concert project whose goal is to develop portable  efficient implementations of fine-grained concurrent object-oriented languages. Our approach incorporates aggressive program analysis and program transformation with careful information management at every stage from the compiler to the runtime system. The paper discusses the basic elements of the Concert approach along with a description of the potential payoffs. Initial performance results and specific plans for system development are also detailed.Object-Oriented Query Language For Events Detection From Images SequencesNASA Astrophysics Data System (ADS)Ganea  Ion Eugen2015-09-01In this paper is presented a method to represent the events extracted from images sequences and the query language used for events detection. Using an object oriented model the spatial and temporal relationships between salient objects and also between events are stored and queried. This works aims to unify the storing and querying phases for video events processing. The object oriented language syntax used for events processing allow the instantiation of the indexes classes in order to improve the accuracy of the query results. The experiments were performed on images sequences provided from sport domain and it shows the reliability and the robustness of the proposed language. To extend the language will be added a specific syntax for constructing the templates for abnormal events and for detection of the incidents as the final goal of the research.Tutorial on Using LISP Object-Oriented Programming for Blackboards: Solving the Radar Tracking ProblemDTIC Science & Technology1989-08-01report demonstrates how flavors (object-oriented programming in Franz is carried out via flavors. can be u> d for this programming. Different approaches...data structures that are part of Franz LISP. A method is a procedure that is invoked by a message to a flavor instance. The method triggered depends...keywordize is a procedure used to intern the :set-op name into the keyword package so that the flavor features of Franz recognize this operation. AnImpacts of object-oriented technologies: Seven years of SEL studiesNASA Technical Reports Server (NTRS)Stark  Mike1993-01-01This paper examines the premise that object-oriented technology (OOT) is the most significant technology ever examined by the Software Engineering Laboratory. The evolution of the use of OOT in the Software Engineering Laboratory (SEL) 'Experience Factory' is described in terms of the SEL's original expectations  focusing on how successive generations of projects have used OOT. General conclusions are drawn on how the usage of the technology has evolved in this environment.Methodology for object-oriented real-time systems analysis and design: Software engineeringNASA Technical Reports Server (NTRS)Schoeffler  James D.1991-01-01Successful application of software engineering methodologies requires an integrated analysis and design life-cycle in which the various phases flow smoothly 'seamlessly' from analysis through design to implementation. Furthermore  different analysis methodologies often lead to different structuring of the system so that the transition from analysis to design may be awkward depending on the design methodology to be used. This is especially important when object-oriented programming is to be used for implementation when the original specification and perhaps high-level design is non-object oriented. Two approaches to real-time systems analysis which can lead to an object-oriented design are contrasted: (1) modeling the system using structured analysis with real-time extensions which emphasizes data and control flows followed by the abstraction of objects where the operations or methods of the objects correspond to processes in the data flow diagrams and then design in terms of these objects; and (2) modeling the system from the beginning as a set of naturally occurring concurrent entities (objects) each having its own time-behavior defined by a set of states and state-transition rules and seamlessly transforming the analysis models into high-level design models. A new concept of a 'real-time systems-analysis object' is introduced and becomes the basic building block of a series of seamlessly-connected models which progress from the object-oriented real-time systems analysis and design system analysis logical models through the physical architectural models and the high-level design stages. The methodology is appropriate to the overall specification including hardware and software modules. In software modules  the systems analysis objects are transformed into software objects.Selecting a Persistent Data Support Environment for Object-Oriented ApplicationsDTIC Science & Technology1998-03-01key features of most object DBMS products is contained in the <DWAS 9{eeds Assessment for Objects from Barry and Associates. The developer should...data structure and behavior in a self- contained module enhances maintainability of the system and promotes reuse of modules for similar domains...considered together  represent a survey of commercial object-oriented database management systems. These references contain detailed information neededAn Object-Oriented Classification Method on High Resolution Satellite DataDTIC Science & Technology2004-11-0125th ACRS 2004 Chiang Mai   Thailand 347 Data Processing B-4.6 AN OBJECT-ORIENTED CLASSIFICATION METHOD ON...unlimited 13. SUPPLEMENTARY NOTES Proceedings of the 25th Asian Conference on Remote Sensing  Held in Chiang Mai   Thailand on 22-26 November 2004...panchromatic (left) and multispectral (right) 25th ACRS 2004 Chiang Mai   Thailand 349 Data Processing B-4.6 First of all  theApplying object-oriented software engineering at the BaBar collaborationNASA Astrophysics Data System (ADS)Jacobsen  Bob; BaBar Collaboration Reconstruction Software Group1997-02-01The BaBar experiment at SLAC will start taking data in 1999. We are attempting to build its reconstruction software using good software engineering practices  including the use of object-oriented technology. We summarize our experience to date with analysis and design activities  training  CASE and documentation tools  C++ programming practice and similar topics. The emphasis is on the practical issues of simultaneously introducing new techniques to a large collaboration while under a deadline for system delivery.GENASIS Basics: Object-oriented utilitarian functionality for large-scale physics simulations (Version 2)NASA Astrophysics Data System (ADS)Cardall  Christian Y.; Budiardja  Reuben D.2017-05-01GenASiS Basics provides Fortran 2003 classes furnishing extensible object-oriented utilitarian functionality for large-scale physics simulations on distributed memory supercomputers. This functionality includes physical units and constants; display to the screen or standard output device; message passing; I/O to disk; and runtime parameter management and usage statistics. This revision -Version 2 of Basics - makes mostly minor additions to functionality and includes some simplifying name changes.GELLO: an object-oriented query and expression language for clinical decision support.PubMedSordo  Margarita; Ogunyemi  Omolola; Boxwala  Aziz A; Greenes  Robert A2003-01-01GELLO is a purpose-specific  object-oriented (OO) query and expression language. GELLO is the result of a concerted effort of the Decision Systems Group (DSG) working with the HL7 Clinical Decision Support Technical Committee (CDSTC) to provide the HL7 community with a common format for data encoding and manipulation. GELLO will soon be submitted for ballot to the HL7 CDSTC for consideration as a standard.The Design and Implementation of an Object-Oriented  Production-Rule Interpreter.DTIC Science & Technology1984-12-01S. CONTRACT OR GRANT NUMBER(s) .Heinz M. McArthur 9. PERFORMING ORGANIZATION NAME AND ADDRESS 10. PROGRAM ELEMENT. PROJECT. TASK AREA & WORK UNIT...implementation of two prototype interpreters for Omega  an object-oriented  production- rule programming language. The first implementation is a throw- away...production-rule programming language. The first implementa- tion is a throw-away prototype written in LISP; the second implementation is a more completeMulti-point objective-oriented sequential sampling strategy for constrained robust designNASA Astrophysics Data System (ADS)Zhu  Ping; Zhang  Siliang; Chen  Wei2015-03-01Metamodelling techniques are widely used to approximate system responses of expensive simulation models. In association with the use of metamodels  objective-oriented sequential sampling methods have been demonstrated to be effective in balancing the need for searching an optimal solution versus reducing the metamodelling uncertainty. However  existing infilling criteria are developed for deterministic problems and restricted to one sampling point in one iteration. To exploit the use of multiple samples and identify the true robust solution in fewer iterations  a multi-point objective-oriented sequential sampling strategy is proposed for constrained robust design problems. In this article  earlier development of objective-oriented sequential sampling strategy for unconstrained robust design is first extended to constrained problems. Next  a double-loop multi-point sequential sampling strategy is developed. The proposed methods are validated using two mathematical examples followed by a highly nonlinear automotive crashworthiness design example. The results show that the proposed method can mitigate the effect of both metamodelling uncertainty and design uncertainty  and identify the robust design solution more efficiently than the single-point sequential sampling approach.Benefits of an Object-oriented Database Representation for Controlled Medical TerminologiesPubMed CentralGu  Huanying; Halper  Michael; Geller  James; Perl  Yehoshua1999-01-01Objective: Controlled medical terminologies (CMTs) have been recognized as important tools in a variety of medical informatics applications  ranging from patient-record systems to decision-support systems. Controlled medical terminologies are typically organized in semantic network structures consisting of tens to hundreds of thousands of concepts. This overwhelming size and complexity can be a serious barrier to their maintenance and widespread utilization. The authors propose the use of object-oriented databases to address the problems posed by the extensive scope and high complexity of most CMTs for maintenance personnel and general users alike. Design: The authors present a methodology that allows an existing CMT  modeled as a semantic network  to be represented as an equivalent object-oriented database. Such a representation is called an object-oriented health care terminology repository (OOHTR). Results: The major benefit of an OOHTR is its schema  which provides an important layer of structural abstraction. Using the high-level view of a CMT afforded by the schema  one can gain insight into the CMT's overarching organization and begin to better comprehend it. The authors' methodology is applied to the Medical Entities Dictionary (MED)  a large CMT developed at Columbia-Presbyterian Medical Center. Examples of how the OOHTR schema facilitated updating  correcting  and improving the design of the MED are presented. Conclusion: The OOHTR schema can serve as an important abstraction mechanism for enhancing comprehension of a large CMT  and thus promotes its usability. PMID:10428002A case of complex regional pain syndrome with agnosia for object orientation.PubMedRobinson  Gail; Cohen  Helen; Goebel  Andreas2011-07-01This systematic investigation of the neurocognitive correlates of complex regional pain syndrome (CRPS) in a single case also reports agnosia for object orientation in the context of persistent CRPS. We report a patient (JW) with severe long-standing CRPS who had no difficulty identifying and naming line drawings of objects presented in 1 of 4 cardinal orientations. In contrast  he was extremely poor at reorienting these objects into the correct upright orientation and in judging whether an object was upright or not. Moreover  JW made orientation errors when copying drawings of objects  and he also showed features of mirror reversal in writing single words and reading single letters. The findings are discussed in relation to accounts of visual processing. Agnosia for object orientation is the term for impaired knowledge of an object's orientation despite good recognition and naming of the same misoriented object. This defect has previously only been reported in patients with major structural brain lesions. The neuroanatomical correlates are discussed. The patient had no structural brain lesion  raising the possibility that nonstructural reorganisation of cortical networks may be responsible for his deficits. Other patients with CRPS may have related neurocognitive defects. Crown Copyright Â© 2011. Published by Elsevier B.V. All rights reserved.Nesting in an Object Oriented Language is NOT for the BirdsNASA Astrophysics Data System (ADS)Buhr  P. A.; Zarnke  C. R.The notion of nested blocks has come into disfavour or has been ignored in recent program language design. Many of the current object oriented programming languages use subclassing as the sole mechanism to establish relationships between classes and have no general notion of nesting. We argue that nesting (and  more generally  hierarchical organization) is a powerful mechanism that provides facilities that are not otherwise possible in a class based programming language. We agree that traditional block structure and its associated nesting have severe problems  and we suggest several extensions to the notion of blocks and block structure that indirectly make nesting a useful and powerful mechanism  particularly in an object oriented programming system. The main extension is to allow references to definitions from outside of the containing block  thereby making the contained definitions available in a larger scope. References are made using either the name of the containing entity or an instance of the containing entity. The extensions suggest a way to organize the programming environment for a large  multi-user system. These facilities are not available with subclassing  and subclassing provides facilities not available by nesting; hence  an object oriented language can benefit by providing nesting as well.Education:=Coding+Aesthetics; Aesthetic Understanding  Computer Science Education  and Computational ThinkingERIC Educational Resources Information CenterGood  Jonathon; Keenan  Sarah; Mishra  Punya2016-01-01The popular press is rife with examples of how students in the United States and around the globe are learning to program  make  and tinker. The Hour of Code  maker-education  and similar efforts are advocating that more students be exposed to principles found within computer science. We propose an expansion beyond simply teaching computationalâ€¦An Object-Oriented Computer Aided Design Program for Modern Control Systems AnalysisDTIC Science & Technology1992-12-01First Operand: LUmat[ 2  1] 0.5000 1.0000 Second Operand: BMat [ 1] 1.0000 1.0000 Result 0.5000 1.0000 *** Subtraction *** First Operand 0.0000...Appendix B - 33 Second Operand: BMat [ 2] 2 -1.0000 ( s + 3.0000s + 2.0000 s - 0.2000 Result -0.2000 s - 0.2000 * Subtraction *** First Operand 1.0000...Multiplication *** First Operand: LUmat[ 1  2] 0.2000 2 s + 3.0000s + 2.0000 Second Operand: BMat 1 2] 2 2.0000 ( s + 3.0000sInterface design of VSOP'94 computer code for safety analysisNASA Astrophysics Data System (ADS)Natsir  Khairina; Yazid  Putranto Ilham; Andiwijayakusuma  D.; Wahanani  Nursinta Adi2014-09-01Today  most software applications  also in the nuclear field  come with a graphical user interface. VSOP'94 (Very Superior Old Program)  was designed to simplify the process of performing reactor simulation. VSOP is a integrated code system to simulate the life history of a nuclear reactor that is devoted in education and research. One advantage of VSOP program is its ability to calculate the neutron spectrum estimation  fuel cycle  2-D diffusion  resonance integral  estimation of reactors fuel costs  and integrated thermal hydraulics. VSOP also can be used to comparative studies and simulation of reactor safety. However  existing VSOP is a conventional program  which was developed using Fortran 65 and have several problems in using it  for example  it is only operated on Dec Alpha mainframe platforms and provide text-based output  difficult to use  especially in data preparation and interpretation of results. We develop a GUI-VSOP  which is an interface program to facilitate the preparation of data  run the VSOP code and read the results in a more user friendly way and useable on the Personal 'Computer (PC). Modifications include the development of interfaces on preprocessing  processing and postprocessing. GUI-based interface for preprocessing aims to provide a convenience way in preparing data. Processing interface is intended to provide convenience in configuring input files and libraries and do compiling VSOP code. Postprocessing interface designed to visualized the VSOP output in table and graphic forms. GUI-VSOP expected to be useful to simplify and speed up the process and analysis of safety aspects.An object-oriented approach for parallel self adaptive mesh refinement on block structured gridsNASA Technical Reports Server (NTRS)Lemke  Max; Witsch  Kristian; Quinlan  Daniel1993-01-01Self-adaptive mesh refinement dynamically matches the computational demands of a solver for partial differential equations to the activity in the application's domain. In this paper we present two C++ class libraries  P++ and AMR++  which significantly simplify the development of sophisticated adaptive mesh refinement codes on (massively) parallel distributed memory architectures. The development is based on our previous research in this area. The C++ class libraries provide abstractions to separate the issues of developing parallel adaptive mesh refinement applications into those of parallelism  abstracted by P++  and adaptive mesh refinement  abstracted by AMR++. P++ is a parallel array class library to permit efficient development of architecture independent codes for structured grid applications  and AMR++ provides support for self-adaptive mesh refinement on block-structured grids of rectangular non-overlapping blocks. Using these libraries  the application programmers' work is greatly simplified to primarily specifying the serial single grid application and obtaining the parallel and self-adaptive mesh refinement code with minimal effort. Initial results for simple singular perturbation problems solved by self-adaptive multilevel techniques (FAC  AFAC)  being implemented on the basis of prototypes of the P++/AMR++ environment  are presented. Singular perturbation problems frequently arise in large applications  e.g. in the area of computational fluid dynamics. They usually have solutions with layers which require adaptive mesh refinement and fast basic solvers in order to be resolved efficiently.Status of MAPA (Modular Accelerator Physics Analysis) and the Tech-X Object-Oriented Accelerator LibraryNASA Astrophysics Data System (ADS)Cary  J. R.; Shasharina  S.; Bruhwiler  D. L.1998-04-01The MAPA code is a fully interactive accelerator modeling and design tool consisting of a GUI and two object-oriented C++ libraries: a general library suitable for treatment of any dynamical system  and an accelerator library including many element types plus an accelerator class. The accelerator library inherits directly from the system library  which uses hash tables to store any relevant parameters or strings. The GUI can access these hash tables in a general way  allowing the user to invoke a window displaying all relevant parameters for a particular element type or for the accelerator class  with the option to change those parameters. The system library can advance an arbitrary number of dynamical variables through an arbitrary mapping. The accelerator class inherits this capability and overloads the relevant functions to advance the phase space variables of a charged particle through a string of elements. Among other things  the GUI makes phase space plots and finds fixed points of the map. We discuss the object hierarchy of the two libraries and use of the code.Computer Tensor Codes to Design the War DriveNASA Astrophysics Data System (ADS)Maccone  C.To address problems in Breakthrough Propulsion Physics (BPP) and design the Warp Drive one needs sheer computing capabilities. This is because General Relativity (GR) and Quantum Field Theory (QFT) are so mathematically sophisticated that the amount of analytical calculations is prohibitive and one can hardly do all of them by hand. In this paper we make a comparative review of the main tensor calculus capabilities of the three most advanced and commercially available â€œsymbolic manipulatorâ€ codes. We also point out that currently one faces such a variety of different conventions in tensor calculus that it is difficult or impossible to compare results obtained by different scholars in GR and QFT. Mathematical physicists  experimental physicists and engineers have each their own way of customizing tensors  especially by using different metric signatures  different metric determinant signs  different definitions of the basic Riemann and Ricci tensors  and by adopting different systems of physical units. This chaos greatly hampers progress toward the design of the Warp Drive. It is thus suggested that NASA would be a suitable organization to establish standards in symbolic tensor calculus and anyone working in BPP should adopt these standards. Alternatively other institutions  like CERN in Europe  might consider the challenge of starting the preliminary implementation of a Universal Tensor Code to design the Warp Drive.A Programming Environment Evaluation Methodology for Object-Oriented Systems. Ph.D Thesis Final Report  1 Jul. 1985 - 31 Dec. 1987NASA Technical Reports Server (NTRS)Dominick  Wayne D. (Editor); Moreau  Dennis R.1987-01-01The object-oriented design strategy as both a problem decomposition and system development paradigm has made impressive inroads into the various areas of the computing sciences. Substantial development productivity improvements have been demonstrated in areas ranging from artificial intelligence to user interface design. However  there has been very little progress in the formal characterization of these productivity improvements and in the identification of the underlying cognitive mechanisms. The development and validation of models and metrics of this sort require large amounts of systematically-gathered structural and productivity data. There has  however  been a notable lack of systematically-gathered information on these development environments. A large part of this problem is attributable to the lack of a systematic programming environment evaluation methodology that is appropriate to the evaluation of object-oriented systems.Object-oriented business process analysis of the cooperative soft tissue sarcoma trial of the german society for paediatric oncology and haematology (GPOH).PubMedWeber  R; Knaup  P; Knietitg  R; Haux  R; Merzweiler  A; Mludek  V; Schilling  F H; Wiedemann  T2001-01-01The German Society for Paediatric Oncology and Haematology (GPOH) runs nation-wide multicentre clinical trials to improve the treatment of children suffering from malignant diseases. We want to provide methods and tools to support the centres of these trials in developing trial specific modules for the computer-based DOcumentation System for Paediatric Oncology (DOSPO). For this we carried out an object-oriented business process analysis for the Cooperative Soft Tissue Sarcoma Trial at the Olgahospital Stuttgart for Child and Adolescent Medicine. The result is a comprehensive business process model consisting of UML-diagrams and use case specifications. We recommend the object-oriented business process analysis as a method for the definition of requirements in information processing projects in the field of clinical trials in general. For this our model can serve as basis because it slightly can be adjusted to each type of clinical trial.Results of comparative RBMK neutron computation using VNIIEF codes (cell computation  3D statics  3D kinetics). Final reportSciTech ConnectGrebennikov  A.N.; Zhitnik  A.K.; Zvenigorodskaya  O.A.1995-12-31In conformity with the protocol of the Workshop under Contract {open_quotes}Assessment of RBMK reactor safety using modern Western Codes{close_quotes} VNIIEF performed a neutronics computation series to compare western and VNIIEF codes and assess whether VNIIEF codes are suitable for RBMK type reactor safety assessment computation. The work was carried out in close collaboration with M.I. Rozhdestvensky and L.M. Podlazov  NIKIET employees. The effort involved: (1) cell computations with the WIMS  EKRAN codes (improved modification of the LOMA code) and the S-90 code (VNIIEF Monte Carlo). Cell  polycell  burnup computation; (2) 3D computation of static states with the KORAT-3D and NEUmoreÂ Â» codes and comparison with results of computation with the NESTLE code (USA). The computations were performed in the geometry and using the neutron constants presented by the American party; (3) 3D computation of neutron kinetics with the KORAT-3D and NEU codes. These computations were performed in two formulations  both being developed in collaboration with NIKIET. Formulation of the first problem maximally possibly agrees with one of NESTLE problems and imitates gas bubble travel through a core. The second problem is a model of the RBMK as a whole with imitation of control and protection system controls (CPS) movement in a core.Â«Â lessObject-oriented crop mapping and monitoring using multi-temporal polarimetric RADARSAT-2 dataNASA Astrophysics Data System (ADS)Jiao  Xianfeng; Kovacs  John M.; Shang  Jiali; McNairn  Heather; Walters  Dan; Ma  Baoluo; Geng  Xiaoyuan2014-10-01The aim of this paper is to assess the accuracy of an object-oriented classification of polarimetric Synthetic Aperture Radar (PolSAR) data to map and monitor crops using 19 RADARSAT-2 fine beam polarimetric (FQ) images of an agricultural area in North-eastern Ontario  Canada. Polarimetric images and field data were acquired during the 2011 and 2012 growing seasons. The classification and field data collection focused on the main crop types grown in the region  which include: wheat  oat  soybean  canola and forage. The polarimetric parameters were extracted with PolSAR analysis using both the Cloude-Pottier and Freeman-Durden decompositions. The object-oriented classification  with a single date of PolSAR data  was able to classify all five crop types with an accuracy of 95% and Kappa of 0.93; a 6% improvement in comparison with linear-polarization only classification. However  the time of acquisition is crucial. The larger biomass crops of canola and soybean were most accurately mapped  whereas the identification of oat and wheat were more variable. The multi-temporal data using the Cloude-Pottier decomposition parameters provided the best classification accuracy compared to the linear polarizations and the Freeman-Durden decomposition parameters. In general  the object-oriented classifications were able to accurately map crop types by reducing the noise inherent in the SAR data. Furthermore  using the crop classification maps we were able to monitor crop growth stage based on a trend analysis of the radar response. Based on field data from canola crops  there was a strong relationship between the phenological growth stage based on the BBCH scale  and the HV backscatter and entropy.ProperCAD: A portable object-oriented parallel environment for VLSI CADNASA Technical Reports Server (NTRS)Ramkumar  Balkrishna; Banerjee  Prithviraj1993-01-01Most parallel algorithms for VLSI CAD proposed to date have one important drawback: they work efficiently only on machines that they were designed for. As a result  algorithms designed to date are dependent on the architecture for which they are developed and do not port easily to other parallel architectures. A new project under way to address this problem is described. A Portable object-oriented parallel environment for CAD algorithms (ProperCAD) is being developed. The objectives of this research are (1) to develop new parallel algorithms that run in a portable object-oriented environment (CAD algorithms using a general purpose platform for portable parallel programming called CARM is being developed and a C++ environment that is truly object-oriented and specialized for CAD applications is also being developed); and (2) to design the parallel algorithms around a good sequential algorithm with a well-defined parallel-sequential interface (permitting the parallel algorithm to benefit from future developments in sequential algorithms). One CAD application that has been implemented as part of the ProperCAD project  flat VLSI circuit extraction  is described. The algorithm  its implementation  and its performance on a range of parallel machines are discussed in detail. It currently runs on an Encore Multimax  a Sequent Symmetry  Intel iPSC/2 and i860 hypercubes  a NCUBE 2 hypercube  and a network of Sun Sparc workstations. Performance data for other applications that were developed are provided: namely test pattern generation for sequential circuits  parallel logic synthesis  and standard cell placement.Objected-oriented remote sensing image classification method based on geographic ontology modelNASA Astrophysics Data System (ADS)Chu  Z.; Liu  Z. J.; Gu  H. Y.2016-11-01Nowadays  with the development of high resolution remote sensing image and the wide application of laser point cloud data  proceeding objected-oriented remote sensing classification based on the characteristic knowledge of multi-source spatial data has been an important trend on the field of remote sensing image classification  which gradually replaced the traditional method through improving algorithm to optimize image classification results. For this purpose  the paper puts forward a remote sensing image classification method that uses the he characteristic knowledge of multi-source spatial data to build the geographic ontology semantic network model  and carries out the objected-oriented classification experiment to implement urban features classification  the experiment uses protÃ©gÃ© software which is developed by Stanford University in the United States  and intelligent image analysis softwareâ€”eCognition software as the experiment platform  uses hyperspectral image and Lidar data that is obtained through flight in DaFeng City of JiangSu as the main data source  first of all  the experiment uses hyperspectral image to obtain feature knowledge of remote sensing image and related special index  the second  the experiment uses Lidar data to generate nDSM(Normalized DSM  Normalized Digital Surface Model) obtaining elevation information  the last  the experiment bases image feature knowledge  special index and elevation information to build the geographic ontology semantic network model that implement urban features classification  the experiment results show that  this method is significantly higher than the traditional classification algorithm on classification accuracy  especially it performs more evidently on the respect of building classification. The method not only considers the advantage of multi-source spatial data  for example  remote sensing image  Lidar data and so on  but also realizes multi-source spatial data knowledge integration and applicationDesign of a Model Execution Framework: Repetitive Object-Oriented Simulation Environment (ROSE)NASA Technical Reports Server (NTRS)Gray  Justin S.; Briggs  Jeffery L.2008-01-01The ROSE framework was designed to facilitate complex system analyses. It completely divorces the model execution process from the model itself. By doing so ROSE frees the modeler to develop a library of standard modeling processes such as Design of Experiments  optimizers  parameter studies  and sensitivity studies which can then be applied to any of their available models. The ROSE framework accomplishes this by means of a well defined API and object structure. Both the API and object structure are presented here with enough detail to implement ROSE in any object-oriented language or modeling tool.An object-oriented approach to the management of meteorological and hydrological dataNASA Technical Reports Server (NTRS)Graves  S. J.; Williams  S. F.; Criswell  E. A.1990-01-01An interface to several meteorological and hydrological databases have been developed that enables researchers efficiently to access and interrelate data through a customized menu system. By extending a relational database system with object-oriented concepts  each user or group of users may have different 'views' of the data to allow user access to data in customized ways without altering the organization of the database. An application to COHMEX and WetNet  two earth science projects within NASA Marshall Space Flight Center's Earth Science and Applications Division  are described.Design and implementation of distributed multimedia surveillance system based on object-oriented middlewareNASA Astrophysics Data System (ADS)Cao  Xuesong; Jiang  Ling; Hu  Ruimin2006-10-01Currently  the applications of surveillance system have been increasingly widespread. But there are few surveillance platforms that can meet the requirement of large-scale  cross-regional  and flexible surveillance business. In the paper  we present a distributed surveillance system platform to improve safety and security of the society. The system is constructed by an object-oriented middleware called as Internet Communications Engine (ICE). This middleware helps our platform to integrate a lot of surveillance resource of the society and accommodate diverse range of surveillance industry requirements. In the follow sections  we will describe in detail the design concepts of system and introduce traits of ICE.Mebuilder: An Object-Oriented Lesson Authoring System for Procedural SkillsDTIC Science & Technology1994-09-01miltifil. typ..of..prologjfile/l. 8 - Gy~ua.Â± alaum..Aef/2  comonent/ 4   property-.set/ 4   property.Aisplay..data/d  relatioa/ 4   daeaon/6  operation...i.AGENCY USE ONLY(Lauvre Blank) .REP0RT DATE 1.;IOTTPA4-E O 4 . TITLE AND SUBTITLE 5. FUNDING NUMBERS MEBUILDER: An Object-Oriented Lesson Authoring System...for Procedural Skills (U) 6. AUTHOR(S) Galvin  Thomas Patrick 7. PERFORMING OR-GANIZATION NAME(SB) AND ADDRESS(ES) 8 . PERFORMING ORGANIZATION NavalReliability database development for use with an object-oriented fault tree evaluation programNASA Technical Reports Server (NTRS)Heger  A. Sharif; Harringtton  Robert J.; Koen  Billy V.; Patterson-Hine  F. Ann1989-01-01A description is given of the development of a fault-tree analysis method using object-oriented programming. In addition  the authors discuss the programs that have been developed or are under development to connect a fault-tree analysis routine to a reliability database. To assess the performance of the routines  a relational database simulating one of the nuclear power industry databases has been constructed. For a realistic assessment of the results of this project  the use of one of existing nuclear power reliability databases is planned.An Object-Oriented Software Architecture for the Explorer-2 Knowledge Management EnvironmentPubMed CentralTarabar  David B.; Greenes  Robert A.; Slosser  Eric T.1989-01-01Explorer-2 is a workstation based environment to facilitate knowledge management. It provides consistent access to a broad range of knowledge on the basis of purpose  not type. We have developed a software architecture based on Object-Oriented programming for Explorer-2. We have defined three classes of program objects: Knowledge ViewFrames  Knowledge Resources  and Knowledge Bases. This results in knowledge management at three levels: the screen level  the disk level and the meta-knowledge level. We have applied this design to several knowledge bases  and believe that there is a broad applicability of this design.An object-oriented  knowledge-based system for cardiovascular rehabilitation--phase II.PubMed CentralRyder  R. M.; Inamdar  B.1995-01-01The Heart Monitor is an object-oriented  knowledge-based system designed to support the clinical activities of cardiovascular (CV) rehabilitation. The original concept was developed as part of graduate research completed in 1992. This paper describes the second generation system which is being implemented in collaboration with a local heart rehabilitation program. The PC UNIX-based system supports an extensive patient database organized by clinical areas. In addition  a knowledge base is employed to monitor patient status. Rule-based automated reasoning is employed to assess risk factors contraindicative to exercise therapy and to monitor administrative and statutory requirements. PMID:8563285Object oriented classification of high resolution data for inventory of horticultural cropsNASA Astrophysics Data System (ADS)Hebbar  R.; Ravishankar  H. M.; Trivedi  S.; Subramoniam  S. R.; Uday  R.; Dadhwal  V. K.2014-11-01High resolution satellite images are associated with large variance and thus  per pixel classifiers often result in poor accuracy especially in delineation of horticultural crops. In this context  object oriented techniques are powerful and promising methods for classification. In the present study  a semi-automatic object oriented feature extraction model has been used for delineation of horticultural fruit and plantation crops using Erdas Objective Imagine. Multi-resolution data from Resourcesat LISS-IV and Cartosat-1 have been used as source data in the feature extraction model. Spectral and textural information along with NDVI were used as inputs for generation of Spectral Feature Probability (SFP) layers using sample training pixels. The SFP layers were then converted into raster objects using threshold and clump function resulting in pixel probability layer. A set of raster and vector operators was employed in the subsequent steps for generating thematic layer in the vector format. This semi-automatic feature extraction model was employed for classification of major fruit and plantations crops viz.  mango  banana  citrus  coffee and coconut grown under different agro-climatic conditions. In general  the classification accuracy of about 75-80 per cent was achieved for these crops using object based classification alone and the same was further improved using minimal visual editing of misclassified areas. A comparison of on-screen visual interpretation with object oriented approach showed good agreement. It was observed that old and mature plantations were classified more accurately while young and recently planted ones (3 years or less) showed poor classification accuracy due to mixed spectral signature  wider spacing and poor stands of plantations. The results indicated the potential use of object oriented approach for classification of high resolution data for delineation of horticultural fruit and plantation crops. The present methodology is applicable atHow the Geothermal Community Upped the Game for Computer CodesSciTech ConnectNoneThe Geothermal Technologies Office Code Comparison Study brought 11 research institutions together to collaborate on coupled thermal  hydrologic  geomechanical  and geochemical numerical simulators. These codes have the potential to help facilitate widespread geothermal energy development.Multi-Scale and Object-Oriented Analysis for Mountain Terrain Segmentation and Geomorphological AssessmentNASA Astrophysics Data System (ADS)Marston  B. K.; Bishop  M. P.; Shroder  J. F.2009-12-01Digital terrain analysis of mountain topography is widely utilized for mapping landforms  assessing the role of surface processes in landscape evolution  and estimating the spatial variation of erosion. Numerous geomorphometry techniques exist to characterize terrain surface parameters  although their utility to characterize the spatial hierarchical structure of the topography and permit an assessment of the erosion/tectonic impact on the landscape is very limited due to scale and data integration issues. To address this problem  we apply scale-dependent geomorphometric and object-oriented analyses to characterize the hierarchical spatial structure of mountain topography. Specifically  we utilized a high resolution digital elevation model to characterize complex topography in the Shimshal Valley in the Western Himalaya of Pakistan. To accomplish this  we generate terrain objects (geomorphological features and landform) including valley floors and walls  drainage basins  drainage network  ridge network  slope facets  and elemental forms based upon curvature. Object-oriented analysis was used to characterize object properties accounting for object size  shape  and morphometry. The spatial overlay and integration of terrain objects at various scales defines the nature of the hierarchical organization. Our results indicate that variations in the spatial complexity of the terrain hierarchical organization is related to the spatio-temporal influence of surface processes and landscape evolution dynamics. Terrain segmentation and the integration of multi-scale terrain information permits further assessment of process domains and erosion  tectonic impact potential  and natural hazard potential. We demonstrate this with landform mapping and geomorphological assessment examples.Modeling a terminology-based electronic nursing record system: an object-oriented approach.PubMedPark  Hyeoun-Ae; Cho  InSook; Byeun  NamSoo2007-10-01The aim of this study was to present our perspectives on healthcare information analysis at a conceptual level and the lessons learned from our experience with the development of a terminology-based enterprise electronic nursing record system - which was one of components in an EMR system at a tertiary teaching hospital in Korea - using an object-oriented system analysis and design concept. To ensure a systematic approach and effective collaboration  the department of nursing constituted a system modeling team comprising a project manager  systems analysts  user representatives  an object-oriented methodology expert  and healthcare informaticists (including the authors). A rational unified process (RUP) and the Unified Modeling Language were used as a development process and for modeling notation  respectively. From the scenario and RUP approach  user requirements were formulated into use case sets and the sequence of activities in the scenario was depicted in an activity diagram. The structure of the system was presented in a class diagram. This approach allowed us to identify clearly the structural and behavioral states and important factors of a terminology-based ENR system (e.g.  business concerns and system design concerns) according to the viewpoints of both domain and technical experts.Implementation of object-oriented programming in study of electrical race carNASA Astrophysics Data System (ADS)Nowak  M.; Baier  M.2016-08-01The paper covers issue of conducting advanced research of electrical race car participating in international competition called Sileverline Corporate Challenge. Process of designing race cars in Silesian Greenpower team is aided by a professional engine test stand built particularly in purpose of this research. Phase of testing and simulation is an important part of the implementation of new technologies. Properly developed solutions and test procedures are able to significantly shorten development time and reduce design costs. Testing process must be controlled by a modular and flexible application  easy to modify and ensuring safety. This paper describes the concept of object-oriented programming in LabVIEW and exemplary architecture of object-oriented control application designed to control engine test stand of the electrical race car. Eventually  the task of application will be to steer the electromagnetic brake and the engine load torque to perform according to data from the actual race track. During the designing process of the car  minimizing energy losses and maximizing powertrain efficiency are the main aspects taken into consideration. One of the crucial issues to accomplish these goals is to maintain optimal performance of the motor by applying effective cooling. The paper covers the research verifying the effectiveness of the cooling system.A Toolkit for Active Object-Oriented Databases with Application to InteroperabilityNASA Technical Reports Server (NTRS)King  Roger1996-01-01In our original proposal we stated that our research would 'develop a novel technology that provides a foundation for collaborative information processing.' The essential ingredient of this technology is the notion of 'deltas ' which are first-class values representing collections of proposed updates to a database. The Heraclitus framework provides a variety of algebraic operators for building up  combining  inspecting  and comparing deltas. Deltas can be directly applied to the database to yield a new state  or used 'hypothetically' in queries against the state that would arise if the delta were applied. The central point here is that the step of elevating deltas to 'first-class' citizens in database programming languages will yield tremendous leverage on the problem of supporting updates in collaborative information processing. In short  our original intention was to develop the theoretical and practical foundation for a technology based on deltas in an object-oriented database context  develop a toolkit for active object-oriented databases  and apply this toward collaborative information processing.A Toolkit for Active Object-Oriented Databases with Application to InteroperabilityNASA Technical Reports Server (NTRS)King  Roger1996-01-01In our original proposal we stated that our research would 'develop a novel technology that provides a foundation for collaborative information processing.' The essential ingredient of this technology is the notion of 'deltas ' which are first-class values representing collections of proposed updates to a database. The Heraclitus framework provides a variety of algebraic operators for building up  combining  inspecting  and comparing deltas. Deltas can be directly applied to the database to yield a new state  or used 'hypothetically' in queries against the state that would arise if the delta were applied. The central point here is that the step of elevating deltas to 'first-class' citizens in database programming languages will yield tremendous leverage on the problem of supporting updates in collaborative information processing. In short  our original intention was to develop the theoretical and practical foundation for a technology based on deltas in an object- oriented database context  develop a toolkit for active object-oriented databases  and apply this toward collaborative information processing.The utilization of neural nets in populating an object-oriented databaseNASA Technical Reports Server (NTRS)Campbell  William J.; Hill  Scott E.; Cromp  Robert F.1989-01-01Existing NASA supported scientific data bases are usually developed  managed and populated in a tedious  error prone and self-limiting way in terms of what can be described in a relational Data Base Management System (DBMS). The next generation Earth remote sensing platforms (i.e.  Earth Observation System  (EOS)  will be capable of generating data at a rate of over 300 Mbs per second from a suite of instruments designed for different applications. What is needed is an innovative approach that creates object-oriented databases that segment  characterize  catalog and are manageable in a domain-specific context and whose contents are available interactively and in near-real-time to the user community. Described here is work in progress that utilizes an artificial neural net approach to characterize satellite imagery of undefined objects into high-level data objects. The characterized data is then dynamically allocated to an object-oriented data base where it can be reviewed and assessed by a user. The definition  development  and evolution of the overall data system model are steps in the creation of an application-driven knowledge-based scientific information system.SILHOUETTE - HIDDEN LINE COMPUTER CODE WITH GENERALIZED SILHOUETTE SOLUTIONNASA Technical Reports Server (NTRS)Hedgley  D. R.1994-01-01Flexibility in choosing how to display computer-generated three-dimensional drawings has become increasingly important in recent years. A major consideration is the enhancement of the realism and aesthetics of the presentation. A polygonal representation of objects  even with hidden lines removed  is not always desirable. A more pleasing pictorial representation often can be achieved by removing some of the remaining visible lines  thus creating silhouettes (or outlines) of selected surfaces of the object. Additionally  it should be noted that this silhouette feature allows warped polygons. This means that any polygon can be decomposed into constituent triangles. Considering these triangles as members of the same family will present a polygon with no interior lines  and thus removes the restriction of flat polygons. SILHOUETTE is a program for calligraphic drawings that can render any subset of polygons as a silhouette with respect to itself. The program is flexible enough to be applicable to every class of object. SILHOUETTE offers all possible combinations of silhouette and nonsilhouette specifications for an arbitrary solid. Thus  it is possible to enhance the clarity of any three-dimensional scene presented in two dimensions. Input to the program can be line segments or polygons. Polygons designated with the same number will be drawn as a silhouette of those polygons. SILHOUETTE is written in FORTRAN 77 and requires a graphics package such as DI-3000. The program has been implemented on a DEC VAX series computer running VMS and used 65K of virtual memory without a graphics package linked in. The source code is intended to be machine independent. This program is available on a 5.25 inch 360K MS-DOS format diskette (standard distribution) and is also available on a 9-track 1600 BPI ASCII CARD IMAGE magnetic tape. SILHOUETTE was developed in 1986 and was last updated in 1992.SMITHERS: An object-oriented modular mapping methodology for MCNP-based neutronicâ€“thermal hydraulic multiphysicsDOE PAGESRichard  Joshua; Galloway  Jack; Fensin  Michael; ...2015-04-04A novel object-oriented modular mapping methodology for externally coupled neutronicsâ€“thermal hydraulics multiphysics simulations was developed. The Simulator using MCNP with Integrated Thermal-Hydraulics for Exploratory Reactor Studies (SMITHERS) code performs on-the-fly mapping of material-wise power distribution tallies implemented by MCNP-based neutron transport/depletion solvers for use in estimating coolant temperature and density distributions with a separate thermal-hydraulic solver. The key development of SMITHERS is that it reconstructs the hierarchical geometry structure of the material-wise power generation tallies from the depletion solver automatically  with only a modicum of additional information required from the user. In addition  it performs the basis mapping from themoreÂ Â» combinatorial geometry of the depletion solver to the required geometry of the thermal-hydraulic solver in a generalizable manner  such that it can transparently accommodate varying levels of thermal-hydraulic solver geometric fidelity  from the nodal geometry of multi-channel analysis solvers to the pin-cell level of discretization for sub-channel analysis solvers.Â«Â lessProcess Management and Exception Handling in Multiprocessor Operating Systems Using Object-Oriented Design Techniques. Revised Sep. 1988NASA Technical Reports Server (NTRS)Russo  Vincent; Johnston  Gary; Campbell  Roy1988-01-01The programming of the interrupt handling mechanisms  process switching primitives  scheduling mechanism  and synchronization primitives of an operating system for a multiprocessor require both efficient code in order to support the needs of high- performance or real-time applications and careful organization to facilitate maintenance. Although many advantages have been claimed for object-oriented class hierarchical languages and their corresponding design methodologies  the application of these techniques to the design of the primitives within an operating system has not been widely demonstrated. To investigate the role of class hierarchical design in systems programming  the authors have constructed the Choices multiprocessor operating system architecture the C++ programming language. During the implementation  it was found that many operating system design concerns can be represented advantageously using a class hierarchical approach  including: the separation of mechanism and policy; the organization of an operating system into layers  each of which represents an abstract machine; and the notions of process and exception management. In this paper  we discuss an implementation of the low-level primitives of this system and outline the strategy by which we developed our solution.Implementation of a 3D mixing layer code on parallel computersNASA Technical Reports Server (NTRS)Roe  K.; Thakur  R.; Dang  T.; Bogucz  E.1995-01-01This paper summarizes our progress and experience in the development of a Computational-Fluid-Dynamics code on parallel computers to simulate three-dimensional spatially-developing mixing layers. In this initial study  the three-dimensional time-dependent Euler equations are solved using a finite-volume explicit time-marching algorithm. The code was first programmed in Fortran 77 for sequential computers. The code was then converted for use on parallel computers using the conventional message-passing technique  while we have not been able to compile the code with the present version of HPF compilers.Object-Oriented Bayesian Networks (OOBN) for Aviation Accident Modeling and Technology Portfolio Impact AssessmentNASA Technical Reports Server (NTRS)Shih  Ann T.; Ancel  Ersin; Jones  Sharon M.2012-01-01The concern for reducing aviation safety risk is rising as the National Airspace System in the United States transforms to the Next Generation Air Transportation System (NextGen). The NASA Aviation Safety Program is committed to developing an effective aviation safety technology portfolio to meet the challenges of this transformation and to mitigate relevant safety risks. The paper focuses on the reasoning of selecting Object-Oriented Bayesian Networks (OOBN) as the technique and commercial software for the accident modeling and portfolio assessment. To illustrate the benefits of OOBN in a large and complex aviation accident model  the in-flight Loss-of-Control Accident Framework (LOCAF) constructed as an influence diagram is presented. An OOBN approach not only simplifies construction and maintenance of complex causal networks for the modelers  but also offers a well-organized hierarchical network that is easier for decision makers to exploit the model examining the effectiveness of risk mitigation strategies through technology insertions.Automatic extraction and visualization of object-oriented software design metricsNASA Astrophysics Data System (ADS)Lakshminarayana  Anuradha; Newman  Timothy S.; Li  Wei; Talburt  John2000-02-01Software visualization is a graphical representation of software characteristics and behavior. Certain modes of software visualization can be useful in isolating problems and identifying unanticipated behavior. In this paper we present a new approach to aid understanding of object- oriented software through 3D visualization of software metrics that can be extracted from the design phase of software development. The focus of the paper is a metric extraction method and a new collection of glyphs for multi- dimensional metric visualization. Our approach utilize the extensibility interface of a popular CASE tool to access and automatically extract the metrics from Unified Modeling Language class diagrams. Following the extraction of the design metrics  3D visualization of these metrics are generated for each class in the design  utilizing intuitively meaningful 3D glyphs that are representative of the ensemble of metrics. Extraction and visualization of design metrics can aid software developers in the early study and understanding of design complexity.Parietal and frontal object areas underlie perception of object orientation in depth.PubMedNiimi  Ryosuke; Saneyoshi  Ayako; Abe  Reiko; Kaminaga  Tatsuro; Yokosawa  Kazuhiko2011-05-27Recent studies have shown that the human parietal and frontal cortices are involved in object image perception. We hypothesized that the parietal/frontal object areas play a role in differentiating the orientations (i.e.  views) of an object. By using functional magnetic resonance imaging  we compared brain activations while human observers differentiated between two object images in depth-orientation (orientation task) and activations while they differentiated the images in object identity (identity task). The left intraparietal area  right angular gyrus  and right inferior frontal areas were activated more for the orientation task than for the identity task. The occipitotemporal object areas  however  were activated equally for the two tasks. No region showed greater activation for the identity task. These results suggested that the parietal/frontal object areas encode view-dependent visual features and underlie object orientation perception. Copyright Â© 2011 Elsevier Ireland Ltd. All rights reserved.An object-oriented approach to risk and reliability analysis : methodology and aviation safety applications.SciTech ConnectDandini  Vincent John; Duran  Felicia Angelica; Wyss  Gregory Dane2003-09-01This article describes how features of event tree analysis and Monte Carlo-based discrete event simulation can be combined with concepts from object-oriented analysis to develop a new risk assessment methodology  with some of the best features of each. The resultant object-based event scenario tree (OBEST) methodology enables an analyst to rapidly construct realistic models for scenarios for which an a priori discovery of event ordering is either cumbersome or impossible. Each scenario produced by OBEST is automatically associated with a likelihood estimate because probabilistic branching is integral to the object model definition. The OBEST methodology is then applied to anmoreÂ Â» aviation safety problem that considers mechanisms by which an aircraft might become involved in a runway incursion incident. The resulting OBEST model demonstrates how a close link between human reliability analysis and probabilistic risk assessment methods can provide important insights into aviation safety phenomenology.Â«Â lessThe Validation by Measurement Theory of Proposed Object-Oriented Software MetricsNASA Technical Reports Server (NTRS)Neal  Ralph D.1996-01-01Moving software development into the engineering arena requires controllability  and to control a process  it must be measurable. Measuring the process does no good if the product is not also measured  i.e.  being the best at producing an inferior product does not define a quality process. Also  not every number extracted from software development is a valid measurement. A valid measurement only results when we are able to verify that the number is representative of the attribute that we wish to measure. Many proposed software metrics are used by practitioners without these metrics ever having been validated  leading to costly but often useless calculations. Several researchers have bemoaned the lack of scientific precision in much of the published software measurement work and have called for validation of software metrics by measurement theory. This dissertation applies measurement theory to validate fifty proposed object-oriented software metrics.SIMSAT: An object oriented architecture for real-time satellite simulationNASA Technical Reports Server (NTRS)Williams  Adam P.1993-01-01Real-time satellite simulators are vital tools in the support of satellite missions. They are used in the testing of ground control systems  the training of operators  the validation of operational procedures  and the development of contingency plans. The simulators must provide high-fidelity modeling of the satellite  which requires detailed system information  much of which is not available until relatively near launch. The short time-scales and resulting high productivity required of such simulator developments culminates in the need for a reusable infrastructure which can be used as a basis for each simulator. This paper describes a major new simulation infrastructure package  the Software Infrastructure for Modelling Satellites (SIMSAT). It outlines the object oriented design methodology used  describes the resulting design  and discusses the advantages and disadvantages experienced in applying the methodology.Lightweight Object Oriented Structure analysis: Tools for building Tools to Analyze Molecular Dynamics SimulationsPubMed CentralRomo  Tod D.; Leioatts  Nicholas; Grossfield  Alan2014-01-01LOOS (Lightweight Object-Oriented Structure-analysis) is a C++ library designed to facilitate making novel tools for analyzing molecular dynamics simulations by abstracting out the repetitive tasks  allowing developers to focus on the scientifically relevant part of the problem. LOOS supports input using the native file formats of most common biomolecular simulation packages  including CHARMM  NAMD  Amber  Tinker  and Gromacs. A dynamic atom selection language based on the C expression syntax is included and is easily accessible to the tool-writer. In addition  LOOS is bundled with over 120 pre-built tools  including suites of tools for analyzing simulation convergence  3D histograms  and elastic network models. Through modern C++ design  LOOS is both simple to develop with (requiring knowledge of only 4 core classes and a few utility functions) and is easily extensible. A python interface to the core classes is also provided  further facilitating tool development. PMID:25327784Integrating heterogeneous databases in clustered medic care environments using object-oriented technologyNASA Astrophysics Data System (ADS)Thakore  Arun K.; Sauer  Frank1994-05-01The organization of modern medical care environments into disease-related clusters  such as a cancer center  a diabetes clinic  etc.  has the side-effect of introducing multiple heterogeneous databases  often containing similar information  within the same organization. This heterogeneity fosters incompatibility and prevents the effective sharing of data amongst applications at different sites. Although integration of heterogeneous databases is now feasible  in the medical arena this is often an ad hoc process  not founded on proven database technology or formal methods. In this paper we illustrate the use of a high-level object- oriented semantic association method to model information found in different databases into an integrated conceptual global model that integrates the databases. We provide examples from the medical domain to illustrate an integration approach resulting in a consistent global view  without attacking the autonomy of the underlying databases.Using object-oriented analysis to design a multi-mission ground data systemNASA Technical Reports Server (NTRS)Shames  Peter1995-01-01This paper describes an analytical approach and descriptive methodology that is adapted from Object-Oriented Analysis (OOA) techniques. The technique is described and then used to communicate key issues of system logical architecture. The essence of the approach is to limit the analysis to only service objects  with the idea of providing a direct mapping from the design to a client-server implementation. Key perspectives on the system  such as user interaction  data flow and management  service interfaces  hardware configuration  and system and data integrity are covered. A significant advantage of this service-oriented approach is that it permits mapping all of these different perspectives on the system onto a single common substrate. This services substrate is readily represented diagramatically  thus making details of the overall design much more accessible.The validation by measurement theory of proposed object-oriented software metricsNASA Technical Reports Server (NTRS)Neal  Ralph D.1994-01-01Moving software development into the engineering arena requires controllability  and to control a process  it must be measurable. Measuring the process does no good if the product is not also measured  i.e.  being the best at producing an inferior product does not define a quality process. Also  not every number extracted from software development is a valid measurement. A valid measurement only results when we are able to verify that the number is representative of the attribute that we wish to measure. Many proposed software metrics are used by practitioners without these metrics ever having been validated  leading to costly but often useless calculations. Several researchers have bemoaned the lack of scientific precision in much of the published software measurement work and have called for validation of software metrics by measurement theory. This dissertation applies measurement theory to validate fifty proposed object-oriented software metrics (Li and Henry  1993; Chidamber and Kemerrer  1994; Lorenz and Kidd  1994).An adaptive  object oriented strategy for base calling in DNA sequence analysis.PubMed CentralGiddings  M C; Brumley  R L; Haker  M; Smith  L M1993-01-01An algorithm has been developed for the determination of nucleotide sequence from data produced in fluorescence-based automated DNA sequencing instruments employing the four-color strategy. This algorithm takes advantage of object oriented programming techniques for modularity and extensibility. The algorithm is adaptive in that data sets from a wide variety of instruments and sequencing conditions can be used with good results. Confidence values are provided on the base calls as an estimate of accuracy. The algorithm iteratively employs confidence determinations from several different modules  each of which examines a different feature of the data for accurate peak identification. Modules within this system can be added or removed for increased performance or for application to a different task. In comparisons with commercial software  the algorithm performed well. Images PMID:8233787Object-oriented sequence analysis: SCL--a C++ class library.PubMedVahrson  W; Hermann  K; Kleffe  J; Wittig  B1996-04-01SCL (Sequence Class Library) is a class library written in the C++ programming language. Designed using object-oriented programming principles  SCL consists of classes of objects performing tasks typically needed for analyzing DNA or protein sequences. Among them are very flexible sequence classes  classes accessing databases in various formats  classes managing collections of sequences  as well as classes performing higher-level tasks like calculating a pairwise sequence alignment. SCL also includes classes that provide general programming support  like a dynamically growing array  sets  matrices  strings  classes performing file input/output  and utilities for error handling. By providing these components  SCL fosters an explorative programming style: experimenting with algorithms and alternative implementations is encouraged rather than punished. A description of SCL's overall structure as well as an overview of its classes is given. Important aspects of the work with SCL are discussed in the context of a sample program.An object-oriented approach for harmonization of multimedia markup languagesNASA Astrophysics Data System (ADS)Chen  Yih-Feng; Kuo  May-Chen; Sun  Xiaoming; Kuo  C.-C. Jay2003-12-01An object-oriented methodology is proposed to harmonize several different markup languages in this research. First  we adopt the Unified Modelling Language (UML) as the data model to formalize the concept and the process of the harmonization process between the eXtensible Markup Language (XML) applications. Then  we design the Harmonization eXtensible Markup Language (HXML) based on the data model and formalize the transformation between the Document Type Definitions (DTDs) of the original XML applications and HXML. The transformation between instances is also discussed. We use the harmonization of SMIL and X3D as an example to demonstrate the proposed methodology. This methodology can be generalized to various application domains.Object-oriented recognition of high-resolution remote sensing imageNASA Astrophysics Data System (ADS)Wang  Yongyan; Li  Haitao; Chen  Hong; Xu  Yuannan2016-01-01With the development of remote sensing imaging technology and the improvement of multi-source image's resolution in satellite visible light  multi-spectral and hyper spectral   the high resolution remote sensing image has been widely used in various fields  for example military field  surveying and mapping  geophysical prospecting  environment and so forth. In remote sensing image  the segmentation of ground targets  feature extraction and the technology of automatic recognition are the hotspot and difficulty in the research of modern information technology. This paper also presents an object-oriented remote sensing image scene classification method. The method is consist of vehicles typical objects classification generation  nonparametric density estimation theory  mean shift segmentation theory  multi-scale corner detection algorithm  local shape matching algorithm based on template. Remote sensing vehicles image classification software system is designed and implemented to meet the requirements .Reducing the complexity of the software design process with object-oriented designNASA Technical Reports Server (NTRS)Schuler  M. P.1991-01-01Designing software is a complex process. How object-oriented design (OOD)  coupled with formalized documentation and tailored object diagraming techniques  can reduce the complexity of the software design process is described and illustrated. The described OOD methodology uses a hierarchical decomposition approach in which parent objects are decomposed into layers of lower level child objects. A method of tracking the assignment of requirements to design components is also included. Increases in the reusability  portability  and maintainability of the resulting products are also discussed. This method was built on a combination of existing technology  teaching experience  consulting experience  and feedback from design method users. The discussed concepts are applicable to hierarchal OOD processes in general. Emphasis is placed on improving the design process by documenting the details of the procedures involved and incorporating improvements into those procedures as they are developed.Lightweight object oriented structure analysis: tools for building tools to analyze molecular dynamics simulations.PubMedRomo  Tod D; Leioatts  Nicholas; Grossfield  Alan2014-12-15LOOS (Lightweight Object Oriented Structure-analysis) is a C++ library designed to facilitate making novel tools for analyzing molecular dynamics simulations by abstracting out the repetitive tasks  allowing developers to focus on the scientifically relevant part of the problem. LOOS supports input using the native file formats of most common biomolecular simulation packages  including CHARMM  NAMD  Amber  Tinker  and Gromacs. A dynamic atom selection language based on the C expression syntax is included and is easily accessible to the tool-writer. In addition  LOOS is bundled with over 140 prebuilt tools  including suites of tools for analyzing simulation convergence  three-dimensional histograms  and elastic network models. Through modern C++ design  LOOS is both simple to develop with (requiring knowledge of only four core classes and a few utility functions) and is easily extensible. A python interface to the core classes is also provided  further facilitating tool development. Â© 2014 Wiley Periodicals  Inc.Object-oriented integrated approach for the design of scalable ECG systems.PubMedBoskovic  Dusanka; Besic  Ingmar; Avdagic  Zikrija2009-01-01The paper presents the implementation of Object-Oriented (OO) integrated approaches to the design of scalable Electro-Cardio-Graph (ECG) Systems. The purpose of this methodology is to preserve real-world structure and relations with the aim to minimize the information loss during the process of modeling  especially for Real-Time (RT) systems. We report on a case study of the design that uses the integration of OO and RT methods and the Unified Modeling Language (UML) standard notation. OO methods identify objects in the real-world domain and use them as fundamental building blocks for the software system. The gained experience based on the strongly defined semantics of the object model is discussed and related problems are analyzed.DISCO: An object-oriented system for music composition and sound designSciTech ConnectKaper  H. G.; Tipei  S.; Wright  J. M.2000-09-05This paper describes an object-oriented approach to music composition and sound design. The approach unifies the processes of music making and instrument building by using similar logic  objects  and procedures. The composition modules use an abstract representation of musical data  which can be easily mapped onto different synthesis languages or a traditionally notated score. An abstract base class is used to derive classes on different time scales. Objects can be related to act across time scales  as well as across an entire piece  and relationships between similar objects can replicate traditional music operations or introduce new ones. The DISCO (DigitalmoreÂ Â» Instrument for Sonification and Composition) system is an open-ended work in progress.Â«Â lessA study of earthquake-induced building detection by object oriented classification approachNASA Astrophysics Data System (ADS)Sabuncu  Asli; Damla Uca Avci  Zehra; Sunar  Filiz2017-04-01Among the natural hazards  earthquakes are the most destructive disasters and cause huge loss of lives  heavily infrastructure damages and great financial losses every year all around the world. According to the statistics about the earthquakes  more than a million earthquakes occur which is equal to two earthquakes per minute in the world. Natural disasters have brought more than 780.000 deaths approximately % 60 of all mortality is due to the earthquakes after 2001. A great earthquake took place at 38.75 N 43.36 E in the eastern part of Turkey in Van Province on On October 23th  2011. 604 people died and about 4000 buildings seriously damaged and collapsed after this earthquake. In recent years  the use of object oriented classification approach based on different object features  such as spectral  textural  shape and spatial information  has gained importance and became widespread for the classification of high-resolution satellite images and orthophotos. The motivation of this study is to detect the collapsed buildings and debris areas after the earthquake by using very high-resolution satellite images and orthophotos with the object oriented classification and also see how well remote sensing technology was carried out in determining the collapsed buildings. In this study  two different land surfaces were selected as homogenous and heterogeneous case study areas. In the first step of application  multi-resolution segmentation was applied and optimum parameters were selected to obtain the objects in each area after testing different color/shape and compactness/smoothness values. In the next step  two different classification approaches  namely ""supervised"" and ""unsupervised"" approaches were applied and their classification performances were compared. Object-based Image Analysis (OBIA) was performed using e-Cognition software.Real-time physiological monitoring with distributed networks of sensors and object-oriented programming techniquesNASA Astrophysics Data System (ADS)Wiesmann  William P.; Pranger  L. Alex; Bogucki  Mary S.1998-05-01Remote monitoring of physiologic data from individual high- risk workers distributed over time and space is a considerable challenge. This is often due to an inadequate capability to accurately integrate large amounts of data into usable information in real time. In this report  we have used the vertical and horizontal organization of the 'fireground' as a framework to design a distributed network of sensors. In this system  sensor output is linked through a hierarchical object oriented programing process to accurately interpret physiological data  incorporate these data into a synchronous model and relay processed data  trends and predictions to members of the fire incident command structure. There are several unique aspects to this approach. The first includes a process to account for variability in vital parameter values for each individual's normal physiologic response by including an adaptive network in each data process. This information is used by the model in an iterative process to baseline a 'normal' physiologic response to a given stress for each individual and to detect deviations that indicate dysfunction or a significant insult. The second unique capability of the system orders the information for each user including the subject  local company officers  medical personnel and the incident commanders. Information can be retrieved and used for training exercises and after action analysis. Finally this system can easily be adapted to existing communication and processing links along with incorporating the best parts of current models through the use of object oriented programming techniques. These modern software techniques are well suited to handling multiple data processes independently over time in a distributed network.[An object-oriented intelligent engineering design approach for lake pollution control].PubMedZou  Rui; Zhou  Jing; Liu  Yong; Zhu  Xiang; Zhao  Lei; Yang  Ping-Jian; Guo  Huai-Cheng2013-03-01Regarding the shortage and deficiency of traditional lake pollution control engineering techniques  a new lake pollution control engineering approach was proposed in this study  based on object-oriented intelligent design (OOID) from the perspective of intelligence. It can provide a new methodology and framework for effectively controlling lake pollution and improving water quality. The differences between the traditional engineering techniques and the OOID approach were compared. The key points for OOID were described as object perspective  cause and effect foundation  set points into surface  and temporal and spatial optimization. The blue algae control in lake was taken as an example in this study. The effect of algae control and water quality improvement were analyzed in details from the perspective of object-oriented intelligent design based on two engineering techniques (vertical hydrodynamic mixer and pumping algaecide recharge). The modeling results showed that the traditional engineering design paradigm cannot provide scientific and effective guidance for engineering design and decision-making regarding lake pollution. Intelligent design approach is based on the object perspective and quantitative causal analysis in this case. This approach identified that the efficiency of mixers was much higher than pumps in achieving the goal of low to moderate water quality improvement. However  when the objective of water quality exceeded a certain value (such as the control objective of peak Chla concentration exceeded 100 microg x L(-1) in this experimental water)  the mixer cannot achieve this goal. The pump technique can achieve the goal but with higher cost. The efficiency of combining the two techniques was higher than using one of the two techniques alone. Moreover  the quantitative scale control of the two engineering techniques has a significant impact on the actual project benefits and costs.User's manual for a material transport code on the Octopus Computer NetworkSciTech ConnectNaymik  T.G.; Mendez  G.D.1978-09-15A code to simulate material transport through porous media was developed at Oak Ridge National Laboratory. This code has been modified and adapted for use at Lawrence Livermore Laboratory. This manual  in conjunction with report ORNL-4928  explains the input  output  and execution of the code on the Octopus Computer Network.Operations analysis (study 2.1). Program listing for the LOVES computer codeNASA Technical Reports Server (NTRS)Wray  S. T.  Jr.1974-01-01A listing of the LOVES computer program is presented. The program is coded partially in SIMSCRIPT and FORTRAN. This version of LOVES is compatible with both the CDC 7600 and the UNIVAC 1108 computers. The code has been compiled  loaded  and executed successfully on the EXEC 8 system for the UNIVAC 1108.Simulation and Digitization of a Gas Electron Multiplier Detector Using Geant4 and an Object-Oriented Digitization ProgramNASA Astrophysics Data System (ADS)McMullen  Timothy; Liyanage  Nilanga; Xiong  Weizhi; Zhao  Zhiwen2017-01-01Our research has focused on simulating the response of a Gas Electron Multiplier (GEM) detector using computational methods. GEM detectors provide a cost effective solution for radiation detection in high rate environments. A detailed simulation of GEM detector response to radiation is essential for the successful adaption of these detectors to different applications. Using Geant4 Monte Carlo (GEMC)  a wrapper around Geant4 which has been successfully used to simulate the Solenoidal Large Intensity Device (SoLID) at Jefferson Lab  we are developing a simulation of a GEM chamber similar to the detectors currently used in our lab. We are also refining an object-oriented digitization program  which translates energy deposition information from GEMC into electronic readout which resembles the readout from our physical detectors. We have run the simulation with beta particles produced by the simulated decay of a 90Sr source  as well as with a simulated bremsstrahlung spectrum. Comparing the simulation data with real GEM data taken under similar conditions is used to refine the simulation parameters. Comparisons between results from the simulations and results from detector tests will be presented.Comparison of two computer codes for crack growth analysis: NASCRAC Versus NASA/FLAGRONASA Technical Reports Server (NTRS)Stallworth  R.; Meyers  C. A.; Stinson  H. C.1989-01-01Results are presented from the comparison study of two computer codes for crack growth analysis - NASCRAC and NASA/FLAGRO. The two computer codes gave compatible conservative results when the part through crack analysis solutions were analyzed versus experimental test data. Results showed good correlation between the codes for the through crack at a lug solution. For the through crack at a lug solution  NASA/FLAGRO gave the most conservative results.Efficient Proximity Computation Techniques Using ZIP Code Data for Smart Cities â€ PubMed CentralMurdani  Muhammad Harist; Hong  Bonghee2018-01-01In this paper  we are interested in computing ZIP code proximity from two perspectives  proximity between two ZIP codes (Ad-Hoc) and neighborhood proximity (Top-K). Such a computation can be used for ZIP code-based target marketing as one of the smart city applications. A naÃ¯ve approach to this computation is the usage of the distance between ZIP codes. We redefine a distance metric combining the centroid distance with the intersecting road network between ZIP codes by using a weighted sum method. Furthermore  we prove that the results of our combined approach conform to the characteristics of distance measurement. We have proposed a general and heuristic approach for computing Ad-Hoc proximity  while for computing Top-K proximity  we have proposed a general approach only. Our experimental results indicate that our approaches are verifiable and effective in reducing the execution time and search space. PMID:29587366Efficient Proximity Computation Techniques Using ZIP Code Data for Smart Cities â€ .PubMedMurdani  Muhammad Harist; Kwon  Joonho; Choi  Yoon-Ho; Hong  Bonghee2018-03-24In this paper  we are interested in computing ZIP code proximity from two perspectives  proximity between two ZIP codes ( Ad-Hoc ) and neighborhood proximity ( Top-K ). Such a computation can be used for ZIP code-based target marketing as one of the smart city applications. A naÃ¯ve approach to this computation is the usage of the distance between ZIP codes. We redefine a distance metric combining the centroid distance with the intersecting road network between ZIP codes by using a weighted sum method. Furthermore  we prove that the results of our combined approach conform to the characteristics of distance measurement. We have proposed a general and heuristic approach for computing Ad-Hoc proximity  while for computing Top-K proximity  we have proposed a general approach only. Our experimental results indicate that our approaches are verifiable and effective in reducing the execution time and search space.MMA  A Computer Code for Multi-Model AnalysisUSGS Publications WarehousePoeter  Eileen P.; Hill  Mary C.2007-01-01This report documents the Multi-Model Analysis (MMA) computer code. MMA can be used to evaluate results from alternative models of a single system using the same set of observations for all models. As long as the observations  the observation weighting  and system being represented are the same  the models can differ in nearly any way imaginable. For example  they may include different processes  different simulation software  different temporal definitions (for example  steady-state and transient models could be considered)  and so on. The multiple models need to be calibrated by nonlinear regression. Calibration of the individual models needs to be completed before application of MMA. MMA can be used to rank models and calculate posterior model probabilities. These can be used to (1) determine the relative importance of the characteristics embodied in the alternative models  (2) calculate model-averaged parameter estimates and predictions  and (3) quantify the uncertainty of parameter estimates and predictions in a way that integrates the variations represented by the alternative models. There is a lack of consensus on what model analysis methods are best  so MMA provides four default methods. Two are based on Kullback-Leibler information  and use the AIC (Akaike Information Criterion) or AICc (second-order-bias-corrected AIC) model discrimination criteria. The other two default methods are the BIC (Bayesian Information Criterion) and the KIC (Kashyap Information Criterion) model discrimination criteria. Use of the KIC criterion is equivalent to using the maximum-likelihood Bayesian model averaging (MLBMA) method. AIC  AICc  and BIC can be derived from Frequentist or Bayesian arguments. The default methods based on Kullback-Leibler information have a number of theoretical advantages  including that they tend to favor more complicated models as more data become available than do the other methods  which makes sense in many situations. Many applications of MMA willmm_par2.0: An object-oriented molecular dynamics simulation program parallelized using a hierarchical scheme with MPI and OPENMPNASA Astrophysics Data System (ADS)Oh  Kwang Jin; Kang  Ji Hoon; Myung  Hun Joo2012-02-01 decomposition is not popular due to its poor scalability. On the other hand  domain decomposition scheme is better for scalability. It still has a limitation in utilizing a large number of cores on recent petascale computers due to the requirement that the domain size is larger than the potential cutoff distance. To go beyond such a limitation  a hierarchical parallelization scheme has been adopted in this new version and implemented using MPI [7] and OPENMP [8]. Summary of revisions: (1) Object-oriented programming has been used. (2) A hierarchical parallelization scheme has been adopted. (3) SPME routine has been fully parallelized with parallel 3D FFT using volumetric decomposition scheme [9]. K.J.O. thanks Mr. Seung Min Lee for useful discussion on programming and debugging. Running time: Running time depends on system size and methods used. For test system containing a protein (PDB id: 5DHFR) with CHARMM22 force field [10] and 7023 TIP3P [11] waters in simulation box having dimension 62.23 Ã…Ã—62.23 Ã…Ã—62.23 Ã…  the benchmark results are given in Fig. 1. Here the potential cutoff distance was set to 12 Ã… and the switching function was applied from 10 Ã… for the force calculation in real space. For the SPME [12] calculation  K  K  and K were set to 64 and the interpolation order was set to 4. To do the fast Fourier transform  we used Intel MKL library. All bonds including hydrogen atoms were constrained using SHAKE/RATTLE algorithms [13 14]. The code was compiled using Intel compiler version 11.1 and mvapich2 version 1.5. Fig. 2 shows performance gains from using CUDA-enabled version [15] of mm_par for 5DHFR simulation in water on Intel Core2Quad 2.83 GHz and GeForce GTX 580. Even though mm_par2.0 is not ported yet for GPU  its performance data would be useful to expect mm_par2.0 performance on GPU. Timing results for 1000 MD steps. 1  2  4  and 8 in the figure mean the number of OPENMP threads. Timing results for 1000 MD steps from double precision simulation on CPUEvaluation of Computational Codes for Underwater Hull Analysis Model ApplicationsDTIC Science & Technology2014-02-05desirable that the code can be run on a Windows operating system on the laptop  desktop  or workstation. The focus on Windows machines allows for...transition to such systems as operated on the Navy-Marine Corp Internet (NMCI). For each code the initial cost and yearly maintenance are identified...suggestions for reducing this burden to Department of Defense  Washington Headquarters Services  Directorate for Information Operations and ReportsHow to differentiate collective variables in free energy codes: Computer-algebra code generation and automatic differentiationNASA Astrophysics Data System (ADS)Giorgino  Toni2018-07-01The proper choice of collective variables (CVs) is central to biased-sampling free energy reconstruction methods in molecular dynamics simulations. The PLUMED 2 library  for instance  provides several sophisticated CV choices  implemented in a C++ framework; however  developing new CVs is still time consuming due to the need to provide code for the analytical derivatives of all functions with respect to atomic coordinates. We present two solutions to this problem  namely (a) symbolic differentiation and code generation  and (b) automatic code differentiation  in both cases leveraging open-source libraries (SymPy and Stan Math  respectively). The two approaches are demonstrated and discussed in detail implementing a realistic example CV  the local radius of curvature of a polymer. Users may use the code as a template to streamline the implementation of their own CVs using high-level constructs and automatic gradient computation.A generalized one-dimensional computer code for turbomachinery cooling passage flow calculationsNASA Technical Reports Server (NTRS)Kumar  Ganesh N.; Roelke  Richard J.; Meitner  Peter L.1989-01-01A generalized one-dimensional computer code for analyzing the flow and heat transfer in the turbomachinery cooling passages was developed. This code is capable of handling rotating cooling passages with turbulators  180 degree turns  pin fins  finned passages  by-pass flows  tip cap impingement flows  and flow branching. The code is an extension of a one-dimensional code developed by P. Meitner. In the subject code  correlations for both heat transfer coefficient and pressure loss computations were developed to model each of the above mentioned type of coolant passages. The code has the capability of independently computing the friction factor and heat transfer coefficient on each side of a rectangular passage. Either the mass flow at the inlet to the channel or the exit plane pressure can be specified. For a specified inlet total temperature  inlet total pressure  and exit static pressure  the code computers the flow rates through the main branch and the subbranches  flow through tip cap for impingement cooling  in addition to computing the coolant pressure  temperature  and heat transfer coefficient distribution in each coolant flow branch. Predictions from the subject code for both nonrotating and rotating passages agree well with experimental data. The code was used to analyze the cooling passage of a research cooled radial rotor.Development of an object-oriented ORIGEN for advanced nuclear fuel modeling applicationsSciTech ConnectSkutnik  S.; Havloej  F.; Lago  D.2013-07-01The ORIGEN package serves as the core depletion and decay calculation module within the SCALE code system. A recent major re-factor to the ORIGEN code architecture as part of an overall modernization of the SCALE code system has both greatly enhanced its maintainability as well as afforded several new capabilities useful for incorporating depletion analysis into other code frameworks. This paper will present an overview of the improved ORIGEN code architecture (including the methods and data structures introduced) as well as current and potential future applications utilizing the new ORIGEN framework. (authors)A Study on the Difficulties of Learning Phase Transition in Object-Oriented Analysis and Design from the Viewpoint of Semantic DistanceERIC Educational Resources Information CenterShin  Shin-Shing2015-01-01Students in object-oriented analysis and design (OOAD) courses typically encounter difficulties transitioning from object-oriented analysis (OOA) to logical design (OOLD). This study conducted an empirical experiment to examine these learning difficulties by evaluating differences between OOA-to-OOLD and OOLD-to-object-oriented-physical-designâ€¦A Python object-oriented framework for the CMS alignment and calibration dataNASA Astrophysics Data System (ADS)Dawes  Joshua H.; CMS Collaboration2017-10-01The Alignment  Calibrations and Databases group at the CMS Experiment delivers Alignment and Calibration Conditions Data to a large set of workflows which process recorded event data and produce simulated events. The current infrastructure for releasing and consuming Conditions Data was designed in the two years of the first LHC long shutdown to respond to use cases from the preceding data-taking period. During the second run of the LHC  new use cases were defined. For the consumption of Conditions Metadata  no common interface existed for the detector experts to use in Python-based custom scripts  resulting in many different querying and transaction management patterns. A new framework has been built to address such use cases: a simple object-oriented tool that detector experts can use to read and write Conditions Metadata when using Oracle and SQLite databases  that provides a homogeneous method of querying across all services. The tool provides mechanisms for segmenting large sets of conditions while releasing them to the production database  allows for uniform error reporting to the client-side from the server-side and optimizes the data transfer to the server. The architecture of the new service has been developed exploiting many of the features made available by the metadata consumption framework to implement the required improvements. This paper presents the details of the design and implementation of the new metadata consumption and data upload framework  as well as analyses of the new upload serviceâ€™s performance as the server-side state varies.Effects of material properties and object orientation on precision grip kinematics.PubMedPaulun  Vivian C; Gegenfurtner  Karl R; Goodale  Melvyn A; Fleming  Roland W2016-08-01Successfully picking up and handling objects requires taking into account their physical properties (e.g.  material) and position relative to the body. Such features are often inferred by sight  but it remains unclear to what extent observers vary their actions depending on the perceived properties. To investigate this  we asked participants to grasp  lift and carry cylinders to a goal location with a precision grip. The cylinders were made of four different materials (Styrofoam  wood  brass and an additional brass cylinder covered with Vaseline) and were presented at six different orientations with respect to the participant (0Â°  30Â°  60Â°  90Â°  120Â°  150Â°). Analysis of their grasping kinematics revealed differences in timing and spatial modulation at all stages of the movement that depended on both material and orientation. Object orientation affected the spatial configuration of index finger and thumb during the grasp  but also the timing of handling and transport duration. Material affected the choice of local grasp points and the duration of the movement from the first visual input until release of the object. We find that conditions that make grasping more difficult (orientation with the base pointing toward the participant  high weight and low surface friction) lead to longer durations of individual movement segments and a more careful placement of the fingers on the object.Object-oriented wavefront correction in an asymmetric amplifying high-power laser systemNASA Astrophysics Data System (ADS)Yang  Ying; Yuan  Qiang; Wang  Deen; Zhang  Xin; Dai  Wanjun; Hu  Dongxia; Xue  Qiao; Zhang  Xiaolu; Zhao  Junpu; Zeng  Fa; Wang  Shenzhen; Zhou  Wei; Zhu  Qihua; Zheng  Wanguo2018-05-01An object-oriented wavefront control method is proposed aiming for excellent near-field homogenization and far-field distribution in an asymmetric amplifying high-power laser system. By averaging the residual errors of the propagating beam  smaller pinholes could be employed on the spatial filters to improve the beam quality. With this wavefront correction system  the laser performance of the main amplifier system in the Shen Guang-III laser facility has been improved. The residual wavefront aberration at the position of each pinhole is below 2 Âµm (peak-to-valley). For each pinhole  95% of the total laser energy is enclosed within a circle whose diameter is no more than six times the diffraction limit. At the output of the main laser system  the near-field modulation and contrast are 1.29% and 7.5%  respectively  and 95% of the 1Ï‰ (1053â€‰nm) beam energy is contained within a 39.8 Âµrad circle (6.81 times the diffraction limit) under a laser fluence of 5.8 J cm-2. The measured 1Ï‰ focal spot size and near-field contrast are better than the design values of the Shen Guang-III laser facility.Vegetation Monitoring of Mashhad Using AN Object-Oriented POST Classification Comparison MethodNASA Astrophysics Data System (ADS)Khalili Moghadam  N.; Delavar  M. R.; Forati  A.2017-09-01By and large  todays mega cities are confronting considerable urban development in which many new buildings are being constructed in fringe areas of these cities. This remarkable urban development will probably end in vegetation reduction even though each mega city requires adequate areas of vegetation  which is considered to be crucial and helpful for these cities from a wide variety of perspectives such as air pollution reduction  soil erosion prevention  and eco system as well as environmental protection. One of the optimum methods for monitoring this vital component of each city is multi-temporal satellite images acquisition and using change detection techniques. In this research  the vegetation and urban changes of Mashhad  Iran  were monitored using an object-oriented (marker-based watershed algorithm) post classification comparison (PCC) method. A Bi-temporal multi-spectral Landsat satellite image was used from the study area to detect the changes of urban and vegetation areas and to find a relation between these changes. The results of this research demonstrate that during 1987-2017  Mashhad urban area has increased about 22525 hectares and the vegetation area has decreased approximately 4903 hectares. These statistics substantiate the close relationship between urban development and vegetation reduction. Moreover  the overall accuracies of 85.5% and 91.2% were achieved for the first and the second image classification  respectively. In addition  the overall accuracy and kappa coefficient of change detection were assessed 84.1% and 70.3%  respectively.Research on Remote Sensing Geological Information Extraction Based on Object Oriented ClassificationNASA Astrophysics Data System (ADS)Gao  Hui2018-04-01The northern Tibet belongs to the Sub cold arid climate zone in the plateau. It is rarely visited by people. The geological working conditions are very poor. However  the stratum exposures are good and human interference is very small. Therefore  the research on the automatic classification and extraction of remote sensing geological information has typical significance and good application prospect. Based on the object-oriented classification in Northern Tibet  using the Worldview2 high-resolution remote sensing data  combined with the tectonic information and image enhancement  the lithological spectral features  shape features  spatial locations and topological relations of various geological information are excavated. By setting the threshold  based on the hierarchical classification  eight kinds of geological information were classified and extracted. Compared with the existing geological maps  the accuracy analysis shows that the overall accuracy reached 87.8561 %  indicating that the classification-oriented method is effective and feasible for this study area and provides a new idea for the automatic extraction of remote sensing geological information.An Object-Oriented Simulator for 3D Digital Breast Tomosynthesis Imaging SystemPubMed CentralCengiz  Kubra2013-01-01Digital breast tomosynthesis (DBT) is an innovative imaging modality that provides 3D reconstructed images of breast to detect the breast cancer. Projections obtained with an X-ray source moving in a limited angle interval are used to reconstruct 3D image of breast. Several reconstruction algorithms are available for DBT imaging. Filtered back projection algorithm has traditionally been used to reconstruct images from projections. Iterative reconstruction algorithms such as algebraic reconstruction technique (ART) were later developed. Recently  compressed sensing based methods have been proposed in tomosynthesis imaging problem. We have developed an object-oriented simulator for 3D digital breast tomosynthesis (DBT) imaging system using C++ programming language. The simulator is capable of implementing different iterative and compressed sensing based reconstruction methods on 3D digital tomosynthesis data sets and phantom models. A user friendly graphical user interface (GUI) helps users to select and run the desired methods on the designed phantom models or real data sets. The simulator has been tested on a phantom study that simulates breast tomosynthesis imaging problem. Results obtained with various methods including algebraic reconstruction technique (ART) and total variation regularized reconstruction techniques (ART+TV) are presented. Reconstruction results of the methods are compared both visually and quantitatively by evaluating performances of the methods using mean structural similarity (MSSIM) values. PMID:24371468[Object-oriented aquatic vegetation extracting approach based on visible vegetation indices.PubMedJing  Ran; Deng  Lei; Zhao  Wen Ji; Gong  Zhao Ning2016-05-01Using the estimation of scale parameters (ESP) image segmentation tool to determine the ideal image segmentation scale  the optimal segmented image was created by the multi-scale segmentation method. Based on the visible vegetation indices derived from mini-UAV imaging data  we chose a set of optimal vegetation indices from a series of visible vegetation indices  and built up a decision tree rule. A membership function was used to automatically classify the study area and an aquatic vegetation map was generated. The results showed the overall accuracy of image classification using the supervised classification was 53.7%  and the overall accuracy of object-oriented image analysis (OBIA) was 91.7%. Compared with pixel-based supervised classification method  the OBIA method improved significantly the image classification result and further increased the accuracy of extracting the aquatic vegetation. The Kappa value of supervised classification was 0.4  and the Kappa value based OBIA was 0.9. The experimental results demonstrated that using visible vegetation indices derived from the mini-UAV data and OBIA method extracting the aquatic vegetation developed in this study was feasible and could be applied in other physically similar areas.A class Hierarchical  object-oriented approach to virtual memory managementNASA Technical Reports Server (NTRS)Russo  Vincent F.; Campbell  Roy H.; Johnston  Gary M.1989-01-01The Choices family of operating systems exploits class hierarchies and object-oriented programming to facilitate the construction of customized operating systems for shared memory and networked multiprocessors. The software is being used in the Tapestry laboratory to study the performance of algorithms  mechanisms  and policies for parallel systems. Described here are the architectural design and class hierarchy of the Choices virtual memory management system. The software and hardware mechanisms and policies of a virtual memory system implement a memory hierarchy that exploits the trade-off between response times and storage capacities. In Choices  the notion of a memory hierarchy is captured by abstract classes. Concrete subclasses of those abstractions implement a virtual address space  segmentation  paging  physical memory management  secondary storage  and remote (that is  networked) storage. Captured in the notion of a memory hierarchy are classes that represent memory objects. These classes provide a storage mechanism that contains encapsulated data and have methods to read or write the memory object. Each of these classes provides specializations to represent the memory hierarchy.Sugarcane Crop Extraction Using Object-Oriented Method from ZY-3 High Resolution Satellite Tlc ImageNASA Astrophysics Data System (ADS)Luo  H.; Ling  Z. Y.; Shao  G. Z.; Huang  Y.; He  Y. Q.; Ning  W. Y.; Zhong  Z.2018-04-01Sugarcane is one of the most important crops in Guangxi  China. As the development of satellite remote sensing technology  more remotely sensed images can be used for monitoring sugarcane crop. With the help of Three Line Camera (TLC) images  wide coverage and stereoscopic mapping ability  Chinese ZY-3 high resolution stereoscopic mapping satellite is useful in attaining more information for sugarcane crop monitoring  such as spectral  shape  texture difference between forward  nadir and backward images. Digital surface model (DSM) derived from ZY-3 TLC images are also able to provide height information for sugarcane crop. In this study  we make attempt to extract sugarcane crop from ZY-3 images  which are acquired in harvest period. Ortho-rectified TLC images  fused image  DSM are processed for our extraction. Then Object-oriented method is used in image segmentation  example collection  and feature extraction. The results of our study show that with the help of ZY-3 TLC image  the information of sugarcane crop in harvest time can be automatic extracted  with an overall accuracy of about 85.3 %.Object-oriented approach to fast display of electrophysiological data under MS-windows.PubMedMarion-Poll  F1995-12-01Microcomputers provide neuroscientists an alternative to a host of laboratory equipment to record and analyze electrophysiological data. Object-oriented programming tools bring an essential link between custom needs for data acquisition and analysis with general software packages. In this paper  we outline the layout of basic objects that display and manipulate electrophysiological data files. Visual inspection of the recordings is a basic requirement of any data analysis software. We present an approach that allows flexible and fast display of large data sets. This approach involves constructing an intermediate representation of the data in order to lower the number of actual points displayed while preserving the aspect of the data. The second group of objects is related to the management of lists of data files. Typical experiments designed to test the biological activity of pharmacological products include scores of files. Data manipulation and analysis are facilitated by creating multi-document objects that include the names of all experiment files. Implementation steps of both objects are described for an MS-Windows hosted application.An object-oriented simulator for 3D digital breast tomosynthesis imaging system.PubMedSeyyedi  Saeed; Cengiz  Kubra; Kamasak  Mustafa; Yildirim  Isa2013-01-01Digital breast tomosynthesis (DBT) is an innovative imaging modality that provides 3D reconstructed images of breast to detect the breast cancer. Projections obtained with an X-ray source moving in a limited angle interval are used to reconstruct 3D image of breast. Several reconstruction algorithms are available for DBT imaging. Filtered back projection algorithm has traditionally been used to reconstruct images from projections. Iterative reconstruction algorithms such as algebraic reconstruction technique (ART) were later developed. Recently  compressed sensing based methods have been proposed in tomosynthesis imaging problem. We have developed an object-oriented simulator for 3D digital breast tomosynthesis (DBT) imaging system using C++ programming language. The simulator is capable of implementing different iterative and compressed sensing based reconstruction methods on 3D digital tomosynthesis data sets and phantom models. A user friendly graphical user interface (GUI) helps users to select and run the desired methods on the designed phantom models or real data sets. The simulator has been tested on a phantom study that simulates breast tomosynthesis imaging problem. Results obtained with various methods including algebraic reconstruction technique (ART) and total variation regularized reconstruction techniques (ART+TV) are presented. Reconstruction results of the methods are compared both visually and quantitatively by evaluating performances of the methods using mean structural similarity (MSSIM) values.Object-oriented approach to the automatic segmentation of bones from pediatric hand radiographsNASA Astrophysics Data System (ADS)Shim  Hyeonjoon; Liu  Brent J.; Taira  Ricky K.; Hall  Theodore R.1997-04-01The purpose of this paper is to develop a robust and accurate method that automatically segments phalangeal and epiphyseal bones from digital pediatric hand radiographs exhibiting various stages of growth. The development of this system draws principles from object-oriented design  model- guided analysis  and feedback control. A system architecture called 'the object segmentation machine' was implemented incorporating these design philosophies. The system is aided by a knowledge base where all model contours and other information such as age  race  and sex  are stored. These models include object structure models  shape models  1-D wrist profiles  and gray level histogram models. Shape analysis is performed first by using an arc-length orientation transform to break down a given contour into elementary segments and curves. Then an interpretation tree is used as an inference engine to map known model contour segments to data contour segments obtained from the transform. Spatial and anatomical relationships among contour segments work as constraints from shape model. These constraints aid in generating a list of candidate matches. The candidate match with the highest confidence is chosen to be the current intermediate result. Verification of intermediate results are perform by a feedback control loop.Object oriented design (OOD) in real-time hardware-in-the-loop (HWIL) simulationsNASA Astrophysics Data System (ADS)Morris  Joe; Richard  Henri; Lowman  Alan; Youngren  Rob2006-05-01Using Object Oriented Design (OOD) concepts in AMRDEC's Hardware-in-the Loop (HWIL) real-time simulations allows the user to interchange parts of the simulation to meet test requirements. A large-scale three-spectral band simulator connected via a high speed reflective memory ring for time-critical data transfers to PC controllers connected by non real-time Ethernet protocols is used to separate software objects from logical entities close to their respective controlled hardware. Each standalone object does its own dynamic initialization  real-time processing  and end of run processing; therefore it can be easily maintained and updated. A Resource Allocation Program (RAP) is also utilized along with a device table to allocate  organize  and document the communication protocol between the software and hardware components. A GUI display program lists all allocations and deallocations of HWIL memory and hardware resources. This interactive program is also used to clean up defunct allocations of dead processes. Three examples are presented using the OOD and RAP concepts. The first is the control of an ACUTRONICS built three-axis flight table using the same control for calibration and real-time functions. The second is the transportability of a six-degree-of-freedom (6-DOF) simulation from an Onyx residence to a Linux-PC. The third is the replacement of the 6-DOF simulation with a replay program to drive the facility with archived run data for demonstration or analysis purposes.The Impact of Ada and Object-Oriented Design in NASA Goddard's Flight Dynamics DivisionNASA Technical Reports Server (NTRS)Waligora  Sharon; Bailey  John; Stark  Mike1996-01-01This paper presents the highlights and key findings of 10 years of use and study of Ada and object-oriented design in NASA Goddard's Flight Dynamics Division (FDD). In 1985  the Software Engineering Laboratory (SEL) began investigating how the Ada language might apply to FDD software development projects. Although they began cautiously using Ada on only a few pilot projects  they expected that  if the Ada pilots showed promising results  the FDD would fully transition its entire development organization from FORTRAN to Ada within 10 years. However  10 years later  the FDD still produced 80 percent of its software in FORTRAN and had begun using C and C++  despite positive results on Ada projects. This paper presents the final results of a SEL study to quantify the impact of Ada in the FDD  to determine why Ada has not flourished  and to recommend future directions regarding Ada. Project trends in both languages are examined as are external factors and cultural issues that affected the infusion of this technology. The detailed results of this study were published in a formal study report in March of 1995. This paper supersedes the preliminary results of this study that were presented at the Eighteenth Annual Software Engineering Workshop in 1993.Detecting Slums from Quick Bird Data in Pune Using AN Object Oriented ApproachNASA Astrophysics Data System (ADS)Shekhar  S.2012-07-01We have been witnessing a gradual and steady transformation from a pre dominantly rural society to an urban society in India and by 2030  it will have more people living in urban than rural areas. Slums formed an integral part of Indian urbanisation as most of the Indian cities lack in basic needs of an acceptable life. Many efforts are being taken to improve their conditions. To carry out slum renewal programs and monitor its implementation  slum settlements should be recorded to obtain an adequate spatial data base. This can be only achieved through the analysis of remote sensing data with very high spatial resolution. Regarding the occurrences of settlement areas in the remote sensing data pixel-based approach on a high resolution image is unable to represent the heterogeneity of complex urban environments. Hence there is a need for sophisticated method and data for slum analysis. An attempt has been made to detect and discriminate the slums of Pune city by describing typical characteristics of these settlements  by using eCognition software from quick bird data on the basis of object oriented approach. Based on multi resolution segmentation  initial objects were created and further depend on texture  geometry and contextual characteristics of the image objects  they were classified into slums and non-slums. The developed rule base allowed the description of knowledge about phenomena clearly and easily using fuzzy membership functions and the described knowledge stored in the classification rule base led to the best classification with more than 80% accuracy.A Neural Dynamic Model Generates Descriptions of Object-Oriented Actions.PubMedRichter  Mathis; Lins  Jonas; SchÃ¶ner  Gregor2017-01-01Describing actions entails that relations between objects are discovered. A pervasively neural account of this process requires that fundamental problems are solved: the neural pointer problem  the binding problem  and the problem of generating discrete processing steps from time-continuous neural processes. We present a prototypical solution to these problems in a neural dynamic model that comprises dynamic neural fields holding representations close to sensorimotor surfaces as well as dynamic neural nodes holding discrete  language-like representations. Making the connection between these two types of representations enables the model to describe actions as well as to perceptually ground movement phrases-all based on real visual input. We demonstrate how the dynamic neural processes autonomously generate the processing steps required to describe or ground object-oriented actions. By solving the fundamental problems of neural pointing  binding  and emergent discrete processing  the model may be a first but critical step toward a systematic neural processing account of higher cognition. Copyright Â© 2017 The Authors. Topics in Cognitive Science published by Wiley Periodicals  Inc. on behalf of Cognitive Science Society.Object-Oriented Control System Design Using On-Line Training of Artificial Neural NetworksNASA Technical Reports Server (NTRS)Rubaai  Ahmed1997-01-01This report deals with the object-oriented model development of a neuro-controller design for permanent magnet (PM) dc motor drives. The system under study is described as a collection of interacting objects. Each object module describes the object behaviors  called methods. The characteristics of the object are included in its variables. The knowledge of the object exists within its variables  and the performance is determined by its methods. This structure maps well to the real world objects that comprise the system being modeled. A dynamic learning architecture that possesses the capabilities of simultaneous on-line identification and control is incorporated to enforce constraints on connections and control the dynamics of the motor. The control action is implemented ""on-line""  in ""real time"" in such a way that the predicted trajectory follows a specified reference model. A design example of controlling a PM dc motor drive on-line shows the effectiveness of the design tool. This will therefore be very useful in aerospace applications. It is expected to provide an innovative and noval software model for the rocket engine numerical simulator executive.ARACHNID: A prototype object-oriented database tool for distributed systemsNASA Technical Reports Server (NTRS)Younger  Herbert; Oreilly  John; Frogner  Bjorn1994-01-01This paper discusses the results of a Phase 2 SBIR project sponsored by NASA and performed by MIMD Systems  Inc. A major objective of this project was to develop specific concepts for improved performance in accessing large databases. An object-oriented and distributed approach was used for the general design  while a geographical decomposition was used as a specific solution. The resulting software framework is called ARACHNID. The Faint Source Catalog developed by NASA was the initial database testbed. This is a database of many giga-bytes  where an order of magnitude improvement in query speed is being sought. This database contains faint infrared point sources obtained from telescope measurements of the sky. A geographical decomposition of this database is an attractive approach to dividing it into pieces. Each piece can then be searched on individual processors with only a weak data linkage between the processors being required. As a further demonstration of the concepts implemented in ARACHNID  a tourist information system is discussed. This version of ARACHNID is the commercial result of the project. It is a distributed  networked  database application where speed  maintenance  and reliability are important considerations. This paper focuses on the design concepts and technologies that form the basis for ARACHNID.An object-oriented model of the cardiopulmonary system with emphasis on the gravity effect.PubMedChuong Ngo; Herranz  Silvia Briones; Misgeld  Berno; Vollmer  Thomas; Leonhardt  Steffen2016-08-01We introduce a novel comprehensive model of the cardiopulmonary system with emphasis on perfusion and ventilation distribution along the vertical thorax axis under the gravity effect. By using an object-oriented environment  the complex physiological system can be represented by a network of electrical  lumped-element compartments. The lungs are divided into three zones: upper  middle  and lower zone. Blood flow increases with the distance from the apex to the base of the lungs. The upper zone is characterized by a complete collapse of the pulmonary capillary vasculature; thus  there is no flow in this zone. The second zone has a ""waterfall effect"" where the blood flow is determined by the difference between the pulmonary-arterial and alveolar pressures. At resting position  the upper lobes of the lungs are more expanded than the middle and lower lobes. However  during spontaneous breathing  ventilation is nonuniform with more air entering the lower lobes than the middle and upper lobes. A simulative model of the complete system is developed which shows results in good agreement with the literature.RTE: A computer code for Rocket Thermal EvaluationNASA Technical Reports Server (NTRS)Naraghi  Mohammad H. N.1995-01-01The numerical model for a rocket thermal analysis code (RTE) is discussed. RTE is a comprehensive thermal analysis code for thermal analysis of regeneratively cooled rocket engines. The input to the code consists of the composition of fuel/oxidant mixture and flow rates  chamber pressure  coolant temperature and pressure. dimensions of the engine  materials and the number of nodes in different parts of the engine. The code allows for temperature variation in axial  radial and circumferential directions. By implementing an iterative scheme  it provides nodal temperature distribution  rates of heat transfer  hot gas and coolant thermal and transport properties. The fuel/oxidant mixture ratio can be varied along the thrust chamber. This feature allows the user to incorporate a non-equilibrium model or an energy release model for the hot-gas-side. The user has the option of bypassing the hot-gas-side calculations and directly inputting the gas-side fluxes. This feature is used to link RTE to a boundary layer module for the hot-gas-side heat flux calculations.Second Generation Integrated Composite Analyzer (ICAN) Computer CodeNASA Technical Reports Server (NTRS)Murthy  Pappu L. N.; Ginty  Carol A.; Sanfeliz  Jose G.1993-01-01This manual updates the original 1986 NASA TP-2515  Integrated Composite Analyzer (ICAN) Users and Programmers Manual. The various enhancements and newly added features are described to enable the user to prepare the appropriate input data to run this updated version of the ICAN code. For reference  the micromechanics equations are provided in an appendix and should be compared to those in the original manual for modifications. A complete output for a sample case is also provided in a separate appendix. The input to the code includes constituent material properties  factors reflecting the fabrication process  and laminate configuration. The code performs micromechanics  macromechanics  and laminate analyses  including the hygrothermal response of polymer-matrix-based fiber composites. The output includes the various ply and composite properties  the composite structural response  and the composite stress analysis results with details on failure. The code is written in FORTRAN 77 and can be used efficiently as a self-contained package (or as a module) in complex structural analysis programs. The input-output format has changed considerably from the original version of ICAN and is described extensively through the use of a sample problem.Analysis of airborne antenna systems using geometrical theory of diffraction and moment method computer codesNASA Technical Reports Server (NTRS)Hartenstein  Richard G.  Jr.1985-01-01Computer codes have been developed to analyze antennas on aircraft and in the presence of scatterers. The purpose of this study is to use these codes to develop accurate computer models of various aircraft and antenna systems. The antenna systems analyzed are a P-3B L-Band antenna  an A-7E UHF relay pod antenna  and traffic advisory antenna system installed on a Bell Long Ranger helicopter. Computer results are compared to measured ones with good agreement. These codes can be used in the design stage of an antenna system to determine the optimum antenna location and save valuable time and costly flight hours.Code of Ethical Conduct for Computer-Using Educators: An ICCE Policy Statement.ERIC Educational Resources Information CenterComputing Teacher  19871987-01-01Prepared by the International Council for Computers in Education's Ethics and Equity Committee  this code of ethics for educators using computers covers nine main areas: curriculum issues  issues relating to computer access  privacy/confidentiality issues  teacher-related issues  student issues  the community  school organizational issues â€¦A fast technique for computing syndromes of BCH and RS codes. [deep space networkNASA Technical Reports Server (NTRS)Reed  I. S.; Truong  T. K.; Miller  R. L.1979-01-01A combination of the Chinese Remainder Theorem and Winograd's algorithm is used to compute transforms of odd length over GF(2 to the m power). Such transforms are used to compute the syndromes needed for decoding CBH and RS codes. The present scheme requires substantially fewer multiplications and additions than the conventional method of computing the syndromes directly.ARCADIA: a system for the integration of angiocardiographic data and images by an object-oriented DBMS.PubMedPinciroli  F; Combi  C; Pozzi  G1995-02-01Use of data base techniques to store medical records has been going on for more than 40 years. Some aspects still remain unresolved  e.g.  the management of textual data and image data within a single system. Object-orientation techniques applied to a database management system (DBMS) allow the definition of suitable data structures (e.g.  to store digital images): some facilities allow the use of predefined structures when defining new ones. Currently available object-oriented DBMS  however  still need improvements both in the schema update and in the query facilities. This paper describes a prototype of a medical record that includes some multimedia features  managing both textual and image data. The prototype here described considers data from the medical records of patients subjected to percutaneous transluminal coronary artery angioplasty. We developed it on a Sun workstation with a Unix operating system and ONTOS as an object-oriented DBMS.Computational Participation: Understanding Coding as an Extension of Literacy InstructionERIC Educational Resources Information CenterBurke  Quinn; O'Byrne  W. Ian; Kafai  Yasmin B.2016-01-01Understanding the computational concepts on which countless digital applications run offers learners the opportunity to no longer simply read such media but also become more discerning end users and potentially innovative ""writers"" of new media themselves. To think computationally--to solve problems  to design systems  and to process andâ€¦Selection of a computer code for Hanford low-level waste engineered-system performance assessmentSciTech ConnectMcGrail  B.P.; Mahoney  L.A.Planned performance assessments for the proposed disposal of low-level waste (LLW) glass produced from remediation of wastes stored in underground tanks at Hanford  Washington will require calculations of radionuclide release rates from the subsurface disposal facility. These calculations will be done with the aid of computer codes. Currently available computer codes were ranked in terms of the feature sets implemented in the code that match a set of physical  chemical  numerical  and functional capabilities needed to assess release rates from the engineered system. The needed capabilities were identified from an analysis of the important physical and chemical process expected tomoreÂ Â» affect LLW glass corrosion and the mobility of radionuclides. The highest ranked computer code was found to be the ARES-CT code developed at PNL for the US Department of Energy for evaluation of and land disposal sites.Â«Â lessminimUML: A Minimalist Approach to UML Diagramming for Early Computer Science EducationERIC Educational Resources Information CenterTurner  Scott A.; Perez-Quinones  Manuel A.; Edwards  Stephen H.2005-01-01In introductory computer science courses  the Unified Modeling Language (UML) is commonly used to teach basic object-oriented design. However  there appears to be a lack of suitable software to support this task. Many of the available programs that support UML focus on developing code and not on enhancing learning. Programs designed forâ€¦Computations for Truck Sliding with TRUCK 3.1 CodeDTIC Science & Technology1989-08-0116 REFERENCES 1. L u. \\Villiam N.. Hobbs. Norman P. and Atkinson  Michael. TRUCK 3.1-An Improrcd Digital (’oiputtr Program for Calculating the Response...for Operations and Plans ATIN: Technical Libary Director of Chemical & Nuear Operations Dpartnt of the AIW Waskbington  DC 20310 1 Cocaeder US Ay...Lawrenoe Livermore Lab. ATIN: Code 2124  Tedhnical ATTN: Tech Info Dept L-3 Reports Libary P.O. Be 808 Monterey  CA 93940 Livermore  CA 94550 AFSCAn architecture for object-oriented intelligent control of power systems in spaceNASA Technical Reports Server (NTRS)Holmquist  Sven G.; Jayaram  Prakash; Jansen  Ben H.1993-01-01A control system for autonomous distribution and control of electrical power during space missions is being developed. This system should free the astronauts from localizing faults and reconfiguring loads if problems with the power distribution and generation components occur. The control system uses an object-oriented simulation model of the power system and first principle knowledge to detect  identify  and isolate faults. Each power system component is represented as a separate object with knowledge of its normal behavior. The reasoning process takes place at three different levels of abstraction: the Physical Component Model (PCM) level  the Electrical Equivalent Model (EEM) level  and the Functional System Model (FSM) level  with the PCM the lowest level of abstraction and the FSM the highest. At the EEM level the power system components are reasoned about as their electrical equivalents  e.g  a resistive load is thought of as a resistor. However  at the PCM level detailed knowledge about the component's specific characteristics is taken into account. The FSM level models the system at the subsystem level  a level appropriate for reconfiguration and scheduling. The control system operates in two modes  a reactive and a proactive mode  simultaneously. In the reactive mode the control system receives measurement data from the power system and compares these values with values determined through simulation to detect the existence of a fault. The nature of the fault is then identified through a model-based reasoning process using mainly the EEM. Compound component models are constructed at the EEM level and used in the fault identification process. In the proactive mode the reasoning takes place at the PCM level. Individual components determine their future health status using a physical model and measured historical data. In case changes in the health status seem imminent the component warns the control system about its impending failure. The fault isolation",life cycle model, 'Personal computer',https://www.science.gov/topicpages/o/object-oriented%2Bcomputer%2Bcode,'previous computer'
